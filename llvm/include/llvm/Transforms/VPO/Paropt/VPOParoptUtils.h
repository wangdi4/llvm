#if INTEL_COLLAB // -*- C++ -*-
//=-- VPOParoptUtils.h - Class definition for VPO Paropt utilites -*- C++ -*-=//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
// Authors:
// --------
// Xinmin Tian (xinmin.tian@intel.com)
//
// Major Revisions:
// ----------------
// Nov 2015: Initial Implementation of OpenMP runtime APIs (Xinmin Tian)
//
//===----------------------------------------------------------------------===//
///
/// \file
/// This file defines the VPOParoptUtils class and provides a set of utilities
/// that are used for Paropt transformation and multi-threaded code generation.
///
//===----------------------------------------------------------------------===//

#ifndef LLVM_TRANSFORM_VPO_PAROPT_UTILS_H
#define LLVM_TRANSFORM_VPO_PAROPT_UTILS_H

#include "llvm/ADT/SmallVector.h"
#include "llvm/ADT/StringMap.h"
#include "llvm/Analysis/LoopInfo.h"
#include "llvm/Analysis/TargetLibraryInfo.h"
#include "llvm/IR/DebugInfo.h"
#include "llvm/IR/Dominators.h"
#include "llvm/IR/Function.h"
#include "llvm/IR/Type.h"
#include "llvm/Support/raw_ostream.h"
#include "llvm/Support/Debug.h"
#include "llvm/Transforms/Utils/ValueMapper.h"
#include "llvm/Transforms/Utils/Cloning.h"
#include "llvm/Analysis/VPO/WRegionInfo/WRegionUtils.h"
#include <unordered_map>
#include <utility>

// Use trampoline for internal microtasks
#define KMP_IDENT_IMB              0x01

// Use c-style ident structure
#define KMP_IDENT_KMPC             0x02

// Entry point generated using Cluster OpenMP switch
#define KMP_IDENT_CLOMP            0x04

// Entry point generated by auto-parallelization
#define KMP_IDENT_AUTOPAR          0x08

// compiler generates atomic reduction option for kmpc_reduce
#define KMP_IDENT_ATOMIC_REDUCE    0x10

// replaced by KMP_IDENT_BARRIER_EXPL below
// #define KMP_IDENT_EXPLICIT_BARRIER 0x20

// Pass OpenMP version to runtime to enable non-monotonic scheduling by default
#define KMP_IDENT_OPENMP_SPEC_VERSION_5_0 0x32000000 //(major*10 + minor) << 24

//
// Implicit barriers are classified further
//
// = 0000 0010 0000 barrier directive in user's code
#define KMP_IDENT_BARRIER_EXPL           0x0020

// = 0000 0100 0000
#define KMP_IDENT_BARRIER_IMPL           0x0040

// = 0001 1100 0000 unused by cmplr
#define KMP_IDENT_BARRIER_IMPL_MASK      0x01C0

// = 0000 0100 0000
#define KMP_IDENT_BARRIER_IMPL_FOR       0x0040

// = 0000 1100 0000
#define KMP_IDENT_BARRIER_IMPL_SECTIONS  0x00C0

// = 0001 0100 0000
#define KMP_IDENT_BARRIER_IMPL_SINGLE    0x0140

// = 0001 1100 0000 workshare construct not supported by cmplr
#define KMP_IDENT_BARRIER_IMPL_WORKSHARE 0x01C0

namespace llvm {

class Value;
class Module;
class Function;
class Type;
class BasicBlock;
class Loop;
class LoopInfo;
class DominatorTree;
class StringRef;
class CallInst;
class IntrinsicInst;
class Constant;
class LLVMContext;
class BasicBlock;

namespace vpo {

namespace spirv {
  enum Scope {
    CrossDevice = 0,
    Device      = 1,
    Workgroup   = 2,
    Subgroup    = 3,
    Invocation  = 4
  };

  enum GroupOperations {
    GroupOperationReduce        = 0,
    GroupOperationInclusiveScan = 1,
    GroupOperationExclusiveScan = 2
  };

  static const StringRef ExecutionSchemeOptionName(
      "vpo-paropt-gpu-execution-scheme");

  enum ExecutionSchemeTy {
    // Implicit SIMD mode, which is kernel-level vectorization.
    // Maximum number of WIs per WG is controlled by
    // CL_DEVICE_MAX_WORK_GROUP_SIZE, CL_KERNEL_WORK_GROUP_SIZE,
    // OMP_THREAD_LIMIT environment variable and thread_limit() clause.
    // Maximum number of WGs controlled by CL_DEVICE_MAX_COMPUTE_UNITS and
    // num_teams() clause.
    ImplicitSIMDES = 0,

    // Implicit SIMD mode with SPMD - implicit SIMD mode, which is kernel-level
    // vectorization.
    // Maximum number of WIs per WG is controlled by
    // CL_DEVICE_MAX_WORK_GROUP_SIZE, CL_KERNEL_WORK_GROUP_SIZE,
    // OMP_THREAD_LIMIT environment variable and thread_limit() clause.
    // Maximum number of WGs is defined by the actual loop(s) trip-count(s)
    // and the maximum number of WIs per WG. This scheme will only be used
    // for combined constructs, e.g. "omp target teams distribute parallel for",
    // for which it is possible to compute the ND-range before the target
    // region. If num_teams() clause is present on the combined construct,
    // then we fall back to implicit SIMD mode (see default above).
    ImplicitSIMDSPMDES,

    // Explicit SIMD mode - loop level vectorization (not supported yet,
    // so we silently ignore this option).
    ExplicitSIMDES
  };
} // end namespace spirv

namespace intrinsics {
  /// This is an std::pair with TypeID as first member, and size as second.
  /// This can be expanded to be a Tuple in the future if needed.
  typedef std::pair<Type::TypeID, unsigned> IntrinsicOperandTy;

  /// \name Instances of IntrinsicOperandTy objects of different kinds.
  /// @{
  static const IntrinsicOperandTy I8   = { Type::IntegerTyID,  8 };
  static const IntrinsicOperandTy I16  = { Type::IntegerTyID,  16 };
  static const IntrinsicOperandTy I32  = { Type::IntegerTyID,  32 };
  static const IntrinsicOperandTy I64  = { Type::IntegerTyID,  64 };
  static const IntrinsicOperandTy P32  = { Type::PointerTyID,  32 };
  static const IntrinsicOperandTy P64  = { Type::PointerTyID,  64 };
  static const IntrinsicOperandTy F16  = { Type::HalfTyID,     16 };
  static const IntrinsicOperandTy F32  = { Type::FloatTyID,    32 };
  static const IntrinsicOperandTy F64  = { Type::DoubleTyID,   64 };
  static const IntrinsicOperandTy F80  = { Type::X86_FP80TyID, 80 };
  static const IntrinsicOperandTy F128 = { Type::FP128TyID,    128 };
  /// @}

} // end namespace intrinsics

/// This class contains a set of utility functions used by VPO Paropt
/// Transformation passes.
class VPOParoptUtils {

public:
  /// \name Utilities for getting/creating named StructTypes.
  /// @{

  /// If module \p M has a StructType of name \p Name, and element types \p
  /// ElementTypes, return it. Assert if a struct with matching name, but
  /// different element types is found. Return `nullptr` otherwise.
  static StructType *
  getStructTypeWithNameAndElementsFromModule(Module *M, StringRef Name,
                                             ArrayRef<Type *> ElementTypes);

  /// If in the module of \p F, a StructType with name \p Name and types \p
  /// ElementTypes exists, then return it, otherwise create that struct and
  /// return it.
  static StructType *getOrCreateStructType(Function *F, StringRef Name,
                                           ArrayRef<Type *> ElementTypes);

  /// Find any existing ident_t (LOC) struct in the module of \p F, and if
  /// found, return it. If not, create an ident_t struct and return it.
  ///
  /// The format is based on OpenMP KMP library
  ///
  /// \code
  /// typedef struct {
  ///   kmp_int32 reserved_1;   // might be used in Fortran
  ///   kmp_int32 flags;        // also f.flags; KMP_IDENT_xxx flags;
  ///                           // KMP_IDENT_KMPC identifies this union member
  ///   kmp_int32 reserved_2;   // not really used in Fortran any more
  ///   kmp_int32 reserved_3;   // source[4] in Fortran, do not use for C++
  ///   char      *psource;
  /// } ident_t;
  /// \endcode
  ///
  /// The bits that the flags field can hold are defined as KMP_IDENT_* before.
  ///
  /// Note: We need to look for exising IdentTy structs in the module before
  /// creating new ones. This is because if don't, then different Types are
  /// created for each function encountered. For example, consider a module with
  /// two functions `foo1()` and `foo2()`. When handling foo1(), a named struct
  /// type `ident_t` would be created and used for generating function
  /// declarations and calls for KMPC routines such as
  /// `__kmpc_global_thread_num(ident_t*)`. When it comes to handling `foo2()`,
  /// a new named IdentTy would be created, say `ident_t.0`, but when trying to
  /// emit a call to `__kmpc_global_thread_num`, there would be a type mismatch
  /// between the expected argument type in the declaration (ident_t *) and
  /// actual type of the argument (ident_t.0 *).
  static StructType *getIdentStructType(Function *F);

  /// @}

  /// Generate OpenMP runtime `__kmpc_begin(&loc, flags)` initialization code.
  /// The generated runtime routine call is invoked (only once) right after
  /// entering the main function.
  static CallInst *genKmpcBeginCall(Function *F, Instruction *InsertPt,
                                    StructType *IdentTy);

  /// Generate OpenMP runtime `__kmpc_end(&loc)` termination code.
  /// The generated runtime routine call is invoked (only once) right
  /// before exiting the main function.
  static CallInst *genKmpcEndCall(Function *F, Instruction *InsertPt,
                                  StructType *IdentTy);

  /// Check whether the call `__kmpc_global_thread_num()` exists in the given
  /// basic block \p BB, and return it.
  static CallInst *findKmpcGlobalThreadNumCall(BasicBlock *BB);

  /// Check whether the given instruction is the call
  /// `__kmpc_global_thread_num()`.
  static bool isKmpcGlobalThreadNumCall(Instruction *I);

  /// Generate OpenMP runtime `__kmpc_global_thread_num()` call.
  /// The generated runtime routine call is invoked (only once) to get
  /// runtime right after entering each function that contains OpenMP
  /// constructs.
  static CallInst *genKmpcGlobalThreadNumCall(Function *F,
                                              Instruction *InsertPt,
                                              StructType *IdentTy);

  /// Generate OpenMP runtime `__kmpc_threadprivate_cached` call.
  static CallInst *genKmpcThreadPrivateCachedCall(Function *F, Instruction *AI,
                                                  StructType *IdentTy,
                                                  Value *Tid, Value *GV,
                                                  Value *GVSize, Value *TpvGV);

  /// Generate OpenMP runtime `ForkTest = ___kmpc_ok_to_fork(&loc)`.
  static CallInst *genKmpcForkTest(WRegionNode *W, StructType *IdentTy,
                                   Instruction *InsertPt);

  /// Generate source location information from Instruction \p AI's `DebugLoc`.
  static GlobalVariable *genKmpcLocfromDebugLoc(Function *F, Instruction *AI,
                                                StructType *IdentTy, int Flags,
                                                BasicBlock *BS, BasicBlock *BE);

  /// \p Arg is a Value from a clause.  It is either a Constant or
  /// a Value of pointer type.  If it is a pointer Value, the method
  /// loads the clause's actual argument value via this pointer,
  /// otherwise the clause's actual argument value is \p Arg itself.
  /// The method sign-extends or truncates the clause's actual argument
  /// value to type \p Ty using the provided \p Builder.
  static Value *getOrLoadClauseArgValueWithSext(
      Value *Arg, Type *Ty, IRBuilder<> &Builder);

  /// Generate a call to set `num_threads` for the `parallel` region and
  /// `parallel loop/sections`. Example:
  /// \code
  ///  call void @__kmpc_push_num_threads(%ident_t* %loc, i32 %tid, i32 %nths)
  /// \endcode
  static CallInst *genKmpcPushNumThreads(WRegionNode *W, StructType *IdentTy,
                                         Value *Tid, Value *NumThreads,
                                         Instruction *InsertPt);

  /// Generate a call to set `num_teams` for the `teams` region. Example:
  /// \code
  ///  call void @__kmpc_push_num_teams(%ident_t* %loc, i32 %tid, i32 %ntms,
  ///                                   i32 %nths)
  /// \endcode
  static CallInst *genKmpcPushNumTeams(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, Value *NumTeams,
                                       Value *NumThreads,
                                       Instruction *InsertPt);

  /// Generate a call to notify the runtime system that the team
  /// level static loop scheduling is started.
  /// \code
  ///   call void @__kmpc_team_static_init_4(%ident_t* %loc, i32 %tid,
  ///               i32 schedtype, i32* %islast,i32* %lb, i32* %ub, i32* %st,
  ///               i32 inc, i32 chunk)
  /// \endcode
  static CallInst *genKmpcTeamStaticInit(WRegionNode *W, StructType *IdentTy,
                                         Value *Tid, Value *IsLastVal,
                                         Value *LB, Value *UB, Value *ST,
                                         Value *Inc, Value *Chunk, int Size,
                                         bool IsUnsigned,
                                         Instruction *InsertPt);

  /// Generate a call to notify the runtime system that the static
  /// loop scheduling is started.
  /// \code
  ///   void __kmpc_dist_for_static_init_4/8[u](
  ///            ident_t *loc, kmp_int32 gtid,
  ///            kmp_int32 schedule, kmp_int32 *plastiter,
  ///            kmp_[u]int32/64 *plower, kmp_[u]int32/64 *pupper,
  ///            kmp_[u]int32/64 *pupperD,
  ///            kmp_int32/64 *pstride, kmp_int32/64 incr, kmp_int32/64 chunk)
  /// \endcode
  /// OR
  /// \code
  ///   void __kmpc_for_static_init_4/8[u](
  ///            ident_t *loc, kmp_int32 gtid,
  ///            kmp_int32 schedule, kmp_int32 *plastiter,
  ///            kmp_[u]int32/64 *plower, kmp_[u]int32/64 *pupper,
  ///            kmp_int32/64 *pstride, kmp_int32/64 incr, kmp_int32/64 chunk)
  /// \endcode
  static CallInst *genKmpcStaticInit(
      WRegionNode *W, StructType *IdentTy, Value *Tid,
      Value *IsLastVal, Value *LB, Value *UB, Value *DistUB, Value *ST,
      Value *Inc, Value *Chunk, bool IsUnsigned, Instruction *InsertPt);

  /// Generate a call to notify the runtime system that the static loop
  /// scheduling is done.
  /// \code
  ///   call void @__kmpc_for_static_fini(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcStaticFini(WRegionNode *W, StructType *IdentTy,
                                     Value *Tid, Instruction *InsertPt);

  /// Generate a call to pass all loop info to the runtime system for
  /// guided/runtime/dynamic/auto loop scheduling.
  ///
  /// \code
  ///   call void @__kmpc_for_dispatch_init_4{u}(%ident_t* %loc, i32 %tid,
  ///   i32 schedtype, i32 %lb, i32 %ub, i32 %st, i32 chunk)
  ///
  ///   call void @__kmpc_for_dispatch_init_8{u}4(%ident_t* %loc, i32 %tid,
  ///   i32 schedtype, i64 %lb, i64 %ub, i64 %st, i64 chunk)
  /// \endcode
  static CallInst *genKmpcDispatchInit(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, Value *SchedType,
                                       Value *IsLastVal, Value *LB, Value *UB,
                                       Value *ST, Value *Chunk, int Size,
                                       bool IsUnsigned, Instruction *InsertPt);

  /// Generate a call to the runtime system that performs loop partitioning for
  /// guided/runtime/dynamic/auto scheduling.
  /// \code
  ///   call void @__kmpc_for_dispatch_next_4{u}(%ident_t* %loc, i32 %tid,
  ///               i32 *isLast, i32 *%lb, i32 *%ub, i32 *%st)
  ///
  ///   call void @__kmpc_for_dispatch_next_8{u}(%ident_t* %loc, i32 %tid,
  ///               i32 *isLast, i64 *%lb, i64 *%ub, i64 *%st)
  /// \endcode
  static CallInst *genKmpcDispatchNext(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, Value *IsLastVal, Value *LB,
                                       Value *UB, Value *ST, int Size,
                                       bool IsUnsigned, Instruction *InsertPt);

  /// Generate a call to the runtime system that informs
  /// guided/runtime/dynamic/auto scheduling is done.
  ///
  /// \code
  ///   call void @__kmpc_for_dispatch_fini_4{u}(%ident_t* %loc, i32 %tid)
  ///   call void @__kmpc_for_dispatch_fini_8{u}(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcDispatchFini(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, int Size, bool IsUnsigned,
                                       Instruction *InsertPt);

  /// Update loop scheduling kind based on ordered clause and chunk size
  /// information.
  static WRNScheduleKind genScheduleKind(WRNScheduleKind Kind, bool IsOrdered,
                                         int Chunk);

  /// Query loop scheduling kind based on ordered clause and chunk size
  /// information.
  static WRNScheduleKind getLoopScheduleKind(WRegionNode *W);

  /// Query distribute loop scheduling kind based on schedule and chunk size
  /// information.
  static WRNScheduleKind getDistLoopScheduleKind(WRegionNode *W);

  /// int __kmpc_master_sub_group_leader();
  static CallInst *genMasterSubGroup(WRegionNode *W, Instruction *InsertPt,
                                     bool LeaderFlag);

  /// void __kmpc_get_shared_variables(void ***shareds);
  static CallInst *genGetSharingVariables(WRegionNode *W, Instruction *InsertPt,
                                          Value *Shareds);

  /// void __kmpc_begin_sharing_variables(void ***shareds, size_t num_shareds);
  static CallInst *genBeginSharingVariables(WRegionNode *W,
                                            Instruction *InsertPt,
                                            Value *Shareds, Value *NumShareds);

  /// void __kmpc_init_sharing_variables(void);
  /// void __kmpc_end_sharing_variables(void);
  static CallInst *genInitEndSharingVariables(Instruction *InsertPt, bool End);

  /// void __kmpc_spmd_kernel_init(int thread_limit, short needs_rtl,
  //                                    short needs_data_sharing);
  static CallInst *genSpmdKernelInit(WRegionNode *W, Instruction *InsertPt,
                                     Value *ThreadLimit, Value *NeedsRtl,
                                     Value *NeedsDataSharing);

  // void __kmpc_kernel_init(int thread_limit, short needs_rtl);
  static CallInst *genKernelInit(WRegionNode *W, Instruction *InsertPt,
                                 Value *ThreadLimit, Value *NeedsRtl);

  /// void __kmpc_kernel_fini(short is_rtl_initialized);
  static CallInst *genKernelFini(WRegionNode *W, Instruction *InsertPt,
                                 Value *NeedsRtl);

  /// void __kmpc_spmd_kernel_fini(short needs_rtl);
  static CallInst *genSpmdKernelFini(WRegionNode *W, Instruction *InsertPt,
                                     Value *NeedsRtl);

  /// void __kmpc_kernel_end_parallel(void);
  static CallInst *genKernelEndParallel(Instruction *InsertPt);

  /// EXTERN void __kmpc_kernel_prepare_parallel(void *work_fn,
  ///                                           short is_rtl_initialized);
  /// EXTERN bool __kmpc_kernel_parallel(void **work_fn, short
  /// is_rtl_initialized);
  static CallInst *genKernelParallel(WRegionNode *W, Instruction *InsertPt,
                                     Value *WorkFn, Value *IsRtlInitialized,
                                     bool Prepare);


  /// Generate source location information for \b explicit barrier.
  static GlobalVariable *genKmpcLocforExplicitBarrier(Instruction *InsertPt,
                                                      StructType *IdentTy,
                                                      BasicBlock *BB);

  /// Generate source location information for \b implicit barrier.
  static GlobalVariable *genKmpcLocforImplicitBarrier(WRegionNode *W,
                                                      Instruction *InsertPt,
                                                      StructType *IdentTy,
                                                      BasicBlock *BB);

  /// Insert `kmpc_[cancel]_barrier` call (based on whether parent WRegion has
  /// a cancel construct) before \p InsertPt and return it.
  ///
  /// If the parent WRegion has a cancel construct:
  /// 1. Emit the following call:
  /// \code
  ///   %1 = call int32 @__kmpc_cancel_barrier(%ident_t* %loc, i32 %tid)
  /// \code
  /// 2. Add `%1` to the parent WRegionNode's `CancellationPoints`.
  ///
  /// Otherwise, emit the following call:
  /// \code
  ///   call void @__kmpc_barrier(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcBarrier(WRegionNode *W, Value *Tid,
                                  Instruction *InsertPt, StructType *IdentTy,
                                  bool IsExplicit, bool IsTargetSPIRV = false);

  /// Insert `kmpc_[cancel]_barrier` call (based on \p IsCancelBarrier) before
  /// \p InsertPt and return it. The CallInst inserted is:
  ///
  /// If \p CancelBarrier is \b true:
  /// \code
  ///   %1 = call int32 @__kmpc_cancel_barrier(%ident_t* %loc, i32 %tid)
  /// \endcode
  ///
  /// Otherwise:
  /// \code
  ///   call void @__kmpc_barrier(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcBarrierImpl(WRegionNode *W, Value *Tid,
                                      Instruction *InsertPt,
                                      StructType *IdentTy, bool IsExplicit,
                                      bool IsCancelBarrier,
                                      bool IsTargetSPIRV = false);

  /// Insert `__kmpc_cancel[lationpoint]` call before \p InsertPt and return
  /// it. The inserted CallInst is:
  ///
  /// If \p IsCancellationPoint is \b false:
  /// \code
  ///   %1 = call void @__kmpc_cancel(%ident_t* %loc, i32 %tid, i32
  ///   cancel_kind)
  /// \endcode
  ///
  /// If \p IsCancellationPoint is \b true:
  /// \code
  ///   %1 = call void @__kmpc_cancellation_point(%ident_t* %loc, i32 %tid,
  ///   i32 cancel_kind)
  /// \endcode
  static CallInst *genKmpcCancelOrCancellationPointCall(
      WRegionNode *W, StructType *IdentTy, Constant *TidPtr,
      Instruction *InsertPoint, WRNCancelKind CancelKind,
      bool IsCancellationPoint);

  /// Generate a critical section surrounding all the inner
  /// BasicBlocks of the WRegionNode \p W. The function works only on
  /// directives which have an Entry BasicBlock with "DIR.OMP..." intrinsic
  /// calls, and an exit BasicBlock with a corresponding "DIR.OMP.END..."
  /// calls. The middle BasicBlocks will then be surrounded by a critical
  /// section. The function emits calls to `__kmpc_critical` and
  /// `__kmpc_end_critical` in positions marked in the following diagram:
  ///
  /// \code
  ///    EntryBB:
  ///      %0 = call token @llvm.directive.region.entry(...) [...]
  /// +------< begin critical >
  /// |    br label %BB1
  /// |
  /// |  BB1:
  /// |    ...
  /// |  ...
  /// |    br label %ExitBB
  /// |
  /// |  ExitBB:
  /// |    call void @llvm.directive.region.exit(%0)
  /// +------< end critical >
  ///      br label %..
  ///
  /// \endcode
  ///
  /// \param W WRegionNode for the OpenMP construct.
  /// \param IdentTy is needed to obtain the Loc struct for the KMPC calls.
  /// \param TidPtr is the AllocaInst for ThreadId, needed for the KMPC calls.
  /// \param IsTargetSPIRV is true, iff compilation is for SPIRV target.
  /// \param LockNameSuffix will be used as suffix in the name of the lock
  /// variable used for the critical section. (The prefix is determined based
  /// on the architecture and the kind of WRegionNode \p W).
  ///
  /// Example KMPC calls:
  /// \code
  ///   call void @__kmpc_begin_critical(%ident_t* %loc.addr.11.12, i32 %my.tid,
  ///   [8 x i32]* @_kmpc_atomic_lock)
  ///
  ///   call void @__kmpc_end_critical(%ident_t* %loc.addr.11.122, i32 %my.tid1,
  ///   [8 x i32]* @_kmpc_atomic_lock)
  /// \endcode
  ///
  /// \returns \b true if the calls to `__kmpc_critical` and
  /// `__kmpc_end_critical` are successfully inserted, \b false otherwise.
  static bool genKmpcCriticalSection(WRegionNode *W, StructType *IdentTy,
                                     Constant *TidPtr,
                                     bool IsTargetSPIRV,
                                     const StringRef LockNameSuffix = "");

  /// Generate a critical section around Instructions \p BeginInst and \p
  /// EndInst. The function emits calls to `__kmpc_critical` \b before \p
  /// BeginInst and `__kmpc_end_critical` \b after \p EndInst.
  ///
  /// \code
  /// +------< begin critical >
  /// |    BeginInst
  /// |    ...
  /// |    ...
  /// |    EndInst
  /// +------< end critical >
  /// \endcode
  ///
  /// \param BeginInst is the Instruction \b before which the call to
  /// `__kmpc_critical` is inserted.
  /// \param EndInst is the Instruction \b after which the call to
  /// `__kmpc_end_critical` is inserted.
  /// \param IsTargetSPIRV is true, iff compilation is for SPIRV target.
  ///
  /// Note: Other Instructions, aside from the `__kmpc_critical` and
  /// `__kmpc_end_critical` calls, which are needed for the KMPC calls,
  /// are also inserted into the IR. \see genKmpcCallWithTid() for details.
  ///
  /// \see genKmpcCriticalSection(WRegionNode*, StructType*, AllocaInst*,
  /// const StringRef) for examples of the KMPC critical calls.
  ///
  /// \returns `true` if the calls to `__kmpc_critical` and
  /// `__kmpc_end_critical` are successfully inserted, `false` otherwise.
  static bool genKmpcCriticalSection(WRegionNode *W, StructType *IdentTy,
                                     Constant *TidPtr, Instruction *BeginInst,
                                     Instruction *EndInst,
                                     bool IsTargetSPIRV,
                                     const StringRef LockNameSuffix);

  /// Generate a call to query if the current thread is master thread or a
  /// call to end_master for the team of threadsi. Emitted call:
  /// \code
  ///   call master = @__kmpc_master(%ident_t* %loc, i32 %tid)
  ///      or
  ///   call void @__kmpc_end_master(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcMasterOrEndMasterCall(WRegionNode *W,
                                                StructType *IdentTy, Value *Tid,
                                                Instruction *InsertPt,
                                                bool IsMasterStart,
                                                bool IsTargetSPIRV = false);

  /// Generate a call to guard single-region is executed by one of threads in
  /// the enclosing thread team. Emitted call:
  /// \code
  ///   call single = @__kmpc_single(%ident_t* %loc, i32 %tid)
  ///      or
  ///   call void @__kmpc_end_single(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcSingleOrEndSingleCall(WRegionNode *W,
                                                StructType *IdentTy, Value *Tid,
                                                Instruction *InsertPt,
                                                bool IsSingleStart);

  /// Generate calls to guard the ordered thread execution for the ordered/end
  /// ordered region. Emitted call:
  /// \code
  ///   call void @__kmpc_ordered(%ident_t* %loc, i32 %tid)
  ///      or
  ///   call void @__kmpc_end_ordered(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcOrderedOrEndOrderedCall(WRegionNode *W,
                                                  StructType *IdentTy,
                                                  Value *Tid,
                                                  Instruction *InsertPt,
                                                  bool IsOrderedStart);

  /// \name Utilities for handling do-across loops.
  /// @{

  /// Insert a call to `kmpc_doacross_wait/post` for `#pragma omp ordered
  /// depend(source/sink)` before \p InsertPt and return it.
  ///
  /// Incoming Directive:
  /// \code
  ///   %1 = call token @llvm.directive.region.entry() [ "DIR.OMP.ORDERED"(),
  ///        "QUAL.OMP.DEPEND.SINK"(i32 %v1, i32 %v2) ]
  /// \endcode
  ///
  /// Generated IR:
  /// \code
  ///   %dep.vec = alloca i64, i32 2
  ///   %conv1 = sext i32 %v1 to i64
  ///   %2 = getelementptr inbounds i64, i64* %dep.vec, i64 0
  ///   store i64 %conv1, i64* %2
  ///   %conv2 = sext i32 %v2 to i64
  ///   %3 = getelementptr inbounds i64, i64* %dep.vec, i64 1
  ///   store i64 %conv2, i64* %3
  ///   %4 = bitcast i64* %dep.vec to i8*
  ///   %tid = load i32, i32* %<tidptr>, align 4
  ///   call void @__kmpc_doacross_wait({ i32, i32, i32, i32, i8* }* @loc,
  ///                                   i32 %tid, i8* %4)
  /// \endcode
  ///
  /// \param DepVecValues is an ArrayRef of Values to be passed to the runtime
  /// as the dependence vector. ({%v1, $v2} in the above example).
  /// \param IsDoacrossPost If \b true, emit `kmpc_doacross_post`, otherwise
  /// emit `kmpc_doacross_wait`.
  ///
  /// A load from \p TidPtr is emitted to get `tid` for the call.
  static CallInst *
  genDoacrossWaitOrPostCall(WRNOrderedNode *W, StructType *IdentTy,
                            Value *TidPtr, Instruction *InsertPt,
                            const ArrayRef<Value *> &DepVecValues,
                            bool IsDoacrossPost);

  /// Insert a call to `kmpc_doacross_init` for `#pragma omp for ordered(n)`
  /// before \p InsertPt, and return it.
  ///
  /// Incoming Directive:
  /// \code
  ///   %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.LOOP"(),
  ///        "QUAL.OMP.ORDERED"(i32 2, i32 4, i32 2), ...]
  /// \endcode
  ///
  /// Generated IR:
  /// \code
  ///   %dims.vec = alloca { i64, i64, i64 }, i32 2
  ///
  ///   %3 = getelementptr inbounds { i64, i64, i64 }, %dims.vec, i32 0
  ///
  ///   %4 = getelementptr inbounds { i64, i64, i64 }, %3, i32 0, i32 0
  ///   store i64 0, i64* %4
  ///   %5 = getelementptr inbounds { i64, i64, i64 }, %3, i32 0, i32 1
  ///   store i64 4, i64* %5
  ///   %6 = getelementptr inbounds { i64, i64, i64 }, %3, i32 0, i32 2
  ///   store i64 1, i64* %6
  ///
  ///   %7 = getelementptr inbounds { i64, i64, i64 }, %dims.vec, i32 1
  ///
  ///   %8 = getelementptr inbounds { i64, i64, i64 }, %7, i32 0, i32 0
  ///   store i64 0, i64* %8
  ///   %9 = getelementptr inbounds { i64, i64, i64 }, %7, i32 0, i32 1
  ///   store i64 2, i64* %9
  ///   %10 = getelementptr inbounds { i64, i64, i64 }, %7, i32 0, i32 2
  ///   store i64 1, i64* %10
  ///
  ///   %11 = bitcast { i64, i64, i64 }* %dims.vec to i8*
  ///   %tid = load i32, i32* %<tidptr>, align 4
  ///   call void @__kmpc_doacross_init({ i32, i32, i32, i32, i8* }* @loc,
  ///                                   i32 %tid, i32 2, i8* %11)
  /// \endcode
  ///
  /// Here `%dims.vec` is a vector of structs of type {i64, i64, i64},
  /// containing a loop's lower bound, upper bound and stride respectively. The
  /// vector contains a struct for each loop in the doacross loop-nest.
  ///
  /// The call, along with the initialization of %dims.vec, is inserted before
  /// \p InsertPt.
  ///
  /// \param TripCounts contains trip counts for each loop in the nest.
  static CallInst *genKmpcDoacrossInit(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, Instruction *InsertPt,
                                       const ArrayRef<Value *> &TripCounts);

  /// Insert a call to `kmpc_doacross_fini` for `#pragma omp for ordered(n)`
  /// \b after \p InsertPt and return it.
  ///
  /// \code
  ///   call void @__kmpc_doacross_fini({ i32, i32, i32, i32, i8* }*
  ///   @.kmpc_loc, i32 %my.tid)
  /// \endcode
  ///
  static CallInst *genKmpcDoacrossFini(WRegionNode *W, StructType *IdentTy,
                                       Value *Tid, Instruction *InsertPt);

  /// @}

  /// Insert a `__kmpc_flush` call at \p InsertPt.
  /// \code
  ///   call void @__kmpc_flush(%ident_t* %loc)
  /// \endcode
  static CallInst *genKmpcFlush(WRegionNode *W, StructType *IdentTy,
                                Instruction *InsertPt);

  /// Generate KMPC runtime call to the function \p IntrinsicName
  /// with arguments Loc(obtained using \p IdentTy), Tid (Obtained using \p
  /// TidPtr), and \p Args.
  /// \param W WRegionNode for current OpenMP construct..
  /// \param TidPtr is the AllocaInst for Tid.
  /// \param IdentTy Used to obtain Loc needed by the KMPC call.
  /// \param InsertPt Used to obtain Loc needed by the KMPC call.
  /// \param IntrinsicName is the name of the function.
  /// \param ReturnTy is the return type of the function.
  /// \param Args arguments for the function call.
  /// Note: The function inserts a LoadInst for getting Tid, into the IR
  /// (before the \p InsertPt), and inserts the function prototype for the
  /// KMPC intrinsic \p IntrinsicName into the module symbol table. But it
  /// does not insert the KMPC call into the IR.
  ///
  /// \returns The generated CallInst.
  static CallInst *genKmpcCallWithTid(WRegionNode *W, StructType *IdentTy,
                                      Value *TidPtr, Instruction *InsertPt,
                                      StringRef IntrinsicName, Type *ReturnTy,
                                      ArrayRef<Value *> Args);

  /// \name Utilities to emit calls to ctor, dtor, cctor, and copyassign.
  /// @{
  static CallInst *genConstructorCall(Function *Ctor, Value *V,
                                      Value *PrivAlloca);
  static CallInst *genDestructorCall(Function *Dtor, Value *V,
                                     Instruction *InsertBeforePt);
  static CallInst *genCopyConstructorCall(Function *Cctor, Value *D, Value *S,
                                          Instruction *InsertBeforePt);
  static CallInst *genCopyAssignCall(Function *Cp, Value *D, Value *S,
                                     Instruction *InsertBeforePt);
  /// @}

  /// Generate an optionally addrspacecast'ed pointer Value for an array
  /// of Type \p ElementType, size \p NumElements, name \p VarName.
  /// \p NumElements can be null for one element.
  /// If new instructions need to be generated, they will be inserted
  /// before \p InsertPt.
  /// \p AllocaAddrSpace specifies address space in which the memory
  /// for the privatized variable needs to be allocated. If it is
  /// llvm::None, then the address space matches the default alloca's
  /// address space, as specified by DataLayout. Note that some address
  /// spaces may require allocating the private version of the variable
  /// as a GlobalVariable, not as an AllocaInst.
  /// If \p ValueAddrSpace does not match llvm::None,
  /// then the generated Value will be immediately addrspacecast'ed
  /// and the generated AddrSpaceCastInst or AddrSpaceCast constant
  /// expression will be returned as a result.
  static Value *genPrivatizationAlloca(
      Type *ElementType, Value *NumElements,
      Instruction *InsertPt, const Twine &VarName = "",
      llvm::Optional<unsigned> AllocaAddrSpace = llvm::None,
      llvm::Optional<unsigned> ValueAddrSpace = llvm::None);

#if INTEL_CUSTOMIZATION
  /// \name Utilities specific to Fortran dope vectors.
  /// @{

  /// Emit code to initialize the local copy of \p I, where \p I is an F90 dope
  /// vector. The code looks like: \code
  ///   %size = call i64 @_f90_dope_vector_init(NewV, OrigV)
  ///   %local_data = alloca <element_type>, %size
  ///   store %local_data, getelementpointer(NewV, 0, 0)
  ///   %num_elements = udiv %size, <element_size> ; Only for reduction items
  /// \endcode
  /// The emitted code is inserted after the alloca NewV, which is the local
  /// dope vector corresponding to \p I, and OrigV is the original.
  static void genF90DVInitCode(Item *I);

  /// Emit a call to `_f90_firstprivate_copy(NewV, OrigV)`. The
  /// call is inserted before \p InsertBefore.
  static void genF90DVFirstprivateCopyCall(Value *NewV, Value *OrigV,
                                           Instruction *InsertBefore);
  /// Emit a call to `_f90_lastprivate_copy(NewV, OrigV)`. The
  /// call is inserted before \p InsertBefore.
  static void genF90DVLastprivateCopyCall(Value *NewV, Value *OrigV,
                                          Instruction *InsertBefore);

private:
  static void genF90DVFirstOrLastprivateCopyCallImpl(StringRef FnName,
                                                     Value *NewV, Value *OrigV,
                                                     Instruction *InsertBefore);

public:
  /// Compute the destination address, number of elements and element type for
  /// reduction initialization loop for Fortran dope vectors. The function emits
  /// code to get the data array for the dope vector, which is inserted before
  /// \p InsertBefore.
  /// \code
  ///   %newv.addr0 = getelementpointer (NewV, 0, 0)
  ///   %dest.arr.begin = load <element_ty>* %addr0
  /// \endcode
  /// Where NewV is the local dope vector for I.
  static void genF90DVRedutionInitDstInfo(const Item *I,
                                          Value *&DestArrayBeginOut,
                                          Type *&DestElementTyOut,
                                          Value *&NumElementsOut,
                                          Instruction *InsertBefore);
  /// Compute the destination address, number of elements and element type for
  /// reduction finalization loop for Fortran dope vectors. The function emits
  /// code to get the data array for the dope vector, which is inserted before
  /// \p InsertBefore.
  /// \code
  ///   %newv.addr0 = getelementpointer (NewV, 0, 0)
  ///   %src.arr.begin = load <element_ty>* %newv.addr0
  ///   %origv.addr0 = getelementpointer (OrigV, 0, 0)
  ///   %src.arr.begin = load <element_ty>* %origv.addr0
  /// \endcode
  /// Where NewV is the local dope vector for I, and OrigV is the original.
  static void genF90DVRedutionFiniSrcDstInfo(const Item *I,
                                             Value *&SrcArrayBeginOut,
                                             Value *&DestArrayBeginOut,
                                             Type *&DestElementTyOut,
                                             Value *&NumElementsOut,
                                             Instruction *InsertBefore);
  /// @}

#endif // INTEL_CUSTOMIZATION
  /// Copy data from the source address \p To to the destination address
  /// \p From
  /// These must both be pointer types.
  /// A copy constructor or copy-assign function \p Cctor will be used if
  /// given.
  /// \p IsByRef will insert an extra load to dereference the \p From pointer.
  static void genCopyByAddr(Value *To, Value *From, Instruction *InsertPt,
                            Function *Cctor = nullptr, bool IsByRef = false);

  /// Compute the OpenMP loop upper bound so that the loop iteration space can
  /// be closed interval.
  static CmpInst::Predicate computeOmpPredicate(CmpInst::Predicate PD);

  /// Return the predicate which includes equal for the zero trip test
  /// of the loop identified by \p Idx.
  static Value *computeOmpUpperBound(WRegionNode *W, unsigned Idx,
                                     Instruction *InsertPt,
                                     const Twine &Name = "");

  /// Update the bottom test predicate to include equal predicate
  /// for the loop identified by \p Idx.
  /// It also updates the loop upper bound.
  static void updateOmpPredicateAndUpperBound(WRegionNode *W,
                                              unsigned Idx,
                                              Value *Load,
                                              Instruction *InsertPt);

  /// Creates a clone of \p CI, and adds \p OpBundlesToAdd the new
  /// CallInst. \returns the created CallInst, if it created one, \p CI
  /// otherwise (when \p OpBundlesToAdd is empty).
  static CallInst *addOperandBundlesInCall(
      CallInst *CI,
      ArrayRef<std::pair<StringRef, ArrayRef<Value *>>> OpBundlesToAdd);

  /// Creates a clone of \p CI without any operand bundles whose tags match an
  /// entry in \p OpBundlesToRemove. Replaces all uses of the original \p CI
  /// with the new Instruction created.
  /// \returns the created CallInst, if it created one, \p CI otherwise (when \p
  /// OpBundlesToRemove is empty, or has no matching bundle on \p CI).
  static CallInst *
  removeOperandBundlesFromCall(CallInst *CI,
                               ArrayRef<StringRef> OpBundlesToRemove);

  /// Returns true, if the given \p V value may be rematerialized
  /// before the given \p W region (i.e. right before the \p W region's
  /// entry block).
  static bool mayCloneUBValueBeforeRegion(Value *V, const WRegionNode *W);

  /// Clone the instructions and insert them before \p InsertPt.
  static Value *cloneInstructions(Value *V, Instruction *InsertPt);

  /// Generate the pointer pointing to the head of the array.
  static Value *genArrayLength(Value *AI, Value *BaseAddr,
                               Instruction *InsertPt, IRBuilder<> &Builder,
                               Type *&ElementTy, Value *&ArrayBegin);

  static Value *genAddrSpaceCast(Value *Ptr, Instruction *InsertPt,
                                 unsigned AddrSpace);

  /// Generate a call to `__kmpc_omp_task_alloc`. Example:
  /// \code
  ///   i8* @__kmpc_omp_task_alloc({ i32, i32, i32, i32, i8* }*, i32, i32,
  ///   i64, i64, i32 (i32, i8*)*)
  /// \endcode
  static CallInst *
  genKmpcTaskAlloc(WRegionNode *W, StructType *IdentTy, Value *TidPtr,
                   Value *KmpTaskTTWithPrivatesTySz, int KmpSharedTySz,
                   PointerType *KmpRoutineEntryPtrTy, Function *MicroTaskFn,
                   Instruction *InsertPt, bool UseTbb);

  /// Generate a call to `__kmpc_taskloop`. Example:
  /// \code
  ///   void @__kmpc_taskloop(
  ///          { i32, i32, i32, i32, i8* }* %loc,
  ///          i32 %tid,
  ///          i8* %thunk_temp,
  ///          i32 if_val,
  ///          i64* lb,
  ///          i64* ub,
  ///          i64 stride,
  ///          i32 nogroup,
  ///          i32 sched, // 0: no grainsize or num_tasks
  ///                     // 1: grainsize is used
  ///                     // 2: num_tasks is used
  ///          i64 grainsize,
  ///          i8* task_dup)
  /// \endcode
  static CallInst *genKmpcTaskLoop(WRegionNode *W, StructType *IdentTy,
                                   Value *TidPtr, Value *TaskAlloc, Value *Cmp,
                                   Value *LBPtr, Value *UBPtr, Value *STPtr,
                                   StructType *KmpTaskTTWithPrivatesTy,
                                   Instruction *InsertPt, bool UseTbb,
                                   Function *FnTaskDup);

  /// Generate a call to `__kmpc_task`. Example:
  /// \code
  ///   void @__kmpc_task(
  ///            { i32, i32, i32, i32, i8* }* %loc,
  ///            i32 %tid,
  ///            i8* thunk_temp)
  /// \endcode
  static CallInst *genKmpcTask(WRegionNode *W, StructType *IdentTy,
                               Value *TidPtr, Value *TaskAlloc,
                               Instruction *InsertPt);

  /// Generate a call to `__kmpc_omp_task_begin_if0`. Example:
  /// \code
  ///   void @__kmpc_omp_task_begin_if0(
  ///         { i32, i32, i32, i32, i8* }* /* &loc */,
  ///         i32 /* tid */,
  ///         i8* /*thunk_temp */)
  /// \endcode
  static CallInst *genKmpcTaskBeginIf0(WRegionNode *W, StructType *IdentTy,
                                       Value *TidPtr, Value *TaskAlloc,
                                       Instruction *InsertPt);

  /// Generate a call to `__kmpc_omp_task_complete_if0`. Example:
  /// \code
  ///   void @__kmpc_omp_task_complete_if0(
  ///         { i32, i32, i32, i32, i8* }* /* &loc */,
  ///         i32 /* tid */,
  ///         i8* /*thunk_temp */)
  /// \endcode
  static CallInst *genKmpcTaskCompleteIf0(WRegionNode *W, StructType *IdentTy,
                                          Value *TidPtr, Value *TaskAlloc,
                                          Instruction *InsertPt);

  /// Generate a call to `__kmpc_omp_task_with_deps`. Example:
  /// \code
  ///   void @__kmpc_omp_task_with_deps(
  ///          { i32, i32, i32, i32, i8* }* /* &loc */,
  ///          i32 /* tid */,
  ///          i8* /*thunk_temp */,
  ///          i32 /* depend_count */,
  ///          i8* /* &depend_record */
  ///          i32 /* 0 */,
  ///          i8* /* 0 */)
  /// \endcode
  static CallInst *genKmpcTaskWithDeps(WRegionNode *W, StructType *IdentTy,
                                       Value *TidPtr, Value *TaskAlloc,
                                       Value *Dep, int DepNum,
                                       Instruction *InsertPt);

  /// Generate a call to `__kmpc_omp_wait_deps`. Example:
  /// \code
  ///   void @__kmpc_omp_wait_deps(
  ///          { i32, i32, i32, i32, i8* }* /* &loc */,
  ///          i32 /* tid */,
  ///          i32 /* depend_count */,
  ///          i8* /* &depend_record */
  ///          i32 /* 0 */,
  ///          i8* /* 0 */)
  /// \endcode
  static CallInst *genKmpcTaskWaitDeps(WRegionNode *W, StructType *IdentTy,
                                       Value *TidPtr, Value *Dep, int DepNum,
                                       Instruction *InsertPt);

  /// Generic routine to generate `__kmpc_omp_task_with_deps` or
  /// `__kmpc_omp_wait_deps` calls.
  static CallInst *genKmpcTaskDepsGeneric(WRegionNode *W, StructType *IdentTy,
                                          Value *TidPtr, Value *TaskAlloc,
                                          Value *Dep, int DepNum,
                                          Instruction *InsertPt,
                                          StringRef FnName);

  /// Generic function to support generation of `__kmpc_task`,
  /// `__kmpc_omp_task_begin_if0` and `__kmpc_omp_task_complete_if0` calls.
  static CallInst *genKmpcTaskGeneric(WRegionNode *W, StructType *IdentTy,
                                      Value *TidPtr, Value *TaskAlloc,
                                      Instruction *InsertPt, StringRef FnName);

  /// Generate a call to `__kmpc_omp_taskwait`. Example:
  /// \code
  ///   void @__kmpc_omp_taskwait({ i32, i32, i32, i32, i8* }*, i32)
  /// \endcode
  static CallInst *genKmpcTaskWait(WRegionNode *W, StructType *IdentTy,
                                   Value *TidPtr, Instruction *InsertPt);

  /// Generate a call to `__tgt_target_data_begin`. Example:
  /// \code
  ///   int32_t __tgt_target_data_begin(int64_t  device_id,
  ///                                   int32_t  num_args,
  ///                                   void**   args_base,
  ///                                   void**   args,
  ///                                   int64_t* args_size,
  ///                                   int64_t* args_maptype)
  /// \endcode
  static CallInst *genTgtTargetDataBegin(WRegionNode *W, int NumArgs,
                                         Value *ArgsBase, Value *Args,
                                         Value *ArgsSize, Value *ArgsMaptype,
                                         Instruction *InsertPt);

  /// Generate a call to `__tgt_target_data_end`. Example:
  /// \code
  ///   int32_t __tgt_target_data_end(int64_t  device_id,
  ///                                 int32_t  num_args,
  ///                                 void**   args_base,
  ///                                 void**   args,
  ///                                 int64_t* args_size,
  ///                                 int64_t* args_maptype)
  /// \endcode
  static CallInst *genTgtTargetDataEnd(WRegionNode *W, int NumArgs,
                                       Value *ArgsBase, Value *Args,
                                       Value *ArgsSize, Value *ArgsMaptype,
                                       Instruction *InsertPt);

  /// Generate a call to `__tgt_target_data_update`. Example:
  /// \code
  ///   int32_t __tgt_target_data_update(int64_t  device_id,
  ///                                    int32_t  num_args,
  ///                                    void**   args_base,
  ///                                    void**   args,
  ///                                    int64_t* args_size,
  ///                                    int64_t* args_maptype)
  /// \endcode
  static CallInst *genTgtTargetDataUpdate(WRegionNode *W, int NumArgs,
                                          Value *ArgsBase, Value *Args,
                                          Value *ArgsSize, Value *ArgsMaptype,
                                          Instruction *InsertPt);

  /// Generate a call to `__tgt_target`. Example:
  /// \code
  ///   int32_t __tgt_target(int64_t  device_id,
  ///                        void*    host_addr,
  ///                        int32_t  num_args,
  ///                        void**   args_base,
  ///                        void**   args,
  ///                        int64_t* args_size,
  ///                        int64_t* args_maptype)
  /// \endcode
  static CallInst *genTgtTarget(WRegionNode *W, Value *HostAddr, int NumArgs,
                                Value *ArgsBase, Value *Args, Value *ArgsSize,
                                Value *ArgsMaptype, Instruction *InsertPt);

  /// Generate a call to `__tgt_target_teams`. Example:
  /// \code
  ///   int32_t __tgt_target_teams(int64_t  device_id,
  ///                              void*    host_addr,
  ///                              int32_t  num_args,
  ///                              void**   args_base,
  ///                              void**   args,
  ///                              int64_t* args_size,
  ///                              int64_t* args_maptype,
  ///                              int32_t  num_teams,
  ///                              int32_t  thread_limit)
  /// \endcode
  static CallInst *genTgtTargetTeams(WRegionNode *W, Value *HostAddr,
                                     int NumArgs, Value *ArgsBase, Value *Args,
                                     Value *ArgsSize, Value *ArgsMaptype,
                                     Instruction *InsertPt);

  /// Base routine to create `libomptarget` calls. Creates one of these calls:
  /// \code
  ///   void    __tgt_target_data_begin( int64_t device_id, <common>)
  ///   void    __tgt_target_data_end(   int64_t device_id, <common>)
  ///   void    __tgt_target_data_update(int64_t device_id, <common>)
  ///   int32_t __tgt_target(int64_t device_id, void *host_addr, <common>)
  ///   int32_t __tgt_target_teams(int64_t device_id, void *host_addr,
  ///                              <common>, int32_t num_teams,
  ///                              int32_t thread_limit)
  /// \endcode
  /// where `<common>` represents these 5 arguments:
  /// \code
  ///   int32_t  num_args,    // number of pointers being mapped
  ///   void**   args_base,   // array of base pointers being mapped
  ///   void**   args,        // array of section pointers (base+offset)
  ///   int64_t* args_size,   // array of sizes (bytes) of each mapped datum
  ///   int32_t* args_maptype // array of map attributes for each mapping
  /// \endcode
  static CallInst *genTgtCall(StringRef FnName, Value *DeviceIDPtr,
                              int NumArgsCount, Value *ArgsBase, Value *Args,
                              Value *ArgsSize, Value *ArgsMaptype,
                              Instruction *InsertPt, Value *HostAddr = nullptr,
                              Value *NumTeamsPtr = nullptr,
                              Value *ThreadLimitPtr = nullptr);

  /// Generate a call to `tgt_unregister_lib`. Example:
  /// \code
  ///   i32 __tgt_unregister_lib(__tgt_bin_desc *desc)
  /// \endcode
  static CallInst *genTgtUnregisterLib(Value *Desc, Instruction *InsertPt);

  /// Generate a call to `tgt_register_lib`. Example:
  /// \code
  ///   i32 __tgt_register_lib(__tgt_bin_desc *desc)`
  /// \endcode
  static CallInst *genTgtRegisterLib(Value *Desc, Instruction *InsertPt);

  /// Generic function to support the generation of `__tgt_register_lib` and
  /// `__tgt_unregister_lib` calls.
  static CallInst *genTgtRegGeneric(Value *Desc, Instruction *InsertPt,
                                    StringRef FnName);

  /// Generate a call to `_cxa_atexit`. Example:
  /// \code
  /// i32 __cxa_atexit(void (i8*)* @.omp_offloading.descriptor_unreg, i8*
  /// bitcast (%struct.__tgt_bin_desc* @.omp_offloading.descriptor to i8*),
  /// i8* @__dso_handle)
  /// \endcode
  static CallInst *genCxaAtExit(Value *TgtDescUnregFn, Value *Desc,
                                Value *Handle, Instruction *InsertPt);

  /// Generate a call to
  /// \code
  ///    bool __tgt_is_device_available(int device_num, void *device_type)
  /// \endcode
  static CallInst *genTgtIsDeviceAvailable(Value *DeviceNum, Value *DeviceType,
                                           Instruction *InsertPt);

  /// Generate a call to
  /// \code
  ///    void *__tgt_create_buffer(int device_num, void *host_ptr)
  /// \endcode
  static CallInst *genTgtCreateBuffer(Value *DeviceNum, Value *HostPtr,
                                      Instruction *InsertPt);

  /// Generate a call to
  /// \code
  ///    int __tgt_release_buffer(int device_num, void *tgt_buffer)
  /// \endcode
  static CallInst *genTgtReleaseBuffer(Value *DeviceNum, Value *TgtBuffer,
                                       Instruction *InsertPt);

  /// Generate a call to
  /// \code
  ///   int omp_get_num_devices()
  /// \endcode
  static CallInst *genOmpGetNumDevices(Instruction *InsertPt);

  /// Generate a call to `__kmpc_task_reduction_get_th_data`. Prototype:
  /// \code
  ///    i8* @__kmpc_task_reduction_get_th_data(i32, i8*, i8*)
  /// \endcode
  static CallInst *genKmpcRedGetNthData(WRegionNode *W, Value *TidPtr,
                                        Value *SharedGep, Instruction *InsertPt,
                                        bool UseTbb);

  /// Generate a call to `__kmpc_task_reduction_init`. Prototype:
  /// \code
  ///   i8* @__kmpc_task_reduction_init(i32, i32, i8*)
  /// \endcode
  static CallInst *genKmpcTaskReductionInit(WRegionNode *W, Value *TidPtr,
                                            int ParmNum, Value *RedRecord,
                                            Instruction *InsertPt, bool UseTbb);

  /// Returns min/max int of the given integer type.
  /// This can be used to initialize min/max reduction variables.
  static Constant *getMinMaxIntVal(LLVMContext &C, Type *Ty, bool IsUnsigned,
                                   bool GetMax);
  // static uint64_t getMinInt(Type *IntTy, bool IsUnsigned);
  // static uint64_t getMaxInt(Type *IntTy, bool IsUnsigned);

  /// Generate a call to `__kmpc_copyprivate`. Example:
  /// \code
  ///   void __kmpc_copyprivate(
  ///     ident_t *loc, kmp_int32 global_tid, kmp_int32 cpy_size, void
  ///     *cpy_data, void(*cpy func)(void *, void *), kmp_int32 didit );
  ///
  ///   /*
  ///   loc: source location information
  ///   global_tid: global thread number
  ///   cpy_size: size of the cpy_data buffer
  ///   cpy_data: pointer to data to be copied
  ///   cpy_func: helper function to call for copying data
  ///   didit: flag variable: 1=single thread; 0=not single thread
  ///   */
  /// \endcode
  static CallInst *genKmpcCopyPrivate(WRegionNode *W, StructType *IdentTy,
                                      Value *TidPtr, unsigned Size,
                                      Value *CpyData, Function *FnCopyPriv,
                                      Value *IsSingleThread,
                                      Instruction *InsertPt);

  /// Generate a call to `__kmpc_taskgroup`. Example:
  /// \code
  ///   void @__kmpc_taskgroup(%ident_t* %loc.addr.11.12, i32 %my.tid)
  /// \endcode
  static CallInst *genKmpcTaskgroupCall(WRegionNode *W, StructType *IdentTy,
                                        Value *Tid, Instruction *InsertPt);

  /// Generate a call to `__kmpc_end_taskgroup`. Example:
  /// \code
  ///   void @__kmpc_end_taskgroup(%ident_t* %loc.addr.11.12, i32 %my.tid)
  /// \endcode
  static CallInst *genKmpcEndTaskgroupCall(WRegionNode *W, StructType *IdentTy,
                                           Value *Tid, Instruction *InsertPt);

  /// Generate a generic call to `get_global_id, get_local_id...`. Example:
  /// \code
  //    %11 = call i64 @_Z14get_local_sizej(i32 0)
  ///      where the value 0 is the dimension number.
  //  \endcode
  static CallInst *genOCLGenericCall(StringRef FnName, Type *RetType,
                                     ArrayRef<Value *> FnArgs,
                                     Instruction *InsertPt);

  /// \name Helper methods for generating calls.
  /// @{

  /// Generate KMPC runtime call to the function \p IntrinsicName
  /// with arguments Loc(obtained using \p IdentTy) and \p Args.
  /// \param IdentTy and \p InsertPt are used to obtain Loc needed by the
  /// KMPC call.
  /// \param IntrinsicName is the name of the function.
  /// \param ReturnTy is the return type of the function.
  /// \param Args arguments for the function call.
  /// \param Insert indicates whether to insert the call at InsertPt
  ///
  /// \returns the generated CallInst.
  static CallInst *genKmpcCall(WRegionNode *W, StructType *IdentTy,
                               Instruction *InsertPt, StringRef IntrinsicName,
                               Type *ReturnTy, ArrayRef<Value *> Args,
                               bool Insert = false);

  /// Generate a CallInst for the given Function* \p Fn and its argument list.
  /// \p Fn must be already declared.
  static CallInst *genCall(Function *Fn, ArrayRef<Value *> FnArgs,
                           ArrayRef<Type *> FnArgTypes, Instruction *InsertPt,
                           bool IsTail = false, bool IsVarArg = false);

  /// Generate a call to the function \p FnName.
  /// If the function is not already declared in the module \p M, then it is
  /// declared here. Otherwise, the existing declaration is used.
  /// \param M Module for which the call is generated.
  /// \param FnName Name of the function.
  /// \param ReturnTy Return type of the function.
  /// \param FnArgs Arguments for the function call.
  /// \param FnArgTypes Types of the arguments for the function call.
  /// \param InsertPt Insertion point for the call. Default is nullptr.
  /// \param IsTail This call attribute is defaulted to false.
  /// \param IsVarArg  This call attribute is defaulted to false.
  ///
  /// \returns the generated CallInst.
  static CallInst *genCall(Module *M, StringRef FnName, Type *ReturnTy,
                           ArrayRef<Value *> FnArgs,
                           ArrayRef<Type *> FnArgTypes,
                           Instruction *InsertPt = nullptr, bool IsTail = false,
                           bool IsVarArg = false);

  // A genCall() interface where FnArgTypes is omitted; it will be computed
  // from FnArgs. **WARNING**: do not use this interface for VarArg functions,
  // as the list of FnArgTypes corresponding to the FnArgs may be longer than
  // the actual list of params in the FunctionType.
  static CallInst *genCall(Module *M, StringRef FnName, Type *ReturnTy,
                           ArrayRef<Value *> FnArgs,
                           Instruction *InsertPt = nullptr, bool IsTail = false,
                           bool IsVarArg = false);

  // A genCall() interface where the Module is omitted; it will be computed
  // from the insertion point, which is must be specified (no default).
  static CallInst *genCall(StringRef FnName, Type *ReturnTy,
                           ArrayRef<Value *> FnArgs,
                           ArrayRef<Type *> FnArgTypes, Instruction *InsertPt,
                           bool IsTail = false, bool IsVarArg = false);

  /// Given a call \p BaseCall, create another call with name \p VariantName
  /// using the same arguments from \p BaseCall. Both functions are expected
  /// to have identical signatures.
  /// \p W is a TargetVariant WRN. If present, replace each call argument that
  /// is a host pointer (listed in the use_device_ptr clause) with its
  /// corresponding target buffer.
  static CallInst *genVariantCall(CallInst *BaseCall, StringRef VariantName,
                                  Instruction *InsertPt,
                                  WRegionNode *W = nullptr,
                                  bool IsTail = false);

  // Creates a call with no parameters.
  // If \p InsertPt is not null, insert the call before InsertPt
  static CallInst *genEmptyCall(Module *M, StringRef FnName, Type *ReturnTy,
                                Instruction *InsertPt = nullptr,
                                bool IsVarArg = false);

  // Creates new Function and outlines \p W region into it.
  // \p DT DominatorTree is updated accordingly.
  static Function *genOutlineFunction(const WRegionNode &W, DominatorTree *DT,
                                      AssumptionCache *AC);

  // If there is a SPIRV builtin performing horizontal reduction for the given
  // reduction operation, this method will insert code with a call
  // of this builtin with \p RedDef as the reduction value.
  // \p Scope defines the SPIRV reduction scope (e.g. Group, Subgroup, etc.)
  // In some case sign/zero integer extension and truncation may be inserted
  // before and after the call.
  static Value *genSPIRVHorizontalReduction(
      ReductionItem *RedI, Type *ScalarTy, Instruction *RedDef,
      spirv::Scope Scope);

  /// Returns true, if work partitioning for the loop-kind \p W region
  /// should rely on ND-range driven parallelization. This implies
  /// that for the given \p W region there is an enclosing "omp target"
  /// region, for which ND-range infomation has already been constructed
  /// (see VPOParoptTransform::constructNDRangeInfo() for details).
  static bool useSPMDMode(WRegionNode *W);

  /// Returns execution scheme for loop-kind regions on SPIR targets.
  static spirv::ExecutionSchemeTy getSPIRExecutionScheme();

  /// Returns true, if the given instruction \p I represents a call
  /// to library function __kmpc_critical.
  static bool isOMPCritical(const Instruction *I, const TargetLibraryInfo &TLI);

  /// Find the first directive that supports the private clause, that dominates
  /// \p PosInst. Add a private clause for \p I into that directive.
  /// Return false if no directive was found. Intended to be called outside
  /// VPO, where no region information is available. It is an error if "I"
  /// is already used in a llvm.directive.region.entry (checked by assertion).
  static bool addPrivateToEnclosingRegion(Instruction *I, Instruction *PosInst,
                                          DominatorTree &DT);
  /// @}

private:
  /// \name Private constructor and destructor to disable instantiation.
  /// @{

  VPOParoptUtils() = delete;
  ~VPOParoptUtils() = delete;

  /// @}

  /// \name Helper methods for generating a Critical Section.
  /// @{

  /// Creates a prefix for the name of the lock var to be used in KMPC
  /// critical calls based on the kind of WRegionNode \p W.
  ///
  /// \returns A string prefix for the KMPC Lock object for \p W.
  static SmallString<64> getKmpcCriticalLockNamePrefix(WRegionNode *W);

  /// Returns a GlobalVariable that can be used as the Lock object for
  /// `__kmpc_critical` and __kmpc_end_critical` calls.
  /// \p W is used to determine the name of the Lock object generated.
  /// \p LockNameSuffix will be used as suffix in the name of the lock
  /// variable used for the critical section. (The prefix is determined based
  /// on the architecture and the kind of WRegionNode \W).
  /// \p IsTargetSPIRV is true, iff compilation is for SPIRV target.
  ///
  /// \returns The lock variable for the critical section to be generated.
  static GlobalVariable *
  genKmpcCriticalLockVar(WRegionNode *W, const StringRef LockNameSuffix,
                         bool IsTargetSPIRV);

  /// Handles generation of a critical section around \p BeginInst and \p
  /// EndInst. The function needs a lock variable \p LockVar, which is
  /// generated by genKmpcCriticalLockVar().
  /// \p IsTargetSPIRV is true, iff compilation is for SPIRV target.
  ///
  /// \see genKmpcCriticalSection() functions for more details. They are the
  /// public functions which invokes this private helper.
  ///
  /// \returns `true` if the calls to `__kmpc_critical` and
  /// `__kmpc_end_critical` are successfully inserted, `false` otherwise.
  static bool genKmpcCriticalSectionImpl(WRegionNode *W, StructType *IdentTy,
                                         Constant *TidPtr,
                                         Instruction *BeginInst,
                                         Instruction *EndInst,
                                         GlobalVariable *LockVar,
                                         bool IsTargetSPIRV);

  /// Generate a call to `__kmpc_[end_]taskgroup`.
  /// \code
  ///   call void @__kmpc_taskgroup(%ident_t* %loc, i32 %tid)
  ///      or
  ///   call void @__kmpc_end_taskgroup(%ident_t* %loc, i32 %tid)
  /// \endcode
  static CallInst *genKmpcTaskgroupOrEndTaskgroupCall(WRegionNode *W,
                                                      StructType *IdentTy,
                                                      Value *Tid,
                                                      Instruction *InsertPt,
                                                      bool IsTaskGroupStart);

  /// @}
};

} // namespace vpo
} // namespace llvm

#endif // LLVM_TRANSFORMS_VPO_PAROPT_UTILS_H
#endif // INTEL_COLLAB
