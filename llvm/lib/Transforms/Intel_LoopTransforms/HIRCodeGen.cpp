//===--------- HIRCodeGen.cpp - Implements HIRCodeGen class ---------------===//
//
// Copyright (C) 2015-2016 Intel Corporation. All rights reserved.
//
// The information and source code contained herein is the exclusive
// property of Intel Corporation and may not be disclosed, examined
// or reproduced in whole or in part without explicit written authorization
// from the company.
//
//===----------------------------------------------------------------------===//
//
// This file implements HIRCodeGen class, used to convert HIR to LLVM IR
// New LLVM IR is generated by visiting each HIR node, and attached regular and
// blob ddrefs. Once the new IR is generated, the CFG is manipulated to ensure
// the old LLVM IR for a region is unreachable, with new IR reached instead.
//
// The emitted LLVM IR is mostly unoptimized. For example, IV's are represented
// as load/stores to memory. While this greatly simplifies the implementation
// of this pass, it does require some passes to be run afterwards, such as
// mem2reg, GVN, and simplifycfg
//
//===----------------------------------------------------------------------===//

#include "llvm/IR/Function.h"
#include "llvm/Pass.h"
#include "llvm/Support/raw_ostream.h"
#include "llvm/Transforms/Intel_LoopTransforms/Passes.h"
#include "llvm/Transforms/Intel_LoopTransforms/Utils/BlobUtils.h"
#include "llvm/Transforms/Intel_LoopTransforms/Utils/DDRefUtils.h"
#include "llvm/Transforms/Intel_LoopTransforms/Utils/HLNodeUtils.h"
#include "llvm/Transforms/Intel_VPO/Utils/VPOUtils.h"

#include "llvm/Analysis/Intel_LoopAnalysis/HIRFramework.h"
#include "llvm/Analysis/ScalarEvolution.h"
#include "llvm/Analysis/ScalarEvolutionExpander.h"
#include "llvm/Analysis/ScalarEvolutionExpressions.h"

#include "llvm/Support/Debug.h"

#include "llvm/ADT/DenseMap.h"
#include "llvm/IR/DebugInfoMetadata.h"
#include "llvm/IR/LLVMContext.h"
#include "llvm/IR/Module.h"
#include "llvm/IR/Verifier.h"
#include "llvm/Transforms/Utils/BasicBlockUtils.h"
#include "llvm/Transforms/Utils/Local.h"

#include "llvm/IR/Intel_LoopIR/HIRVisitor.h"
// TODO audit includes
#define DEBUG_TYPE "hir-cg"

using namespace llvm;
using namespace llvm::loopopt;
using namespace llvm::vpo;

static cl::opt<bool> forceHIRCG("force-hir-cg", cl::init(false), cl::Hidden,
                                cl::desc("forces CodeGen on all HIR regions"));

static cl::opt<unsigned> HIRDebugRegion(
    "hir-cg-x-region-only", cl::Optional,
    cl::desc("HIRCG the x'th region only, regardless of modification status"),
    cl::Hidden, cl::value_desc("number"), cl::init(0));

namespace {

class HIRCodeGen : public FunctionPass {
private:
  ScalarEvolution *SE;
  Function *F;
  HIRFramework *HIRF;

  // This does the real work of llvm ir cg
  // Uses IRBuilder to generate LLVM IR for each HIR construct
  // visited
  // Note that the visitor used is not the standard HLVisitor
  // HIR code gen visits HIR in an unusual order, so a different
  // visitor class which does not define a traversal order is used.
  // TODO probably could use a return of void
  class CGVisitor : public HIRVisitor<CGVisitor, Value *> {
  public:
    // following are extra functions not part of visitor
    // ddref and ce cg generates many intermediate inst and values
    // but each one logically represents a single resulting value
    // which is returned
    Value *visitCanonExpr(CanonExpr *CE);

    // While a ddref represents a single value, the ddref for A[i] has a
    // different meaning whether lval or rval. For Lvals, we are storing into
    // &A[i], and so we need to return a value representing that address to use
    // in a store instruction. For rvals, we want a value for what is stored at
    // that address to use as operand of an instruction. This function will
    // return an address or a load of that address depending on rval/lval of
    // ref. If MaskVal is not null, we generate a masked load/gather instead
    // of the load.
    Value *visitRegDDRef(RegDDRef *Ref, Value *MaskVal = nullptr);
    Value *visitScalar(RegDDRef *Ref);

    Value *visitRegion(HLRegion *R);
    Value *visitLoop(HLLoop *L);
    // IVAdd and IVAlloca are passed to generate store for the iv update inside
    // the bottom test of unknown loops.
    Value *visitIf(HLIf *I, Value *IVAdd = nullptr,
                   AllocaInst *IVAlloca = nullptr);

    Value *visitSwitch(HLSwitch *S);

    Value *visitInst(HLInst *I);

    Value *visitGoto(HLGoto *G);
    Value *visitLabel(HLLabel *L);
    BasicBlock *getBBlockForLabel(HLLabel *L);

    // Regions have a list of live in values and their corresponding symbase
    // Any use of the value in HIR region is represented by a temp with some
    // symbase
    // CG turns those temps into load/stores of memory corresponding ot symbase.
    // However we must store the initial value into symbase's memory slot or the
    // first use of live in value will remain as load of uninitialized memory
    void initializeLiveIn(HLRegion *R);

    // Regions have a list of liveout values and their symbase. We must ensure
    // that all uses of liveout value are replaced by a load of symbase's
    // memory slot. We must be careful of cases where one region's live out
    // is another's livein
    // TODO: support liveout for multiexit region
    void processLiveOut(HLRegion *R);

    // any client shouldhave used visit(node), this function is used as a
    // fallback when visitXXX couldnt be found for an hlnode of type XXX
    Value *visitHLNode(HLNode *Node) {
      llvm_unreachable("Unknown HIR type in CG");
    }

    CGVisitor(Function *CurFunc, ScalarEvolution *SE, HIRCodeGen *CG)
        : F(CurFunc), HIRCG(CG) {
      Builder = new IRBuilder<>(F->getContext());
      // TODO possibly IV conflict if scev blobs contain IV
      const DataLayout &DL =
          CurFunc->getEntryBlock().getModule()->getDataLayout();
      Expander = new HIRSCEVExpander(*SE, DL, "i", *this);
    }
    ~CGVisitor() {
      delete Builder;
      delete Expander;
    }

  private:
    // Adds an unconditional branch from the current insertion point to \p ToBB
    // if the last inserted instruction is not an unconditional branch.
    void generateBranchIfRequired(BasicBlock *ToBB);

    // Set the metadata for the instruction using the passed in MDNodes.
    static void setMetadata(Value *Val, const RegDDRef *Ref);
    static void setMetadata(Instruction *Inst, const RegDDRef *Ref);
    static void setMetadata(Instruction *Inst, const RegDDRef::MDNodesTy &MDs);

    // Generate llvm.dbg.declare for the dbg intrinstic \p DbgInfoIntrin.
    void generateDeclareValue(AllocaInst *Alloca,
                              const DbgInfoIntrinsic *DbgInfoIntrin);

    // Generate llvm.dbg.declare with the specific \p LocalVariable, \p
    // Expression and \p Location.
    void generateDeclareValue(AllocaInst *Alloca,
                              DILocalVariable *LocalVariable,
                              DIExpression *Expression, DILocation *Location);

    // Generates eventual store for an lval HLInst once all the operands have
    // been CG'd.
    void generateLvalStore(const HLInst *HInst, Value *StorePtr,
                           Value *StoreVal);

    // Returns a value representing the summation of all coef*blob pairs.
    Value *sumBlobs(CanonExpr *CE);

    // For a canon expr of form c_1 * i_1[ + c_2 *i_2 + ...] + c_0 + blob
    // return a value representing ONLY the summation of c_n * i_n pairs where
    // c_i is a constant and i_n is an induction variable
    Value *sumIV(CanonExpr *CE);

    /// Generates a bool value* representing truth value of HLIf's
    /// predicate(s)
    Value *generateAllPredicates(HLIf *HIf);

    /// Generates a bool value for predicate in HLIf
    Value *generatePredicate(HLIf *HIf, HLIf::const_pred_iterator P);

    // Creates and returns icmp or fcmp instuction(depending on lhs type)
    // at current IP
    Value *createCmpInst(const HLPredicate &P, Value *LHS, Value *RHS,
                         const Twine &Name);

    // Return a value for blob corresponding to BlobIdx
    // We normally expect Blob type to match CE type. The only exception is
    // ptr blobs. Ptrs are converted to int of argument type, which should be
    // CE src type
    Value *getBlobValue(int BlobIdx, Type *Ty);

    // TODO blobs are reprsented by scev with some caveats
    SCEV *getBlobSCEV(int BlobIdx) {
      return const_cast<SCEV *>(HIRCG->HIRF->getBlobUtils().getBlob(BlobIdx));
    }

    Value *IVCoefCG(CanonExpr *CE, CanonExpr::iv_iterator IVIt) {
      return CoefCG(CE->getIVConstCoeff(IVIt),
                    getBlobValue(CE->getIVBlobCoeff(IVIt), CE->getSrcType()));
    }

    // Return value for blobCoeff * constCoeff * iv with IV at level
    Value *IVPairCG(CanonExpr *CE, CanonExpr::iv_iterator IVIt, Type *Ty);

    // Return value for coeff*V
    Value *CoefCG(int64_t Coeff, Value *V);

    // Returns value for blobCoeff*blob in <blobidx,coeff> pair
    Value *BlobPairCG(CanonExpr *CE, CanonExpr::blob_iterator BlobIt) {
      auto BlobVal =
          CoefCG(CE->getBlobCoeff(BlobIt),
                 getBlobValue(CE->getBlobIndex(BlobIt), CE->getSrcType()));
      return BlobVal;
    }

    // Applies cast to Val according to CE's dest type, if applicable.
    Value *castToDestType(CanonExpr *CE, Value *Val);

    // Creates a stack allocation of size with name at entry of
    // current func. used for allocs that we expect to regisiterize
    AllocaInst *CreateEntryBlockAlloca(const std::string &VarName, Type *Ty,
                                       Value *size = 0) {
      IRBuilder<> TmpB(&F->getEntryBlock(), F->getEntryBlock().begin());
      return TmpB.CreateAlloca(Ty, size, VarName.c_str());
    }

    // HIRCG's considers iv names is iN.ty where N is nesting level and
    // ty is type
    static std::string getIVName(int NestingLevel, Type *Ty) {
      return "i" + std::to_string(NestingLevel) + ".i" +
             std::to_string(Ty->getPrimitiveSizeInBits());
    }

    static std::string getIVName(const HLLoop *L) {
      return getIVName(L->getNestingLevel(), L->getIVType());
    }

    // Temps are named in format of tN where N is the symbase
    static std::string getTempName(unsigned Symbase) {
      return "t" + std::to_string(Symbase);
    }

    static std::string getTempName(RegDDRef *Ref) {
      assert(!Ref->hasGEPInfo() && "Non scalar ref accessed as scalar");
      return getTempName(Ref->getSymbase());
    }

    // Gets an allocation for name of type T, creating a new allocation
    // if necessary. Allocation is a alloca at function entry
    AllocaInst *getLvalTerminalAlloca(RegDDRef *Ref);
    AllocaInst *getSymbaseAlloca(unsigned Symbase, Type *Ty,
                                 HLRegion *Region = nullptr);
    AllocaInst *getLoopIVAlloca(const HLLoop *Loop);

    // Handles special casing for SCEVUnknowns possibly representing blobs
    // within HIR framework
    // We don't want to replicate logic for handling add exprs and the like
    // so we inherit from SCEVExpander and override visitUnknown and expand()
    // Also SCEVExpander caches expanded values per IP, and attempts to hoist
    // values as far up as possible out of loop. Overridden functions do
    // not have this behavior.
    class HIRSCEVExpander : public SCEVExpander {
    public:
      HIRSCEVExpander(ScalarEvolution &SE, const DataLayout &DL,
                      const char *Name, CGVisitor &CurCG)
          : SCEVExpander(SE, DL, Name), CG(CurCG) {}

      ~HIRSCEVExpander() {}

    private:
      // provides access to named value map, blob table and ir builder
      CGVisitor &CG;

      // Some blobs require a load from memory. If an SCEVUnknown has a
      // value of type Instruction, it is assumed to be created within HIR and
      // requires a load of that blob's symbase's memory slot
      Value *visitUnknown(const SCEVUnknown *S) override {
        // Blobs represented by SCEVUnknowns whose value is constexpr or
        // globals can have their values directly returned. For example a blob
        // for a global ptr or function arg we can return the scevunknown's
        // value.
        Value *V = S->getValue();
        if (!isa<Instruction>(V))
          return V;

        // Blobs represented by an scevunknown whose value is an instruction
        // are represented by load and stores to a memory location corresponding
        // to the blob's symbase. Blobs are always rvals, and so loaded
        unsigned BlobSymbase =
            CG.HIRCG->HIRF->getBlobUtils().findTempBlobSymbase(S);

        // SCEVExpander can create its own SCEVs as intermediates which are
        // then expanded. One example is expandAddToGep which replaces
        // adds of ptr types with a SCEV for a gep instead of ptrtoints
        // and adds. These new scevunknowns have an instruction but no
        // corresponding blob. For those, return their underlying value
        if (BlobSymbase == InvalidBlobIndex) {
          return V;
        }

        AllocaInst *TempAddr = CG.getSymbaseAlloca(BlobSymbase, S->getType());
        // Be careful to use scevexpanders builder, not CGVisitor's
        // otherwise some insertions may be in wrong place.
        // There will be many loads of same temp name, so a . is added to end
        // to distinguish second load of t2 vs first load of t22
        return Builder.CreateLoad(TempAddr, TempAddr->getName() + ".");
      }

      // This is called by expandCodeFor(). Default implementation hoists
      // generated values out of loop and caches generated values. This version
      // has no caching, and no loop lookups.
      Value *expand(const SCEV *S) override { return visit(S); }
    };

    class ScopeDbgLoc {
      CGVisitor &Visitor;
      DebugLoc OldDbgLoc;

    public:
      ScopeDbgLoc(ScopeDbgLoc &&Scope) : Visitor(Scope.Visitor) {}
      ScopeDbgLoc(const ScopeDbgLoc &) = delete;

      ScopeDbgLoc(CGVisitor &Visitor, const DebugLoc &Loc) : Visitor(Visitor) {
        OldDbgLoc = Visitor.Builder->getCurrentDebugLocation();

        if (Loc) {
          Visitor.Builder->SetCurrentDebugLocation(Loc);
        }
      }

      ~ScopeDbgLoc() { Visitor.Builder->SetCurrentDebugLocation(OldDbgLoc); }
    };

    Function *F;

    HIRSCEVExpander *Expander;
    // Dont need custom insertion funcs...yet
    IRBuilder<> *Builder;
    HIRCodeGen *HIRCG;

    // keep track of our mem allocs. Only IV and temps atm
    std::map<std::string, AllocaInst *> NamedValues;

    // maps internal labels to bblocks. Needed if we encounter "goto Label"
    // before the label itself
    SmallDenseMap<HLLabel *, BasicBlock *, 16> InternalLabels;

    // A stack of IV memory slots for current loop nest. Creating a load
    // of value at CurIVValues[1] will return the IV for loop level 1 of
    // current loop nest
    SmallVector<Value *, MaxLoopNestLevel + 1> CurIVValues;

    // These are stored in HLRegion but become invalidated once CFG is
    // changed. They are required for liveout materialization, which occurs
    // after HIRCG's cfg modification
    SmallDenseMap<HLRegion *, Instruction *, 16> RegionTerminators;
    SmallDenseMap<HLRegion *, BasicBlock *, 16> RegionSucc;

    // CG splits entry block in two, creating a new bblock which should
    // still be considered part of region, as it contains values from incoming
    // LLVM IR for that HLRegion.
    SmallDenseMap<HLRegion *, BasicBlock *, 16> RegionEntrySplitBlock;
  };

  // Performs the necessary HIR Level transformations before visiting
  // CodeGen like extracting ztt.
  void preVisitCG(HLRegion *Reg) const;

  // Clears HIR related metadata from instructions. Returns true if any
  // instruction was cleared.
  bool clearHIRMetadata(HLRegion *Reg) const;

  // Returns true if we need to generate code for this region.
  bool shouldGenCode(HLRegion *Reg, unsigned RegionIdx) const;

public:
  static char ID;

  HIRCodeGen() : FunctionPass(ID) {
    initializeHIRCodeGenPass(*PassRegistry::getPassRegistry());
  }

  bool runOnFunction(Function &F) override {
    DEBUG(dbgs().write_escaped(F.getName()) << "\n");
    DEBUG(F.dump());

    this->F = &F;
    SE = &(getAnalysis<ScalarEvolutionWrapperPass>().getSE());
    HIRF = &getAnalysis<HIRFramework>();

    // generate code
    CGVisitor CG(&F, SE, this);
    bool Transformed = false;
    unsigned RegionIdx = 1;

    for (auto I = HIRF->hir_begin(), E = HIRF->hir_end(); I != E;
         ++I, ++RegionIdx) {
      HLRegion *Reg = cast<HLRegion>(&*I);

      if (shouldGenCode(Reg, RegionIdx)) {
        DEBUG(dbgs() << "Starting the code gen for " << RegionIdx << "\n");
        DEBUG(Reg->dump(true));
        DEBUG(Reg->dump());
        preVisitCG(Reg);
        CG.visit(Reg);
        Transformed = true;
      } else {
        // Clear HIR related metadata.
        bool Cleared = clearHIRMetadata(Reg);
        Transformed = Transformed || Cleared;
      }
    }

    // Liveout must be processed after all regions have be cg'd. One region's
    // live out value may be the next regions live in.
    RegionIdx = 1;
    for (auto I = HIRF->hir_begin(), E = HIRF->hir_end(); I != E;
         ++I, ++RegionIdx) {
      HLRegion *Reg = cast<HLRegion>(I);
      if (shouldGenCode(Reg, RegionIdx)) {
        CG.processLiveOut(Reg);
      }
    }

    eraseDummyInstructions();

    // No longer need to suppress scalar optimizations.
    F.resetPreLoopOpt();

    return Transformed;
  }

  void getAnalysisUsage(AnalysisUsage &AU) const {

    // AU.addRequiredTransitive<ScalarEvolutionWrapperPass>();
    AU.addRequired<ScalarEvolutionWrapperPass>();
    AU.addRequired<HIRFramework>();
  }

  /// Erases all the dummy instructions.
  void eraseDummyInstructions();
};
}

FunctionPass *llvm::createHIRCodeGenPass() { return new HIRCodeGen(); }

char HIRCodeGen::ID = 0;
INITIALIZE_PASS_BEGIN(HIRCodeGen, "hir-cg", "HIR Code Generation", false, false)
INITIALIZE_PASS_DEPENDENCY(ScalarEvolutionWrapperPass)
INITIALIZE_PASS_DEPENDENCY(HIRFramework)
INITIALIZE_PASS_END(HIRCodeGen, "hir-cg", "HIR Code Generation", false, false)

bool HIRCodeGen::shouldGenCode(HLRegion *Reg, unsigned RegionIdx) const {

  if (HIRDebugRegion) {
    if (HIRDebugRegion == RegionIdx) {
      return true;
    } else {
      return false;
    }
  }

  if (forceHIRCG) {
    return true;
  }

  if (Reg->shouldGenCode()) {
    return true;
  }

  return false;
}

bool HIRCodeGen::clearHIRMetadata(HLRegion *Reg) const {
  bool Cleared = false;
  unsigned LiveInID = SE->getHIRMDKindID(ScalarEvolution::HIRLiveKind::LiveIn);
  unsigned LiveOutID =
      SE->getHIRMDKindID(ScalarEvolution::HIRLiveKind::LiveOut);
  unsigned LiveRangeID =
      SE->getHIRMDKindID(ScalarEvolution::HIRLiveKind::LiveRange);

  for (auto BB = Reg->bb_begin(), End = Reg->bb_end(); BB != End; ++BB) {
    for (auto &Inst : **BB) {
      Instruction &NonConstInst = const_cast<Instruction &>(Inst);

      if (Inst.getMetadata(LiveInID)) {
        Cleared = true;
        NonConstInst.setMetadata(LiveInID, nullptr);

      } else if (Inst.getMetadata(LiveOutID)) {
        Cleared = true;
        NonConstInst.setMetadata(LiveOutID, nullptr);

      } else if (Inst.getMetadata(LiveRangeID)) {
        Cleared = true;
        NonConstInst.setMetadata(LiveRangeID, nullptr);
      }
    }
  }

  return Cleared;
}

void HIRCodeGen::preVisitCG(HLRegion *Reg) const {
  // Gather all loops for processing.
  SmallVector<HLLoop *, 64> Loops;
  Reg->getHLNodeUtils().gatherAllLoops(Reg, Loops);

  // Extract ztt, preheader and postexit.
  for (auto &I : Loops) {
    I->extractZtt();
    I->extractPreheaderAndPostexit();
  }
}

Value *HIRCodeGen::CGVisitor::castToDestType(CanonExpr *CE, Value *Val) {

  auto DestTy = CE->getDestType();
  Type *CastToTy;

  // If Val is a scalar and DestType is a vector, apply the cast operation
  // before the broadcast - this is important for good performance
  if (DestTy->isVectorTy() && !Val->getType()->isVectorTy()) {
    CastToTy = DestTy->getScalarType();
  } else {
    CastToTy = DestTy;
  }

  if (CE->isSExt()) {
    Val = Builder->CreateSExt(Val, CastToTy);
  } else if (CE->isZExt()) {
    Val = Builder->CreateZExt(Val, CastToTy);
  } else if (CE->isTrunc()) {
    Val = Builder->CreateTrunc(Val, CastToTy);
  }

  // If the cast value is a scalar type and dest type is a vector, we need
  // to do a broadcast.
  if (DestTy->isVectorTy() && !Val->getType()->isVectorTy()) {
    Val = Builder->CreateVectorSplat(DestTy->getVectorNumElements(), Val);
  }

  return Val;
}

Value *HIRCodeGen::CGVisitor::createCmpInst(const HLPredicate &P, Value *LHS,
                                            Value *RHS, const Twine &Name) {
  Value *CmpInst = nullptr;

  ScopeDbgLoc DbgLoc(*this, P.DbgLoc);

  // Account for vector type
  auto LType = LHS->getType()->getScalarType();

  assert(P != UNDEFINED_PREDICATE && "invalid predicate for cmp/sel in HIRCG");

  if (LType->isIntegerTy() || LType->isPointerTy()) {
    CmpInst = Builder->CreateICmp(P, LHS, RHS, Name);
  } else if (LType->isFloatingPointTy()) {
    Builder->setFastMathFlags(P.FMF);
    CmpInst = Builder->CreateFCmp(P, LHS, RHS, Name);
    Builder->clearFastMathFlags();
  } else {
    llvm_unreachable("unknown predicate type in HIRCG");
  }

  return CmpInst;
}

Value *HIRCodeGen::CGVisitor::getBlobValue(int BlobIdx, Type *Ty) {
  // SCEVExpander instruction generator references the insertion point's
  // parent.
  // If the IP is bblock.end(), undefined behavior results because the
  // parent of that "instruction" is invalid. We work around this by
  // adding temporary instruction to use as our IP, and remove it after
  Instruction *TmpIP = Builder->CreateUnreachable();
  Value *Blob = Expander->expandCodeFor(getBlobSCEV(BlobIdx), nullptr, TmpIP);

  // Expander shouldnt create new Bblocks, new IP is end of current bblock
  Builder->SetInsertPoint(TmpIP->getParent());
  TmpIP->eraseFromParent();
  Type *BType = Blob->getType();
  if (BType->isPointerTy() && BType != Ty) {
    // A version of this should be in verifier, but we want to test CG'd
    // type
    unsigned PtrSize =
        F->getParent()->getDataLayout().getPointerTypeSizeInBits(BType);
    assert(Ty->getScalarSizeInBits() == PtrSize &&
           "Pointer size and CE size mismatch");
    Blob = Builder->CreatePtrToInt(Blob, Ty->getScalarType());
  }
  return Blob;
}

Value *HIRCodeGen::CGVisitor::visitCanonExpr(CanonExpr *CE) {
  Value *BlobSum = nullptr, *IVSum = nullptr, *C0Value = nullptr,
        *DenomVal = nullptr;

  ScopeDbgLoc DbgLoc(*this, CE->getDebugLoc());

  auto SrcType = CE->getSrcType();

  DEBUG(dbgs() << "cg for CE ");
  DEBUG(CE->dump());
  DEBUG(dbgs() << "\n");

  if (CE->isNull()) {
    return ConstantPointerNull::get(cast<PointerType>(SrcType));
  }

  if (CE->isNullVector()) {
    auto PtrType = cast<PointerType>(SrcType->getScalarType());

    auto NullVal = ConstantPointerNull::get(PtrType);
    return Builder->CreateVectorSplat(SrcType->getVectorNumElements(), NullVal);
  }

  BlobSum = sumBlobs(CE);
  IVSum = sumIV(CE);

  // Broadcast scalar value only when absolutely needed. The broadcast is
  // needed when both BlobSum and IVSum are non-null and one of BlobSum/IVSum
  // is a vector and the other is a scalar.
  if (SrcType->isVectorTy()) {
    if ((BlobSum && BlobSum->getType()->isVectorTy()) ||
        (IVSum && IVSum->getType()->isVectorTy())) {
      if (BlobSum && !(BlobSum->getType()->isVectorTy())) {
        BlobSum = Builder->CreateVectorSplat(SrcType->getVectorNumElements(),
                                             BlobSum);
      }
      if (IVSum && !(IVSum->getType()->isVectorTy())) {
        IVSum =
            Builder->CreateVectorSplat(SrcType->getVectorNumElements(), IVSum);
      }
    } else {
      // Both BlobSum/IVSum are scalar, for C0/Denom use Scalar type.
      // Any necessary broadcast is done in castToDestType.
      SrcType = SrcType->getScalarType();
    }
  }

  int64_t C0 = CE->getConstant();
  int64_t Denom = CE->getDenominator();

  // TODO I dunno about htis more specially a pointer?
  // ie [i32 X 10] for type of base ptr what type to use?
  if (C0) {
    if (isa<CompositeType>(SrcType)) {
      // We should be generating a GEP for a pointer base with an offset. For
      // struct types, we need to follow the structure layout.
      assert("Pointer base with offset not handled!");
      // SrcType = IntegerType::get(F->getContext(),
      // SrcType->getPrimitiveSizeInBits());
    }
    C0Value = ConstantInt::getSigned(SrcType, C0);
  }

  // combine the blob, const, and ivs into one value
  Value *Res = nullptr;
  if (BlobSum && IVSum) {
    Res = Builder->CreateAdd(BlobSum, IVSum);
  } else {
    Res = IVSum ? IVSum : BlobSum;
  }
  if (Res) {
    Res = C0Value ? Builder->CreateAdd(Res, C0Value) : Res;
  } else {
    Res = C0Value;
  }

  if (!Res) {
    // assert c0 is 0. no iv no blob
    if (CE->hasIV() || CE->hasBlob() || C0 != 0)
      llvm_unreachable("failed to cg IV or blob");
    Res = ConstantInt::getSigned(SrcType, C0);
  }

  if (Denom != 1) {
    DenomVal = ConstantInt::getSigned(SrcType, Denom);

    if (CE->isSignedDiv()) {
      Res = Builder->CreateSDiv(Res, DenomVal);
    } else {
      Res = Builder->CreateUDiv(Res, DenomVal);
    }
  }

  Res = castToDestType(CE, Res);

  return Res;
}

AllocaInst *HIRCodeGen::CGVisitor::getLvalTerminalAlloca(RegDDRef *Ref) {
  assert(Ref->isLval() && "Ref is expected to be Lval");
  assert(Ref->isTerminalRef() && "Ref is expected to be terminal");

  return getSymbaseAlloca(Ref->getSymbase(), Ref->getDestType(),
                          Ref->getHLDDNode()->getParentRegion());
}

AllocaInst *HIRCodeGen::CGVisitor::getSymbaseAlloca(unsigned Symbase, Type *Ty,
                                                    HLRegion *Region) {
  AllocaInst *Alloca;
  std::string Name = getTempName(Symbase);
  if (!NamedValues.count(Name)) {
    assert(Region && "Region should be defined for uninitialized symbase");

    Alloca = CreateEntryBlockAlloca(Name, Ty);

    auto Iter = Region->getDebugIntrinMap().find(Symbase);
    if (Iter != Region->getDebugIntrinMap().end()) {
      auto &DbgInstVector = Iter->second;

      for (const DbgInfoIntrinsic *DbgInfoInst : DbgInstVector) {
        generateDeclareValue(Alloca, DbgInfoInst);
      }
    }

    NamedValues[Name] = Alloca;
  } else {
    Alloca = NamedValues[Name];
    assert(Ty == Alloca->getAllocatedType() && "Mismatch alloca type request");
  }
  return Alloca;
}

AllocaInst *HIRCodeGen::CGVisitor::getLoopIVAlloca(const HLLoop *Loop) {
  AllocaInst *Alloca;

  std::string Name = getIVName(Loop);
  if (!NamedValues.count(Name)) {
    Alloca = CreateEntryBlockAlloca(Name, Loop->getIVType());
    NamedValues[Name] = Alloca;
  } else {
    Alloca = NamedValues[Name];
    assert(Loop->getIVType() == Alloca->getAllocatedType() &&
           "Mismatch alloca type request");
  }

  return Alloca;
}

Value *HIRCodeGen::CGVisitor::visitScalar(RegDDRef *Ref) {
  CanonExpr *ScalarCE = Ref->getSingleCanonExpr();

  // For rval temps, we generate value directly from CE
  if (Ref->isRval()) {
    return visitCanonExpr(ScalarCE);
  }

  ScopeDbgLoc DbgLoc(*this, ScalarCE->getDebugLoc());

  // For lvals return address of temp
  return getLvalTerminalAlloca(Ref);
}

Value *HIRCodeGen::CGVisitor::visitRegDDRef(RegDDRef *Ref, Value *MaskVal) {
  assert(Ref && " Reference is null.");
  DEBUG(dbgs() << "cg for RegRef ");
  DEBUG(Ref->dump());
  DEBUG(dbgs() << " Symbase: " << Ref->getSymbase() << " \n");

  if (Ref->isTerminalRef()) {
    return visitScalar(Ref);
  }

  ScopeDbgLoc GepDbgLoc(*this, Ref->getGepDebugLoc());

  Value *BaseV = visitCanonExpr(Ref->getBaseCE());

  SmallVector<Value *, 4> IndexV;
  bool AnyVector = false;
  bool NeedGEP = true;
  unsigned DimNum = Ref->getNumDimensions();

  // Ref either looks like t[0] or &t[0]. In such cases we don't need a GEP, we
  // can simply use the base value. Also, for opaque (forward declared) struct
  // types, LLVM doesn't allow any indices even if it is just a zero.
  if ((DimNum == 1) && !Ref->hasTrailingStructOffsets() &&
      (*Ref->canon_begin())->isZero()) {
    NeedGEP = false;
  } else {

    // stored as A[canon3][canon2][canon1], but gep requires them in reverse
    // order
    for (auto CEIt = Ref->canon_rbegin(), E = Ref->canon_rend(); CEIt != E;
         ++CEIt, --DimNum) {
      auto IndexVal = visitCanonExpr(*CEIt);

      if (IndexVal->getType()->isVectorTy()) {
        AnyVector = true;
      }

      IndexV.push_back(IndexVal);

      // Push back indices for dimensions's trailing offsets.
      auto Offsets = Ref->getTrailingStructOffsets(DimNum);

      if (Offsets) {
        // Structure fields are always i32 type.
        auto I32Ty = Type::getInt32Ty(F->getContext());

        for (auto OffsetVal : *Offsets) {
          auto OffsetIndex = ConstantInt::get(I32Ty, OffsetVal);
          IndexV.push_back(OffsetIndex);
        }
      }
    }
  }

  // A GEP instruction is allowed to have a mix of scalar and vector operands.
  // However, not all optimizations(especially LLVM loop unroller) are handling
  // such cases. To workaround, the base pointer value needs to be broadcast.
  if (AnyVector && !BaseV->getType()->isVectorTy()) {
    auto VL = Ref->getDestType()->getVectorNumElements();
    BaseV = Builder->CreateVectorSplat(VL, BaseV);
  }

  Value *GEPVal;

  if (!NeedGEP) {
    GEPVal = BaseV;
  } else if (Ref->isInBounds()) {
    GEPVal = Builder->CreateInBoundsGEP(BaseV, IndexV, "arrayIdx");
  } else {
    GEPVal = Builder->CreateGEP(BaseV, IndexV, "arrayIdx");
  }

  if (GEPVal->getType()->isVectorTy() &&
      isa<PointerType>(Ref->getBaseDestType())) {
    // When we have a vector of pointers and base src and dest types do not
    // match, we need to bitcast from vector of pointers of src type to vector
    // of pointers of dest type. Example case, Src type is int * and Dest type
    // is <4 x float>*, we will have pointer vector <4 x int*>. This vector
    // needs to be bitcast to <4 x float*> so that the gather/scatter
    // loads/stores <4 x float>.
    auto BaseDestTy = Ref->getBaseDestType();             // <4 x float>*
    auto PtrBaseDestTy = cast<PointerType>(BaseDestTy);   // <4 x float>*
    auto BaseDestElTy = PtrBaseDestTy->getElementType();  // <4 x float>
    auto BaseDestScTy = BaseDestElTy->getScalarType();    // float
    auto BaseDestScPtrTy = PointerType::get(BaseDestScTy, // float *
                                            PtrBaseDestTy->getAddressSpace());

    if (Ref->getBaseSrcType() != BaseDestScPtrTy) {
      auto VL = BaseDestElTy->getVectorNumElements();

      // We have a vector of pointers of BaseSrcType. We need to convert it to
      // vector of pointers of BaseDestScType.
      GEPVal =
          Builder->CreateBitCast(GEPVal, VectorType::get(BaseDestScPtrTy, VL));
    }
  } else {
    // Base CE could have different src and dest types in which case we need a
    // bitcast. Can occur from llvm's canonicalization of store/load of float
    // to int by bitcast. Note that bitcast of  something like int * to
    // <4 x int>* is also handled here.
    if (Ref->getBaseSrcType() != Ref->getBaseDestType()) {
      GEPVal = Builder->CreateBitCast(GEPVal, Ref->getBaseDestType());
    }
  }

  if (Ref->isAddressOf()) {
    return GEPVal;
  }

  ScopeDbgLoc DbgLoc(*this, Ref->getMemDebugLoc());

  // Ref is A[i], but meaning differs for lval vs rval. On rhs, we want the
  // value of A[i], ie a load. For lval, we will store into &A[i], so we
  // want the address, the gep
  if (Ref->isRval()) {
    Instruction *LInst;

    if (GEPVal->getType()->isVectorTy()) {
      LInst = VPOUtils::createMaskedGatherCall(F->getParent(), GEPVal, *Builder,
                                               Ref->getAlignment(), MaskVal);
    } else if (MaskVal) {
      LInst = VPOUtils::createMaskedLoadCall(GEPVal, *Builder,
                                             Ref->getAlignment(), MaskVal);
    } else {
      LInst = Builder->CreateAlignedLoad(GEPVal, Ref->getAlignment(),
                                         Ref->isVolatile(), "gepload");
    }

    setMetadata(LInst, Ref);

    return LInst;
  }

  return GEPVal;
}

void HIRCodeGen::CGVisitor::processLiveOut(HLRegion *Region) {

  BasicBlock *SuccBBlock = RegionSucc[Region];
  BasicBlock *NewRegionBlock = RegionEntrySplitBlock[Region];

  Instruction *RegionTerminator = RegionTerminators[Region];
  BasicBlock *LastRegionBBlock =
      RegionTerminator ? RegionTerminator->getParent() : nullptr;

  for (auto I = Region->live_out_begin(), E = Region->live_out_end(); I != E;
       ++I) {

    DEBUG(dbgs() << "Symbase " << I->first
                 << " is liveout with tracked value ");
    DEBUG(I->second->dump());
    DEBUG(dbgs() << " \n");
    DEBUG(SuccBBlock->dump());

    BasicBlock::iterator IP = SuccBBlock->getFirstInsertionPt();
    Builder->SetInsertPoint(&*IP);

    AllocaInst *SymSlot =
        getSymbaseAlloca(I->first, I->second->getType(), Region);
    Value *ReplVal = Builder->CreateLoad(SymSlot);

    Value *LiveOutVal = const_cast<Value *>(I->second);
    SmallVector<Instruction *, 4> CurUsers;
    SmallVector<PHINode *, 4> PhiUsers;

    // Gather all uses outside of region before replacing any
    for (Use &LiveOutUse : LiveOutVal->uses()) {
      if (Instruction *Inst = dyn_cast<Instruction>(LiveOutUse.getUser())) {
        BasicBlock *UseParentBBlock = Inst->getParent();
        // Might need to constrain this to only uses outside ANY HIR region?

        // Use is in the now split entry bblock's second half, consider it
        // part of hlregion and skip it, lest the use precede the def
        if (NewRegionBlock == UseParentBBlock) {
          continue;
        }
        if (!Region->containsBBlock(UseParentBBlock)) {
          if (PHINode *Phi = dyn_cast<PHINode>(Inst)) {
            if (UseParentBBlock == SuccBBlock) {
              // uses in succ bblock must be handled differently if user itself
              // is a phi. The load was generated after the user since all phi
              // are before any other inst in bblock. We must insert
              // load in last bblock of region and add a new phi operand.
              PhiUsers.push_back(Phi);
              continue;
            }
          }
          CurUsers.push_back(Inst);
        }
      } else {
        llvm_unreachable("unknown case of liveout");
      }
    }

    // Replace those uses with loaded value
    for (auto I = CurUsers.begin(), E = CurUsers.end(); I != E; ++I) {
      (*I)->replaceUsesOfWith(LiveOutVal, ReplVal);
    }

    // create load before region terminator and add it as
    // incoming value to successor bblock phi
    Builder->SetInsertPoint(RegionTerminator);
    for (auto I = PhiUsers.begin(), E = PhiUsers.end(); I != E; ++I) {
      Value *InRegionLoad = Builder->CreateLoad(SymSlot);
      (*I)->addIncoming(InRegionLoad, LastRegionBBlock);
    }
  }

  if (LastRegionBBlock) {
    // In some cases, loops exits have single operand phi where the operand is
    // defined before the loop. These values are simply flowing through the
    // region. We patch such phis so that the same value flows through the
    // generated code as well.
    for (auto Inst = SuccBBlock->begin(), E = SuccBBlock->end(); Inst != E;
         ++Inst) {
      auto Phi = dyn_cast<PHINode>(&*Inst);

      if (!Phi) {
        break;
      }

      if (Phi->getNumIncomingValues() != 1) {
        continue;
      }

      auto InComingVal = Phi->getIncomingValue(0);

      assert((!isa<Instruction>(InComingVal) ||
              !Region->containsBBlock(
                  dyn_cast<Instruction>(InComingVal)->getParent())) &&
             "Unprocessed liveout value cannot be inside the region!");
      assert(
          (Phi->getIncomingBlock(0) != LastRegionBBlock) &&
          "Single operand phi with incoming block as generated region's last "
          "bblock not expected!");
      Phi->addIncoming(Phi->getIncomingValue(0), LastRegionBBlock);
    }
  }
}

void HIRCodeGen::CGVisitor::generateDeclareValue(
    AllocaInst *Alloca, const DbgInfoIntrinsic *DbgInfoIntrin) {
  if (const DbgValueInst *ValueInst = dyn_cast<DbgValueInst>(DbgInfoIntrin)) {
    generateDeclareValue(Alloca, ValueInst->getVariable(),
                         ValueInst->getExpression(), ValueInst->getDebugLoc());
  } else if (const DbgDeclareInst *DeclareInst =
                 dyn_cast<DbgDeclareInst>(DbgInfoIntrin)) {
    generateDeclareValue(Alloca, DeclareInst->getVariable(),
                         DeclareInst->getExpression(),
                         DeclareInst->getDebugLoc());
  } else {
    llvm_unreachable("Unexpected debug intrinsic type");
  }
}

void HIRCodeGen::CGVisitor::generateDeclareValue(AllocaInst *Alloca,
                                                 DILocalVariable *LocalVariable,
                                                 DIExpression *Expression,
                                                 DILocation *Location) {
  assert(LocalVariable &&
         "empty or invalid DILocalVariable* passed to dbg.declare");
  assert(Location && "Expected debug loc");
  assert(Location->getScope()->getSubprogram() ==
             LocalVariable->getScope()->getSubprogram() &&
         "Expected matching subprograms");

  Function *DeclareFn =
      Intrinsic::getDeclaration(F->getParent(), Intrinsic::dbg_declare);

  auto &Context = F->getContext();
  Value *Args[] = {MetadataAsValue::get(Context, ValueAsMetadata::get(Alloca)),
                   MetadataAsValue::get(Context, LocalVariable),
                   MetadataAsValue::get(Context, Expression)};

  Instruction *CallInst = CallInst::Create(DeclareFn, Args);
  CallInst->setDebugLoc(Location);

  CallInst->insertAfter(Alloca);
}

void HIRCodeGen::CGVisitor::initializeLiveIn(HLRegion *R) {
  for (auto I = R->live_in_begin(), E = R->live_in_end(); I != E; ++I) {
    DEBUG(dbgs() << "Symbase " << I->first << " is livein with initial value ");
    DEBUG(I->second->dump());
    DEBUG(dbgs() << " \n");
    AllocaInst *SymSlot = getSymbaseAlloca(I->first, I->second->getType(), R);

    Value *Val = const_cast<Value *>(I->second);
    Builder->CreateStore(Val, SymSlot);
  }
}

Value *HIRCodeGen::CGVisitor::visitRegion(HLRegion *R) {

  assert(CurIVValues.empty() && "IV list not empty at region start");

  // push back one null so iv for level 1 is at array position 1
  // in other words, make this vector 1 indexed
  CurIVValues.push_back(nullptr);
  // create new bblock for region entry
  BasicBlock *RegionEntry = BasicBlock::Create(
      F->getContext(), "region." + std::to_string(R->getNumber()), F);
  Builder->SetInsertPoint(RegionEntry);

  initializeLiveIn(R);

  // Onto children cg
  for (auto It = R->child_begin(), E = R->child_end(); It != E; ++It) {
    visit(*It);
  }

  // Patch up predecessor(s) to region entry bblock
  // We do this by splitting the region entry bblock, with first block having
  // original label, but only a br to the second block, with second bblock
  // with the original instructions. Then the br to second block is replaced by
  // a cond br with true branch jumping to our new region'a entry and
  // false jumping to old code(second bblock), but cond always being true.
  // We end on valid IR but must call some form of pred opt to remove old code

  // Save entry and succ fields, these get invalidated once block is split
  BasicBlock *EntryFirstHalf = R->getEntryBBlock();

  // Split the block if the region entry is the same as function entry
  // TODO - As mentioned in discussions with Pankaj, the framework should
  // handle this splitting as splitting here can cause problems.
  if (&(F->getEntryBlock()) == EntryFirstHalf) {
    EntryFirstHalf = EntryFirstHalf->splitBasicBlock(
        EntryFirstHalf->getTerminator(), "entry.split");
  }

  BasicBlock *RegionSuccessor = R->getSuccBBlock();
  RegionSucc[R] = RegionSuccessor;

  BasicBlock *EntrySecondHalf =
      SplitBlock(EntryFirstHalf, &*(EntryFirstHalf->begin()));
  RegionEntrySplitBlock[R] = EntrySecondHalf;

  Instruction *Term = EntryFirstHalf->getTerminator();
  BasicBlock::iterator ii(Term);
  BranchInst *RegionBranch = BranchInst::Create(
      RegionEntry, EntrySecondHalf,
      ConstantInt::get(IntegerType::get(F->getContext(), 1), 1));
  ReplaceInstWithInst(Term->getParent()->getInstList(), ii, RegionBranch);

  // current insertion point is at end of region, add jump to successor
  // and we are done
  if (RegionSuccessor) {
    Value *Terminator = Builder->CreateBr(RegionSuccessor);
    RegionTerminators[R] = cast<Instruction>(Terminator);
  } else {
    assert(R->exitsFunction() && "no successor block to region!");
    assert((R->live_out_begin() == R->live_out_end()) &&
           "Unsupported liveout for multiexit region!");
  }

  // DEBUG(F->dump());
  // Remove null value used for indexing
  CurIVValues.pop_back();
  return nullptr;
}

Value *HIRCodeGen::CGVisitor::generatePredicate(HLIf *HIf,
                                                HLIf::const_pred_iterator P) {
  Value *CurPred = nullptr;
  Value *LHSVal, *RHSVal;

  RegDDRef *LHSRef = HIf->getPredicateOperandDDRef(P, true);
  RegDDRef *RHSRef = HIf->getPredicateOperandDDRef(P, false);

  // For undef predicate, we don't need to CG operands since end result
  // is undef anyway.
  if (*P == UNDEFINED_PREDICATE) {
    // TODO icmp/fcmp with nonvector args return a boolean, i1 but
    // vector types would require cmp to return vector of i1
    return UndefValue::get(IntegerType::get(F->getContext(), 1));
  }

  LHSVal = visitRegDDRef(LHSRef);
  RHSVal = visitRegDDRef(RHSRef);
  assert(LHSVal->getType() == RHSVal->getType() &&
         "HLIf predicate type mismatch");

  CurPred = createCmpInst(*P, LHSVal, RHSVal,
                          "hir.cmp." + std::to_string(HIf->getNumber()));

  return CurPred;
}

Value *HIRCodeGen::CGVisitor::generateAllPredicates(HLIf *HIf) {

  auto FirstPred = HIf->pred_begin();
  Value *CurPred = generatePredicate(HIf, FirstPred);

  for (auto It = HIf->pred_begin() + 1, E = HIf->pred_end(); It != E; ++It) {
    // conjunctions are implicitly AND atm.
    CurPred = Builder->CreateAnd(CurPred, generatePredicate(HIf, It));
  }

  return CurPred;
}

void HIRCodeGen::CGVisitor::generateBranchIfRequired(BasicBlock *ToBB) {
  auto InsertBB = Builder->GetInsertBlock();

  if (InsertBB->empty() || !isa<TerminatorInst>(InsertBB->back())) {
    Builder->CreateBr(ToBB);
  }
}

Value *HIRCodeGen::CGVisitor::visitIf(HLIf *HIf, Value *IVAdd,
                                      AllocaInst *IVAlloca) {
  ScopeDbgLoc DbgLoc(*this, HIf->getDebugLoc());

  Value *CondV = generateAllPredicates(HIf);

  std::string HNumStr = std::to_string(HIf->getNumber());
  BasicBlock *MergeBB =
      BasicBlock::Create(F->getContext(), "ifmerge." + HNumStr);

  bool HasThenChildren = HIf->hasThenChildren();
  bool HasElseChildren = HIf->hasElseChildren();

  BasicBlock *ThenBB =
      HasThenChildren ? BasicBlock::Create(F->getContext(), "then." + HNumStr)
                      : MergeBB;
  BasicBlock *ElseBB =
      HasElseChildren ? BasicBlock::Create(F->getContext(), "else." + HNumStr)
                      : MergeBB;

  Builder->CreateCondBr(CondV, ThenBB, ElseBB);

  if (HasThenChildren) {
    // generate then block
    F->getBasicBlockList().push_back(ThenBB);
    Builder->SetInsertPoint(ThenBB);

    if (IVAdd) {
      // Create the IV store for unknown loops inside the bottom test.
      Builder->CreateStore(IVAdd, IVAlloca);
    }

    for (auto It = HIf->then_begin(), E = HIf->then_end(); It != E; ++It) {
      visit(*It);
    }

    generateBranchIfRequired(MergeBB);
  }

  if (HasElseChildren) {
    assert(!IVAdd && "Bottom test cannot have else case!");

    // generate else block
    F->getBasicBlockList().push_back(ElseBB);
    Builder->SetInsertPoint(ElseBB);
    for (auto It = HIf->else_begin(), E = HIf->else_end(); It != E; ++It) {
      visit(*It);
    }

    generateBranchIfRequired(MergeBB);
  }

  // CG resumes at merge block
  F->getBasicBlockList().push_back(MergeBB);
  Builder->SetInsertPoint(MergeBB);

  return nullptr;
}

Value *HIRCodeGen::CGVisitor::visitLoop(HLLoop *Lp) {
  assert(!Lp->hasZtt() && "Ztt should have been extracted!");
  assert((!Lp->hasPreheader() && !Lp->hasPostexit()) &&
         "Preheader/Postexit should have been extracted!");

  bool IsUnknownLoop = Lp->isUnknown();

  // set up IV, I think we can reuse the IV allocation across
  // multiple loops of same depth
  AllocaInst *Alloca = getLoopIVAlloca(Lp);

  // Keep a stack of IV values. CanonExpr CG needs to know types
  // of loop IV itself, but this information is not available from
  // CE
  CurIVValues.push_back(Alloca);

  Value *StartVal = visitRegDDRef(Lp->getLowerDDRef());

  if (!StartVal || !Alloca)
    llvm_unreachable("Failed to CG IV");

  assert(StartVal->getType() == Lp->getIVType() &&
         "IVtype does not match start type");

  Builder->CreateStore(StartVal, Alloca);

  Value *Upper = nullptr;
  BasicBlock *LoopBB = nullptr;

  std::string LName = "loop." + std::to_string(Lp->getNumber());

  if (!IsUnknownLoop) {
    // upper is loop invariant so we can generate it outside the loop
    Upper = visitRegDDRef(Lp->getUpperDDRef());

    assert(Upper->getType() == Lp->getIVType() &&
           "IVtype does not match upper type");

    LoopBB = BasicBlock::Create(F->getContext(), LName, F);

    // explicit fallthru to loop, terminates current bblock
    Builder->CreateBr(LoopBB);
    Builder->SetInsertPoint(LoopBB);
  }

  auto LastIt =
      IsUnknownLoop ? Lp->getBottomTest()->getIterator() : Lp->child_end();

  // CG children
  for (auto It = Lp->child_begin(); It != LastIt; ++It) {
    visit(*It);
  }

  ScopeDbgLoc DbgLocBottomTest(*this, Lp->getCmpDebugLoc());

  // increment IV
  Value *CurVar = Builder->CreateLoad(Alloca);
  Value *StepVal = IsUnknownLoop ? ConstantInt::getSigned(Lp->getIVType(), 1)
                                 : visitRegDDRef(Lp->getStrideDDRef());

  assert(StepVal->getType() == Lp->getIVType() &&
         "IVtype does not match stepval type");

  bool IsNSW = Lp->isNSW();

  // NUW flag is applicable either if loop is not unknown or we could deduce
  // NSW.
  // NOTE: We do not try to deduce NUW flag for unknown loops so we may be
  // losing info in some cases.
  Value *NextVar = Builder->CreateAdd(CurVar, StepVal, "nextiv" + LName,
                                      (IsNSW || !IsUnknownLoop), IsNSW);

  if (IsUnknownLoop) {
    // visit bottom test of unknown loop and pass in information to generate IV
    // store inside it.
    visitIf(cast<HLIf>(&*LastIt), NextVar, Alloca);
  } else {
    // Create store to IV.
    Builder->CreateStore(NextVar, Alloca);

    // generate bottom test.
    Value *EndCond =
        Builder->CreateICmp(Lp->isNSW() ? CmpInst::ICMP_SLE : CmpInst::ICMP_ULE,
                            NextVar, Upper, "cond" + LName);

    BasicBlock *AfterBB =
        BasicBlock::Create(F->getContext(), "after" + LName, F);

    ScopeDbgLoc DbgLocBranch(*this, Lp->getBranchDebugLoc());

    // latch
    BranchInst *Br = Builder->CreateCondBr(EndCond, LoopBB, AfterBB);

    if (MDNode *MD = Lp->getLoopMetadata()) {
      Br->setMetadata(LLVMContext::MD_loop, MD);
    }

    // new code goes after loop
    Builder->SetInsertPoint(AfterBB);
  }

  CurIVValues.pop_back();

  return nullptr;
}

BasicBlock *HIRCodeGen::CGVisitor::getBBlockForLabel(HLLabel *L) {
  if (InternalLabels.count(L))
    return InternalLabels[L];

  BasicBlock *LabelBB =
      BasicBlock::Create(F->getContext(), "hir." + L->getName(), F);
  InternalLabels[L] = LabelBB;
  return LabelBB;
}

Value *HIRCodeGen::CGVisitor::visitLabel(HLLabel *L) {
  // if we see label it must be internal, and it must be unique
  BasicBlock *LabelBBlock = getBBlockForLabel(L);
  assert(LabelBBlock->empty() && "label already in use");

  // create a br to L's block. ending current block
  generateBranchIfRequired(LabelBBlock);
  Builder->SetInsertPoint(LabelBBlock);
  return nullptr;
}

Value *HIRCodeGen::CGVisitor::visitGoto(HLGoto *Goto) {
  ScopeDbgLoc DbgLoc(*this, Goto->getDebugLoc());

  // get basic block for G's target
  BasicBlock *TargetBBlock = Goto->getTargetBBlock();

  if (TargetBBlock) {
    HLRegion *R = Goto->getParentRegion();
    if ((Goto != R->getLastChild()) &&
        (R->live_out_begin() != R->live_out_end())) {
      llvm_unreachable("Unsupported liveout for multiexit region");
    }
  }

  // if bblock is null, it must be internal.
  if (!TargetBBlock)
    TargetBBlock = getBBlockForLabel(Goto->getTargetLabel());

  assert(TargetBBlock && "No bblock target for goto");
  // create a br to target, ending this block
  Builder->CreateBr(TargetBBlock);

  return nullptr;
}

Value *HIRCodeGen::CGVisitor::visitSwitch(HLSwitch *S) {
  ScopeDbgLoc DbgLoc(*this, S->getDebugLoc());

  Value *CondV = visitRegDDRef(S->getConditionDDRef());
  SmallString<10> SwitchName("hir.sw." + std::to_string(S->getNumber()));

  BasicBlock *DefaultBlock =
      BasicBlock::Create(F->getContext(), SwitchName + ".default");
  BasicBlock *EndBlock =
      BasicBlock::Create(F->getContext(), SwitchName + ".end");

  SwitchInst *LLVMSwitch =
      Builder->CreateSwitch(CondV, DefaultBlock, S->getNumCases());

  // generate default block
  F->getBasicBlockList().push_back(DefaultBlock);
  Builder->SetInsertPoint(DefaultBlock);
  for (auto I = S->default_case_child_begin(), E = S->default_case_child_end();
       I != E; ++I) {
    visit(*I);
  }

  generateBranchIfRequired(EndBlock);

  // generate case blocks
  for (unsigned int I = 1; I <= S->getNumCases(); ++I) {
    Value *CaseV = visitRegDDRef(S->getCaseValueDDRef(I));
    // assert its a constant or rely on verifier?
    ConstantInt *CaseInt = cast<ConstantInt>(CaseV);

    BasicBlock *CaseBlock = BasicBlock::Create(
        F->getContext(), SwitchName + ".case." + std::to_string(I - 1));
    F->getBasicBlockList().push_back(CaseBlock);
    Builder->SetInsertPoint(CaseBlock);

    for (auto HNode = S->case_child_begin(I), E = S->case_child_end(I);
         HNode != E; ++HNode) {
      visit(*HNode);
    }

    generateBranchIfRequired(EndBlock);
    LLVMSwitch->addCase(CaseInt, CaseBlock);
  }

  F->getBasicBlockList().push_back(EndBlock);
  Builder->SetInsertPoint(EndBlock);
  return nullptr;
}

void HIRCodeGen::CGVisitor::setMetadata(Value *Val, const RegDDRef *Ref) {
  if (Instruction *Instr = dyn_cast<Instruction>(Val)) {
    setMetadata(Instr, Ref);
  }
}

void HIRCodeGen::CGVisitor::setMetadata(Instruction *Inst,
                                        const RegDDRef *Ref) {
  RegDDRef::MDNodesTy MDs;
  Ref->getAllMetadataOtherThanDebugLoc(MDs);
  setMetadata(Inst, MDs);
}

void HIRCodeGen::CGVisitor::setMetadata(Instruction *Inst,
                                        const RegDDRef::MDNodesTy &MDs) {
  for (auto const &I : MDs) {
    Inst->setMetadata(I.first, I.second);
  }
}

void HIRCodeGen::CGVisitor::generateLvalStore(const HLInst *HInst,
                                              Value *StorePtr,
                                              Value *StoreVal) {
  if (!HInst->hasLval()) {
    return;
  }

  auto LvalRef = HInst->getLvalDDRef();
  RegDDRef *MaskDDRef = const_cast<RegDDRef *>(HInst->getMaskDDRef());
  Value *MaskVal = MaskDDRef ? visitRegDDRef(MaskDDRef) : nullptr;

  ScopeDbgLoc DbgLoc(*this, HInst->getDebugLoc());

  if (LvalRef->hasGEPInfo()) {
    Instruction *ResInst;

    if (StorePtr->getType()->isVectorTy()) {
      ResInst = VPOUtils::createMaskedScatterCall(
          F->getParent(), StorePtr, StoreVal, *Builder, LvalRef->getAlignment(),
          MaskVal);
    } else if (MaskVal) {
      ResInst = VPOUtils::createMaskedStoreCall(
          StorePtr, StoreVal, *Builder, LvalRef->getAlignment(), MaskVal);
    } else {
      ResInst = Builder->CreateAlignedStore(
          StoreVal, StorePtr, LvalRef->getAlignment(), LvalRef->isVolatile());
    }

    setMetadata(ResInst, LvalRef);
  } else {
    if (MaskVal) {
      // At this point we know StorePtr is an address from an alloca that
      // is safe to load. We use a blended unmasked store here which is
      // better for performance and also needed as a work around for i1
      // maskedstore issue in codegen(CQ416258).
      // As an example consider the masked HLInst:
      // %.vec = (<4 x i32>*)(%ip)[i1]; Mask = @{%Pred42_10}
      // The generated LLVM IR looks like the following. %9 contains the
      // address of (%ip)[i1], %t22. contains the mask value %Pred42_10,
      // %t24 is the address of alloca corresponding to %.vec.
      //
      // %10 = call <4 x i32> @llvm.masked.load.v4i32.p0v4i32(
      //     <4 x i32>* %9, i32 4, <4 x i1> %t22., <4 x i32> undef), !tbaa !2
      //  %t22.18 = load <4 x i1>, <4 x i1>* %t22
      //  %mload19 = load <4 x i32>, <4 x i32>* %t24
      //  %11 = select <4 x i1> %t22.18, <4 x i32> %10, <4 x i32> %mload19
      //  store <4 x i32> %11, <4 x i32>* %t24
      auto MLoad = Builder->CreateLoad(StorePtr, "mload");
      auto MSel = Builder->CreateSelect(MaskVal, StoreVal, MLoad);
      Builder->CreateStore(MSel, StorePtr);
    } else {
      Builder->CreateStore(StoreVal, StorePtr);
    }
  }
}

Value *HIRCodeGen::CGVisitor::visitInst(HLInst *HInst) {
  ScopeDbgLoc DbgLoc(*this, HInst->getDebugLoc());

  // CG the operands
  SmallVector<Value *, 6> Ops;

  // See if we need to compute the mask value. Currently we need to mask
  // any generated loads if the HLInst has a mask DDRef.
  Value *MaskVal = nullptr;
  RegDDRef *MaskRef = HInst->getMaskDDRef();

  for (auto R = HInst->op_ddref_begin(), E = HInst->op_ddref_end(); R != E;
       ++R) {
    auto Ref = (*R);

    // We need to mask loads if we have a mask ddref - generate mask value
    // to be used for these loads.
    if (MaskRef && !MaskVal && Ref->isRval() && Ref->isMemRef()) {
      MaskVal = visitRegDDRef(MaskRef);
    }

    auto DestTy = Ref->getDestType();
    auto OpVal = visitRegDDRef(Ref, MaskVal);

    // Do a broadcast of instruction operands if needed.
    if (Ref->isRval() && DestTy->isVectorTy() &&
        !(OpVal->getType()->isVectorTy())) {
      OpVal = Builder->CreateVectorSplat(DestTy->getVectorNumElements(), OpVal);
    }

    Ops.push_back(OpVal);
  }

  // Operands for the eventual store that needs to be generated for a lval
  // HLInst.
  Value *StorePtr = !Ops.empty() ? Ops[0] : nullptr;
  Value *StoreVal = nullptr;

  // create the inst
  auto Inst = HInst->getLLVMInstruction();

  // Any LLVM instruction which semantically has a terminal lval/rval can
  // alternatively contain a memref operand in HIR.
  // For example, add instruction can look like this- A[i] = B[i] + C[i].
  if (isa<LoadInst>(Inst) || isa<StoreInst>(Inst)) {
    StoreVal = Ops[1];

  } else if (auto BOp = dyn_cast<BinaryOperator>(Inst)) {
    StoreVal = Builder->CreateBinOp(BOp->getOpcode(), Ops[1], Ops[2], "",
                                    BOp->getMetadata(LLVMContext::MD_fpmath));

    // CreateBinOp could fold operator to constant.
    BinaryOperator *StoreBinOp = dyn_cast<BinaryOperator>(StoreVal);

    if (StoreBinOp) {
      if (isa<PossiblyExactOperator>(BOp)) {
        StoreBinOp->setIsExact(BOp->isExact());
      }

      if (isa<OverflowingBinaryOperator>(BOp)) {
        StoreBinOp->setHasNoSignedWrap(BOp->hasNoSignedWrap());
        StoreBinOp->setHasNoUnsignedWrap(BOp->hasNoUnsignedWrap());
      }

      if (auto FPOp = dyn_cast<FPMathOperator>(BOp)) {
        StoreBinOp->copyFastMathFlags(FPOp->getFastMathFlags());
      }
    }

  } else if (auto Call = dyn_cast<CallInst>(Inst)) {
    if (HInst->hasLval()) {
      // Turns Operands vector into function args vector by removing lval
      // TODO: Separate this logic from framework's implementation of putting
      // lval as the first operand.
      Ops.erase(Ops.begin());
    }

    // TODO twine for call?
    CallInst *ResCall =
        Builder->CreateCall(const_cast<Value *>(Call->getCalledValue()), Ops);

    // TODO: Copy parameter attributes as well.
    ResCall->setCallingConv(Call->getCallingConv());
    ResCall->setAttributes(Call->getAttributes());
    ResCall->setTailCallKind(Call->getTailCallKind());

    // TODO: Copy metadata from HLInst instead.
    RegDDRef::MDNodesTy MDs;
    Inst->getAllMetadata(MDs);
    setMetadata(ResCall, MDs);

    StoreVal = ResCall;

  } else if (auto Cast = dyn_cast<CastInst>(Inst)) {
    assert(Ops.size() == 2 && "invalid cast");

    StoreVal = Builder->CreateCast(Cast->getOpcode(), Ops[1],
                                   Ops[0]->getType()->getPointerElementType());

  } else if (isa<SelectInst>(Inst)) {
    Value *CmpLHS = Ops[1];
    Value *CmpRHS = Ops[2];
    Value *TVal = Ops[3];
    Value *FVal = Ops[4];

    Value *Pred =
        createCmpInst(HInst->getPredicate(), CmpLHS, CmpRHS,
                      "hir.selcmp." + std::to_string(HInst->getNumber()));
    StoreVal = Builder->CreateSelect(Pred, TVal, FVal);

  } else if (isa<CmpInst>(Inst)) {

    StoreVal = createCmpInst(HInst->getPredicate(), Ops[1], Ops[2],
                             "hir.cmp." + std::to_string(HInst->getNumber()));

  } else if (isa<GetElementPtrInst>(Inst)) {
    // Gep Instructions in LLVM may have any number of operands but the HIR
    // representation for them is always a single rhs ddref
    assert(Ops.size() == 2 && "Gep Inst have single rhs of form &val");
    StoreVal = Ops[1];

  } else if (isa<AllocaInst>(Inst)) {
    // Lval type is a pointer to type returned by alloca inst. We need to
    // dereference twice to get to element type
    Type *ElementType =
        Ops[0]->getType()->getPointerElementType()->getPointerElementType();

    StoreVal = Builder->CreateAlloca(ElementType, Ops[1],
                                     "hir.alloca." +
                                         std::to_string(HInst->getNumber()));

  } else if (isa<ExtractElementInst>(Inst)) {
    StoreVal = Builder->CreateExtractElement(Ops[1], Ops[2], Inst->getName());

  } else if (isa<ShuffleVectorInst>(Inst)) {
    StoreVal =
        Builder->CreateShuffleVector(Ops[1], Ops[2], Ops[3], Inst->getName());

  } else if (isa<ReturnInst>(Inst)) {
    StoreVal =
        !Ops.empty() ? Builder->CreateRet(Ops[0]) : Builder->CreateRetVoid();
  } else {
    llvm_unreachable("Unimpl CG for inst");
  }

  generateLvalStore(HInst, StorePtr, StoreVal);

  return nullptr;
}

Value *HIRCodeGen::CGVisitor::sumBlobs(CanonExpr *CE) {
  if (!CE->hasBlob())
    return nullptr;

  auto CurBlobPair = CE->blob_begin();
  Value *Res = BlobPairCG(CE, CurBlobPair);
  CurBlobPair++;

  auto CEDestTy = CE->getDestType();
  for (auto E = CE->blob_end(); CurBlobPair != E; ++CurBlobPair) {
    Value *CurRes = BlobPairCG(CE, CurBlobPair);

    // We can have a CanonExpr with blobs where some of the blobs have
    // been replaced by vectorized values while others simply need a
    // broadcast of the loop invariant blob value. Handle these cases
    // here. Example CE: i1 + %N + %.vec + <i32 0, i32 1, i32 2, i32 3>
    // %N is a blob that needs a broadcast.
    if (CEDestTy->isVectorTy()) {
      if (Res->getType()->isVectorTy() && !CurRes->getType()->isVectorTy()) {
        CurRes = Builder->CreateVectorSplat(CEDestTy->getVectorNumElements(),
                                            CurRes);
      } else if (CurRes->getType()->isVectorTy() &&
                 !Res->getType()->isVectorTy()) {
        Res = Builder->CreateVectorSplat(CEDestTy->getVectorNumElements(), Res);
      }
    }

    Res = Builder->CreateAdd(Res, CurRes);
  }

  return Res;
}

Value *HIRCodeGen::CGVisitor::sumIV(CanonExpr *CE) {
  if (!CE->hasIV())
    return nullptr;

  auto CurIVPair = CE->iv_begin();
  // start with first summation not of x*0
  for (auto E = CE->iv_end(); CurIVPair != E; ++CurIVPair) {
    if (CE->getIVConstCoeff(CurIVPair))
      break;
  }

  if (CurIVPair == CE->iv_end()) {
    llvm_unreachable("No iv in CE");
  }

  Type *Ty = CE->getSrcType();
  if (Ty->isVectorTy()) {
    Ty = Ty->getVectorElementType();
  }

  Value *res = IVPairCG(CE, CurIVPair, Ty);
  CurIVPair++;

  // accumulate other pairs
  for (auto E = CE->iv_end(); CurIVPair != E; ++CurIVPair) {
    if (CE->getIVConstCoeff(CurIVPair))
      res = Builder->CreateAdd(res, IVPairCG(CE, CurIVPair, Ty));
  }

  return res;
}

Value *HIRCodeGen::CGVisitor::IVPairCG(CanonExpr *CE,
                                       CanonExpr::iv_iterator IVIt, Type *Ty) {

  // Load IV at given level from this loop nest
  Value *IV = Builder->CreateLoad(CurIVValues[CE->getLevel(IVIt)]);

  // IV type and Ty(CE src type) may not match, zext or trunc as needed
  if (IV->getType() != Ty) {
    if (Ty->getPrimitiveSizeInBits() >
        IV->getType()->getPrimitiveSizeInBits()) {
      IV = Builder->CreateZExt(IV, Ty);
    } else {
      IV = Builder->CreateTrunc(IV, Ty);
    }
  }

  // pairs are of form <Index, Coeff>.
  if (CE->getIVBlobCoeff(IVIt)) {
    return Builder->CreateMul(IVCoefCG(CE, IVIt), IV);
  } else {
    return CoefCG(CE->getIVConstCoeff(IVIt), IV);
  }
}
Value *HIRCodeGen::CGVisitor::CoefCG(int64_t Coeff, Value *V) {

  // do not emit 1*iv, just emit IV
  if (Coeff == 1)
    return V;
  if (Coeff == 0)
    llvm_unreachable("Dead mul in CoefCG");

  return Builder->CreateMul(
      ConstantInt::getSigned(const_cast<Type *>(V->getType()), Coeff), V);
}

void HIRCodeGen::eraseDummyInstructions() {

  auto FirstInst = HIRF->getHLNodeUtils().getFirstDummyInst();
  auto LastInst = HIRF->getHLNodeUtils().getLastDummyInst();

  if (!FirstInst) {
    return;
  }

  for (auto I = BasicBlock::iterator(FirstInst),
            E = std::next(BasicBlock::iterator(LastInst));
       I != E;) {
    I = I->eraseFromParent();
  }
}
