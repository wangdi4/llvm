#!/usr/bin/env python2.7

"""A script to generate FileCheck statements for VPlan regression tests using
'opt' tool. The dumps of VPlan are slightly different than standard LLVM IR,
hence a separate tool.

This script is an utility to update VPlan opt test cases with new FileCheck
patterns.

Example usage:
$ intel_update_vplan_checks.py --opt=../bin/opt test/foo.ll

Workflow:
1. Make a compiler patch that requires updating some number of FileCheck lines
   in regression test files.
2. Save the patch and revert it from your local work area.
3. Update the RUN-lines in the affected regression tests to look canonical.
   Example:
     "; RUN: opt < %s -VPlanDriver -vplan-cost-model-print-analyses -disable-output | FileCheck %s"
4. Refresh the FileCheck lines for the file running this script.
5. Commit the fresh baseline of checks.
6. Apply your patch from step 1 and rebuild your local binaries.
7. Re-run this script on affected regression tests.
8. Check the diffs to ensure the script has done something reasonable.
9. Submit a patch including the regression test diffs for review.

A common pattern is to have the script insert complete checking of every
VPInstruction. Then, edit it down to only check the relevant instructions.
The script is designed to make adding checks to a test case fast, it is *not*
designed to be authoratitive about what constitutes a good test!
"""

# TODO: Rewrite using common utils as in https://reviews.llvm.org/D42805.

import argparse
import itertools
import os         # Used to advertise this file's name ("autogenerated_note").
import string
import subprocess
import sys
import tempfile
import re

ADVERT = '; NOTE: Assertions have been autogenerated by '

SCRUB_LEADING_WHITESPACE_RE = re.compile(r'^(\s+)')
SCRUB_WHITESPACE_RE = re.compile(r'(?!^(|  \w))[ \t]+', flags=re.M)
SCRUB_TRAILING_WHITESPACE_RE = re.compile(r'[ \t]+$', flags=re.M)
SCRUB_KILL_COMMENT_RE = re.compile(r'^ *#+ +kill:.*\n')
SCRUB_IR_COMMENT_RE = re.compile(r'\s*;.*')

RUN_LINE_RE = re.compile('^\s*;\s*RUN:\s*(.*)$')
IR_FUNCTION_RE = re.compile('^\s*define\s+(?:internal\s+)?[^@]*@([\w-]+)\s*\(')
OPT_FUNCTION_RE = re.compile(
    r'^\s*define\s+(?:internal\s+)?[^@]*@(?P<func>[\w-]+?)\s*\('
    r'(\s+)?[^)]*[^{]*\{\n(?P<body>.*?)^\}$',
    flags=(re.M | re.S))
CHECK_PREFIX_RE = re.compile('--?check-prefix(?:es)?=(\S+)')
CHECK_RE = re.compile(r'^\s*;\s*([^:]+?)(?:-NEXT|-NOT|-DAG|-LABEL|-EMPTY)?:')
CHECK_LABEL_RE = re.compile(r'Cost Model')
# Match things that look at identifiers, but only if they are followed by
# spaces, commas, paren, or end of the string
IR_VALUE_RE = re.compile(r'(\s+|[\(\!])%([\w\.]+?)([,\s\(\)]|\Z)')
VP_VALUE_RE = re.compile(r'vp[0-9]+')
VP_NAMED_VALUE_RE = re.compile(r'vp\.[\w\.]+\.[0-9]+')
VPBB_RE = re.compile(r'\b(BB[0-9]+|blend\.bb[0-9]+|intermediate\.bb[0-9]+|new.loop.latch[0-9]+|cascaded.if.block[0-9]+)')
REGION_RE = re.compile(r'(region[0-9]+)')
VPLOOP_RE = re.compile(r'(loop[0-9]+)')
PREDICATOR_IF_STMT_RE = re.compile(r'(If[FT][0-9]+)')
PREDICATOR_BLOCK_PREDICATE_RE = re.compile(r'(BP[0-9]+)')
ANALYSIS_PRINTING_RE = re.compile(r'Pass::print not implemented|Printing analysis')

def scrub_body(body):
  # Expand the tabs used for indentation.
  body = string.expandtabs(body, 2)
  # Strip trailing whitespace.
  body = SCRUB_TRAILING_WHITESPACE_RE.sub(r'', body)
  return body

def get_vplan_output(args, cmd_args, ir, func):
  with open(ir) as ir_file:
    # TODO: move llvm-extract to args
    # "-S" for llvm-extract is to supress expansion of "fast" FMF flag into its
    # parts.
    # We do need that llvm-extract because VPlan dumps don't necessarily contain
    # enough information to determine when another function starts being
    # processed.
    #
    # Unfortunately, we lose initializers for globals when doing such extraction :(
    stdout = subprocess.check_output('{} -S --func {} | {} {}'.format(
      'llvm-extract', func, args.opt_binary, cmd_args), shell=True, stdin=ir_file)
  # Fix line endings to unix CR style.
  stdout = stdout.replace('\r\n', '\n')
  return scrub_body(stdout)

# Create a FileCheck variable from regex.
def get_value_definition(name):
  return '[[' + name + ':%.*]]'


# Use a FileCheck variable.
def get_value_use(name):
  return '[[' + name + ']]'

# Replace IR value defs and uses with FileCheck variables.
def genericize_check_lines(lines):
  # "Static" variable accessible from the "get_value_name" closure
  genericize_check_lines = {}

  def get_predicator_if_stmt_name_prefix(var):
    # var either starts with IfT or with IfF, return that prefix.
    return var[0:3]

  # Create a FileCheck variable name based on an IR name.
  def get_value_name(var):
    orig_var = var
    if var.isdigit():
      var = 'TMP' + var

    if VP_NAMED_VALUE_RE.match(var):
      var = 'VP' + re.sub('\.[0-9]+$', '', var[2:])
    if VP_VALUE_RE.match(var):
      var = 'VP'
    if VPBB_RE.match(var):
      var = var.rstrip('0123456789')
    if REGION_RE.match(var):
      var = 'REGION'
    if VPLOOP_RE.match(var):
      var = 'LOOP'

    if PREDICATOR_IF_STMT_RE.match(var):
      var = get_predicator_if_stmt_name_prefix(var)
    if PREDICATOR_BLOCK_PREDICATE_RE.match(var):
      var = 'BP'

    # var_before_genericizing = var
    if not orig_var.isdigit():
      num = genericize_check_lines.get(var, 0)
      genericize_check_lines[var] = num + 1
      if VP_NAMED_VALUE_RE.match(orig_var):
        if num != 0:
          var = var + "." + str(num)
      else:
        var = var + str(num)

      # print "Var: {}, before_genericize: {}, num: {}, new name: {}".format(orig_var, var_before_genericizing, num, var)


    var = var.replace('.', '_')
    return var.upper()

  # This gets called for each match that occurs in
  # a line. We transform variables we haven't seen
  # into defs, and variables we have seen into uses.
  def transform_line_vars(match):
    # print '  {}'.format(match.group(2))
    var = match.group(2)
    if var in vars_seen.keys():
      rv = get_value_use(vars_seen[var])
    else:
      name = get_value_name(var)
      vars_seen[var] = name
      rv = get_value_definition(name)
    # re.sub replaces the entire regex match
    # with whatever you return, so we have
    # to make sure to hand it back everything
    # including the commas and spaces.
    return match.group(1) + rv + match.group(3)

  def transform_cfg_vars(match, prefix):
    var = match.group(0)
    if var in vars_seen.keys():
      rv = get_value_use(vars_seen[var])
    else:
      name = get_value_name(var)
      vars_seen[var] = name
      rv = '[[' + name + ':{}[0-9]+]]'.format(prefix)
    return rv

  def transform_vpbb(match):
    name_without_number =match.group(0).rstrip('0123456789')
    return transform_cfg_vars(match, name_without_number)

  def transform_region(match):
    return transform_cfg_vars(match, 'region')

  def transform_vploop(match):
    return transform_cfg_vars(match, 'loop')

  def transform_predicator_if_stmt(match):
    prefix = get_predicator_if_stmt_name_prefix(match.group(0))
    return transform_cfg_vars(match, prefix)

  def transform_predicator_block_predicate(match):
    return transform_cfg_vars(match, 'BP')


  vars_seen = dict() # variable -> match_name mapping

  # The cost-modeling tests runs some optimizations before running
  # "-cost-model -analyze". Get rid of unnecessary output from non-analysis passes.
  while ANALYSIS_PRINTING_RE.match(lines[1]):
    lines = lines[1:]

  for i, line in enumerate(lines):
    # An IR variable named '%.' matches the FileCheck regex string.
    line = line.replace('%.', '%dot')
    # Ignore any comments, since the check lines will too.
    scrubbed_line = SCRUB_IR_COMMENT_RE.sub(r'', line)
    # print 'Line: <{}>, matches:\n'.format(scrubbed_line)
    tmp =  IR_VALUE_RE.sub(transform_line_vars, scrubbed_line)
    # FIXME: why isn't it enough to perform substitution once?
    tmp =  IR_VALUE_RE.sub(transform_line_vars, tmp)
    tmp = VPBB_RE.sub(transform_vpbb, tmp)
    tmp = REGION_RE.sub(transform_region, tmp)
    tmp = VPLOOP_RE.sub(transform_vploop, tmp)
    tmp = PREDICATOR_IF_STMT_RE.sub(transform_predicator_if_stmt, tmp)
    tmp = PREDICATOR_BLOCK_PREDICATE_RE.sub(transform_predicator_block_predicate, tmp)
    lines[i] = tmp
  return lines

def add_checks(output_lines, prefix_list, func_dict, func_name, opt_basename):
  printed_prefixes = []
  for checkprefixes, _ in prefix_list:
    for checkprefix in checkprefixes:
      if checkprefix in printed_prefixes:
        break
      if not func_dict[checkprefix][func_name]:
        continue
      printed_prefixes.append(checkprefix)
      cost_model_output = func_dict[checkprefix][func_name].splitlines()
      cost_model_output = genericize_check_lines(cost_model_output)
      output_lines.append('; %s-LABEL:  %s' % (checkprefix, cost_model_output[0]))
      is_blank_line = False
      for cost_line in cost_model_output[1:]:
        if cost_line.strip() == '':
          is_blank_line = True
          continue
        if is_blank_line:
          output_lines.append('; %s-EMPTY:' % (checkprefix))
        output_lines.append('; %s-NEXT:  %s' % (checkprefix, cost_line))
        is_blank_line = False

    # Add space between different check prefixes and also before the first
    # line of code in the test function.
    output_lines.append(';')
  return output_lines

def should_add_line_to_output(input_line, prefix_set):
  # Skip any blank comment lines in the IR.
  if input_line.strip() == ';':
    return False
  # Skip any blank lines in the IR.
  #if input_line.strip() == '':
  #  return False
  # And skip any CHECK lines. We're building our own.
  m = CHECK_RE.match(input_line)
  if m and m.group(1) in prefix_set:
    return False

  return True


def main():
  from argparse import RawTextHelpFormatter
  parser = argparse.ArgumentParser(description=__doc__, formatter_class=RawTextHelpFormatter)
  parser.add_argument('-v', '--verbose', action='store_true',
                      help='Show verbose output')
  parser.add_argument('--opt-binary', default='opt',
                      help='The opt binary used to generate the test case')
  parser.add_argument(
      '--function', help='The function in the test file to update')
  parser.add_argument('tests', nargs='+')
  args = parser.parse_args()

  autogenerated_note = (ADVERT + 'utils/' + os.path.basename(__file__))

  opt_basename = os.path.basename(args.opt_binary)
  if (opt_basename != "opt"):
    print >>sys.stderr, 'ERROR: Unexpected opt name: ' + opt_basename
    sys.exit(1)

  for test in args.tests:
    if args.verbose:
      print >>sys.stderr, 'Scanning for RUN lines in test file: %s' % (test,)
    with open(test) as f:
      input_lines = [l.rstrip() for l in f]

    raw_lines = [m.group(1)
                 for m in [RUN_LINE_RE.match(l) for l in input_lines] if m]
    run_lines = [raw_lines[0]] if len(raw_lines) > 0 else []
    for l in raw_lines[1:]:
      if run_lines[-1].endswith("\\"):
        run_lines[-1] = run_lines[-1].rstrip("\\") + " " + l
      else:
        run_lines.append(l)

    if args.verbose:
      print >>sys.stderr, 'Found %d RUN lines:' % (len(run_lines),)
      for l in run_lines:
        print >>sys.stderr, '  RUN: ' + l

    prefix_list = []
    for l in run_lines:
      (tool_cmd, filecheck_cmd) = tuple([cmd.strip() for cmd in l.split('|', 1)])

      if not tool_cmd.startswith(opt_basename + ' '):
        print >>sys.stderr, 'WARNING: Skipping non-%s RUN line: %s' % (opt_basename, l)
        continue

      if not filecheck_cmd.startswith('FileCheck '):
        print >>sys.stderr, 'WARNING: Skipping non-FileChecked RUN line: ' + l
        continue

      tool_cmd_args = tool_cmd[len(opt_basename):].strip()
      tool_cmd_args = tool_cmd_args.replace('< %s', '').replace('%s', '').strip()

      check_prefixes = [item for m in CHECK_PREFIX_RE.finditer(filecheck_cmd)
                               for item in m.group(1).split(',')]
      if not check_prefixes:
        check_prefixes = ['CHECK']

      # FIXME: We should use multiple check prefixes to common check lines. For
      # now, we just ignore all but the last.
      prefix_list.append((check_prefixes, tool_cmd_args))

    func_dict = {}
    for prefixes, _ in prefix_list:
      for prefix in prefixes:
        func_dict.update({prefix: dict()})

    funcs = set()
    for input_line in input_lines:
      m = IR_FUNCTION_RE.match(input_line)
      if m:
        funcs.add(m.group(1))

    for prefixes, opt_args in prefix_list:
      opt_args += " --vplan-enable-names"
      if args.verbose:
        print >>sys.stderr, 'Extracted opt cmd: ' + opt_basename + ' ' + opt_args
        print >>sys.stderr, 'Extracted FileCheck prefixes: ' + str(prefixes)

      for func in funcs:
        raw_analysis_output = get_vplan_output(args, opt_args, test, func)
        func_dict[prefixes[0]][func] = raw_analysis_output

    is_in_function = False
    is_in_function_start = False
    prefix_set = set([prefix for prefixes, _ in prefix_list for prefix in prefixes])
    if args.verbose:
      print >>sys.stderr, 'Rewriting FileCheck prefixes: %s' % (prefix_set,)
    output_lines = []
    output_lines.append(autogenerated_note)

    for input_line in input_lines:
      if is_in_function_start:
        if input_line == '':
          continue
        if input_line.lstrip().startswith(';'):
          m = CHECK_RE.match(input_line)
          if not m or m.group(1) not in prefix_set:
            output_lines.append(input_line)
            continue

        # Print out the various check lines here.
        output_lines = add_checks(output_lines, prefix_list, func_dict, name, opt_basename)
        is_in_function_start = False

      if is_in_function:
        if should_add_line_to_output(input_line, prefix_set) == True:
          # This input line of the function body will go as-is into the output.
          # Except make leading whitespace uniform: 2 spaces.
          input_line = SCRUB_LEADING_WHITESPACE_RE.sub(r'  ', input_line)
          output_lines.append(input_line)
        else:
          continue
        if input_line.strip() == '}':
          is_in_function = False
        continue

      # Discard any previous script advertising.
      if input_line.startswith(ADVERT):
        continue

      # If it's outside a function, it just gets copied to the output.
      output_lines.append(input_line)

      m = IR_FUNCTION_RE.match(input_line)
      if not m:
        continue
      name = m.group(1)
      if args.function is not None and name != args.function:
        # When filtering on a specific function, skip all others.
        continue
      is_in_function = is_in_function_start = True

    if args.verbose:
      print>>sys.stderr, 'Writing %d lines to %s...' % (len(output_lines), test)

    with open(test, 'wb') as f:
      f.writelines([l + '\n' for l in output_lines])


if __name__ == '__main__':
  main()
