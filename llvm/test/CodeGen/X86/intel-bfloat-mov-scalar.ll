; INTEL_FEATURE_ISA_BF16_BASE
; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_bf16_base
; TODO: Complement SSE2 tests when vector emulation bfloat on SSE2 is supported.
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+sse2 | FileCheck %s --check-prefix=SSE2-X64
; RUN: llc < %s -mtriple=i686-unknown-unknown -mattr=+sse2 | FileCheck %s --check-prefix=SSE2-X86
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16,+avx512vl | FileCheck %s --check-prefix=AVX512FP16-X64
; RUN: llc < %s -mtriple=i686-unknown-unknown -mattr=+avx512fp16,+avx512vl | FileCheck %s --check-prefix=AVX512FP16-X86

define i16 @test1(bfloat %x) {
; SSE2-X64-LABEL: test1:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-X64-NEXT:    # kill: def $ax killed $ax killed $eax
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: test1:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: test1:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovw %xmm0, %eax
; AVX512FP16-X64-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test1:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movzwl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    retl
   %res = bitcast bfloat %x to i16
   ret i16 %res
}

define void @test5(bfloat %x, bfloat* %y) {
; SSE2-X64-LABEL: test5:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    pextrw $0, %xmm0, %eax
; SSE2-X64-NEXT:    movw %ax, (%rdi)
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: test5:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    pinsrw $0, {{[0-9]+}}(%esp), %xmm0
; SSE2-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; SSE2-X86-NEXT:    pextrw $0, %xmm0, %ecx
; SSE2-X86-NEXT:    movw %cx, (%eax)
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: test5:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test5:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   store bfloat %x, bfloat* %y, align 2
   ret void
}

define bfloat @test7(i16* %x) {
; SSE2-X64-LABEL: test7:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    pinsrw $0, (%rdi), %xmm0
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: test7:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; SSE2-X86-NEXT:    pinsrw $0, (%eax), %xmm0
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: test7:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test7:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %y = load i16, i16* %x
   %res = bitcast i16 %y to bfloat
   ret bfloat %res
}

define bfloat @test_movw2(i16 %x) {
; SSE2-X64-LABEL: test_movw2:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    pinsrw $0, %edi, %xmm0
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: test_movw2:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    pinsrw $0, {{[0-9]+}}(%esp), %xmm0
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: test_movw2:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovw %edi, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test_movw2:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %res = bitcast i16 %x to bfloat
  ret bfloat %res
}

; sext avoids having a truncate in front of the bitcast input due to calling
; convention or i16 op promotion.
define bfloat @test_movw3(i8 %x) {
; SSE2-X64-LABEL: test_movw3:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    movsbl %dil, %eax
; SSE2-X64-NEXT:    pinsrw $0, %eax, %xmm0
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: test_movw3:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    movsbl {{[0-9]+}}(%esp), %eax
; SSE2-X86-NEXT:    pinsrw $0, %eax, %xmm0
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: test_movw3:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movsbl %dil, %eax
; AVX512FP16-X64-NEXT:    vmovw %eax, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test_movw3:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movsbl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovw %eax, %xmm0
; AVX512FP16-X86-NEXT:    retl
  %z = sext i8 %x to i16
  %a = bitcast i16 %z to bfloat
  ret bfloat %a
}

define bfloat @load_bfloat(bfloat* %fptr) {
; SSE2-X64-LABEL: load_bfloat:
; SSE2-X64:       # %bb.0:
; SSE2-X64-NEXT:    pinsrw $0, (%rdi), %xmm0
; SSE2-X64-NEXT:    retq
;
; SSE2-X86-LABEL: load_bfloat:
; SSE2-X86:       # %bb.0:
; SSE2-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; SSE2-X86-NEXT:    pinsrw $0, (%eax), %xmm0
; SSE2-X86-NEXT:    retl
;
; AVX512FP16-X64-LABEL: load_bfloat:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load_bfloat:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %v = load bfloat, bfloat* %fptr, align 2
  ret bfloat %v
}
; end INTEL_FEATURE_ISA_BF16_BASE
