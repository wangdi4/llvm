; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=i686-linux  -enable-intel-advanced-opts=true -O3 -mattr=+avx512f,+avx512vl,+avx512dq | FileCheck %s --check-prefix=X86-AVX512-VL-DQ
; RUN: llc < %s -mtriple=i686-linux  -enable-intel-advanced-opts=true -O3 -mattr=+avx,+avx2 | FileCheck %s --check-prefix=X86-AVX2

%struct.2 = type {[2 x float], %struct.2*, %struct.2* }
%struct.6 = type {[6 x float], %struct.6*, %struct.6* }
%struct.8 = type {[8 x float], %struct.8*, %struct.8* }
%struct.17 = type {[17 x float], %struct.17*, %struct.17* }
%struct.4294967304 = type {[4294967304 x float], %struct.4294967304*, %struct.4294967304* }

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array2x_Gather6x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather6x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovq {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermd %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather6x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array2x_Gather2x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather2x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather2x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 true, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array2x_Gather8x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather8x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather8x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array2x_Gather17x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather17x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    kxnorw %k0, %k0, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array2x_Gather17x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovdqu (%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm0, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, 16(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, (%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array6x_Gather6x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather6x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovups (%eax), %ymm1 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermd %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather6x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovups (%eax), %xmm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm1, %ymm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array6x_Gather2x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather2x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather2x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 true, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array6x_Gather8x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather8x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    movb $63, %cl
; X86-AVX512-VL-DQ-NEXT:    kmovb %ecx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovups (%eax), %ymm1 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather8x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vmovups (%eax), %xmm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm1, %ymm1
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array6x_Gather17x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather17x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    kxnorw %k0, %k0, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array6x_Gather17x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovdqu (%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm0, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, 16(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, (%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}


; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array8x_Gather6x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather6x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermd (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather6x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array8x_Gather2x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather2x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather2x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 true, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array8x_Gather8x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather8x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather8x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array8x_Gather17x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather17x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    kxnorw %k0, %k0, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array8x_Gather17x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovdqu (%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm0, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, 16(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, (%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array2x_Gather6x(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather6x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovq {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermd %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather6x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array2x_Gather2x(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather2x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather2x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 false, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array2x_Gather8x(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather8x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array2x_Gather8x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array2x_Gather17x(i32* nocapture readonly %index_ptr, %struct.2* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array2x_Gather17x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    movw $-2, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array2x_Gather17x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vextractps $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vbroadcastss (%eax,%ecx,4), %xmm5
; X86-AVX2-NEXT:    vextractps $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vextractps $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, (%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, 16(%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.2, %struct.2* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array6x_Gather6x(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather6x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovups (%eax), %ymm1 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermd %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather6x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovups (%eax), %xmm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm1, %ymm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array6x_Gather2x(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather2x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather2x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vpermps %ymm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 false, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array6x_Gather8x(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather8x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    movb $63, %cl
; X86-AVX512-VL-DQ-NEXT:    kmovb %ecx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovups (%eax), %ymm1 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array6x_Gather8x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vmovups (%eax), %xmm1
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm2, %ymm1, %ymm1
; X86-AVX2-NEXT:    vpermps %ymm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array6x_Gather17x(i32* nocapture readonly %index_ptr, %struct.6* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array6x_Gather17x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    movw $-2, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array6x_Gather17x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vextractps $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vbroadcastss (%eax,%ecx,4), %xmm5
; X86-AVX2-NEXT:    vextractps $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vextractps $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, (%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, 16(%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.6, %struct.6* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array8x_Gather6x(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather6x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm0 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vpermd (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather6x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <2 x float> @Array8x_Gather2x(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather2x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX512-VL-DQ-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather2x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    # kill: def $xmm0 killed $xmm0 killed $ymm0
; X86-AVX2-NEXT:    vzeroupper
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <2 x i32>*
  %index = load <2 x i32>, <2 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <2 x i32> %index
  %res = call <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*> %gep, i32 4, <2 x i1> <i1 false, i1 true>, <2 x float> undef)
  ret <2 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <8 x float> @Array8x_Gather8x(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather8x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-VL-DQ-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather8x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX2-NEXT:    vpermps (%eax), %ymm0, %ymm0
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <8 x i32>*
  %index = load <8 x i32>, <8 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <8 x i32> %index
  %res = call <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*> %gep, i32 4, <8 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x float> undef)
  ret <8 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <17 x float> @Array8x_Gather17x(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather17x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %edx
; X86-AVX512-VL-DQ-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX512-VL-DQ-NEXT:    vmovups (%edx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm2, %xmm2, %xmm2
; X86-AVX512-VL-DQ-NEXT:    movw $-2, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm3, %xmm3, %xmm3
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm1,4), %zmm3 {%k1}
; X86-AVX512-VL-DQ-NEXT:    movw $1, %dx
; X86-AVX512-VL-DQ-NEXT:    kmovw %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%ecx,%zmm0,4), %zmm2 {%k1}
; X86-AVX512-VL-DQ-NEXT:    vmovaps %zmm3, (%eax)
; X86-AVX512-VL-DQ-NEXT:    vmovss %xmm2, 64(%eax)
; X86-AVX512-VL-DQ-NEXT:    vzeroupper
; X86-AVX512-VL-DQ-NEXT:    retl $4
;
; X86-AVX2-LABEL: Array8x_Gather17x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %xmm0
; X86-AVX2-NEXT:    vmovdqu 16(%ecx), %xmm1
; X86-AVX2-NEXT:    vmovdqu 32(%ecx), %xmm2
; X86-AVX2-NEXT:    vmovdqu 48(%ecx), %xmm3
; X86-AVX2-NEXT:    movl 64(%ecx), %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm4 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vmovd %xmm1, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm1, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm2, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm2, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm2 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vmovd %xmm3, %ecx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm5 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpextrd $1, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0],mem[0],xmm5[2,3]
; X86-AVX2-NEXT:    vpextrd $2, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vpextrd $3, %xmm3, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm3 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    vextractps $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vbroadcastss (%eax,%ecx,4), %xmm5
; X86-AVX2-NEXT:    vextractps $2, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm5 = xmm5[0,1],mem[0],xmm5[3]
; X86-AVX2-NEXT:    vextractps $3, %xmm0, %ecx
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm5[0,1,2],mem[0]
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovss %xmm4, 64(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm0, (%eax)
; X86-AVX2-NEXT:    vmovaps %xmm3, 48(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm2, 32(%eax)
; X86-AVX2-NEXT:    vmovaps %xmm1, 16(%eax)
; X86-AVX2-NEXT:    retl $4
entry:
  %bc = bitcast i32* %index_ptr to <17 x i32>*
  %index = load <17 x i32>, <17 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <17 x i32> %index
  %res = call <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*> %gep, i32 4, <17 x i1> <i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <17 x float> undef)
  ret <17 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <16 x float> @Array8x_Gather16x(i32* nocapture readonly %index_ptr, %struct.8* nocapture readonly %node) #0 {
; X86-AVX512-VL-DQ-LABEL: Array8x_Gather16x:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    vmovups (%ecx), %zmm1
; X86-AVX512-VL-DQ-NEXT:    kxnorw %k0, %k0, %k1
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%eax,%zmm1,4), %zmm0 {%k1}
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array8x_Gather16x:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX2-NEXT:    vmovups (%ecx), %zmm1
; X86-AVX2-NEXT:    kxnorw %k0, %k0, %k1
; X86-AVX2-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; X86-AVX2-NEXT:    vgatherdps (%eax,%zmm1,4), %zmm0 {%k1}
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <16 x i32>*
  %index = load <16 x i32>, <16 x i32>* %bc, align 4
  %gep = getelementptr inbounds %struct.8, %struct.8* %node, i64 0, i32 0, <16 x i32> %index
  %res = call <16 x float> @llvm.masked.gather.v16f32.v16p0f32(<16 x float*> %gep, i32 4, <16 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <16 x float> undef)
  ret <16 x float> %res
}

; Function Attrs: norecurse nounwind readonly uwtable
define dso_local <6 x float> @Array4294967304x_Gather6x_AllOneMask(i32* nocapture readonly %index_ptr, %struct.4294967304* nocapture readonly %node) {
; X86-AVX512-VL-DQ-LABEL: Array4294967304x_Gather6x_AllOneMask:
; X86-AVX512-VL-DQ:       # %bb.0: # %entry
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-VL-DQ-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-VL-DQ-NEXT:    movb $63, %dl
; X86-AVX512-VL-DQ-NEXT:    kmovb %edx, %k1
; X86-AVX512-VL-DQ-NEXT:    vmovdqu32 (%ecx), %ymm1 {%k1} {z}
; X86-AVX512-VL-DQ-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; X86-AVX512-VL-DQ-NEXT:    vgatherdps (%eax,%ymm1,4), %ymm0 {%k1}
; X86-AVX512-VL-DQ-NEXT:    retl
;
; X86-AVX2-LABEL: Array4294967304x_Gather6x_AllOneMask:
; X86-AVX2:       # %bb.0: # %entry
; X86-AVX2-NEXT:    pushl %ebx
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 8
; X86-AVX2-NEXT:    pushl %edi
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 12
; X86-AVX2-NEXT:    pushl %esi
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 16
; X86-AVX2-NEXT:    .cfi_offset %esi, -16
; X86-AVX2-NEXT:    .cfi_offset %edi, -12
; X86-AVX2-NEXT:    .cfi_offset %ebx, -8
; X86-AVX2-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX2-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vpinsrd $1, 20(%eax), %xmm0, %xmm0
; X86-AVX2-NEXT:    vmovdqu (%eax), %xmm1
; X86-AVX2-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    vpslld $2, %ymm0, %ymm0
; X86-AVX2-NEXT:    vpbroadcastd {{[0-9]+}}(%esp), %ymm1
; X86-AVX2-NEXT:    vpaddd %ymm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    vmovd %xmm0, %eax
; X86-AVX2-NEXT:    vpextrd $1, %xmm0, %ecx
; X86-AVX2-NEXT:    vpextrd $2, %xmm0, %edx
; X86-AVX2-NEXT:    vpextrd $3, %xmm0, %esi
; X86-AVX2-NEXT:    vextracti128 $1, %ymm0, %xmm0
; X86-AVX2-NEXT:    vmovd %xmm0, %edi
; X86-AVX2-NEXT:    vpextrd $1, %xmm0, %ebx
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; X86-AVX2-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; X86-AVX2-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; X86-AVX2-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; X86-AVX2-NEXT:    popl %esi
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 12
; X86-AVX2-NEXT:    popl %edi
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 8
; X86-AVX2-NEXT:    popl %ebx
; X86-AVX2-NEXT:    .cfi_def_cfa_offset 4
; X86-AVX2-NEXT:    retl
entry:
  %bc = bitcast i32* %index_ptr to <6 x i32>*
  %index = load <6 x i32>, <6 x i32>* %bc, align 4
  %index_i64 = sext <6 x i32> %index to <6 x i64>
  %gep = getelementptr inbounds %struct.4294967304, %struct.4294967304* %node, i64 0, i32 0, <6 x i64> %index_i64
  %res = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> %gep, i32 4, <6 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
  ret <6 x float> %res
}

; Function Attrs: nounwind readonly willreturn
declare <2 x float> @llvm.masked.gather.v2f32.v2p0f32(<2 x float*>, i32 immarg, <2 x i1>, <2 x float>) #1

; Function Attrs: nounwind readonly willreturn
declare <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*>, i32 immarg, <6 x i1>, <6 x float>) #1

; Function Attrs: nounwind readonly willreturn
declare <8 x float> @llvm.masked.gather.v8f32.v8p0f32(<8 x float*>, i32 immarg, <8 x i1>, <8 x float>) #1

; Function Attrs: nounwind readonly willreturn
declare <16 x float> @llvm.masked.gather.v16f32.v16p0f32(<16 x float*>, i32 immarg, <16 x i1>, <16 x float>) #1

; Function Attrs: nounwind readonly willreturn
declare <17 x float> @llvm.masked.gather.v17f32.v17p0f32(<17 x float*>, i32 immarg, <17 x i1>, <17 x float>) #1

attributes #0 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "denormal-fp-math"="preserve-sign,preserve-sign" "denormal-fp-math-f32"="ieee,ieee" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "may-have-openmp-directive"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-jump-tables"="false" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "prefer-vector-width"="512" "stack-protector-buffer-size"="8" "target-cpu"="skylake-avx512" "target-features"="+adx,+aes,+avx,+avx2,+avx512bw,+avx512cd,+avx512dq,+avx512f,+avx512vl,+bmi,+bmi2,+clflushopt,+clwb,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+pku,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "unsafe-fp-math"="true" "use-soft-float"="false" }

attributes #1 = { nounwind readonly willreturn }
