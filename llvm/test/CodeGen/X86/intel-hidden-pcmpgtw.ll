; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -enable-intel-advanced-opts -mattr=avx2 | FileCheck %s --check-prefixes=CHECK,AVX2
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -enable-intel-advanced-opts -mattr=avx512f | FileCheck %s --check-prefixes=CHECK,KNL
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -enable-intel-advanced-opts -mattr=avx512bw,avx512vl | FileCheck %s --check-prefixes=CHECK,SKX
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=avx2 | FileCheck %s --check-prefixes=NOOPT

; This sequence is equivalent to x<0 on 16-bit elements which can be
; handled by an xor+pcmpgtw. We have a special pattern to handle it since
; hidden in 32-bit elements.
define <8 x i32> @hidden_cmpw_v8i32(<8 x i32> %x) {
; CHECK-LABEL: hidden_cmpw_v8i32:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpxor %xmm1, %xmm1, %xmm1
; CHECK-NEXT:    vpcmpgtw %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
;
; NOOPT-LABEL: hidden_cmpw_v8i32:
; NOOPT:       # %bb.0:
; NOOPT-NEXT:    vpsrld $15, %ymm0, %ymm0
; NOOPT-NEXT:    vpbroadcastd {{.*#+}} ymm1 = [65537,65537,65537,65537,65537,65537,65537,65537]
; NOOPT-NEXT:    vpand %ymm1, %ymm0, %ymm0
; NOOPT-NEXT:    vpslld $16, %ymm0, %ymm1
; NOOPT-NEXT:    vpsubd %ymm0, %ymm1, %ymm0
; NOOPT-NEXT:    retq
  %a = lshr <8 x i32> %x, <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %b = and <8 x i32> %a, <i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537>
  %c = mul <8 x i32> %b, <i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535>
  ret <8 x i32> %c
}

; This sequence is equivalent to x<0 on 16-bit elements which can be
; handled by an xor+pcmpgtw. We have a special pattern to handle it since
; hidden in 32-bit elements.
; FIXME: AVX2 doesn't generate the expected sequence because ISD::MUL isn't
; legal for v16i32 and a different transform kicks in.
define <16 x i32> @hidden_cmpw_v16i32(<16 x i32> %x) {
; AVX2-LABEL: hidden_cmpw_v16i32:
; AVX2:       # %bb.0:
; AVX2-NEXT:    vpxor %xmm2, %xmm2, %xmm2
; AVX2-NEXT:    vpcmpgtw %ymm0, %ymm2, %ymm0
; AVX2-NEXT:    vpcmpgtw %ymm1, %ymm2, %ymm1
; AVX2-NEXT:    retq
;
; KNL-LABEL: hidden_cmpw_v16i32:
; KNL:       # %bb.0:
; KNL-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; KNL-NEXT:    vpxor %xmm2, %xmm2, %xmm2
; KNL-NEXT:    vpcmpgtw %ymm1, %ymm2, %ymm1
; KNL-NEXT:    vpcmpgtw %ymm0, %ymm2, %ymm0
; KNL-NEXT:    vinserti64x4 $1, %ymm1, %zmm0, %zmm0
; KNL-NEXT:    retq
;
; SKX-LABEL: hidden_cmpw_v16i32:
; SKX:       # %bb.0:
; SKX-NEXT:    vpmovw2m %zmm0, %k0
; SKX-NEXT:    vpmovm2w %k0, %zmm0
; SKX-NEXT:    retq
;
; NOOPT-LABEL: hidden_cmpw_v16i32:
; NOOPT:       # %bb.0:
; NOOPT-NEXT:    vpsrld $15, %ymm0, %ymm0
; NOOPT-NEXT:    vpsrld $15, %ymm1, %ymm1
; NOOPT-NEXT:    vpbroadcastd {{.*#+}} ymm2 = [65537,65537,65537,65537,65537,65537,65537,65537]
; NOOPT-NEXT:    vpand %ymm2, %ymm1, %ymm1
; NOOPT-NEXT:    vpand %ymm2, %ymm0, %ymm0
; NOOPT-NEXT:    vpslld $16, %ymm0, %ymm2
; NOOPT-NEXT:    vpsubd %ymm0, %ymm2, %ymm0
; NOOPT-NEXT:    vpslld $16, %ymm1, %ymm2
; NOOPT-NEXT:    vpsubd %ymm1, %ymm2, %ymm1
; NOOPT-NEXT:    retq
  %a = lshr <16 x i32> %x, <i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15, i32 15>
  %b = and <16 x i32> %a, <i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537, i32 65537>
  %c = mul <16 x i32> %b, <i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535, i32 65535>
  ret <16 x i32> %c
}
