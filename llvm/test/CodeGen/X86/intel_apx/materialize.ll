; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+cmov,+ndd %s -o - | FileCheck %s --check-prefix=CHECK64
; RUN: llc -mtriple=x86_64-pc-win32 -mattr=+cmov,+ndd %s -o - | FileCheck %s --check-prefix=CHECKWIN64

; RUN: llc -mtriple=x86_64-unknown-linux-gnu -mattr=+cmov,+ndd %s -o /dev/null \
; RUN:     -print-after postrapseudos -filter-print-funcs one64_minsize 2>&1 \
; RUN:    | FileCheck %s --check-prefix=OPERAND64

define i32 @one32_nooptsize() {
; CHECK64-LABEL: one32_nooptsize:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movl $1, %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one32_nooptsize:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 1

; When not optimizing for size, use mov.
}

define i32 @one32() optsize {
; CHECK64-LABEL: one32:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movl $1, %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one32:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 1


; FIXME: Figure out the best approach in 64-bit mode.
}

define i32 @one32_pgso() !prof !14 {
; CHECK64-LABEL: one32_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movl $1, %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one32_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 1


; FIXME: Figure out the best approach in 64-bit mode.
}

define i32 @one32_minsize() minsize {
; CHECK64-LABEL: one32_minsize:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq $1
; CHECK64-NEXT:    .cfi_adjust_cfa_offset 8
; CHECK64-NEXT:    popq %rax
; CHECK64-NEXT:    .cfi_adjust_cfa_offset -8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one32_minsize:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 1

; On 32-bit, xor-inc is preferred over push-pop.

; On 64-bit we don't do xor-inc yet, so push-pop it is. Note that we have to
; pop into a 64-bit register even when we just need 32 bits.

; On Win64 we can't adjust the stack unless there's a frame pointer.
}

define i32 @pr26023() minsize {
; CHECK64-LABEL: pr26023:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    leaq -{{[0-9]+}}(%rsp), %rax
; CHECK64-NEXT:    movq %rax, -{{[0-9]+}}(%rsp)
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    movb $-2, 119(%rax)
; CHECK64-NEXT:    movl $5, %ecx
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    movsbl 119(%rax), %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: pr26023:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    subq $128, %rsp
; CHECKWIN64-NEXT:    .seh_stackalloc 128
; CHECKWIN64-NEXT:    .seh_endprologue
; CHECKWIN64-NEXT:    leaq {{[0-9]+}}(%rsp), %rax
; CHECKWIN64-NEXT:    movq %rax, (%rsp)
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    movb $-2, 119(%rax)
; CHECKWIN64-NEXT:    movl $5, %ecx
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    movsbl 119(%rax), %eax
; CHECKWIN64-NEXT:    addq $128, %rsp
; CHECKWIN64-NEXT:    retq
; CHECKWIN64-NEXT:    .seh_endproc
entry:
  %x = alloca [120 x i8]
  call void asm sideeffect "", "imr,~{memory},~{dirflag},~{fpsr},~{flags}"(ptr %x)
  %arrayidx = getelementptr inbounds [120 x i8], ptr %x, i64 0, i64 119
  store volatile i8 -2, ptr %arrayidx
  call void asm sideeffect "", "r,~{dirflag},~{fpsr},~{flags}"(i32 5)
  %0 = load volatile i8, ptr %arrayidx
  %conv = sext i8 %0 to i32
  ret i32 %conv

; The function writes to the redzone, so push/pop cannot be used.

; 32-bit X86 doesn't have a redzone.

; Check push/pop have implicit def/use of $esp
}


define i64 @one64_minsize() minsize {
; CHECK64-LABEL: one64_minsize:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq $1
; CHECK64-NEXT:    .cfi_adjust_cfa_offset 8
; CHECK64-NEXT:    popq %rax
; CHECK64-NEXT:    .cfi_adjust_cfa_offset -8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one64_minsize:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i64 1
; On 64-bit we don't do xor-inc yet, so push-pop it is.

; On Win64 we can't adjust the stack unless there's a frame pointer.

; Check push/pop have implicit def/use of $rsp
}

define i32 @minus_one32() optsize {
; CHECK64-LABEL: minus_one32:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movl $-1, %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_one32:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $-1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 -1

}

define i32 @minus_one32_pgso() !prof !14 {
; CHECK64-LABEL: minus_one32_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movl $-1, %eax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_one32_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $-1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 -1

}

define i32 @minus_one32_minsize() minsize {
; CHECK64-LABEL: minus_one32_minsize:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq $-1
; CHECK64-NEXT:    .cfi_adjust_cfa_offset 8
; CHECK64-NEXT:    popq %rax
; CHECK64-NEXT:    .cfi_adjust_cfa_offset -8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_one32_minsize:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $-1, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 -1

; xor-dec is preferred over push-pop.
}

define i16 @one16() optsize {
; CHECK64-LABEL: one16:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movw $1, %ax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one16:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movw $1, %ax
; CHECKWIN64-NEXT:    retq
entry:
  ret i16 1

}

define i16 @minus_one16() optsize {
; CHECK64-LABEL: minus_one16:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movw $-1, %ax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_one16:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movw $-1, %ax
; CHECKWIN64-NEXT:    retq
entry:
  ret i16 -1

}

define i16 @one16_pgso() !prof !14 {
; CHECK64-LABEL: one16_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movw $1, %ax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: one16_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movw $1, %ax
; CHECKWIN64-NEXT:    retq
entry:
  ret i16 1

}

define i16 @minus_one16_pgso() !prof !14 {
; CHECK64-LABEL: minus_one16_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    movw $-1, %ax
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_one16_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movw $-1, %ax
; CHECKWIN64-NEXT:    retq
entry:
  ret i16 -1

}

define i32 @minus_five32() minsize {
; CHECK64-LABEL: minus_five32:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq $-5
; CHECK64-NEXT:    .cfi_adjust_cfa_offset 8
; CHECK64-NEXT:    popq %rax
; CHECK64-NEXT:    .cfi_adjust_cfa_offset -8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_five32:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movl $-5, %eax
; CHECKWIN64-NEXT:    retq
entry:
  ret i32 -5

}

define i64 @minus_five64() minsize {
; CHECK64-LABEL: minus_five64:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq $-5
; CHECK64-NEXT:    .cfi_adjust_cfa_offset 8
; CHECK64-NEXT:    popq %rax
; CHECK64-NEXT:    .cfi_adjust_cfa_offset -8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: minus_five64:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    movq $-5, %rax
; CHECKWIN64-NEXT:    retq
entry:
  ret i64 -5

}

define i32 @rematerialize_minus_one() optsize {
; CHECK64-LABEL: rematerialize_minus_one:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    pushq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    pushq %rax
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    .cfi_offset %rbx, -24
; CHECK64-NEXT:    .cfi_offset %rbp, -16
; CHECK64-NEXT:    movl $-1, %edi
; CHECK64-NEXT:    callq f@PLT
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    movl $-1, %eax
; CHECK64-NEXT:    addq $8, %rsp
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    popq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    popq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: rematerialize_minus_one:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    pushq %rsi
; CHECKWIN64-NEXT:    .seh_pushreg %rsi
; CHECKWIN64-NEXT:    pushq %rdi
; CHECKWIN64-NEXT:    .seh_pushreg %rdi
; CHECKWIN64-NEXT:    pushq %rbp
; CHECKWIN64-NEXT:    .seh_pushreg %rbp
; CHECKWIN64-NEXT:    pushq %rbx
; CHECKWIN64-NEXT:    .seh_pushreg %rbx
; CHECKWIN64-NEXT:    subq $40, %rsp
; CHECKWIN64-NEXT:    .seh_stackalloc 40
; CHECKWIN64-NEXT:    .seh_endprologue
; CHECKWIN64-NEXT:    movl $-1, %ecx
; CHECKWIN64-NEXT:    callq f
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    movl $-1, %eax
; CHECKWIN64-NEXT:    addq $40, %rsp
; CHECKWIN64-NEXT:    popq %rbx
; CHECKWIN64-NEXT:    popq %rbp
; CHECKWIN64-NEXT:    popq %rdi
; CHECKWIN64-NEXT:    popq %rsi
; CHECKWIN64-NEXT:    retq
; CHECKWIN64-NEXT:    .seh_endproc
entry:
  ; Materialize -1 (thiscall forces it into %ecx).
  tail call x86_thiscallcc void @f(i32 -1)

  ; Clobber all registers except %esp, leaving nowhere to store the -1 besides
  ; spilling it to the stack.
  tail call void asm sideeffect "", "~{eax},~{ebx},~{ecx},~{edx},~{edi},~{esi},~{ebp},~{dirflag},~{fpsr},~{flags}"()

  ; -1 should be re-materialized here instead of getting spilled above.
  ret i32 -1

}

define i32 @rematerialize_minus_one_eflags(i32 %x) optsize {
; CHECK64-LABEL: rematerialize_minus_one_eflags:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    pushq %r15
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    pushq %r14
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    pushq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 40
; CHECK64-NEXT:    pushq %rax
; CHECK64-NEXT:    .cfi_def_cfa_offset 48
; CHECK64-NEXT:    .cfi_offset %rbx, -40
; CHECK64-NEXT:    .cfi_offset %r14, -32
; CHECK64-NEXT:    .cfi_offset %r15, -24
; CHECK64-NEXT:    .cfi_offset %rbp, -16
; CHECK64-NEXT:    movl %edi, %r14d
; CHECK64-NEXT:    movl $-1, %r15d
; CHECK64-NEXT:    movl $-1, %edi
; CHECK64-NEXT:    callq f@PLT
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    xorl %eax, %eax
; CHECK64-NEXT:    cmpl $123, %r14d
; CHECK64-NEXT:    setne %al
; CHECK64-NEXT:    cmovel %r15d, %eax
; CHECK64-NEXT:    addq $8, %rsp
; CHECK64-NEXT:    .cfi_def_cfa_offset 40
; CHECK64-NEXT:    popq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    popq %r14
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    popq %r15
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    popq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: rematerialize_minus_one_eflags:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    pushq %r15
; CHECKWIN64-NEXT:    .seh_pushreg %r15
; CHECKWIN64-NEXT:    pushq %r14
; CHECKWIN64-NEXT:    .seh_pushreg %r14
; CHECKWIN64-NEXT:    pushq %rsi
; CHECKWIN64-NEXT:    .seh_pushreg %rsi
; CHECKWIN64-NEXT:    pushq %rdi
; CHECKWIN64-NEXT:    .seh_pushreg %rdi
; CHECKWIN64-NEXT:    pushq %rbp
; CHECKWIN64-NEXT:    .seh_pushreg %rbp
; CHECKWIN64-NEXT:    pushq %rbx
; CHECKWIN64-NEXT:    .seh_pushreg %rbx
; CHECKWIN64-NEXT:    subq $40, %rsp
; CHECKWIN64-NEXT:    .seh_stackalloc 40
; CHECKWIN64-NEXT:    .seh_endprologue
; CHECKWIN64-NEXT:    movl %ecx, %r14d
; CHECKWIN64-NEXT:    movl $-1, %r15d
; CHECKWIN64-NEXT:    movl $-1, %ecx
; CHECKWIN64-NEXT:    callq f
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    xorl %eax, %eax
; CHECKWIN64-NEXT:    cmpl $123, %r14d
; CHECKWIN64-NEXT:    setne %al
; CHECKWIN64-NEXT:    cmovel %r15d, %eax
; CHECKWIN64-NEXT:    addq $40, %rsp
; CHECKWIN64-NEXT:    popq %rbx
; CHECKWIN64-NEXT:    popq %rbp
; CHECKWIN64-NEXT:    popq %rdi
; CHECKWIN64-NEXT:    popq %rsi
; CHECKWIN64-NEXT:    popq %r14
; CHECKWIN64-NEXT:    popq %r15
; CHECKWIN64-NEXT:    retq
; CHECKWIN64-NEXT:    .seh_endproc
entry:
  ; Materialize -1 (thiscall forces it into %ecx).
  tail call x86_thiscallcc void @f(i32 -1)

  ; Clobber all registers except %esp, leaving nowhere to store the -1 besides
  ; spilling it to the stack.
  tail call void asm sideeffect "", "~{eax},~{ebx},~{ecx},~{edx},~{edi},~{esi},~{ebp},~{dirflag},~{fpsr},~{flags}"()

  ; Define eflags.
  %a = icmp ne i32 %x, 123
  %b = zext i1 %a to i32
  ; Cause -1 to be rematerialized right in front of the cmov, which needs eflags.
  ; It must therefore not use the xor-dec lowering.
  %c = select i1 %a, i32 %b, i32 -1
  ret i32 %c

}

define i32 @rematerialize_minus_one_pgso() !prof !14 {
; CHECK64-LABEL: rematerialize_minus_one_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    pushq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    pushq %rax
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    .cfi_offset %rbx, -24
; CHECK64-NEXT:    .cfi_offset %rbp, -16
; CHECK64-NEXT:    movl $-1, %edi
; CHECK64-NEXT:    callq f@PLT
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    movl $-1, %eax
; CHECK64-NEXT:    addq $8, %rsp
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    popq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    popq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: rematerialize_minus_one_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    pushq %rsi
; CHECKWIN64-NEXT:    .seh_pushreg %rsi
; CHECKWIN64-NEXT:    pushq %rdi
; CHECKWIN64-NEXT:    .seh_pushreg %rdi
; CHECKWIN64-NEXT:    pushq %rbp
; CHECKWIN64-NEXT:    .seh_pushreg %rbp
; CHECKWIN64-NEXT:    pushq %rbx
; CHECKWIN64-NEXT:    .seh_pushreg %rbx
; CHECKWIN64-NEXT:    subq $40, %rsp
; CHECKWIN64-NEXT:    .seh_stackalloc 40
; CHECKWIN64-NEXT:    .seh_endprologue
; CHECKWIN64-NEXT:    movl $-1, %ecx
; CHECKWIN64-NEXT:    callq f
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    movl $-1, %eax
; CHECKWIN64-NEXT:    addq $40, %rsp
; CHECKWIN64-NEXT:    popq %rbx
; CHECKWIN64-NEXT:    popq %rbp
; CHECKWIN64-NEXT:    popq %rdi
; CHECKWIN64-NEXT:    popq %rsi
; CHECKWIN64-NEXT:    retq
; CHECKWIN64-NEXT:    .seh_endproc
entry:
  ; Materialize -1 (thiscall forces it into %ecx).
  tail call x86_thiscallcc void @f(i32 -1)

  ; Clobber all registers except %esp, leaving nowhere to store the -1 besides
  ; spilling it to the stack.
  tail call void asm sideeffect "", "~{eax},~{ebx},~{ecx},~{edx},~{edi},~{esi},~{ebp},~{dirflag},~{fpsr},~{flags}"()

  ; -1 should be re-materialized here instead of getting spilled above.
  ret i32 -1

}

define i32 @rematerialize_minus_one_eflags_pgso(i32 %x) !prof !14 {
; CHECK64-LABEL: rematerialize_minus_one_eflags_pgso:
; CHECK64:       # %bb.0: # %entry
; CHECK64-NEXT:    pushq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    pushq %r15
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    pushq %r14
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    pushq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 40
; CHECK64-NEXT:    pushq %rax
; CHECK64-NEXT:    .cfi_def_cfa_offset 48
; CHECK64-NEXT:    .cfi_offset %rbx, -40
; CHECK64-NEXT:    .cfi_offset %r14, -32
; CHECK64-NEXT:    .cfi_offset %r15, -24
; CHECK64-NEXT:    .cfi_offset %rbp, -16
; CHECK64-NEXT:    movl %edi, %r14d
; CHECK64-NEXT:    movl $-1, %r15d
; CHECK64-NEXT:    movl $-1, %edi
; CHECK64-NEXT:    callq f@PLT
; CHECK64-NEXT:    #APP
; CHECK64-NEXT:    #NO_APP
; CHECK64-NEXT:    xorl %eax, %eax
; CHECK64-NEXT:    cmpl $123, %r14d
; CHECK64-NEXT:    setne %al
; CHECK64-NEXT:    cmovel %r15d, %eax
; CHECK64-NEXT:    addq $8, %rsp
; CHECK64-NEXT:    .cfi_def_cfa_offset 40
; CHECK64-NEXT:    popq %rbx
; CHECK64-NEXT:    .cfi_def_cfa_offset 32
; CHECK64-NEXT:    popq %r14
; CHECK64-NEXT:    .cfi_def_cfa_offset 24
; CHECK64-NEXT:    popq %r15
; CHECK64-NEXT:    .cfi_def_cfa_offset 16
; CHECK64-NEXT:    popq %rbp
; CHECK64-NEXT:    .cfi_def_cfa_offset 8
; CHECK64-NEXT:    retq
;
; CHECKWIN64-LABEL: rematerialize_minus_one_eflags_pgso:
; CHECKWIN64:       # %bb.0: # %entry
; CHECKWIN64-NEXT:    pushq %r15
; CHECKWIN64-NEXT:    .seh_pushreg %r15
; CHECKWIN64-NEXT:    pushq %r14
; CHECKWIN64-NEXT:    .seh_pushreg %r14
; CHECKWIN64-NEXT:    pushq %rsi
; CHECKWIN64-NEXT:    .seh_pushreg %rsi
; CHECKWIN64-NEXT:    pushq %rdi
; CHECKWIN64-NEXT:    .seh_pushreg %rdi
; CHECKWIN64-NEXT:    pushq %rbp
; CHECKWIN64-NEXT:    .seh_pushreg %rbp
; CHECKWIN64-NEXT:    pushq %rbx
; CHECKWIN64-NEXT:    .seh_pushreg %rbx
; CHECKWIN64-NEXT:    subq $40, %rsp
; CHECKWIN64-NEXT:    .seh_stackalloc 40
; CHECKWIN64-NEXT:    .seh_endprologue
; CHECKWIN64-NEXT:    movl %ecx, %r14d
; CHECKWIN64-NEXT:    movl $-1, %r15d
; CHECKWIN64-NEXT:    movl $-1, %ecx
; CHECKWIN64-NEXT:    callq f
; CHECKWIN64-NEXT:    #APP
; CHECKWIN64-NEXT:    #NO_APP
; CHECKWIN64-NEXT:    xorl %eax, %eax
; CHECKWIN64-NEXT:    cmpl $123, %r14d
; CHECKWIN64-NEXT:    setne %al
; CHECKWIN64-NEXT:    cmovel %r15d, %eax
; CHECKWIN64-NEXT:    addq $40, %rsp
; CHECKWIN64-NEXT:    popq %rbx
; CHECKWIN64-NEXT:    popq %rbp
; CHECKWIN64-NEXT:    popq %rdi
; CHECKWIN64-NEXT:    popq %rsi
; CHECKWIN64-NEXT:    popq %r14
; CHECKWIN64-NEXT:    popq %r15
; CHECKWIN64-NEXT:    retq
; CHECKWIN64-NEXT:    .seh_endproc
entry:
  ; Materialize -1 (thiscall forces it into %ecx).
  tail call x86_thiscallcc void @f(i32 -1)

  ; Clobber all registers except %esp, leaving nowhere to store the -1 besides
  ; spilling it to the stack.
  tail call void asm sideeffect "", "~{eax},~{ebx},~{ecx},~{edx},~{edi},~{esi},~{ebp},~{dirflag},~{fpsr},~{flags}"()

  ; Define eflags.
  %a = icmp ne i32 %x, 123
  %b = zext i1 %a to i32
  ; Cause -1 to be rematerialized right in front of the cmov, which needs eflags.
  ; It must therefore not use the xor-dec lowering.
  %c = select i1 %a, i32 %b, i32 -1
  ret i32 %c

}

declare x86_thiscallcc void @f(i32)

!llvm.module.flags = !{!0}
!0 = !{i32 1, !"ProfileSummary", !1}
!1 = !{!2, !3, !4, !5, !6, !7, !8, !9}
!2 = !{!"ProfileFormat", !"InstrProf"}
!3 = !{!"TotalCount", i64 10000}
!4 = !{!"MaxCount", i64 10}
!5 = !{!"MaxInternalCount", i64 1}
!6 = !{!"MaxFunctionCount", i64 1000}
!7 = !{!"NumCounts", i64 3}
!8 = !{!"NumFunctions", i64 3}
!9 = !{!"DetailedSummary", !10}
!10 = !{!11, !12, !13}
!11 = !{i32 10000, i64 100, i32 1}
!12 = !{i32 999000, i64 100, i32 1}
!13 = !{i32 999999, i64 1, i32 2}
!14 = !{!"function_entry_count", i64 0}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; OPERAND64: {{.*}}
