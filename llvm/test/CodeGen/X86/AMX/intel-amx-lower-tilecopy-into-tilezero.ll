; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+amx-int8 -mattr=+avx512f -verify-machineinstrs | FileCheck %s
; After TwoAddress, D = PTDPBSSDV A, B, C will become D = tilecopy A and D = PTDPBSSDV D, B, C.
define void @test() {
; CHECK-LABEL: test:
; CHECK:       # %bb.0: # %wrapper_entry
; CHECK-NEXT:    pushq %rbp
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movq %rsp, %rbp
; CHECK-NEXT:    .cfi_def_cfa_register %rbp
; CHECK-NEXT:    andq $-64, %rsp
; CHECK-NEXT:    subq $2176, %rsp # imm = 0x880
; CHECK-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vmovups %zmm0, (%rsp)
; CHECK-NEXT:    movb $1, (%rsp)
; CHECK-NEXT:    movb $16, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $64, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movb $16, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $64, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movb $16, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $64, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movb $16, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $64, {{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $64, %ax
; CHECK-NEXT:    ldtilecfg (%rsp)
; CHECK-NEXT:    movw $16, %cx
; CHECK-NEXT:    tilezero %tmm0
; CHECK-NEXT:    movl $64, %edx
; CHECK-NEXT:    leaq {{[0-9]+}}(%rsp), %rsi
; CHECK-NEXT:    leaq {{[0-9]+}}(%rsp), %rdi
; CHECK-NEXT:    .p2align 4, 0x90
; CHECK-NEXT:  .LBB0_1: # %scalar_kernel_entry
; CHECK-NEXT:    # =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    tileloadd (%rsi,%rdx), %tmm1
; CHECK-NEXT:    tileloadd (%rdi,%rdx), %tmm2
; CHECK-NEXT:    tilezero %tmm3
; CHECK-NEXT:    tdpbssd %tmm2, %tmm1, %tmm3
; CHECK-NEXT:    jmp .LBB0_1
wrapper_entry:
  %0 = call x86_amx @llvm.x86.tilezero.internal(i16 16, i16 64)
  %1 = call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx %0)
  br label %scalar_kernel_entry

scalar_kernel_entry:                              ; preds = %scalar_kernel_entry, %wrapper_entry
  %2 = call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> %1)
  %3 = call x86_amx @llvm.x86.cast.vector.to.tile.v1024i8(<1024 x i8> poison)
  %4 = call x86_amx @llvm.x86.cast.vector.to.tile.v1024i8(<1024 x i8> poison)
  %5 = call x86_amx @llvm.x86.tdpbssd.internal(i16 16, i16 64, i16 64, x86_amx %2, x86_amx %3, x86_amx %4)
  %6 = call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx %5)
  br label %scalar_kernel_entry
}

declare x86_amx @llvm.x86.tilezero.internal(i16, i16)
declare <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx)
declare x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32>)
declare x86_amx @llvm.x86.cast.vector.to.tile.v1024i8(<1024 x i8>)
declare x86_amx @llvm.x86.tdpbssd.internal(i16, i16, i16, x86_amx, x86_amx, x86_amx)
