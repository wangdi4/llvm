; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_amx_avx512_cvtrow
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+amx-tile,+amx-bf16,+avx512f, \
; RUN: -mattr=+amx-avx512-cvtrow,+avx512fp16 \
; RUN: -verify-machineinstrs | FileCheck %s

define void @test_amx(i8* %pointer, i8* %base, i64 %stride) {
; CHECK-LABEL: test_amx:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vxorps %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vmovups %zmm0, -{{[0-9]+}}(%rsp)
; CHECK-NEXT:    movb $1, -{{[0-9]+}}(%rsp)
; CHECK-NEXT:    movb $8, -{{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $8, -{{[0-9]+}}(%rsp)
; CHECK-NEXT:    ldtilecfg -{{[0-9]+}}(%rsp)
; CHECK-NEXT:    movw $8, %ax
; CHECK-NEXT:    tileloadd (%rsi,%rdx), %tmm0
; CHECK-NEXT:    tcvtrowd2ps $16, %tmm0, %zmm0
; CHECK-NEXT:    movl $16, %ecx
; CHECK-NEXT:    tcvtrowd2ps %ecx, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2pbf16h $16, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2pbf16h %ecx, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2pbf16l $16, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2pbf16l %ecx, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2phh $16, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2phh %ecx, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2phl $16, %tmm0, %zmm0
; CHECK-NEXT:    tcvtrowps2phl %ecx, %tmm0, %zmm0
; CHECK-NEXT:    tilestored %tmm0, (%rdi,%rdx)
; CHECK-NEXT:    tilerelease
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq

  %a = call x86_amx @llvm.x86.tileloadd64.internal(i16 8, i16 8, i8* %base, i64 %stride)
  call <16 x float> @llvm.x86.tcvtrowd2psi.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <16 x float> @llvm.x86.tcvtrowd2pse.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x i16> @llvm.x86.tcvtrowps2pbf16hi.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x i16> @llvm.x86.tcvtrowps2pbf16he.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x i16> @llvm.x86.tcvtrowps2pbf16li.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x i16> @llvm.x86.tcvtrowps2pbf16le.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x half> @llvm.x86.tcvtrowps2phhi.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x half> @llvm.x86.tcvtrowps2phhe.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x half> @llvm.x86.tcvtrowps2phli.internal(i16 8, i16 8, x86_amx %a, i32 16)
  call <32 x half> @llvm.x86.tcvtrowps2phle.internal(i16 8, i16 8, x86_amx %a, i32 16)

  call void @llvm.x86.tilestored64.internal(i16 8, i16 8, i8* %pointer, i64 %stride, x86_amx %a)
  ret void
}

declare x86_amx @llvm.x86.tilezero.internal(i16, i16)
declare x86_amx @llvm.x86.tileloadd64.internal(i16, i16, i8*, i64)
declare x86_amx @llvm.x86.tileloaddt164.internal(i16, i16, i8*, i64)
declare void @llvm.x86.tilestored64.internal(i16, i16, i8*, i64, x86_amx)

declare <16 x float> @llvm.x86.tcvtrowd2psi.internal(i16, i16, x86_amx, i32)
declare <16 x float> @llvm.x86.tcvtrowd2pse.internal(i16, i16, x86_amx, i32)
declare <32 x i16> @llvm.x86.tcvtrowps2pbf16hi.internal(i16, i16, x86_amx, i32)
declare <32 x i16> @llvm.x86.tcvtrowps2pbf16he.internal(i16, i16, x86_amx, i32)
declare <32 x i16> @llvm.x86.tcvtrowps2pbf16li.internal(i16, i16, x86_amx, i32)
declare <32 x i16> @llvm.x86.tcvtrowps2pbf16le.internal(i16, i16, x86_amx, i32)
declare <32 x half> @llvm.x86.tcvtrowps2phhi.internal(i16, i16, x86_amx, i32)
declare <32 x half> @llvm.x86.tcvtrowps2phhe.internal(i16, i16, x86_amx, i32)
declare <32 x half> @llvm.x86.tcvtrowps2phli.internal(i16, i16, x86_amx, i32)
declare <32 x half> @llvm.x86.tcvtrowps2phle.internal(i16, i16, x86_amx, i32)
