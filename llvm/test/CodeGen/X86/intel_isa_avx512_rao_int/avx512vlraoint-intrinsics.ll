; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_rao_int
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512raoint | FileCheck %s --check-prefixes=X64-AVX512RAO
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512raoint | FileCheck %s --check-prefixes=X86-AVX512RAO
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512raoint,+avxraoint | FileCheck %s --check-prefixes=X64-AVXRAO
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512raoint,+avxraoint | FileCheck %s --check-prefixes=X86-AVXRAO

define void @test_int_x86_vpaaddd128(i8* %A, <4 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaaddd128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaaddd %xmm0, (%rdi) # encoding: [0x62,0xf2,0x7c,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaaddd128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaaddd %xmm0, (%eax) # encoding: [0x62,0xf2,0x7c,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaaddd128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaaddd %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x78,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaaddd128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaaddd %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x78,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaaddd128(i8* %A, <4 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaaddd128(i8* %A, <4 x i32> %B)

define void @test_int_x86_mask_vpaaddd128(i8* %A, <4 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaaddd128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaaddd %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaaddd128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaaddd %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaaddd128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaaddd %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaaddd128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaaddd %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaaddd128(i8* %A, <4 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaaddd128(i8* %A, <4 x i32> %B, i8 %C)

define void @test_int_x86_vpaaddd256(i8* %A, <8 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaaddd256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaaddd %ymm0, (%rdi) # encoding: [0x62,0xf2,0x7c,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaaddd256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaaddd %ymm0, (%eax) # encoding: [0x62,0xf2,0x7c,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaaddd256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaaddd %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7c,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaaddd256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaaddd %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7c,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaaddd256(i8* %A, <8 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaaddd256(i8* %A, <8 x i32> %B)

define void @test_int_x86_mask_vpaaddd256(i8* %A, <8 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaaddd256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaaddd %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaaddd256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaaddd %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaaddd256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaaddd %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaaddd256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaaddd %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaaddd256(i8* %A, <8 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaaddd256(i8* %A, <8 x i32> %B, i8 %C)

define void @test_int_x86_vpaaddq128(i8* %A, <2 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaaddq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaaddq %xmm0, (%rdi) # encoding: [0x62,0xf2,0xfc,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaaddq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaaddq %xmm0, (%eax) # encoding: [0x62,0xf2,0xfc,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaaddq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaaddq %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf8,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaaddq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaaddq %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf8,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaaddq128(i8* %A, <2 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaaddq128(i8* %A, <2 x i64> %B)

define void @test_int_x86_mask_vpaaddq128(i8* %A, <2 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaaddq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaaddq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfc,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaaddq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaaddq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfc,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaaddq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaaddq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfc,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaaddq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaaddq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfc,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaaddq128(i8* %A, <2 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaaddq128(i8* %A, <2 x i64> %B, i8 %C)

define void @test_int_x86_vpaaddq256(i8* %A, <4 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaaddq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaaddq %ymm0, (%rdi) # encoding: [0x62,0xf2,0xfc,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaaddq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaaddq %ymm0, (%eax) # encoding: [0x62,0xf2,0xfc,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaaddq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaaddq %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfc,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaaddq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaaddq %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfc,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaaddq256(i8* %A, <4 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaaddq256(i8* %A, <4 x i64> %B)

define void @test_int_x86_mask_vpaaddq256(i8* %A, <4 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaaddq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaaddq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfc,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaaddq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaaddq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfc,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaaddq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaaddq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfc,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaaddq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaaddq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfc,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaaddq256(i8* %A, <4 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaaddq256(i8* %A, <4 x i64> %B, i8 %C)

define void @test_int_x86_vpaandd128(i8* %A, <4 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaandd128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaandd %xmm0, (%rdi) # encoding: [0x62,0xf2,0x7d,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaandd128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaandd %xmm0, (%eax) # encoding: [0x62,0xf2,0x7d,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaandd128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaandd %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x79,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaandd128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaandd %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x79,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaandd128(i8* %A, <4 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaandd128(i8* %A, <4 x i32> %B)

define void @test_int_x86_mask_vpaandd128(i8* %A, <4 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaandd128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaandd %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaandd128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaandd %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaandd128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaandd %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaandd128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaandd %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaandd128(i8* %A, <4 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaandd128(i8* %A, <4 x i32> %B, i8 %C)

define void @test_int_x86_vpaandd256(i8* %A, <8 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaandd256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaandd %ymm0, (%rdi) # encoding: [0x62,0xf2,0x7d,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaandd256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaandd %ymm0, (%eax) # encoding: [0x62,0xf2,0x7d,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaandd256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaandd %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7d,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaandd256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaandd %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7d,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaandd256(i8* %A, <8 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaandd256(i8* %A, <8 x i32> %B)

define void @test_int_x86_mask_vpaandd256(i8* %A, <8 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaandd256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaandd %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaandd256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaandd %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaandd256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaandd %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaandd256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaandd %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaandd256(i8* %A, <8 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaandd256(i8* %A, <8 x i32> %B, i8 %C)

define void @test_int_x86_vpaandq128(i8* %A, <2 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaandq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaandq %xmm0, (%rdi) # encoding: [0x62,0xf2,0xfd,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaandq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaandq %xmm0, (%eax) # encoding: [0x62,0xf2,0xfd,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaandq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaandq %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf9,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaandq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaandq %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf9,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaandq128(i8* %A, <2 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaandq128(i8* %A, <2 x i64> %B)

define void @test_int_x86_mask_vpaandq128(i8* %A, <2 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaandq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaandq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaandq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaandq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaandq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaandq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaandq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaandq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaandq128(i8* %A, <2 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaandq128(i8* %A, <2 x i64> %B, i8 %C)

define void @test_int_x86_vpaandq256(i8* %A, <4 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaandq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaandq %ymm0, (%rdi) # encoding: [0x62,0xf2,0xfd,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaandq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaandq %ymm0, (%eax) # encoding: [0x62,0xf2,0xfd,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaandq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaandq %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfd,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaandq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaandq %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfd,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaandq256(i8* %A, <4 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaandq256(i8* %A, <4 x i64> %B)

define void @test_int_x86_mask_vpaandq256(i8* %A, <4 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaandq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaandq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaandq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaandq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaandq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaandq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaandq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaandq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaandq256(i8* %A, <4 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaandq256(i8* %A, <4 x i64> %B, i8 %C)

define void @test_int_x86_vpaord128(i8* %A, <4 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaord128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaord %xmm0, (%rdi) # encoding: [0x62,0xf2,0x7f,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaord128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaord %xmm0, (%eax) # encoding: [0x62,0xf2,0x7f,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaord128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaord %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7b,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaord128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaord %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7b,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaord128(i8* %A, <4 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaord128(i8* %A, <4 x i32> %B)

define void @test_int_x86_mask_vpaord128(i8* %A, <4 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaord128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaord %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7f,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaord128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaord %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7f,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaord128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaord %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7f,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaord128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaord %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7f,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaord128(i8* %A, <4 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaord128(i8* %A, <4 x i32> %B, i8 %C)

define void @test_int_x86_vpaord256(i8* %A, <8 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaord256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaord %ymm0, (%rdi) # encoding: [0x62,0xf2,0x7f,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaord256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaord %ymm0, (%eax) # encoding: [0x62,0xf2,0x7f,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaord256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaord %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7f,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaord256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaord %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7f,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaord256(i8* %A, <8 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaord256(i8* %A, <8 x i32> %B)

define void @test_int_x86_mask_vpaord256(i8* %A, <8 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaord256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaord %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7f,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaord256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaord %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7f,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaord256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaord %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7f,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaord256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaord %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7f,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaord256(i8* %A, <8 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaord256(i8* %A, <8 x i32> %B, i8 %C)

define void @test_int_x86_vpaorq128(i8* %A, <2 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaorq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaorq %xmm0, (%rdi) # encoding: [0x62,0xf2,0xff,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaorq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaorq %xmm0, (%eax) # encoding: [0x62,0xf2,0xff,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaorq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaorq %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfb,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaorq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaorq %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfb,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaorq128(i8* %A, <2 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaorq128(i8* %A, <2 x i64> %B)

define void @test_int_x86_mask_vpaorq128(i8* %A, <2 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaorq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaorq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xff,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaorq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaorq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xff,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaorq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaorq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xff,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaorq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaorq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xff,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaorq128(i8* %A, <2 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaorq128(i8* %A, <2 x i64> %B, i8 %C)

define void @test_int_x86_vpaorq256(i8* %A, <4 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaorq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaorq %ymm0, (%rdi) # encoding: [0x62,0xf2,0xff,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaorq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaorq %ymm0, (%eax) # encoding: [0x62,0xf2,0xff,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaorq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaorq %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xff,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaorq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaorq %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xff,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaorq256(i8* %A, <4 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaorq256(i8* %A, <4 x i64> %B)

define void @test_int_x86_mask_vpaorq256(i8* %A, <4 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaorq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaorq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xff,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaorq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaorq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xff,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaorq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaorq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xff,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaorq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaorq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xff,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaorq256(i8* %A, <4 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaorq256(i8* %A, <4 x i64> %B, i8 %C)

define void @test_int_x86_vpaxord128(i8* %A, <4 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaxord128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaxord %xmm0, (%rdi) # encoding: [0x62,0xf2,0x7e,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaxord128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaxord %xmm0, (%eax) # encoding: [0x62,0xf2,0x7e,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaxord128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaxord %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7a,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaxord128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaxord %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7a,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaxord128(i8* %A, <4 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaxord128(i8* %A, <4 x i32> %B)

define void @test_int_x86_mask_vpaxord128(i8* %A, <4 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaxord128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaxord %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7e,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaxord128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaxord %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7e,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaxord128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaxord %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7e,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaxord128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaxord %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7e,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaxord128(i8* %A, <4 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaxord128(i8* %A, <4 x i32> %B, i8 %C)

define void @test_int_x86_vpaxord256(i8* %A, <8 x i32> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaxord256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaxord %ymm0, (%rdi) # encoding: [0x62,0xf2,0x7e,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaxord256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaxord %ymm0, (%eax) # encoding: [0x62,0xf2,0x7e,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaxord256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaxord %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7e,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaxord256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaxord %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0x7e,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaxord256(i8* %A, <8 x i32> %B)
  ret  void
}
declare void @llvm.x86.vpaxord256(i8* %A, <8 x i32> %B)

define void @test_int_x86_mask_vpaxord256(i8* %A, <8 x i32> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaxord256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaxord %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7e,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaxord256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaxord %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7e,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaxord256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaxord %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7e,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaxord256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaxord %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7e,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaxord256(i8* %A, <8 x i32> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaxord256(i8* %A, <8 x i32> %B, i8 %C)

define void @test_int_x86_vpaxorq128(i8* %A, <2 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaxorq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaxorq %xmm0, (%rdi) # encoding: [0x62,0xf2,0xfe,0x08,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaxorq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaxorq %xmm0, (%eax) # encoding: [0x62,0xf2,0xfe,0x08,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaxorq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaxorq %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfa,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaxorq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaxorq %xmm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfa,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaxorq128(i8* %A, <2 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaxorq128(i8* %A, <2 x i64> %B)

define void @test_int_x86_mask_vpaxorq128(i8* %A, <2 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaxorq128:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaxorq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfe,0x09,0xfc,0x07]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaxorq128:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaxorq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfe,0x09,0xfc,0x00]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaxorq128:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaxorq %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfe,0x09,0xfc,0x07]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaxorq128:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaxorq %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfe,0x09,0xfc,0x00]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaxorq128(i8* %A, <2 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaxorq128(i8* %A, <2 x i64> %B, i8 %C)

define void @test_int_x86_vpaxorq256(i8* %A, <4 x i64> %B) {
; X64-AVX512RAO-LABEL: test_int_x86_vpaxorq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    vpaxorq %ymm0, (%rdi) # encoding: [0x62,0xf2,0xfe,0x28,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_vpaxorq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    vpaxorq %ymm0, (%eax) # encoding: [0x62,0xf2,0xfe,0x28,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_vpaxorq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    vpaxorq %ymm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfe,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_vpaxorq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    vpaxorq %ymm0, (%eax) # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xfe,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vpaxorq256(i8* %A, <4 x i64> %B)
  ret  void
}
declare void @llvm.x86.vpaxorq256(i8* %A, <4 x i64> %B)

define void @test_int_x86_mask_vpaxorq256(i8* %A, <4 x i64> %B, i8 %C) {
; X64-AVX512RAO-LABEL: test_int_x86_mask_vpaxorq256:
; X64-AVX512RAO:       # %bb.0:
; X64-AVX512RAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVX512RAO-NEXT:    # implicit-def: $eax
; X64-AVX512RAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVX512RAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVX512RAO-NEXT:    vpaxorq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfe,0x29,0xfc,0x07]
; X64-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVX512RAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVX512RAO-LABEL: test_int_x86_mask_vpaxorq256:
; X86-AVX512RAO:       # %bb.0:
; X86-AVX512RAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVX512RAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVX512RAO-NEXT:    # implicit-def: $ecx
; X86-AVX512RAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVX512RAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVX512RAO-NEXT:    vpaxorq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfe,0x29,0xfc,0x00]
; X86-AVX512RAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVX512RAO-NEXT:    retl # encoding: [0xc3]
;
; X64-AVXRAO-LABEL: test_int_x86_mask_vpaxorq256:
; X64-AVXRAO:       # %bb.0:
; X64-AVXRAO-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-AVXRAO-NEXT:    # implicit-def: $eax
; X64-AVXRAO-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-AVXRAO-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X64-AVXRAO-NEXT:    vpaxorq %ymm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfe,0x29,0xfc,0x07]
; X64-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-AVXRAO-NEXT:    retq # encoding: [0xc3]
;
; X86-AVXRAO-LABEL: test_int_x86_mask_vpaxorq256:
; X86-AVXRAO:       # %bb.0:
; X86-AVXRAO-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-AVXRAO-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-AVXRAO-NEXT:    # implicit-def: $ecx
; X86-AVXRAO-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-AVXRAO-NEXT:    kmovw %ecx, %k1 # encoding: [0xc5,0xf8,0x92,0xc9]
; X86-AVXRAO-NEXT:    vpaxorq %ymm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfe,0x29,0xfc,0x00]
; X86-AVXRAO-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-AVXRAO-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vpaxorq256(i8* %A, <4 x i64> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vpaxorq256(i8* %A, <4 x i64> %B, i8 %C)

