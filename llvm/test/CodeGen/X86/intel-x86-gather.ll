; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mattr=+prefer-no-gather -disable-peephole -mcpu=skylake -mtriple=x86_64-unknown-linux-gnu -mattr=avx2 < %s | FileCheck %s

@int_base = external dso_local global [0 x i32], align 4

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s1p32i32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32i32v4Dv2_x:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 1)
  %c = bitcast <4 x i32> %b to <2 x i64>
  ret <2 x i64> %c
}

; Function Attrs: nofree nounwind readonly
declare <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32>, i8*, <4 x i32>, <4 x i32>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s1p32i32v4m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32i32v4m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB1_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB1_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB1_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB1_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB1_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB1_7
; CHECK-NEXT:  .LBB1_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB1_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB1_8
; CHECK-NEXT:  .LBB1_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %index to <4 x i32>
  %c = bitcast <2 x i64> %mask to <4 x i32>
  %d = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %b, <4 x i32> %c, i8 1)
  %e = bitcast <4 x i32> %d to <2 x i64>
  ret <2 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s1p32i32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32i32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpmovsxdq %xmm1, %ymm1
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm2
; CHECK-NEXT:    vpbroadcastq %xmm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm1, %ymm2, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm2, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rcx
; CHECK-NEXT:    vmovq %xmm1, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm1, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm1, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rdi
; CHECK-NEXT:    vmovq %xmm1, %r8
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm1, %xmm1
; CHECK-NEXT:    vpinsrd $2, (%r8), %xmm1, %xmm1
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpinsrd $3, (%rdi), %xmm1, %xmm0
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovq %xmm2, %rax
; CHECK-NEXT:    vpinsrd $2, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x i32> <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>, i8 1)
  %c = bitcast <8 x i32> %b to <4 x i64>
  ret <4 x i64> %c
}

; Function Attrs: nofree nounwind readonly
declare <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32>, i8*, <8 x i32>, <8 x i32>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s1p32i32v8m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32i32v8m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB3_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB3_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB3_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB3_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB3_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm4
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB3_6: # %else5
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB3_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB3_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB3_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB3_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB3_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB3_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB3_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB3_15
; CHECK-NEXT:  .LBB3_16: # %else20
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB3_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB3_16
; CHECK-NEXT:  .LBB3_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastd (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %src to <8 x i32>
  %b = bitcast <4 x i64> %index to <8 x i32>
  %c = bitcast <4 x i64> %mask to <8 x i32>
  %d = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %b, <8 x i32> %c, i8 1)
  %e = bitcast <8 x i32> %d to <4 x i64>
  ret <4 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s1p32i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> <i64 -1, i64 -1>, i8 1)
  ret <2 x i64> %b
}

; Function Attrs: nofree nounwind readonly
declare <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64>, i8*, <4 x i32>, <2 x i64>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s1p32i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB5_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB5_3
; CHECK-NEXT:  .LBB5_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB5_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB5_4
; CHECK-NEXT:  .LBB5_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> %mask, i8 1)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s1p32i64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32i64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 1)
  ret <4 x i64> %b
}

; Function Attrs: nofree nounwind readonly
declare <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64>, i8*, <4 x i32>, <4 x i64>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s1p32i64v4m0Dv2_xDv4_xS0_(<2 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32i64v4m0Dv2_xDv4_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB7_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB7_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB7_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB7_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB7_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB7_7
; CHECK-NEXT:  .LBB7_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB7_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB7_8
; CHECK-NEXT:  .LBB7_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> %mask, i8 1)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s1p64i32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64i32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpunpckldq {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm0[0],zero
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 1)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: nofree nounwind readonly
declare <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32>, i8*, <2 x i64>, <4 x i32>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s1p64i32v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64i32v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB9_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB9_3
; CHECK-NEXT:  .LBB9_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB9_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB9_4
; CHECK-NEXT:  .LBB9_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> %b, i8 1)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s1p64i32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64i32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 1)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: nofree nounwind readonly
declare <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32>, i8*, <4 x i64>, <4 x i32>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s1p64i32v4m0Dv4_xDv2_xS0_(<4 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64i32v4m0Dv4_xDv2_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB11_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB11_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB11_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB11_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB11_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB11_7
; CHECK-NEXT:  .LBB11_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB11_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB11_8
; CHECK-NEXT:  .LBB11_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> %b, i8 1)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s1p64i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> <i64 -1, i64 -1>, i8 1)
  ret <2 x i64> %a
}

; Function Attrs: nofree nounwind readonly
declare <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64>, i8*, <2 x i64>, <2 x i64>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s1p64i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB13_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB13_3
; CHECK-NEXT:  .LBB13_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB13_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB13_4
; CHECK-NEXT:  .LBB13_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> %mask, i8 1)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s1p64i64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64i64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 1)
  ret <4 x i64> %a
}

; Function Attrs: nofree nounwind readonly
declare <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64>, i8*, <4 x i64>, <4 x i64>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s1p64i64v4m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64i64v4m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB15_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB15_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB15_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB15_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB15_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB15_7
; CHECK-NEXT:  .LBB15_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB15_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB15_8
; CHECK-NEXT:  .LBB15_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> %mask, i8 1)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s1p32f32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32f32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 1)
  ret <4 x float> %b
}

; Function Attrs: nofree nounwind readonly
declare <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float>, i8*, <4 x i32>, <4 x float>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s1p32f32v4m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32f32v4m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB17_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB17_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB17_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB17_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB17_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB17_7
; CHECK-NEXT:  .LBB17_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB17_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB17_8
; CHECK-NEXT:  .LBB17_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x float>
  %c = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> %b, i8 1)
  ret <4 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z10s1p32f32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32f32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpmovsxdq %xmm1, %ymm1
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm2
; CHECK-NEXT:    vpbroadcastq %xmm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm1, %ymm2, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm2, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rcx
; CHECK-NEXT:    vmovq %xmm1, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm1, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm1, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rdi
; CHECK-NEXT:    vmovq %xmm1, %r8
; CHECK-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vmovq %xmm2, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 1)
  ret <8 x float> %b
}

; Function Attrs: nofree nounwind readonly
declare <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float>, i8*, <8 x i32>, <8 x float>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z12s1p32f32v8m0Dv4_xDv8_fS_(<4 x i64> noundef %index, <8 x float> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32f32v8m0Dv4_xDv8_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB19_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB19_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB19_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB19_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB19_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm4 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB19_6: # %else5
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB19_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB19_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB19_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB19_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB19_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB19_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB19_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB19_15
; CHECK-NEXT:  .LBB19_16: # %else20
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB19_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB19_16
; CHECK-NEXT:  .LBB19_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastss (%rax), %ymm0
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = bitcast <4 x i64> %mask to <8 x float>
  %c = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> %b, i8 1)
  ret <8 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s1p32f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 1)
  ret <2 x double> %b
}

; Function Attrs: nofree nounwind readonly
declare <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double>, i8*, <4 x i32>, <2 x double>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s1p32f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB21_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB21_3
; CHECK-NEXT:  .LBB21_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB21_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB21_4
; CHECK-NEXT:  .LBB21_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <2 x double>
  %c = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> %b, i8 1)
  ret <2 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s1p32f64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p32f64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 1)
  ret <4 x double> %b
}

; Function Attrs: nofree nounwind readonly
declare <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double>, i8*, <4 x i32>, <4 x double>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s1p32f64v4m0Dv2_xDv4_dDv4_x(<2 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p32f64v4m0Dv2_xDv4_dDv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB23_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB23_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB23_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB23_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB23_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB23_7
; CHECK-NEXT:  .LBB23_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB23_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB23_8
; CHECK-NEXT:  .LBB23_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <4 x i64> %mask to <4 x double>
  %c = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> %b, i8 1)
  ret <4 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s1p64f32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64f32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],zero,zero
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 1)
  ret <4 x float> %a
}

; Function Attrs: nofree nounwind readonly
declare <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float>, i8*, <2 x i64>, <4 x float>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s1p64f32v2m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64f32v2m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB25_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB25_3
; CHECK-NEXT:  .LBB25_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB25_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpblendd {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB25_4
; CHECK-NEXT:  .LBB25_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> %a, i8 1)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s1p64f32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64f32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 1)
  ret <4 x float> %a
}

; Function Attrs: nofree nounwind readonly
declare <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float>, i8*, <4 x i64>, <4 x float>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s1p64f32v4m0Dv4_xDv4_fDv2_x(<4 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64f32v4m0Dv4_xDv4_fDv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB27_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB27_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB27_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB27_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB27_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB27_7
; CHECK-NEXT:  .LBB27_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB27_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB27_8
; CHECK-NEXT:  .LBB27_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> %a, i8 1)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s1p64f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 1)
  ret <2 x double> %a
}

; Function Attrs: nofree nounwind readonly
declare <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double>, i8*, <2 x i64>, <2 x double>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s1p64f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB29_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB29_3
; CHECK-NEXT:  .LBB29_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB29_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB29_4
; CHECK-NEXT:  .LBB29_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <2 x double>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> %a, i8 1)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s1p64f64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s1p64f64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 1)
  ret <4 x double> %a
}

; Function Attrs: nofree nounwind readonly
declare <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double>, i8*, <4 x i64>, <4 x double>, i8 immarg)

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s1p64f64v4m0Dv4_xDv4_dS_(<4 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s1p64f64v4m0Dv4_xDv4_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB31_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB31_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB31_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB31_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB31_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB31_7
; CHECK-NEXT:  .LBB31_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB31_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB31_8
; CHECK-NEXT:  .LBB31_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %mask to <4 x double>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> %a, i8 1)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s2p32i32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32i32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 2)
  %c = bitcast <4 x i32> %b to <2 x i64>
  ret <2 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s2p32i32v4m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32i32v4m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB33_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB33_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB33_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB33_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB33_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB33_7
; CHECK-NEXT:  .LBB33_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB33_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB33_8
; CHECK-NEXT:  .LBB33_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %index to <4 x i32>
  %c = bitcast <2 x i64> %mask to <4 x i32>
  %d = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %b, <4 x i32> %c, i8 2)
  %e = bitcast <4 x i32> %d to <2 x i64>
  ret <2 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s2p32i32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32i32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm2, %xmm2
; CHECK-NEXT:    vpinsrd $2, (%r8), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpinsrd $3, (%rdi), %xmm2, %xmm0
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vpinsrd $2, (%rax), %xmm2, %xmm1
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x i32> <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>, i8 2)
  %c = bitcast <8 x i32> %b to <4 x i64>
  ret <4 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s2p32i32v8m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32i32v8m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB35_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB35_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB35_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB35_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB35_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm4
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB35_6: # %else5
; CHECK-NEXT:    vpaddq %ymm2, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB35_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB35_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB35_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB35_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB35_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB35_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB35_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB35_15
; CHECK-NEXT:  .LBB35_16: # %else20
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB35_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB35_16
; CHECK-NEXT:  .LBB35_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastd (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %src to <8 x i32>
  %b = bitcast <4 x i64> %index to <8 x i32>
  %c = bitcast <4 x i64> %mask to <8 x i32>
  %d = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %b, <8 x i32> %c, i8 2)
  %e = bitcast <8 x i32> %d to <4 x i64>
  ret <4 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s2p32i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> <i64 -1, i64 -1>, i8 2)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s2p32i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB37_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB37_3
; CHECK-NEXT:  .LBB37_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB37_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB37_4
; CHECK-NEXT:  .LBB37_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> %mask, i8 2)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s2p32i64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32i64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 2)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s2p32i64v4m0Dv2_xDv4_xS0_(<2 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32i64v4m0Dv2_xDv4_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB39_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB39_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB39_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB39_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB39_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB39_7
; CHECK-NEXT:  .LBB39_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB39_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB39_8
; CHECK-NEXT:  .LBB39_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> %mask, i8 2)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s2p64i32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64i32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpunpckldq {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm0[0],zero
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 2)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s2p64i32v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64i32v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB41_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB41_3
; CHECK-NEXT:  .LBB41_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB41_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB41_4
; CHECK-NEXT:  .LBB41_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> %b, i8 2)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s2p64i32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64i32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 2)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s2p64i32v4m0Dv4_xDv2_xS0_(<4 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64i32v4m0Dv4_xDv2_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB43_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB43_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB43_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB43_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB43_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB43_7
; CHECK-NEXT:  .LBB43_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB43_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB43_8
; CHECK-NEXT:  .LBB43_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> %b, i8 2)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s2p64i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> <i64 -1, i64 -1>, i8 2)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s2p64i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB45_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB45_3
; CHECK-NEXT:  .LBB45_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB45_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB45_4
; CHECK-NEXT:  .LBB45_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> %mask, i8 2)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s2p64i64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64i64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 2)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s2p64i64v4m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64i64v4m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB47_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB47_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB47_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB47_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB47_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB47_7
; CHECK-NEXT:  .LBB47_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB47_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB47_8
; CHECK-NEXT:  .LBB47_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> %mask, i8 2)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s2p32f32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32f32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 2)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s2p32f32v4m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32f32v4m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB49_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB49_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB49_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB49_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB49_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB49_7
; CHECK-NEXT:  .LBB49_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB49_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB49_8
; CHECK-NEXT:  .LBB49_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x float>
  %c = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> %b, i8 2)
  ret <4 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z10s2p32f32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32f32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm2[0,1,2],mem[0]
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 2)
  ret <8 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z12s2p32f32v8m0Dv4_xDv8_fS_(<4 x i64> noundef %index, <8 x float> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32f32v8m0Dv4_xDv8_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB51_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB51_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB51_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB51_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB51_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm4 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB51_6: # %else5
; CHECK-NEXT:    vpaddq %ymm2, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB51_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB51_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB51_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB51_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB51_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB51_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB51_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB51_15
; CHECK-NEXT:  .LBB51_16: # %else20
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB51_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB51_16
; CHECK-NEXT:  .LBB51_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastss (%rax), %ymm0
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = bitcast <4 x i64> %mask to <8 x float>
  %c = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> %b, i8 2)
  ret <8 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s2p32f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 2)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s2p32f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB53_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB53_3
; CHECK-NEXT:  .LBB53_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB53_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB53_4
; CHECK-NEXT:  .LBB53_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <2 x double>
  %c = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> %b, i8 2)
  ret <2 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s2p32f64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p32f64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 2)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s2p32f64v4m0Dv2_xDv4_dDv4_x(<2 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p32f64v4m0Dv2_xDv4_dDv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB55_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB55_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB55_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB55_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB55_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB55_7
; CHECK-NEXT:  .LBB55_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB55_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB55_8
; CHECK-NEXT:  .LBB55_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <4 x i64> %mask to <4 x double>
  %c = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> %b, i8 2)
  ret <4 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s2p64f32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64f32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],zero,zero
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 2)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s2p64f32v2m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64f32v2m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB57_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB57_3
; CHECK-NEXT:  .LBB57_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB57_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpblendd {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB57_4
; CHECK-NEXT:  .LBB57_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> %a, i8 2)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s2p64f32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64f32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 2)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s2p64f32v4m0Dv4_xDv4_fDv2_x(<4 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64f32v4m0Dv4_xDv4_fDv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB59_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB59_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB59_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB59_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB59_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB59_7
; CHECK-NEXT:  .LBB59_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB59_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB59_8
; CHECK-NEXT:  .LBB59_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> %a, i8 2)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s2p64f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 2)
  ret <2 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s2p64f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB61_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB61_3
; CHECK-NEXT:  .LBB61_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB61_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB61_4
; CHECK-NEXT:  .LBB61_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <2 x double>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> %a, i8 2)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s2p64f64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s2p64f64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 2)
  ret <4 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s2p64f64v4m0Dv4_xDv4_dS_(<4 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s2p64f64v4m0Dv4_xDv4_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB63_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB63_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB63_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB63_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB63_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB63_7
; CHECK-NEXT:  .LBB63_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB63_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB63_8
; CHECK-NEXT:  .LBB63_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %mask to <4 x double>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> %a, i8 2)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s4p32i32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32i32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 4)
  %c = bitcast <4 x i32> %b to <2 x i64>
  ret <2 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s4p32i32v4m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32i32v4m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB65_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB65_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB65_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB65_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB65_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB65_7
; CHECK-NEXT:  .LBB65_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB65_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB65_8
; CHECK-NEXT:  .LBB65_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %index to <4 x i32>
  %c = bitcast <2 x i64> %mask to <4 x i32>
  %d = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %b, <4 x i32> %c, i8 4)
  %e = bitcast <4 x i32> %d to <2 x i64>
  ret <2 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s4p32i32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32i32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpsllq $2, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm2, %xmm2
; CHECK-NEXT:    vpinsrd $2, (%r8), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpinsrd $3, (%rdi), %xmm2, %xmm0
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vpinsrd $2, (%rax), %xmm2, %xmm1
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x i32> <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>, i8 4)
  %c = bitcast <8 x i32> %b to <4 x i64>
  ret <4 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s4p32i32v8m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32i32v8m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpsllq $2, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB67_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB67_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB67_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB67_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB67_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm4
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB67_6: # %else5
; CHECK-NEXT:    vpsllq $2, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB67_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB67_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB67_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB67_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB67_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB67_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB67_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB67_15
; CHECK-NEXT:  .LBB67_16: # %else20
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB67_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB67_16
; CHECK-NEXT:  .LBB67_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastd (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %src to <8 x i32>
  %b = bitcast <4 x i64> %index to <8 x i32>
  %c = bitcast <4 x i64> %mask to <8 x i32>
  %d = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %b, <8 x i32> %c, i8 4)
  %e = bitcast <8 x i32> %d to <4 x i64>
  ret <4 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s4p32i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> <i64 -1, i64 -1>, i8 4)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s4p32i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB69_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB69_3
; CHECK-NEXT:  .LBB69_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB69_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB69_4
; CHECK-NEXT:  .LBB69_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> %mask, i8 4)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s4p32i64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32i64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 4)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s4p32i64v4m0Dv2_xDv4_xS0_(<2 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32i64v4m0Dv2_xDv4_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB71_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB71_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB71_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB71_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB71_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB71_7
; CHECK-NEXT:  .LBB71_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB71_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB71_8
; CHECK-NEXT:  .LBB71_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> %mask, i8 4)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s4p64i32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64i32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpunpckldq {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm0[0],zero
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 4)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s4p64i32v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64i32v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB73_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB73_3
; CHECK-NEXT:  .LBB73_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB73_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB73_4
; CHECK-NEXT:  .LBB73_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> %b, i8 4)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s4p64i32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64i32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 4)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s4p64i32v4m0Dv4_xDv2_xS0_(<4 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64i32v4m0Dv4_xDv2_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB75_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB75_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB75_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB75_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB75_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB75_7
; CHECK-NEXT:  .LBB75_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB75_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB75_8
; CHECK-NEXT:  .LBB75_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> %b, i8 4)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s4p64i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> <i64 -1, i64 -1>, i8 4)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s4p64i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB77_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB77_3
; CHECK-NEXT:  .LBB77_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB77_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB77_4
; CHECK-NEXT:  .LBB77_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> %mask, i8 4)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s4p64i64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64i64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 4)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s4p64i64v4m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64i64v4m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB79_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB79_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB79_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB79_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB79_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB79_7
; CHECK-NEXT:  .LBB79_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB79_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB79_8
; CHECK-NEXT:  .LBB79_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> %mask, i8 4)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s4p32f32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32f32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 4)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s4p32f32v4m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32f32v4m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB81_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB81_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB81_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB81_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB81_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB81_7
; CHECK-NEXT:  .LBB81_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB81_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB81_8
; CHECK-NEXT:  .LBB81_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x float>
  %c = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> %b, i8 4)
  ret <4 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z10s4p32f32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32f32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpsllq $2, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm2[0,1,2],mem[0]
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 4)
  ret <8 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z12s4p32f32v8m0Dv4_xDv8_fS_(<4 x i64> noundef %index, <8 x float> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32f32v8m0Dv4_xDv8_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpsllq $2, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB83_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB83_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB83_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB83_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB83_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm4 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB83_6: # %else5
; CHECK-NEXT:    vpsllq $2, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB83_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB83_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB83_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB83_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB83_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB83_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB83_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB83_15
; CHECK-NEXT:  .LBB83_16: # %else20
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB83_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB83_16
; CHECK-NEXT:  .LBB83_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastss (%rax), %ymm0
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = bitcast <4 x i64> %mask to <8 x float>
  %c = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> %b, i8 4)
  ret <8 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s4p32f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 4)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s4p32f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB85_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB85_3
; CHECK-NEXT:  .LBB85_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB85_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB85_4
; CHECK-NEXT:  .LBB85_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <2 x double>
  %c = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> %b, i8 4)
  ret <2 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s4p32f64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p32f64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 4)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s4p32f64v4m0Dv2_xDv4_dDv4_x(<2 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p32f64v4m0Dv2_xDv4_dDv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB87_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB87_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB87_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB87_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB87_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB87_7
; CHECK-NEXT:  .LBB87_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB87_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB87_8
; CHECK-NEXT:  .LBB87_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <4 x i64> %mask to <4 x double>
  %c = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> %b, i8 4)
  ret <4 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s4p64f32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64f32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],zero,zero
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 4)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s4p64f32v2m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64f32v2m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB89_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB89_3
; CHECK-NEXT:  .LBB89_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB89_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpblendd {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB89_4
; CHECK-NEXT:  .LBB89_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> %a, i8 4)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s4p64f32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64f32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 4)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s4p64f32v4m0Dv4_xDv4_fDv2_x(<4 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64f32v4m0Dv4_xDv4_fDv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB91_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB91_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB91_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB91_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB91_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB91_7
; CHECK-NEXT:  .LBB91_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB91_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB91_8
; CHECK-NEXT:  .LBB91_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> %a, i8 4)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s4p64f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 4)
  ret <2 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s4p64f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB93_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB93_3
; CHECK-NEXT:  .LBB93_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB93_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB93_4
; CHECK-NEXT:  .LBB93_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <2 x double>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> %a, i8 4)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s4p64f64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s4p64f64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 4)
  ret <4 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s4p64f64v4m0Dv4_xDv4_dS_(<4 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s4p64f64v4m0Dv4_xDv4_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $2, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB95_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB95_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB95_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB95_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB95_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB95_7
; CHECK-NEXT:  .LBB95_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB95_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB95_8
; CHECK-NEXT:  .LBB95_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %mask to <4 x double>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> %a, i8 4)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s8p32i32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32i32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 8)
  %c = bitcast <4 x i32> %b to <2 x i64>
  ret <2 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s8p32i32v4m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32i32v4m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB97_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB97_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB97_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB97_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB97_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB97_7
; CHECK-NEXT:  .LBB97_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB97_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB97_8
; CHECK-NEXT:  .LBB97_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %index to <4 x i32>
  %c = bitcast <2 x i64> %mask to <4 x i32>
  %d = tail call <4 x i32> @llvm.x86.avx2.gather.d.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %b, <4 x i32> %c, i8 8)
  %e = bitcast <4 x i32> %d to <2 x i64>
  ret <2 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s8p32i32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32i32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpsllq $3, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm2, %xmm2
; CHECK-NEXT:    vpinsrd $2, (%r8), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpinsrd $3, (%rdi), %xmm2, %xmm0
; CHECK-NEXT:    vmovd {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm2, %xmm2
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vpinsrd $2, (%rax), %xmm2, %xmm1
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x i32> <i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1, i32 -1>, i8 8)
  %c = bitcast <8 x i32> %b to <4 x i64>
  ret <4 x i64> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s8p32i32v8m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32i32v8m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpsllq $3, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB99_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB99_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB99_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB99_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB99_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm4
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB99_6: # %else5
; CHECK-NEXT:    vpsllq $3, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB99_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $3, (%rcx), %xmm1, %xmm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB99_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB99_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB99_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB99_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB99_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB99_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB99_15
; CHECK-NEXT:  .LBB99_16: # %else20
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB99_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastd (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB99_16
; CHECK-NEXT:  .LBB99_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastd (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %src to <8 x i32>
  %b = bitcast <4 x i64> %index to <8 x i32>
  %c = bitcast <4 x i64> %mask to <8 x i32>
  %d = tail call <8 x i32> @llvm.x86.avx2.gather.d.d.256(<8 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %b, <8 x i32> %c, i8 8)
  %e = bitcast <8 x i32> %d to <4 x i64>
  ret <4 x i64> %e
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s8p32i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> <i64 -1, i64 -1>, i8 8)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s8p32i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB101_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB101_3
; CHECK-NEXT:  .LBB101_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB101_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB101_4
; CHECK-NEXT:  .LBB101_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <2 x i64> @llvm.x86.avx2.gather.d.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x i64> %mask, i8 8)
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s8p32i64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32i64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 8)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s8p32i64v4m0Dv2_xDv4_xS0_(<2 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32i64v4m0Dv2_xDv4_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB103_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB103_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB103_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB103_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB103_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB103_7
; CHECK-NEXT:  .LBB103_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB103_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB103_8
; CHECK-NEXT:  .LBB103_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call <4 x i64> @llvm.x86.avx2.gather.d.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x i64> %mask, i8 8)
  ret <4 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s8p64i32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64i32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vmovd {{.*#+}} xmm1 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpunpckldq {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[1],xmm0[1]
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm0[0],zero
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 8)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s8p64i32v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64i32v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsrld $31, %xmm2, %xmm2
; CHECK-NEXT:    vpmovzxdq {{.*#+}} xmm2 = xmm2[0],zero,xmm2[1],zero
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vpsllq $63, %xmm2, %xmm2
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB105_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB105_3
; CHECK-NEXT:  .LBB105_4: # %else2
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB105_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB105_4
; CHECK-NEXT:  .LBB105_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovq {{.*#+}} xmm0 = xmm1[0],zero
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x i32> %b, i8 8)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s8p64i32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64i32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vpinsrd $1, (%rax), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $2, (%rdx), %xmm0, %xmm0
; CHECK-NEXT:    vpinsrd $3, (%rsi), %xmm0, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> <i32 -1, i32 -1, i32 -1, i32 -1>, i8 8)
  %b = bitcast <4 x i32> %a to <2 x i64>
  ret <2 x i64> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s8p64i32v4m0Dv4_xDv2_xS0_(<4 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64i32v4m0Dv4_xDv2_xS0_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB107_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB107_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB107_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $1, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:  .LBB107_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB107_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB107_7
; CHECK-NEXT:  .LBB107_8: # %else8
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB107_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrd $2, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB107_8
; CHECK-NEXT:  .LBB107_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrd $3, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %src to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x i32>
  %c = tail call <4 x i32> @llvm.x86.avx2.gather.q.d.256(<4 x i32> %a, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i32> %b, i8 8)
  %d = bitcast <4 x i32> %c to <2 x i64>
  ret <2 x i64> %d
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z10s8p64i64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64i64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> <i64 -1, i64 -1>, i8 8)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x i64> @_Z12s8p64i64v2m0Dv2_xS_S_(<2 x i64> noundef %index, <2 x i64> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64i64v2m0Dv2_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB109_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB109_3
; CHECK-NEXT:  .LBB109_4: # %else2
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB109_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $0, (%rcx), %xmm1, %xmm1
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB109_4
; CHECK-NEXT:  .LBB109_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpinsrq $1, (%rax), %xmm1, %xmm1
; CHECK-NEXT:    vmovdqa %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <2 x i64> @llvm.x86.avx2.gather.q.q(<2 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x i64> %mask, i8 8)
  ret <2 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z10s8p64i64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64i64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vmovlhps {{.*#+}} xmm1 = xmm2[0],xmm1[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> <i64 -1, i64 -1, i64 -1, i64 -1>, i8 8)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x i64> @_Z12s8p64i64v4m0Dv4_xS_S_(<4 x i64> noundef %index, <4 x i64> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64i64v4m0Dv4_xS_S_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB111_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB111_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB111_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vpinsrq $1, (%rcx), %xmm1, %xmm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB111_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB111_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB111_7
; CHECK-NEXT:  .LBB111_8: # %else8
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB111_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vpbroadcastq (%rcx), %ymm2
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4,5],ymm1[6,7]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB111_8
; CHECK-NEXT:  .LBB111_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vpbroadcastq (%rax), %ymm0
; CHECK-NEXT:    vpblendd {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm0[6,7]
; CHECK-NEXT:    vmovdqa %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call <4 x i64> @llvm.x86.avx2.gather.q.q.256(<4 x i64> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x i64> %mask, i8 8)
  ret <4 x i64> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s8p32f32v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32f32v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 8)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s8p32f32v4m0Dv2_xDv4_fS_(<2 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32f32v4m0Dv2_xDv4_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB113_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB113_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB113_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB113_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB113_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB113_7
; CHECK-NEXT:  .LBB113_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB113_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB113_8
; CHECK-NEXT:  .LBB113_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <4 x float>
  %c = tail call fast <4 x float> @llvm.x86.avx2.gather.d.ps(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x float> %b, i8 8)
  ret <4 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z10s8p32f32v8Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32f32v8Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm2
; CHECK-NEXT:    vpmovsxdq %xmm2, %ymm2
; CHECK-NEXT:    vpsllq $3, %ymm2, %ymm2
; CHECK-NEXT:    vpaddq %ymm2, %ymm1, %ymm2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1
; CHECK-NEXT:    vpextrq $1, %xmm1, %rcx
; CHECK-NEXT:    vmovq %xmm2, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm2, %rsi
; CHECK-NEXT:    vextracti128 $1, %ymm2, %xmm2
; CHECK-NEXT:    vpextrq $1, %xmm2, %rdi
; CHECK-NEXT:    vmovq %xmm2, %r8
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm2[0,1,2],mem[0]
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm2[0],mem[0],xmm2[2,3]
; CHECK-NEXT:    vmovq %xmm1, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm2[0,1],mem[0],xmm2[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 8)
  ret <8 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <8 x float> @_Z12s8p32f32v8m0Dv4_xDv8_fS_(<4 x i64> noundef %index, <8 x float> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32f32v8m0Dv4_xDv8_fS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm4
; CHECK-NEXT:    vpsllq $3, %ymm4, %ymm4
; CHECK-NEXT:    vpaddq %ymm4, %ymm3, %ymm4
; CHECK-NEXT:    vmovmskps %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB115_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm4, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3,4,5,6,7]
; CHECK-NEXT:  .LBB115_2: # %else
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB115_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm4, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm2 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm2[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB115_4: # %else2
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm2
; CHECK-NEXT:    vextracti128 $1, %ymm4, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    je .LBB115_6
; CHECK-NEXT:  # %bb.5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm4 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm4[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB115_6: # %else5
; CHECK-NEXT:    vpsllq $3, %ymm2, %ymm2
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB115_8
; CHECK-NEXT:  # %bb.7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:  .LBB115_8: # %else8
; CHECK-NEXT:    vpaddq %ymm2, %ymm3, %ymm0
; CHECK-NEXT:    testb $16, %al
; CHECK-NEXT:    je .LBB115_10
; CHECK-NEXT:  # %bb.9: # %cond.load10
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3],ymm2[4],ymm1[5,6,7]
; CHECK-NEXT:  .LBB115_10: # %else11
; CHECK-NEXT:    testb $32, %al
; CHECK-NEXT:    je .LBB115_12
; CHECK-NEXT:  # %bb.11: # %cond.load13
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4],ymm2[5],ymm1[6,7]
; CHECK-NEXT:  .LBB115_12: # %else14
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $64, %al
; CHECK-NEXT:    jne .LBB115_13
; CHECK-NEXT:  # %bb.14: # %else17
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    jne .LBB115_15
; CHECK-NEXT:  .LBB115_16: # %else20
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB115_13: # %cond.load16
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastss (%rcx), %ymm2
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5],ymm2[6],ymm1[7]
; CHECK-NEXT:    testb $-128, %al
; CHECK-NEXT:    je .LBB115_16
; CHECK-NEXT:  .LBB115_15: # %cond.load19
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastss (%rax), %ymm0
; CHECK-NEXT:    vblendps {{.*#+}} ymm1 = ymm1[0,1,2,3,4,5,6],ymm0[7]
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %index to <8 x i32>
  %b = bitcast <4 x i64> %mask to <8 x float>
  %c = tail call fast <8 x float> @llvm.x86.avx2.gather.d.ps.256(<8 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <8 x i32> %a, <8 x float> %b, i8 8)
  ret <8 x float> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s8p32f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 8)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s8p32f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %xmm0
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB117_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB117_3
; CHECK-NEXT:  .LBB117_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB117_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB117_4
; CHECK-NEXT:  .LBB117_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <2 x i64> %mask to <2 x double>
  %c = tail call fast <2 x double> @llvm.x86.avx2.gather.d.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <2 x double> %b, i8 8)
  ret <2 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s8p32f64v4Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p32f64v4Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 8)
  ret <4 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s8p32f64v4m0Dv2_xDv4_dDv4_x(<2 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p32f64v4m0Dv2_xDv4_dDv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpmovsxdq %xmm0, %ymm0
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB119_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB119_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB119_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB119_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB119_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB119_7
; CHECK-NEXT:  .LBB119_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB119_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB119_8
; CHECK-NEXT:  .LBB119_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %index to <4 x i32>
  %b = bitcast <4 x i64> %mask to <4 x double>
  %c = tail call fast <4 x double> @llvm.x86.avx2.gather.d.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i32> %a, <4 x double> %b, i8 8)
  ret <4 x double> %c
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s8p64f32v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64f32v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],zero,zero
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 8)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z10s8p64f32v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64f32v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],mem[0],xmm0[2,3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],mem[0],xmm0[3]
; CHECK-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],mem[0]
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> <float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000>, i8 8)
  ret <4 x float> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x float> @_Z12s8p64f32v4m0Dv4_xDv4_fDv2_x(<4 x i64> noundef %index, <4 x float> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64f32v4m0Dv4_xDv4_fDv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskps %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB122_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovss {{.*#+}} xmm2 = mem[0],zero,zero,zero
; CHECK-NEXT:    vblendps {{.*#+}} xmm1 = xmm2[0],xmm1[1,2,3]
; CHECK-NEXT:  .LBB122_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB122_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0],mem[0],xmm1[2,3]
; CHECK-NEXT:  .LBB122_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB122_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB122_7
; CHECK-NEXT:  .LBB122_8: # %else8
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB122_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1],mem[0],xmm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB122_8
; CHECK-NEXT:  .LBB122_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vinsertps {{.*#+}} xmm1 = xmm1[0,1,2],mem[0]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <4 x float>
  %b = tail call fast <4 x float> @llvm.x86.avx2.gather.q.ps.256(<4 x float> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x float> %a, i8 8)
  ret <4 x float> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z10s8p64f64v2Dv2_x(<2 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64f64v2Dv2_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %xmm1
; CHECK-NEXT:    vpaddq %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rax
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 8)
  ret <2 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <2 x double> @_Z12s8p64f64v2m0Dv2_xDv2_dS_(<2 x i64> noundef %index, <2 x double> noundef %src, <2 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64f64v2m0Dv2_xDv2_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %xmm0, %xmm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %xmm3
; CHECK-NEXT:    vpaddq %xmm0, %xmm3, %xmm0
; CHECK-NEXT:    vmovmskpd %xmm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    jne .LBB124_1
; CHECK-NEXT:  # %bb.2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    jne .LBB124_3
; CHECK-NEXT:  .LBB124_4: # %else2
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB124_1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovlps {{.*#+}} xmm1 = mem[0,1],xmm1[2,3]
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB124_4
; CHECK-NEXT:  .LBB124_3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <2 x i64> %mask to <2 x double>
  %b = tail call fast <2 x double> @llvm.x86.avx2.gather.q.pd(<2 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <2 x i64> %index, <2 x double> %a, i8 8)
  ret <2 x double> %b
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z10s8p64f64v4Dv4_x(<4 x i64> noundef %index) local_unnamed_addr {
; CHECK-LABEL: _Z10s8p64f64v4Dv4_x:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm1
; CHECK-NEXT:    vpbroadcastq %xmm1, %ymm1
; CHECK-NEXT:    vpaddq %ymm0, %ymm1, %ymm0
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    vmovq %xmm0, %rdx
; CHECK-NEXT:    vpextrq $1, %xmm0, %rsi
; CHECK-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm0 = xmm0[0,1],mem[0,1]
; CHECK-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; CHECK-NEXT:    vmovhps {{.*#+}} xmm1 = xmm1[0,1],mem[0,1]
; CHECK-NEXT:    vinsertf128 $1, %xmm0, %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> zeroinitializer, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> <double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF, double 0xFFFFFFFFFFFFFFFF>, i8 8)
  ret <4 x double> %a
}

; Function Attrs: mustprogress nofree nounwind readonly willreturn uwtable
define dso_local noundef <4 x double> @_Z12s8p64f64v4m0Dv4_xDv4_dS_(<4 x i64> noundef %index, <4 x double> noundef %src, <4 x i64> noundef %mask) local_unnamed_addr {
; CHECK-LABEL: _Z12s8p64f64v4m0Dv4_xDv4_dS_:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vpsllq $3, %ymm0, %ymm0
; CHECK-NEXT:    movl $int_base, %eax
; CHECK-NEXT:    vmovq %rax, %xmm3
; CHECK-NEXT:    vpbroadcastq %xmm3, %ymm3
; CHECK-NEXT:    vpaddq %ymm0, %ymm3, %ymm0
; CHECK-NEXT:    vmovmskpd %ymm2, %eax
; CHECK-NEXT:    testb $1, %al
; CHECK-NEXT:    je .LBB126_2
; CHECK-NEXT:  # %bb.1: # %cond.load
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vmovsd {{.*#+}} xmm2 = mem[0],zero
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0],ymm1[1,2,3]
; CHECK-NEXT:  .LBB126_2: # %else
; CHECK-NEXT:    testb $2, %al
; CHECK-NEXT:    je .LBB126_4
; CHECK-NEXT:  # %bb.3: # %cond.load1
; CHECK-NEXT:    vpextrq $1, %xmm0, %rcx
; CHECK-NEXT:    vmovhpd {{.*#+}} xmm2 = xmm1[0],mem[0]
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm2[0,1],ymm1[2,3]
; CHECK-NEXT:  .LBB126_4: # %else2
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0
; CHECK-NEXT:    testb $4, %al
; CHECK-NEXT:    jne .LBB126_5
; CHECK-NEXT:  # %bb.6: # %else5
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    jne .LBB126_7
; CHECK-NEXT:  .LBB126_8: # %else8
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
; CHECK-NEXT:  .LBB126_5: # %cond.load4
; CHECK-NEXT:    vmovq %xmm0, %rcx
; CHECK-NEXT:    vbroadcastsd (%rcx), %ymm2
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1],ymm2[2],ymm1[3]
; CHECK-NEXT:    testb $8, %al
; CHECK-NEXT:    je .LBB126_8
; CHECK-NEXT:  .LBB126_7: # %cond.load7
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax
; CHECK-NEXT:    vbroadcastsd (%rax), %ymm0
; CHECK-NEXT:    vblendpd {{.*#+}} ymm1 = ymm1[0,1,2],ymm0[3]
; CHECK-NEXT:    vmovapd %ymm1, %ymm0
; CHECK-NEXT:    retq
entry:
  %a = bitcast <4 x i64> %mask to <4 x double>
  %b = tail call fast <4 x double> @llvm.x86.avx2.gather.q.pd.256(<4 x double> %src, i8* bitcast ([0 x i32]* @int_base to i8*), <4 x i64> %index, <4 x double> %a, i8 8)
  ret <4 x double> %b
}
