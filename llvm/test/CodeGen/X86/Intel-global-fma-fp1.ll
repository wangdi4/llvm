; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; INTEL_CUSTOMIZATION:
; This test checks that Global FMA optimizes an arbitrary (1 of ~40k) test case
; using 1.0 fp const.
; For the input expression:
;   +acd+a+b
; the output code must have 2 arithmetic instructions:
;   F0=+c*d+1; F1=+F0*a+b;

; The tests are started with AVX2 and with SKX flags. The generated code is
; different now because the FMA form selection optimization is not enabled for
; SKX opcodes. the code should become identical for AVX2 and SKX after the
; FMA form selection is enabled for SKX.

; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=core-avx2 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=small -relocation-model=pic | FileCheck --check-prefix=SML %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=skx       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=small -relocation-model=pic | FileCheck --check-prefix=SML %s

; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=core-avx2 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=large | FileCheck --check-prefix=LRG %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=skx       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=large | FileCheck --check-prefix=LRG %s

; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=core-avx2 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=OTHER --check-prefix=AVX2OTHER %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=skx       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=OTHER --check-prefix=SKXOTHER %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mcpu=knl       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=OTHER --check-prefix=KNLOTHER %s

; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown -mcpu=core-avx2 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=X86OTHER --check-prefix=X86AVX2OTHER %s
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown -mcpu=skx       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=X86OTHER --check-prefix=X86SKXOTHER %s
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown -mcpu=knl       -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=X86OTHER --check-prefix=X86KNLOTHER %s

attributes #0 = { nounwind }

define float @test_ss(float %a32, float %b32, float %c32, float %d32) #0 {
; SML-LABEL: test_ss:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; SML-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_ss:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; LRG-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_ss:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; OTHER-NEXT:    vmovd %eax, %xmm4
; OTHER-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; OTHER-NEXT:    vfmadd213ss {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ss:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %eax
; X86OTHER-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86OTHER-NEXT:    vmovss {{.*#+}} xmm1 = mem[0],zero,zero,zero
; X86OTHER-NEXT:    vfmadd231ss {{.*#+}} xmm1 = (xmm0 * mem) + xmm1
; X86OTHER-NEXT:    vmovss {{.*#+}} xmm0 = mem[0],zero,zero,zero
; X86OTHER-NEXT:    vfmadd231ss {{.*#+}} xmm0 = (xmm1 * mem) + xmm0
; X86OTHER-NEXT:    vmovss %xmm0, (%esp)
; X86OTHER-NEXT:    flds (%esp)
; X86OTHER-NEXT:    popl %eax
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast float %a32, %d32
  %mul1 = fmul fast float %mul, %c32
  %add = fadd fast float %mul1, %d32
  %add2 = fadd fast float %add, %b32
  ret float %add2
}

define double @test_sd(double %a64, double %b64, double %c64, double %d64) #0 {
; SML-LABEL: test_sd:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; SML-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_sd:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; LRG-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_sd:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; OTHER-NEXT:    vmovq %rax, %xmm4
; OTHER-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; OTHER-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_sd:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-8, %esp
; X86OTHER-NEXT:    subl $8, %esp
; X86OTHER-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86OTHER-NEXT:    vmovsd {{.*#+}} xmm1 = mem[0],zero
; X86OTHER-NEXT:    vfmadd231sd {{.*#+}} xmm1 = (xmm0 * mem) + xmm1
; X86OTHER-NEXT:    vmovsd {{.*#+}} xmm0 = mem[0],zero
; X86OTHER-NEXT:    vfmadd231sd {{.*#+}} xmm0 = (xmm1 * mem) + xmm0
; X86OTHER-NEXT:    vmovsd %xmm0, (%esp)
; X86OTHER-NEXT:    fldl (%esp)
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast double %a64, %d64
  %mul1 = fmul fast double %mul, %c64
  %add = fadd fast double %mul1, %d64
  %add2 = fadd fast double %add, %b64
  ret double %add2
}

define <4 x float> @test_ps(<4 x float> %a32, <4 x float> %b32, <4 x float> %c32, <4 x float> %d32) #0 {
; SML-LABEL: test_ps:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; SML-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_ps:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; LRG-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; LRG-NEXT:    retq
;
; AVX2OTHER-LABEL: test_ps:
; AVX2OTHER:       # %bb.0: # %entry
; AVX2OTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; AVX2OTHER-NEXT:    vmovd %eax, %xmm4
; AVX2OTHER-NEXT:    vpbroadcastd %xmm4, %xmm4
; AVX2OTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; AVX2OTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; AVX2OTHER-NEXT:    retq
;
; SKXOTHER-LABEL: test_ps:
; SKXOTHER:       # %bb.0: # %entry
; SKXOTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; SKXOTHER-NEXT:    vpbroadcastd %eax, %xmm4
; SKXOTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; SKXOTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SKXOTHER-NEXT:    retq
;
; KNLOTHER-LABEL: test_ps:
; KNLOTHER:       # %bb.0: # %entry
; KNLOTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; KNLOTHER-NEXT:    vpbroadcastd %eax, %zmm4
; KNLOTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; KNLOTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; KNLOTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ps:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-16, %esp
; X86OTHER-NEXT:    subl $16, %esp
; X86OTHER-NEXT:    vfmadd213ps {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; X86OTHER-NEXT:    vfmadd132ps {{.*#+}} xmm0 = (xmm0 * mem) + xmm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <4 x float> %a32, %d32
  %mul1 = fmul fast <4 x float> %mul, %c32
  %add = fadd fast <4 x float> %mul1, %d32
  %add2 = fadd fast <4 x float> %add, %b32
  ret <4 x float> %add2
}

define <2 x double> @test_pd(<2 x double> %a32, <2 x double> %b32, <2 x double> %c32, <2 x double> %d32) #0 {
; SML-LABEL: test_pd:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; SML-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_pd:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; LRG-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; LRG-NEXT:    retq
;
; AVX2OTHER-LABEL: test_pd:
; AVX2OTHER:       # %bb.0: # %entry
; AVX2OTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; AVX2OTHER-NEXT:    vmovq %rax, %xmm4
; AVX2OTHER-NEXT:    vpbroadcastq %xmm4, %xmm4
; AVX2OTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; AVX2OTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; AVX2OTHER-NEXT:    retq
;
; SKXOTHER-LABEL: test_pd:
; SKXOTHER:       # %bb.0: # %entry
; SKXOTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; SKXOTHER-NEXT:    vpbroadcastq %rax, %xmm4
; SKXOTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; SKXOTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; SKXOTHER-NEXT:    retq
;
; KNLOTHER-LABEL: test_pd:
; KNLOTHER:       # %bb.0: # %entry
; KNLOTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; KNLOTHER-NEXT:    vpbroadcastq %rax, %zmm4
; KNLOTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + xmm4
; KNLOTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm3 * xmm0) + xmm1
; KNLOTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_pd:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-16, %esp
; X86OTHER-NEXT:    subl $16, %esp
; X86OTHER-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm2 * xmm0) + mem
; X86OTHER-NEXT:    vfmadd132pd {{.*#+}} xmm0 = (xmm0 * mem) + xmm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <2 x double> %a32, %d32
  %mul1 = fmul fast <2 x double> %mul, %c32
  %add = fadd fast <2 x double> %mul1, %d32
  %add2 = fadd fast <2 x double> %add, %b32
  ret <2 x double> %add2
}

define <8 x float> @test_ps256(<8 x float> %a32, <8 x float> %b32, <8 x float> %c32, <8 x float> %d32) #0 {
; SML-LABEL: test_ps256:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; SML-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_ps256:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; LRG-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; LRG-NEXT:    retq
;
; AVX2OTHER-LABEL: test_ps256:
; AVX2OTHER:       # %bb.0: # %entry
; AVX2OTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; AVX2OTHER-NEXT:    vmovd %eax, %xmm4
; AVX2OTHER-NEXT:    vpbroadcastd %xmm4, %ymm4
; AVX2OTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; AVX2OTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; AVX2OTHER-NEXT:    retq
;
; SKXOTHER-LABEL: test_ps256:
; SKXOTHER:       # %bb.0: # %entry
; SKXOTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; SKXOTHER-NEXT:    vpbroadcastd %eax, %ymm4
; SKXOTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; SKXOTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; SKXOTHER-NEXT:    retq
;
; KNLOTHER-LABEL: test_ps256:
; KNLOTHER:       # %bb.0: # %entry
; KNLOTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; KNLOTHER-NEXT:    vpbroadcastd %eax, %zmm4
; KNLOTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; KNLOTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; KNLOTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ps256:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-32, %esp
; X86OTHER-NEXT:    subl $32, %esp
; X86OTHER-NEXT:    vfmadd213ps {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; X86OTHER-NEXT:    vfmadd132ps {{.*#+}} ymm0 = (ymm0 * mem) + ymm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <8 x float> %a32, %d32
  %mul1 = fmul fast <8 x float> %mul, %c32
  %add = fadd fast <8 x float> %mul1, %d32
  %add2 = fadd fast <8 x float> %add, %b32
  ret <8 x float> %add2
}

define <4 x double> @test_pd256(<4 x double> %a32, <4 x double> %b32, <4 x double> %c32, <4 x double> %d32) #0 {
; SML-LABEL: test_pd256:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; SML-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_pd256:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; LRG-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; LRG-NEXT:    retq
;
; AVX2OTHER-LABEL: test_pd256:
; AVX2OTHER:       # %bb.0: # %entry
; AVX2OTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; AVX2OTHER-NEXT:    vmovq %rax, %xmm4
; AVX2OTHER-NEXT:    vpbroadcastq %xmm4, %ymm4
; AVX2OTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; AVX2OTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; AVX2OTHER-NEXT:    retq
;
; SKXOTHER-LABEL: test_pd256:
; SKXOTHER:       # %bb.0: # %entry
; SKXOTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; SKXOTHER-NEXT:    vpbroadcastq %rax, %ymm4
; SKXOTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; SKXOTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; SKXOTHER-NEXT:    retq
;
; KNLOTHER-LABEL: test_pd256:
; KNLOTHER:       # %bb.0: # %entry
; KNLOTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; KNLOTHER-NEXT:    vpbroadcastq %rax, %zmm4
; KNLOTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + ymm4
; KNLOTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm3 * ymm0) + ymm1
; KNLOTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_pd256:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-32, %esp
; X86OTHER-NEXT:    subl $32, %esp
; X86OTHER-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm2 * ymm0) + mem
; X86OTHER-NEXT:    vfmadd132pd {{.*#+}} ymm0 = (ymm0 * mem) + ymm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <4 x double> %a32, %d32
  %mul1 = fmul fast <4 x double> %mul, %c32
  %add = fadd fast <4 x double> %mul1, %d32
  %add2 = fadd fast <4 x double> %add, %b32
  ret <4 x double> %add2
}

attributes #1 = { nounwind "target-cpu"="skx" "target-features"="+avx512f,+fma" }

define <16 x float> @test_ps512(<16 x float> %a32, <16 x float> %b32, <16 x float> %c32, <16 x float> %d32) #1 {
; SML-LABEL: test_ps512:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; SML-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_ps512:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; LRG-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_ps512:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $1065353216, %eax # imm = 0x3F800000
; OTHER-NEXT:    vpbroadcastd %eax, %zmm4
; OTHER-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm2 * zmm0) + zmm4
; OTHER-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ps512:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-64, %esp
; X86OTHER-NEXT:    subl $64, %esp
; X86OTHER-NEXT:    vfmadd213ps {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; X86OTHER-NEXT:    vfmadd132ps {{.*#+}} zmm0 = (zmm0 * mem) + zmm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <16 x float> %a32, %d32
  %mul1 = fmul fast <16 x float> %mul, %c32
  %add = fadd fast <16 x float> %mul1, %d32
  %add2 = fadd fast <16 x float> %add, %b32
  ret <16 x float> %add2
}

define <8 x double> @test_pd512(<8 x double> %a32, <8 x double> %b32, <8 x double> %c32, <8 x double> %d32) #1 {
; SML-LABEL: test_pd512:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; SML-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; SML-NEXT:    retq
;
; LRG-LABEL: test_pd512:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.LCPI.*}}, %rax
; LRG-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; LRG-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_pd512:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movabsq $4607182418800017408, %rax # imm = 0x3FF0000000000000
; OTHER-NEXT:    vpbroadcastq %rax, %zmm4
; OTHER-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm2 * zmm0) + zmm4
; OTHER-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm3 * zmm0) + zmm1
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_pd512:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    andl $-64, %esp
; X86OTHER-NEXT:    subl $64, %esp
; X86OTHER-NEXT:    vfmadd213pd {{.*#+}} zmm0 = (zmm2 * zmm0) + mem
; X86OTHER-NEXT:    vfmadd132pd {{.*#+}} zmm0 = (zmm0 * mem) + zmm1
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <8 x double> %a32, %d32
  %mul1 = fmul fast <8 x double> %mul, %c32
  %add = fadd fast <8 x double> %mul1, %d32
  %add2 = fadd fast <8 x double> %add, %b32
  ret <8 x double> %add2
}
