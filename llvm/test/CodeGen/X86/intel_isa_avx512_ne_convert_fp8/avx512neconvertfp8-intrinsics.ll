; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_ne_convert_fp8
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512neconvertfp8 | FileCheck %s --check-prefixes=CHECK,X64
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512neconvertfp8 | FileCheck %s --check-prefixes=CHECK,X86

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtbias2ph2bf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbias2ph2bf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbias2ph2bf8 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf2,0x75,0x48,0x74,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2bf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2bf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtbias2ph2bf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbias2ph2bf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbias2ph2bf8s %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x74,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2bf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2bf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtbias2ph2hf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbias2ph2hf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbias2ph2hf8 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x18,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2hf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2hf8512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtbias2ph2hf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbias2ph2hf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbias2ph2hf8s %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x1b,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2hf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtbias2ph2hf8s512(<64 x i8> %A, <32 x half> %B, <32 x half> %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtbiasph2bf8512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbiasph2bf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbiasph2bf8 %zmm0, %ymm0 # encoding: [0x62,0xf2,0x7c,0x48,0x74,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2bf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x74,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2bf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x74,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2bf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf2,0x7c,0xc9,0x74,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2bf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf2,0x7c,0xc9,0x74,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtbiasph2bf8s512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbiasph2bf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbiasph2bf8s %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7c,0x48,0x74,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8s512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8s512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2bf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x74,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2bf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2bf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x74,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8s512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2bf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x74,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2bf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2bf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x74,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2bf8s512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtbiasph2hf8512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbiasph2hf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbiasph2hf8 %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7c,0x48,0x18,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2hf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x18,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2hf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x18,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2hf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x18,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2hf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x18,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtbiasph2hf8s512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtbiasph2hf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtbiasph2hf8s %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7c,0x48,0x1b,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8s512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8s512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2hf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x1b,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtbiasph2hf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2hf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7c,0x49,0x1b,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8s512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtbiasph2hf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x1b,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtbiasph2hf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtbiasph2hf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7c,0xc9,0x1b,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtbiasph2hf8s512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtne2ph2bf8512(<32 x half> %A, <32 x half> %B) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtne2ph2bf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtne2ph2bf8 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf2,0x7f,0x48,0x74,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2bf8512(<32 x half> %A, <32 x half> %B)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2bf8512(<32 x half> %A, <32 x half> %B)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtne2ph2bf8s512(<32 x half> %A, <32 x half> %B) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtne2ph2bf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtne2ph2bf8s %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7f,0x48,0x74,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2bf8s512(<32 x half> %A, <32 x half> %B)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2bf8s512(<32 x half> %A, <32 x half> %B)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtne2ph2hf8512(<32 x half> %A, <32 x half> %B) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtne2ph2hf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtne2ph2hf8 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7f,0x48,0x18,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2hf8512(<32 x half> %A, <32 x half> %B)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2hf8512(<32 x half> %A, <32 x half> %B)

define <64 x i8> @test_int_x86_avx512neconvertfp8_vcvtne2ph2hf8s512(<32 x half> %A, <32 x half> %B) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtne2ph2hf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtne2ph2hf8s %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7f,0x48,0x1b,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2hf8s512(<32 x half> %A, <32 x half> %B)
  ret <64 x i8> %ret
}

declare <64 x i8> @llvm.x86.avx512neconvertfp8.vcvtne2ph2hf8s512(<32 x half> %A, <32 x half> %B)

define <32 x half> @test_int_x86_avx512neconvertfp8_vcvtnebf82ph512(<32 x i8> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtnebf82ph512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtnebf82ph %ymm0, %zmm0 # encoding: [0x62,0xf5,0x7e,0x48,0x1e,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnebf82ph512(<32 x i8> %A, <32 x half> undef, i32 -1)
  ret <32 x half> %ret
}

define <32 x half> @test_int_x86_avx512neconvertfp8_mask_vcvtnebf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtnebf82ph512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtnebf82ph %ymm0, %zmm1 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x1e,0xc8]
; X64-NEXT:    vmovdqa64 %zmm1, %zmm0 # encoding: [0x62,0xf1,0xfd,0x48,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtnebf82ph512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtnebf82ph %ymm0, %zmm1 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x1e,0xc8]
; X86-NEXT:    vmovdqa64 %zmm1, %zmm0 # encoding: [0x62,0xf1,0xfd,0x48,0x6f,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnebf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C)
  ret <32 x half> %ret
}

declare <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnebf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C)

define <32 x half> @test_int_x86_avx512neconvertfp8_maskz_vcvtnebf82ph512(<32 x i8> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtnebf82ph512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtnebf82ph %ymm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x1e,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtnebf82ph512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtnebf82ph %ymm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x1e,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnebf82ph512(<32 x i8> %A, <32 x half> zeroinitializer, i32 %B)
  ret <32 x half> %ret
}

define <32 x half> @test_int_x86_avx512neconvertfp8_vcvtnehf82ph512(<32 x i8> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtnehf82ph512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtnehf82ph %ymm0, %zmm0 # encoding: [0x62,0xf5,0x7f,0x48,0x1e,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnehf82ph512(<32 x i8> %A, <32 x half> undef, i32 -1)
  ret <32 x half> %ret
}

define <32 x half> @test_int_x86_avx512neconvertfp8_mask_vcvtnehf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtnehf82ph512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtnehf82ph %ymm0, %zmm1 {%k1} # encoding: [0x62,0xf5,0x7f,0x49,0x1e,0xc8]
; X64-NEXT:    vmovdqa64 %zmm1, %zmm0 # encoding: [0x62,0xf1,0xfd,0x48,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtnehf82ph512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtnehf82ph %ymm0, %zmm1 {%k1} # encoding: [0x62,0xf5,0x7f,0x49,0x1e,0xc8]
; X86-NEXT:    vmovdqa64 %zmm1, %zmm0 # encoding: [0x62,0xf1,0xfd,0x48,0x6f,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnehf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C)
  ret <32 x half> %ret
}

declare <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnehf82ph512(<32 x i8> %A, <32 x half> %B, i32 %C)

define <32 x half> @test_int_x86_avx512neconvertfp8_maskz_vcvtnehf82ph512(<32 x i8> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtnehf82ph512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtnehf82ph %ymm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7f,0xc9,0x1e,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtnehf82ph512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtnehf82ph %ymm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7f,0xc9,0x1e,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x half> @llvm.x86.avx512neconvertfp8.mask.vcvtnehf82ph512(<32 x i8> %A, <32 x half> zeroinitializer, i32 %B)
  ret <32 x half> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtneph2bf8512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtneph2bf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtneph2bf8 %zmm0, %ymm0 # encoding: [0x62,0xf2,0x7e,0x48,0x74,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2bf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf2,0x7e,0x49,0x74,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2bf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf2,0x7e,0x49,0x74,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2bf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf2,0x7e,0xc9,0x74,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2bf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf2,0x7e,0xc9,0x74,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtneph2bf8s512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtneph2bf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtneph2bf8s %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7e,0x48,0x74,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8s512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8s512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2bf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x74,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2bf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2bf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x74,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8s512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2bf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x74,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2bf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2bf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x74,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2bf8s512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtneph2hf8512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtneph2hf8512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtneph2hf8 %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7e,0x48,0x18,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2hf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x18,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2hf8 %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x18,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2hf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x18,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2hf8 %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x18,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_vcvtneph2hf8s512(<32 x half> %A) nounwind {
; CHECK-LABEL: test_int_x86_avx512neconvertfp8_vcvtneph2hf8s512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcvtneph2hf8s %zmm0, %ymm0 # encoding: [0x62,0xf5,0x7e,0x48,0x1b,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8s512(<32 x half> %A, <32 x i8> undef, i32 -1)
  ret <32 x i8> %ret
}

define <32 x i8> @test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8s512(<32 x i8> %B, <32 x half> %A, i32 %C) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2hf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x1b,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_mask_vcvtneph2hf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2hf8s %zmm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x7e,0x49,0x1b,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)
  ret <32 x i8> %ret
}

declare <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8s512(<32 x half> %A, <32 x i8> %B, i32 %C)

define <32 x i8> @test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8s512(<32 x half> %A, i32 %B) nounwind {
; X64-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8s512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vcvtneph2hf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x1b,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512neconvertfp8_maskz_vcvtneph2hf8s512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vcvtneph2hf8s %zmm0, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x7e,0xc9,0x1b,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <32 x i8> @llvm.x86.avx512neconvertfp8.mask.vcvtneph2hf8s512(<32 x half> %A, <32 x i8> zeroinitializer, i32 %B)
  ret <32 x i8> %ret
}
