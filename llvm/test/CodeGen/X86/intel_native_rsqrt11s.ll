; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx2,+fma | FileCheck %s --check-prefixes=AVX

declare double @llvm.sqrt.f64(double)
declare <2 x double> @llvm.sqrt.v2f64(<2 x double>)
declare <4 x double> @llvm.sqrt.v4f64(<4 x double>)

define double @rsqrt_ss_rec_0(double %data) #0 {
; AVX-LABEL: rsqrt_ss_rec_0:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm0
; AVX-NEXT:    vrsqrtss %xmm0, %xmm0, %xmm0
; AVX-NEXT:    vcvtss2sd %xmm0, %xmm0, %xmm0
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_rec_0(<2 x double> %data) #0 {
; AVX-LABEL: rsqrt_v2_rec_0:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm0
; AVX-NEXT:    vrsqrtps %xmm0, %xmm0
; AVX-NEXT:    vcvtps2pd %xmm0, %xmm0
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_rec_0(<4 x double> %data) #0 {
; AVX-LABEL: rsqrt_v4_rec_0:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm0
; AVX-NEXT:    vrsqrtps %xmm0, %xmm0
; AVX-NEXT:    vcvtps2pd %xmm0, %ymm0
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

define double @rsqrt_ss_acc_11(double %data) #1 {
; AVX-LABEL: rsqrt_ss_acc_11:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm0
; AVX-NEXT:    vrsqrtss %xmm0, %xmm0, %xmm0
; AVX-NEXT:    vcvtss2sd %xmm0, %xmm0, %xmm0
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_acc_11(<2 x double> %data) #1 {
; AVX-LABEL: rsqrt_v2_acc_11:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm0
; AVX-NEXT:    vrsqrtps %xmm0, %xmm0
; AVX-NEXT:    vcvtps2pd %xmm0, %xmm0
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_acc_11(<4 x double> %data) #1 {
; AVX-LABEL: rsqrt_v4_acc_11:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm0
; AVX-NEXT:    vrsqrtps %xmm0, %xmm0
; AVX-NEXT:    vcvtps2pd %xmm0, %ymm0
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

define double @rsqrt_ss_rec_1(double %data) #2 {
; AVX-LABEL: rsqrt_ss_rec_1:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm1
; AVX-NEXT:    vrsqrtss %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vcvtss2sd %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm1 * xmm0) + mem
; AVX-NEXT:    vmulsd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_rec_1(<2 x double> %data) #2 {
; AVX-LABEL: rsqrt_v2_rec_1:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm1 * xmm0) + mem
; AVX-NEXT:    vmulpd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_rec_1(<4 x double> %data) #2 {
; AVX-LABEL: rsqrt_v4_rec_1:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm2 = [-3.0E+0,-3.0E+0,-3.0E+0,-3.0E+0]
; AVX-NEXT:    vfmadd231pd {{.*#+}} ymm2 = (ymm1 * ymm0) + ymm2
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm0 = [-5.0E-1,-5.0E-1,-5.0E-1,-5.0E-1]
; AVX-NEXT:    vmulpd %ymm0, %ymm1, %ymm0
; AVX-NEXT:    vmulpd %ymm2, %ymm0, %ymm0
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

define double @rsqrt_ss_acc_23(double %data) #3 {
; AVX-LABEL: rsqrt_ss_acc_23:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm1
; AVX-NEXT:    vrsqrtss %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vcvtss2sd %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovsd {{.*#+}} xmm3 = mem[0],zero
; AVX-NEXT:    vmulsd %xmm3, %xmm1, %xmm0
; AVX-NEXT:    vfnmadd213sd {{.*#+}} xmm0 = -(xmm2 * xmm0) + xmm3
; AVX-NEXT:    vfmadd132sd {{.*#+}} xmm0 = (xmm0 * xmm1) + xmm1
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_acc_23(<2 x double> %data) #3 {
; AVX-LABEL: rsqrt_v2_acc_23:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovddup {{.*#+}} xmm3 = [5.0E-1,5.0E-1]
; AVX-NEXT:    # xmm3 = mem[0,0]
; AVX-NEXT:    vmulpd %xmm3, %xmm1, %xmm0
; AVX-NEXT:    vfnmadd213pd {{.*#+}} xmm0 = -(xmm2 * xmm0) + xmm3
; AVX-NEXT:    vfmadd132pd {{.*#+}} xmm0 = (xmm0 * xmm1) + xmm1
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_acc_23(<4 x double> %data) #3 {
; AVX-LABEL: rsqrt_v4_acc_23:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm2
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm3 = [5.0E-1,5.0E-1,5.0E-1,5.0E-1]
; AVX-NEXT:    vmulpd %ymm3, %ymm1, %ymm0
; AVX-NEXT:    vfnmadd213pd {{.*#+}} ymm0 = -(ymm2 * ymm0) + ymm3
; AVX-NEXT:    vfmadd132pd {{.*#+}} ymm0 = (ymm0 * ymm1) + ymm1
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

define double @rsqrt_ss_rec_2(double %data) #4 {
; AVX-LABEL: rsqrt_ss_rec_2:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm1
; AVX-NEXT:    vrsqrtss %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vcvtss2sd %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovsd {{.*#+}} xmm3 = mem[0],zero
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmovsd {{.*#+}} xmm4 = mem[0],zero
; AVX-NEXT:    vmulsd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm1 * xmm0) + xmm3
; AVX-NEXT:    vmulsd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_rec_2(<2 x double> %data) #4 {
; AVX-LABEL: rsqrt_v2_rec_2:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovddup {{.*#+}} xmm3 = [-3.0E+0,-3.0E+0]
; AVX-NEXT:    # xmm3 = mem[0,0]
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmovddup {{.*#+}} xmm4 = [-5.0E-1,-5.0E-1]
; AVX-NEXT:    # xmm4 = mem[0,0]
; AVX-NEXT:    vmulpd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm1 * xmm0) + xmm3
; AVX-NEXT:    vmulpd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_rec_2(<4 x double> %data) #4 {
; AVX-LABEL: rsqrt_v4_rec_2:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm2
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm3 = [-3.0E+0,-3.0E+0,-3.0E+0,-3.0E+0]
; AVX-NEXT:    vfmadd213pd {{.*#+}} ymm2 = (ymm1 * ymm2) + ymm3
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm4 = [-5.0E-1,-5.0E-1,-5.0E-1,-5.0E-1]
; AVX-NEXT:    vmulpd %ymm4, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm2, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm1 * ymm0) + ymm3
; AVX-NEXT:    vmulpd %ymm4, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm0, %ymm1, %ymm0
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

define double @rsqrt_ss_rec_3(double %data) #5 {
; AVX-LABEL: rsqrt_ss_rec_3:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtsd2ss %xmm0, %xmm0, %xmm1
; AVX-NEXT:    vrsqrtss %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vcvtss2sd %xmm1, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovsd {{.*#+}} xmm3 = mem[0],zero
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmovsd {{.*#+}} xmm4 = mem[0],zero
; AVX-NEXT:    vmulsd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmulsd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213sd {{.*#+}} xmm0 = (xmm1 * xmm0) + xmm3
; AVX-NEXT:    vmulsd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulsd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    retq
    %sqrt = tail call double @llvm.sqrt.f64(double %data)
    %div = fdiv fast double 1.0, %sqrt
    ret double %div
}

define <2 x double> @rsqrt_v2_rec_3(<2 x double> %data) #5 {
; AVX-LABEL: rsqrt_v2_rec_3:
; AVX:       # %bb.0:
; AVX-NEXT:    # kill: def $xmm0 killed $xmm0 def $ymm0
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vmovddup {{.*#+}} xmm3 = [-3.0E+0,-3.0E+0]
; AVX-NEXT:    # xmm3 = mem[0,0]
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmovddup {{.*#+}} xmm4 = [-5.0E-1,-5.0E-1]
; AVX-NEXT:    # xmm4 = mem[0,0]
; AVX-NEXT:    vmulpd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm2
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm2 = (xmm1 * xmm2) + xmm3
; AVX-NEXT:    vmulpd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm2, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm1, %xmm0, %xmm0
; AVX-NEXT:    vfmadd213pd {{.*#+}} xmm0 = (xmm1 * xmm0) + xmm3
; AVX-NEXT:    vmulpd %xmm4, %xmm1, %xmm1
; AVX-NEXT:    vmulpd %xmm0, %xmm1, %xmm0
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
    %sqrt = tail call <2 x double> @llvm.sqrt.v2f64(<2 x double> %data)
    %div = fdiv fast <2 x double> <double 1.0, double 1.0>, %sqrt
    ret <2 x double> %div
}

define <4 x double> @rsqrt_v4_rec_3(<4 x double> %data) #5 {
; AVX-LABEL: rsqrt_v4_rec_3:
; AVX:       # %bb.0:
; AVX-NEXT:    vcvtpd2ps %ymm0, %xmm1
; AVX-NEXT:    vrsqrtps %xmm1, %xmm1
; AVX-NEXT:    vcvtps2pd %xmm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm2
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm3 = [-3.0E+0,-3.0E+0,-3.0E+0,-3.0E+0]
; AVX-NEXT:    vfmadd213pd {{.*#+}} ymm2 = (ymm1 * ymm2) + ymm3
; AVX-NEXT:    vbroadcastsd {{.*#+}} ymm4 = [-5.0E-1,-5.0E-1,-5.0E-1,-5.0E-1]
; AVX-NEXT:    vmulpd %ymm4, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm2, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm2
; AVX-NEXT:    vfmadd213pd {{.*#+}} ymm2 = (ymm1 * ymm2) + ymm3
; AVX-NEXT:    vmulpd %ymm4, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm2, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vfmadd213pd {{.*#+}} ymm0 = (ymm1 * ymm0) + ymm3
; AVX-NEXT:    vmulpd %ymm4, %ymm1, %ymm1
; AVX-NEXT:    vmulpd %ymm0, %ymm1, %ymm0
; AVX-NEXT:    retq
    %sqrt = tail call <4 x double> @llvm.sqrt.v4f64(<4 x double> %data)
    %div = fdiv fast <4 x double> <double 1.0, double 1.0, double 1.0, double 1.0>, %sqrt
    ret <4 x double> %div
}

attributes #0 = { "reciprocal-estimates"="sqrt:0,vec-sqrt:0" }
attributes #1 = { "imf-accuracy-bits-sqrt"="11" }

attributes #2 = { "reciprocal-estimates"="sqrt:1,vec-sqrt:1" }
attributes #3 = { "imf-accuracy-bits-sqrt"="22" }

attributes #4 = { "reciprocal-estimates"="sqrt:2,vec-sqrt:2" }
attributes #5 = { "reciprocal-estimates"="sqrt:3,vec-sqrt:3" }

