; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_vpmm
; RUN: llc %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vpmm,+avx512vl -o - | FileCheck %s

; Function Attrs: nounwind uwtable
define dso_local void @test_mm128_vmmxf16_spill(<4 x float>* nocapture noundef %HighPtr, <4 x float>* nocapture noundef %LowPtr, <8 x half> noundef %Src1, <8 x half> noundef %Src2) local_unnamed_addr {
; CHECK-LABEL: test_mm128_vmmxf16_spill:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmovaps (%rsi), %xmm3
; CHECK-NEXT:    vmovaps (%rdi), %xmm2
; CHECK-NEXT:    vmmxf16ps %xmm1, %xmm0, %xmm2
; CHECK-NEXT:    vmovaps %xmm2, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    vmovaps %xmm3, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
; CHECK-NEXT:    #APP
; CHECK-NEXT:    nop
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
; CHECK-NEXT:    vmovaps %xmm0, (%rsi)
; CHECK-NEXT:    vmovaps %xmm1, (%rdi)
; CHECK-NEXT:    retq
entry:
  %0 = load <4 x float>, <4 x float>* %LowPtr, align 16
  %1 = load <4 x float>, <4 x float>* %HighPtr, align 16
  %2 = tail call { <4 x float>, <4 x float> } @llvm.x86.vpmm.vmmxf16ps.128(<4 x float> %1, <4 x float> %0, <8 x half> %Src1, <8 x half> %Src2)
  tail call void asm sideeffect "nop", "~{xmm0},~{xmm1},~{xmm2},~{xmm3},~{xmm4},~{xmm5},~{xmm6},~{xmm7},~{xmm8},~{xmm9},~{xmm11},~{xmm12},~{xmm13},~{xmm14},~{xmm15},~{xmm16},~{xmm17},~{xmm18},~{xmm19},~{xmm20},~{xmm21},~{xmm22},~{xmm23},~{xmm24},~{xmm25},~{xmm26},~{xmm27},~{xmm28},~{xmm29},~{xmm30},~{xmm31},~{dirflag},~{fpsr},~{flags}"()
  %3 = extractvalue { <4 x float>, <4 x float> } %2, 0
  store <4 x float> %3, <4 x float>* %LowPtr, align 16
  %4 = extractvalue { <4 x float>, <4 x float> } %2, 1
  store <4 x float> %4, <4 x float>* %HighPtr, align 16
  ret void
}

; Function Attrs: nounwind uwtable
define dso_local void @test_mm256_vmmxf16_spill(<8 x float>* nocapture noundef %HighPtr, <8 x float>* nocapture noundef %LowPtr, <16 x half> noundef %Src1, <16 x half> noundef %Src2) local_unnamed_addr {
; CHECK-LABEL: test_mm256_vmmxf16_spill:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vmovaps (%rsi), %ymm3
; CHECK-NEXT:    vmovaps (%rdi), %ymm2
; CHECK-NEXT:    vmmxf16ps %ymm1, %ymm0, %ymm2
; CHECK-NEXT:    vmovaps %ymm2, {{[-0-9]+}}(%r{{[sb]}}p) # 32-byte Spill
; CHECK-NEXT:    vmovaps %ymm3, {{[-0-9]+}}(%r{{[sb]}}p) # 32-byte Spill
; CHECK-NEXT:    #APP
; CHECK-NEXT:    nop
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %ymm0 # 32-byte Reload
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %ymm1 # 32-byte Reload
; CHECK-NEXT:    vmovaps %ymm0, (%rsi)
; CHECK-NEXT:    vmovaps %ymm1, (%rdi)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %0 = load <8 x float>, <8 x float>* %LowPtr, align 32
  %1 = load <8 x float>, <8 x float>* %HighPtr, align 32
  %2 = tail call { <8 x float>, <8 x float> } @llvm.x86.vpmm.vmmxf16ps.256(<8 x float> %1, <8 x float> %0, <16 x half> %Src1, <16 x half> %Src2)
  tail call void asm sideeffect "nop", "~{ymm0},~{ymm1},~{ymm2},~{ymm3},~{ymm4},~{ymm5},~{ymm6},~{ymm7},~{ymm8},~{ymm9},~{ymm11},~{ymm12},~{ymm13},~{ymm14},~{ymm15},~{ymm16},~{ymm17},~{ymm18},~{ymm19},~{ymm20},~{ymm21},~{ymm22},~{ymm23},~{ymm24},~{ymm25},~{ymm26},~{ymm27},~{ymm28},~{ymm29},~{ymm30},~{ymm31},~{dirflag},~{fpsr},~{flags}"()
  %3 = extractvalue { <8 x float>, <8 x float> } %2, 0
  store <8 x float> %3, <8 x float>* %LowPtr, align 32
  %4 = extractvalue { <8 x float>, <8 x float> } %2, 1
  store <8 x float> %4, <8 x float>* %HighPtr, align 32
  ret void
}

; Function Attrs: nounwind uwtable
define dso_local void @test_mm512_vmmxf16_spill(<16 x float>* nocapture noundef %HighPtr, <16 x float>* nocapture noundef %LowPtr, <32 x half> noundef %Src1, <32 x half> noundef %Src2) local_unnamed_addr {
; CHECK-LABEL: test_mm512_vmmxf16_spill:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    pushq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    vmovaps (%rsi), %zmm3
; CHECK-NEXT:    vmovaps (%rdi), %zmm2
; CHECK-NEXT:    vmmxf16ps %zmm1, %zmm0, %zmm2
; CHECK-NEXT:    vmovaps %zmm2, {{[-0-9]+}}(%r{{[sb]}}p) # 64-byte Spill
; CHECK-NEXT:    vmovaps %zmm3, {{[-0-9]+}}(%r{{[sb]}}p) # 64-byte Spill
; CHECK-NEXT:    #APP
; CHECK-NEXT:    nop
; CHECK-NEXT:    #NO_APP
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %zmm0 # 64-byte Reload
; CHECK-NEXT:    vmovaps {{[-0-9]+}}(%r{{[sb]}}p), %zmm1 # 64-byte Reload
; CHECK-NEXT:    vmovaps %zmm0, (%rsi)
; CHECK-NEXT:    vmovaps %zmm1, (%rdi)
; CHECK-NEXT:    popq %rax
; CHECK-NEXT:    .cfi_def_cfa_offset 8
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
entry:
  %0 = load <16 x float>, <16 x float>* %LowPtr, align 64
  %1 = load <16 x float>, <16 x float>* %HighPtr, align 64
  %2 = tail call { <16 x float>, <16 x float> } @llvm.x86.vpmm.vmmxf16ps.512(<16 x float> %1, <16 x float> %0, <32 x half> %Src1, <32 x half> %Src2)
  tail call void asm sideeffect "nop", "~{zmm0},~{zmm1},~{zmm2},~{zmm3},~{zmm4},~{zmm5},~{zmm6},~{zmm7},~{zmm8},~{zmm9},~{zmm11},~{zmm12},~{zmm13},~{zmm14},~{zmm15},~{zmm16},~{zmm17},~{zmm18},~{zmm19},~{zmm20},~{zmm21},~{zmm22},~{zmm23},~{zmm24},~{zmm25},~{zmm26},~{zmm27},~{zmm28},~{zmm29},~{zmm30},~{zmm31},~{dirflag},~{fpsr},~{flags}"()
  %3 = extractvalue { <16 x float>, <16 x float> } %2, 0
  store <16 x float> %3, <16 x float>* %LowPtr, align 64
  %4 = extractvalue { <16 x float>, <16 x float> } %2, 1
  store <16 x float> %4, <16 x float>* %HighPtr, align 64
  ret void
}

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare { <4 x float>, <4 x float> } @llvm.x86.vpmm.vmmxf16ps.128(<4 x float>, <4 x float>, <8 x half>, <8 x half>)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare { <8 x float>, <8 x float> } @llvm.x86.vpmm.vmmxf16ps.256(<8 x float>, <8 x float>, <16 x half>, <16 x half>)

; Function Attrs: mustprogress nocallback nofree nosync nounwind willreturn memory(none)
declare { <16 x float>, <16 x float> } @llvm.x86.vpmm.vmmxf16ps.512(<16 x float>, <16 x float>, <32 x half>, <32 x half>)
