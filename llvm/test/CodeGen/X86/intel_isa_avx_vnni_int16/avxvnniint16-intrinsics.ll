; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx_vnni_int16
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx2,+avxvnniint16 | FileCheck %s --check-prefixes=X64
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx2,+avxvnniint16 | FileCheck %s --check-prefixes=X86

define <4 x i32> @test_int_x86_vpdpwsud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwsud128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwsud %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x72,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwsud128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwsud %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x72,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwsud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwsud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwsud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwsud256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwsud %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x76,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwsud256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwsud %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x76,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwsud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwsud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

define <4 x i32> @test_int_x86_vpdpwsuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwsuds128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwsuds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x72,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwsuds128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwsuds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x72,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwsuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwsuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwsuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwsuds256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwsuds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x76,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwsuds256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwsuds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x76,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwsuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwsuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

define <4 x i32> @test_int_x86_vpdpwusd128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwusd128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwusd %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x71,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwusd128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwusd %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x71,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwusd128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwusd128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwusd256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwusd256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwusd %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x75,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwusd256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwusd %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x75,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwusd256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwusd256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

define <4 x i32> @test_int_x86_vpdpwusds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwusds128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwusds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x71,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwusds128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwusds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x71,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwusds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwusds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwusds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwusds256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwusds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x75,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwusds256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwusds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x75,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwusds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwusds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

define <4 x i32> @test_int_x86_vpdpwuud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwuud128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuud %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuud128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwuud %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwuud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwuud128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwuud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwuud256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuud %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd2,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuud256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwuud %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd2,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwuud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwuud256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

define <4 x i32> @test_int_x86_vpdpwuuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwuuds128:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuuds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuuds128:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwuuds %xmm2, %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <4 x i32> @llvm.x86.vpdpwuuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)
  ret <4 x i32> %ret
}

; Test if the operands be commuted.
define <4 x i32> @test_int_x86_vpdpwuuds128_2(<4 x i32> %A, <4 x i32> %B, <4 x i32>* %C) {
; X64-LABEL: test_int_x86_vpdpwuuds128_2:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuuds (%rdi), %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd3,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuuds128_2:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vpdpwuuds (%eax), %xmm1, %xmm0 # encoding: [0xc4,0xe2,0x70,0xd3,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  %C1 = load <4 x i32>, <4 x i32>* %C
  %ret = call <4 x i32> @llvm.x86.vpdpwuuds128(<4 x i32> %A, <4 x i32> %C1, <4 x i32> %B)
  ret <4 x i32> %ret
}
declare <4 x i32> @llvm.x86.vpdpwuuds128(<4 x i32> %A, <4 x i32> %B, <4 x i32> %C)

define <8 x i32> @test_int_x86_vpdpwuuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C) {
; X64-LABEL: test_int_x86_vpdpwuuds256:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuuds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd3,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuuds256:
; X86:       # %bb.0:
; X86-NEXT:    vpdpwuuds %ymm2, %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd3,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %ret = call <8 x i32> @llvm.x86.vpdpwuuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)
  ret <8 x i32> %ret
}

; Test if the operands be commuted.
define <8 x i32> @test_int_x86_vpdpwuuds256_2(<8 x i32> %A, <8 x i32> %B, <8 x i32> *%C) {
; X64-LABEL: test_int_x86_vpdpwuuds256_2:
; X64:       # %bb.0:
; X64-NEXT:    vpdpwuuds (%rdi), %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd3,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vpdpwuuds256_2:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vpdpwuuds (%eax), %ymm1, %ymm0 # encoding: [0xc4,0xe2,0x74,0xd3,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  %C1 = load <8 x i32>, <8 x i32> *%C
  %ret = call <8 x i32> @llvm.x86.vpdpwuuds256(<8 x i32> %A, <8 x i32> %C1, <8 x i32> %B)
  ret <8 x i32> %ret
}
declare <8 x i32> @llvm.x86.vpdpwuuds256(<8 x i32> %A, <8 x i32> %B, <8 x i32> %C)

