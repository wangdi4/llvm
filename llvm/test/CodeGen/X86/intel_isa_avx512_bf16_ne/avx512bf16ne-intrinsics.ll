; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_bf16_ne
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512bf16ne | FileCheck %s --check-prefixes=CHECK,X64
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512bf16ne | FileCheck %s --check-prefixes=CHECK,X86

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vaddnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vaddnepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vaddnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x58,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_add_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_add_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vaddnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x58,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_add_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vaddnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x58,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_add_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_add_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vaddnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x58,0xc2]
; X64-NEXT:    vaddnepbf16 (%rsi), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x58,0x0e]
; X64-NEXT:    vaddnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x58,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_add_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vaddnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x58,0xc2]
; X86-NEXT:    vaddnepbf16 (%eax), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x58,0x08]
; X86-NEXT:    vaddnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x58,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat>, <32 x bfloat>)

define <32 x bfloat> @test_int_x86_avx512bf16ne_sub_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_sub_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsubnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5c,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_sub_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_sub_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vsubnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x5c,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_sub_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vsubnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x5c,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_sub_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_sub_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vsubnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5c,0xc2]
; X64-NEXT:    vsubnepbf16 (%rsi), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5c,0x0e]
; X64-NEXT:    vsubnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5c,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_sub_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vsubnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5c,0xc2]
; X86-NEXT:    vsubnepbf16 (%eax), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5c,0x08]
; X86-NEXT:    vsubnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5c,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vsubnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat>, <32 x bfloat>)

define <32 x bfloat> @test_int_x86_avx512bf16ne_mul_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_mul_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmulnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x59,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_mul_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_mul_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmulnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x59,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_mul_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vmulnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x59,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_mul_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_mul_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmulnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x59,0xc2]
; X64-NEXT:    vmulnepbf16 (%rsi), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x59,0x0e]
; X64-NEXT:    vmulnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x59,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_mul_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vmulnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x59,0xc2]
; X86-NEXT:    vmulnepbf16 (%eax), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x59,0x08]
; X86-NEXT:    vmulnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x59,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vmulnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat>, <32 x bfloat>)

define <32 x bfloat> @test_int_x86_avx512bf16ne_div_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_div_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdivnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5e,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_div_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_div_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vdivnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x5e,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_div_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdivnepbf16 %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x5e,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

; FIXME: assembly order is different from fp16 ones
define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_div_nepbf16_512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_div_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vdivnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5e,0xc2]
; X64-NEXT:    vdivnepbf16 (%rsi), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5e,0x0e]
; X64-NEXT:    vdivnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5e,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_div_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdivnepbf16 %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5e,0xc2]
; X86-NEXT:    vdivnepbf16 (%eax), %zmm1, %zmm1 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x5e,0x08]
; X86-NEXT:    vdivnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5e,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vdivnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vminnepbf16512(<32 x bfloat>, <32 x bfloat>)

define <32 x bfloat> @test_int_x86_avx512bf16ne_min_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_min_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vminnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5d,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vminnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res0
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_min_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_min_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vminnepbf16 %zmm1, %zmm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7d,0xc9,0x5d,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_min_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vminnepbf16 %zmm1, %zmm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7d,0xc9,0x5d,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vminnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  ret <32 x bfloat> %res1
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vmaxnepbf16512(<32 x bfloat>, <32 x bfloat>)

define <32 x bfloat> @test_int_x86_avx512bf16ne_max_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_max_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmaxnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x5f,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmaxnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  ret <32 x bfloat> %res0
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_max_nepbf16_512(<32 x bfloat> %x1, <32 x bfloat> %x2, i32 %msk) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_max_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmaxnepbf16 %zmm1, %zmm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7d,0xc9,0x5f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_max_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vmaxnepbf16 %zmm1, %zmm0, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x7d,0xc9,0x5f,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vmaxnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  ret <32 x bfloat> %res1
}

declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16eq(<8 x bfloat>, <8 x bfloat>)
declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16lt(<8 x bfloat>, <8 x bfloat>)
declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16le(<8 x bfloat>, <8 x bfloat>)
declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16gt(<8 x bfloat>, <8 x bfloat>)
declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16ge(<8 x bfloat>, <8 x bfloat>)
declare i32 @llvm.x86.avx512bf16ne.vcomnesbf16neq(<8 x bfloat>, <8 x bfloat>)

define i32 @test_x86_avx512bf16ne_com_nesbf16_eq(<8 x bfloat> %a0, <8 x bfloat> %a1) {
; CHECK-LABEL: test_x86_avx512bf16ne_com_nesbf16_eq:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcomnesbf16 %xmm1, %xmm0 # encoding: [0x62,0xf5,0x7d,0x08,0x2f,0xc1]
; CHECK-NEXT:    setnp %al # encoding: [0x0f,0x9b,0xc0]
; CHECK-NEXT:    sete %cl # encoding: [0x0f,0x94,0xc1]
; CHECK-NEXT:    andb %al, %cl # encoding: [0x20,0xc1]
; CHECK-NEXT:    movzbl %cl, %eax # encoding: [0x0f,0xb6,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcomnesbf16eq(<8 x bfloat> %a0, <8 x bfloat> %a1)
  ret i32 %res
}

define i32 @test_x86_avx512bf16ne_com_nesbf16_lt(<8 x bfloat> %a0, <8 x bfloat> %a1) {
; CHECK-LABEL: test_x86_avx512bf16ne_com_nesbf16_lt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorl %eax, %eax # encoding: [0x31,0xc0]
; CHECK-NEXT:    vcomnesbf16 %xmm0, %xmm1 # encoding: [0x62,0xf5,0x7d,0x08,0x2f,0xc8]
; CHECK-NEXT:    seta %al # encoding: [0x0f,0x97,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcomnesbf16lt(<8 x bfloat> %a0, <8 x bfloat> %a1)
  ret i32 %res
}

define i32 @test_x86_avx512bf16ne_com_nesbf16_le(<8 x bfloat> %a0, <8 x bfloat> %a1) {
; CHECK-LABEL: test_x86_avx512bf16ne_com_nesbf16_le:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorl %eax, %eax # encoding: [0x31,0xc0]
; CHECK-NEXT:    vcomnesbf16 %xmm0, %xmm1 # encoding: [0x62,0xf5,0x7d,0x08,0x2f,0xc8]
; CHECK-NEXT:    setae %al # encoding: [0x0f,0x93,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcomnesbf16le(<8 x bfloat> %a0, <8 x bfloat> %a1)
  ret i32 %res
}

define i32 @test_x86_avx512bf16ne_com_nesbf16_gt(<8 x bfloat> %a0, <8 x bfloat> %a1) {
; CHECK-LABEL: test_x86_avx512bf16ne_com_nesbf16_gt:
; CHECK:       # %bb.0:
; CHECK-NEXT:    xorl %eax, %eax # encoding: [0x31,0xc0]
; CHECK-NEXT:    vcomnesbf16 %xmm1, %xmm0 # encoding: [0x62,0xf5,0x7d,0x08,0x2f,0xc1]
; CHECK-NEXT:    setae %al # encoding: [0x0f,0x93,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcomnesbf16ge(<8 x bfloat> %a0, <8 x bfloat> %a1)
  ret i32 %res
}

define i32 @test_x86_avx512bf16ne_com_nesbf16_neq(<8 x bfloat> %a0, <8 x bfloat> %a1) {
; CHECK-LABEL: test_x86_avx512bf16ne_com_nesbf16_neq:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcomnesbf16 %xmm1, %xmm0 # encoding: [0x62,0xf5,0x7d,0x08,0x2f,0xc1]
; CHECK-NEXT:    setp %al # encoding: [0x0f,0x9a,0xc0]
; CHECK-NEXT:    setne %cl # encoding: [0x0f,0x95,0xc1]
; CHECK-NEXT:    orb %al, %cl # encoding: [0x08,0xc1]
; CHECK-NEXT:    movzbl %cl, %eax # encoding: [0x0f,0xb6,0xc1]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcomnesbf16neq(<8 x bfloat> %a0, <8 x bfloat> %a1)
  ret i32 %res
}

declare i32 @llvm.x86.avx512bf16ne.vcmpnepbf16512.mask(<32 x bfloat>, <32 x bfloat>, i32, i32)
define i32 @test_int_x86_avx512bf16ne_vcmpnepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vcmpnepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vcmpunordnepbf16 %zmm1, %zmm0, %k0 # encoding: [0x62,0xf3,0x7f,0x48,0xc2,0xc1,0x03]
; CHECK-NEXT:    kmovd %k0, %eax # encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call i32 @llvm.x86.avx512bf16ne.vcmpnepbf16512.mask(<32 x bfloat> %x1, <32 x bfloat> %x2, i32 3, i32 -1)
  ret i32 %res
}

define i32 @test_int_x86_avx512bf16ne_vcmpnepbf16512_mask2(<32 x bfloat> %x1, <32 x bfloat> %x2) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vcmpnepbf16512_mask2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movl $3, %eax # encoding: [0xb8,0x03,0x00,0x00,0x00]
; CHECK-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; CHECK-NEXT:    vcmpeqnepbf16 %zmm1, %zmm0, %k0 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0xc2,0xc1,0x00]
; CHECK-NEXT:    kmovd %k0, %eax # encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = call i32 @llvm.x86.avx512bf16ne.vcmpnepbf16512.mask(<32 x bfloat> %x1, <32 x bfloat> %x2, i32 0, i32 3)
  ret i32 %1
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.sqrt.nepbf16.512(<32 x bfloat>, <32 x bfloat>, i32)

define <32 x bfloat> @test_sqrt_nepbf16_512(<32 x bfloat> %a0) {
; CHECK-LABEL: test_sqrt_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vsqrtnepbf16 %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x51,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.sqrt.nepbf16.512(<32 x bfloat> %a0, <32 x bfloat> zeroinitializer, i32 -1)
  ret <32 x bfloat> %res
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rsqrt.nepbf16.512(<32 x bfloat>, <32 x bfloat>, i32)

define <32 x bfloat> @test_rsqrt_nepbf16_512(<32 x bfloat> %a0) {
; CHECK-LABEL: test_rsqrt_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vrsqrtnepbf16 %zmm0, %zmm0 # encoding: [0x62,0xf6,0x7c,0x48,0x4e,0xc0]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rsqrt.nepbf16.512(<32 x bfloat> %a0, <32 x bfloat> zeroinitializer, i32 -1)
  ret <32 x bfloat> %res
}

declare <32 x i1> @llvm.x86.avx512bf16ne.fpclass.nepbf16.512(<32 x bfloat>, i32)

;FIXME ne
define i32 @test_int_x86_avx512_fpclass_nepbf16_512(<32 x bfloat> %x0) {
; CHECK-LABEL: test_int_x86_avx512_fpclass_nepbf16_512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfpclassnepbf16 $2, %zmm0, %k1 # encoding: [0x62,0xf3,0x7f,0x48,0x66,0xc8,0x02]
; CHECK-NEXT:    vfpclassnepbf16 $4, %zmm0, %k0 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x66,0xc0,0x04]
; CHECK-NEXT:    kmovd %k0, %eax # encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x i1> @llvm.x86.avx512bf16ne.fpclass.nepbf16.512(<32 x bfloat> %x0, i32 4)
  %res1 = call <32 x i1> @llvm.x86.avx512bf16ne.fpclass.nepbf16.512(<32 x bfloat> %x0, i32 2)
  %1 = and <32 x i1> %res1, %res
  %2 = bitcast <32 x i1> %1 to i32
  ret i32 %2
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rcp.nepbf16.512(<32 x bfloat>, <32 x bfloat>, i32)

define <32 x bfloat> @test_rcp_nepbf16_512(<32 x bfloat> %a0, <32 x bfloat> %a1, i32 %mask) {
; X64-LABEL: test_rcp_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vrcpnepbf16 %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf6,0x7c,0x49,0x4c,0xc8]
; X64-NEXT:    vmovaps %zmm1, %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_rcp_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vrcpnepbf16 %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf6,0x7c,0x49,0x4c,0xc8]
; X86-NEXT:    vmovaps %zmm1, %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0xc1]
; X86-NEXT:    retl # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rcp.nepbf16.512(<32 x bfloat> %a0, <32 x bfloat> %a1, i32 %mask)
  ret <32 x bfloat> %res
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.reduce.nepbf16.512(<32 x bfloat>, i32, <32 x bfloat>, i32)

define <32 x bfloat>@test_int_x86_avx512_mask_reduce_nepbf16_512(<32 x bfloat> %x0, <32 x bfloat> %x2, i32 %x3) {
; X64-LABEL: test_int_x86_avx512_mask_reduce_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vreducenepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x56,0xc8,0x08]
; X64-NEXT:    vreducenepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x56,0xc0,0x04]
; X64-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512_mask_reduce_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vreducenepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x56,0xc8,0x08]
; X86-NEXT:    vreducenepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x56,0xc0,0x04]
; X86-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.reduce.nepbf16.512(<32 x bfloat> %x0, i32 8, <32 x bfloat> %x2, i32 %x3)
  %res1 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.reduce.nepbf16.512(<32 x bfloat> %x0, i32 4, <32 x bfloat> %x2, i32 -1)
  %res2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res, <32 x bfloat> %res1)
  ret <32 x bfloat> %res2
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rndscale.nepbf16.512(<32 x bfloat>, i32, <32 x bfloat>, i32)

define <32 x bfloat>@test_int_x86_avx512_mask_rndscale_nepbf16_512(<32 x bfloat> %x0, <32 x bfloat> %x2, i32 %x3) {
; X64-LABEL: test_int_x86_avx512_mask_rndscale_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vrndscalenepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x08,0xc8,0x08]
; X64-NEXT:    vrndscalenepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x08,0xc0,0x04]
; X64-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512_mask_rndscale_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vrndscalenepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x08,0xc8,0x08]
; X86-NEXT:    vrndscalenepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x08,0xc0,0x04]
; X86-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rndscale.nepbf16.512(<32 x bfloat> %x0, i32 8, <32 x bfloat> %x2, i32 %x3)
  %res1 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.rndscale.nepbf16.512(<32 x bfloat> %x0, i32 4, <32 x bfloat> %x2, i32 -1)
  %res2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res, <32 x bfloat> %res1)
  ret <32 x bfloat> %res2
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getexp.nepbf16.512(<32 x bfloat>, <32 x bfloat>, i32)

define <32 x bfloat>@test_int_x86_avx512_mask_getexp_nepbf16_512(<32 x bfloat> %x0, <32 x bfloat> %x1, i32 %x2) {
; X64-LABEL: test_int_x86_avx512_mask_getexp_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vgetexpnepbf16 %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x42,0xc0]
; X64-NEXT:    vmovdqu16 %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc8]
; X64-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512_mask_getexp_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vgetexpnepbf16 %zmm0, %zmm0 # encoding: [0x62,0xf5,0x7d,0x48,0x42,0xc0]
; X86-NEXT:    vmovdqu16 %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc8]
; X86-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %res1 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getexp.nepbf16.512(<32 x bfloat> %x0, <32 x bfloat> %x1, i32 %x2)
  %res2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getexp.nepbf16.512(<32 x bfloat> %x0, <32 x bfloat> zeroinitializer, i32 -1)
  %res3 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getmant.nepbf16.512(<32 x bfloat>, i32, <32 x bfloat>, i32)

define <32 x bfloat>@test_int_x86_avx512_mask_getmant_nepbf16_512(<32 x bfloat> %x0, <32 x bfloat> %x2, i32 %x3) {
; X64-LABEL: test_int_x86_avx512_mask_getmant_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vgetmantnepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x26,0xc8,0x08]
; X64-NEXT:    vgetmantnepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x26,0xc0,0x04]
; X64-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512_mask_getmant_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vgetmantnepbf16 $8, %zmm0, %zmm1 {%k1} # encoding: [0x62,0xf3,0x7f,0x49,0x26,0xc8,0x08]
; X86-NEXT:    vgetmantnepbf16 $4, %zmm0, %zmm0 # encoding: [0x62,0xf3,0x7f,0x48,0x26,0xc0,0x04]
; X86-NEXT:    vaddnepbf16 %zmm0, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x58,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getmant.nepbf16.512(<32 x bfloat> %x0, i32 8, <32 x bfloat> %x2, i32 %x3)
  %res1 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.getmant.nepbf16.512(<32 x bfloat> %x0, i32 4, <32 x bfloat> %x2, i32 -1)
  %res2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res, <32 x bfloat> %res1)
  ret <32 x bfloat> %res2
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.mask.scalef.nepbf16.512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>, i32)

define <32 x bfloat>@test_int_x86_avx512_mask_scalef_nepbf16_512(<32 x bfloat> %x0, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %x3) {
; X64-LABEL: test_int_x86_avx512_mask_scalef_nepbf16_512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vscalefnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf6,0x7c,0x48,0x2c,0xc1]
; X64-NEXT:    vmovdqu16 %zmm0, %zmm2 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xd0]
; X64-NEXT:    vaddnepbf16 %zmm0, %zmm2, %zmm0 # encoding: [0x62,0xf5,0x6d,0x48,0x58,0xc0]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512_mask_scalef_nepbf16_512:
; X86:       # %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vscalefnepbf16 %zmm1, %zmm0, %zmm0 # encoding: [0x62,0xf6,0x7c,0x48,0x2c,0xc1]
; X86-NEXT:    vmovdqu16 %zmm0, %zmm2 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xd0]
; X86-NEXT:    vaddnepbf16 %zmm0, %zmm2, %zmm0 # encoding: [0x62,0xf5,0x6d,0x48,0x58,0xc0]
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %x3 to <32 x i1>
  %res1 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.scalef.nepbf16.512(<32 x bfloat> %x0, <32 x bfloat> %x1, <32 x bfloat> %x2, i32 %x3)
  %res2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.mask.scalef.nepbf16.512(<32 x bfloat> %x0, <32 x bfloat> %x1, <32 x bfloat> zeroinitializer, i32 -1)
  %res3 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vaddnepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmadd213nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmadd213nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xa8,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmadd213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmadd213nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xa8,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmadd213nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xa8,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmadd213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmadd213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xa8,0xd3]
; X64-NEXT:    vfmadd213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xa8,0xc3]
; X64-NEXT:    vfmadd213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xa8,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmadd213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xa8,0xd3]
; X86-NEXT:    vfmadd213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xa8,0xc3]
; X86-NEXT:    vfmadd213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xa8,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd213nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmsub213nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmsub213nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xaa,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmsub213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmsub213nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xaa,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmsub213nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xaa,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmsub213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmsub213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xaa,0xd3]
; X64-NEXT:    vfmsub213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xaa,0xc3]
; X64-NEXT:    vfmsub213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xaa,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmsub213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xaa,0xd3]
; X86-NEXT:    vfmsub213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xaa,0xc3]
; X86-NEXT:    vfmsub213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xaa,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub213nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmadd213nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmadd213nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xac,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmadd213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xac,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmadd213nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xac,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmadd213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xac,0xd3]
; X64-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xac,0xc3]
; X64-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xac,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xac,0xd3]
; X86-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xac,0xc3]
; X86-NEXT:    vfnmadd213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xac,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd213nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmsub213nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmsub213nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xae,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmsub213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xae,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmsub213nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xae,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmsub213nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub213nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xae,0xd3]
; X64-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xae,0xc3]
; X64-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xae,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub213nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xae,0xd3]
; X86-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xae,0xc3]
; X86-NEXT:    vfnmsub213nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xae,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub213nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmadd132nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmadd132nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0x98,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmadd132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmadd132nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x98,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmadd132nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x98,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmadd132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmadd132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x98,0xd3]
; X64-NEXT:    vfmadd132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x98,0xc3]
; X64-NEXT:    vfmadd132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x98,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmadd132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x98,0xd3]
; X86-NEXT:    vfmadd132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x98,0xc3]
; X86-NEXT:    vfmadd132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x98,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd132nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmsub132nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmsub132nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0x9a,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmsub132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmsub132nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9a,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmsub132nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9a,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmsub132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmsub132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9a,0xd3]
; X64-NEXT:    vfmsub132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9a,0xc3]
; X64-NEXT:    vfmsub132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9a,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmsub132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9a,0xd3]
; X86-NEXT:    vfmsub132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9a,0xc3]
; X86-NEXT:    vfmsub132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9a,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub132nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmadd132nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmadd132nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0x9c,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmadd132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9c,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmadd132nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9c,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmadd132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9c,0xd3]
; X64-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9c,0xc3]
; X64-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9c,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9c,0xd3]
; X86-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9c,0xc3]
; X86-NEXT:    vfnmadd132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9c,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd132nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmsub132nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmsub132nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0x9e,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmsub132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9e,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmsub132nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0x9e,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmsub132nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub132nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9e,0xd3]
; X64-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9e,0xc3]
; X64-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9e,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub132nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9e,0xd3]
; X86-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0x9e,0xc3]
; X86-NEXT:    vfnmsub132nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0x9e,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub132nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmadd231nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmadd231nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xb8,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmadd231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmadd231nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xb8,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmadd231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmadd231nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xb8,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmadd231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmadd231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xb8,0xd3]
; X64-NEXT:    vfmadd231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xb8,0xc3]
; X64-NEXT:    vfmadd231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xb8,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmadd231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmadd231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xb8,0xd3]
; X86-NEXT:    vfmadd231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xb8,0xc3]
; X86-NEXT:    vfmadd231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xb8,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmadd231nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfmsub231nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfmsub231nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xba,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfmsub231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfmsub231nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xba,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfmsub231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfmsub231nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xba,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfmsub231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfmsub231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xba,0xd3]
; X64-NEXT:    vfmsub231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xba,0xc3]
; X64-NEXT:    vfmsub231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xba,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfmsub231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfmsub231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xba,0xd3]
; X86-NEXT:    vfmsub231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xba,0xc3]
; X86-NEXT:    vfmsub231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xba,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfmsub231nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmadd231nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmadd231nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xbc,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmadd231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xbc,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmadd231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmadd231nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xbc,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmadd231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbc,0xd3]
; X64-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbc,0xc3]
; X64-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xbc,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmadd231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbc,0xd3]
; X86-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbc,0xc3]
; X86-NEXT:    vfnmadd231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xbc,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmadd231nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}

declare <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat>, <32 x bfloat>, <32 x bfloat>)
define <32 x bfloat> @test_int_x86_avx512bf16ne_vfnmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3) {
; CHECK-LABEL: test_int_x86_avx512bf16ne_vfnmsub231nepbf16512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vfnmsub231nepbf16 %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf6,0x74,0x48,0xbe,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %res = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_mask_vfnmsub231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xbe,0xcb]
; X64-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_mask_vfnmsub231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vfnmsub231nepbf16 8(%ebp), %zmm2, %zmm1 # encoding: [0x62,0xf6,0x6c,0x48,0xbe,0x8d,0x08,0x00,0x00,0x00]
; X86-NEXT:    vmovdqu16 %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf1,0xff,0x49,0x6f,0xc1]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> %src
  ret <32 x bfloat> %res
}

define <32 x bfloat> @test_int_x86_avx512bf16ne_maskz_vfnmsub231nepbf16512(<32 x bfloat> %src, <32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3, i32 %msk, <32 x bfloat>* %ptr) {
; X64-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub231nepbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %edi, %k1 # encoding: [0xc5,0xfb,0x92,0xcf]
; X64-NEXT:    vmovaps (%rsi), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x06]
; X64-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbe,0xd3]
; X64-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbe,0xc3]
; X64-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xbe,0xc3]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_avx512bf16ne_maskz_vfnmsub231nepbf16512:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebp # encoding: [0x55]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    .cfi_offset %ebp, -8
; X86-NEXT:    movl %esp, %ebp # encoding: [0x89,0xe5]
; X86-NEXT:    .cfi_def_cfa_register %ebp
; X86-NEXT:    andl $-64, %esp # encoding: [0x83,0xe4,0xc0]
; X86-NEXT:    subl $64, %esp # encoding: [0x83,0xec,0x40]
; X86-NEXT:    vmovaps 8(%ebp), %zmm3 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x9d,0x08,0x00,0x00,0x00]
; X86-NEXT:    movl 76(%ebp), %eax # encoding: [0x8b,0x45,0x4c]
; X86-NEXT:    kmovd 72(%ebp), %k1 # encoding: [0xc4,0xe1,0xf9,0x90,0x4d,0x48]
; X86-NEXT:    vmovaps (%eax), %zmm0 # encoding: [0x62,0xf1,0x7c,0x48,0x28,0x00]
; X86-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm1, %zmm2 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbe,0xd3]
; X86-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf6,0x74,0xc9,0xbe,0xc3]
; X86-NEXT:    vfnmsub231nepbf16 %zmm3, %zmm2, %zmm0 # encoding: [0x62,0xf6,0x6c,0x48,0xbe,0xc3]
; X86-NEXT:    movl %ebp, %esp # encoding: [0x89,0xec]
; X86-NEXT:    popl %ebp # encoding: [0x5d]
; X86-NEXT:    .cfi_def_cfa %esp, 4
; X86-NEXT:    retl # encoding: [0xc3]
  %mask = bitcast i32 %msk to <32 x i1>
  %val = load <32 x bfloat>, <32 x bfloat>* %ptr
  %res0 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %x2, <32 x bfloat> %x3)
  %res1 = select <32 x i1> %mask, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  %t2 = call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat> %x1, <32 x bfloat> %val, <32 x bfloat> %x3)
  %res2 = select <32 x i1> %mask, <32 x bfloat> %t2, <32 x bfloat> zeroinitializer
  %res3  =  call <32 x bfloat> @llvm.x86.avx512bf16ne.vfnmsub231nepbf16512(<32 x bfloat> %res1, <32 x bfloat> %res2, <32 x bfloat> %x3)
  ret <32 x bfloat> %res3
}
