; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_fp16
; This test checks that Global FMA optimizes an arbitrary (1 of ~40k) test case
; using 1.0 fp const.
; For the input expression:
;   +acd+a+b
; the output code must have 2 arithmetic instructions:
;   F0=+c*d+1; F1=+F0*a+b;

; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=small -relocation-model=pic | FileCheck --check-prefix=SML %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=large | FileCheck --check-prefix=LRG %s
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefixes=OTHER %s
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown -mattr=+avx512fp16 -fp-contract=fast -enable-unsafe-fp-math -enable-misched=0 -code-model=kernel | FileCheck --check-prefix=X86OTHER %s

define half @test_sh(half %a32, half %b32, half %c32, half %d32) {
; SML-LABEL: test_sh:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213sh {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm2, %xmm0
; SML-NEXT:    vfmadd213sh %xmm1, %xmm3, %xmm0
; SML-NEXT:    retq
;
; LRG-LABEL: test_sh:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.?LCPI[0-9]+_[0-9]+}}, %rax
; LRG-NEXT:    vfmadd213sh (%rax), %xmm2, %xmm0
; LRG-NEXT:    vfmadd213sh %xmm1, %xmm3, %xmm0
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_sh:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $15360, %eax # imm = 0x3C00
; OTHER-NEXT:    vmovw %eax, %xmm4
; OTHER-NEXT:    vfmadd213sh %xmm4, %xmm2, %xmm0
; OTHER-NEXT:    vfmadd213sh %xmm1, %xmm3, %xmm0
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_sh:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; X86OTHER-NEXT:    vmovsh {{\.?LCPI[0-9]+_[0-9]+}}, %xmm1
; X86OTHER-NEXT:    vfmadd231sh {{[0-9]+}}(%esp), %xmm0, %xmm1
; X86OTHER-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; X86OTHER-NEXT:    vfmadd231sh {{[0-9]+}}(%esp), %xmm1, %xmm0
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast half %a32, %d32
  %mul1 = fmul fast half %mul, %c32
  %add = fadd fast half %mul1, %d32
  %add2 = fadd fast half %add, %b32
  ret half %add2
}

define <8 x half> @test_ph(<8 x half> %a32, <8 x half> %b32, <8 x half> %c32, <8 x half> %d32) {
; SML-LABEL: test_ph:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm2, %xmm0
; SML-NEXT:    vfmadd213ph %xmm1, %xmm3, %xmm0
; SML-NEXT:    retq
;
; LRG-LABEL: test_ph:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.?LCPI[0-9]+_[0-9]+}}, %rax
; LRG-NEXT:    vfmadd213ph (%rax), %xmm2, %xmm0
; LRG-NEXT:    vfmadd213ph %xmm1, %xmm3, %xmm0
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_ph:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $15360, %eax # imm = 0x3C00
; OTHER-NEXT:    vpbroadcastw %eax, %xmm4
; OTHER-NEXT:    vfmadd213ph %xmm4, %xmm2, %xmm0
; OTHER-NEXT:    vfmadd213ph %xmm1, %xmm3, %xmm0
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ph:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_offset 8
; X86OTHER-NEXT:    .cfi_offset %ebp, -8
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_register %ebp
; X86OTHER-NEXT:    andl $-16, %esp
; X86OTHER-NEXT:    subl $16, %esp
; X86OTHER-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}, %xmm2, %xmm0
; X86OTHER-NEXT:    vfmadd132ph 8(%ebp), %xmm1, %xmm0
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa %esp, 4
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <8 x half> %a32, %d32
  %mul1 = fmul fast <8 x half> %mul, %c32
  %add = fadd fast <8 x half> %mul1, %d32
  %add2 = fadd fast <8 x half> %add, %b32
  ret <8 x half> %add2
}

define <16 x half> @test_ph256(<16 x half> %a32, <16 x half> %b32, <16 x half> %c32, <16 x half> %d32) {
; SML-LABEL: test_ph256:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm2, %ymm0
; SML-NEXT:    vfmadd213ph %ymm1, %ymm3, %ymm0
; SML-NEXT:    retq
;
; LRG-LABEL: test_ph256:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.?LCPI[0-9]+_[0-9]+}}, %rax
; LRG-NEXT:    vfmadd213ph (%rax), %ymm2, %ymm0
; LRG-NEXT:    vfmadd213ph %ymm1, %ymm3, %ymm0
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_ph256:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $15360, %eax # imm = 0x3C00
; OTHER-NEXT:    vpbroadcastw %eax, %ymm4
; OTHER-NEXT:    vfmadd213ph %ymm4, %ymm2, %ymm0
; OTHER-NEXT:    vfmadd213ph %ymm1, %ymm3, %ymm0
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ph256:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_offset 8
; X86OTHER-NEXT:    .cfi_offset %ebp, -8
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_register %ebp
; X86OTHER-NEXT:    andl $-32, %esp
; X86OTHER-NEXT:    subl $32, %esp
; X86OTHER-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}, %ymm2, %ymm0
; X86OTHER-NEXT:    vfmadd132ph 8(%ebp), %ymm1, %ymm0
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa %esp, 4
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <16 x half> %a32, %d32
  %mul1 = fmul fast <16 x half> %mul, %c32
  %add = fadd fast <16 x half> %mul1, %d32
  %add2 = fadd fast <16 x half> %add, %b32
  ret <16 x half> %add2
}

define <32 x half> @test_ph512(<32 x half> %a32, <32 x half> %b32, <32 x half> %c32, <32 x half> %d32) {
; SML-LABEL: test_ph512:
; SML:       # %bb.0: # %entry
; SML-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %zmm2, %zmm0
; SML-NEXT:    vfmadd213ph %zmm1, %zmm3, %zmm0
; SML-NEXT:    retq
;
; LRG-LABEL: test_ph512:
; LRG:       # %bb.0: # %entry
; LRG-NEXT:    movabsq ${{\.?LCPI[0-9]+_[0-9]+}}, %rax
; LRG-NEXT:    vfmadd213ph (%rax), %zmm2, %zmm0
; LRG-NEXT:    vfmadd213ph %zmm1, %zmm3, %zmm0
; LRG-NEXT:    retq
;
; OTHER-LABEL: test_ph512:
; OTHER:       # %bb.0: # %entry
; OTHER-NEXT:    movl $15360, %eax # imm = 0x3C00
; OTHER-NEXT:    vpbroadcastw %eax, %zmm4
; OTHER-NEXT:    vfmadd213ph %zmm4, %zmm2, %zmm0
; OTHER-NEXT:    vfmadd213ph %zmm1, %zmm3, %zmm0
; OTHER-NEXT:    retq
;
; X86OTHER-LABEL: test_ph512:
; X86OTHER:       # %bb.0: # %entry
; X86OTHER-NEXT:    pushl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_offset 8
; X86OTHER-NEXT:    .cfi_offset %ebp, -8
; X86OTHER-NEXT:    movl %esp, %ebp
; X86OTHER-NEXT:    .cfi_def_cfa_register %ebp
; X86OTHER-NEXT:    andl $-64, %esp
; X86OTHER-NEXT:    subl $64, %esp
; X86OTHER-NEXT:    vfmadd213ph {{\.?LCPI[0-9]+_[0-9]+}}, %zmm2, %zmm0
; X86OTHER-NEXT:    vfmadd132ph 8(%ebp), %zmm1, %zmm0
; X86OTHER-NEXT:    movl %ebp, %esp
; X86OTHER-NEXT:    popl %ebp
; X86OTHER-NEXT:    .cfi_def_cfa %esp, 4
; X86OTHER-NEXT:    retl
entry:
  %mul = fmul fast <32 x half> %a32, %d32
  %mul1 = fmul fast <32 x half> %mul, %c32
  %add = fadd fast <32 x half> %mul1, %d32
  %add2 = fadd fast <32 x half> %add, %b32
  ret <32 x half> %add2
}
