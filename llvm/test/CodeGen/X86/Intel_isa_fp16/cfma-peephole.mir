# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# This case is to test the memory information, kill/fast flag are set properly after cfma optimization.
# RUN: llc -mtriple=x86_64-- -run-pass x86-cfma -verify-machineinstrs -mcpu=sapphirerapids -o - %s | FileCheck %s
--- |
  target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
  target triple = "x86_64-unknown-linux-gnu"

  ; Function Attrs: nofree nosync nounwind readonly uwtable
  define dso_local <16 x float> @test_fmaconj_sum(<16 x float>* nocapture readonly %x0, <16 x float>* nocapture readonly %x1) local_unnamed_addr #0 {
  entry:
    %0 = load <16 x float>, <16 x float>* %x0, align 64, !tbaa !3
    %1 = load <16 x float>, <16 x float>* %x1, align 64, !tbaa !3
    %2 = tail call fast <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float> zeroinitializer, <16 x float> %0, <16 x float> %1, i16 -1, i32 4) #2
    %arrayidx.1 = getelementptr inbounds <16 x float>, <16 x float>* %x0, i64 1
    %3 = load <16 x float>, <16 x float>* %arrayidx.1, align 64, !tbaa !3
    %arrayidx2.1 = getelementptr inbounds <16 x float>, <16 x float>* %x1, i64 1
    %4 = load <16 x float>, <16 x float>* %arrayidx2.1, align 64, !tbaa !3
    %5 = tail call fast <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float> %2, <16 x float> %3, <16 x float> %4, i16 -1, i32 4) #2
    %arrayidx.2 = getelementptr inbounds <16 x float>, <16 x float>* %x0, i64 2
    %6 = load <16 x float>, <16 x float>* %arrayidx.2, align 64, !tbaa !3
    %arrayidx2.2 = getelementptr inbounds <16 x float>, <16 x float>* %x1, i64 2
    %7 = load <16 x float>, <16 x float>* %arrayidx2.2, align 64, !tbaa !3
    %8 = tail call fast <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float> %5, <16 x float> %6, <16 x float> %7, i16 -1, i32 4) #2
    %arrayidx.3 = getelementptr inbounds <16 x float>, <16 x float>* %x0, i64 3
    %9 = load <16 x float>, <16 x float>* %arrayidx.3, align 64, !tbaa !3
    %arrayidx2.3 = getelementptr inbounds <16 x float>, <16 x float>* %x1, i64 3
    %10 = load <16 x float>, <16 x float>* %arrayidx2.3, align 64, !tbaa !3
    %11 = tail call fast <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float> %8, <16 x float> %9, <16 x float> %10, i16 -1, i32 4) #2
    %arrayidx.4 = getelementptr inbounds <16 x float>, <16 x float>* %x0, i64 4
    %12 = load <16 x float>, <16 x float>* %arrayidx.4, align 64, !tbaa !3
    %arrayidx2.4 = getelementptr inbounds <16 x float>, <16 x float>* %x1, i64 4
    %13 = load <16 x float>, <16 x float>* %arrayidx2.4, align 64, !tbaa !3
    %14 = tail call fast <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float> %11, <16 x float> %12, <16 x float> %13, i16 -1, i32 4) #2
    ret <16 x float> %14
  }

  ; Function Attrs: nounwind readnone
  declare <16 x float> @llvm.x86.avx512fp16.mask.vfcmadd.cph.512(<16 x float>, <16 x float>, <16 x float>, i16, i32 immarg) #1

  attributes #0 = { nofree nosync nounwind readonly uwtable "denormal-fp-math"="preserve-sign,preserve-sign" "denormal-fp-math-f32"="ieee,ieee" "frame-pointer"="none" "min-legal-vector-width"="512" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="sapphirerapids" "target-features"="+adx,+aes,+amx-bf16,+amx-int8,+amx-tile,+avx,+avx2,+avx512bf16,+avx512bitalg,+avx512bw,+avx512cd,+avx512dq,+avx512f,+avx512fp16,+avx512ifma,+avx512vbmi,+avx512vbmi2,+avx512vl,+avx512vnni,+avx512vp2intersect,+avx512vpopcntdq,+avxvnni,+bmi,+bmi2,+cldemote,+clflushopt,+clwb,+cx16,+cx8,+enqcmd,+f16c,+fma,+fsgsbase,+fxsr,+gfni,+invpcid,+lzcnt,+mmx,+movbe,+movdir64b,+movdiri,+pclmul,+pconfig,+pku,+popcnt,+prfchw,+ptwrite,+rdpid,+rdrnd,+rdseed,+sahf,+serialize,+sgx,+sha,+shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+tsxldtrk,+uintr,+vaes,+vpclmulqdq,+waitpkg,+wbnoinvd,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "unsafe-fp-math"="true" }
  attributes #1 = { nounwind readnone }
  attributes #2 = { nounwind }

  !llvm.module.flags = !{!0, !1}
  !llvm.ident = !{!2}

  !0 = !{i32 1, !"wchar_size", i32 4}
  !1 = !{i32 7, !"uwtable", i32 1}
  !2 = !{!"Intel(R) oneAPI DPC++/C++ Compiler 2021.4.0 (2021.x.0.YYYYMMDD)"}
  !3 = !{!4, !4, i64 0}
  !4 = !{!"omnipotent char", !5, i64 0}
  !5 = !{!"Simple C/C++ TBAA"}

...
---
name:            test_fmaconj_sum
alignment:       16
tracksRegLiveness: true
registers:
  - { id: 0, class: gr64 }
  - { id: 1, class: gr64 }
  - { id: 2, class: vr512 }
  - { id: 3, class: vr512 }
  - { id: 4, class: vr512 }
  - { id: 5, class: vr512 }
  - { id: 6, class: vr512 }
  - { id: 7, class: vr512 }
  - { id: 8, class: vr512 }
  - { id: 9, class: vr512 }
  - { id: 10, class: vr512 }
  - { id: 11, class: vr512 }
  - { id: 12, class: vr512 }
liveins:
  - { reg: '$rdi', virtual-reg: '%0' }
  - { reg: '$rsi', virtual-reg: '%1' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  bb.0.entry:
    liveins: $rdi, $rsi

    ; CHECK-LABEL: name: test_fmaconj_sum
    ; CHECK: liveins: $rdi, $rsi
    ; CHECK: [[COPY:%[0-9]+]]:gr64 = COPY $rsi
    ; CHECK: [[COPY1:%[0-9]+]]:gr64 = COPY $rdi
    ; CHECK: [[AVX512_512_SET0_:%[0-9]+]]:vr512 = AVX512_512_SET0
    ; CHECK: [[VMOVAPSZrm:%[0-9]+]]:vr512 = VMOVAPSZrm [[COPY1]], 1, $noreg, 0, $noreg :: (load (s512) from %ir.x0, !tbaa !3)
    ; CHECK: [[VMOVAPSZrm1:%[0-9]+]]:vr512 = VMOVAPSZrm [[COPY1]], 1, $noreg, 64, $noreg :: (load (s512) from %ir.arrayidx.1, !tbaa !3)
    ; CHECK: [[VMOVAPSZrm2:%[0-9]+]]:vr512 = VMOVAPSZrm [[COPY1]], 1, $noreg, 128, $noreg :: (load (s512) from %ir.arrayidx.2, !tbaa !3)
    ; CHECK: [[VMOVAPSZrm3:%[0-9]+]]:vr512 = VMOVAPSZrm [[COPY1]], 1, $noreg, 192, $noreg :: (load (s512) from %ir.arrayidx.3, !tbaa !3)
    ; CHECK: early-clobber %7:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm [[AVX512_512_SET0_]], killed [[VMOVAPSZrm]], [[COPY]], 1, $noreg, 0, $noreg, implicit $mxcsr :: (load (s512) from %ir.x1, !tbaa !3)
    ; CHECK: [[AVX512_512_SET0_1:%[0-9]+]]:vr512 = AVX512_512_SET0
    ; CHECK: early-clobber %8:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm [[AVX512_512_SET0_1]], killed [[VMOVAPSZrm1]], [[COPY]], 1, $noreg, 64, $noreg, implicit $mxcsr :: (load (s512) from %ir.arrayidx2.1, !tbaa !3)
    ; CHECK: early-clobber %9:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %7, killed [[VMOVAPSZrm2]], [[COPY]], 1, $noreg, 128, $noreg, implicit $mxcsr :: (load (s512) from %ir.arrayidx2.2, !tbaa !3)
    ; CHECK: early-clobber %10:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %8, killed [[VMOVAPSZrm3]], [[COPY]], 1, $noreg, 192, $noreg, implicit $mxcsr :: (load (s512) from %ir.arrayidx2.3, !tbaa !3)
    ; CHECK: [[VMOVAPSZrm4:%[0-9]+]]:vr512 = VMOVAPSZrm [[COPY1]], 1, $noreg, 256, $noreg :: (load (s512) from %ir.arrayidx.4, !tbaa !3)
    ; CHECK: early-clobber %12:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %9, killed [[VMOVAPSZrm4]], [[COPY]], 1, $noreg, 256, $noreg, implicit $mxcsr :: (load (s512) from %ir.arrayidx2.4, !tbaa !3)
    ; CHECK: [[VADDPHZrr:%[0-9]+]]:vr512 = nnan ninf nsz arcp contract afn reassoc VADDPHZrr killed %10, killed %12, implicit $mxcsr
    ; CHECK: $zmm0 = COPY [[VADDPHZrr]]
    ; CHECK: RET 0, $zmm0
    %1:gr64 = COPY $rsi
    %0:gr64 = COPY $rdi
    %2:vr512 = AVX512_512_SET0
    %3:vr512 = VMOVAPSZrm %0, 1, $noreg, 0, $noreg :: (load 64 from %ir.x0, !tbaa !3)
    %4:vr512 = VMOVAPSZrm %0, 1, $noreg, 64, $noreg :: (load 64 from %ir.arrayidx.1, !tbaa !3)
    %5:vr512 = VMOVAPSZrm %0, 1, $noreg, 128, $noreg :: (load 64 from %ir.arrayidx.2, !tbaa !3)
    %6:vr512 = VMOVAPSZrm %0, 1, $noreg, 192, $noreg :: (load 64 from %ir.arrayidx.3, !tbaa !3)
    early-clobber %7:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %2, killed %3, %1, 1, $noreg, 0, $noreg, implicit $mxcsr :: (load 64 from %ir.x1, !tbaa !3)
    early-clobber %8:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %7, killed %4, %1, 1, $noreg, 64, $noreg, implicit $mxcsr :: (load 64 from %ir.arrayidx2.1, !tbaa !3)
    early-clobber %9:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %8, killed %5, %1, 1, $noreg, 128, $noreg, implicit $mxcsr :: (load 64 from %ir.arrayidx2.2, !tbaa !3)
    early-clobber %10:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %9, killed %6, %1, 1, $noreg, 192, $noreg, implicit $mxcsr :: (load 64 from %ir.arrayidx2.3, !tbaa !3)
    %11:vr512 = VMOVAPSZrm %0, 1, $noreg, 256, $noreg :: (load 64 from %ir.arrayidx.4, !tbaa !3)
    early-clobber %12:vr512 = nnan ninf nsz arcp contract afn reassoc VFCMADDCPHZm %10, killed %11, %1, 1, $noreg, 256, $noreg, implicit $mxcsr :: (load 64 from %ir.arrayidx2.4, !tbaa !3)
    $zmm0 = COPY %12
    RET 0, $zmm0

...
