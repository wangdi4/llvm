; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --no_x86_scrub_mem_shuffle --version 3
; RUN: llc < %s -mtriple=i386-unknown-linux-gnu -mattr=+avx | FileCheck %s --check-prefixes=X86-AVX
; RUN: llc < %s -mtriple=i386-unknown-linux-gnu -mattr=+avx512f,+avx512bw,+avx512dq,+avx512vl | FileCheck %s --check-prefixes=X86-AVX512
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx | FileCheck %s --check-prefixes=X64-AVX
; RUN: llc < %s -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512f,+avx512bw,+avx512dq,+avx512vl | FileCheck %s --check-prefixes=X64-AVX512

define void @move(ptr %from, ptr %to) {
; X86-AVX-LABEL: move:
; X86-AVX:       # %bb.0: # %entry
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX-NEXT:    vmovaps %ymm0, (%eax)
; X86-AVX-NEXT:    vzeroupper
; X86-AVX-NEXT:    retl
;
; X86-AVX512-LABEL: move:
; X86-AVX512:       # %bb.0: # %entry
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-NEXT:    vmovups (%ecx), %ymm0
; X86-AVX512-NEXT:    vmovaps %ymm0, (%eax)
; X86-AVX512-NEXT:    vzeroupper
; X86-AVX512-NEXT:    retl
;
; X64-AVX-LABEL: move:
; X64-AVX:       # %bb.0: # %entry
; X64-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX-NEXT:    vmovaps %ymm0, (%rsi)
; X64-AVX-NEXT:    vzeroupper
; X64-AVX-NEXT:    retq
;
; X64-AVX512-LABEL: move:
; X64-AVX512:       # %bb.0: # %entry
; X64-AVX512-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX512-NEXT:    vmovaps %ymm0, (%rsi)
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
entry:
  %0 = call <32 x i8> @llvm.x86.avx.ldu.dq.256(ptr %from)
  store <32 x i8> %0, ptr %to
  ret void
}

define <8 x i64> @broadcast(ptr %from, ptr %to) {
; X86-AVX-LABEL: broadcast:
; X86-AVX:       # %bb.0: # %entry
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    vmovups (%eax), %ymm0
; X86-AVX-NEXT:    vmovaps %ymm0, %ymm1
; X86-AVX-NEXT:    retl
;
; X86-AVX512-LABEL: broadcast:
; X86-AVX512:       # %bb.0: # %entry
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-NEXT:    vbroadcasti64x4 (%eax), %zmm0 # zmm0 = mem[0,1,2,3,0,1,2,3]
; X86-AVX512-NEXT:    retl
;
; X64-AVX-LABEL: broadcast:
; X64-AVX:       # %bb.0: # %entry
; X64-AVX-NEXT:    vmovups (%rdi), %ymm0
; X64-AVX-NEXT:    vmovaps %ymm0, %ymm1
; X64-AVX-NEXT:    retq
;
; X64-AVX512-LABEL: broadcast:
; X64-AVX512:       # %bb.0: # %entry
; X64-AVX512-NEXT:    vbroadcasti64x4 (%rdi), %zmm0 # zmm0 = mem[0,1,2,3,0,1,2,3]
; X64-AVX512-NEXT:    retq
entry:
  %0 = call <32 x i8> @llvm.x86.avx.ldu.dq.256(ptr %from)
  %1 = bitcast <32 x i8> %0 to <4 x i64>
  %shuffle.i = shufflevector <4 x i64> %1, <4 x i64> poison, <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 0, i32 1, i32 2, i32 3>
  ret <8 x i64> %shuffle.i
}

define <4 x i64> @add(ptr %lhs, ptr %rhs) {
; X86-AVX-LABEL: add:
; X86-AVX:       # %bb.0: # %entry
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX-NEXT:    vmovdqu (%ecx), %xmm0
; X86-AVX-NEXT:    vmovdqu 16(%ecx), %xmm1
; X86-AVX-NEXT:    vpaddd 16(%eax), %xmm1, %xmm1
; X86-AVX-NEXT:    vpaddd (%eax), %xmm0, %xmm0
; X86-AVX-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X86-AVX-NEXT:    retl
;
; X86-AVX512-LABEL: add:
; X86-AVX512:       # %bb.0: # %entry
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %eax
; X86-AVX512-NEXT:    movl {{[0-9]+}}(%esp), %ecx
; X86-AVX512-NEXT:    vmovdqu (%ecx), %ymm0
; X86-AVX512-NEXT:    vpaddd (%eax), %ymm0, %ymm0
; X86-AVX512-NEXT:    retl
;
; X64-AVX-LABEL: add:
; X64-AVX:       # %bb.0: # %entry
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 16(%rdi), %xmm1
; X64-AVX-NEXT:    vpaddd 16(%rsi), %xmm1, %xmm1
; X64-AVX-NEXT:    vpaddd (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vinsertf128 $1, %xmm1, %ymm0, %ymm0
; X64-AVX-NEXT:    retq
;
; X64-AVX512-LABEL: add:
; X64-AVX512:       # %bb.0: # %entry
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vpaddd (%rsi), %ymm0, %ymm0
; X64-AVX512-NEXT:    retq
entry:
  %0 = call <32 x i8> @llvm.x86.avx.ldu.dq.256(ptr %lhs)
  %1 = bitcast <32 x i8> %0 to <8 x i32>
  %2 = call <32 x i8> @llvm.x86.avx.ldu.dq.256(ptr %rhs)
  %3 = bitcast <32 x i8> %2 to <8 x i32>
  %4 = add <8 x i32> %1, %3
  %5 = bitcast <8 x i32> %4 to <4 x i64>
  ret <4 x i64> %5
}

declare <32 x i8> @llvm.x86.avx.ldu.dq.256(ptr)
