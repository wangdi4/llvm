; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -O0 -mtriple=x86_64-unknown-unknown -mattr=+avx512vl,+avx512dq,+avx512bw -enable-intel-advanced-opts | FileCheck %s --check-prefixes=X64
; RUN: llc < %s -O0 -mtriple=i686-unknown-unknown -mattr=+avx512vl,+avx512dq,+avx512bw -enable-intel-advanced-opts | FileCheck %s --check-prefixes=X86

define <8 x i1> @test_pseudo_kmovb_spill() nounwind {
; X64-LABEL: test_pseudo_kmovb_spill:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rbx
; X64-NEXT:    #APP
; X64-NEXT:    #NO_APP
; X64-NEXT:    movb $3, %dil
; X64-NEXT:    # implicit-def: $esi
; X64-NEXT:    movb %dil, %sil
; X64-NEXT:    kmovb %esi, %k0
; X64-NEXT:    #APP
; X64-NEXT:    #NO_APP
; X64-NEXT:    vpmovm2w %k0, %xmm0
; X64-NEXT:    popq %rbx
; X64-NEXT:    retq
;
; X86-LABEL: test_pseudo_kmovb_spill:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    subl $8, %esp
; X86-NEXT:    #APP
; X86-NEXT:    #NO_APP
; X86-NEXT:    movl %eax, {{[-0-9]+}}(%e{{[sb]}}p) # 4-byte Spill
; X86-NEXT:    movl %ecx, (%esp) # 4-byte Spill
; X86-NEXT:    movb $3, %cl
; X86-NEXT:    # implicit-def: $eax
; X86-NEXT:    movb %cl, %al
; X86-NEXT:    movl (%esp), %ecx # 4-byte Reload
; X86-NEXT:    kmovb %eax, %k0
; X86-NEXT:    movl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 4-byte Reload
; X86-NEXT:    #APP
; X86-NEXT:    #NO_APP
; X86-NEXT:    vpmovm2w %k0, %xmm0
; X86-NEXT:    addl $8, %esp
; X86-NEXT:    popl %ebx
; X86-NEXT:    retl
  %1 = call { i32, i32, i32, i32 } asm sideeffect "", "={ax},={bx},={cx},={dx},~{dirflag},~{fpsr},~{flags}"()
  %2 = bitcast i8 3 to <8 x i1>
  %a = extractvalue { i32, i32, i32, i32 } %1, 0
  %b = extractvalue { i32, i32, i32, i32 } %1, 1
  %c = extractvalue { i32, i32, i32, i32 } %1, 2
  %d = extractvalue { i32, i32, i32, i32 } %1, 3
  call void asm sideeffect "", "{ax},{bx},{cx},{dx},~{dirflag},~{fpsr},~{flags}"(i32 %a, i32 %b, i32 %c, i32 %d)
  ret <8 x i1> %2
}

define <16 x i1> @test_pseudo_kmovw_spill() nounwind {
; X64-LABEL: test_pseudo_kmovw_spill:
; X64:       # %bb.0:
; X64-NEXT:    pushq %rbx
; X64-NEXT:    #APP
; X64-NEXT:    #NO_APP
; X64-NEXT:    movw $3, %di
; X64-NEXT:    # implicit-def: $esi
; X64-NEXT:    movw %di, %si
; X64-NEXT:    kmovw %esi, %k0
; X64-NEXT:    #APP
; X64-NEXT:    #NO_APP
; X64-NEXT:    vpmovm2b %k0, %xmm0
; X64-NEXT:    popq %rbx
; X64-NEXT:    retq
;
; X86-LABEL: test_pseudo_kmovw_spill:
; X86:       # %bb.0:
; X86-NEXT:    pushl %ebx
; X86-NEXT:    pushl %edi
; X86-NEXT:    pushl %esi
; X86-NEXT:    #APP
; X86-NEXT:    #NO_APP
; X86-NEXT:    movw $3, %di
; X86-NEXT:    # implicit-def: $esi
; X86-NEXT:    movw %di, %si
; X86-NEXT:    kmovw %esi, %k0
; X86-NEXT:    #APP
; X86-NEXT:    #NO_APP
; X86-NEXT:    vpmovm2b %k0, %xmm0
; X86-NEXT:    popl %esi
; X86-NEXT:    popl %edi
; X86-NEXT:    popl %ebx
; X86-NEXT:    retl
  %1 = call { i32, i32, i32, i32 } asm sideeffect "", "={ax},={bx},={cx},={dx},~{dirflag},~{fpsr},~{flags}"()
  %2 = bitcast i16 3 to <16 x i1>
  %a = extractvalue { i32, i32, i32, i32 } %1, 0
  %b = extractvalue { i32, i32, i32, i32 } %1, 1
  %c = extractvalue { i32, i32, i32, i32 } %1, 2
  %d = extractvalue { i32, i32, i32, i32 } %1, 3
  call void asm sideeffect "", "{ax},{bx},{cx},{dx},~{dirflag},~{fpsr},~{flags}"(i32 %a, i32 %b, i32 %c, i32 %d)
  ret <16 x i1> %2
}
