; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -enable-intel-advanced-opts -mattr=+sse4.1 | FileCheck %s --check-prefix=SSE
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -enable-intel-advanced-opts -mattr=+avx2 | FileCheck %s --check-prefix=AVX
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -enable-intel-advanced-opts -mattr=+avx512f,+avx512bw,+avx512vl | FileCheck %s --check-prefixes=AVX512

;
; Truncate
;


define i1 @trunc_v2i64_v2i1(<2 x i64>) {
; SSE-LABEL: trunc_v2i64_v2i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v2i64_v2i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v2i64_v2i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastq {{.*#+}} xmm1 = [1,1]
; AVX512-NEXT:    vptest %xmm1, %xmm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    retq
  %a = trunc <2 x i64> %0 to <2 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v2i1(<2 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v4i32_v4i1(<4 x i32>) {
; SSE-LABEL: trunc_v4i32_v4i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v4i32_v4i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpbroadcastd {{.*#+}} xmm1 = [1,1,1,1]
; AVX-NEXT:    vptest %xmm1, %xmm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v4i32_v4i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastd {{.*#+}} xmm1 = [1,1,1,1]
; AVX512-NEXT:    vptest %xmm1, %xmm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    retq
  %a = trunc <4 x i32> %0 to <4 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v4i1(<4 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v6i32_v6i1(<6 x i32>) {
; SSE-LABEL: trunc_v6i32_v6i1:
; SSE:       # %bb.0:
; SSE-NEXT:    movl %r8d, %eax
; SSE-NEXT:    andl %esi, %edi
; SSE-NEXT:    andl %ecx, %edx
; SSE-NEXT:    andl %edi, %edx
; SSE-NEXT:    andl %r9d, %eax
; SSE-NEXT:    andl %edx, %eax
; SSE-NEXT:    andl $1, %eax
; SSE-NEXT:    # kill: def $al killed $al killed $eax
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v6i32_v6i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpshufb {{.*#+}} ymm0 = ymm0[0,1,4,5,8,9,12,13,u,u,u,u,u,u,u,u,16,17,20,21,24,25,28,29,u,u,u,u,u,u,u,u]
; AVX-NEXT:    vpermq {{.*#+}} ymm0 = ymm0[0,2,2,3]
; AVX-NEXT:    vpextrw $1, %xmm0, %eax
; AVX-NEXT:    vmovd %xmm0, %ecx
; AVX-NEXT:    andl %eax, %ecx
; AVX-NEXT:    vpextrw $2, %xmm0, %eax
; AVX-NEXT:    vpextrw $3, %xmm0, %edx
; AVX-NEXT:    andl %eax, %edx
; AVX-NEXT:    andl %ecx, %edx
; AVX-NEXT:    vpextrw $4, %xmm0, %ecx
; AVX-NEXT:    vpextrw $5, %xmm0, %eax
; AVX-NEXT:    andl %ecx, %eax
; AVX-NEXT:    andl %edx, %eax
; AVX-NEXT:    andl $1, %eax
; AVX-NEXT:    # kill: def $al killed $al killed $eax
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v6i32_v6i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpslld $31, %ymm0, %ymm0
; AVX512-NEXT:    vptestmd %ymm0, %ymm0, %k0
; AVX512-NEXT:    kshiftrw $4, %k0, %k1
; AVX512-NEXT:    kandw %k1, %k0, %k1
; AVX512-NEXT:    kshiftrw $2, %k0, %k0
; AVX512-NEXT:    kandw %k0, %k1, %k0
; AVX512-NEXT:    kshiftrw $1, %k0, %k1
; AVX512-NEXT:    kandw %k1, %k0, %k0
; AVX512-NEXT:    kmovd %k0, %eax
; AVX512-NEXT:    # kill: def $al killed $al killed $eax
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <6 x i32> %0 to <6 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v6i1(<6 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v8i16_v8i1(<8 x i8>) {
; SSE-LABEL: trunc_v8i16_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    movq %xmm0, %rax
; SSE-NEXT:    movabsq $72340172838076673, %rcx # imm = 0x101010101010101
; SSE-NEXT:    cmpq %rcx, %rax
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v8i16_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpand {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; AVX-NEXT:    vmovq %xmm0, %rax
; AVX-NEXT:    movabsq $72340172838076673, %rcx # imm = 0x101010101010101
; AVX-NEXT:    cmpq %rcx, %rax
; AVX-NEXT:    sete %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v8i16_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpand {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; AVX512-NEXT:    vmovq %xmm0, %rax
; AVX512-NEXT:    movabsq $72340172838076673, %rcx # imm = 0x101010101010101
; AVX512-NEXT:    cmpq %rcx, %rax
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    retq
  %a = trunc <8 x i8> %0 to <8 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v16i8_v16i1(<16 x i8>) {
; SSE-LABEL: trunc_v16i8_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v16i8_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v16i8_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    retq
  %a = trunc <16 x i8> %0 to <16 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v4i64_v4i1(<4 x i64>) {
; SSE-LABEL: trunc_v4i64_v4i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v4i64_v4i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpbroadcastq {{.*#+}} ymm1 = [1,1,1,1]
; AVX-NEXT:    vptest %ymm1, %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v4i64_v4i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastq {{.*#+}} ymm1 = [1,1,1,1]
; AVX512-NEXT:    vptest %ymm1, %ymm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <4 x i64> %0 to <4 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v4i1(<4 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v8i32_v8i1(<8 x i32>) {
; SSE-LABEL: trunc_v8i32_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v8i32_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpbroadcastd {{.*#+}} ymm1 = [1,1,1,1,1,1,1,1]
; AVX-NEXT:    vptest %ymm1, %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v8i32_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastd {{.*#+}} ymm1 = [1,1,1,1,1,1,1,1]
; AVX512-NEXT:    vptest %ymm1, %ymm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <8 x i32> %0 to <8 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v16i16_v16i1(<16 x i16>) {
; SSE-LABEL: trunc_v16i16_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v16i16_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v16i16_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <16 x i16> %0 to <16 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v32i8_v32i1(<32 x i8>) {
; SSE-LABEL: trunc_v32i8_v32i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v32i8_v32i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v32i8_v32i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX512-NEXT:    setb %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <32 x i8> %0 to <32 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v32i1(<32 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v8i64_v8i1(<8 x i64>) {
; SSE-LABEL: trunc_v8i64_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm3, %xmm1
; SSE-NEXT:    pand %xmm2, %xmm0
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v8i64_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpand %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vpbroadcastq {{.*#+}} ymm1 = [1,1,1,1]
; AVX-NEXT:    vptest %ymm1, %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v8i64_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vpbroadcastq {{.*#+}} zmm1 = [1,1,1,1,1,1,1,1]
; AVX512-NEXT:    vpandq %zmm1, %zmm0, %zmm0
; AVX512-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <8 x i64> %0 to <8 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v16i32_v16i1(<16 x i32>) {
; SSE-LABEL: trunc_v16i32_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm3, %xmm1
; SSE-NEXT:    pand %xmm2, %xmm0
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v16i32_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpand %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vpbroadcastd {{.*#+}} ymm1 = [1,1,1,1,1,1,1,1]
; AVX-NEXT:    vptest %ymm1, %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v16i32_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptestnmd {{\.?LCPI[0-9]+_[0-9]+}}(%rip){1to16}, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <16 x i32> %0 to <16 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v32i16_v32i1(<32 x i16>) {
; SSE-LABEL: trunc_v32i16_v32i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm3, %xmm1
; SSE-NEXT:    pand %xmm2, %xmm0
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v32i16_v32i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpand %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v32i16_v32i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovdqa64 {{.*#+}} zmm1 = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
; AVX512-NEXT:    vpandq %zmm1, %zmm0, %zmm0
; AVX512-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <32 x i16> %0 to <32 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v32i1(<32 x i1> %a)
  ret i1 %b
}

define i1 @trunc_v64i8_v64i1(<64 x i8>) {
; SSE-LABEL: trunc_v64i8_v64i1:
; SSE:       # %bb.0:
; SSE-NEXT:    pand %xmm3, %xmm1
; SSE-NEXT:    pand %xmm2, %xmm0
; SSE-NEXT:    pand %xmm1, %xmm0
; SSE-NEXT:    ptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0
; SSE-NEXT:    setb %al
; SSE-NEXT:    retq
;
; AVX-LABEL: trunc_v64i8_v64i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpand %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0
; AVX-NEXT:    setb %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: trunc_v64i8_v64i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovdqa64 {{.*#+}} zmm1 = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
; AVX512-NEXT:    vpandq %zmm1, %zmm0, %zmm0
; AVX512-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = trunc <64 x i8> %0 to <64 x i1>
  %b = call i1 @llvm.experimental.vector.reduce.and.v64i1(<64 x i1> %a)
  ret i1 %b
}


define i1 @icmp_v2i64_v2i1(<2 x i64>) {
; SSE-LABEL: icmp_v2i64_v2i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v2i64_v2i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %xmm0, %xmm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v2i64_v2i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %xmm0, %xmm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    retq
  %a = icmp eq <2 x i64> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v2i1(<2 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v4i32_v4i1(<4 x i32>) {
; SSE-LABEL: icmp_v4i32_v4i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v4i32_v4i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %xmm0, %xmm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v4i32_v4i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %xmm0, %xmm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    retq
  %a = icmp eq <4 x i32> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v4i1(<4 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v8i16_v8i1(<8 x i8>) {
; SSE-LABEL: icmp_v8i16_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    movq %xmm0, %rax
; SSE-NEXT:    testq %rax, %rax
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v8i16_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovq %xmm0, %rax
; AVX-NEXT:    testq %rax, %rax
; AVX-NEXT:    sete %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v8i16_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vmovq %xmm0, %rax
; AVX512-NEXT:    testq %rax, %rax
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    retq
  %a = icmp eq <8 x i8> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v16i8_v16i1(<16 x i8>) {
; SSE-LABEL: icmp_v16i8_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v16i8_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %xmm0, %xmm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v16i8_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %xmm0, %xmm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    retq
  %a = icmp eq <16 x i8> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v4i64_v4i1(<4 x i64>) {
; SSE-LABEL: icmp_v4i64_v4i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v4i64_v4i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v4i64_v4i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %ymm0, %ymm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <4 x i64> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v4i1(<4 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v8i32_v8i1(<8 x i32>) {
; SSE-LABEL: icmp_v8i32_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v8i32_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v8i32_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %ymm0, %ymm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <8 x i32> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v16i16_v16i1(<16 x i16>) {
; SSE-LABEL: icmp_v16i16_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v16i16_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v16i16_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %ymm0, %ymm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <16 x i16> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v32i8_v32i1(<32 x i8>) {
; SSE-LABEL: icmp_v32i8_v32i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v32i8_v32i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v32i8_v32i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptest %ymm0, %ymm0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <32 x i8> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v32i1(<32 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v8i64_v8i1(<8 x i64>) {
; SSE-LABEL: icmp_v8i64_v8i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm3, %xmm1
; SSE-NEXT:    por %xmm2, %xmm0
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v8i64_v8i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v8i64_v8i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptestmd %zmm0, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <8 x i64> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v16i32_v16i1(<16 x i32>) {
; SSE-LABEL: icmp_v16i32_v16i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm3, %xmm1
; SSE-NEXT:    por %xmm2, %xmm0
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v16i32_v16i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v16i32_v16i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptestmd %zmm0, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <16 x i32> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v32i16_v32i1(<32 x i16>) {
; SSE-LABEL: icmp_v32i16_v32i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm3, %xmm1
; SSE-NEXT:    por %xmm2, %xmm0
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v32i16_v32i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v32i16_v32i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptestmd %zmm0, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <32 x i16> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v32i1(<32 x i1> %a)
  ret i1 %b
}

define i1 @icmp_v64i8_v64i1(<64 x i8>) {
; SSE-LABEL: icmp_v64i8_v64i1:
; SSE:       # %bb.0:
; SSE-NEXT:    por %xmm3, %xmm1
; SSE-NEXT:    por %xmm2, %xmm0
; SSE-NEXT:    por %xmm1, %xmm0
; SSE-NEXT:    ptest %xmm0, %xmm0
; SSE-NEXT:    sete %al
; SSE-NEXT:    retq
;
; AVX-LABEL: icmp_v64i8_v64i1:
; AVX:       # %bb.0:
; AVX-NEXT:    vpor %ymm1, %ymm0, %ymm0
; AVX-NEXT:    vptest %ymm0, %ymm0
; AVX-NEXT:    sete %al
; AVX-NEXT:    vzeroupper
; AVX-NEXT:    retq
;
; AVX512-LABEL: icmp_v64i8_v64i1:
; AVX512:       # %bb.0:
; AVX512-NEXT:    vptestmd %zmm0, %zmm0, %k0
; AVX512-NEXT:    kortestw %k0, %k0
; AVX512-NEXT:    sete %al
; AVX512-NEXT:    vzeroupper
; AVX512-NEXT:    retq
  %a = icmp eq <64 x i8> %0, zeroinitializer
  %b = call i1 @llvm.experimental.vector.reduce.and.v64i1(<64 x i1> %a)
  ret i1 %b
}

declare i1 @llvm.experimental.vector.reduce.and.v2i1(<2 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v4i1(<4 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v6i1(<6 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v8i1(<8 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v16i1(<16 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v32i1(<32 x i1>)
declare i1 @llvm.experimental.vector.reduce.and.v64i1(<64 x i1>)
