; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_vnni_fp8
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512vnnifp8 | FileCheck %s --check-prefixes=CHECK,X64
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vl,+avx512vnnifp8 | FileCheck %s --check-prefixes=CHECK,X86

define <4 x float> @test_mm_dpbf8_ps(<4 x float> %__A, <2 x i64> %__B, <2 x i64> %__C) {
; CHECK-LABEL: test_mm_dpbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbf8ps %xmm2, %xmm1, %xmm0 # encoding: [0x62,0xf5,0x74,0x08,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__B to <4 x float>
  %2 = bitcast <2 x i64> %__C to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  ret <4 x float> %3
}

define <4 x float> @test_mm_mask_dpbf8_ps(<4 x float> %__A, i8 zeroext %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_mask_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x74,0x09,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_mask_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x74,0x09,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> %__A
  ret <4 x float> %5
}

define <4 x float> @test_mm_maskz_dpbf8_ps(i8 zeroext %__A, <4 x float> %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_maskz_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0x89,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_maskz_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0x89,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps128(<4 x float> %__B, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> zeroinitializer
  ret <4 x float> %5
}

define <8 x float> @test_mm256_dpbf8_ps(<8 x float> %__A, <4 x i64> %__B, <4 x i64> %__C) local_unnamed_addr #1 {
; CHECK-LABEL: test_mm256_dpbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbf8ps %ymm2, %ymm1, %ymm0 # encoding: [0x62,0xf5,0x74,0x28,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__B to <8 x float>
  %2 = bitcast <4 x i64> %__C to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  ret <8 x float> %3
}

define <8 x float> @test_mm256_mask_dpbf8_ps(<8 x float> %__A, i8 zeroext %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_mask_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x74,0x29,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_mask_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x74,0x29,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> %__A
  ret <8 x float> %5
}

define <8 x float> @test_mm256_maskz_dpbf8_ps(i8 zeroext %__A, <8 x float> %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_maskz_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0xa9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_maskz_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0xa9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps256(<8 x float> %__B, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> zeroinitializer
  ret <8 x float> %5
}

define <4 x float> @test_mm_dpbhf8_ps(<4 x float> %__A, <2 x i64> %__B, <2 x i64> %__C) {
; CHECK-LABEL: test_mm_dpbhf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbhf8ps %xmm2, %xmm1, %xmm0 # encoding: [0x62,0xf5,0x77,0x08,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__B to <4 x float>
  %2 = bitcast <2 x i64> %__C to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  ret <4 x float> %3
}

define <4 x float> @test_mm_mask_dpbhf8_ps(<4 x float> %__A, i8 zeroext %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_mask_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x77,0x09,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_mask_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbhf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x77,0x09,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> %__A
  ret <4 x float> %5
}

define <4 x float> @test_mm_maskz_dpbhf8_ps(i8 zeroext %__A, <4 x float> %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_maskz_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0x89,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_maskz_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbhf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0x89,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps128(<4 x float> %__B, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> zeroinitializer
  ret <4 x float> %5
}

define <8 x float> @test_mm256_dpbhf8_ps(<8 x float> %__A, <4 x i64> %__B, <4 x i64> %__C) local_unnamed_addr #1 {
; CHECK-LABEL: test_mm256_dpbhf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbhf8ps %ymm2, %ymm1, %ymm0 # encoding: [0x62,0xf5,0x77,0x28,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__B to <8 x float>
  %2 = bitcast <4 x i64> %__C to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  ret <8 x float> %3
}

define <8 x float> @test_mm256_mask_dpbhf8_ps(<8 x float> %__A, i8 zeroext %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_mask_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x77,0x29,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_mask_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbhf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x77,0x29,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> %__A
  ret <8 x float> %5
}

define <8 x float> @test_mm256_maskz_dpbhf8_ps(i8 zeroext %__A, <8 x float> %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_maskz_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0xa9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_maskz_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdpbhf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0xa9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps256(<8 x float> %__B, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> zeroinitializer
  ret <8 x float> %5
}

define <4 x float> @test_mm_dphbf8_ps(<4 x float> %__A, <2 x i64> %__B, <2 x i64> %__C) {
; CHECK-LABEL: test_mm_dphbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphbf8ps %xmm2, %xmm1, %xmm0 # encoding: [0x62,0xf5,0x76,0x08,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__B to <4 x float>
  %2 = bitcast <2 x i64> %__C to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  ret <4 x float> %3
}

define <4 x float> @test_mm_mask_dphbf8_ps(<4 x float> %__A, i8 zeroext %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_mask_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x76,0x09,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_mask_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphbf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x76,0x09,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> %__A
  ret <4 x float> %5
}

define <4 x float> @test_mm_maskz_dphbf8_ps(i8 zeroext %__A, <4 x float> %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_maskz_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0x89,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_maskz_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphbf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0x89,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps128(<4 x float> %__B, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> zeroinitializer
  ret <4 x float> %5
}

define <8 x float> @test_mm256_dphbf8_ps(<8 x float> %__A, <4 x i64> %__B, <4 x i64> %__C) local_unnamed_addr #1 {
; CHECK-LABEL: test_mm256_dphbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphbf8ps %ymm2, %ymm1, %ymm0 # encoding: [0x62,0xf5,0x76,0x28,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__B to <8 x float>
  %2 = bitcast <4 x i64> %__C to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  ret <8 x float> %3
}

define <8 x float> @test_mm256_mask_dphbf8_ps(<8 x float> %__A, i8 zeroext %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_mask_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x76,0x29,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_mask_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphbf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x76,0x29,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> %__A
  ret <8 x float> %5
}

define <8 x float> @test_mm256_maskz_dphbf8_ps(i8 zeroext %__A, <8 x float> %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_maskz_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0xa9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_maskz_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphbf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0xa9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps256(<8 x float> %__B, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> zeroinitializer
  ret <8 x float> %5
}

define <4 x float> @test_mm_dphf8_ps(<4 x float> %__A, <2 x i64> %__B, <2 x i64> %__C) {
; CHECK-LABEL: test_mm_dphf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphf8ps %xmm2, %xmm1, %xmm0 # encoding: [0x62,0xf5,0x75,0x08,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__B to <4 x float>
  %2 = bitcast <2 x i64> %__C to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  ret <4 x float> %3
}

define <4 x float> @test_mm_mask_dphf8_ps(<4 x float> %__A, i8 zeroext %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_mask_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x09,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_mask_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphf8ps %xmm2, %xmm1, %xmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x09,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphf8ps128(<4 x float> %__A, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> %__A
  ret <4 x float> %5
}

define <4 x float> @test_mm_maskz_dphf8_ps(i8 zeroext %__A, <4 x float> %__B, <2 x i64> %__C, <2 x i64> %__D) {
; X64-LABEL: test_mm_maskz_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0x89,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm_maskz_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphf8ps %xmm2, %xmm1, %xmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0x89,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <2 x i64> %__C to <4 x float>
  %2 = bitcast <2 x i64> %__D to <4 x float>
  %3 = tail call <4 x float> @llvm.x86.avx512vnnifp8.vdphf8ps128(<4 x float> %__B, <4 x float> %1, <4 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %extract.i = shufflevector <8 x i1> %4, <8 x i1> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %5 = select <4 x i1> %extract.i, <4 x float> %3, <4 x float> zeroinitializer
  ret <4 x float> %5
}

define <8 x float> @test_mm256_dphf8_ps(<8 x float> %__A, <4 x i64> %__B, <4 x i64> %__C) local_unnamed_addr #1 {
; CHECK-LABEL: test_mm256_dphf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphf8ps %ymm2, %ymm1, %ymm0 # encoding: [0x62,0xf5,0x75,0x28,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__B to <8 x float>
  %2 = bitcast <4 x i64> %__C to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  ret <8 x float> %3
}

define <8 x float> @test_mm256_mask_dphf8_ps(<8 x float> %__A, i8 zeroext %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_mask_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x75,0x29,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_mask_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphf8ps %ymm2, %ymm1, %ymm0 {%k1} # encoding: [0x62,0xf5,0x75,0x29,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphf8ps256(<8 x float> %__A, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__B to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> %__A
  ret <8 x float> %5
}

define <8 x float> @test_mm256_maskz_dphf8_ps(i8 zeroext %__A, <8 x float> %__B, <4 x i64> %__C, <4 x i64> %__D) local_unnamed_addr #1 {
; X64-LABEL: test_mm256_maskz_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xa9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm256_maskz_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax # encoding: [0x0f,0xb6,0x44,0x24,0x04]
; X86-NEXT:    kmovw %eax, %k1 # encoding: [0xc5,0xf8,0x92,0xc8]
; X86-NEXT:    vdphf8ps %ymm2, %ymm1, %ymm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xa9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <4 x i64> %__C to <8 x float>
  %2 = bitcast <4 x i64> %__D to <8 x float>
  %3 = tail call <8 x float> @llvm.x86.avx512vnnifp8.vdphf8ps256(<8 x float> %__B, <8 x float> %1, <8 x float> %2)
  %4 = bitcast i8 %__A to <8 x i1>
  %5 = select <8 x i1> %4, <8 x float> %3, <8 x float> zeroinitializer
  ret <8 x float> %5
}

declare <4 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps128(<4 x float>, <4 x float>, <4 x float>)

declare <8 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps256(<8 x float>, <8 x float>, <8 x float>)

declare <4 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps128(<4 x float>, <4 x float>, <4 x float>)

declare <8 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps256(<8 x float>, <8 x float>, <8 x float>)

declare <4 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps128(<4 x float>, <4 x float>, <4 x float>)

declare <8 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps256(<8 x float>, <8 x float>, <8 x float>)

declare <4 x float> @llvm.x86.avx512vnnifp8.vdphf8ps128(<4 x float>, <4 x float>, <4 x float>)

declare <8 x float> @llvm.x86.avx512vnnifp8.vdphf8ps256(<8 x float>, <8 x float>, <8 x float>)
