; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_vnni_fp8
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vnnifp8 | FileCheck %s --check-prefixes=CHECK,X64
; RUN: llc < %s -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512vnnifp8 | FileCheck %s --check-prefixes=CHECK,X86

define <16 x float> @test_mm512_dpbf8_ps(<16 x float> %__A, <8 x i64> %__B, <8 x i64> %__C) {
; CHECK-LABEL: test_mm512_dpbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbf8ps %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x74,0x48,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__B to <16 x float>
  %2 = bitcast <8 x i64> %__C to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  ret <16 x float> %3
}

define <16 x float> @test_mm512_mask_dpbf8_ps(<16 x float> %__A, i16 zeroext %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_mask_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x74,0x49,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_mask_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdpbf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x74,0x49,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__B to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> %__A
  ret <16 x float> %5
}

define <16 x float> @test_mm512_maskz_dpbf8_ps(i16 zeroext %__A, <16 x float> %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_maskz_dpbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0xc9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_maskz_dpbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdpbf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x74,0xc9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps512(<16 x float> %__B, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__A to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> zeroinitializer
  ret <16 x float> %5
}

define <16 x float> @test_mm512_dpbhf8_ps(<16 x float> %__A, <8 x i64> %__B, <8 x i64> %__C) {
; CHECK-LABEL: test_mm512_dpbhf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdpbhf8ps %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x77,0x48,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__B to <16 x float>
  %2 = bitcast <8 x i64> %__C to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  ret <16 x float> %3
}

define <16 x float> @test_mm512_mask_dpbhf8_ps(<16 x float> %__A, i16 zeroext %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_mask_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x77,0x49,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_mask_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdpbhf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x77,0x49,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__B to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> %__A
  ret <16 x float> %5
}

define <16 x float> @test_mm512_maskz_dpbhf8_ps(i16 zeroext %__A, <16 x float> %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_maskz_dpbhf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdpbhf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0xc9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_maskz_dpbhf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdpbhf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x77,0xc9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps512(<16 x float> %__B, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__A to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> zeroinitializer
  ret <16 x float> %5
}

define <16 x float> @test_mm512_dphbf8_ps(<16 x float> %__A, <8 x i64> %__B, <8 x i64> %__C) {
; CHECK-LABEL: test_mm512_dphbf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphbf8ps %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x76,0x48,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__B to <16 x float>
  %2 = bitcast <8 x i64> %__C to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  ret <16 x float> %3
}

define <16 x float> @test_mm512_mask_dphbf8_ps(<16 x float> %__A, i16 zeroext %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_mask_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x76,0x49,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_mask_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdphbf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x76,0x49,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__B to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> %__A
  ret <16 x float> %5
}

define <16 x float> @test_mm512_maskz_dphbf8_ps(i16 zeroext %__A, <16 x float> %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_maskz_dphbf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphbf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0xc9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_maskz_dphbf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdphbf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x76,0xc9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps512(<16 x float> %__B, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__A to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> zeroinitializer
  ret <16 x float> %5
}

define <16 x float> @test_mm512_dphf8_ps(<16 x float> %__A, <8 x i64> %__B, <8 x i64> %__C) {
; CHECK-LABEL: test_mm512_dphf8_ps:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdphf8ps %zmm2, %zmm1, %zmm0 # encoding: [0x62,0xf5,0x75,0x48,0x50,0xc2]
; CHECK-NEXT:    ret{{[l|q]}} # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__B to <16 x float>
  %2 = bitcast <8 x i64> %__C to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  ret <16 x float> %3
}

define <16 x float> @test_mm512_mask_dphf8_ps(<16 x float> %__A, i16 zeroext %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_mask_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_mask_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdphf8ps %zmm2, %zmm1, %zmm0 {%k1} # encoding: [0x62,0xf5,0x75,0x49,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphf8ps512(<16 x float> %__A, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__B to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> %__A
  ret <16 x float> %5
}

define <16 x float> @test_mm512_maskz_dphf8_ps(i16 zeroext %__A, <16 x float> %__B, <8 x i64> %__C, <8 x i64> %__D) {
; X64-LABEL: test_mm512_maskz_dphf8_ps:
; X64:       # %bb.0:
; X64-NEXT:    kmovw %edi, %k1 # encoding: [0xc5,0xf8,0x92,0xcf]
; X64-NEXT:    vdphf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x50,0xc2]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_mm512_maskz_dphf8_ps:
; X86:       # %bb.0:
; X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1 # encoding: [0xc5,0xf8,0x90,0x4c,0x24,0x04]
; X86-NEXT:    vdphf8ps %zmm2, %zmm1, %zmm0 {%k1} {z} # encoding: [0x62,0xf5,0x75,0xc9,0x50,0xc2]
; X86-NEXT:    retl # encoding: [0xc3]
  %1 = bitcast <8 x i64> %__C to <16 x float>
  %2 = bitcast <8 x i64> %__D to <16 x float>
  %3 = tail call <16 x float> @llvm.x86.avx512vnnifp8.vdphf8ps512(<16 x float> %__B, <16 x float> %1, <16 x float> %2)
  %4 = bitcast i16 %__A to <16 x i1>
  %5 = select <16 x i1> %4, <16 x float> %3, <16 x float> zeroinitializer
  ret <16 x float> %5
}

declare <16 x float> @llvm.x86.avx512vnnifp8.vdpbf8ps512(<16 x float>, <16 x float>, <16 x float>)

declare <16 x float> @llvm.x86.avx512vnnifp8.vdpbhf8ps512(<16 x float>, <16 x float>, <16 x float>)

declare <16 x float> @llvm.x86.avx512vnnifp8.vdphbf8ps512(<16 x float>, <16 x float>, <16 x float>)

declare <16 x float> @llvm.x86.avx512vnnifp8.vdphf8ps512(<16 x float>, <16 x float>, <16 x float>)
