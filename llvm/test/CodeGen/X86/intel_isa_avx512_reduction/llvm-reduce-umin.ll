; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_reduction
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mattr=+avx512reduction,+avx512vl | FileCheck %s --check-prefixes=ALL,AVX512REDUCTION
; RUN: llc < %s -verify-machineinstrs -mtriple=x86_64-unknown-unknown -mattr=+avx512f,+avx512vl | FileCheck %s --check-prefixes=ALL,AVX512F

define i64 @reduce_uminq_13xi64(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminq_13xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa64 64(%rdi), %zmm0
; AVX512REDUCTION-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512REDUCTION-NEXT:    movb $32, %al
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    movb $64, %al
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    movb $-128, %al
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    vpminuq (%rdi), %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vphrminq %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_13xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa64 64(%rdi), %zmm0
; AVX512F-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512F-NEXT:    movb $32, %al
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    movb $64, %al
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    movb $-128, %al
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    vpminuq (%rdi), %zmm0, %zmm0
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminuq %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrq $1, %xmm0, %rax
; AVX512F-NEXT:    vmovq %xmm0, %rcx
; AVX512F-NEXT:    cmpq %rax, %rcx
; AVX512F-NEXT:    cmovbq %rcx, %rax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <13 x i64>, ptr %p
  %res = tail call i64 @llvm.vector.reduce.umin.v13i64(<13 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_8xi64(<8 x i64> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminq_8xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminq %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_8xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminuq %zmm1, %zmm0, %zmm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovq %xmm0, %rax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i64 @llvm.vector.reduce.umin.v8i64(<8 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_7xi64(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminq_7xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512REDUCTION-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512REDUCTION-NEXT:    movb $-128, %al
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    vphrminq %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_7xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512F-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512F-NEXT:    movb $-128, %al
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa64 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminuq %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrq $1, %xmm0, %rax
; AVX512F-NEXT:    vmovq %xmm0, %rcx
; AVX512F-NEXT:    cmpq %rax, %rcx
; AVX512F-NEXT:    cmovbq %rcx, %rax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <7 x i64>, ptr %p
  %res = tail call i64 @llvm.vector.reduce.umin.v7i64(<7 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_4xi64(<4 x i64> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminq_4xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminq %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_4xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovq %xmm0, %rax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i64 @llvm.vector.reduce.umin.v4i64(<4 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_3xi64(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminq_3xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} ymm0 = mem[0,1,2,3,4,5],ymm0[6,7]
; AVX512REDUCTION-NEXT:    vphrminq %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_3xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512F-NEXT:    vpblendd {{.*#+}} ymm0 = mem[0,1,2,3,4,5],ymm0[6,7]
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrq $1, %xmm0, %rax
; AVX512F-NEXT:    vmovq %xmm0, %rcx
; AVX512F-NEXT:    cmpq %rax, %rcx
; AVX512F-NEXT:    cmovbq %rcx, %rax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <3 x i64>, ptr %p
  %res = tail call i64 @llvm.vector.reduce.umin.v3i64(<3 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_2xi64(<2 x i64> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminq_2xi64:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminq %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovq %xmm0, %rax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminq_2xi64:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminuq %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovq %xmm0, %rax
; AVX512F-NEXT:    retq
  %res = tail call i64 @llvm.vector.reduce.umin.v2i64(<2 x i64> %vec)
  ret i64 %res
}

define i64 @reduce_uminq_1xi64(<1 x i64> %vec) {
; ALL-LABEL: reduce_uminq_1xi64:
; ALL:       # %bb.0:
; ALL-NEXT:    movq %rdi, %rax
; ALL-NEXT:    retq
  %res = tail call i64 @llvm.vector.reduce.umin.v1i64(<1 x i64> %vec)
  ret i64 %res
}

declare i64 @llvm.vector.reduce.umin.v13i64(<13 x i64>)
declare i64 @llvm.vector.reduce.umin.v8i64(<8 x i64>)
declare i64 @llvm.vector.reduce.umin.v7i64(<7 x i64>)
declare i64 @llvm.vector.reduce.umin.v4i64(<4 x i64>)
declare i64 @llvm.vector.reduce.umin.v3i64(<3 x i64>)
declare i64 @llvm.vector.reduce.umin.v2i64(<2 x i64>)
declare i64 @llvm.vector.reduce.umin.v1i64(<1 x i64>)

define i32 @reduce_umind_17xi32(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_umind_17xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295>
; AVX512REDUCTION-NEXT:    vpinsrd $0, 64(%rdi), %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovdqa64 {{.*#+}} zmm1 = <u,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295>
; AVX512REDUCTION-NEXT:    vinserti32x4 $0, %xmm0, %zmm1, %zmm0
; AVX512REDUCTION-NEXT:    vpminud (%rdi), %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vphrmind %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_17xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295>
; AVX512F-NEXT:    vpinsrd $0, 64(%rdi), %xmm0, %xmm0
; AVX512F-NEXT:    vmovdqa64 {{.*#+}} zmm1 = <u,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295,4294967295>
; AVX512F-NEXT:    vinserti32x4 $0, %xmm0, %zmm1, %zmm0
; AVX512F-NEXT:    vpminud (%rdi), %zmm0, %zmm0
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminud %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrd $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpl %eax, %ecx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrd $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrd $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <17 x i32>, ptr %p
  %res = tail call i32 @llvm.vector.reduce.umin.v17i32(<17 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_16xi32(<16 x i32> %vec) {
; AVX512REDUCTION-LABEL: reduce_umind_16xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrmind %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_16xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminud %zmm1, %zmm0, %zmm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i32 @llvm.vector.reduce.umin.v16i32(<16 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_13xi32(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_umind_13xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512REDUCTION-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512REDUCTION-NEXT:    movw $8192, %ax # imm = 0x2000
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    movw $16384, %ax # imm = 0x4000
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    movw $-32768, %ax # imm = 0x8000
; AVX512REDUCTION-NEXT:    kmovw %eax, %k1
; AVX512REDUCTION-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512REDUCTION-NEXT:    vphrmind %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_13xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512F-NEXT:    vpternlogd $255, %zmm1, %zmm1, %zmm1
; AVX512F-NEXT:    movw $8192, %ax # imm = 0x2000
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    movw $16384, %ax # imm = 0x4000
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    movw $-32768, %ax # imm = 0x8000
; AVX512F-NEXT:    kmovw %eax, %k1
; AVX512F-NEXT:    vmovdqa32 %zmm1, %zmm0 {%k1}
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminud %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrd $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpl %eax, %ecx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrd $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrd $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <13 x i32>, ptr %p
  %res = tail call i32 @llvm.vector.reduce.umin.v13i32(<13 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_8xi32(<8 x i32> %vec) {
; AVX512REDUCTION-LABEL: reduce_umind_8xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrmind %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_8xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i32 @llvm.vector.reduce.umin.v8i32(<8 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_7xi32(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_umind_7xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} ymm0 = mem[0,1,2,3,4,5,6],ymm0[7]
; AVX512REDUCTION-NEXT:    vphrmind %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_7xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512F-NEXT:    vpblendd {{.*#+}} ymm0 = mem[0,1,2,3,4,5,6],ymm0[7]
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrd $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpl %eax, %ecx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrd $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrd $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <7 x i32>, ptr %p
  %res = tail call i32 @llvm.vector.reduce.umin.v7i32(<7 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_4xi32(<4 x i32> %vec) {
; AVX512REDUCTION-LABEL: reduce_umind_4xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrmind %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_4xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[2,3,2,3]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    retq
  %res = tail call i32 @llvm.vector.reduce.umin.v4i32(<4 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_3xi32(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_umind_3xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm0, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} xmm0 = mem[0,1,2],xmm0[3]
; AVX512REDUCTION-NEXT:    vphrmind %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_3xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    movl (%rdi), %ecx
; AVX512F-NEXT:    movl 4(%rdi), %eax
; AVX512F-NEXT:    cmpl %eax, %ecx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    movl 8(%rdi), %ecx
; AVX512F-NEXT:    cmpl %ecx, %eax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    retq
  %vec= load <3 x i32>, ptr %p
  %res = tail call i32 @llvm.vector.reduce.umin.v3i32(<3 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_2xi32(<2 x i32> %vec) {
; AVX512REDUCTION-LABEL: reduce_umind_2xi32:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} xmm0 = xmm0[0,1],xmm1[2,3]
; AVX512REDUCTION-NEXT:    vphrmind %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_umind_2xi32:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminud %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    retq
  %res = tail call i32 @llvm.vector.reduce.umin.v2i32(<2 x i32> %vec)
  ret i32 %res
}

define i32 @reduce_umind_1xi32(<1 x i32> %vec) {
; ALL-LABEL: reduce_umind_1xi32:
; ALL:       # %bb.0:
; ALL-NEXT:    movl %edi, %eax
; ALL-NEXT:    retq
  %res = tail call i32 @llvm.vector.reduce.umin.v1i32(<1 x i32> %vec)
  ret i32 %res
}

declare i32 @llvm.vector.reduce.umin.v17i32(<17 x i32>)
declare i32 @llvm.vector.reduce.umin.v16i32(<16 x i32>)
declare i32 @llvm.vector.reduce.umin.v13i32(<13 x i32>)
declare i32 @llvm.vector.reduce.umin.v8i32(<8 x i32>)
declare i32 @llvm.vector.reduce.umin.v7i32(<7 x i32>)
declare i32 @llvm.vector.reduce.umin.v4i32(<4 x i32>)
declare i32 @llvm.vector.reduce.umin.v3i32(<3 x i32>)
declare i32 @llvm.vector.reduce.umin.v2i32(<2 x i32>)
declare i32 @llvm.vector.reduce.umin.v1i32(<1 x i32>)

define i16 @reduce_uminw_33xi16(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminw_33xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535>
; AVX512REDUCTION-NEXT:    vpinsrw $0, 64(%rdi), %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],mem[4,5,6,7]
; AVX512REDUCTION-NEXT:    vpminuw (%rdi), %ymm0, %ymm0
; AVX512REDUCTION-NEXT:    vinserti64x4 $1, 32(%rdi), %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vphrminw %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_33xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535,65535>
; AVX512F-NEXT:    vpinsrw $0, 64(%rdi), %xmm0, %xmm0
; AVX512F-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],mem[4,5,6,7]
; AVX512F-NEXT:    vpminuw (%rdi), %ymm0, %ymm0
; AVX512F-NEXT:    vpminuw 32(%rdi), %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrw $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpw %ax, %cx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrw $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <33 x i16>, ptr %p
  %res = tail call i16 @llvm.vector.reduce.umin.v33i16(<33 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_32xi16(<32 x i16> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminw_32xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminw %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_32xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminuw %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v32i16(<32 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_17xi16(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminw_17xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512REDUCTION-NEXT:    vmovdqa64 {{.*#+}} zmm1 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,65535,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
; AVX512REDUCTION-NEXT:    vpternlogq $248, {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %zmm0, %zmm1
; AVX512REDUCTION-NEXT:    vpternlogd $255, %zmm0, %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vmovdqa64 {{.*#+}} zmm2 = [0,1,2,3,4,5,6,7,8,25,26,27,28,29,30,31]
; AVX512REDUCTION-NEXT:    vpermi2d %zmm0, %zmm1, %zmm2
; AVX512REDUCTION-NEXT:    vphrminw %zmm2, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_17xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512F-NEXT:    vmovdqa64 {{.*#+}} zmm1 = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,65535,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
; AVX512F-NEXT:    vpternlogq $248, {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %zmm0, %zmm1
; AVX512F-NEXT:    vpternlogd $255, %zmm0, %zmm0, %zmm0
; AVX512F-NEXT:    vmovdqa64 {{.*#+}} zmm2 = [0,1,2,3,4,5,6,7,8,25,26,27,28,29,30,31]
; AVX512F-NEXT:    vpermi2d %zmm0, %zmm1, %zmm2
; AVX512F-NEXT:    vextracti64x4 $1, %zmm2, %ymm0
; AVX512F-NEXT:    vpminuw %ymm0, %ymm2, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrw $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpw %ax, %cx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrw $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <17 x i16>, ptr %p
  %res = tail call i16 @llvm.vector.reduce.umin.v17i16(<17 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_16xi16(<16 x i16> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminw_16xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminw %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_16xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v16i16(<16 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_13xi16(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminw_13xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa (%rdi), %ymm0
; AVX512REDUCTION-NEXT:    vpcmpeqd %ymm1, %ymm1, %ymm1
; AVX512REDUCTION-NEXT:    vpblendw {{.*#+}} ymm1 = ymm0[0,1,2,3,4],ymm1[5,6,7],ymm0[8,9,10,11,12],ymm1[13,14,15]
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; AVX512REDUCTION-NEXT:    vphrminw %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_13xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpcmpeqd %ymm0, %ymm0, %ymm0
; AVX512F-NEXT:    vpblendw {{.*#+}} ymm0 = mem[0,1,2,3,4],ymm0[5,6,7],mem[8,9,10,11,12],ymm0[13,14,15]
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm0
; AVX512F-NEXT:    vpminuw (%rdi), %xmm0, %xmm0
; AVX512F-NEXT:    vpextrw $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpw %ax, %cx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrw $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <13 x i16>, ptr %p
  %res = tail call i16 @llvm.vector.reduce.umin.v13i16(<13 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_8xi16(<8 x i16> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminw_8xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminw %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_8xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v8i16(<8 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_7xi16(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminw_7xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm0, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpblendw {{.*#+}} xmm0 = mem[0,1,2,3,4,5,6],xmm0[7]
; AVX512REDUCTION-NEXT:    vphrminw %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_7xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa (%rdi), %xmm0
; AVX512F-NEXT:    vpextrw $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpw %ax, %cx
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrw $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrw $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpw %cx, %ax
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    retq
  %vec= load <7 x i16>, ptr %p
  %res = tail call i16 @llvm.vector.reduce.umin.v7i16(<7 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_4xi16(<4 x i16> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminw_4xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} xmm0 = xmm0[0,1],xmm1[2,3]
; AVX512REDUCTION-NEXT:    vphrminw %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_4xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v4i16(<4 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_3xi16(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminw_3xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovq {{.*#+}} xmm0 = mem[0],zero
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3,4,5,6,7]
; AVX512REDUCTION-NEXT:    vphrminw %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_3xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    movq (%rdi), %rcx
; AVX512F-NEXT:    movl %ecx, %edx
; AVX512F-NEXT:    shrl $16, %edx
; AVX512F-NEXT:    cmpw %dx, %cx
; AVX512F-NEXT:    cmovbl %ecx, %edx
; AVX512F-NEXT:    shrq $32, %rcx
; AVX512F-NEXT:    movzwl %cx, %eax
; AVX512F-NEXT:    cmpw %cx, %dx
; AVX512F-NEXT:    cmovbl %edx, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    retq
  %vec= load <3 x i16>, ptr %p
  %res = tail call i16 @llvm.vector.reduce.umin.v3i16(<3 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_2xi16(<2 x i16> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminw_2xi16:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vpcmpeqd %xmm1, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} xmm0 = xmm0[0],xmm1[1,2,3]
; AVX512REDUCTION-NEXT:    vphrminw %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminw_2xi16:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512F-NEXT:    vpminuw %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v2i16(<2 x i16> %vec)
  ret i16 %res
}

define i16 @reduce_uminw_1xi16(<1 x i16> %vec) {
; ALL-LABEL: reduce_uminw_1xi16:
; ALL:       # %bb.0:
; ALL-NEXT:    movl %edi, %eax
; ALL-NEXT:    # kill: def $ax killed $ax killed $eax
; ALL-NEXT:    retq
  %res = tail call i16 @llvm.vector.reduce.umin.v1i16(<1 x i16> %vec)
  ret i16 %res
}

declare i16 @llvm.vector.reduce.umin.v33i16(<33 x i16>)
declare i16 @llvm.vector.reduce.umin.v32i16(<32 x i16>)
declare i16 @llvm.vector.reduce.umin.v17i16(<17 x i16>)
declare i16 @llvm.vector.reduce.umin.v16i16(<16 x i16>)
declare i16 @llvm.vector.reduce.umin.v13i16(<13 x i16>)
declare i16 @llvm.vector.reduce.umin.v8i16(<8 x i16>)
declare i16 @llvm.vector.reduce.umin.v7i16(<7 x i16>)
declare i16 @llvm.vector.reduce.umin.v4i16(<4 x i16>)
declare i16 @llvm.vector.reduce.umin.v3i16(<3 x i16>)
declare i16 @llvm.vector.reduce.umin.v2i16(<2 x i16>)
declare i16 @llvm.vector.reduce.umin.v1i16(<1 x i16>)

define i8 @reduce_uminb_65xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_65xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255>
; AVX512REDUCTION-NEXT:    vpinsrb $0, 64(%rdi), %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],mem[4,5,6,7]
; AVX512REDUCTION-NEXT:    vpminub (%rdi), %ymm0, %ymm0
; AVX512REDUCTION-NEXT:    vinserti64x4 $1, 32(%rdi), %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vphrminb %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_65xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa {{.*#+}} xmm0 = <u,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255>
; AVX512F-NEXT:    vpinsrb $0, 64(%rdi), %xmm0, %xmm0
; AVX512F-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],mem[4,5,6,7]
; AVX512F-NEXT:    vpminub (%rdi), %ymm0, %ymm0
; AVX512F-NEXT:    vpminub 32(%rdi), %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrb $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrb $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $9, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $10, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $11, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $12, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $13, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $14, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $15, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <65 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v65i8(<65 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_64xi8(<64 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_64xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminb %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_64xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminub %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v64i8(<64 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_33xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_33xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512REDUCTION-NEXT:    vmovdqa 48(%rdi), %xmm1
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $0, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $1, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $2, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $3, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vmovdqa 32(%rdi), %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $1, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $2, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $3, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm2, %xmm2
; AVX512REDUCTION-NEXT:    vinserti32x4 $2, %xmm2, %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vinserti32x4 $3, %xmm1, %zmm0, %zmm0
; AVX512REDUCTION-NEXT:    vphrminb %zmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_33xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa64 (%rdi), %zmm0
; AVX512F-NEXT:    vmovdqa 48(%rdi), %xmm1
; AVX512F-NEXT:    movl $255, %eax
; AVX512F-NEXT:    vpinsrb $0, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $1, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $2, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $3, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $4, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $5, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $6, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $7, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $8, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $9, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $10, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $11, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $12, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $13, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $14, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vpinsrb $15, %eax, %xmm1, %xmm1
; AVX512F-NEXT:    vmovdqa 32(%rdi), %xmm2
; AVX512F-NEXT:    vpinsrb $1, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $2, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $3, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $4, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $5, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $6, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $7, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $8, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $9, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $10, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $11, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $12, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $13, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $14, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vpinsrb $15, %eax, %xmm2, %xmm2
; AVX512F-NEXT:    vinserti32x4 $2, %xmm2, %zmm0, %zmm0
; AVX512F-NEXT:    vinserti32x4 $3, %xmm1, %zmm0, %zmm0
; AVX512F-NEXT:    vextracti64x4 $1, %zmm0, %ymm1
; AVX512F-NEXT:    vpminub %ymm1, %ymm0, %ymm0
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpextrb $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrb $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $9, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $10, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $11, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $12, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $13, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $14, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $15, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %vec= load <33 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v33i8(<33 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_32xi8(<32 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_32xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminb %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_32xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vextracti128 $1, %ymm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    vzeroupper
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v32i8(<32 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_17xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_17xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa (%rdi), %ymm0
; AVX512REDUCTION-NEXT:    vmovdqa 16(%rdi), %xmm1
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $1, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $2, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $3, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm1, %xmm1
; AVX512REDUCTION-NEXT:    vinserti128 $1, %xmm1, %ymm0, %ymm0
; AVX512REDUCTION-NEXT:    vphrminb %ymm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    vzeroupper
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_17xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa 16(%rdi), %xmm0
; AVX512F-NEXT:    movl $255, %eax
; AVX512F-NEXT:    vpinsrb $1, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $2, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $3, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $4, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $5, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $6, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $7, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512F-NEXT:    vpminub (%rdi), %xmm0, %xmm0
; AVX512F-NEXT:    vpextrb $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrb $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $9, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $10, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $11, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $12, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $13, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $14, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $15, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %vec= load <17 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v17i8(<17 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_16xi8(<16 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_16xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_16xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vphminposuw %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v16i8(<16 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_13xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_13xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovdqa (%rdi), %xmm0
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_13xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vmovdqa (%rdi), %xmm0
; AVX512F-NEXT:    vpextrb $1, %xmm0, %eax
; AVX512F-NEXT:    vmovd %xmm0, %ecx
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    vpextrb $2, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $3, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $4, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $5, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $6, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $7, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $8, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $9, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $10, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $11, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    vpextrb $12, %xmm0, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %vec= load <13 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v13i8(<13 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_8xi8(<8 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_8xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_8xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpshufd {{.*#+}} xmm1 = xmm0[1,1,1,1]
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v8i8(<8 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_7xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_7xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovq {{.*#+}} xmm0 = mem[0],zero
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_7xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    movq (%rdi), %rcx
; AVX512F-NEXT:    movl %ecx, %eax
; AVX512F-NEXT:    shrl $8, %eax
; AVX512F-NEXT:    movzbl %al, %eax
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    movl %ecx, %edx
; AVX512F-NEXT:    shrl $16, %edx
; AVX512F-NEXT:    movzbl %dl, %edx
; AVX512F-NEXT:    cmpb %dl, %al
; AVX512F-NEXT:    cmovael %edx, %eax
; AVX512F-NEXT:    movl %ecx, %edx
; AVX512F-NEXT:    shrl $24, %edx
; AVX512F-NEXT:    cmpb %dl, %al
; AVX512F-NEXT:    cmovbl %eax, %edx
; AVX512F-NEXT:    movq %rcx, %rax
; AVX512F-NEXT:    shrq $32, %rax
; AVX512F-NEXT:    movzbl %al, %esi
; AVX512F-NEXT:    cmpb %al, %dl
; AVX512F-NEXT:    cmovbl %edx, %esi
; AVX512F-NEXT:    movq %rcx, %rax
; AVX512F-NEXT:    shrq $40, %rax
; AVX512F-NEXT:    movzbl %al, %edx
; AVX512F-NEXT:    cmpb %al, %sil
; AVX512F-NEXT:    cmovbl %esi, %edx
; AVX512F-NEXT:    shrq $48, %rcx
; AVX512F-NEXT:    movzbl %cl, %eax
; AVX512F-NEXT:    cmpb %cl, %dl
; AVX512F-NEXT:    cmovbl %edx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %vec= load <7 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v7i8(<7 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_4xi8(<4 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_4xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_4xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpsrld $16, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v4i8(<4 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_3xi8(ptr %p) {
; AVX512REDUCTION-LABEL: reduce_uminb_3xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    vmovd {{.*#+}} xmm0 = mem[0],zero,zero,zero
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $3, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_3xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    movl (%rdi), %ecx
; AVX512F-NEXT:    movl %ecx, %eax
; AVX512F-NEXT:    shrl $8, %eax
; AVX512F-NEXT:    movzbl %al, %eax
; AVX512F-NEXT:    cmpb %al, %cl
; AVX512F-NEXT:    cmovbl %ecx, %eax
; AVX512F-NEXT:    shrl $16, %ecx
; AVX512F-NEXT:    movzbl %cl, %ecx
; AVX512F-NEXT:    cmpb %cl, %al
; AVX512F-NEXT:    cmovael %ecx, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %vec= load <3 x i8>, ptr %p
  %res = tail call i8 @llvm.vector.reduce.umin.v3i8(<3 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_2xi8(<2 x i8> %vec) {
; AVX512REDUCTION-LABEL: reduce_uminb_2xi8:
; AVX512REDUCTION:       # %bb.0:
; AVX512REDUCTION-NEXT:    movl $255, %eax
; AVX512REDUCTION-NEXT:    vpinsrb $2, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $3, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $4, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $5, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $6, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $7, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $8, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $9, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $10, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $11, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $12, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $13, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $14, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vpinsrb $15, %eax, %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vphrminb %xmm0, %xmm0
; AVX512REDUCTION-NEXT:    vmovd %xmm0, %eax
; AVX512REDUCTION-NEXT:    # kill: def $al killed $al killed $eax
; AVX512REDUCTION-NEXT:    retq
;
; AVX512F-LABEL: reduce_uminb_2xi8:
; AVX512F:       # %bb.0:
; AVX512F-NEXT:    vpsrlw $8, %xmm0, %xmm1
; AVX512F-NEXT:    vpminub %xmm1, %xmm0, %xmm0
; AVX512F-NEXT:    vmovd %xmm0, %eax
; AVX512F-NEXT:    # kill: def $al killed $al killed $eax
; AVX512F-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v2i8(<2 x i8> %vec)
  ret i8 %res
}

define i8 @reduce_uminb_1xi8(<1 x i8> %vec) {
; ALL-LABEL: reduce_uminb_1xi8:
; ALL:       # %bb.0:
; ALL-NEXT:    movl %edi, %eax
; ALL-NEXT:    # kill: def $al killed $al killed $eax
; ALL-NEXT:    retq
  %res = tail call i8 @llvm.vector.reduce.umin.v1i8(<1 x i8> %vec)
  ret i8 %res
}

declare i8 @llvm.vector.reduce.umin.v65i8(<65 x i8>)
declare i8 @llvm.vector.reduce.umin.v64i8(<64 x i8>)
declare i8 @llvm.vector.reduce.umin.v33i8(<33 x i8>)
declare i8 @llvm.vector.reduce.umin.v32i8(<32 x i8>)
declare i8 @llvm.vector.reduce.umin.v17i8(<17 x i8>)
declare i8 @llvm.vector.reduce.umin.v16i8(<16 x i8>)
declare i8 @llvm.vector.reduce.umin.v13i8(<13 x i8>)
declare i8 @llvm.vector.reduce.umin.v8i8(<8 x i8>)
declare i8 @llvm.vector.reduce.umin.v7i8(<7 x i8>)
declare i8 @llvm.vector.reduce.umin.v4i8(<4 x i8>)
declare i8 @llvm.vector.reduce.umin.v3i8(<3 x i8>)
declare i8 @llvm.vector.reduce.umin.v2i8(<2 x i8>)
declare i8 @llvm.vector.reduce.umin.v1i8(<1 x i8>)
