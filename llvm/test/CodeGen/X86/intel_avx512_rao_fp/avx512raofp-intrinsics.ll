; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx512_rao_fp
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=x86_64-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512raofp,+avx512fp16 | FileCheck %s --check-prefixes=X64
; RUN: llc < %s -O0 -verify-machineinstrs -mtriple=i686-unknown-unknown --show-mc-encoding -mattr=+avx512f,+avx512raofp,+avx512fp16 | FileCheck %s --check-prefixes=X86

define void @test_int_x86_vaaddpbf16512(i8* %A, <32 x i16> %B) {
; X64-LABEL: test_int_x86_vaaddpbf16512:
; X64:       # %bb.0:
; X64-NEXT:    vaaddpbf16 %zmm0, (%rdi) # encoding: [0x62,0xf2,0x7d,0x48,0x94,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vaaddpbf16512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vaaddpbf16 %zmm0, (%eax) # encoding: [0x62,0xf2,0x7d,0x48,0x94,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vaaddpbf16512(i8* %A, <32 x i16> %B)
  ret  void
}
declare void @llvm.x86.vaaddpbf16512(i8* %A, <32 x i16> %B)

define void @test_int_x86_mask_vaaddpbf16512(i8* %A, <32 x i16> %B, i32 %C) {
; X64-LABEL: test_int_x86_mask_vaaddpbf16512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; X64-NEXT:    vaaddpbf16 %zmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x49,0x94,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddpbf16512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx # encoding: [0x8b,0x4c,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddpbf16 %zmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x49,0x94,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddpbf16512(i8* %A, <32 x i16> %B, i32 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddpbf16512(i8* %A, <32 x i16> %B, i32 %C)

define void @test_int_x86_vaaddpd512(i8* %A, <8 x double> %B) {
; X64-LABEL: test_int_x86_vaaddpd512:
; X64:       # %bb.0:
; X64-NEXT:    vaaddpd %zmm0, (%rdi) # encoding: [0x62,0xf2,0xfd,0x48,0x84,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vaaddpd512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vaaddpd %zmm0, (%eax) # encoding: [0x62,0xf2,0xfd,0x48,0x84,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vaaddpd512(i8* %A, <8 x double> %B)
  ret  void
}
declare void @llvm.x86.vaaddpd512(i8* %A, <8 x double> %B)

define void @test_int_x86_mask_vaaddpd512(i8* %A, <8 x double> %B, i8 %C) {
; X64-LABEL: test_int_x86_mask_vaaddpd512:
; X64:       # %bb.0:
; X64-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddpd %zmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x49,0x84,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddpd512:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddpd %zmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x49,0x84,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddpd512(i8* %A, <8 x double> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddpd512(i8* %A, <8 x double> %B, i8 %C)

define void @test_int_x86_vaaddph512(i8* %A, <32 x half> %B) {
; X64-LABEL: test_int_x86_vaaddph512:
; X64:       # %bb.0:
; X64-NEXT:    vaaddph %zmm0, (%rdi) # encoding: [0x62,0xf2,0x7c,0x48,0x94,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vaaddph512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vaaddph %zmm0, (%eax) # encoding: [0x62,0xf2,0x7c,0x48,0x94,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vaaddph512(i8* %A, <32 x half> %B)
  ret  void
}
declare void @llvm.x86.vaaddph512(i8* %A, <32 x half> %B)

define void @test_int_x86_mask_vaaddph512(i8* %A, <32 x half> %B, i32 %C) {
; X64-LABEL: test_int_x86_mask_vaaddph512:
; X64:       # %bb.0:
; X64-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; X64-NEXT:    vaaddph %zmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x94,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddph512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx # encoding: [0x8b,0x4c,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddph %zmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x94,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddph512(i8* %A, <32 x half> %B, i32 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddph512(i8* %A, <32 x half> %B, i32 %C)

define void @test_int_x86_vaaddps512(i8* %A, <16 x float> %B) {
; X64-LABEL: test_int_x86_vaaddps512:
; X64:       # %bb.0:
; X64-NEXT:    vaaddps %zmm0, (%rdi) # encoding: [0x62,0xf2,0x7c,0x48,0x84,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_vaaddps512:
; X86:       # %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vaaddps %zmm0, (%eax) # encoding: [0x62,0xf2,0x7c,0x48,0x84,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.vaaddps512(i8* %A, <16 x float> %B)
  ret  void
}
declare void @llvm.x86.vaaddps512(i8* %A, <16 x float> %B)

define void @test_int_x86_mask_vaaddps512(i8* %A, <16 x float> %B, i16 %C) {
; X64-LABEL: test_int_x86_mask_vaaddps512:
; X64:       # %bb.0:
; X64-NEXT:    movw %si, %cx # encoding: [0x66,0x89,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movw %cx, %ax # encoding: [0x66,0x89,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddps %zmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x84,0x07]
; X64-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddps512:
; X86:       # %bb.0:
; X86-NEXT:    movw {{[0-9]+}}(%esp), %dx # encoding: [0x66,0x8b,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movw %dx, %cx # encoding: [0x66,0x89,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddps %zmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x49,0x84,0x00]
; X86-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddps512(i8* %A, <16 x float> %B, i16 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddps512(i8* %A, <16 x float> %B, i16 %C)

define void @test_int_x86_mask_vaaddsbf16128(i8* %A, <8 x i16> %B, i8 %C) {
; X64-LABEL: test_int_x86_mask_vaaddsbf16128:
; X64:       # %bb.0:
; X64-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddpbf16 %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x94,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddsbf16128:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddpbf16 %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x94,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddsbf16128(i8* %A, <8 x i16> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddsbf16128(i8* %A, <8 x i16> %B, i8 %C)

define void @test_int_x86_mask_vaaddsd128(i8* %A, <2 x double> %B, i8 %C) {
; X64-LABEL: test_int_x86_mask_vaaddsd128:
; X64:       # %bb.0:
; X64-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddpd %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x84,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddsd128:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddpd %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x84,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddsd128(i8* %A, <2 x double> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddsd128(i8* %A, <2 x double> %B, i8 %C)

define void @test_int_x86_mask_vaaddsh128(i8* %A, <8 x half> %B, i8 %C) {
; X64-LABEL: test_int_x86_mask_vaaddsh128:
; X64:       # %bb.0:
; X64-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddph %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0x94,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddsh128:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddph %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0x94,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddsh128(i8* %A, <8 x half> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddsh128(i8* %A, <8 x half> %B, i8 %C)

define void @test_int_x86_mask_vaaddss128(i8* %A, <4 x float> %B, i8 %C) {
; X64-LABEL: test_int_x86_mask_vaaddss128:
; X64:       # %bb.0:
; X64-NEXT:    movb %sil, %cl # encoding: [0x40,0x88,0xf1]
; X64-NEXT:    # implicit-def: $eax
; X64-NEXT:    movb %cl, %al # encoding: [0x88,0xc8]
; X64-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; X64-NEXT:    vaaddps %xmm0, (%rdi) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0x84,0x07]
; X64-NEXT:    retq # encoding: [0xc3]
;
; X86-LABEL: test_int_x86_mask_vaaddss128:
; X86:       # %bb.0:
; X86-NEXT:    movb {{[0-9]+}}(%esp), %dl # encoding: [0x8a,0x54,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax # encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    # implicit-def: $ecx
; X86-NEXT:    movb %dl, %cl # encoding: [0x88,0xd1]
; X86-NEXT:    kmovd %ecx, %k1 # encoding: [0xc5,0xfb,0x92,0xc9]
; X86-NEXT:    vaaddps %xmm0, (%eax) {%k1} # encoding: [0x62,0xf2,0x7c,0x09,0x84,0x00]
; X86-NEXT:    retl # encoding: [0xc3]
  call void @llvm.x86.mask.vaaddss128(i8* %A, <4 x float> %B, i8 %C)
  ret  void
}
declare void @llvm.x86.mask.vaaddss128(i8* %A, <4 x float> %B, i8 %C)

