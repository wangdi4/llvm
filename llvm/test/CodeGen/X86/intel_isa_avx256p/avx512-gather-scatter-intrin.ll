; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx256p
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx256p -show-mc-encoding | FileCheck %s

define <2 x double> @test_int_x86_avx512_mask_gather3div2_df(<2 x double> %x0, ptr %x1, <2 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div2_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherqpd (%rdi,%xmm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x93,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorpd %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0x57,0xd2]
; CHECK-NEXT:    vgatherqpd (%rdi,%xmm1,2), %xmm2 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x93,0x14,0x4f]
; CHECK-NEXT:    vaddpd %xmm2, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res = call <2 x double> @llvm.x86.avx512.mask.gather3div2.df(<2 x double> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> %extract, i32 4)
  %res1 = call <2 x double> @llvm.x86.avx512.mask.gather3div2.df(<2 x double> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> <i1 true, i1 true>, i32 2)
  %res2 = fadd <2 x double> %res, %res1
  ret <2 x double> %res2
}

define <2 x i64> @test_int_x86_avx512_mask_gather3div2_di(<2 x i64> %x0, ptr %x1, <2 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div2_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherqq (%rdi,%xmm1,8), %xmm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x91,0x04,0xcf]
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xd4,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract1 = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res = call <2 x i64> @llvm.x86.avx512.mask.gather3div2.di(<2 x i64> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> %extract1, i32 8)
  %2 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %2, <8 x i1> %2, <2 x i32> <i32 0, i32 1>
  %res1 = call <2 x i64> @llvm.x86.avx512.mask.gather3div2.di(<2 x i64> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> %extract, i32 8)
  %res2 = add <2 x i64> %res, %res1
  ret <2 x i64> %res2
}

define <4 x double> @test_int_x86_avx512_mask_gather3div4_df(<4 x double> %x0, ptr %x1, <4 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div4_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherqpd (%rdi,%ymm1,4), %ymm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x93,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorpd %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0x57,0xd2]
; CHECK-NEXT:    vgatherqpd (%rdi,%ymm1,2), %ymm2 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x93,0x14,0x4f]
; CHECK-NEXT:    vaddpd %ymm2, %ymm0, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xfd,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x double> @llvm.x86.avx512.mask.gather3div4.df(<4 x double> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> %extract, i32 4)
  %res1 = call <4 x double> @llvm.x86.avx512.mask.gather3div4.df(<4 x double> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 2)
  %res2 = fadd <4 x double> %res, %res1
  ret <4 x double> %res2
}

define <4 x i64> @test_int_x86_avx512_mask_gather3div4_di(<4 x i64> %x0, ptr %x1, <4 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div4_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherqq (%rdi,%ymm1,8), %ymm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x91,0x04,0xcf]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpxor %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xef,0xd2]
; CHECK-NEXT:    vpgatherqq (%rdi,%ymm1,8), %ymm2 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x91,0x14,0xcf]
; CHECK-NEXT:    vpaddq %ymm2, %ymm0, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xfd,0xd4,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x i64> @llvm.x86.avx512.mask.gather3div4.di(<4 x i64> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> %extract, i32 8)
  %res1 = call <4 x i64> @llvm.x86.avx512.mask.gather3div4.di(<4 x i64> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 8)
  %res2 = add <4 x i64> %res, %res1
  ret <4 x i64> %res2
}

define <4 x float> @test_int_x86_avx512_mask_gather3div4_sf(<4 x float> %x0, ptr %x1, <2 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div4_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherqps (%rdi,%xmm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x93,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorps %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe8,0x57,0xd2]
; CHECK-NEXT:    vgatherqps (%rdi,%xmm1,2), %xmm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x93,0x14,0x4f]
; CHECK-NEXT:    vaddps %xmm2, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf8,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res = call <4 x float> @llvm.x86.avx512.mask.gather3div4.sf(<4 x float> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> %extract, i32 4)
  %res1 = call <4 x float> @llvm.x86.avx512.mask.gather3div4.sf(<4 x float> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> <i1 true, i1 true>, i32 2)
  %res2 = fadd <4 x float> %res, %res1
  ret <4 x float> %res2
}

define <4 x i32> @test_int_x86_avx512_mask_gather3div4_si(<4 x i32> %x0, ptr %x1, <2 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div4_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpxor %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xef,0xd2]
; CHECK-NEXT:    vpgatherqd (%rdi,%xmm1,4), %xmm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x91,0x14,0x8f]
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherqd (%rdi,%xmm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x91,0x04,0x8f]
; CHECK-NEXT:    vpaddd %xmm0, %xmm2, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xfe,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %res = call <4 x i32> @llvm.x86.avx512.mask.gather3div4.si(<4 x i32> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> <i1 true, i1 true>, i32 4)
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res1 = call <4 x i32> @llvm.x86.avx512.mask.gather3div4.si(<4 x i32> %x0, ptr %x1, <2 x i64> %x2, <2 x i1> %extract, i32 4)
  %res2 = add <4 x i32> %res, %res1
  ret <4 x i32> %res2
}

define <4 x float> @test_int_x86_avx512_mask_gather3div8_sf(<4 x float> %x0, ptr %x1, <4 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div8_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherqps (%rdi,%ymm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x93,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorps %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe8,0x57,0xd2]
; CHECK-NEXT:    vgatherqps (%rdi,%ymm1,2), %xmm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x93,0x14,0x4f]
; CHECK-NEXT:    vaddps %xmm2, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf8,0x58,0xc2]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x float> @llvm.x86.avx512.mask.gather3div8.sf(<4 x float> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> %extract, i32 4)
  %res1 = call <4 x float> @llvm.x86.avx512.mask.gather3div8.sf(<4 x float> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 2)
  %res2 = fadd <4 x float> %res, %res1
  ret <4 x float> %res2
}

define <4 x i32> @test_int_x86_avx512_mask_gather3div8_si(<4 x i32> %x0, ptr %x1, <4 x i64> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3div8_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vmovdqa %xmm0, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x6f,0xd0]
; CHECK-NEXT:    kmovq %k1, %k2 # encoding: [0xc4,0xe1,0xf8,0x90,0xd1]
; CHECK-NEXT:    vpgatherqd (%rdi,%ymm1,4), %xmm2 {%k2} # encoding: [0x62,0xf2,0x7d,0x2a,0x91,0x14,0x8f]
; CHECK-NEXT:    vpgatherqd (%rdi,%ymm1,2), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x91,0x04,0x4f]
; CHECK-NEXT:    vpaddd %xmm0, %xmm2, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xfe,0xc0]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract1 = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x i32> @llvm.x86.avx512.mask.gather3div8.si(<4 x i32> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> %extract1, i32 4)
  %2 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %2, <8 x i1> %2, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res1 = call <4 x i32> @llvm.x86.avx512.mask.gather3div8.si(<4 x i32> %x0, ptr %x1, <4 x i64> %x2, <4 x i1> %extract, i32 2)
  %res2 = add <4 x i32> %res, %res1
  ret <4 x i32> %res2
}

define <2 x double> @test_int_x86_avx512_mask_gather3siv2_df(<2 x double> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv2_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherdpd (%rdi,%xmm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x92,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorpd %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0x57,0xd2]
; CHECK-NEXT:    vgatherdpd (%rdi,%xmm1,2), %xmm2 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x92,0x14,0x4f]
; CHECK-NEXT:    vaddpd %xmm2, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res = call <2 x double> @llvm.x86.avx512.mask.gather3siv2.df(<2 x double> %x0, ptr %x1, <4 x i32> %x2, <2 x i1> %extract, i32 4)
  %res1 = call <2 x double> @llvm.x86.avx512.mask.gather3siv2.df(<2 x double> %x0, ptr %x1, <4 x i32> %x2, <2 x i1> <i1 true, i1 true>, i32 2)
  %res2 = fadd <2 x double> %res, %res1
  ret <2 x double> %res2
}

define <2 x i64> @test_int_x86_avx512_mask_gather3siv2_di(<2 x i64> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv2_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherdq (%rdi,%xmm1,8), %xmm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0x90,0x04,0xcf]
; CHECK-NEXT:    vpaddq %xmm0, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xd4,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract1 = shufflevector <8 x i1> %1, <8 x i1> %1, <2 x i32> <i32 0, i32 1>
  %res = call <2 x i64> @llvm.x86.avx512.mask.gather3siv2.di(<2 x i64> %x0, ptr %x1, <4 x i32> %x2, <2 x i1> %extract1, i32 8)
  %2 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %2, <8 x i1> %2, <2 x i32> <i32 0, i32 1>
  %res1 = call <2 x i64> @llvm.x86.avx512.mask.gather3siv2.di(<2 x i64> %x0, ptr %x1, <4 x i32> %x2, <2 x i1> %extract, i32 8)
  %res2 = add <2 x i64> %res, %res1
  ret <2 x i64> %res2
}

define <4 x double> @test_int_x86_avx512_mask_gather3siv4_df(<4 x double> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv4_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherdpd (%rdi,%xmm1,4), %ymm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x92,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorpd %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0x57,0xd2]
; CHECK-NEXT:    vgatherdpd (%rdi,%xmm1,2), %ymm2 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x92,0x14,0x4f]
; CHECK-NEXT:    vaddpd %ymm2, %ymm0, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xfd,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x double> @llvm.x86.avx512.mask.gather3siv4.df(<4 x double> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> %extract, i32 4)
  %res1 = call <4 x double> @llvm.x86.avx512.mask.gather3siv4.df(<4 x double> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 2)
  %res2 = fadd <4 x double> %res, %res1
  ret <4 x double> %res2
}

define <4 x i64> @test_int_x86_avx512_mask_gather3siv4_di(<4 x i64> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv4_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherdq (%rdi,%xmm1,8), %ymm0 {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0x90,0x04,0xcf]
; CHECK-NEXT:    vpaddq %ymm0, %ymm0, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xfd,0xd4,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract1 = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x i64> @llvm.x86.avx512.mask.gather3siv4.di(<4 x i64> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> %extract1, i32 8)
  %2 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %2, <8 x i1> %2, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res1 = call <4 x i64> @llvm.x86.avx512.mask.gather3siv4.di(<4 x i64> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> %extract, i32 8)
  %res2 = add <4 x i64> %res, %res1
  ret <4 x i64> %res2
}

define <4 x float> @test_int_x86_avx512_mask_gather3siv4_sf(<4 x float> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv4_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherdps (%rdi,%xmm1,4), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x92,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorps %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe8,0x57,0xd2]
; CHECK-NEXT:    vgatherdps (%rdi,%xmm1,2), %xmm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x92,0x14,0x4f]
; CHECK-NEXT:    vaddps %xmm2, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf8,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res = call <4 x float> @llvm.x86.avx512.mask.gather3siv4.sf(<4 x float> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> %extract, i32 4)
  %res1 = call <4 x float> @llvm.x86.avx512.mask.gather3siv4.sf(<4 x float> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 2)
  %res2 = fadd <4 x float> %res, %res1
  ret <4 x float> %res2
}

define <4 x i32> @test_int_x86_avx512_mask_gather3siv4_si(<4 x i32> %x0, ptr %x1, <4 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv4_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpxor %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xef,0xd2]
; CHECK-NEXT:    vpgatherdd (%rdi,%xmm1,4), %xmm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x90,0x14,0x8f]
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpgatherdd (%rdi,%xmm1,2), %xmm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0x90,0x04,0x4f]
; CHECK-NEXT:    vpaddd %xmm0, %xmm2, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xe9,0xfe,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %res = call <4 x i32> @llvm.x86.avx512.mask.gather3siv4.si(<4 x i32> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, i32 4)
  %1 = bitcast i8 %x3 to <8 x i1>
  %extract = shufflevector <8 x i1> %1, <8 x i1> %1, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %res1 = call <4 x i32> @llvm.x86.avx512.mask.gather3siv4.si(<4 x i32> %x0, ptr %x1, <4 x i32> %x2, <4 x i1> %extract, i32 2)
  %res2 = add <4 x i32> %res, %res1
  ret <4 x i32> %res2
}

define <8 x float> @test_int_x86_avx512_mask_gather3siv8_sf(<8 x float> %x0, ptr %x1, <8 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv8_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vgatherdps (%rdi,%ymm1,4), %ymm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x92,0x04,0x8f]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vxorps %xmm2, %xmm2, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xe8,0x57,0xd2]
; CHECK-NEXT:    vgatherdps (%rdi,%ymm1,2), %ymm2 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x92,0x14,0x4f]
; CHECK-NEXT:    vaddps %ymm2, %ymm0, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xfc,0x58,0xc2]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %res = call <8 x float> @llvm.x86.avx512.mask.gather3siv8.sf(<8 x float> %x0, ptr %x1, <8 x i32> %x2, <8 x i1> %1, i32 4)
  %res1 = call <8 x float> @llvm.x86.avx512.mask.gather3siv8.sf(<8 x float> %x0, ptr %x1, <8 x i32> %x2, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, i32 2)
  %res2 = fadd <8 x float> %res, %res1
  ret <8 x float> %res2
}

define <8 x i32> @test_int_x86_avx512_mask_gather3siv8_si(<8 x i32> %x0, ptr %x1, <8 x i32> %x2, i8 %x3) {
; CHECK-LABEL: test_int_x86_avx512_mask_gather3siv8_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vmovdqa %ymm0, %ymm2 # EVEX TO VEX Compression encoding: [0xc5,0xfd,0x6f,0xd0]
; CHECK-NEXT:    kmovq %k1, %k2 # encoding: [0xc4,0xe1,0xf8,0x90,0xd1]
; CHECK-NEXT:    vpgatherdd (%rdi,%ymm1,4), %ymm2 {%k2} # encoding: [0x62,0xf2,0x7d,0x2a,0x90,0x14,0x8f]
; CHECK-NEXT:    vpgatherdd (%rdi,%ymm1,2), %ymm0 {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0x90,0x04,0x4f]
; CHECK-NEXT:    vpaddd %ymm0, %ymm2, %ymm0 # EVEX TO VEX Compression encoding: [0xc5,0xed,0xfe,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x3 to <8 x i1>
  %res = call <8 x i32> @llvm.x86.avx512.mask.gather3siv8.si(<8 x i32> %x0, ptr %x1, <8 x i32> %x2, <8 x i1> %1, i32 4)
  %2 = bitcast i8 %x3 to <8 x i1>
  %res1 = call <8 x i32> @llvm.x86.avx512.mask.gather3siv8.si(<8 x i32> %x0, ptr %x1, <8 x i32> %x2, <8 x i1> %2, i32 2)
  %res2 = add <8 x i32> %res, %res1
  ret <8 x i32> %res2
}

define dso_local void@test_int_x86_avx512_scatterdiv2_df(ptr %x0, i8 %x1, <2 x i64> %x2, <2 x double> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv2_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    kxnorw %k0, %k0, %k2 # encoding: [0xc5,0xfc,0x46,0xd0]
; CHECK-NEXT:    vscatterqpd %xmm1, (%rdi,%xmm0,2) {%k2} # encoding: [0x62,0xf2,0xfd,0x0a,0xa3,0x0c,0x47]
; CHECK-NEXT:    vscatterqpd %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xa3,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scatterdiv2.df(ptr %x0, <2 x i1> <i1 true, i1 true>, <2 x i64> %x2, <2 x double> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv2.df(ptr %x0, <2 x i1> %2, <2 x i64> %x2, <2 x double> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv2_di(ptr %x0, i8 %x1, <2 x i64> %x2, <2 x i64> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv2_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpscatterqq %xmm1, (%rdi,%xmm0,2) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xa1,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterqq %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xa1,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scatterdiv2.di(ptr %x0, <2 x i1> %2, <2 x i64> %x2, <2 x i64> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv2.di(ptr %x0, <2 x i1> <i1 true, i1 true>, <2 x i64> %x2, <2 x i64> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv4_df(ptr %x0, i8 %x1, <4 x i64> %x2, <4 x double> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv4_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterqpd %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa3,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterqpd %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa3,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scatterdiv4.df(ptr %x0, <4 x i1> %2, <4 x i64> %x2, <4 x double> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv4.df(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i64> %x2, <4 x double> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv4_di(ptr %x0, i8 %x1, <4 x i64> %x2, <4 x i64> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv4_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpscatterqq %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa1,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterqq %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa1,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scatterdiv4.di(ptr %x0, <4 x i1> %2, <4 x i64> %x2, <4 x i64> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv4.di(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i64> %x2, <4 x i64> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv4_sf(ptr %x0, i8 %x1, <2 x i64> %x2, <4 x float> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv4_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterqps %xmm1, (%rdi,%xmm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa3,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterqps %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa3,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scatterdiv4.sf(ptr %x0, <2 x i1> %2, <2 x i64> %x2, <4 x float> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv4.sf(ptr %x0, <2 x i1> <i1 true, i1 true>, <2 x i64> %x2, <4 x float> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv4_si(ptr %x0, i8 %x1, <2 x i64> %x2, <4 x i32> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv4_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    kxnorw %k0, %k0, %k2 # encoding: [0xc5,0xfc,0x46,0xd0]
; CHECK-NEXT:    vpscatterqd %xmm1, (%rdi,%xmm0,2) {%k2} # encoding: [0x62,0xf2,0x7d,0x0a,0xa1,0x0c,0x47]
; CHECK-NEXT:    vpscatterqd %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa1,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scatterdiv4.si(ptr %x0, <2 x i1> <i1 true, i1 true>, <2 x i64> %x2, <4 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv4.si(ptr %x0, <2 x i1> %2, <2 x i64> %x2, <4 x i32> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv8_sf(ptr %x0, i8 %x1, <4 x i64> %x2, <4 x float> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv8_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterqps %xmm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa3,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterqps %xmm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa3,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scatterdiv8.sf(ptr %x0, <4 x i1> %2, <4 x i64> %x2, <4 x float> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv8.sf(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i64> %x2, <4 x float> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scatterdiv8_si(ptr %x0, i8 %x1, <4 x i64> %x2, <4 x i32> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scatterdiv8_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpscatterqd %xmm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa1,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterqd %xmm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa1,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scatterdiv8.si(ptr %x0, <4 x i1> %2, <4 x i64> %x2, <4 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scatterdiv8.si(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i64> %x2, <4 x i32> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv2_df(ptr %x0, i8 %x1, <4 x i32> %x2, <2 x double> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv2_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    kxnorw %k0, %k0, %k2 # encoding: [0xc5,0xfc,0x46,0xd0]
; CHECK-NEXT:    vscatterdpd %xmm1, (%rdi,%xmm0,2) {%k2} # encoding: [0x62,0xf2,0xfd,0x0a,0xa2,0x0c,0x47]
; CHECK-NEXT:    vscatterdpd %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xa2,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scattersiv2.df(ptr %x0, <2 x i1> <i1 true, i1 true>, <4 x i32> %x2, <2 x double> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv2.df(ptr %x0, <2 x i1> %2, <4 x i32> %x2, <2 x double> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv2_di(ptr %x0, i8 %x1, <4 x i32> %x2, <2 x i64> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv2_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    kxnorw %k0, %k0, %k2 # encoding: [0xc5,0xfc,0x46,0xd0]
; CHECK-NEXT:    vpscatterdq %xmm1, (%rdi,%xmm0,2) {%k2} # encoding: [0x62,0xf2,0xfd,0x0a,0xa0,0x0c,0x47]
; CHECK-NEXT:    vpscatterdq %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x09,0xa0,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <2 x i32> <i32 0, i32 1>
  call void @llvm.x86.avx512.mask.scattersiv2.di(ptr %x0, <2 x i1> <i1 true, i1 true>, <4 x i32> %x2, <2 x i64> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv2.di(ptr %x0, <2 x i1> %2, <4 x i32> %x2, <2 x i64> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv4_df(ptr %x0, i8 %x1, <4 x i32> %x2, <4 x double> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv4_df:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterdpd %ymm1, (%rdi,%xmm0,2) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa2,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterdpd %ymm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa2,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scattersiv4.df(ptr %x0, <4 x i1> %2, <4 x i32> %x2, <4 x double> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv4.df(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i32> %x2, <4 x double> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv4_di(ptr %x0, i8 %x1, <4 x i32> %x2, <4 x i64> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv4_di:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    kxnorw %k0, %k0, %k2 # encoding: [0xc5,0xfc,0x46,0xd0]
; CHECK-NEXT:    vpscatterdq %ymm1, (%rdi,%xmm0,2) {%k2} # encoding: [0x62,0xf2,0xfd,0x2a,0xa0,0x0c,0x47]
; CHECK-NEXT:    vpscatterdq %ymm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0xfd,0x29,0xa0,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scattersiv4.di(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i32> %x2, <4 x i64> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv4.di(ptr %x0, <4 x i1> %2, <4 x i32> %x2, <4 x i64> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv4_sf(ptr %x0, i8 %x1, <4 x i32> %x2, <4 x float> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv4_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterdps %xmm1, (%rdi,%xmm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa2,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterdps %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa2,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scattersiv4.sf(ptr %x0, <4 x i1> %2, <4 x i32> %x2, <4 x float> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv4.sf(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i32> %x2, <4 x float> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv4_si(ptr %x0, i8 %x1, <4 x i32> %x2, <4 x i32> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv4_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpscatterdd %xmm1, (%rdi,%xmm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa0,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterdd %xmm1, (%rdi,%xmm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x09,0xa0,0x0c,0x87]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  %2 = shufflevector <8 x i1> %1, <8 x i1> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  call void @llvm.x86.avx512.mask.scattersiv4.si(ptr %x0, <4 x i1> %2, <4 x i32> %x2, <4 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv4.si(ptr %x0, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i32> %x2, <4 x i32> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv8_sf(ptr %x0, i8 %x1, <8 x i32> %x2, <8 x float> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv8_sf:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vscatterdps %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa2,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vscatterdps %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa2,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  call void @llvm.x86.avx512.mask.scattersiv8.sf(ptr %x0, <8 x i1> %1, <8 x i32> %x2, <8 x float> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv8.sf(ptr %x0, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x i32> %x2, <8 x float> %x3, i32 4)
  ret void
}

define dso_local void@test_int_x86_avx512_scattersiv8_si(ptr %x0, i8 %x1, <8 x i32> %x2, <8 x i32> %x3) {
; CHECK-LABEL: test_int_x86_avx512_scattersiv8_si:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1 # encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x47]
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %1 = bitcast i8 %x1 to <8 x i1>
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> %1, <8 x i32> %x2, <8 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x i32> %x2, <8 x i32> %x3, i32 4)
  ret void
}

define dso_local void @scatter_mask_test(ptr %x0, <8 x i32> %x2, <8 x i32> %x3) {
; CHECK-LABEL: scatter_mask_test:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kxnorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x46,0xc8]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x47]
; CHECK-NEXT:    kxorw %k0, %k0, %k1 # encoding: [0xc5,0xfc,0x47,0xc8]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x87]
; CHECK-NEXT:    movb $1, %al # encoding: [0xb0,0x01]
; CHECK-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,2) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x47]
; CHECK-NEXT:    movb $96, %al # encoding: [0xb0,0x60]
; CHECK-NEXT:    kmovd %eax, %k1 # encoding: [0xc5,0xfb,0x92,0xc8]
; CHECK-NEXT:    vpscatterdd %ymm1, (%rdi,%ymm0,4) {%k1} # encoding: [0x62,0xf2,0x7d,0x29,0xa0,0x0c,0x87]
; CHECK-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq # encoding: [0xc3]
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <8 x i32> %x2, <8 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> zeroinitializer, <8 x i32> %x2, <8 x i32> %x3, i32 4)
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> bitcast (<1 x i8> <i8 1> to <8 x i1>), <8 x i32> %x2, <8 x i32> %x3, i32 2)
  call void @llvm.x86.avx512.mask.scattersiv8.si(ptr %x0, <8 x i1> bitcast (<1 x i8> <i8 96> to <8 x i1>), <8 x i32> %x2, <8 x i32> %x3, i32 4)
  ret void
}
declare <2 x double> @llvm.x86.avx512.mask.gather3div2.df(<2 x double>, ptr, <2 x i64>, <2 x i1>, i32)
declare <2 x i64> @llvm.x86.avx512.mask.gather3div2.di(<2 x i64>, ptr, <2 x i64>, <2 x i1>, i32)
declare <4 x double> @llvm.x86.avx512.mask.gather3div4.df(<4 x double>, ptr, <4 x i64>, <4 x i1>, i32)
declare <4 x i64> @llvm.x86.avx512.mask.gather3div4.di(<4 x i64>, ptr, <4 x i64>, <4 x i1>, i32)
declare <4 x float> @llvm.x86.avx512.mask.gather3div4.sf(<4 x float>, ptr, <2 x i64>, <2 x i1>, i32)
declare <4 x i32> @llvm.x86.avx512.mask.gather3div4.si(<4 x i32>, ptr, <2 x i64>, <2 x i1>, i32)
declare <4 x float> @llvm.x86.avx512.mask.gather3div8.sf(<4 x float>, ptr, <4 x i64>, <4 x i1>, i32)
declare <4 x i32> @llvm.x86.avx512.mask.gather3div8.si(<4 x i32>, ptr, <4 x i64>, <4 x i1>, i32)
declare <2 x double> @llvm.x86.avx512.mask.gather3siv2.df(<2 x double>, ptr, <4 x i32>, <2 x i1>, i32)
declare <2 x i64> @llvm.x86.avx512.mask.gather3siv2.di(<2 x i64>, ptr, <4 x i32>, <2 x i1>, i32)
declare <4 x double> @llvm.x86.avx512.mask.gather3siv4.df(<4 x double>, ptr, <4 x i32>, <4 x i1>, i32)
declare <4 x i64> @llvm.x86.avx512.mask.gather3siv4.di(<4 x i64>, ptr, <4 x i32>, <4 x i1>, i32)
declare <4 x float> @llvm.x86.avx512.mask.gather3siv4.sf(<4 x float>, ptr, <4 x i32>, <4 x i1>, i32)
declare <4 x i32> @llvm.x86.avx512.mask.gather3siv4.si(<4 x i32>, ptr, <4 x i32>, <4 x i1>, i32)
declare <8 x float> @llvm.x86.avx512.mask.gather3siv8.sf(<8 x float>, ptr, <8 x i32>, <8 x i1>, i32)
declare <8 x i32> @llvm.x86.avx512.mask.gather3siv8.si(<8 x i32>, ptr, <8 x i32>, <8 x i1>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv2.df(ptr, <2 x i1>, <2 x i64>, <2 x double>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv2.di(ptr, <2 x i1>, <2 x i64>, <2 x i64>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv4.df(ptr, <4 x i1>, <4 x i64>, <4 x double>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv4.di(ptr, <4 x i1>, <4 x i64>, <4 x i64>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv4.sf(ptr, <2 x i1>, <2 x i64>, <4 x float>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv4.si(ptr, <2 x i1>, <2 x i64>, <4 x i32>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv8.sf(ptr, <4 x i1>, <4 x i64>, <4 x float>, i32)
declare void @llvm.x86.avx512.mask.scatterdiv8.si(ptr, <4 x i1>, <4 x i64>, <4 x i32>, i32)
declare void @llvm.x86.avx512.mask.scattersiv2.df(ptr, <2 x i1>, <4 x i32>, <2 x double>, i32)
declare void @llvm.x86.avx512.mask.scattersiv2.di(ptr, <2 x i1>, <4 x i32>, <2 x i64>, i32)
declare void @llvm.x86.avx512.mask.scattersiv4.df(ptr, <4 x i1>, <4 x i32>, <4 x double>, i32)
declare void @llvm.x86.avx512.mask.scattersiv4.di(ptr, <4 x i1>, <4 x i32>, <4 x i64>, i32)
declare void @llvm.x86.avx512.mask.scattersiv4.sf(ptr, <4 x i1>, <4 x i32>, <4 x float>, i32)
declare void @llvm.x86.avx512.mask.scattersiv4.si(ptr, <4 x i1>, <4 x i32>, <4 x i32>, i32)
declare void @llvm.x86.avx512.mask.scattersiv8.sf(ptr, <8 x i1>, <8 x i32>, <8 x float>, i32)
declare void @llvm.x86.avx512.mask.scattersiv8.si(ptr, <8 x i1>, <8 x i32>, <8 x i32>, i32)
