; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx256p
; RUN: llc < %s -stack-symbol-ordering=0 -mtriple=x86_64-apple-darwin -mattr=+avx256p --show-mc-encoding | FileCheck %s --check-prefixes=CHECK
; RUN: llc < %s -stack-symbol-ordering=0 -mtriple=i686-apple-darwin -mattr=+avx256p --show-mc-encoding | FileCheck %s --check-prefix=X86

define void @mask16_mem(ptr %ptr) {
; CHECK-LABEL: mask16_mem:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovw (%rdi), %k0 ## encoding: [0xc5,0xf8,0x90,0x07]
; CHECK-NEXT:    knotw %k0, %k0 ## encoding: [0xc5,0xf8,0x44,0xc0]
; CHECK-NEXT:    kmovw %k0, (%rdi) ## encoding: [0xc5,0xf8,0x91,0x07]
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: mask16_mem:
; X86:       ## %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax ## encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    kmovw (%eax), %k0 ## encoding: [0xc5,0xf8,0x90,0x00]
; X86-NEXT:    knotw %k0, %k0 ## encoding: [0xc5,0xf8,0x44,0xc0]
; X86-NEXT:    kmovw %k0, (%eax) ## encoding: [0xc5,0xf8,0x91,0x00]
; X86-NEXT:    retl ## encoding: [0xc3]
  %x = load i16, ptr %ptr, align 4
  %m0 = bitcast i16 %x to <16 x i1>
  %m1 = xor <16 x i1> %m0, <i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1>
  %ret = bitcast <16 x i1> %m1 to i16
  store i16 %ret, ptr %ptr, align 4
  ret void
}

define void @mask8_mem(ptr %ptr) {
; CHECK-LABEL: mask8_mem:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovb (%rdi), %k0 ## encoding: [0xc5,0xf9,0x90,0x07]
; CHECK-NEXT:    knotb %k0, %k0 ## encoding: [0xc5,0xf9,0x44,0xc0]
; CHECK-NEXT:    kmovb %k0, (%rdi) ## encoding: [0xc5,0xf9,0x91,0x07]
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: mask8_mem:
; X86:       ## %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax ## encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    kmovb (%eax), %k0 ## encoding: [0xc5,0xf9,0x90,0x00]
; X86-NEXT:    knotb %k0, %k0 ## encoding: [0xc5,0xf9,0x44,0xc0]
; X86-NEXT:    kmovb %k0, (%eax) ## encoding: [0xc5,0xf9,0x91,0x00]
; X86-NEXT:    retl ## encoding: [0xc3]
  %x = load i8, ptr %ptr, align 4
  %m0 = bitcast i8 %x to <8 x i1>
  %m1 = xor <8 x i1> %m0, <i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1, i1 -1>
  %ret = bitcast <8 x i1> %m1 to i8
  store i8 %ret, ptr %ptr, align 4
  ret void
}

define i16 @mand16_mem(ptr %x, ptr %y) {
; CHECK-LABEL: mand16_mem:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovw (%rdi), %k0 ## encoding: [0xc5,0xf8,0x90,0x07]
; CHECK-NEXT:    kmovw (%rsi), %k1 ## encoding: [0xc5,0xf8,0x90,0x0e]
; CHECK-NEXT:    korw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x45,0xc1]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: mand16_mem:
; X86:       ## %bb.0:
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax ## encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %ecx ## encoding: [0x8b,0x4c,0x24,0x04]
; X86-NEXT:    kmovw (%ecx), %k0 ## encoding: [0xc5,0xf8,0x90,0x01]
; X86-NEXT:    kmovw (%eax), %k1 ## encoding: [0xc5,0xf8,0x90,0x08]
; X86-NEXT:    korw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x45,0xc1]
; X86-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; X86-NEXT:    ## kill: def $ax killed $ax killed $eax
; X86-NEXT:    retl ## encoding: [0xc3]
  %ma = load <16 x i1>, ptr %x
  %mb = load <16 x i1>, ptr %y
  %mc = and <16 x i1> %ma, %mb
  %md = xor <16 x i1> %ma, %mb
  %me = or <16 x i1> %mc, %md
  %ret = bitcast <16 x i1> %me to i16
  ret i16 %ret
}

define i8 @shuf_test1(i16 %v) nounwind {
; CHECK-LABEL: shuf_test1:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovd %edi, %k0 ## encoding: [0xc5,0xfb,0x92,0xc7]
; CHECK-NEXT:    kshiftrw $8, %k0, %k0 ## encoding: [0xc4,0xe3,0xf9,0x30,0xc0,0x08]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: shuf_test1:
; X86:       ## %bb.0:
; X86-NEXT:    movzbl {{[0-9]+}}(%esp), %eax ## encoding: [0x0f,0xb6,0x44,0x24,0x05]
; X86-NEXT:    retl ## encoding: [0xc3]
   %v1 = bitcast i16 %v to <16 x i1>
   %mask = shufflevector <16 x i1> %v1, <16 x i1> undef, <8 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
   %mask1 = bitcast <8 x i1> %mask to i8
   ret i8 %mask1
}

define void @test6(<16 x i1> %mask)  {
; CHECK-LABEL: test6:
; CHECK:       ## %bb.0: ## %allocas
; CHECK-NEXT:    vpsllw $7, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0x71,0xf0,0x07]
; CHECK-NEXT:    vpmovmskb %xmm0, %eax ## encoding: [0xc5,0xf9,0xd7,0xc0]
; CHECK-NEXT:    testl $21845, %eax ## encoding: [0xa9,0x55,0x55,0x00,0x00]
; CHECK-NEXT:    ## imm = 0x5555
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: test6:
; X86:       ## %bb.0: ## %allocas
; X86-NEXT:    vpsllw $7, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0x71,0xf0,0x07]
; X86-NEXT:    vpmovmskb %xmm0, %eax ## encoding: [0xc5,0xf9,0xd7,0xc0]
; X86-NEXT:    testl $21845, %eax ## encoding: [0xa9,0x55,0x55,0x00,0x00]
; X86-NEXT:    ## imm = 0x5555
; X86-NEXT:    retl ## encoding: [0xc3]
allocas:
  %a= and <16 x i1> %mask, <i1 true, i1 false, i1 true, i1 false, i1 true, i1 false, i1 true, i1 false, i1 true, i1 false, i1 true, i1 false, i1 true, i1 false, i1 true, i1 false>
  %b = bitcast <16 x i1> %a to i16
  %c = icmp eq i16 %b, 0
  br i1 %c, label %true, label %false

true:
  ret void

false:
  ret void
}

define <4 x i1> @test14()  {
; CHECK-LABEL: test14:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vmovaps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0 ## EVEX TO VEX Compression xmm0 = [1,1,0,1]
; CHECK-NEXT:    ## encoding: [0xc5,0xf8,0x28,0x05,A,A,A,A]
; CHECK-NEXT:    ## fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}-4, kind: reloc_riprel_4byte
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: test14:
; X86:       ## %bb.0:
; X86-NEXT:    vmovaps {{\.?LCPI[0-9]+_[0-9]+}}, %xmm0 ## EVEX TO VEX Compression xmm0 = [1,1,0,1]
; X86-NEXT:    ## encoding: [0xc5,0xf8,0x28,0x05,A,A,A,A]
; X86-NEXT:    ## fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}, kind: FK_Data_4
; X86-NEXT:    retl ## encoding: [0xc3]
  %a = bitcast i16 21845 to <16 x i1>
  %b = extractelement <16 x i1> %a, i32 2
  %c = insertelement <4 x i1> <i1 true, i1 false, i1 false, i1 true>, i1 %b, i32 1
  ret <4 x i1> %c
}

define void @store_v1i1(<1 x i1> %c , ptr %ptr) {
; CHECK-LABEL: store_v1i1:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovd %edi, %k0 ## encoding: [0xc5,0xfb,0x92,0xc7]
; CHECK-NEXT:    knotw %k0, %k0 ## encoding: [0xc5,0xf8,0x44,0xc0]
; CHECK-NEXT:    kshiftlb $7, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x32,0xc0,0x07]
; CHECK-NEXT:    kshiftrb $7, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x30,0xc0,0x07]
; CHECK-NEXT:    kmovb %k0, (%rsi) ## encoding: [0xc5,0xf9,0x91,0x06]
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: store_v1i1:
; X86:       ## %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k0 ## encoding: [0xc4,0xe1,0xf9,0x90,0x44,0x24,0x04]
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax ## encoding: [0x8b,0x44,0x24,0x08]
; X86-NEXT:    knotw %k0, %k0 ## encoding: [0xc5,0xf8,0x44,0xc0]
; X86-NEXT:    kshiftlb $7, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x32,0xc0,0x07]
; X86-NEXT:    kshiftrb $7, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x30,0xc0,0x07]
; X86-NEXT:    kmovb %k0, (%eax) ## encoding: [0xc5,0xf9,0x91,0x00]
; X86-NEXT:    retl ## encoding: [0xc3]
  %x = xor <1 x i1> %c, <i1 1>
  store <1 x i1> %x, ptr  %ptr, align 4
  ret void
}

define void @store_v128i1_constant(ptr %R) {
; CHECK-LABEL: store_v128i1_constant:
; CHECK:       ## %bb.0: ## %entry
; CHECK-NEXT:    vmovaps {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0 ## EVEX TO VEX Compression xmm0 = [4294963197,3758096251,4294959101,3221225403]
; CHECK-NEXT:    ## encoding: [0xc5,0xf8,0x28,0x05,A,A,A,A]
; CHECK-NEXT:    ## fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}-4, kind: reloc_riprel_4byte
; CHECK-NEXT:    vmovaps %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x07]
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: store_v128i1_constant:
; X86:       ## %bb.0: ## %entry
; X86-NEXT:    movl {{[0-9]+}}(%esp), %eax ## encoding: [0x8b,0x44,0x24,0x04]
; X86-NEXT:    vmovaps {{\.?LCPI[0-9]+_[0-9]+}}, %xmm0 ## EVEX TO VEX Compression xmm0 = [4294963197,3758096251,4294959101,3221225403]
; X86-NEXT:    ## encoding: [0xc5,0xf8,0x28,0x05,A,A,A,A]
; X86-NEXT:    ## fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}, kind: FK_Data_4
; X86-NEXT:    vmovaps %xmm0, (%eax) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x00]
; X86-NEXT:    retl ## encoding: [0xc3]
entry:
  store <128 x i1> <i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 0, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 1, i1 0, i1 1>, ptr %R
  ret void
}

define <1 x i1> @usub_sat_v1i1(<1 x i1> %x, <1 x i1> %y) nounwind {
; CHECK-LABEL: usub_sat_v1i1:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovd %esi, %k0 ## encoding: [0xc5,0xfb,0x92,0xc6]
; CHECK-NEXT:    kmovd %edi, %k1 ## encoding: [0xc5,0xfb,0x92,0xcf]
; CHECK-NEXT:    kandnw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x42,0xc1]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: usub_sat_v1i1:
; X86:       ## %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k0 ## encoding: [0xc4,0xe1,0xf9,0x90,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 ## encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    kandnw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x42,0xc1]
; X86-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; X86-NEXT:    ## kill: def $al killed $al killed $eax
; X86-NEXT:    retl ## encoding: [0xc3]
  %z = call <1 x i1> @llvm.usub.sat.v1i1(<1 x i1> %x, <1 x i1> %y)
  ret <1 x i1> %z
}

define <1 x i1> @ssub_sat_v1i1(<1 x i1> %x, <1 x i1> %y) nounwind {
; CHECK-LABEL: ssub_sat_v1i1:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovd %esi, %k0 ## encoding: [0xc5,0xfb,0x92,0xc6]
; CHECK-NEXT:    kmovd %edi, %k1 ## encoding: [0xc5,0xfb,0x92,0xcf]
; CHECK-NEXT:    kandnw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x42,0xc1]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: ssub_sat_v1i1:
; X86:       ## %bb.0:
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k0 ## encoding: [0xc4,0xe1,0xf9,0x90,0x44,0x24,0x08]
; X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1 ## encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x04]
; X86-NEXT:    kandnw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x42,0xc1]
; X86-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; X86-NEXT:    ## kill: def $al killed $al killed $eax
; X86-NEXT:    retl ## encoding: [0xc3]
  %z = call <1 x i1> @llvm.ssub.sat.v1i1(<1 x i1> %x, <1 x i1> %y)
  ret <1 x i1> %z
}
declare <1 x i1> @llvm.usub.sat.v1i1(<1 x i1> %x, <1 x i1> %y)
declare <1 x i1> @llvm.ssub.sat.v1i1(<1 x i1> %x, <1 x i1> %y)

define void @masked_spill(ptr %dummy1, ptr %dummy2, ptr %dummy3, ptr %dummy4, ptr %dummy5, ptr %ptr, i1 %pred) {
; CHECK-LABEL: masked_spill:
; CHECK:       ## %bb.0: ## %entry
; CHECK-NEXT:    pushq %rbx ## encoding: [0x53]
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    subq $16, %rsp ## encoding: [0x48,0x83,0xec,0x10]
; CHECK-NEXT:    .cfi_def_cfa_offset 32
; CHECK-NEXT:    .cfi_offset %rbx, -16
; CHECK-NEXT:    movq %r9, %rbx ## encoding: [0x4c,0x89,0xcb]
; CHECK-NEXT:    kmovb {{[0-9]+}}(%rsp), %k1 ## encoding: [0xc5,0xf9,0x90,0x4c,0x24,0x20]
; CHECK-NEXT:    kmovd %k1, {{[-0-9]+}}(%r{{[sb]}}p) ## 4-byte Spill
; CHECK-NEXT:    ## encoding: [0xc4,0xe1,0xf9,0x91,0x4c,0x24,0x0c]
; CHECK-NEXT:    callq _dummy_call ## encoding: [0xe8,A,A,A,A]
; CHECK-NEXT:    ## fixup A - offset: 1, value: _dummy_call-4, kind: reloc_branch_4byte_pcrel
; CHECK-NEXT:    vxorps %xmm1, %xmm1, %xmm1 ## EVEX TO VEX Compression encoding: [0xc5,0xf0,0x57,0xc9]
; CHECK-NEXT:    kmovd {{[-0-9]+}}(%r{{[sb]}}p), %k1 ## 4-byte Reload
; CHECK-NEXT:    ## encoding: [0xc4,0xe1,0xf9,0x90,0x4c,0x24,0x0c]
; CHECK-NEXT:    vmovss %xmm1, %xmm0, %xmm0 {%k1} ## encoding: [0x62,0xf1,0x7e,0x09,0x10,0xc1]
; CHECK-NEXT:    vmovss %xmm0, (%rbx) ## EVEX TO VEX Compression encoding: [0xc5,0xfa,0x11,0x03]
; CHECK-NEXT:    addq $16, %rsp ## encoding: [0x48,0x83,0xc4,0x10]
; CHECK-NEXT:    popq %rbx ## encoding: [0x5b]
; CHECK-NEXT:    retq ## encoding: [0xc3]
;
; X86-LABEL: masked_spill:
; X86:       ## %bb.0: ## %entry
; X86-NEXT:    pushl %esi ## encoding: [0x56]
; X86-NEXT:    .cfi_def_cfa_offset 8
; X86-NEXT:    subl $8, %esp ## encoding: [0x83,0xec,0x08]
; X86-NEXT:    .cfi_def_cfa_offset 16
; X86-NEXT:    .cfi_offset %esi, -8
; X86-NEXT:    movl {{[0-9]+}}(%esp), %esi ## encoding: [0x8b,0x74,0x24,0x24]
; X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1 ## encoding: [0xc5,0xf9,0x90,0x4c,0x24,0x28]
; X86-NEXT:    kmovd %k1, (%esp) ## 4-byte Spill
; X86-NEXT:    ## encoding: [0xc4,0xe1,0xf9,0x91,0x0c,0x24]
; X86-NEXT:    calll _dummy_call ## encoding: [0xe8,A,A,A,A]
; X86-NEXT:    ## fixup A - offset: 1, value: _dummy_call-4, kind: FK_PCRel_4
; X86-NEXT:    fstps {{[0-9]+}}(%esp) ## encoding: [0xd9,0x5c,0x24,0x04]
; X86-NEXT:    vmovss {{[0-9]+}}(%esp), %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xfa,0x10,0x44,0x24,0x04]
; X86-NEXT:    ## xmm0 = mem[0],zero,zero,zero
; X86-NEXT:    vxorps %xmm1, %xmm1, %xmm1 ## EVEX TO VEX Compression encoding: [0xc5,0xf0,0x57,0xc9]
; X86-NEXT:    kmovd (%esp), %k1 ## 4-byte Reload
; X86-NEXT:    ## encoding: [0xc4,0xe1,0xf9,0x90,0x0c,0x24]
; X86-NEXT:    vmovss %xmm1, %xmm0, %xmm0 {%k1} ## encoding: [0x62,0xf1,0x7e,0x09,0x10,0xc1]
; X86-NEXT:    vmovss %xmm0, (%esi) ## EVEX TO VEX Compression encoding: [0xc5,0xfa,0x11,0x06]
; X86-NEXT:    addl $8, %esp ## encoding: [0x83,0xc4,0x08]
; X86-NEXT:    popl %esi ## encoding: [0x5e]
; X86-NEXT:    retl ## encoding: [0xc3]
entry:
  %result = call float () @dummy_call()
  %select = select i1 %pred, float 0.000000e+00, float %result
  store float %select, ptr %ptr, align 1
  ret void
}
declare float @dummy_call()
