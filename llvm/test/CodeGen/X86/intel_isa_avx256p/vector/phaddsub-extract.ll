; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx256p
; RUN: llc < %s -mtriple=x86_64-unknown -mattr=+avx256p --show-mc-encoding          | FileCheck %s --check-prefixes=AVX,AVX-SLOW,AVX512-SLOW
; RUN: llc < %s -mtriple=x86_64-unknown -mattr=+avx256p,fast-hops --show-mc-encoding | FileCheck %s --check-prefixes=AVX,AVX-FAST,AVX512-FAST

; 128-bit vectors, 16/32-bit, add/sub

define i32 @extract_extract01_v4i32_add_i32(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v4i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v4i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  %x1 = extractelement <4 x i32> %x, i32 1
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract23_v4i32_add_i32(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v4i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v4i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 2
  %x1 = extractelement <4 x i32> %x, i32 3
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v4i32_add_i32_commute(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v4i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v4i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  %x1 = extractelement <4 x i32> %x, i32 1
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i32 @extract_extract23_v4i32_add_i32_commute(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v4i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v4i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 2
  %x1 = extractelement <4 x i32> %x, i32 3
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v8i16_add_i16(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 0
  %x1 = extractelement <8 x i16> %x, i32 1
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract45_v8i16_add_i16(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract45_v8i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpextrw $4, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x04]
; AVX-SLOW-NEXT:    vpextrw $5, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x05]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract45_v8i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vpextrw $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x02]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 4
  %x1 = extractelement <8 x i16> %x, i32 5
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract01_v8i16_add_i16_commute(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 0
  %x1 = extractelement <8 x i16> %x, i32 1
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i16 @extract_extract45_v8i16_add_i16_commute(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract45_v8i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpextrw $4, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x04]
; AVX-SLOW-NEXT:    vpextrw $5, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x05]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract45_v8i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vpextrw $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x02]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 4
  %x1 = extractelement <8 x i16> %x, i32 5
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i32 @extract_extract01_v4i32_sub_i32(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v4i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc1,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v4i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  %x1 = extractelement <4 x i32> %x, i32 1
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract23_v4i32_sub_i32(<4 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v4i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x03]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v4i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 2
  %x1 = extractelement <4 x i32> %x, i32 3
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v4i32_sub_i32_commute(<4 x i32> %x) {
; AVX-LABEL: extract_extract01_v4i32_sub_i32_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  %x1 = extractelement <4 x i32> %x, i32 1
  %x01 = sub i32 %x1, %x0
  ret i32 %x01
}

define i32 @extract_extract23_v4i32_sub_i32_commute(<4 x i32> %x) {
; AVX-LABEL: extract_extract23_v4i32_sub_i32_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 2
  %x1 = extractelement <4 x i32> %x, i32 3
  %x01 = sub i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v8i16_sub_i16(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i16_sub_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i16_sub_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x05,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 0
  %x1 = extractelement <8 x i16> %x, i32 1
  %x01 = sub i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract23_v8i16_sub_i16(<8 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract23_v8i16_sub_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpextrw $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x02]
; AVX-SLOW-NEXT:    vpextrw $3, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x03]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v8i16_sub_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x05,0xc0]
; AVX-FAST-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 2
  %x1 = extractelement <8 x i16> %x, i32 3
  %x01 = sub i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract01_v8i16_sub_i16_commute(<8 x i16> %x) {
; AVX-LABEL: extract_extract01_v8i16_sub_i16_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 0
  %x1 = extractelement <8 x i16> %x, i32 1
  %x01 = sub i16 %x1, %x0
  ret i16 %x01
}

define i16 @extract_extract23_v8i16_sub_i16_commute(<8 x i16> %x) {
; AVX-LABEL: extract_extract23_v8i16_sub_i16_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vpextrw $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x02]
; AVX-NEXT:    vpextrw $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x03]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i16> %x, i32 2
  %x1 = extractelement <8 x i16> %x, i32 3
  %x01 = sub i16 %x1, %x0
  ret i16 %x01
}

; 256-bit vectors, i32/i16, add/sub

define i32 @extract_extract01_v8i32_add_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 0
  %x1 = extractelement <8 x i32> %x, i32 1
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract23_v8i32_add_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v8i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v8i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 2
  %x1 = extractelement <8 x i32> %x, i32 3
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract67_v8i32_add_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract67_v8i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractf128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x19,0xc0,0x01]
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract67_v8i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 6
  %x1 = extractelement <8 x i32> %x, i32 7
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v8i32_add_i32_commute(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 0
  %x1 = extractelement <8 x i32> %x, i32 1
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i32 @extract_extract23_v8i32_add_i32_commute(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v8i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v8i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 2
  %x1 = extractelement <8 x i32> %x, i32 3
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i32 @extract_extract67_v8i32_add_i32_commute(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract67_v8i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractf128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x19,0xc0,0x01]
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract67_v8i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 6
  %x1 = extractelement <8 x i32> %x, i32 7
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v16i16_add_i16(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 0
  %x1 = extractelement <16 x i16> %x, i32 1
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract23_v16i16_add_i16(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract23_v16i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpextrw $2, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x02]
; AVX-SLOW-NEXT:    vpextrw $3, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x03]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v16i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 2
  %x1 = extractelement <16 x i16> %x, i32 3
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract89_v16i16_add_i16(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract89_v16i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract89_v16i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 8
  %x1 = extractelement <16 x i16> %x, i32 9
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract01_v16i16_add_i16_commute(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 0
  %x1 = extractelement <16 x i16> %x, i32 1
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i16 @extract_extract45_v16i16_add_i16_commute(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract45_v16i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpextrw $4, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x04]
; AVX-SLOW-NEXT:    vpextrw $5, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x05]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract45_v16i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vpextrw $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x02]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 4
  %x1 = extractelement <16 x i16> %x, i32 5
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i16 @extract_extract89_v16i16_add_i16_commute(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract89_v16i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract89_v16i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 8
  %x1 = extractelement <16 x i16> %x, i32 9
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i32 @extract_extract01_v8i32_sub_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v8i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc1,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v8i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 0
  %x1 = extractelement <8 x i32> %x, i32 1
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract23_v8i32_sub_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract23_v8i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x03]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract23_v8i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 2
  %x1 = extractelement <8 x i32> %x, i32 3
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract67_v8i32_sub_i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract67_v8i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vextractf128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x19,0xc0,0x01]
; AVX-SLOW-NEXT:    vextractps $2, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x02]
; AVX-SLOW-NEXT:    vextractps $3, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc1,0x03]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract67_v8i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vextracti128 $1, %ymm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 6
  %x1 = extractelement <8 x i32> %x, i32 7
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

; Negative test...or get hoppy and negate?

define i32 @extract_extract01_v8i32_sub_i32_commute(<8 x i32> %x) {
; AVX-LABEL: extract_extract01_v8i32_sub_i32_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <8 x i32> %x, i32 0
  %x1 = extractelement <8 x i32> %x, i32 1
  %x01 = sub i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v16i16_sub_i16(<16 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i16_sub_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i16_sub_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x05,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 0
  %x1 = extractelement <16 x i16> %x, i32 1
  %x01 = sub i16 %x0, %x1
  ret i16 %x01
}

; Negative test...or get hoppy and negate?

define i16 @extract_extract01_v16i16_sub_i16_commute(<16 x i16> %x) {
; AVX-LABEL: extract_extract01_v16i16_sub_i16_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i16> %x, i32 0
  %x1 = extractelement <16 x i16> %x, i32 1
  %x01 = sub i16 %x1, %x0
  ret i16 %x01
}

; 512-bit vectors, i32/i16, add/sub

define i32 @extract_extract01_v16i32_add_i32(<16 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i32_add_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i32_add_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i32> %x, i32 0
  %x1 = extractelement <16 x i32> %x, i32 1
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v16i32_add_i32_commute(<16 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i32_add_i32_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i32_add_i32_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i32> %x, i32 0
  %x1 = extractelement <16 x i32> %x, i32 1
  %x01 = add i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v32i16_add_i16(<32 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v32i16_add_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v32i16_add_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <32 x i16> %x, i32 0
  %x1 = extractelement <32 x i16> %x, i32 1
  %x01 = add i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract01_v32i16_add_i16_commute(<32 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v32i16_add_i16_commute:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v32i16_add_i16_commute:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <32 x i16> %x, i32 0
  %x1 = extractelement <32 x i16> %x, i32 1
  %x01 = add i16 %x1, %x0
  ret i16 %x01
}

define i32 @extract_extract01_v16i32_sub_i32(<16 x i32> %x) {
; AVX-SLOW-LABEL: extract_extract01_v16i32_sub_i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc1,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v16i32_sub_i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i32> %x, i32 0
  %x1 = extractelement <16 x i32> %x, i32 1
  %x01 = sub i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v16i32_sub_i32_commute(<16 x i32> %x) {
; AVX-LABEL: extract_extract01_v16i32_sub_i32_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <16 x i32> %x, i32 0
  %x1 = extractelement <16 x i32> %x, i32 1
  %x01 = sub i32 %x1, %x0
  ret i32 %x01
}

define i16 @extract_extract01_v32i16_sub_i16(<32 x i16> %x) {
; AVX-SLOW-LABEL: extract_extract01_v32i16_sub_i16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-SLOW-NEXT:    vpextrw $1, %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc8,0x01]
; AVX-SLOW-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v32i16_sub_i16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphsubw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x05,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <32 x i16> %x, i32 0
  %x1 = extractelement <32 x i16> %x, i32 1
  %x01 = sub i16 %x0, %x1
  ret i16 %x01
}

define i16 @extract_extract01_v32i16_sub_i16_commute(<32 x i16> %x) {
; AVX-LABEL: extract_extract01_v32i16_sub_i16_commute:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovw %xmm0, %ecx # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc1]
; AVX-NEXT:    vpextrw $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; AVX-NEXT:    subl %ecx, %eax # encoding: [0x29,0xc8]
; AVX-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <32 x i16> %x, i32 0
  %x1 = extractelement <32 x i16> %x, i32 1
  %x01 = sub i16 %x1, %x0
  ret i16 %x01
}

; Check output when 1 or both extracts have extra uses.

define i32 @extract_extract01_v4i32_add_i32_uses1(<4 x i32> %x, ptr %p) {
; AVX-SLOW-LABEL: extract_extract01_v4i32_add_i32_uses1:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0x07]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v4i32_add_i32_uses1:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vmovd %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0x07]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  store i32 %x0, ptr %p
  %x1 = extractelement <4 x i32> %x, i32 1
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v4i32_add_i32_uses2(<4 x i32> %x, ptr %p) {
; AVX-SLOW-LABEL: extract_extract01_v4i32_add_i32_uses2:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-SLOW-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-SLOW-NEXT:    vpextrd $1, %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0x07,0x01]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: extract_extract01_v4i32_add_i32_uses2:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vpextrd $1, %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0x07,0x01]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  %x1 = extractelement <4 x i32> %x, i32 1
  store i32 %x1, ptr %p
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

define i32 @extract_extract01_v4i32_add_i32_uses3(<4 x i32> %x, ptr %p1, ptr %p2) {
; AVX-LABEL: extract_extract01_v4i32_add_i32_uses3:
; AVX:       # %bb.0:
; AVX-NEXT:    vmovd %xmm0, %ecx # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc1]
; AVX-NEXT:    vmovd %xmm0, (%rdi) # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0x07]
; AVX-NEXT:    vpextrd $1, %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0xc0,0x01]
; AVX-NEXT:    addl %ecx, %eax # encoding: [0x01,0xc8]
; AVX-NEXT:    vpextrd $1, %xmm0, (%rsi) # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x16,0x06,0x01]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x0 = extractelement <4 x i32> %x, i32 0
  store i32 %x0, ptr %p1
  %x1 = extractelement <4 x i32> %x, i32 1
  store i32 %x1, ptr %p2
  %x01 = add i32 %x0, %x1
  ret i32 %x01
}

; PR33758: https://bugs.llvm.org/show_bug.cgi?id=33758

define i32 @partial_reduction_add_v8i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: partial_reduction_add_v8i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: partial_reduction_add_v8i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x23 = shufflevector <8 x i32> %x, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0213 = add <8 x i32> %x, %x23
  %x13 = shufflevector <8 x i32> %x0213, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0123 = add <8 x i32> %x0213, %x13
  %r = extractelement <8 x i32> %x0123, i32 0
  ret i32 %r
}

define i32 @partial_reduction_add_v16i32(<16 x i32> %x) {
; AVX-SLOW-LABEL: partial_reduction_add_v16i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: partial_reduction_add_v16i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x23 = shufflevector <16 x i32> %x, <16 x i32> undef, <16 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0213 = add <16 x i32> %x, %x23
  %x13 = shufflevector <16 x i32> %x0213, <16 x i32> undef, <16 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0123 = add <16 x i32> %x0213, %x13
  %r = extractelement <16 x i32> %x0123, i32 0
  ret i32 %r
}

define i32 @partial_reduction_sub_v8i32(<8 x i32> %x) {
; AVX-SLOW-LABEL: partial_reduction_sub_v8i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: partial_reduction_sub_v8i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-FAST-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-FAST-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x23 = shufflevector <8 x i32> %x, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0213 = sub <8 x i32> %x, %x23
  %x13 = shufflevector <8 x i32> %x0213, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0123 = sub <8 x i32> %x0213, %x13
  %r = extractelement <8 x i32> %x0123, i32 0
  ret i32 %r
}

define i32 @partial_reduction_sub_v16i32(<16 x i32> %x) {
; AVX-SLOW-LABEL: partial_reduction_sub_v16i32:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: partial_reduction_sub_v16i32:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-FAST-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-FAST-NEXT:    vpsubd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfa,0xc1]
; AVX-FAST-NEXT:    vphsubd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x06,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x23 = shufflevector <16 x i32> %x, <16 x i32> undef, <16 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0213 = sub <16 x i32> %x, %x23
  %x13 = shufflevector <16 x i32> %x0213, <16 x i32> undef, <16 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x0123 = sub <16 x i32> %x0213, %x13
  %r = extractelement <16 x i32> %x0123, i32 0
  ret i32 %r
}

; https://bugs.chromium.org/p/chromium/issues/detail?id=1195353
define <2 x i64> @negative_extract_v16i16_v8i16(<4 x i64> %a0) {
; AVX-LABEL: negative_extract_v16i16_v8i16:
; AVX:       # %bb.0:
; AVX-NEXT:    vextracti128 $1, %ymm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc1,0x01]
; AVX-NEXT:    vpaddw %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfd,0xc1]
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %s = shufflevector <4 x i64> %a0, <4 x i64> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %b = bitcast <4 x i64> %a0 to <16 x i16>
  %c = bitcast <4 x i64> %s to <16 x i16>
  %d = add <16 x i16> %b, %c
  %e = bitcast <16 x i16> %d to <4 x i64>
  %f = shufflevector <4 x i64> %e, <4 x i64> undef, <2 x i32> <i32 0, i32 1>
  ret <2 x i64> %f
}

; PR42023 - https://bugs.llvm.org/show_bug.cgi?id=42023

define i16 @hadd16_8(<8 x i16> %x223) {
; AVX-SLOW-LABEL: hadd16_8:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddw %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfd,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddw %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfd,0xc1]
; AVX-SLOW-NEXT:    vpsrld $16, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf1,0x72,0xd0,0x10]
; AVX-SLOW-NEXT:    vpaddw %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfd,0xc1]
; AVX-SLOW-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-SLOW-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: hadd16_8:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-FAST-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-FAST-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x224 = shufflevector <8 x i16> %x223, <8 x i16> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %x225 = add <8 x i16> %x223, %x224
  %x226 = shufflevector <8 x i16> %x225, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <8 x i16> %x225, %x226
  %x228 = shufflevector <8 x i16> %x227, <8 x i16> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <8 x i16> %x227, %x228
  %x230 = extractelement <8 x i16> %x229, i32 0
  ret i16 %x230
}

define i32 @hadd32_4(<4 x i32> %x225) {
; AVX-SLOW-LABEL: hadd32_4:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: hadd32_4:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <4 x i32> %x225, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %x227 = add <4 x i32> %x225, %x226
  %x228 = shufflevector <4 x i32> %x227, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %x229 = add <4 x i32> %x227, %x228
  %x230 = extractelement <4 x i32> %x229, i32 0
  ret i32 %x230
}

define i32 @hadd32_8(<8 x i32> %x225) {
; AVX-SLOW-LABEL: hadd32_8:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: hadd32_8:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <8 x i32> %x225, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <8 x i32> %x225, %x226
  %x228 = shufflevector <8 x i32> %x227, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <8 x i32> %x227, %x228
  %x230 = extractelement <8 x i32> %x229, i32 0
  ret i32 %x230
}

define i32 @hadd32_16(<16 x i32> %x225) {
; AVX-SLOW-LABEL: hadd32_16:
; AVX-SLOW:       # %bb.0:
; AVX-SLOW-NEXT:    vpshufd $238, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0xee]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[2,3,2,3]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vpshufd $85, %xmm0, %xmm1 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x70,0xc8,0x55]
; AVX-SLOW-NEXT:    # xmm1 = xmm0[1,1,1,1]
; AVX-SLOW-NEXT:    vpaddd %xmm1, %xmm0, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf9,0xfe,0xc1]
; AVX-SLOW-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-SLOW-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-SLOW-NEXT:    retq # encoding: [0xc3]
;
; AVX-FAST-LABEL: hadd32_16:
; AVX-FAST:       # %bb.0:
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-FAST-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-FAST-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-FAST-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <16 x i32> %x225, <16 x i32> undef, <16 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <16 x i32> %x225, %x226
  %x228 = shufflevector <16 x i32> %x227, <16 x i32> undef, <16 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <16 x i32> %x227, %x228
  %x230 = extractelement <16 x i32> %x229, i32 0
  ret i32 %x230
}

define i16 @hadd16_8_optsize(<8 x i16> %x223) optsize {
; AVX-LABEL: hadd16_8_optsize:
; AVX:       # %bb.0:
; AVX-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-NEXT:    vphaddw %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x01,0xc0]
; AVX-NEXT:    vmovw %xmm0, %eax # encoding: [0x62,0xf5,0x7d,0x08,0x7e,0xc0]
; AVX-NEXT:    # kill: def $ax killed $ax killed $eax
; AVX-NEXT:    retq # encoding: [0xc3]
  %x224 = shufflevector <8 x i16> %x223, <8 x i16> undef, <8 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef>
  %x225 = add <8 x i16> %x223, %x224
  %x226 = shufflevector <8 x i16> %x225, <8 x i16> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <8 x i16> %x225, %x226
  %x228 = shufflevector <8 x i16> %x227, <8 x i16> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <8 x i16> %x227, %x228
  %x230 = extractelement <8 x i16> %x229, i32 0
  ret i16 %x230
}

define i32 @hadd32_4_optsize(<4 x i32> %x225) optsize {
; AVX-LABEL: hadd32_4_optsize:
; AVX:       # %bb.0:
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <4 x i32> %x225, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %x227 = add <4 x i32> %x225, %x226
  %x228 = shufflevector <4 x i32> %x227, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %x229 = add <4 x i32> %x227, %x228
  %x230 = extractelement <4 x i32> %x229, i32 0
  ret i32 %x230
}

define i32 @hadd32_4_pgso(<4 x i32> %x225) !prof !14 {
; AVX-LABEL: hadd32_4_pgso:
; AVX:       # %bb.0:
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <4 x i32> %x225, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %x227 = add <4 x i32> %x225, %x226
  %x228 = shufflevector <4 x i32> %x227, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %x229 = add <4 x i32> %x227, %x228
  %x230 = extractelement <4 x i32> %x229, i32 0
  ret i32 %x230
}

define i32 @hadd32_8_optsize(<8 x i32> %x225) optsize {
; AVX-LABEL: hadd32_8_optsize:
; AVX:       # %bb.0:
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <8 x i32> %x225, <8 x i32> undef, <8 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <8 x i32> %x225, %x226
  %x228 = shufflevector <8 x i32> %x227, <8 x i32> undef, <8 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <8 x i32> %x227, %x228
  %x230 = extractelement <8 x i32> %x229, i32 0
  ret i32 %x230
}

define i32 @hadd32_16_optsize(<16 x i32> %x225) optsize {
; AVX-LABEL: hadd32_16_optsize:
; AVX:       # %bb.0:
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vphaddd %xmm0, %xmm0, %xmm0 # encoding: [0xc4,0xe2,0x79,0x02,0xc0]
; AVX-NEXT:    vmovd %xmm0, %eax # EVEX TO VEX Compression encoding: [0xc5,0xf9,0x7e,0xc0]
; AVX-NEXT:    vzeroupper # encoding: [0xc5,0xf8,0x77]
; AVX-NEXT:    retq # encoding: [0xc3]
  %x226 = shufflevector <16 x i32> %x225, <16 x i32> undef, <16 x i32> <i32 2, i32 3, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x227 = add <16 x i32> %x225, %x226
  %x228 = shufflevector <16 x i32> %x227, <16 x i32> undef, <16 x i32> <i32 1, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %x229 = add <16 x i32> %x227, %x228
  %x230 = extractelement <16 x i32> %x229, i32 0
  ret i32 %x230
}

!llvm.module.flags = !{!0}
!0 = !{i32 1, !"ProfileSummary", !1}
!1 = !{!2, !3, !4, !5, !6, !7, !8, !9}
!2 = !{!"ProfileFormat", !"InstrProf"}
!3 = !{!"TotalCount", i64 10000}
!4 = !{!"MaxCount", i64 10}
!5 = !{!"MaxInternalCount", i64 1}
!6 = !{!"MaxFunctionCount", i64 1000}
!7 = !{!"NumCounts", i64 3}
!8 = !{!"NumFunctions", i64 3}
!9 = !{!"DetailedSummary", !10}
!10 = !{!11, !12, !13}
!11 = !{i32 10000, i64 100, i32 1}
!12 = !{i32 999000, i64 100, i32 1}
!13 = !{i32 999999, i64 1, i32 2}
!14 = !{!"function_entry_count", i64 0}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; AVX512-FAST: {{.*}}
; AVX512-SLOW: {{.*}}
