; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx256p
; RUN: llc < %s -mtriple=x86_64-apple-darwin -mattr=+avx256p --show-mc-encoding | FileCheck --check-prefixes=CHECK,SKX %s

define i32 @test5(<4 x float> %x) nounwind {
; CHECK-LABEL: test5:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextractps $3, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x03]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %ef = extractelement <4 x float> %x, i32 3
  %ei = bitcast float %ef to i32
  ret i32 %ei
}

define void @test6(<4 x float> %x, ptr %out) nounwind {
; CHECK-LABEL: test6:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextractps $3, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0x07,0x03]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %ef = extractelement <4 x float> %x, i32 3
  store float %ef, ptr %out, align 4
  ret void
}

define i16 @test13(i32 %a, i32 %b) {
; KNL-LABEL: test13:
; KNL:       ## %bb.0:
; KNL-NEXT:    cmpl %esi, %edi
; KNL-NEXT:    setb %al
; KNL-NEXT:    movw $-4, %cx
; KNL-NEXT:    kmovw %ecx, %k0
; KNL-NEXT:    kshiftrw $1, %k0, %k0
; KNL-NEXT:    kshiftlw $1, %k0, %k0
; KNL-NEXT:    andl $1, %eax
; KNL-NEXT:    kmovw %eax, %k1
; KNL-NEXT:    korw %k1, %k0, %k0
; KNL-NEXT:    kmovw %k0, %eax
; KNL-NEXT:    ## kill: def $ax killed $ax killed $eax
; KNL-NEXT:    retq
;
; CHECK-LABEL: test13:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    cmpl %esi, %edi ## encoding: [0x39,0xf7]
; CHECK-NEXT:    setb %al ## encoding: [0x0f,0x92,0xc0]
; CHECK-NEXT:    movw $-4, %cx ## encoding: [0x66,0xb9,0xfc,0xff]
; CHECK-NEXT:    kmovd %ecx, %k0 ## encoding: [0xc5,0xfb,0x92,0xc1]
; CHECK-NEXT:    kshiftrw $1, %k0, %k0 ## encoding: [0xc4,0xe3,0xf9,0x30,0xc0,0x01]
; CHECK-NEXT:    kshiftlw $1, %k0, %k0 ## encoding: [0xc4,0xe3,0xf9,0x32,0xc0,0x01]
; CHECK-NEXT:    andl $1, %eax ## encoding: [0x83,0xe0,0x01]
; CHECK-NEXT:    kmovw %eax, %k1 ## encoding: [0xc5,0xf8,0x92,0xc8]
; CHECK-NEXT:    korw %k1, %k0, %k0 ## encoding: [0xc5,0xfc,0x45,0xc1]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %cmp_res = icmp ult i32 %a, %b
  %maskv = insertelement <16 x i1> <i1 true, i1 false, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, i1 %cmp_res, i32 0
  %res = bitcast <16 x i1> %maskv to i16
  ret i16 %res
}

define i16 @test16(ptr%addr, i16 %a) {
; KNL-LABEL: test16:
; KNL:       ## %bb.0:
; KNL-NEXT:    movzbl (%rdi), %eax
; KNL-NEXT:    kmovw %esi, %k0
; KNL-NEXT:    movw $-1025, %cx ## imm = 0xFBFF
; KNL-NEXT:    kmovw %ecx, %k1
; KNL-NEXT:    kandw %k1, %k0, %k0
; KNL-NEXT:    kmovw %eax, %k1
; KNL-NEXT:    kshiftlw $15, %k1, %k1
; KNL-NEXT:    kshiftrw $5, %k1, %k1
; KNL-NEXT:    korw %k1, %k0, %k0
; KNL-NEXT:    kmovw %k0, %eax
; KNL-NEXT:    ## kill: def $ax killed $ax killed $eax
; KNL-NEXT:    retq
;
; CHECK-LABEL: test16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovb (%rdi), %k0 ## encoding: [0xc5,0xf9,0x90,0x07]
; CHECK-NEXT:    kmovd %esi, %k1 ## encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    movw $-1025, %ax ## encoding: [0x66,0xb8,0xff,0xfb]
; CHECK-NEXT:    ## imm = 0xFBFF
; CHECK-NEXT:    kmovd %eax, %k2 ## encoding: [0xc5,0xfb,0x92,0xd0]
; CHECK-NEXT:    kandw %k2, %k1, %k1 ## encoding: [0xc5,0xf4,0x41,0xca]
; CHECK-NEXT:    kshiftlw $15, %k0, %k0 ## encoding: [0xc4,0xe3,0xf9,0x32,0xc0,0x0f]
; CHECK-NEXT:    kshiftrw $5, %k0, %k0 ## encoding: [0xc4,0xe3,0xf9,0x30,0xc0,0x05]
; CHECK-NEXT:    korw %k0, %k1, %k0 ## encoding: [0xc5,0xf4,0x45,0xc0]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %x = load i1 , ptr %addr, align 128
  %a1 = bitcast i16 %a to <16 x i1>
  %x1 = insertelement <16 x i1> %a1, i1 %x, i32 10
  %x2 = bitcast <16 x i1>%x1 to i16
  ret i16 %x2
}

define i8 @test17(ptr%addr, i8 %a) {
; KNL-LABEL: test17:
; KNL:       ## %bb.0:
; KNL-NEXT:    movzbl (%rdi), %eax
; KNL-NEXT:    kmovw %esi, %k0
; KNL-NEXT:    movw $-17, %cx
; KNL-NEXT:    kmovw %ecx, %k1
; KNL-NEXT:    kandw %k1, %k0, %k0
; KNL-NEXT:    kmovw %eax, %k1
; KNL-NEXT:    kshiftlw $15, %k1, %k1
; KNL-NEXT:    kshiftrw $11, %k1, %k1
; KNL-NEXT:    korw %k1, %k0, %k0
; KNL-NEXT:    kmovw %k0, %eax
; KNL-NEXT:    ## kill: def $al killed $al killed $eax
; KNL-NEXT:    retq
;
; CHECK-LABEL: test17:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    kmovb (%rdi), %k0 ## encoding: [0xc5,0xf9,0x90,0x07]
; CHECK-NEXT:    kmovd %esi, %k1 ## encoding: [0xc5,0xfb,0x92,0xce]
; CHECK-NEXT:    movb $-17, %al ## encoding: [0xb0,0xef]
; CHECK-NEXT:    kmovd %eax, %k2 ## encoding: [0xc5,0xfb,0x92,0xd0]
; CHECK-NEXT:    kandb %k2, %k1, %k1 ## encoding: [0xc5,0xf5,0x41,0xca]
; CHECK-NEXT:    kshiftlb $7, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x32,0xc0,0x07]
; CHECK-NEXT:    kshiftrb $3, %k0, %k0 ## encoding: [0xc4,0xe3,0x79,0x30,0xc0,0x03]
; CHECK-NEXT:    korb %k0, %k1, %k0 ## encoding: [0xc5,0xf5,0x45,0xc0]
; CHECK-NEXT:    kmovd %k0, %eax ## encoding: [0xc5,0xfb,0x93,0xc0]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %x = load i1 , ptr %addr, align 128
  %a1 = bitcast i8 %a to <8 x i1>
  %x1 = insertelement <8 x i1> %a1, i1 %x, i32 4
  %x2 = bitcast <8 x i1>%x1 to i8
  ret i8 %x2
}

define i64 @extract_v8i64(<8 x i64> %x, ptr %dst) {
; CHECK-LABEL: extract_v8i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x16,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrq $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x16,0x07,0x01]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <8 x i64> %x, i32 1
  %r2 = extractelement <8 x i64> %x, i32 3
  store i64 %r2, ptr %dst, align 1
  ret i64 %r1
}

define i64 @extract_v4i64(<4 x i64> %x, ptr %dst) {
; CHECK-LABEL: extract_v4i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrq $1, %xmm0, %rax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x16,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrq $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x16,0x07,0x01]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <4 x i64> %x, i32 1
  %r2 = extractelement <4 x i64> %x, i32 3
  store i64 %r2, ptr %dst, align 1
  ret i64 %r1
}

define i64 @extract_v2i64(<2 x i64> %x, ptr %dst) {
; CHECK-LABEL: extract_v2i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vmovq %xmm0, %rax ## EVEX TO VEX Compression encoding: [0xc4,0xe1,0xf9,0x7e,0xc0]
; CHECK-NEXT:    vpextrq $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x16,0x07,0x01]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <2 x i64> %x, i32 0
  %r2 = extractelement <2 x i64> %x, i32 1
  store i64 %r2, ptr %dst, align 1
  ret i64 %r1
}

define i32 @extract_v16i32(<16 x i32> %x, ptr %dst) {
; CHECK-LABEL: extract_v16i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextractps $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x01]
; CHECK-NEXT:    vextractf128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x19,0xc0,0x01]
; CHECK-NEXT:    vextractps $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0x07,0x01]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <16 x i32> %x, i32 1
  %r2 = extractelement <16 x i32> %x, i32 5
  store i32 %r2, ptr %dst, align 1
  ret i32 %r1
}

define i32 @extract_v8i32(<8 x i32> %x, ptr %dst) {
; CHECK-LABEL: extract_v8i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextractps $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x01]
; CHECK-NEXT:    vextractf128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x19,0xc0,0x01]
; CHECK-NEXT:    vextractps $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0x07,0x01]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <8 x i32> %x, i32 1
  %r2 = extractelement <8 x i32> %x, i32 5
  store i32 %r2, ptr %dst, align 1
  ret i32 %r1
}

define i32 @extract_v4i32(<4 x i32> %x, ptr %dst) {
; CHECK-LABEL: extract_v4i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextractps $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0xc0,0x01]
; CHECK-NEXT:    vextractps $3, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x17,0x07,0x03]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <4 x i32> %x, i32 1
  %r2 = extractelement <4 x i32> %x, i32 3
  store i32 %r2, ptr %dst, align 1
  ret i32 %r1
}

define i16 @extract_v32i16(<32 x i16> %x, ptr %dst) {
; CHECK-LABEL: extract_v32i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrw $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrw $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x15,0x07,0x01]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <32 x i16> %x, i32 1
  %r2 = extractelement <32 x i16> %x, i32 9
  store i16 %r2, ptr %dst, align 1
  ret i16 %r1
}

define i16 @extract_v16i16(<16 x i16> %x, ptr %dst) {
; CHECK-LABEL: extract_v16i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrw $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrw $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x15,0x07,0x01]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <16 x i16> %x, i32 1
  %r2 = extractelement <16 x i16> %x, i32 9
  store i16 %r2, ptr %dst, align 1
  ret i16 %r1
}

define i16 @extract_v8i16(<8 x i16> %x, ptr %dst) {
; CHECK-LABEL: extract_v8i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrw $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc5,0xc0,0x01]
; CHECK-NEXT:    vpextrw $3, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x15,0x07,0x03]
; CHECK-NEXT:    ## kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <8 x i16> %x, i32 1
  %r2 = extractelement <8 x i16> %x, i32 3
  store i16 %r2, ptr %dst, align 1
  ret i16 %r1
}

define i8 @extract_v64i8(<64 x i8> %x, ptr %dst) {
; CHECK-LABEL: extract_v64i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrb $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrb $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0x07,0x01]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <64 x i8> %x, i32 1
  %r2 = extractelement <64 x i8> %x, i32 17
  store i8 %r2, ptr %dst, align 1
  ret i8 %r1
}

define i8 @extract_v32i8(<32 x i8> %x, ptr %dst) {
; CHECK-LABEL: extract_v32i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrb $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0xc0,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpextrb $1, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0x07,0x01]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <32 x i8> %x, i32 1
  %r2 = extractelement <32 x i8> %x, i32 17
  store i8 %r2, ptr %dst, align 1
  ret i8 %r1
}

define i8 @extract_v16i8(<16 x i8> %x, ptr %dst) {
; CHECK-LABEL: extract_v16i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpextrb $1, %xmm0, %eax ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0xc0,0x01]
; CHECK-NEXT:    vpextrb $3, %xmm0, (%rdi) ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x14,0x07,0x03]
; CHECK-NEXT:    ## kill: def $al killed $al killed $eax
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r1 = extractelement <16 x i8> %x, i32 1
  %r2 = extractelement <16 x i8> %x, i32 3
  store i8 %r2, ptr %dst, align 1
  ret i8 %r1
}

define <4 x i64> @insert_v4i64(<4 x i64> %x, i64 %y , ptr %ptr) {
; KNL-LABEL: insert_v4i64:
; KNL:       ## %bb.0:
; KNL-NEXT:    vpinsrq $1, (%rsi), %xmm0, %xmm1
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; KNL-NEXT:    vmovq %rdi, %xmm1
; KNL-NEXT:    vpbroadcastq %xmm1, %ymm1
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3,4,5],ymm1[6,7]
; KNL-NEXT:    retq
;
; CHECK-LABEL: insert_v4i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrq $1, (%rsi), %xmm0, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0xf9,0x22,0x0e,0x01]
; CHECK-NEXT:    vpblendd $15, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0x0f]
; CHECK-NEXT:    ## ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; CHECK-NEXT:    vpbroadcastq %rdi, %ymm1 ## encoding: [0x62,0xf2,0xfd,0x28,0x7c,0xcf]
; CHECK-NEXT:    vpblendd $192, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0xc0]
; CHECK-NEXT:    ## ymm0 = ymm0[0,1,2,3,4,5],ymm1[6,7]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i64, ptr %ptr
  %r1 = insertelement <4 x i64> %x, i64 %val, i32 1
  %r2 = insertelement <4 x i64> %r1, i64 %y, i32 3
  ret <4 x i64> %r2
}

define <2 x i64> @insert_v2i64(<2 x i64> %x, i64 %y , ptr %ptr) {
; CHECK-LABEL: insert_v2i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vmovq (%rsi), %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xfa,0x7e,0x06]
; CHECK-NEXT:    ## xmm0 = mem[0],zero
; CHECK-NEXT:    vmovq %rdi, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe1,0xf9,0x6e,0xcf]
; CHECK-NEXT:    vpunpcklqdq %xmm0, %xmm1, %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xf1,0x6c,0xc0]
; CHECK-NEXT:    ## xmm0 = xmm1[0],xmm0[0]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i64, ptr %ptr
  %r1 = insertelement <2 x i64> %x, i64 %val, i32 1
  %r2 = insertelement <2 x i64> %r1, i64 %y, i32 0
  ret <2 x i64> %r2
}

define <8 x i32> @insert_v8i32(<8 x i32> %x, i32 %y, ptr %ptr) {
; KNL-LABEL: insert_v8i32:
; KNL:       ## %bb.0:
; KNL-NEXT:    vpinsrd $1, (%rsi), %xmm0, %xmm1
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; KNL-NEXT:    vmovd %edi, %xmm1
; KNL-NEXT:    vpbroadcastd %xmm1, %ymm1
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3,4],ymm1[5],ymm0[6,7]
; KNL-NEXT:    retq
;
; CHECK-LABEL: insert_v8i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm0, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x22,0x0e,0x01]
; CHECK-NEXT:    vpblendd $15, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0x0f]
; CHECK-NEXT:    ## ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; CHECK-NEXT:    vpbroadcastd %edi, %ymm1 ## encoding: [0x62,0xf2,0x7d,0x28,0x7c,0xcf]
; CHECK-NEXT:    vpblendd $32, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0x20]
; CHECK-NEXT:    ## ymm0 = ymm0[0,1,2,3,4],ymm1[5],ymm0[6,7]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i32, ptr %ptr
  %r1 = insertelement <8 x i32> %x, i32 %val, i32 1
  %r2 = insertelement <8 x i32> %r1, i32 %y, i32 5
  ret <8 x i32> %r2
}

define <4 x i32> @insert_v4i32(<4 x i32> %x, i32 %y, ptr %ptr) {
; CHECK-LABEL: insert_v4i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrd $1, (%rsi), %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x22,0x06,0x01]
; CHECK-NEXT:    vpinsrd $3, %edi, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x22,0xc7,0x03]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i32, ptr %ptr
  %r1 = insertelement <4 x i32> %x, i32 %val, i32 1
  %r2 = insertelement <4 x i32> %r1, i32 %y, i32 3
  ret <4 x i32> %r2
}

define <16 x i16> @insert_v16i16(<16 x i16> %x, i16 %y, ptr %ptr) {
; KNL-LABEL: insert_v16i16:
; KNL:       ## %bb.0:
; KNL-NEXT:    vpinsrw $1, (%rsi), %xmm0, %xmm1
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; KNL-NEXT:    vmovd %edi, %xmm1
; KNL-NEXT:    vpbroadcastw %xmm1, %ymm1
; KNL-NEXT:    vpblendw {{.*#+}} ymm1 = ymm0[0],ymm1[1],ymm0[2,3,4,5,6,7,8],ymm1[9],ymm0[10,11,12,13,14,15]
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; KNL-NEXT:    retq
;
; CHECK-LABEL: insert_v16i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrw $1, (%rsi), %xmm0, %xmm1 ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc4,0x0e,0x01]
; CHECK-NEXT:    vpblendd $15, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0x0f]
; CHECK-NEXT:    ## ymm0 = ymm1[0,1,2,3],ymm0[4,5,6,7]
; CHECK-NEXT:    vpbroadcastw %edi, %ymm1 ## encoding: [0x62,0xf2,0x7d,0x28,0x7b,0xcf]
; CHECK-NEXT:    vpblendw $2, %ymm1, %ymm0, %ymm1 ## encoding: [0xc4,0xe3,0x7d,0x0e,0xc9,0x02]
; CHECK-NEXT:    ## ymm1 = ymm0[0],ymm1[1],ymm0[2,3,4,5,6,7,8],ymm1[9],ymm0[10,11,12,13,14,15]
; CHECK-NEXT:    vpblendd $240, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0xf0]
; CHECK-NEXT:    ## ymm0 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i16, ptr %ptr
  %r1 = insertelement <16 x i16> %x, i16 %val, i32 1
  %r2 = insertelement <16 x i16> %r1, i16 %y, i32 9
  ret <16 x i16> %r2
}

define <8 x i16> @insert_v8i16(<8 x i16> %x, i16 %y, ptr %ptr) {
; CHECK-LABEL: insert_v8i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrw $1, (%rsi), %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc4,0x06,0x01]
; CHECK-NEXT:    vpinsrw $5, %edi, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc5,0xf9,0xc4,0xc7,0x05]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i16, ptr %ptr
  %r1 = insertelement <8 x i16> %x, i16 %val, i32 1
  %r2 = insertelement <8 x i16> %r1, i16 %y, i32 5
  ret <8 x i16> %r2
}

define <32 x i8> @insert_v32i8(<32 x i8> %x, i8 %y, ptr %ptr) {
; CHECK-LABEL: insert_v32i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrb $1, (%rsi), %xmm0, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x20,0x0e,0x01]
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc0,0x01]
; CHECK-NEXT:    vpinsrb $1, %edi, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x20,0xc7,0x01]
; CHECK-NEXT:    vinserti128 $1, %xmm0, %ymm1, %ymm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x75,0x38,0xc0,0x01]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i8, ptr %ptr
  %r1 = insertelement <32 x i8> %x, i8 %val, i32 1
  %r2 = insertelement <32 x i8> %r1, i8 %y, i32 17
  ret <32 x i8> %r2
}

define <16 x i8> @insert_v16i8(<16 x i8> %x, i8 %y, ptr %ptr) {
; CHECK-LABEL: insert_v16i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpinsrb $3, (%rsi), %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x20,0x06,0x03]
; CHECK-NEXT:    vpinsrb $10, %edi, %xmm0, %xmm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x79,0x20,0xc7,0x0a]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %val = load i8, ptr %ptr
  %r1 = insertelement <16 x i8> %x, i8 %val, i32 3
  %r2 = insertelement <16 x i8> %r1, i8 %y, i32 10
  ret <16 x i8> %r2
}

define <16 x i16> @test_insert_128_v16i16(<16 x i16> %x, i16 %y) {
; KNL-LABEL: test_insert_128_v16i16:
; KNL:       ## %bb.0:
; KNL-NEXT:    vmovd %edi, %xmm1
; KNL-NEXT:    vpbroadcastw %xmm1, %ymm1
; KNL-NEXT:    vpblendw {{.*#+}} ymm1 = ymm0[0,1],ymm1[2],ymm0[3,4,5,6,7,8,9],ymm1[10],ymm0[11,12,13,14,15]
; KNL-NEXT:    vpblendd {{.*#+}} ymm0 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; KNL-NEXT:    retq
;
; CHECK-LABEL: test_insert_128_v16i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpbroadcastw %edi, %ymm1 ## encoding: [0x62,0xf2,0x7d,0x28,0x7b,0xcf]
; CHECK-NEXT:    vpblendw $4, %ymm1, %ymm0, %ymm1 ## encoding: [0xc4,0xe3,0x7d,0x0e,0xc9,0x04]
; CHECK-NEXT:    ## ymm1 = ymm0[0,1],ymm1[2],ymm0[3,4,5,6,7,8,9],ymm1[10],ymm0[11,12,13,14,15]
; CHECK-NEXT:    vpblendd $240, %ymm1, %ymm0, %ymm0 ## encoding: [0xc4,0xe3,0x7d,0x02,0xc1,0xf0]
; CHECK-NEXT:    ## ymm0 = ymm0[0,1,2,3],ymm1[4,5,6,7]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r = insertelement <16 x i16> %x, i16 %y, i32 10
  ret <16 x i16> %r
}

define <32 x i8> @test_insert_128_v32i8(<32 x i8> %x, i8 %y) {
; CHECK-LABEL: test_insert_128_v32i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vextracti128 $1, %ymm0, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x39,0xc1,0x01]
; CHECK-NEXT:    vpinsrb $4, %edi, %xmm1, %xmm1 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x71,0x20,0xcf,0x04]
; CHECK-NEXT:    vinserti128 $1, %xmm1, %ymm0, %ymm0 ## EVEX TO VEX Compression encoding: [0xc4,0xe3,0x7d,0x38,0xc1,0x01]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %r = insertelement <32 x i8> %x, i8 %y, i32 20
  ret <32 x i8> %r
}

define i64 @test_extractelement_variable_v2i64(<2 x i64> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v2i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x44,0x24,0xe8]
; CHECK-NEXT:    andl $1, %edi ## encoding: [0x83,0xe7,0x01]
; CHECK-NEXT:    movq -24(%rsp,%rdi,8), %rax ## encoding: [0x48,0x8b,0x44,0xfc,0xe8]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <2 x i64> %t1, i32 %index
  ret i64 %t2
}

define i64 @test_extractelement_variable_v4i64(<4 x i64> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v4i64:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    pushq %rbp ## encoding: [0x55]
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movq %rsp, %rbp ## encoding: [0x48,0x89,0xe5]
; CHECK-NEXT:    .cfi_def_cfa_register %rbp
; CHECK-NEXT:    andq $-32, %rsp ## encoding: [0x48,0x83,0xe4,0xe0]
; CHECK-NEXT:    subq $64, %rsp ## encoding: [0x48,0x83,0xec,0x40]
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %ymm0, (%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xfc,0x29,0x04,0x24]
; CHECK-NEXT:    andl $3, %edi ## encoding: [0x83,0xe7,0x03]
; CHECK-NEXT:    movq (%rsp,%rdi,8), %rax ## encoding: [0x48,0x8b,0x04,0xfc]
; CHECK-NEXT:    movq %rbp, %rsp ## encoding: [0x48,0x89,0xec]
; CHECK-NEXT:    popq %rbp ## encoding: [0x5d]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <4 x i64> %t1, i32 %index
  ret i64 %t2
}

define i32 @test_extractelement_variable_v4i32(<4 x i32> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v4i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x44,0x24,0xe8]
; CHECK-NEXT:    andl $3, %edi ## encoding: [0x83,0xe7,0x03]
; CHECK-NEXT:    movl -24(%rsp,%rdi,4), %eax ## encoding: [0x8b,0x44,0xbc,0xe8]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <4 x i32> %t1, i32 %index
  ret i32 %t2
}

define i32 @test_extractelement_variable_v8i32(<8 x i32> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v8i32:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    pushq %rbp ## encoding: [0x55]
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movq %rsp, %rbp ## encoding: [0x48,0x89,0xe5]
; CHECK-NEXT:    .cfi_def_cfa_register %rbp
; CHECK-NEXT:    andq $-32, %rsp ## encoding: [0x48,0x83,0xe4,0xe0]
; CHECK-NEXT:    subq $64, %rsp ## encoding: [0x48,0x83,0xec,0x40]
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %ymm0, (%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xfc,0x29,0x04,0x24]
; CHECK-NEXT:    andl $7, %edi ## encoding: [0x83,0xe7,0x07]
; CHECK-NEXT:    movl (%rsp,%rdi,4), %eax ## encoding: [0x8b,0x04,0xbc]
; CHECK-NEXT:    movq %rbp, %rsp ## encoding: [0x48,0x89,0xec]
; CHECK-NEXT:    popq %rbp ## encoding: [0x5d]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <8 x i32> %t1, i32 %index
  ret i32 %t2
}

define i16 @test_extractelement_variable_v8i16(<8 x i16> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v8i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x44,0x24,0xe8]
; CHECK-NEXT:    andl $7, %edi ## encoding: [0x83,0xe7,0x07]
; CHECK-NEXT:    movzwl -24(%rsp,%rdi,2), %eax ## encoding: [0x0f,0xb7,0x44,0x7c,0xe8]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <8 x i16> %t1, i32 %index
  ret i16 %t2
}

define i16 @test_extractelement_variable_v16i16(<16 x i16> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v16i16:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    pushq %rbp ## encoding: [0x55]
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movq %rsp, %rbp ## encoding: [0x48,0x89,0xe5]
; CHECK-NEXT:    .cfi_def_cfa_register %rbp
; CHECK-NEXT:    andq $-32, %rsp ## encoding: [0x48,0x83,0xe4,0xe0]
; CHECK-NEXT:    subq $64, %rsp ## encoding: [0x48,0x83,0xec,0x40]
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %ymm0, (%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xfc,0x29,0x04,0x24]
; CHECK-NEXT:    andl $15, %edi ## encoding: [0x83,0xe7,0x0f]
; CHECK-NEXT:    movzwl (%rsp,%rdi,2), %eax ## encoding: [0x0f,0xb7,0x04,0x7c]
; CHECK-NEXT:    movq %rbp, %rsp ## encoding: [0x48,0x89,0xec]
; CHECK-NEXT:    popq %rbp ## encoding: [0x5d]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <16 x i16> %t1, i32 %index
  ret i16 %t2
}

define i8 @test_extractelement_variable_v16i8(<16 x i8> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v16i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %xmm0, -{{[0-9]+}}(%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xf8,0x29,0x44,0x24,0xe8]
; CHECK-NEXT:    andl $15, %edi ## encoding: [0x83,0xe7,0x0f]
; CHECK-NEXT:    movzbl -24(%rsp,%rdi), %eax ## encoding: [0x0f,0xb6,0x44,0x3c,0xe8]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t2 = extractelement <16 x i8> %t1, i32 %index
  ret i8 %t2
}

define i8 @test_extractelement_variable_v32i8(<32 x i8> %t1, i32 %index) {
; CHECK-LABEL: test_extractelement_variable_v32i8:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    pushq %rbp ## encoding: [0x55]
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    .cfi_offset %rbp, -16
; CHECK-NEXT:    movq %rsp, %rbp ## encoding: [0x48,0x89,0xe5]
; CHECK-NEXT:    .cfi_def_cfa_register %rbp
; CHECK-NEXT:    andq $-32, %rsp ## encoding: [0x48,0x83,0xe4,0xe0]
; CHECK-NEXT:    subq $64, %rsp ## encoding: [0x48,0x83,0xec,0x40]
; CHECK-NEXT:    ## kill: def $edi killed $edi def $rdi
; CHECK-NEXT:    vmovaps %ymm0, (%rsp) ## EVEX TO VEX Compression encoding: [0xc5,0xfc,0x29,0x04,0x24]
; CHECK-NEXT:    andl $31, %edi ## encoding: [0x83,0xe7,0x1f]
; CHECK-NEXT:    movzbl (%rsp,%rdi), %eax ## encoding: [0x0f,0xb6,0x04,0x3c]
; CHECK-NEXT:    movq %rbp, %rsp ## encoding: [0x48,0x89,0xec]
; CHECK-NEXT:    popq %rbp ## encoding: [0x5d]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]

  %t2 = extractelement <32 x i8> %t1, i32 %index
  ret i8 %t2
}

define zeroext i8 @test_extractelement_varible_v32i1(<32 x i8> %a, <32 x i8> %b, i32 %index) {
; KNL-LABEL: test_extractelement_varible_v32i1:
; KNL:       ## %bb.0:
; KNL-NEXT:    vpminub %ymm1, %ymm0, %ymm1
; KNL-NEXT:    vpcmpeqb %ymm1, %ymm0, %ymm0
; KNL-NEXT:    vpmovmskb %ymm0, %ecx
; KNL-NEXT:    xorl %eax, %eax
; KNL-NEXT:    btl %edi, %ecx
; KNL-NEXT:    setae %al
; KNL-NEXT:    vzeroupper
; KNL-NEXT:    retq
;
; CHECK-LABEL: test_extractelement_varible_v32i1:
; CHECK:       ## %bb.0:
; CHECK-NEXT:    vpcmpnleub %ymm1, %ymm0, %k0 ## encoding: [0x62,0xf3,0x7d,0x28,0x3e,0xc1,0x06]
; CHECK-NEXT:    vpmovm2b %k0, %ymm0 ## encoding: [0x62,0xf2,0x7e,0x28,0x28,0xc0]
; CHECK-NEXT:    vpmovmskb %ymm0, %ecx ## encoding: [0xc5,0xfd,0xd7,0xc8]
; CHECK-NEXT:    xorl %eax, %eax ## encoding: [0x31,0xc0]
; CHECK-NEXT:    btl %edi, %ecx ## encoding: [0x0f,0xa3,0xf9]
; CHECK-NEXT:    setb %al ## encoding: [0x0f,0x92,0xc0]
; CHECK-NEXT:    vzeroupper ## encoding: [0xc5,0xf8,0x77]
; CHECK-NEXT:    retq ## encoding: [0xc3]
  %t1 = icmp ugt <32 x i8> %a, %b
  %t2 = extractelement <32 x i1> %t1, i32 %index
  %res = zext i1 %t2 to i8
  ret i8 %res
}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; SKX: {{.*}}
