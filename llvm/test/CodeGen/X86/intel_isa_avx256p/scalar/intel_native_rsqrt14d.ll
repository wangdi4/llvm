; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_avx256p
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx256p --show-mc-encoding | FileCheck %s

define double @test_native_rsqrt14_sd_recip(double %data) #0 {
; CHECK-LABEL: test_native_rsqrt14_sd_recip:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm0 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %sqrt = tail call double @llvm.sqrt.f64(double %data)
  %div = fdiv fast double 1.0, %sqrt
  ret double %div
}

define double @test_native_rsqrt14_sd_imf_acc_bt14(double %data) #1 {
; CHECK-LABEL: test_native_rsqrt14_sd_imf_acc_bt14:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm0 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
  %sqrt = tail call double @llvm.sqrt.f64(double %data)
  %div = fdiv fast double 1.0, %sqrt
  ret double %div
}

define double @test_native_rsqrt14_sd_imf_acc_bt26(double %data) #2 {
; CHECK-LABEL: test_native_rsqrt14_sd_imf_acc_bt26:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm1 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc8]
; CHECK-NEXT:    vmulsd %xmm1, %xmm0, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xfb,0x59,0xd1]
; CHECK-NEXT:    vmovsd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm3 # EVEX TO VEX Compression encoding: [0xc5,0xfb,0x10,0x1d,A,A,A,A]
; CHECK-NEXT:    # fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}-4, kind: reloc_riprel_4byte
; CHECK-NEXT:    # xmm3 = mem[0],zero
; CHECK-NEXT:    vmulsd %xmm3, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf3,0x59,0xc3]
; CHECK-NEXT:    vfnmadd213sd %xmm3, %xmm2, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xe9,0xad,0xc3]
; CHECK-NEXT:    # xmm0 = -(xmm2 * xmm0) + xmm3
; CHECK-NEXT:    vfmadd132sd %xmm1, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf1,0x99,0xc1]
; CHECK-NEXT:    # xmm0 = (xmm0 * xmm1) + xmm1
; CHECK-NEXT:    retq # encoding: [0xc3]
  %sqrt = tail call double @llvm.sqrt.f64(double %data)
  %div = fdiv fast double 1.0, %sqrt
  ret double %div
}

define double @test_native_div_sqrt14_sd(double %a, double %b) #0 {
; CHECK-LABEL: test_native_div_sqrt14_sd:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdivsd %xmm0, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf3,0x5e,0xc0]
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm0 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
    %div = fdiv fast double %a, %b
    %sqrt = tail call fast double @llvm.sqrt.f64(double %div)
    ret double %sqrt
  }

define double @test_native_div_sqrt14_sd_acc_bit14(double %a, double %b) #1 {
; CHECK-LABEL: test_native_div_sqrt14_sd_acc_bit14:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdivsd %xmm0, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf3,0x5e,0xc0]
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm0 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc0]
; CHECK-NEXT:    retq # encoding: [0xc3]
    %div = fdiv fast double %a, %b
    %sqrt = tail call fast double @llvm.sqrt.f64(double %div)
    ret double %sqrt
  }

define double @test_native_div_sqrt14_sd_acc_bit26(double %a, double %b) #2 {
; CHECK-LABEL: test_native_div_sqrt14_sd_acc_bit26:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vdivsd %xmm0, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf3,0x5e,0xc0]
; CHECK-NEXT:    vrsqrt14sd %xmm0, %xmm0, %xmm1 # encoding: [0x62,0xf2,0xfd,0x08,0x4f,0xc8]
; CHECK-NEXT:    vmulsd %xmm1, %xmm0, %xmm2 # EVEX TO VEX Compression encoding: [0xc5,0xfb,0x59,0xd1]
; CHECK-NEXT:    vmovsd {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm3 # EVEX TO VEX Compression encoding: [0xc5,0xfb,0x10,0x1d,A,A,A,A]
; CHECK-NEXT:    # fixup A - offset: 4, value: {{\.?LCPI[0-9]+_[0-9]+}}-4, kind: reloc_riprel_4byte
; CHECK-NEXT:    # xmm3 = mem[0],zero
; CHECK-NEXT:    vmulsd %xmm3, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc5,0xf3,0x59,0xc3]
; CHECK-NEXT:    vfnmadd213sd %xmm3, %xmm2, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xe9,0xad,0xc3]
; CHECK-NEXT:    # xmm0 = -(xmm2 * xmm0) + xmm3
; CHECK-NEXT:    vfmadd132sd %xmm1, %xmm1, %xmm0 # EVEX TO VEX Compression encoding: [0xc4,0xe2,0xf1,0x99,0xc1]
; CHECK-NEXT:    # xmm0 = (xmm0 * xmm1) + xmm1
; CHECK-NEXT:    retq # encoding: [0xc3]
    %div = fdiv fast double %a, %b
    %sqrt = tail call fast double @llvm.sqrt.f64(double %div)
    ret double %sqrt
  }
declare double @llvm.sqrt.f64(double)

attributes #0 = { "reciprocal-estimates"="sqrtd:0,vec-sqrtd:0" }
attributes #1 = { "imf-accuracy-bits-sqrt"="14" }
attributes #2 = { "imf-accuracy-bits-sqrt"="26.0" }
