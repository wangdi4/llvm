; INTEL_FEATURE_ISA_BF16_BASE
; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_bf16_base
; TODO: Add SSE2 tests when vector emulation bfloat on SSE2 is supported.
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16,+avx512vl | FileCheck %s --check-prefix=AVX512FP16-X64
; RUN: llc < %s -mtriple=i686-unknown-unknown -mattr=+avx512fp16,+avx512vl | FileCheck %s --check-prefix=AVX512FP16-X86

define <8 x bfloat> @broadcastph128(bfloat* %x) {
; AVX512FP16-X64-LABEL: broadcastph128:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph128:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpbroadcastw (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %l1 = load bfloat, bfloat* %x, align 2
  %vec = insertelement <8 x bfloat> undef, bfloat %l1, i32 0
  %res = shufflevector <8 x bfloat> %vec, <8 x bfloat> undef, <8 x i32> zeroinitializer
  ret <8 x bfloat> %res
}

define <16 x bfloat> @broadcastph256(bfloat* %x) {
; AVX512FP16-X64-LABEL: broadcastph256:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw (%rdi), %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph256:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpbroadcastw (%eax), %ymm0
; AVX512FP16-X86-NEXT:    retl
  %l1 = load bfloat, bfloat* %x, align 2
  %vec = insertelement <16 x bfloat> undef, bfloat %l1, i32 0
  %res = shufflevector <16 x bfloat> %vec, <16 x bfloat> undef, <16 x i32> zeroinitializer
  ret <16 x bfloat> %res
}

define <32 x bfloat> @broadcastph512(bfloat* %x) {
; AVX512FP16-X64-LABEL: broadcastph512:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw (%rdi), %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph512:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpbroadcastw (%eax), %zmm0
; AVX512FP16-X86-NEXT:    retl
  %l1 = load bfloat, bfloat* %x, align 2
  %vec = insertelement <32 x bfloat> undef, bfloat %l1, i32 0
  %res = shufflevector <32 x bfloat> %vec, <32 x bfloat> undef, <32 x i32> zeroinitializer
  ret <32 x bfloat> %res
}

define <8 x bfloat> @broadcastph128_scalar(bfloat %x) {
; AVX512FP16-X64-LABEL: broadcastph128_scalar:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph128_scalar:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %vec = insertelement <8 x bfloat> undef, bfloat %x, i32 0
  %res = shufflevector <8 x bfloat> %vec, <8 x bfloat> undef, <8 x i32> zeroinitializer
  ret <8 x bfloat> %res
}

define <16 x bfloat> @broadcastph256_scalar(bfloat %x) {
; AVX512FP16-X64-LABEL: broadcastph256_scalar:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph256_scalar:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %ymm0
; AVX512FP16-X86-NEXT:    retl
  %vec = insertelement <16 x bfloat> undef, bfloat %x, i32 0
  %res = shufflevector <16 x bfloat> %vec, <16 x bfloat> undef, <16 x i32> zeroinitializer
  ret <16 x bfloat> %res
}

define <32 x bfloat> @broadcastph512_scalar(bfloat %x) {
; AVX512FP16-X64-LABEL: broadcastph512_scalar:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph512_scalar:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %zmm0
; AVX512FP16-X86-NEXT:    retl
  %vec = insertelement <32 x bfloat> undef, bfloat %x, i32 0
  %res = shufflevector <32 x bfloat> %vec, <32 x bfloat> undef, <32 x i32> zeroinitializer
  ret <32 x bfloat> %res
}

define <8 x bfloat> @broadcastph128_reg(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: broadcastph128_reg:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph128_reg:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    retl
  %res = shufflevector <8 x bfloat> %x, <8 x bfloat> undef, <8 x i32> zeroinitializer
  ret <8 x bfloat> %res
}

define <16 x bfloat> @broadcastph256_reg(<16 x bfloat> %x) {
; AVX512FP16-X64-LABEL: broadcastph256_reg:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph256_reg:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw %xmm0, %ymm0
; AVX512FP16-X86-NEXT:    retl
  %res = shufflevector <16 x bfloat> %x, <16 x bfloat> undef, <16 x i32> zeroinitializer
  ret <16 x bfloat> %res
}

define <32 x bfloat> @broadcastph512_reg(<32 x bfloat> %x) {
; AVX512FP16-X64-LABEL: broadcastph512_reg:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: broadcastph512_reg:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpbroadcastw %xmm0, %zmm0
; AVX512FP16-X86-NEXT:    retl
  %res = shufflevector <32 x bfloat> %x, <32 x bfloat> undef, <32 x i32> zeroinitializer
  ret <32 x bfloat> %res
}

define <8 x bfloat> @test11(bfloat* %x) {
; AVX512FP16-X64-LABEL: test11:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test11:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %y = load bfloat, bfloat* %x, align 2
   %res = insertelement <8 x bfloat>zeroinitializer, bfloat %y, i32 0
   ret <8 x bfloat>%res
}

define <16 x bfloat> @test11b(bfloat* %x) {
; AVX512FP16-X64-LABEL: test11b:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test11b:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %y = load bfloat, bfloat* %x, align 2
   %res = insertelement <16 x bfloat>zeroinitializer, bfloat %y, i32 0
   ret <16 x bfloat>%res
}

define <32 x bfloat> @test11c(bfloat* %x) {
; AVX512FP16-X64-LABEL: test11c:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test11c:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %y = load bfloat, bfloat* %x, align 2
   %res = insertelement <32 x bfloat>zeroinitializer, bfloat %y, i32 0
   ret <32 x bfloat>%res
}

define <8 x bfloat> @test14(bfloat %x) {
; AVX512FP16-X64-LABEL: test14:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, %xmm1, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test14:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %res = insertelement <8 x bfloat>zeroinitializer, bfloat %x, i32 0
   ret <8 x bfloat>%res
}

define <16 x bfloat> @test14b(bfloat %x) {
; AVX512FP16-X64-LABEL: test14b:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, %xmm1, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test14b:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %res = insertelement <16 x bfloat>zeroinitializer, bfloat %x, i32 0
   ret <16 x bfloat>%res
}

define <32 x bfloat> @test14c(bfloat %x) {
; AVX512FP16-X64-LABEL: test14c:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vxorps %xmm1, %xmm1, %xmm1
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, %xmm1, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: test14c:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    retl
   %res = insertelement <32 x bfloat>zeroinitializer, bfloat %x, i32 0
   ret <32 x bfloat>%res
}

@g8bf16 = external global <8 x bfloat>
@g8bf16u = external global <8 x bfloat>, align 8
@g16bf16 = external global <16 x bfloat>
@g16bf16u = external global <16 x bfloat>, align 8
@g32bf16 = external global <32 x bfloat>
@g32bf16u = external global <32 x bfloat>, align 8

define <32 x bfloat> @load32bf16(<32 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: load32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps (%rdi), %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovaps (%eax), %zmm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <32 x bfloat>, <32 x bfloat>* %a
  ret <32 x bfloat> %res
}

define <32 x bfloat> @load32bf16mask(<32 x bfloat>* %a, <32 x bfloat> %b, i32 %c) {
; AVX512FP16-X64-LABEL: load32bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load32bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %zmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x bfloat>, <32 x bfloat>* %a
  %res = select <32 x i1> %msk, <32 x bfloat> %res0, <32 x bfloat> %b
  ret <32 x bfloat> %res
}

define <32 x bfloat> @load32bf16maskz(<32 x bfloat>* %a, i32 %c) {
; AVX512FP16-X64-LABEL: load32bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load32bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %zmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x bfloat>, <32 x bfloat>* %a
  %res = select <32 x i1> %msk, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  ret <32 x bfloat> %res
}

define <32 x bfloat> @loadu32bf16(<32 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: loadu32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovups (%rdi), %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovups (%eax), %zmm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <32 x bfloat>, <32 x bfloat>* %a, align 8
  ret <32 x bfloat> %res
}

define <32 x bfloat> @loadu32bf16mask(<32 x bfloat>* %a, <32 x bfloat> %b, i32 %c) {
; AVX512FP16-X64-LABEL: loadu32bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu32bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %zmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x bfloat>, <32 x bfloat>* %a, align 8
  %res = select <32 x i1> %msk, <32 x bfloat> %res0, <32 x bfloat> %b
  ret <32 x bfloat> %res
}

define <32 x bfloat> @loadu32bf16maskz(<32 x bfloat>* %a, i32 %c) {
; AVX512FP16-X64-LABEL: loadu32bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu32bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %zmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x bfloat>, <32 x bfloat>* %a, align 8
  %res = select <32 x i1> %msk, <32 x bfloat> %res0, <32 x bfloat> zeroinitializer
  ret <32 x bfloat> %res
}

define void @store32bf16(<32 x bfloat> %a) {
; AVX512FP16-X64-LABEL: store32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g32bf16@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovaps %zmm0, (%rax)
; AVX512FP16-X64-NEXT:    vzeroupper
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: store32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %zmm0, g32bf16
; AVX512FP16-X86-NEXT:    vzeroupper
; AVX512FP16-X86-NEXT:    retl
  store <32 x bfloat> %a, <32 x bfloat>* @g32bf16
  ret void
}

define void @storeu32bf16(<32 x bfloat> %a) {
; AVX512FP16-X64-LABEL: storeu32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g32bf16u@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovups %zmm0, (%rax)
; AVX512FP16-X64-NEXT:    vzeroupper
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: storeu32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovups %zmm0, g32bf16u
; AVX512FP16-X86-NEXT:    vzeroupper
; AVX512FP16-X86-NEXT:    retl
  store <32 x bfloat> %a, <32 x bfloat>* @g32bf16u, align 8
  ret void
}

define <32 x bfloat> @movrr32bf16(<32 x bfloat> %a, <32 x bfloat> %b) {
; AVX512FP16-X64-LABEL: movrr32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps %zmm1, %zmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrr32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %zmm1, %zmm0
; AVX512FP16-X86-NEXT:    retl
  ret <32 x bfloat> %b
}

define <32 x bfloat> @movrrk32bf16(<32 x bfloat> %a, <32 x bfloat> %b, i32 %msk) {
; AVX512FP16-X64-LABEL: movrrk32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vpblendmw %zmm0, %zmm1, %zmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrk32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vpblendmw %zmm0, %zmm1, %zmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i32 %msk to <32 x i1>
  %res = select <32 x i1> %mask, <32 x bfloat> %a, <32 x bfloat> %b
  ret <32 x bfloat> %res
}

define <32 x bfloat> @movrrkz32bf16(<32 x bfloat> %a, i32 %msk) {
; AVX512FP16-X64-LABEL: movrrkz32bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 %zmm0, %zmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrkz32bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovd {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 %zmm0, %zmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i32 %msk to <32 x i1>
  %res = select <32 x i1> %mask, <32 x bfloat> %a, <32 x bfloat> zeroinitializer
  ret <32 x bfloat> %res
}

define <16 x bfloat> @load16bf16(<16 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: load16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps (%rdi), %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovaps (%eax), %ymm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <16 x bfloat>, <16 x bfloat>* %a
  ret <16 x bfloat> %res
}

define <16 x bfloat> @load16bf16mask(<16 x bfloat>* %a, <16 x bfloat> %b, i16 %c) {
; AVX512FP16-X64-LABEL: load16bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load16bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %ymm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x bfloat>, <16 x bfloat>* %a
  %res = select <16 x i1> %msk, <16 x bfloat> %res0, <16 x bfloat> %b
  ret <16 x bfloat> %res
}

define <16 x bfloat> @load16bf16maskz(<16 x bfloat>* %a, i16 %c) {
; AVX512FP16-X64-LABEL: load16bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load16bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %ymm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x bfloat>, <16 x bfloat>* %a
  %res = select <16 x i1> %msk, <16 x bfloat> %res0, <16 x bfloat> zeroinitializer
  ret <16 x bfloat> %res
}

define <16 x bfloat> @loadu16bf16(<16 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: loadu16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovups (%rdi), %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovups (%eax), %ymm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <16 x bfloat>, <16 x bfloat>* %a, align 8
  ret <16 x bfloat> %res
}

define <16 x bfloat> @loadu16bf16mask(<16 x bfloat>* %a, <16 x bfloat> %b, i16 %c) {
; AVX512FP16-X64-LABEL: loadu16bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu16bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %ymm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x bfloat>, <16 x bfloat>* %a, align 8
  %res = select <16 x i1> %msk, <16 x bfloat> %res0, <16 x bfloat> %b
  ret <16 x bfloat> %res
}

define <16 x bfloat> @loadu16bf16maskz(<16 x bfloat>* %a, i16 %c) {
; AVX512FP16-X64-LABEL: loadu16bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu16bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %ymm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x bfloat>, <16 x bfloat>* %a, align 8
  %res = select <16 x i1> %msk, <16 x bfloat> %res0, <16 x bfloat> zeroinitializer
  ret <16 x bfloat> %res
}

define void @store16bf16(<16 x bfloat> %a) {
; AVX512FP16-X64-LABEL: store16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g16bf16@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovaps %ymm0, (%rax)
; AVX512FP16-X64-NEXT:    vzeroupper
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: store16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %ymm0, g16bf16
; AVX512FP16-X86-NEXT:    vzeroupper
; AVX512FP16-X86-NEXT:    retl
  store <16 x bfloat> %a, <16 x bfloat>* @g16bf16
  ret void
}

define void @storeu16bf16(<16 x bfloat> %a) {
; AVX512FP16-X64-LABEL: storeu16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g16bf16u@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovups %ymm0, (%rax)
; AVX512FP16-X64-NEXT:    vzeroupper
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: storeu16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovups %ymm0, g16bf16u
; AVX512FP16-X86-NEXT:    vzeroupper
; AVX512FP16-X86-NEXT:    retl
  store <16 x bfloat> %a, <16 x bfloat>* @g16bf16u, align 8
  ret void
}

define <16 x bfloat> @movrr16bf16(<16 x bfloat> %a, <16 x bfloat> %b) {
; AVX512FP16-X64-LABEL: movrr16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps %ymm1, %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrr16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %ymm1, %ymm0
; AVX512FP16-X86-NEXT:    retl
  ret <16 x bfloat> %b
}

define <16 x bfloat> @movrrk16bf16(<16 x bfloat> %a, <16 x bfloat> %b, i16 %msk) {
; AVX512FP16-X64-LABEL: movrrk16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vpblendmw %ymm0, %ymm1, %ymm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrk16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vpblendmw %ymm0, %ymm1, %ymm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i16 %msk to <16 x i1>
  %res = select <16 x i1> %mask, <16 x bfloat> %a, <16 x bfloat> %b
  ret <16 x bfloat> %res
}

define <16 x bfloat> @movrrkz16bf16(<16 x bfloat> %a, i16 %msk) {
; AVX512FP16-X64-LABEL: movrrkz16bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 %ymm0, %ymm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrkz16bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovw {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 %ymm0, %ymm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i16 %msk to <16 x i1>
  %res = select <16 x i1> %mask, <16 x bfloat> %a, <16 x bfloat> zeroinitializer
  ret <16 x bfloat> %res
}

define <8 x bfloat> @load8bf16(<8 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: load8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovaps (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <8 x bfloat>, <8 x bfloat>* %a
  ret <8 x bfloat> %res
}

define <8 x bfloat> @load8bf16mask(<8 x bfloat>* %a, <8 x bfloat> %b, i8 %c) {
; AVX512FP16-X64-LABEL: load8bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load8bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x bfloat>, <8 x bfloat>* %a
  %res = select <8 x i1> %msk, <8 x bfloat> %res0, <8 x bfloat> %b
  ret <8 x bfloat> %res
}

define <8 x bfloat> @load8bf16maskz(<8 x bfloat>* %a, i8 %c) {
; AVX512FP16-X64-LABEL: load8bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: load8bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x bfloat>, <8 x bfloat>* %a
  %res = select <8 x i1> %msk, <8 x bfloat> %res0, <8 x bfloat> zeroinitializer
  ret <8 x bfloat> %res
}

define <8 x bfloat> @loadu8bf16(<8 x bfloat>* %a) {
; AVX512FP16-X64-LABEL: loadu8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovups (%rdi), %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovups (%eax), %xmm0
; AVX512FP16-X86-NEXT:    retl
  %res = load <8 x bfloat>, <8 x bfloat>* %a, align 8
  ret <8 x bfloat> %res
}

define <8 x bfloat> @loadu8bf16mask(<8 x bfloat>* %a, <8 x bfloat> %b, i8 %c) {
; AVX512FP16-X64-LABEL: loadu8bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu8bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x bfloat>, <8 x bfloat>* %a, align 8
  %res = select <8 x i1> %msk, <8 x bfloat> %res0, <8 x bfloat> %b
  ret <8 x bfloat> %res
}

define <8 x bfloat> @loadu8bf16maskz(<8 x bfloat>* %a, i8 %c) {
; AVX512FP16-X64-LABEL: loadu8bf16maskz:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %esi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: loadu8bf16maskz:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x bfloat>, <8 x bfloat>* %a, align 8
  %res = select <8 x i1> %msk, <8 x bfloat> %res0, <8 x bfloat> zeroinitializer
  ret <8 x bfloat> %res
}

define void @store8bf16(<8 x bfloat> %a) {
; AVX512FP16-X64-LABEL: store8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g8bf16@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovaps %xmm0, (%rax)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: store8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %xmm0, g8bf16
; AVX512FP16-X86-NEXT:    retl
  store <8 x bfloat> %a, <8 x bfloat>* @g8bf16
  ret void
}

define void @storeu8bf16(<8 x bfloat> %a) {
; AVX512FP16-X64-LABEL: storeu8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    movq g8bf16u@GOTPCREL(%rip), %rax
; AVX512FP16-X64-NEXT:    vmovups %xmm0, (%rax)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: storeu8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovups %xmm0, g8bf16u
; AVX512FP16-X86-NEXT:    retl
  store <8 x bfloat> %a, <8 x bfloat>* @g8bf16u, align 8
  ret void
}

define <8 x bfloat> @movrr8bf16(<8 x bfloat> %a, <8 x bfloat> %b) {
; AVX512FP16-X64-LABEL: movrr8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovaps %xmm1, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrr8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovaps %xmm1, %xmm0
; AVX512FP16-X86-NEXT:    retl
  ret <8 x bfloat> %b
}

define <8 x bfloat> @movrrk8bf16(<8 x bfloat> %a, <8 x bfloat> %b, i8 %msk) {
; AVX512FP16-X64-LABEL: movrrk8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vpblendmw %xmm0, %xmm1, %xmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrk8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vpblendmw %xmm0, %xmm1, %xmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i8 %msk to <8 x i1>
  %res = select <8 x i1> %mask, <8 x bfloat> %a, <8 x bfloat> %b
  ret <8 x bfloat> %res
}

define <8 x bfloat> @movrrkz8bf16(<8 x bfloat> %a, i8 %msk) {
; AVX512FP16-X64-LABEL: movrrkz8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    kmovd %edi, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 %xmm0, %xmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: movrrkz8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    kmovb {{[0-9]+}}(%esp), %k1
; AVX512FP16-X86-NEXT:    vmovdqu16 %xmm0, %xmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %mask = bitcast i8 %msk to <8 x i1>
  %res = select <8 x i1> %mask, <8 x bfloat> %a, <8 x bfloat> zeroinitializer
  ret <8 x bfloat> %res
}

define bfloat @extract_f16_0(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_0:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_0:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 0
   ret bfloat %res
}

define bfloat @extract_f16_1(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_1:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrld $16, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_1:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsrld $16, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 1
   ret bfloat %res
}

define bfloat @extract_f16_2(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_2:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_2:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 2
   ret bfloat %res
}

define bfloat @extract_f16_3(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_3:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrlq $48, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_3:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsrlq $48, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 3
   ret bfloat %res
}

define bfloat @extract_f16_4(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_4:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[2,3,0,1]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_4:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[2,3,0,1]
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 4
   ret bfloat %res
}

define bfloat @extract_f16_5(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_5:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_5:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 5
   ret bfloat %res
}

define bfloat @extract_f16_6(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_6:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_6:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 6
   ret bfloat %res
}

define bfloat @extract_f16_7(<8 x bfloat> %x) {
; AVX512FP16-X64-LABEL: extract_f16_7:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_f16_7:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 7
   ret bfloat %res
}

define void @extract_store_f16_0(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_0:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_0:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 0
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_1(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_1:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrld $16, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_1:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpsrld $16, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 1
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_2(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_2:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_2:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[1,1,3,3]
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 2
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_3(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_3:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrlq $48, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_3:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpsrlq $48, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 3
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_4(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_4:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[2,3,0,1]
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_4:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[2,3,0,1]
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 4
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_5(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_5:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_5:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[10,11,12,13,14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 5
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_6(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_6:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_6:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpermilps {{.*#+}} xmm0 = xmm0[3,3,3,3]
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 6
   store bfloat %res, bfloat* %y
   ret void
}

define void @extract_store_f16_7(<8 x bfloat> %x, bfloat* %y) {
; AVX512FP16-X64-LABEL: extract_store_f16_7:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X64-NEXT:    vmovsh %xmm0, (%rdi)
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: extract_store_f16_7:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vpsrldq {{.*#+}} xmm0 = xmm0[14,15],zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero,zero
; AVX512FP16-X86-NEXT:    vmovsh %xmm0, (%eax)
; AVX512FP16-X86-NEXT:    retl
   %res = extractelement <8 x bfloat> %x, i32 7
   store bfloat %res, bfloat* %y
   ret void
}

define <8 x bfloat> @build_vector_xxxxuuuu(bfloat %a0, bfloat %a1, bfloat %a2, bfloat %a3) {
; AVX512FP16-X64-LABEL: build_vector_xxxxuuuu:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpunpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],xmm2[0],xmm0[2,3]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm3, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3],xmm0[4,5,6,7]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: build_vector_xxxxuuuu:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm2
; AVX512FP16-X86-NEXT:    vpunpcklwd {{.*#+}} xmm1 = xmm1[0],xmm2[0],xmm1[1],xmm2[1],xmm1[2],xmm2[2],xmm1[3],xmm2[3]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[2,3]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3],xmm0[4,5,6,7]
; AVX512FP16-X86-NEXT:    retl
  %a = insertelement <8 x bfloat> undef, bfloat %a0, i32 0
  %b = insertelement <8 x bfloat> %a, bfloat %a1, i32 1
  %c = insertelement <8 x bfloat> %b, bfloat %a2, i32 2
  %d = insertelement <8 x bfloat> %c, bfloat %a3, i32 3
  ret <8 x bfloat> %d
}

define <8 x bfloat> @build_vector_uuuuxxxx(bfloat %a0, bfloat %a1, bfloat %a2, bfloat %a3) {
; AVX512FP16-X64-LABEL: build_vector_uuuuxxxx:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm1, %xmm1
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4],xmm1[5],xmm0[6,7]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],xmm2[0]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm3, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,5,6],xmm1[7]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: build_vector_uuuuxxxx:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm2
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm1 = xmm2[0,1,2,3,4],xmm1[5],xmm2[6,7]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],xmm0[0]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,5,6],xmm1[7]
; AVX512FP16-X86-NEXT:    retl
  %a = insertelement <8 x bfloat> undef, bfloat %a0, i32 4
  %b = insertelement <8 x bfloat> %a, bfloat %a1, i32 5
  %c = insertelement <8 x bfloat> %b, bfloat %a2, i32 6
  %d = insertelement <8 x bfloat> %c, bfloat %a3, i32 7
  ret <8 x bfloat> %d
}

define <8 x bfloat> @build_vector_xxxxxxxx(bfloat %a0, bfloat %a1, bfloat %a2, bfloat %a3, bfloat %a4, bfloat %a5, bfloat %a6, bfloat %a7) {
; AVX512FP16-X64-LABEL: build_vector_xxxxxxxx:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpunpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],xmm2[0],zero,zero
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm3, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3],xmm0[4,5,6,7]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1],xmm4[0],xmm0[3]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm5, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4],xmm1[5],xmm0[6,7]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0,1,2],xmm6[0]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm7, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,5,6],xmm1[7]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: build_vector_xxxxxxxx:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm2
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm3
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm4
; AVX512FP16-X86-NEXT:    vpunpcklwd {{.*#+}} xmm3 = xmm3[0],xmm4[0],xmm3[1],xmm4[1],xmm3[2],xmm4[2],xmm3[3],xmm4[3]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm2 = xmm3[0],xmm2[0],zero,zero
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm3
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm2 = xmm2[0,1,2],xmm3[3],xmm2[4,5,6,7]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm1 = xmm2[0,1],xmm1[0],xmm2[3]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm2
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm1 = xmm1[0,1,2,3,4],xmm2[5],xmm1[6,7]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0,1,2],xmm0[0]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2,3,4,5,6],xmm1[7]
; AVX512FP16-X86-NEXT:    retl
  %a = insertelement <8 x bfloat> undef, bfloat %a0, i32 0
  %b = insertelement <8 x bfloat> %a, bfloat %a1, i32 1
  %c = insertelement <8 x bfloat> %b, bfloat %a2, i32 2
  %d = insertelement <8 x bfloat> %c, bfloat %a3, i32 3
  %e = insertelement <8 x bfloat> %d, bfloat %a4, i32 4
  %f = insertelement <8 x bfloat> %e, bfloat %a5, i32 5
  %g = insertelement <8 x bfloat> %f, bfloat %a6, i32 6
  %h = insertelement <8 x bfloat> %g, bfloat %a7, i32 7
  ret <8 x bfloat> %h
}

define <16 x bfloat> @build_vector_xxxxuuuuuuuuxxxx(bfloat %a0, bfloat %a1, bfloat %a2, bfloat %a3, bfloat %a4, bfloat %a5, bfloat %a6, bfloat %a7) {
; AVX512FP16-X64-LABEL: build_vector_xxxxuuuuuuuuxxxx:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm5, %xmm5
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm4, %xmm4
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm4 = xmm4[0,1,2,3,4],xmm5[5],xmm4[6,7]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm4 = xmm4[0,1,2],xmm6[0]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm7, %xmm5
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm4 = xmm4[0,1,2,3,4,5,6],xmm5[7]
; AVX512FP16-X64-NEXT:    vpunpcklwd {{.*#+}} xmm0 = xmm0[0],xmm1[0],xmm0[1],xmm1[1],xmm0[2],xmm1[2],xmm0[3],xmm1[3]
; AVX512FP16-X64-NEXT:    vinsertps {{.*#+}} xmm0 = xmm0[0],xmm2[0],xmm0[2,3]
; AVX512FP16-X64-NEXT:    vpbroadcastw %xmm3, %xmm1
; AVX512FP16-X64-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3],xmm0[4,5,6,7]
; AVX512FP16-X64-NEXT:    vinserti128 $1, %xmm4, %ymm0, %ymm0
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: build_vector_xxxxuuuuuuuuxxxx:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm0
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm2
; AVX512FP16-X86-NEXT:    vmovsh {{[0-9]+}}(%esp), %xmm3
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm4
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm5
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm4 = xmm5[0,1,2,3,4],xmm4[5],xmm5[6,7]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm3 = xmm4[0,1,2],xmm3[0]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm4
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm3 = xmm3[0,1,2,3,4,5,6],xmm4[7]
; AVX512FP16-X86-NEXT:    vpunpcklwd {{.*#+}} xmm1 = xmm1[0],xmm2[0],xmm1[1],xmm2[1],xmm1[2],xmm2[2],xmm1[3],xmm2[3]
; AVX512FP16-X86-NEXT:    vinsertps {{.*#+}} xmm0 = xmm1[0],xmm0[0],xmm1[2,3]
; AVX512FP16-X86-NEXT:    vpbroadcastw {{[0-9]+}}(%esp), %xmm1
; AVX512FP16-X86-NEXT:    vpblendw {{.*#+}} xmm0 = xmm0[0,1,2],xmm1[3],xmm0[4,5,6,7]
; AVX512FP16-X86-NEXT:    vinserti128 $1, %xmm3, %ymm0, %ymm0
; AVX512FP16-X86-NEXT:    retl
  %a = insertelement <16 x bfloat> undef, bfloat %a0, i32 0
  %b = insertelement <16 x bfloat> %a, bfloat %a1, i32 1
  %c = insertelement <16 x bfloat> %b, bfloat %a2, i32 2
  %d = insertelement <16 x bfloat> %c, bfloat %a3, i32 3
  %e = insertelement <16 x bfloat> %d, bfloat %a4, i32 12
  %f = insertelement <16 x bfloat> %e, bfloat %a5, i32 13
  %g = insertelement <16 x bfloat> %f, bfloat %a6, i32 14
  %h = insertelement <16 x bfloat> %g, bfloat %a7, i32 15
  ret <16 x bfloat> %h
}

define <8 x bfloat> @regression1(<8 x bfloat> %a, <8 x bfloat> %b) {
; AVX512FP16-X64-LABEL: regression1:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpshufb {{.*#+}} xmm0 = xmm0[0,1,14,15,0,1,2,3,4,5,6,7,14,15,10,11]
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: regression1:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpshufb {{.*#+}} xmm0 = xmm0[0,1,14,15,0,1,2,3,4,5,6,7,14,15,10,11]
; AVX512FP16-X86-NEXT:    retl
  %res = shufflevector <8 x bfloat> %a, <8 x bfloat> %b, <8 x i32> <i32 0, i32 7, i32 0, i32 1, i32 2, i32 3, i32 7, i32 5>
  ret <8 x bfloat> %res
}

declare void @llvm.masked.store.v8bf16.p0v8bf16(<8 x bfloat>, <8 x bfloat>*, i32, <8 x i1>)
declare <8 x bfloat> @llvm.masked.load.v8bf16.p0v8bf16(<8 x bfloat>*, i32,  <8 x i1>, <8 x bfloat>)

define void @storeu8bf16mask(<8 x i1> %mask, <8 x bfloat>* %addr, <8 x bfloat> %val) {
; AVX512FP16-X64-LABEL: storeu8bf16mask:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 %xmm1, (%rdi) {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: storeu8bf16mask:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovdqu16 %xmm1, (%eax) {%k1}
; AVX512FP16-X86-NEXT:    retl
  call void @llvm.masked.store.v8bf16.p0v8bf16(<8 x bfloat> %val, <8 x bfloat>* %addr, i32 4, <8 x i1>%mask)
  ret void
}

define <8 x bfloat> @maskloadu8bf16(<8 x bfloat>* %addr, <8 x bfloat> %val, <8 x i1> %mask) {
; AVX512FP16-X64-LABEL: maskloadu8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsllw $15, %xmm1, %xmm1
; AVX512FP16-X64-NEXT:    vpmovw2m %xmm1, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: maskloadu8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsllw $15, %xmm1, %xmm1
; AVX512FP16-X86-NEXT:    vpmovw2m %xmm1, %k1
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1}
; AVX512FP16-X86-NEXT:    retl
  %res = call <8 x bfloat> @llvm.masked.load.v8bf16.p0v8bf16(<8 x bfloat>* %addr, i32 4, <8 x i1> %mask, <8 x bfloat> %val)
  ret <8 x bfloat> %res
}

define <8 x bfloat> @maskuloadu8bf16(<8 x bfloat>* %addr, <8 x i1> %mask) {
; AVX512FP16-X64-LABEL: maskuloadu8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: maskuloadu8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %res = call <8 x bfloat> @llvm.masked.load.v8bf16.p0v8bf16(<8 x bfloat>* %addr, i32 4, <8 x i1> %mask, <8 x bfloat> undef)
  ret <8 x bfloat> %res
}

define <8 x bfloat> @maskzloadu8bf16(<8 x bfloat>* %addr, <8 x i1> %mask) {
; AVX512FP16-X64-LABEL: maskzloadu8bf16:
; AVX512FP16-X64:       # %bb.0:
; AVX512FP16-X64-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X64-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X64-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; AVX512FP16-X64-NEXT:    retq
;
; AVX512FP16-X86-LABEL: maskzloadu8bf16:
; AVX512FP16-X86:       # %bb.0:
; AVX512FP16-X86-NEXT:    vpsllw $15, %xmm0, %xmm0
; AVX512FP16-X86-NEXT:    vpmovw2m %xmm0, %k1
; AVX512FP16-X86-NEXT:    movl {{[0-9]+}}(%esp), %eax
; AVX512FP16-X86-NEXT:    vmovdqu16 (%eax), %xmm0 {%k1} {z}
; AVX512FP16-X86-NEXT:    retl
  %res = call <8 x bfloat> @llvm.masked.load.v8bf16.p0v8bf16(<8 x bfloat>* %addr, i32 4, <8 x i1> %mask, <8 x bfloat> zeroinitializer)
  ret <8 x bfloat> %res
}

; end INTEL_FEATURE_ISA_BF16_BASE
