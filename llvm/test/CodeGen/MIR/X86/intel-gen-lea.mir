# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -march=x86-64 -run-pass x86-generate-lea-opt -o - %s | FileCheck %s

--- |
  target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
  target triple = "x86_64-unknown-linux-gnu"

  @block_ = internal global [9 x [9 x [9 x i32]]] zeroinitializer, align 8

  ; Function Attrs: nounwind
  define internal fastcc void @lea_opt(i64 %in) unnamed_addr #0 {
    %base_addr = getelementptr i8, i8* bitcast ([9 x [9 x [9 x i32]]]* @block_ to i8*), i64 %in
    %addr_0 = getelementptr i8, i8* %base_addr, i64 2412
    %val_0 = bitcast i8* %addr_0 to i32*
    store i32 10, i32* %val_0, align 4
    %addr_1 = getelementptr i8, i8* %base_addr, i64 12
    %val_1 = bitcast i8* %addr_1 to i32*
    store i32 10, i32* %val_1, align 4
    %addr_2 = getelementptr i8, i8* %base_addr, i64 2012
    %val_2 = bitcast i8* %addr_2 to i32*
    store i32 10, i32* %val_2, align 4
    %addr_3 = getelementptr i8, i8* %base_addr, i64 2062
    %val_3 = bitcast i8* %addr_3 to i32*
    store i32 10, i32* %val_3, align 4
    %addr_4 = getelementptr i8, i8* %base_addr, i64 2212
    %val_4 = bitcast i8* %addr_4 to i32*
    store i32 10, i32* %val_4, align 4
    ret void
  }

  attributes #0 = { nounwind "contains-rec-pro-clone" "target-cpu"="skylake-avx512" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="true" }

...
---
name:            lea_opt
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: gr64 }
liveins:
  - { reg: '$rdi', virtual-reg: '%0' }
machineFunctionInfo: {}
body:             |
  bb.0 (%ir-block.0):
    liveins: $rdi
    ; CHECK-LABEL: name: lea_opt
    ; CHECK: liveins: $rdi
    ; CHECK: [[COPY:%[0-9]+]]:gr64 = COPY $rdi
    ; CHECK: [[LEA64r:%[0-9]+]]:gr64 = LEA64r [[COPY]], 1, $noreg, @block_ + 2412, $noreg
    ; CHECK: MOV32mi [[LEA64r]], 1, $noreg, 0, $noreg, 10 :: (store 4 into %ir.val_0)
    ; CHECK: [[LEA64r1:%[0-9]+]]:gr64 = LEA64r [[COPY]], 1, $noreg, @block_ + 12, $noreg
    ; CHECK: MOV32mi [[LEA64r1]], 1, $noreg, 0, $noreg, 10 :: (store 4 into %ir.val_1)
    ; CHECK: [[LEA64r2:%[0-9]+]]:gr64 = LEA64r [[COPY]], 1, $noreg, @block_ + 2012, $noreg
    ; CHECK: MOV32mi [[LEA64r2]], 1, $noreg, 0, $noreg, 10 :: (store 4 into %ir.val_2)
    ; CHECK: [[LEA64r3:%[0-9]+]]:gr64 = LEA64r [[COPY]], 1, $noreg, @block_ + 2062, $noreg
    ; CHECK: MOV32mi [[LEA64r3]], 1, $noreg, 0, $noreg, 10 :: (store 4 into %ir.val_3)
    ; CHECK: [[LEA64r4:%[0-9]+]]:gr64 = LEA64r [[COPY]], 1, $noreg, @block_ + 2212, $noreg
    ; CHECK: MOV32mi [[LEA64r4]], 1, $noreg, 0, $noreg, 10 :: (store 4 into %ir.val_4)
    ; CHECK: RET 0
    %0:gr64 = COPY $rdi
    MOV32mi %0, 1, $noreg, @block_ + 2412, $noreg, 10 :: (store 4 into %ir.val_0)
    MOV32mi %0, 1, $noreg, @block_ + 12, $noreg, 10 :: (store 4 into %ir.val_1)
    MOV32mi %0, 1, $noreg, @block_ + 2012, $noreg, 10 :: (store 4 into %ir.val_2)
    MOV32mi %0, 1, $noreg, @block_ + 2062, $noreg, 10 :: (store 4 into %ir.val_3)
    MOV32mi %0, 1, $noreg, @block_ + 2212, $noreg, 10 :: (store 4 into %ir.val_4)
    RET 0

...

