; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function _ZGVeN8uuuu__ZTSZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_E10add_matrix --scrub-attributes --include-generated-funcs
; RUN: opt -opaque-pointers=0 -passes=sycl-kernel-resolve-matrix-fill,sycl-kernel-resolve-matrix-wi-slice,sycl-kernel-set-vf,sycl-kernel-vec-clone,lcssa,vplan-vec -sycl-vector-variant-isa-encoding-override=AVX512Core -S %s | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux"

%"class.cl::sycl::range" = type { %"class.cl::sycl::detail::array" }
%"class.cl::sycl::detail::array" = type { [2 x i64] }

; Function Attrs: nounwind
define void @_ZTSZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_E10add_matrix(i16 addrspace(1)* noalias %_arg_, %"class.cl::sycl::range"* byval(%"class.cl::sycl::range") align 8 %_arg_1, %"class.cl::sycl::range"* byval(%"class.cl::sycl::range") align 8 %_arg_2, %"class.cl::sycl::range"* byval(%"class.cl::sycl::range") align 8 %_arg_3) local_unnamed_addr #0 !kernel_arg_addr_space !7 !kernel_arg_access_qual !8 !kernel_arg_type !9 !kernel_arg_base_type !9 !kernel_arg_type_qual !10 !no_barrier_path !11 !kernel_has_sub_groups !12 !max_wg_dimensions !13 !intel_reqd_sub_group_size !14 !spirv.ParameterDecorations !15 {
entry:
  %0 = tail call i64 @_Z13get_global_idj(i32 0) #6
  %1 = tail call i64 @_Z13get_global_idj(i32 1) #6
  %2 = tail call i64 @_Z12get_local_idj(i32 0) #6
  %3 = tail call i64 @_Z12get_local_idj(i32 1) #6
  %cmp.i.i = icmp ult i64 %1, 2147483648
  tail call void @llvm.assume(i1 %cmp.i.i)
  %cmp.i33.i = icmp ult i64 %0, 2147483648
  tail call void @llvm.assume(i1 %cmp.i33.i)
  %cmp.i40.i = icmp ult i64 %3, 2147483648
  tail call void @llvm.assume(i1 %cmp.i40.i)
  %cmp.i48.i = icmp ult i64 %2, 2147483648
  tail call void @llvm.assume(i1 %cmp.i48.i)
  %call.i59.i = tail call <128 x i16> @llvm.experimental.matrix.fill.v128i16.i16(i16 16544, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
  br label %for.cond.i

for.cond.i:                                       ; preds = %for.body.i, %entry
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body.i ], [ 0, %entry ]
  %sub_a.sroa.0.0.i = phi <128 x i16> [ %call.i.i, %for.body.i ], [ %call.i59.i, %entry ]
  %call.i56.i = tail call i64 @llvm.experimental.matrix.wi.slice.length.v128i16(<128 x i16> %sub_a.sroa.0.0.i, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
  %cmp.i = icmp ugt i64 %call.i56.i, %indvars.iv
  br i1 %cmp.i, label %for.body.i, label %_ZZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_ENKUlNS1_7nd_itemILi2EEEE_clESE_.exit

for.body.i:                                       ; preds = %for.cond.i
  %call.i38.i = tail call i16 @llvm.experimental.matrix.wi.slice.extractelement.v128i16.i64(<128 x i16> %sub_a.sroa.0.0.i, i32 8, i32 16, i64 %indvars.iv, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
  %conv.i.i.i = zext i16 %call.i38.i to i32
  %shl.i.i.i = shl nuw i32 %conv.i.i.i, 16
  %4 = bitcast i32 %shl.i.i.i to float
  %add.i.i = fadd fast float %4, 2.000000e+00
  %5 = bitcast float %add.i.i to i32
  %6 = lshr i32 %5, 16
  %conv.i5.i.i = trunc i32 %6 to i16
  %call.i.i = tail call <128 x i16> @llvm.experimental.matrix.wi.slice.insertelement.v128i16.i64(<128 x i16> %sub_a.sroa.0.0.i, i32 8, i32 16, i16 %conv.i5.i.i, i64 %indvars.iv, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
  %indvars.iv.next = add nuw i64 %indvars.iv, 1
  br label %for.cond.i

_ZZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_ENKUlNS1_7nd_itemILi2EEEE_clESE_.exit: ; preds = %for.cond.i
  %sub5.i = sub nsw i64 %0, %2
  %sub.i = sub nsw i64 %1, %3
  %mul21.i = shl nsw i64 %sub.i, 7
  %add.ptr.i51.i = getelementptr inbounds i16, i16 addrspace(1)* %_arg_, i64 %mul21.i
  %div.i = and i64 %sub5.i, -8
  %add.ptr.i.i = getelementptr inbounds i16, i16 addrspace(1)* %add.ptr.i51.i, i64 %div.i
  %call.ascast.i.i = addrspacecast i16 addrspace(1)* %add.ptr.i.i to i16 addrspace(4)*
  tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> %sub_a.sroa.0.0.i, i16 addrspace(4)* %call.ascast.i.i, i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
  ret void
}

; Function Attrs: inaccessiblememonly mustprogress nofree nosync nounwind willreturn
declare void @llvm.assume(i1 noundef) #1

; Function Attrs: mustprogress nofree nosync nounwind readnone willreturn
declare <128 x i16> @llvm.experimental.matrix.fill.v128i16.i16(i16, i32, i32, metadata, metadata, metadata) #2

; Function Attrs: mustprogress nofree nosync nounwind willreturn
declare i64 @llvm.experimental.matrix.wi.slice.length.v128i16(<128 x i16>, i32, i32, metadata, metadata, metadata) #3

; Function Attrs: mustprogress nofree nosync nounwind willreturn
declare i16 @llvm.experimental.matrix.wi.slice.extractelement.v128i16.i64(<128 x i16>, i32, i32, i64, metadata, metadata, metadata) #3

; Function Attrs: mustprogress nofree nosync nounwind willreturn
declare <128 x i16> @llvm.experimental.matrix.wi.slice.insertelement.v128i16.i64(<128 x i16>, i32, i32, i16, i64, metadata, metadata, metadata) #3

; Function Attrs: convergent mustprogress nofree nosync nounwind willreturn
declare void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16>, i16 addrspace(4)*, i64, i1, i32, i32, metadata, metadata, metadata, metadata) #4

; Function Attrs: mustprogress nofree nosync nounwind readnone willreturn
declare i64 @_Z13get_global_idj(i32) local_unnamed_addr #5

; Function Attrs: mustprogress nofree nosync nounwind readnone willreturn
declare i64 @_Z12get_local_idj(i32) local_unnamed_addr #5

declare i64 @_Z14get_local_sizej(i32)

declare i64 @get_base_global_id.(i32)

attributes #0 = { nounwind "prefer-vector-width"="512" }
attributes #1 = { inaccessiblememonly mustprogress nofree nosync nounwind willreturn }
attributes #2 = { mustprogress nofree nosync nounwind readnone willreturn }
attributes #3 = { mustprogress nofree nosync nounwind willreturn }
attributes #4 = { convergent mustprogress nofree nosync nounwind willreturn "kernel-call-once" "kernel-uniform-call" "opencl-vec-uniform-return" }
attributes #5 = { mustprogress nofree nosync nounwind readnone willreturn "prefer-vector-width"="512" }
attributes #6 = { nounwind readnone willreturn }

!spirv.MemoryModel = !{!0}
!opencl.enable.FP_CONTRACT = !{}
!spirv.Source = !{!1}
!opencl.spir.version = !{!2}
!opencl.ocl.version = !{!3}
!opencl.used.extensions = !{!4}
!opencl.used.optional.core.features = !{!4}
!spirv.Generator = !{!5}
!sycl.kernels = !{!6}

!0 = !{i32 2, i32 2}
!1 = !{i32 4, i32 100000}
!2 = !{i32 1, i32 2}
!3 = !{i32 1, i32 0}
!4 = !{}
!5 = !{i16 6, i16 14}
!6 = !{void (i16 addrspace(1)*, %"class.cl::sycl::range"*, %"class.cl::sycl::range"*, %"class.cl::sycl::range"*)* @_ZTSZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_E10add_matrix}
!7 = !{i32 1, i32 0, i32 0, i32 0}
!8 = !{!"none", !"none", !"none", !"none"}
!9 = !{!"short*", !"class.cl::sycl::range", !"class.cl::sycl::range", !"class.cl::sycl::range"}
!10 = !{!"", !"", !"", !""}
!11 = !{i1 true}
!12 = !{i1 false}
!13 = !{i32 2}
!14 = !{i32 8}
!15 = !{!4, !16, !16, !16}
!16 = !{!17, !18}
!17 = !{i32 38, i32 2}
!18 = !{i32 44, i32 8}
; CHECK-LABEL: @_ZTSZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_E10add_matrix(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @_Z13get_global_idj(i32 0)
; CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @_Z13get_global_idj(i32 1)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @_Z12get_local_idj(i32 0)
; CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @_Z12get_local_idj(i32 1)
; CHECK-NEXT:    [[CMP_I_I:%.*]] = icmp ult i64 [[TMP1]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I_I]])
; CHECK-NEXT:    [[CMP_I33_I:%.*]] = icmp ult i64 [[TMP0]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I33_I]])
; CHECK-NEXT:    [[CMP_I40_I:%.*]] = icmp ult i64 [[TMP3]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I40_I]])
; CHECK-NEXT:    [[CMP_I48_I:%.*]] = icmp ult i64 [[TMP2]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I48_I]])
; CHECK-NEXT:    [[MAT_INIT:%.*]] = call <128 x i16> @llvm.experimental.matrix.fill.v128i16.i16(i16 0, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    [[SG_SLICE_LENGTH:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    br label [[MATRIX_FILL_SLICE_LOOP_HEADER:%.*]]
; CHECK:       matrix.fill.slice.loop.header:
; CHECK-NEXT:    [[ELEMENT_INDEX:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[ELEMENT_INDEX_INC:%.*]], [[MATRIX_FILL_SLICE_LOOP:%.*]] ]
; CHECK-NEXT:    [[MAT:%.*]] = phi <128 x i16> [ [[MAT_INIT]], [[ENTRY]] ], [ [[MAT_UPDATE3:%.*]], [[MATRIX_FILL_SLICE_LOOP]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = icmp slt i64 [[ELEMENT_INDEX]], [[SG_SLICE_LENGTH]]
; CHECK-NEXT:    br i1 [[TMP4]], label [[MATRIX_FILL_SLICE_LOOP]], label [[MATRIX_FILL_SLICE_LOOP_END:%.*]]
; CHECK:       matrix.fill.slice.loop:
; CHECK-NEXT:    [[ROWSLICE_ID2:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[MAT]], i32 8, i32 16, i64 [[ELEMENT_INDEX]])
; CHECK-NEXT:    call void @sub_group_rowslice_insertelement.i16(i64 [[ROWSLICE_ID2]], i16 16544)
; CHECK-NEXT:    [[MAT_UPDATE3]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[ROWSLICE_ID2]])
; CHECK-NEXT:    [[ELEMENT_INDEX_INC]] = add nuw i64 [[ELEMENT_INDEX]], 1
; CHECK-NEXT:    br label [[MATRIX_FILL_SLICE_LOOP_HEADER]]
; CHECK:       matrix.fill.slice.loop.end:
; CHECK-NEXT:    [[MAT_LCSSA:%.*]] = phi <128 x i16> [ [[MAT]], [[MATRIX_FILL_SLICE_LOOP_HEADER]] ]
; CHECK-NEXT:    br label [[FOR_COND_I:%.*]]
; CHECK:       for.cond.i:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY_I:%.*]] ], [ 0, [[MATRIX_FILL_SLICE_LOOP_END]] ]
; CHECK-NEXT:    [[SUB_A_SROA_0_0_I:%.*]] = phi <128 x i16> [ [[MAT_UPDATE:%.*]], [[FOR_BODY_I]] ], [ [[MAT_LCSSA]], [[MATRIX_FILL_SLICE_LOOP_END]] ]
; CHECK-NEXT:    [[SG_SLICE_LENGTH1:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    [[CMP_I:%.*]] = icmp ugt i64 [[SG_SLICE_LENGTH1]], [[INDVARS_IV]]
; CHECK-NEXT:    br i1 [[CMP_I]], label [[FOR_BODY_I]], label [[_ZZZ17MATRIX_VERIFY_ADDITLM16ELM16EEVN2CL4SYCL5QUEUEER10BIG_MATRIXIT_XT0_EXT1_EERNS1_8ND_RANGEILI2EEEFENKULRNS1_7HANDLEREE_CLESB_ENKULNS1_7ND_ITEMILI2EEEE_CLESE__EXIT:%.*]]
; CHECK:       for.body.i:
; CHECK-NEXT:    [[ROWSLICE_ID:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[SUB_A_SROA_0_0_I]], i32 8, i32 16, i64 [[INDVARS_IV]])
; CHECK-NEXT:    [[EXTRACT_ELEM:%.*]] = call i16 @sub_group_rowslice_extractelement.i16(i64 [[ROWSLICE_ID]])
; CHECK-NEXT:    [[CONV_I_I_I:%.*]] = zext i16 [[EXTRACT_ELEM]] to i32
; CHECK-NEXT:    [[SHL_I_I_I:%.*]] = shl nuw i32 [[CONV_I_I_I]], 16
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i32 [[SHL_I_I_I]] to float
; CHECK-NEXT:    [[ADD_I_I:%.*]] = fadd fast float [[TMP5]], 2.000000e+00
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast float [[ADD_I_I]] to i32
; CHECK-NEXT:    [[TMP7:%.*]] = lshr i32 [[TMP6]], 16
; CHECK-NEXT:    [[CONV_I5_I_I:%.*]] = trunc i32 [[TMP7]] to i16
; CHECK-NEXT:    [[ROWSLICE_ID4:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[SUB_A_SROA_0_0_I]], i32 8, i32 16, i64 [[INDVARS_IV]])
; CHECK-NEXT:    call void @sub_group_rowslice_insertelement.i16(i64 [[ROWSLICE_ID4]], i16 [[CONV_I5_I_I]])
; CHECK-NEXT:    [[MAT_UPDATE]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[ROWSLICE_ID4]])
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    br label [[FOR_COND_I]]
; CHECK:       _ZZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_ENKUlNS1_7nd_itemILi2EEEE_clESE_.exit:
; CHECK-NEXT:    [[SUB_A_SROA_0_0_I_LCSSA:%.*]] = phi <128 x i16> [ [[SUB_A_SROA_0_0_I]], [[FOR_COND_I]] ]
; CHECK-NEXT:    [[SUB5_I:%.*]] = sub nsw i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    [[SUB_I:%.*]] = sub nsw i64 [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[MUL21_I:%.*]] = shl nsw i64 [[SUB_I]], 7
; CHECK-NEXT:    [[ADD_PTR_I51_I:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[_ARG_:%.*]], i64 [[MUL21_I]]
; CHECK-NEXT:    [[DIV_I:%.*]] = and i64 [[SUB5_I]], -8
; CHECK-NEXT:    [[ADD_PTR_I_I:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[ADD_PTR_I51_I]], i64 [[DIV_I]]
; CHECK-NEXT:    [[CALL_ASCAST_I_I:%.*]] = addrspacecast i16 addrspace(1)* [[ADD_PTR_I_I]] to i16 addrspace(4)*
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[SUB_A_SROA_0_0_I_LCSSA]], i16 addrspace(4)* [[CALL_ASCAST_I_I]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: @_ZGVeN8uuuu__ZTSZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_E10add_matrix(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ALLOCA__ARG_:%.*]] = alloca i16 addrspace(1)*, align 8
; CHECK-NEXT:    store i16 addrspace(1)* [[_ARG_:%.*]], i16 addrspace(1)** [[ALLOCA__ARG_]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = tail call i64 @_Z13get_global_idj(i32 1)
; CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @_Z13get_global_idj(i32 0)
; CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @_Z12get_local_idj(i32 1)
; CHECK-NEXT:    [[TMP3:%.*]] = tail call i64 @_Z12get_local_idj(i32 0)
; CHECK-NEXT:    [[TMP4:%.*]] = trunc i64 [[TMP3]] to i32
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION:%.*]]
; CHECK:       simd.begin.region:
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER:%.*]]
; CHECK:       simd.loop.preheader:
; CHECK-NEXT:    [[LOAD__ARG_:%.*]] = load i16 addrspace(1)*, i16 addrspace(1)** [[ALLOCA__ARG_]], align 8
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <8 x i32> poison, i32 [[TMP4]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <8 x i32> [[BROADCAST_SPLATINSERT]], <8 x i32> poison, <8 x i32> zeroinitializer
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT4:%.*]] = insertelement <8 x i64> poison, i64 [[TMP1]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT5:%.*]] = shufflevector <8 x i64> [[BROADCAST_SPLATINSERT4]], <8 x i64> poison, <8 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB2:%.*]]
; CHECK:       VPlannedBB2:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i32 [ 0, [[VPLANNEDBB2]] ], [ [[TMP39:%.*]], [[VPLANNEDBB35:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <8 x i32> [ <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, [[VPLANNEDBB2]] ], [ [[TMP38:%.*]], [[VPLANNEDBB35]] ]
; CHECK-NEXT:    [[TMP5:%.*]] = add nuw <8 x i32> [[BROADCAST_SPLAT]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP6:%.*]] = sext <8 x i32> [[TMP5]] to <8 x i64>
; CHECK-NEXT:    [[DOTEXTRACT_0_33:%.*]] = extractelement <8 x i64> [[TMP6]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = sext <8 x i32> [[VEC_PHI]] to <8 x i64>
; CHECK-NEXT:    [[TMP8:%.*]] = add nuw <8 x i64> [[TMP7]], [[BROADCAST_SPLAT5]]
; CHECK-NEXT:    [[DOTEXTRACT_0_32:%.*]] = extractelement <8 x i64> [[TMP8]], i32 0
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ult i64 [[TMP0]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[TMP9]])
; CHECK-NEXT:    [[TMP10:%.*]] = icmp ult <8 x i64> [[TMP8]], <i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648>
; CHECK-NEXT:    [[DOTEXTRACT_7_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 7
; CHECK-NEXT:    [[DOTEXTRACT_6_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 6
; CHECK-NEXT:    [[DOTEXTRACT_5_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 5
; CHECK-NEXT:    [[DOTEXTRACT_4_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 4
; CHECK-NEXT:    [[DOTEXTRACT_3_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 3
; CHECK-NEXT:    [[DOTEXTRACT_2_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 2
; CHECK-NEXT:    [[DOTEXTRACT_1_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 1
; CHECK-NEXT:    [[DOTEXTRACT_0_:%.*]] = extractelement <8 x i1> [[TMP10]], i32 0
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_0_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_1_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_2_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_3_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_4_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_5_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_6_]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_7_]])
; CHECK-NEXT:    [[TMP11:%.*]] = icmp ult i64 [[TMP2]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[TMP11]])
; CHECK-NEXT:    [[TMP12:%.*]] = icmp ult <8 x i64> [[TMP6]], <i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648, i64 2147483648>
; CHECK-NEXT:    [[DOTEXTRACT_7_13:%.*]] = extractelement <8 x i1> [[TMP12]], i32 7
; CHECK-NEXT:    [[DOTEXTRACT_6_12:%.*]] = extractelement <8 x i1> [[TMP12]], i32 6
; CHECK-NEXT:    [[DOTEXTRACT_5_11:%.*]] = extractelement <8 x i1> [[TMP12]], i32 5
; CHECK-NEXT:    [[DOTEXTRACT_4_10:%.*]] = extractelement <8 x i1> [[TMP12]], i32 4
; CHECK-NEXT:    [[DOTEXTRACT_3_9:%.*]] = extractelement <8 x i1> [[TMP12]], i32 3
; CHECK-NEXT:    [[DOTEXTRACT_2_8:%.*]] = extractelement <8 x i1> [[TMP12]], i32 2
; CHECK-NEXT:    [[DOTEXTRACT_1_7:%.*]] = extractelement <8 x i1> [[TMP12]], i32 1
; CHECK-NEXT:    [[DOTEXTRACT_0_6:%.*]] = extractelement <8 x i1> [[TMP12]], i32 0
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_0_6]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_1_7]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_2_8]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_3_9]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_4_10]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_5_11]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_6_12]])
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[DOTEXTRACT_7_13]])
; CHECK-NEXT:    [[TMP13:%.*]] = call <128 x i16> @llvm.experimental.matrix.fill.v128i16.i16(i16 0, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    [[TMP14:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    br label [[VPLANNEDBB14:%.*]]
; CHECK:       VPlannedBB14:
; CHECK-NEXT:    [[UNI_PHI15:%.*]] = phi i64 [ 0, [[VECTOR_BODY]] ], [ [[UNI_PHI18:%.*]], [[NEW_LOOP_LATCH14:%.*]] ]
; CHECK-NEXT:    [[UNI_PHI16:%.*]] = phi <128 x i16> [ [[TMP13]], [[VECTOR_BODY]] ], [ [[UNI_PHI19:%.*]], [[NEW_LOOP_LATCH14]] ]
; CHECK-NEXT:    [[TMP15:%.*]] = icmp slt i64 [[UNI_PHI15]], [[TMP14]]
; CHECK-NEXT:    br i1 [[TMP15]], label [[VPLANNEDBB17:%.*]], label [[NEW_LOOP_LATCH14]]
; CHECK:       VPlannedBB17:
; CHECK-NEXT:    [[TMP16:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[UNI_PHI16]], i32 8, i32 16, i64 [[UNI_PHI15]])
; CHECK-NEXT:    call void @_ZGVbN8uv_sub_group_rowslice_insertelement.i16(i64 [[TMP16]], <8 x i16> <i16 16544, i16 16544, i16 16544, i16 16544, i16 16544, i16 16544, i16 16544, i16 16544>)
; CHECK-NEXT:    [[TMP17:%.*]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[TMP16]])
; CHECK-NEXT:    [[TMP18:%.*]] = add i64 [[UNI_PHI15]], 1
; CHECK-NEXT:    br label [[NEW_LOOP_LATCH14]]
; CHECK:       new.loop.latch14:
; CHECK-NEXT:    [[UNI_PHI18]] = phi i64 [ [[TMP18]], [[VPLANNEDBB17]] ], [ undef, [[VPLANNEDBB14]] ]
; CHECK-NEXT:    [[UNI_PHI19]] = phi <128 x i16> [ [[TMP17]], [[VPLANNEDBB17]] ], [ undef, [[VPLANNEDBB14]] ]
; CHECK-NEXT:    [[UNI_PHI20:%.*]] = phi i1 [ true, [[VPLANNEDBB17]] ], [ false, [[VPLANNEDBB14]] ]
; CHECK-NEXT:    br i1 [[UNI_PHI20]], label [[VPLANNEDBB14]], label [[VPLANNEDBB21:%.*]]
; CHECK:       VPlannedBB21:
; CHECK-NEXT:    [[UNI_PHI22:%.*]] = phi <128 x i16> [ [[UNI_PHI16]], [[NEW_LOOP_LATCH14]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB23:%.*]]
; CHECK:       VPlannedBB23:
; CHECK-NEXT:    [[UNI_PHI24:%.*]] = phi i64 [ [[UNI_PHI27:%.*]], [[NEW_LOOP_LATCH16:%.*]] ], [ 0, [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[UNI_PHI25:%.*]] = phi <128 x i16> [ [[UNI_PHI28:%.*]], [[NEW_LOOP_LATCH16]] ], [ [[UNI_PHI22]], [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[TMP19:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    [[TMP20:%.*]] = icmp ugt i64 [[TMP19]], [[UNI_PHI24]]
; CHECK-NEXT:    br i1 [[TMP20]], label [[VPLANNEDBB26:%.*]], label [[NEW_LOOP_LATCH16]]
; CHECK:       VPlannedBB26:
; CHECK-NEXT:    [[TMP21:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[UNI_PHI25]], i32 8, i32 16, i64 [[UNI_PHI24]])
; CHECK-NEXT:    [[TMP22:%.*]] = call <8 x i16> @_ZGVbN8u_sub_group_rowslice_extractelement.i16(i64 [[TMP21]])
; CHECK-NEXT:    [[TMP23:%.*]] = zext <8 x i16> [[TMP22]] to <8 x i32>
; CHECK-NEXT:    [[TMP24:%.*]] = shl nuw <8 x i32> [[TMP23]], <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
; CHECK-NEXT:    [[TMP25:%.*]] = bitcast <8 x i32> [[TMP24]] to <8 x float>
; CHECK-NEXT:    [[TMP26:%.*]] = fadd fast <8 x float> [[TMP25]], <float 2.000000e+00, float 2.000000e+00, float 2.000000e+00, float 2.000000e+00, float 2.000000e+00, float 2.000000e+00, float 2.000000e+00, float 2.000000e+00>
; CHECK-NEXT:    [[TMP27:%.*]] = bitcast <8 x float> [[TMP26]] to <8 x i32>
; CHECK-NEXT:    [[TMP28:%.*]] = lshr <8 x i32> [[TMP27]], <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
; CHECK-NEXT:    [[TMP29:%.*]] = trunc <8 x i32> [[TMP28]] to <8 x i16>
; CHECK-NEXT:    [[TMP30:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[UNI_PHI25]], i32 8, i32 16, i64 [[UNI_PHI24]])
; CHECK-NEXT:    call void @_ZGVbN8uv_sub_group_rowslice_insertelement.i16(i64 [[TMP30]], <8 x i16> [[TMP29]])
; CHECK-NEXT:    [[TMP31:%.*]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[TMP30]])
; CHECK-NEXT:    [[TMP32:%.*]] = add i64 [[UNI_PHI24]], 1
; CHECK-NEXT:    br label [[NEW_LOOP_LATCH16]]
; CHECK:       new.loop.latch16:
; CHECK-NEXT:    [[UNI_PHI27]] = phi i64 [ [[TMP32]], [[VPLANNEDBB26]] ], [ undef, [[VPLANNEDBB23]] ]
; CHECK-NEXT:    [[UNI_PHI28]] = phi <128 x i16> [ [[TMP31]], [[VPLANNEDBB26]] ], [ undef, [[VPLANNEDBB23]] ]
; CHECK-NEXT:    [[UNI_PHI29:%.*]] = phi i1 [ true, [[VPLANNEDBB26]] ], [ false, [[VPLANNEDBB23]] ]
; CHECK-NEXT:    br i1 [[UNI_PHI29]], label [[VPLANNEDBB23]], label [[VPLANNEDBB30:%.*]]
; CHECK:       VPlannedBB30:
; CHECK-NEXT:    [[UNI_PHI31:%.*]] = phi <128 x i16> [ [[UNI_PHI25]], [[NEW_LOOP_LATCH16]] ]
; CHECK-NEXT:    [[TMP33:%.*]] = sub i64 [[DOTEXTRACT_0_32]], [[DOTEXTRACT_0_33]]
; CHECK-NEXT:    [[TMP34:%.*]] = sub i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    [[TMP35:%.*]] = shl i64 [[TMP34]], 7
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[LOAD__ARG_]], i64 [[TMP35]]
; CHECK-NEXT:    [[TMP36:%.*]] = and i64 [[TMP33]], -8
; CHECK-NEXT:    [[SCALAR_GEP34:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[SCALAR_GEP]], i64 [[TMP36]]
; CHECK-NEXT:    [[TMP37:%.*]] = addrspacecast i16 addrspace(1)* [[SCALAR_GEP34]] to i16 addrspace(4)*
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[UNI_PHI31]], i16 addrspace(4)* [[TMP37]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    br label [[VPLANNEDBB35]]
; CHECK:       VPlannedBB35:
; CHECK-NEXT:    [[TMP38]] = add nuw <8 x i32> [[VEC_PHI]], <i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8, i32 8>
; CHECK-NEXT:    [[TMP39]] = add nuw i32 [[UNI_PHI]], 8
; CHECK-NEXT:    [[TMP40:%.*]] = icmp ult i32 [[TMP39]], 8
; CHECK-NEXT:    br i1 false, label [[VECTOR_BODY]], label [[VPLANNEDBB36:%.*]], !llvm.loop [[LOOP22:![0-9]+]]
; CHECK:       VPlannedBB36:
; CHECK-NEXT:    br label [[VPLANNEDBB37:%.*]]
; CHECK:       VPlannedBB37:
; CHECK-NEXT:    br label [[FINAL_MERGE:%.*]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI38:%.*]] = phi i32 [ 8, [[VPLANNEDBB37]] ]
; CHECK-NEXT:    br label [[SIMD_END_REGION:%.*]]
; CHECK:       simd.loop.header:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ [[INDVAR:%.*]], [[SIMD_LOOP_LATCH:%.*]] ]
; CHECK-NEXT:    [[ADD1:%.*]] = add nuw i32 [[TMP4]], [[INDEX]]
; CHECK-NEXT:    [[TMP41:%.*]] = sext i32 [[ADD1]] to i64
; CHECK-NEXT:    [[TMP42:%.*]] = sext i32 [[INDEX]] to i64
; CHECK-NEXT:    [[ADD:%.*]] = add nuw i64 [[TMP42]], [[TMP1]]
; CHECK-NEXT:    [[CMP_I_I:%.*]] = icmp ult i64 [[TMP0]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I_I]])
; CHECK-NEXT:    [[CMP_I33_I:%.*]] = icmp ult i64 [[ADD]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I33_I]])
; CHECK-NEXT:    [[CMP_I40_I:%.*]] = icmp ult i64 [[TMP2]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I40_I]])
; CHECK-NEXT:    [[CMP_I48_I:%.*]] = icmp ult i64 [[TMP41]], 2147483648
; CHECK-NEXT:    tail call void @llvm.assume(i1 [[CMP_I48_I]])
; CHECK-NEXT:    [[MAT_INIT:%.*]] = call <128 x i16> @llvm.experimental.matrix.fill.v128i16.i16(i16 0, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    [[SG_SLICE_LENGTH:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    br label [[MATRIX_FILL_SLICE_LOOP_HEADER:%.*]]
; CHECK:       matrix.fill.slice.loop.header:
; CHECK-NEXT:    [[ELEMENT_INDEX:%.*]] = phi i64 [ 0, [[SIMD_LOOP_HEADER:%.*]] ], [ [[ELEMENT_INDEX_INC:%.*]], [[MATRIX_FILL_SLICE_LOOP:%.*]] ]
; CHECK-NEXT:    [[MAT:%.*]] = phi <128 x i16> [ [[MAT_INIT]], [[SIMD_LOOP_HEADER]] ], [ [[MAT_UPDATE3:%.*]], [[MATRIX_FILL_SLICE_LOOP]] ]
; CHECK-NEXT:    [[TMP43:%.*]] = icmp slt i64 [[ELEMENT_INDEX]], [[SG_SLICE_LENGTH]]
; CHECK-NEXT:    br i1 [[TMP43]], label [[MATRIX_FILL_SLICE_LOOP]], label [[MATRIX_FILL_SLICE_LOOP_END:%.*]]
; CHECK:       matrix.fill.slice.loop:
; CHECK-NEXT:    [[ROWSLICE_ID2:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[MAT]], i32 8, i32 16, i64 [[ELEMENT_INDEX]])
; CHECK-NEXT:    call void @sub_group_rowslice_insertelement.i16(i64 [[ROWSLICE_ID2]], i16 16544)
; CHECK-NEXT:    [[MAT_UPDATE3]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[ROWSLICE_ID2]])
; CHECK-NEXT:    [[ELEMENT_INDEX_INC]] = add nuw i64 [[ELEMENT_INDEX]], 1
; CHECK-NEXT:    br label [[MATRIX_FILL_SLICE_LOOP_HEADER]]
; CHECK:       matrix.fill.slice.loop.end:
; CHECK-NEXT:    [[MAT_LCSSA:%.*]] = phi <128 x i16> [ [[MAT]], [[MATRIX_FILL_SLICE_LOOP_HEADER]] ]
; CHECK-NEXT:    br label [[FOR_COND_I:%.*]]
; CHECK:       for.cond.i:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY_I:%.*]] ], [ 0, [[MATRIX_FILL_SLICE_LOOP_END]] ]
; CHECK-NEXT:    [[SUB_A_SROA_0_0_I:%.*]] = phi <128 x i16> [ [[MAT_UPDATE:%.*]], [[FOR_BODY_I]] ], [ [[MAT_LCSSA]], [[MATRIX_FILL_SLICE_LOOP_END]] ]
; CHECK-NEXT:    [[SG_SLICE_LENGTH1:%.*]] = call i64 @get_sub_group_slice_length.(i32 128)
; CHECK-NEXT:    [[CMP_I:%.*]] = icmp ugt i64 [[SG_SLICE_LENGTH1]], [[INDVARS_IV]]
; CHECK-NEXT:    br i1 [[CMP_I]], label [[FOR_BODY_I]], label [[_ZZZ17MATRIX_VERIFY_ADDITLM16ELM16EEVN2CL4SYCL5QUEUEER10BIG_MATRIXIT_XT0_EXT1_EERNS1_8ND_RANGEILI2EEEFENKULRNS1_7HANDLEREE_CLESB_ENKULNS1_7ND_ITEMILI2EEEE_CLESE__EXIT:%.*]]
; CHECK:       for.body.i:
; CHECK-NEXT:    [[ROWSLICE_ID:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[SUB_A_SROA_0_0_I]], i32 8, i32 16, i64 [[INDVARS_IV]])
; CHECK-NEXT:    [[EXTRACT_ELEM:%.*]] = call i16 @sub_group_rowslice_extractelement.i16(i64 [[ROWSLICE_ID]])
; CHECK-NEXT:    [[CONV_I_I_I:%.*]] = zext i16 [[EXTRACT_ELEM]] to i32
; CHECK-NEXT:    [[SHL_I_I_I:%.*]] = shl nuw i32 [[CONV_I_I_I]], 16
; CHECK-NEXT:    [[TMP44:%.*]] = bitcast i32 [[SHL_I_I_I]] to float
; CHECK-NEXT:    [[ADD_I_I:%.*]] = fadd fast float [[TMP44]], 2.000000e+00
; CHECK-NEXT:    [[TMP45:%.*]] = bitcast float [[ADD_I_I]] to i32
; CHECK-NEXT:    [[TMP46:%.*]] = lshr i32 [[TMP45]], 16
; CHECK-NEXT:    [[CONV_I5_I_I:%.*]] = trunc i32 [[TMP46]] to i16
; CHECK-NEXT:    [[ROWSLICE_ID4:%.*]] = call i64 @get_sub_group_rowslice_id.v128i16.i64(<128 x i16> [[SUB_A_SROA_0_0_I]], i32 8, i32 16, i64 [[INDVARS_IV]])
; CHECK-NEXT:    call void @sub_group_rowslice_insertelement.i16(i64 [[ROWSLICE_ID4]], i16 [[CONV_I5_I_I]])
; CHECK-NEXT:    [[MAT_UPDATE]] = call <128 x i16> @sub_group_insert_rowslice_to_matrix.v128i16(i64 [[ROWSLICE_ID4]])
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    br label [[FOR_COND_I]]
; CHECK:       _ZZZ17matrix_verify_addItLm16ELm16EEvN2cl4sycl5queueER10big_matrixIT_XT0_EXT1_EERNS1_8nd_rangeILi2EEEfENKUlRNS1_7handlerEE_clESB_ENKUlNS1_7nd_itemILi2EEEE_clESE_.exit:
; CHECK-NEXT:    [[SUB_A_SROA_0_0_I_LCSSA:%.*]] = phi <128 x i16> [ [[SUB_A_SROA_0_0_I]], [[FOR_COND_I]] ]
; CHECK-NEXT:    [[SUB5_I:%.*]] = sub nsw i64 [[ADD]], [[TMP41]]
; CHECK-NEXT:    [[SUB_I:%.*]] = sub nsw i64 [[TMP0]], [[TMP2]]
; CHECK-NEXT:    [[MUL21_I:%.*]] = shl nsw i64 [[SUB_I]], 7
; CHECK-NEXT:    [[ADD_PTR_I51_I:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[LOAD__ARG_]], i64 [[MUL21_I]]
; CHECK-NEXT:    [[DIV_I:%.*]] = and i64 [[SUB5_I]], -8
; CHECK-NEXT:    [[ADD_PTR_I_I:%.*]] = getelementptr inbounds i16, i16 addrspace(1)* [[ADD_PTR_I51_I]], i64 [[DIV_I]]
; CHECK-NEXT:    [[CALL_ASCAST_I_I:%.*]] = addrspacecast i16 addrspace(1)* [[ADD_PTR_I_I]] to i16 addrspace(4)*
; CHECK-NEXT:    tail call void @llvm.experimental.matrix.store.v128i16.p4i16(<128 x i16> [[SUB_A_SROA_0_0_I_LCSSA]], i16 addrspace(4)* [[CALL_ASCAST_I_I]], i64 16, i1 false, i32 8, i32 16, metadata !"matrix.rowmajor", metadata !"matrix.rowmajor", metadata !"scope.subgroup", metadata !"matrix.use.unnecessary")
; CHECK-NEXT:    br label [[SIMD_LOOP_LATCH]]
; CHECK:       simd.loop.latch:
; CHECK-NEXT:    [[INDVAR]] = add nuw i32 [[INDEX]], 1
; CHECK-NEXT:    [[VL_COND:%.*]] = icmp ult i32 [[INDVAR]], 8
; CHECK-NEXT:    br label [[SIMD_LOOP_HEADER]]
; CHECK:       simd.end.region:
; CHECK-NEXT:    br label [[RETURN:%.*]]
; CHECK:       return:
; CHECK-NEXT:    ret void
;
