; Ensure scalar SVML functions generated by -imf-use-svml and similar calls generated in remainder loops are lowered identically.
; RUN: opt -bugpoint-enable-legacy-pm -vector-library=SVML -S -iml-trans < %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; CHECK-LABEL: @sin_test
; CHECK: [[INSERT:%.*]] = insertelement <1 x float> undef, float %{{.*}}, i32 0
; CHECK: [[CALL:%.*]] = call svml_cc <1 x float> @__svml_sinf1_l9(<1 x float> [[INSERT]])
; CHECK: [[EXTRACT:%.*]] = extractelement <1 x float> [[CALL]], i32 0
; CHECK: store float [[EXTRACT]]

define dso_local void @sin_test(float* noalias nocapture noundef readonly %src, float* noalias nocapture noundef writeonly %sinA, i32 noundef %N) local_unnamed_addr #0 {
entry:
  %0 = load float, float* %src, align 4
  %1 = tail call fast float @llvm.sin.f32(float %0) #2
  store float %1, float* %sinA, align 4
  ret void
}

; CHECK-LABEL: @csqrtf_test
; CHECK: [[CALL:%.*]] = tail call fast svml_cc <2 x float> @__svml_csqrtf1_l9(<2 x float> %{{.*}})
; CHECK: store <2 x float> [[CALL]]

define dso_local void @csqrtf_test(<2 x float>* noalias nocapture noundef readonly %src, <2 x float>* noalias nocapture noundef writeonly %dst, i32 noundef %N) local_unnamed_addr #0 {
entry:
  %0 = load <2 x float>, <2 x float>* %src, align 4
  %1 = tail call fast <2 x float> @csqrtf(<2 x float> %0) #2
  store <2 x float> %1, <2 x float>* %dst, align 4
  ret void
}

; CHECK-LABEL: @sinvec_test
; CHECK: call fast svml_cc <1 x float> @__svml_sinf1_l9(<1 x float> %{{.*}})

define dso_local void @sinvec_test(float* noalias nocapture noundef readonly %src, float* noalias nocapture noundef writeonly %sinA, i32 noundef %N) local_unnamed_addr #1 {
entry:
  %cmp7 = icmp sgt i32 %N, 0
  br i1 %cmp7, label %for.body.preheader, label %for.cond.cleanup

for.body.preheader:                               ; preds = %entry
  %wide.trip.count = zext i32 %N to i64
  %0 = and i64 %wide.trip.count, 4294967292
  %extract.0.40 = icmp eq i64 %0, 0
  br i1 %extract.0.40, label %hir.L.24, label %ifmerge.23

for.cond.cleanup.loopexit:                        ; preds = %loop.98
  br label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.cond.cleanup.loopexit, %hir.L.60, %entry
  ret void

hir.L.24:                                         ; preds = %hir.L.60, %for.body.preheader
  %t20.0 = phi i64 [ 0, %for.body.preheader ], [ %t40.0, %hir.L.60 ]
  br label %loop.98

ifmerge.23:                                       ; preds = %for.body.preheader
  %1 = and i64 %wide.trip.count, 4294967280
  %extract.0.1443 = icmp eq i64 %1, 0
  br i1 %extract.0.1443, label %loop.73.preheader, label %loop.16.preheader

loop.16.preheader:                                ; preds = %ifmerge.23
  br label %loop.16

loop.73.preheader:                                ; preds = %afterloop.16, %ifmerge.23
  %i1.i64.1.ph = phi i64 [ %1, %afterloop.16 ], [ 0, %ifmerge.23 ]
  br label %loop.73

loop.16:                                          ; preds = %loop.16.preheader, %loop.16
  %i1.i64.0 = phi i64 [ %nextivloop.16, %loop.16 ], [ 0, %loop.16.preheader ]
  %scevgep90 = getelementptr float, float* %src, i64 %i1.i64.0
  %scevgep9091 = bitcast float* %scevgep90 to <16 x float>*
  %gepload = load <16 x float>, <16 x float>* %scevgep9091, align 4
  %2 = tail call fast svml_cc <16 x float> @__svml_sinf16(<16 x float> %gepload) #2
  %scevgep88 = getelementptr float, float* %sinA, i64 %i1.i64.0
  %scevgep8889 = bitcast float* %scevgep88 to <16 x float>*
  store <16 x float> %2, <16 x float>* %scevgep8889, align 4
  %nextivloop.16 = add nuw nsw i64 %i1.i64.0, 16
  %condloop.16.not.not = icmp ult i64 %nextivloop.16, %1
  br i1 %condloop.16.not.not, label %loop.16, label %afterloop.16

afterloop.16:                                     ; preds = %loop.16
  %extract.0.2451 = icmp eq i64 %0, %1
  br i1 %extract.0.2451, label %hir.L.60, label %loop.73.preheader

hir.L.60.loopexit:                                ; preds = %loop.73
  br label %hir.L.60

hir.L.60:                                         ; preds = %hir.L.60.loopexit, %afterloop.16
  %t40.0 = phi i64 [ %1, %afterloop.16 ], [ %0, %hir.L.60.loopexit ]
  %extract.0.3864 = icmp eq i64 %0, %wide.trip.count
  br i1 %extract.0.3864, label %for.cond.cleanup, label %hir.L.24

loop.73:                                          ; preds = %loop.73.preheader, %loop.73
  %i1.i64.1 = phi i64 [ %nextivloop.73, %loop.73 ], [ %i1.i64.1.ph, %loop.73.preheader ]
  %scevgep86 = getelementptr float, float* %src, i64 %i1.i64.1
  %scevgep8687 = bitcast float* %scevgep86 to <4 x float>*
  %gepload57 = load <4 x float>, <4 x float>* %scevgep8687, align 4
  %3 = tail call fast svml_cc <4 x float> @__svml_sinf4(<4 x float> %gepload57) #2
  %scevgep84 = getelementptr float, float* %sinA, i64 %i1.i64.1
  %scevgep8485 = bitcast float* %scevgep84 to <4 x float>*
  store <4 x float> %3, <4 x float>* %scevgep8485, align 4
  %nextivloop.73 = add nuw nsw i64 %i1.i64.1, 4
  %condloop.73.not.not = icmp ult i64 %nextivloop.73, %0
  br i1 %condloop.73.not.not, label %loop.73, label %hir.L.60.loopexit

loop.98:                                          ; preds = %loop.98, %hir.L.24
  %i1.i64.2 = phi i64 [ %t20.0, %hir.L.24 ], [ %nextivloop.98, %loop.98 ]
  %scevgep83 = getelementptr float, float* %src, i64 %i1.i64.2
  %gepload65 = load float, float* %scevgep83, align 4
  %.splatinsert66 = insertelement <1 x float> poison, float %gepload65, i64 0
  %4 = tail call fast svml_cc <1 x float> @__svml_sinf1(<1 x float> %.splatinsert66) #2
  %elem68 = extractelement <1 x float> %4, i64 0
  %scevgep = getelementptr float, float* %sinA, i64 %i1.i64.2
  store float %elem68, float* %scevgep, align 4
  %nextivloop.98 = add nuw nsw i64 %i1.i64.2, 1
  %condloop.98.not = icmp eq i64 %wide.trip.count, %nextivloop.98
  br i1 %condloop.98.not, label %for.cond.cleanup.loopexit, label %loop.98
}

declare <16 x float> @__svml_sinf16(<16 x float>) #3

declare <4 x float> @__svml_sinf4(<4 x float>) #3

declare <1 x float> @__svml_sinf1(<1 x float>) #3

declare float @llvm.sin.f32(float) #3

declare <2 x float> @csqrtf(<2 x float>) #3

attributes #0 = { argmemonly mustprogress nofree nosync nounwind willreturn uwtable "approx-func-fp-math"="true" "denormal-fp-math"="preserve-sign,preserve-sign" "frame-pointer"="none" "imf-use-svml"="true" "loopopt-pipeline"="full" "min-legal-vector-width"="0"
"no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="core-avx2" "target-features"="+avx,+avx2,+bmi,+bmi2,+crc32,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt" "unsafe-fp-math"="true" }
attributes #1 = { argmemonly nofree nosync nounwind uwtable "approx-func-fp-math"="true" "denormal-fp-math"="preserve-sign,preserve-sign" "frame-pointer"="none" "imf-use-svml"="true" "loopopt-pipeline"="full" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="core-avx2" "target-features"="+avx,+avx2,+bmi,+bmi2,+crc32,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+popcnt,+rdrnd,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsaveopt" "unsafe-fp-math"="true" }
attributes #2 = { "imf-use-svml"="true" }
attributes #3 = { mustprogress nocallback nofree nosync nounwind readnone speculatable willreturn }
