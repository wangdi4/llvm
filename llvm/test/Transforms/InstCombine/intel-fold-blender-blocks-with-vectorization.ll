; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -passes=simplifycfg -mtriple=i686-linux -mattr=+avx512f,+avx512vl,+avx512dq -enable-intel-advanced-opts=true -mattr=-prefer-256-bit %s -S 2>&1 | FileCheck %s --check-prefixes=CHECK

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.VBVHNode = type { [6 x float], %struct.VBVHNode*, %struct.VBVHNode* }
%struct.Isect = type { [3 x float], [3 x float], float, [3 x float], [3 x float], [6 x i32], [3 x float] }

; Function Attrs: uwtable
define hidden fastcc i32 @fold-blender-test(%struct.VBVHNode* %node, %struct.Isect* %isec) unnamed_addr {
; CHECK-LABEL: @fold-blender-test(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[BB:%.*]] = getelementptr inbounds [[STRUCT_VBVHNODE:%.*]], %struct.VBVHNode* [[NODE:%.*]], i64 0, i32 0
; CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [6 x float], [6 x float]* [[BB]], i64 0, i64 0
; CHECK-NEXT:    [[BV_INDEX:%.*]] = getelementptr inbounds [[STRUCT_ISECT:%.*]], %struct.Isect* [[ISEC:%.*]], i64 0, i32 5
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 0
; CHECK-NEXT:    [[BV_INDEX_V0:%.*]] = load i32, i32* [[ARRAYIDX]], align 4
; CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[BV_INDEX_V0]] to i64
; CHECK-NEXT:    [[PTRIDX:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM]]
; CHECK-NEXT:    [[BB_0:%.*]] = load float, float* [[PTRIDX]], align 4
; CHECK-NEXT:    [[START:%.*]] = getelementptr inbounds [[STRUCT_ISECT]], %struct.Isect* [[ISEC]], i64 0, i32 0
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[START]], i64 0, i64 0
; CHECK-NEXT:    [[START_0:%.*]] = load float, float* [[ARRAYIDX1]], align 8
; CHECK-NEXT:    [[SUB:%.*]] = fsub fast float [[BB_0]], [[START_0]]
; CHECK-NEXT:    [[IDOT_AXIS:%.*]] = getelementptr inbounds [[STRUCT_ISECT]], %struct.Isect* [[ISEC]], i64 0, i32 6
; CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[IDOT_AXIS]], i64 0, i64 0
; CHECK-NEXT:    [[IDOT_AXIS_0:%.*]] = load float, float* [[ARRAYIDX2]], align 4
; CHECK-NEXT:    [[MUL:%.*]] = fmul fast float [[SUB]], [[IDOT_AXIS_0]]
; CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 1
; CHECK-NEXT:    [[BV_INDEX_V1:%.*]] = load i32, i32* [[ARRAYIDX4]], align 4
; CHECK-NEXT:    [[IDXPROM5:%.*]] = sext i32 [[BV_INDEX_V1]] to i64
; CHECK-NEXT:    [[PTRIDX6:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM5]]
; CHECK-NEXT:    [[BB_1:%.*]] = load float, float* [[PTRIDX6]], align 4
; CHECK-NEXT:    [[SUB9:%.*]] = fsub fast float [[BB_1]], [[START_0]]
; CHECK-NEXT:    [[MUL12:%.*]] = fmul fast float [[SUB9]], [[IDOT_AXIS_0]]
; CHECK-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 2
; CHECK-NEXT:    [[BV_INDEX_V2:%.*]] = load i32, i32* [[ARRAYIDX14]], align 4
; CHECK-NEXT:    [[IDXPROM15:%.*]] = sext i32 [[BV_INDEX_V2]] to i64
; CHECK-NEXT:    [[PTRIDX16:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM15]]
; CHECK-NEXT:    [[BB_2:%.*]] = load float, float* [[PTRIDX16]], align 4
; CHECK-NEXT:    [[ARRAYIDX18:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[START]], i64 0, i64 1
; CHECK-NEXT:    [[START_1:%.*]] = load float, float* [[ARRAYIDX18]], align 4
; CHECK-NEXT:    [[SUB19:%.*]] = fsub fast float [[BB_2]], [[START_1]]
; CHECK-NEXT:    [[ARRAYIDX21:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[IDOT_AXIS]], i64 0, i64 1
; CHECK-NEXT:    [[IDOT_AXIS_1:%.*]] = load float, float* [[ARRAYIDX21]], align 4
; CHECK-NEXT:    [[MUL22:%.*]] = fmul fast float [[SUB19]], [[IDOT_AXIS_1]]
; CHECK-NEXT:    [[ARRAYIDX24:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 3
; CHECK-NEXT:    [[BV_INDEX_V3:%.*]] = load i32, i32* [[ARRAYIDX24]], align 4
; CHECK-NEXT:    [[IDXPROM25:%.*]] = sext i32 [[BV_INDEX_V3]] to i64
; CHECK-NEXT:    [[PTRIDX26:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM25]]
; CHECK-NEXT:    [[BB_3:%.*]] = load float, float* [[PTRIDX26]], align 4
; CHECK-NEXT:    [[SUB29:%.*]] = fsub fast float [[BB_3]], [[START_1]]
; CHECK-NEXT:    [[MUL32:%.*]] = fmul fast float [[SUB29]], [[IDOT_AXIS_1]]
; CHECK-NEXT:    [[ARRAYIDX34:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 4
; CHECK-NEXT:    [[BV_INDEX_V4:%.*]] = load i32, i32* [[ARRAYIDX34]], align 4
; CHECK-NEXT:    [[IDXPROM35:%.*]] = sext i32 [[BV_INDEX_V4]] to i64
; CHECK-NEXT:    [[PTRIDX36:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM35]]
; CHECK-NEXT:    [[BB_4:%.*]] = load float, float* [[PTRIDX36]], align 4
; CHECK-NEXT:    [[ARRAYIDX38:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[START]], i64 0, i64 2
; CHECK-NEXT:    [[START_2:%.*]] = load float, float* [[ARRAYIDX38]], align 8
; CHECK-NEXT:    [[SUB39:%.*]] = fsub fast float [[BB_4]], [[START_2]]
; CHECK-NEXT:    [[ARRAYIDX41:%.*]] = getelementptr inbounds [3 x float], [3 x float]* [[IDOT_AXIS]], i64 0, i64 2
; CHECK-NEXT:    [[IDOT_AXIS_2:%.*]] = load float, float* [[ARRAYIDX41]], align 4
; CHECK-NEXT:    [[MUL42:%.*]] = fmul fast float [[SUB39]], [[IDOT_AXIS_2]]
; CHECK-NEXT:    [[ARRAYIDX44:%.*]] = getelementptr inbounds [6 x i32], [6 x i32]* [[BV_INDEX]], i64 0, i64 5
; CHECK-NEXT:    [[BV_INDEX_V5:%.*]] = load i32, i32* [[ARRAYIDX44]], align 4
; CHECK-NEXT:    [[IDXPROM45:%.*]] = sext i32 [[BV_INDEX_V5]] to i64
; CHECK-NEXT:    [[PTRIDX46:%.*]] = getelementptr inbounds float, float* [[ARRAYDECAY]], i64 [[IDXPROM45]]
; CHECK-NEXT:    [[BB_5:%.*]] = load float, float* [[PTRIDX46]], align 4
; CHECK-NEXT:    [[SUB49:%.*]] = fsub fast float [[BB_5]], [[START_2]]
; CHECK-NEXT:    [[MUL52:%.*]] = fmul fast float [[SUB49]], [[IDOT_AXIS_2]]
; CHECK-NEXT:    [[CMP_I35:%.*]] = fcmp fast ogt float [[MUL]], [[MUL32]]
; CHECK-NEXT:    [[CMP53:%.*]] = fcmp fast olt float [[MUL12]], [[MUL22]]
; CHECK-NEXT:    [[OR_COND129:%.*]] = or i1 [[CMP53]], [[CMP_I35]]
; CHECK-NEXT:    [[CMP55:%.*]] = fcmp fast ogt float [[MUL]], [[MUL52]]
; CHECK-NEXT:    [[OR_COND130:%.*]] = or i1 [[OR_COND129]], [[CMP55]]
; CHECK-NEXT:    [[CMP57:%.*]] = fcmp fast olt float [[MUL12]], [[MUL42]]
; CHECK-NEXT:    [[OR_COND131:%.*]] = or i1 [[CMP57]], [[OR_COND130]]
; CHECK-NEXT:    [[CMP59:%.*]] = fcmp fast ogt float [[MUL22]], [[MUL52]]
; CHECK-NEXT:    [[OR_COND132:%.*]] = or i1 [[CMP59]], [[OR_COND131]]
; CHECK-NEXT:    [[CMP61:%.*]] = fcmp fast olt float [[MUL32]], [[MUL42]]
; CHECK-NEXT:    [[BVINDEXPTR:%.*]] = bitcast i32* [[ARRAYIDX]] to <6 x i32>*
; CHECK-NEXT:    [[BVINDEXV:%.*]] = load <6 x i32>, <6 x i32>* [[BVINDEXPTR]], align 1
; CHECK-NEXT:    [[BBPTR:%.*]] = getelementptr inbounds [6 x float], [6 x float]* [[BB]], i64 0, <6 x i32> [[BVINDEXV]]
; CHECK-NEXT:    [[BBV:%.*]] = call <6 x float> @llvm.masked.gather.v6f32.v6p0f32(<6 x float*> [[BBPTR]], i32 1, <6 x i1> <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>, <6 x float> undef)
; CHECK-NEXT:    [[STARTPTR:%.*]] = bitcast float* [[ARRAYIDX1]] to <3 x float>*
; CHECK-NEXT:    [[STARTV:%.*]] = load <3 x float>, <3 x float>* [[STARTPTR]], align 1
; CHECK-NEXT:    [[STARTWIDENV:%.*]] = shufflevector <3 x float> [[STARTV]], <3 x float> undef, <6 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2>
; CHECK-NEXT:    [[IDOTAXISPTR:%.*]] = bitcast float* [[ARRAYIDX2]] to <3 x float>*
; CHECK-NEXT:    [[IDOTAXISV:%.*]] = load <3 x float>, <3 x float>* [[IDOTAXISPTR]], align 1
; CHECK-NEXT:    [[IDOTAXISWIDENV:%.*]] = shufflevector <3 x float> [[IDOTAXISV]], <3 x float> undef, <6 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2>
; CHECK-NEXT:    [[TMP0:%.*]] = fsub <6 x float> [[BBV]], [[STARTWIDENV]]
; CHECK-NEXT:    [[T:%.*]] = fmul <6 x float> [[TMP0]], [[IDOTAXISWIDENV]]
; CHECK-NEXT:    [[T1:%.*]] = shufflevector <6 x float> [[T]], <6 x float> undef, <8 x i32> <i32 0, i32 0, i32 2, i32 2, i32 4, i32 4, i32 4, i32 4>
; CHECK-NEXT:    [[T2:%.*]] = shufflevector <6 x float> [[T]], <6 x float> undef, <8 x i32> <i32 3, i32 5, i32 5, i32 1, i32 1, i32 3, i32 1, i32 3>
; CHECK-NEXT:    [[T1CMPT2:%.*]] = fcmp ogt <8 x float> [[T1]], [[T2]]
; CHECK-NEXT:    [[T2LT0:%.*]] = fcmp olt <8 x float> [[T2]], zeroinitializer
; CHECK-NEXT:    [[OR:%.*]] = or <8 x i1> [[T1CMPT2]], [[T2LT0]]
; CHECK-NEXT:    [[TMP1:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[OR]])
; CHECK-NEXT:    [[OR_COND133:%.*]] = or i1 [[CMP61]], [[OR_COND132]]
; CHECK-NEXT:    [[CMP62:%.*]] = fcmp fast olt float [[MUL12]], 0.000000e+00
; CHECK-NEXT:    [[CMP64:%.*]] = fcmp fast olt float [[MUL32]], 0.000000e+00
; CHECK-NEXT:    [[OR_COND:%.*]] = or i1 [[CMP62]], [[CMP64]]
; CHECK-NEXT:    [[CMP66:%.*]] = fcmp fast olt float [[MUL52]], 0.000000e+00
; CHECK-NEXT:    [[OR_COND84:%.*]] = or i1 [[OR_COND]], [[CMP66]]
; CHECK-NEXT:    [[OR_COND4:%.*]] = or i1 [[OR_COND133]], [[OR_COND84]]
; CHECK-NEXT:    br i1 [[TMP1]], label [[CLEANUP:%.*]], label [[_ZL17BVH_NODE_HIT_TESTI8VBVHNODEEIPT_P5ISECT_EXIT:%.*]], !unpredictable !0
; CHECK:       _ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit:
; CHECK-NEXT:    [[DIST_PTR:%.*]] = getelementptr inbounds [[STRUCT_ISECT]], %struct.Isect* [[ISEC]], i64 0, i32 2
; CHECK-NEXT:    [[DIST:%.*]] = load float, float* [[DIST_PTR]], align 8
; CHECK-NEXT:    [[CMP69:%.*]] = fcmp fast ogt float [[MUL]], [[DIST]]
; CHECK-NEXT:    [[CMP72:%.*]] = fcmp fast ogt float [[MUL22]], [[DIST]]
; CHECK-NEXT:    [[OR_COND134:%.*]] = or i1 [[CMP69]], [[CMP72]]
; CHECK-NEXT:    [[CMP75:%.*]] = fcmp fast ogt float [[MUL42]], [[DIST]]
; CHECK-NEXT:    [[SPLATDIST_SPLATINSERT:%.*]] = insertelement <8 x float> undef, float [[DIST]], i32 0
; CHECK-NEXT:    [[SPLATDIST_SPLAT:%.*]] = shufflevector <8 x float> [[SPLATDIST_SPLATINSERT]], <8 x float> undef, <8 x i32> zeroinitializer
; CHECK-NEXT:    [[T2GTDIST:%.*]] = fcmp ogt <8 x float> [[T1]], [[SPLATDIST_SPLAT]]
; CHECK-NEXT:    [[TMP2:%.*]] = call i1 @llvm.vector.reduce.or.v8i1(<8 x i1> [[T2GTDIST]])
; CHECK-NEXT:    [[OR_COND135:%.*]] = or i1 [[CMP75]], [[OR_COND134]]
; CHECK-NEXT:    [[NOT_OR_COND135:%.*]] = xor i1 [[TMP2]], true
; CHECK-NEXT:    [[ZEXT_0:%.*]] = zext i1 [[NOT_OR_COND135]] to i32
; CHECK-NEXT:    [[TOBOOL6:%.*]] = icmp eq i32 [[ZEXT_0]], 0
; CHECK-NEXT:    [[SPEC_SELECT:%.*]] = select i1 [[TOBOOL6]], i32 0, i32 1
; CHECK-NEXT:    ret i32 [[SPEC_SELECT]]
; CHECK:       cleanup:
; CHECK-NEXT:    ret i32 0
;
entry:                                         ;
  %bb = getelementptr inbounds %struct.VBVHNode, %struct.VBVHNode* %node, i64 0, i32 0
  %arraydecay = getelementptr inbounds [6 x float], [6 x float]* %bb, i64 0, i64 0
  %bv_index = getelementptr inbounds %struct.Isect, %struct.Isect* %isec, i64 0, i32 5
  %arrayidx = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 0
  %bv_index.v0 = load i32, i32* %arrayidx, align 4
  %idxprom = sext i32 %bv_index.v0 to i64
  %ptridx = getelementptr inbounds float, float* %arraydecay, i64 %idxprom
  %bb.0 = load float, float* %ptridx, align 4
  %start = getelementptr inbounds %struct.Isect, %struct.Isect* %isec, i64 0, i32 0
  %arrayidx1 = getelementptr inbounds [3 x float], [3 x float]* %start, i64 0, i64 0
  %start.0 = load float, float* %arrayidx1, align 8
  %sub = fsub fast float %bb.0, %start.0
  %idot_axis = getelementptr inbounds %struct.Isect, %struct.Isect* %isec, i64 0, i32 6
  %arrayidx2 = getelementptr inbounds [3 x float], [3 x float]* %idot_axis, i64 0, i64 0
  %idot_axis.0 = load float, float* %arrayidx2, align 4
  %mul = fmul fast float %sub, %idot_axis.0
  %arrayidx4 = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 1
  %bv_index.v1 = load i32, i32* %arrayidx4, align 4
  %idxprom5 = sext i32 %bv_index.v1 to i64
  %ptridx6 = getelementptr inbounds float, float* %arraydecay, i64 %idxprom5
  %bb.1 = load float, float* %ptridx6, align 4
  %sub9 = fsub fast float %bb.1, %start.0
  %mul12 = fmul fast float %sub9, %idot_axis.0
  %arrayidx14 = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 2
  %bv_index.v2 = load i32, i32* %arrayidx14, align 4
  %idxprom15 = sext i32 %bv_index.v2 to i64
  %ptridx16 = getelementptr inbounds float, float* %arraydecay, i64 %idxprom15
  %bb.2 = load float, float* %ptridx16, align 4
  %arrayidx18 = getelementptr inbounds [3 x float], [3 x float]* %start, i64 0, i64 1
  %start.1 = load float, float* %arrayidx18, align 4
  %sub19 = fsub fast float %bb.2, %start.1
  %arrayidx21 = getelementptr inbounds [3 x float], [3 x float]* %idot_axis, i64 0, i64 1
  %idot_axis.1 = load float, float* %arrayidx21, align 4
  %mul22 = fmul fast float %sub19, %idot_axis.1
  %arrayidx24 = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 3
  %bv_index.v3 = load i32, i32* %arrayidx24, align 4
  %idxprom25 = sext i32 %bv_index.v3 to i64
  %ptridx26 = getelementptr inbounds float, float* %arraydecay, i64 %idxprom25
  %bb.3 = load float, float* %ptridx26, align 4
  %sub29 = fsub fast float %bb.3, %start.1
  %mul32 = fmul fast float %sub29, %idot_axis.1
  %arrayidx34 = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 4
  %bv_index.v4 = load i32, i32* %arrayidx34, align 4
  %idxprom35 = sext i32 %bv_index.v4 to i64
  %ptridx36 = getelementptr inbounds float, float* %arraydecay, i64 %idxprom35
  %bb.4 = load float, float* %ptridx36, align 4
  %arrayidx38 = getelementptr inbounds [3 x float], [3 x float]* %start, i64 0, i64 2
  %start.2 = load float, float* %arrayidx38, align 8
  %sub39 = fsub fast float %bb.4, %start.2
  %arrayidx41 = getelementptr inbounds [3 x float], [3 x float]* %idot_axis, i64 0, i64 2
  %idot_axis.2 = load float, float* %arrayidx41, align 4
  %mul42 = fmul fast float %sub39, %idot_axis.2
  %arrayidx44 = getelementptr inbounds [6 x i32], [6 x i32]* %bv_index, i64 0, i64 5
  %bv_index.v5 = load i32, i32* %arrayidx44, align 4
  %idxprom45 = sext i32 %bv_index.v5 to i64
  %ptridx46 = getelementptr inbounds float, float* %arraydecay, i64 %idxprom45
  %bb.5 = load float, float* %ptridx46, align 4
  %sub49 = fsub fast float %bb.5, %start.2
  %mul52 = fmul fast float %sub49, %idot_axis.2
  %cmp.i35 = fcmp fast ogt float %mul, %mul32
  %cmp53 = fcmp fast olt float %mul12, %mul22
  %or.cond129 = or i1 %cmp53, %cmp.i35
  %cmp55 = fcmp fast ogt float %mul, %mul52
  %or.cond130 = or i1 %or.cond129, %cmp55
  %cmp57 = fcmp fast olt float %mul12, %mul42
  %or.cond131 = or i1 %cmp57, %or.cond130
  %cmp59 = fcmp fast ogt float %mul22, %mul52
  %or.cond132 = or i1 %cmp59, %or.cond131
  %cmp61 = fcmp fast olt float %mul32, %mul42
  %or.cond133 = or i1 %cmp61, %or.cond132
  br i1 %or.cond133, label %cleanup, label %if.end

if.end:                                       ; preds = %if.then4
  %cmp62 = fcmp fast olt float %mul12, 0.000000e+00
  %cmp64 = fcmp fast olt float %mul32, 0.000000e+00
  %or.cond = or i1 %cmp62, %cmp64
  %cmp66 = fcmp fast olt float %mul52, 0.000000e+00
  %or.cond84 = or i1 %or.cond, %cmp66
  br i1 %or.cond84, label %cleanup, label %_ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit

_ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit: ; preds = %if.end
  %dist.ptr = getelementptr inbounds %struct.Isect, %struct.Isect* %isec, i64 0, i32 2
  %dist = load float, float* %dist.ptr, align 8
  %cmp69 = fcmp fast ogt float %mul, %dist
  %cmp72 = fcmp fast ogt float %mul22, %dist
  %or.cond134 = or i1 %cmp69, %cmp72
  %cmp75 = fcmp fast ogt float %mul42, %dist
  %or.cond135 = or i1 %cmp75, %or.cond134
  %not.or.cond135 = xor i1 %or.cond135, true
  %zext.0 = zext i1 %not.or.cond135 to i32
  %tobool6 = icmp eq i32 %zext.0, 0
  br i1 %tobool6, label %cleanup, label %if.then7

if.then7:                                         ; preds = %_ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit
  br label %cleanup

cleanup:                                        ; preds = %if.then7, %_ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit, %if.end, %entry
  %retval = phi i32 [ 1, %if.then7 ], [ 0, %_ZL17bvh_node_hit_testI8VBVHNodeEiPT_P5Isect.exit ], [0, %if.end ], [ 0, %entry ]
  ret i32 %retval
}

