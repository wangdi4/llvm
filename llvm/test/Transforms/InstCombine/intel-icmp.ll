; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; This test checks that comparison sizes are optimized and
; unnecessary sext/zext or other instructions are eliminated
;
; RUN: opt < %s -instcombine -S -mtriple=x86_64-unknown-linux-gnu | FileCheck %s

target datalayout = "n8:16:32:64"

define i32 @test_s32_to_s8(i32 %a, i8 %b) {
; CHECK-LABEL: @test_s32_to_s8(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], 127
; CHECK-NEXT:    [[E:%.*]] = icmp sge i8 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 127
  %d = sext i8 %b to i32
  %e = icmp sge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_s32_to_s16(i32 %a, i16 %b) {
; CHECK-LABEL: @test_s32_to_s16(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i16
; CHECK-NEXT:    [[TMP2:%.*]] = and i16 [[TMP1]], 1000
; CHECK-NEXT:    [[E:%.*]] = icmp sge i16 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 1000
  %d = sext i16 %b to i32
  %e = icmp sge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_s64_to_s32(i64 %a, i32 %b) {
; CHECK-LABEL: @test_s64_to_s32(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = and i32 [[TMP1]], 2147483647
; CHECK-NEXT:    [[E:%.*]] = icmp sge i32 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i64 %a, 2147483647
  %d = sext i32 %b to i64
  %e = icmp sge i64 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u8(i32 %a, i8 %b) {
; CHECK-LABEL: @test_u32_to_u8(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -2
; CHECK-NEXT:    [[E:%.*]] = icmp uge i8 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 254
  %d = zext i8 %b to i32
  %e = icmp uge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u16(i32 %a, i16 %b) {
; CHECK-LABEL: @test_u32_to_u16(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i16
; CHECK-NEXT:    [[TMP2:%.*]] = and i16 [[TMP1]], 1000
; CHECK-NEXT:    [[E:%.*]] = icmp uge i16 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 1000
  %d = zext i16 %b to i32
  %e = icmp uge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u64_to_u32(i64 %a, i32 %b) {
; CHECK-LABEL: @test_u64_to_u32(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = and i32 [[TMP1]], -2
; CHECK-NEXT:    [[E:%.*]] = icmp uge i32 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i64 %a, 4294967294
  %d = zext i32 %b to i64
  %e = icmp uge i64 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_s64_to_u32(i64 %a, i32 %b) {
; CHECK-LABEL: @test_s64_to_u32(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[A:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = and i32 [[TMP1]], -2
; CHECK-NEXT:    [[E:%.*]] = icmp uge i32 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i64 %a, 4294967294
  %d = zext i32 %b to i64
  %e = icmp sge i64 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_s32_to_u8(i32 %a, i8 %b) {
; CHECK-LABEL: @test_s32_to_u8(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -2
; CHECK-NEXT:    [[E:%.*]] = icmp uge i8 [[TMP2]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 254
  %d = zext i8 %b to i32
  %e = icmp sge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_s32_to_s8_two_sext(i8 %a, i8 %b) {
; CHECK-LABEL: @test_s32_to_s8_two_sext(
; CHECK-NEXT:    [[E:%.*]] = icmp sge i8 [[A:%.*]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %a1 = sext i8 %a to i32
  %b1 = sext i8 %b to i32
  %e = icmp sge i32 %a1, %b1
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u8_two_zext(i8 %a, i8 %b) {
; CHECK-LABEL: @test_u32_to_u8_two_zext(
; CHECK-NEXT:    [[E:%.*]] = icmp uge i8 [[A:%.*]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %a1 = zext i8 %a to i32
  %b1 = zext i8 %b to i32
  %e = icmp uge i32 %a1, %b1
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u8_different_zext(i8 %a, i16 %b) {
; CHECK-LABEL: @test_u32_to_u8_different_zext(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i8 [[A:%.*]] to i16
; CHECK-NEXT:    [[E:%.*]] = icmp uge i16 [[TMP1]], [[B:%.*]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %a1 = zext i8 %a to i32
  %b1 = zext i16 %b to i32
  %e = icmp uge i32 %a1, %b1
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u8_two_and(i32 %a, i32 %b) {
; CHECK-LABEL: @test_u32_to_u8_two_and(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = trunc i32 [[B:%.*]] to i8
; CHECK-NEXT:    [[E:%.*]] = icmp uge i8 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 255
  %d = and i32 %b, 255
  %e = icmp uge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u16_different_and(i32 %a, i32 %b) {
; CHECK-LABEL: @test_u32_to_u16_different_and(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i16
; CHECK-NEXT:    [[TMP2:%.*]] = trunc i32 [[B:%.*]] to i16
; CHECK-NEXT:    [[TMP3:%.*]] = and i16 [[TMP2]], 255
; CHECK-NEXT:    [[E:%.*]] = icmp ule i16 [[TMP3]], [[TMP1]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 65535
  %d = and i32 %b, 255
  %e = icmp uge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

; Compare in the result gets reversed due to operand complexity sorting
define i32 @test_u32_to_u8_and(i32 %a, i32 %b) {
; CHECK-LABEL: @test_u32_to_u8_and(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = trunc i32 [[B:%.*]] to i8
; CHECK-NEXT:    [[TMP3:%.*]] = and i8 [[TMP2]], -84
; CHECK-NEXT:    [[E:%.*]] = icmp ule i8 [[TMP3]], [[TMP1]]
; CHECK-NEXT:    [[E1:%.*]] = sext i1 [[E]] to i32
; CHECK-NEXT:    ret i32 [[E1]]
;
  %c = and i32 %a, 255
  %d = and i32 %b, 172
  %e = icmp uge i32 %c, %d
  %e1 = sext i1 %e to i32
  ret i32 %e1
}

define i32 @test_u32_to_u8_shift(i32 %a, i32 %b) {
; CHECK-LABEL: @test_u32_to_u8_shift(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -84
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[B:%.*]] to i8
; CHECK-NEXT:    [[F:%.*]] = icmp uge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[F1:%.*]] = sext i1 [[F]] to i32
; CHECK-NEXT:    ret i32 [[F1]]
;
  %c = and i32 %a, 172
  %d = shl i32 %b, 24
  %e = lshr i32 %d, 24
  %f = icmp uge i32 %c, %e
  %f1 = sext i1 %f to i32
  ret i32 %f1
}

define i32 @test_u32_to_u8_shift_binop(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_u32_to_u8_shift_binop(
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[C:%.*]], 24
; CHECK-NEXT:    [[E2:%.*]] = add i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -84
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[E2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp uge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 172
  %e = shl i32 %b, 24
  %f = add i32 %e, %c
  %g = lshr i32 %f, 24
  %h = icmp uge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; Same as above with add operands commuted
define i32 @test_u32_to_u8_shift_binop2(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_u32_to_u8_shift_binop2(
; CHECK-NEXT:    [[Q:%.*]] = mul i32 [[C:%.*]], 57
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[Q]], 24
; CHECK-NEXT:    [[Q2:%.*]] = add i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -84
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[Q2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp uge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 172
  %e = shl i32 %b, 24
  %q = mul i32 %c, 57 ; to thwart operand complexity sorting on the add
  %f = add i32 %q, %e
  %g = lshr i32 %f, 24
  %h = icmp uge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; We cannot reduce the compare width because the shl is on the LHS of the sub so the shifts won't be removed
define i32 @test_u32_to_u8_shift_sub(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_u32_to_u8_shift_sub(
; CHECK-NEXT:    [[D:%.*]] = and i32 [[A:%.*]], 172
; CHECK-NEXT:    [[E:%.*]] = shl i32 [[B:%.*]], 24
; CHECK-NEXT:    [[F:%.*]] = sub i32 [[E]], [[C:%.*]]
; CHECK-NEXT:    [[G:%.*]] = lshr i32 [[F]], 24
; CHECK-NEXT:    [[H:%.*]] = icmp uge i32 [[D]], [[G]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 172
  %e = shl i32 %b, 24
  %f = sub i32 %e, %c
  %g = lshr i32 %f, 24
  %h = icmp uge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; Same as above with sub operands commuted
define i32 @test_u32_to_u8_shift_sub2(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_u32_to_u8_shift_sub2(
; INTEL_CUSTOMIZATION
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[C:%.*]], 24
; CHECK-NEXT:    [[C2:%.*]] = sub i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], -84
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[C2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp uge i8 [[TMP2]], [[TMP3]]
; end INTEL_CUSTOMIZATION
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 172
  %e = shl i32 %b, 24
  %f = sub i32 %c, %e
  %g = lshr i32 %f, 24
  %h = icmp uge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

define i32 @test_s32_to_s8_ashift(i32 %a, i32 %b) {
; CHECK-LABEL: @test_s32_to_s8_ashift(
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], 62
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[B:%.*]] to i8
; CHECK-NEXT:    [[F:%.*]] = icmp sge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[F1:%.*]] = sext i1 [[F]] to i32
; CHECK-NEXT:    ret i32 [[F1]]
;
  %c = and i32 %a, 62
  %d = shl i32 %b, 24
  %e = ashr i32 %d, 24
  %f = icmp sge i32 %c, %e
  %f1 = sext i1 %f to i32
  ret i32 %f1
}

define i32 @test_s32_to_s8_ashift_binop(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_s32_to_s8_ashift_binop(
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[C:%.*]], 24
; CHECK-NEXT:    [[E2:%.*]] = add i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], 62
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[E2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp sge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 62
  %e = shl i32 %b, 24
  %f = add i32 %e, %c
  %g = ashr i32 %f, 24
  %h = icmp sge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; Same as above with add operands commuted
define i32 @test_s32_to_s8_ashift_binop2(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_s32_to_s8_ashift_binop2(
; CHECK-NEXT:    [[Q:%.*]] = mul i32 [[C:%.*]], 57
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[Q]], 24
; CHECK-NEXT:    [[Q2:%.*]] = add i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], 62
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[Q2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp sge i8 [[TMP2]], [[TMP3]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 62
  %e = shl i32 %b, 24
  %q = mul i32 %c, 57 ; to thwart operand complexity sorting on the add
  %f = add i32 %q, %e
  %g = ashr i32 %f, 24
  %h = icmp sge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; We cannot reduce the compare width because the shl is on the LHS of the sub so the shifts won't be removed
define i32 @test_s32_to_s8_ashift_sub(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_s32_to_s8_ashift_sub(
; CHECK-NEXT:    [[D:%.*]] = and i32 [[A:%.*]], 62
; CHECK-NEXT:    [[E:%.*]] = shl i32 [[B:%.*]], 24
; CHECK-NEXT:    [[F:%.*]] = sub i32 [[E]], [[C:%.*]]
; CHECK-NEXT:    [[G:%.*]] = ashr i32 [[F]], 24
; CHECK-NEXT:    [[H:%.*]] = icmp sge i32 [[D]], [[G]]
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 62
  %e = shl i32 %b, 24
  %f = sub i32 %e, %c
  %g = ashr i32 %f, 24
  %h = icmp sge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

; Same as above with sub operands commuted
define i32 @test_s32_to_s8_ashift_sub2(i32 %a, i32 %b, i32 %c) {
; CHECK-LABEL: @test_s32_to_s8_ashift_sub2(
; INTEL_CUSTOMIZATION
; CHECK-NEXT:    [[F1:%.*]] = lshr i32 [[C:%.*]], 24
; CHECK-NEXT:    [[C2:%.*]] = sub i32 [[F1]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = trunc i32 [[A:%.*]] to i8
; CHECK-NEXT:    [[TMP2:%.*]] = and i8 [[TMP1]], 62
; CHECK-NEXT:    [[TMP3:%.*]] = trunc i32 [[C2]] to i8
; CHECK-NEXT:    [[H:%.*]] = icmp sge i8 [[TMP2]], [[TMP3]]
; end INTEL_CUSTOMIZATION
; CHECK-NEXT:    [[H1:%.*]] = sext i1 [[H]] to i32
; CHECK-NEXT:    ret i32 [[H1]]
;
  %d = and i32 %a, 62
  %e = shl i32 %b, 24
  %f = sub i32 %c, %e
  %g = ashr i32 %f, 24
  %h = icmp sge i32 %d, %g
  %h1 = sext i1 %h to i32
  ret i32 %h1
}

define void @test_icmp_sub_sub(i32* %p1, i32* %p2, i32 %g, i32 %gh) {
; CHECK-LABEL: @test_icmp_sub_sub(
; CHECK-NEXT:    [[I2:%.*]] = load i32, i32* [[P1:%.*]], align 4
; CHECK-NEXT:    [[SUB17:%.*]] = sub nsw i32 [[I2]], [[GH:%.*]]
; CHECK-NEXT:    store i32 [[SUB17]], i32* [[P1]], align 4
; CHECK-NEXT:    [[I3:%.*]] = load i32, i32* [[P2:%.*]], align 4
; CHECK-NEXT:    [[I20:%.*]] = add nsw i32 [[I3]], [[G:%.*]]
; CHECK-NEXT:    [[CMP24:%.*]] = icmp slt i32 [[I2]], [[I20]]
; CHECK-NEXT:    br i1 [[CMP24]], label [[IF_THEN25:%.*]], label [[IF_END28:%.*]]
; CHECK:       if.then25:
; CHECK-NEXT:    [[SUB21:%.*]] = sub nsw i32 [[I20]], [[GH]]
; CHECK-NEXT:    store i32 [[SUB21]], i32* [[P1]], align 4
; CHECK-NEXT:    br label [[IF_END28]]
; CHECK:       if.end28:
; CHECK-NEXT:    br label [[END:%.*]]
; CHECK:       end:
; CHECK-NEXT:    ret void
;
  %i2 = load i32, i32* %p1, align 4
  %sub17 = sub nsw i32 %i2, %gh
  store i32 %sub17, i32* %p1, align 4
  %i3 = load i32, i32* %p2, align 4
  %i20 = add nsw i32 %i3, %g
  %sub21 = sub nsw i32 %i20, %gh
; The icmp operands below are "%i2 - %gh" and "%i20 - %gh".
; If instcombine transform replaces the operands with "%i2" and "%i20"
; it specifically appears a problem for -simplifycfg pass making it unable
; to convert if-then into select.
  %cmp24 = icmp slt i32 %sub17, %sub21
  br i1 %cmp24, label %if.then25, label %if.end28

if.then25:
  store i32 %sub21, i32* %p1, align 4
  br label %if.end28

if.end28:
  br label %end

end:
  ret void
}
