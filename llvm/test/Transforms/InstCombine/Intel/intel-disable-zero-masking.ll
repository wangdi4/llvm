; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -opaque-pointers=0 -passes="instcombine" -S -mtriple=i686-linux -mattr=+avx512f,+avx512vl,+avx512dq -enable-intel-advanced-opts=true %s | FileCheck %s

; Function Attrs: nofree nosync nounwind uwtable
define dso_local void @disable-zero-masking(i64* noalias %vec_ptr, i32* noalias %cnt_ptr, i64* noalias %mat_ptr, i64 %offset) {
; CHECK-LABEL: @disable-zero-masking(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i64* [[MAT_PTR:%.*]] to <8 x i64>*
; CHECK-NEXT:    [[TMP1:%.*]] = load <8 x i64>, <8 x i64>* [[TMP0]], align 64
; CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 8
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i64* [[ARRAYIDX1]] to <8 x i64>*
; CHECK-NEXT:    [[TMP3:%.*]] = load <8 x i64>, <8 x i64>* [[TMP2]], align 64
; CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 16
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i64* [[ARRAYIDX3]] to <8 x i64>*
; CHECK-NEXT:    [[TMP5:%.*]] = load <8 x i64>, <8 x i64>* [[TMP4]], align 64
; CHECK-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 24
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i64* [[ARRAYIDX5]] to <8 x i64>*
; CHECK-NEXT:    [[TMP7:%.*]] = load <8 x i64>, <8 x i64>* [[TMP6]], align 64
; CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 32
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i64* [[ARRAYIDX7]] to <8 x i64>*
; CHECK-NEXT:    [[TMP9:%.*]] = load <8 x i64>, <8 x i64>* [[TMP8]], align 64
; CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 40
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i64* [[ARRAYIDX9]] to <8 x i64>*
; CHECK-NEXT:    [[TMP11:%.*]] = load <8 x i64>, <8 x i64>* [[TMP10]], align 64
; CHECK-NEXT:    [[ARRAYIDX11:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 48
; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i64* [[ARRAYIDX11]] to <8 x i64>*
; CHECK-NEXT:    [[TMP13:%.*]] = load <8 x i64>, <8 x i64>* [[TMP12]], align 64
; CHECK-NEXT:    [[ARRAYIDX13:%.*]] = getelementptr inbounds i64, i64* [[MAT_PTR]], i64 56
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast i64* [[ARRAYIDX13]] to <8 x i64>*
; CHECK-NEXT:    [[TMP15:%.*]] = load <8 x i64>, <8 x i64>* [[TMP14]], align 64
; CHECK-NEXT:    [[ARRAYIDX15:%.*]] = getelementptr inbounds i64, i64* [[VEC_PTR:%.*]], i64 [[OFFSET:%.*]]
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast i64* [[ARRAYIDX15]] to i8*
; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i64* [[ARRAYIDX15]] to <8 x i1>*
; CHECK-NEXT:    [[TMP18:%.*]] = load <8 x i1>, <8 x i1>* [[TMP17]], align 8
; CHECK-NEXT:    [[TMP19:%.*]] = select <8 x i1> [[TMP18]], <8 x i64> [[TMP1]], <8 x i64> zeroinitializer
; CHECK-NEXT:    [[ARRAYIDX19:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 1
; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i8* [[ARRAYIDX19]] to <8 x i1>*
; CHECK-NEXT:    [[TMP21:%.*]] = load <8 x i1>, <8 x i1>* [[TMP20]], align 1
; CHECK-NEXT:    [[XOR_I_I151:%.*]] = xor <8 x i64> [[TMP19]], [[TMP3]]
; CHECK-NEXT:    [[TMP22:%.*]] = select <8 x i1> [[TMP21]], <8 x i64> [[XOR_I_I151]], <8 x i64> [[TMP19]]
; CHECK-NEXT:    [[ARRAYIDX24:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 2
; CHECK-NEXT:    [[TMP23:%.*]] = bitcast i8* [[ARRAYIDX24]] to <8 x i1>*
; CHECK-NEXT:    [[TMP24:%.*]] = load <8 x i1>, <8 x i1>* [[TMP23]], align 2
; CHECK-NEXT:    [[XOR_I_I150:%.*]] = xor <8 x i64> [[TMP22]], [[TMP5]]
; CHECK-NEXT:    [[TMP25:%.*]] = select <8 x i1> [[TMP24]], <8 x i64> [[XOR_I_I150]], <8 x i64> [[TMP22]]
; CHECK-NEXT:    [[ARRAYIDX29:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 3
; CHECK-NEXT:    [[TMP26:%.*]] = bitcast i8* [[ARRAYIDX29]] to <8 x i1>*
; CHECK-NEXT:    [[TMP27:%.*]] = load <8 x i1>, <8 x i1>* [[TMP26]], align 1
; CHECK-NEXT:    [[XOR_I_I149:%.*]] = xor <8 x i64> [[TMP25]], [[TMP7]]
; CHECK-NEXT:    [[TMP28:%.*]] = select <8 x i1> [[TMP27]], <8 x i64> [[XOR_I_I149]], <8 x i64> [[TMP25]]
; CHECK-NEXT:    [[ARRAYIDX34:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 4
; CHECK-NEXT:    [[TMP29:%.*]] = bitcast i8* [[ARRAYIDX34]] to <8 x i1>*
; CHECK-NEXT:    [[TMP30:%.*]] = load <8 x i1>, <8 x i1>* [[TMP29]], align 4
; CHECK-NEXT:    [[XOR_I_I148:%.*]] = xor <8 x i64> [[TMP28]], [[TMP9]]
; CHECK-NEXT:    [[TMP31:%.*]] = select <8 x i1> [[TMP30]], <8 x i64> [[XOR_I_I148]], <8 x i64> [[TMP28]]
; CHECK-NEXT:    [[ARRAYIDX39:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 5
; CHECK-NEXT:    [[TMP32:%.*]] = bitcast i8* [[ARRAYIDX39]] to <8 x i1>*
; CHECK-NEXT:    [[TMP33:%.*]] = load <8 x i1>, <8 x i1>* [[TMP32]], align 1
; CHECK-NEXT:    [[XOR_I_I147:%.*]] = xor <8 x i64> [[TMP31]], [[TMP11]]
; CHECK-NEXT:    [[TMP34:%.*]] = select <8 x i1> [[TMP33]], <8 x i64> [[XOR_I_I147]], <8 x i64> [[TMP31]]
; CHECK-NEXT:    [[ARRAYIDX44:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 6
; CHECK-NEXT:    [[TMP35:%.*]] = bitcast i8* [[ARRAYIDX44]] to <8 x i1>*
; CHECK-NEXT:    [[TMP36:%.*]] = load <8 x i1>, <8 x i1>* [[TMP35]], align 2
; CHECK-NEXT:    [[XOR_I_I146:%.*]] = xor <8 x i64> [[TMP34]], [[TMP13]]
; CHECK-NEXT:    [[TMP37:%.*]] = select <8 x i1> [[TMP36]], <8 x i64> [[XOR_I_I146]], <8 x i64> [[TMP34]]
; CHECK-NEXT:    [[ARRAYIDX49:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i64 7
; CHECK-NEXT:    [[TMP38:%.*]] = bitcast i8* [[ARRAYIDX49]] to <8 x i1>*
; CHECK-NEXT:    [[TMP39:%.*]] = load <8 x i1>, <8 x i1>* [[TMP38]], align 1
; CHECK-NEXT:    [[XOR_I_I:%.*]] = xor <8 x i64> [[TMP37]], [[TMP15]]
; CHECK-NEXT:    [[TMP40:%.*]] = select <8 x i1> [[TMP39]], <8 x i64> [[XOR_I_I]], <8 x i64> [[TMP37]]
; CHECK-NEXT:    [[SHUFFLE_I145:%.*]] = shufflevector <8 x i64> [[TMP40]], <8 x i64> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[EXTRACT:%.*]] = shufflevector <8 x i64> [[TMP40]], <8 x i64> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
; CHECK-NEXT:    [[XOR_I144:%.*]] = xor <4 x i64> [[EXTRACT]], [[SHUFFLE_I145]]
; CHECK-NEXT:    [[SHUFFLE_I:%.*]] = shufflevector <4 x i64> [[XOR_I144]], <4 x i64> poison, <2 x i32> <i32 0, i32 1>
; CHECK-NEXT:    [[EXTRACT59:%.*]] = shufflevector <4 x i64> [[XOR_I144]], <4 x i64> poison, <2 x i32> <i32 2, i32 3>
; CHECK-NEXT:    [[XOR_I143:%.*]] = xor <2 x i64> [[EXTRACT59]], [[SHUFFLE_I]]
; CHECK-NEXT:    [[TMP41:%.*]] = bitcast <2 x i64> [[XOR_I143]] to <4 x i32>
; CHECK-NEXT:    [[PERMIL:%.*]] = shufflevector <4 x i32> [[TMP41]], <4 x i32> poison, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
; CHECK-NEXT:    [[TMP42:%.*]] = bitcast <4 x i32> [[PERMIL]] to <2 x i64>
; CHECK-NEXT:    [[XOR_I:%.*]] = xor <2 x i64> [[XOR_I143]], [[TMP42]]
; CHECK-NEXT:    [[TMP43:%.*]] = extractelement <2 x i64> [[XOR_I]], i64 0
; CHECK-NEXT:    [[SHR:%.*]] = lshr i64 [[TMP43]], 32
; CHECK-NEXT:    [[OR:%.*]] = or i64 [[TMP43]], [[SHR]]
; CHECK-NEXT:    [[SHR62:%.*]] = lshr i64 [[OR]], 16
; CHECK-NEXT:    [[AND63:%.*]] = and i64 [[OR]], [[SHR62]]
; CHECK-NEXT:    [[AND64:%.*]] = and i64 [[AND63]], 255
; CHECK-NEXT:    [[SHR65:%.*]] = lshr i64 [[AND63]], 8
; CHECK-NEXT:    [[AND66:%.*]] = and i64 [[SHR65]], 255
; CHECK-NEXT:    [[ADD:%.*]] = add nuw nsw i64 [[AND64]], [[AND66]]
; CHECK-NEXT:    [[ARRAYIDX67:%.*]] = getelementptr inbounds i32, i32* [[CNT_PTR:%.*]], i64 [[ADD]]
; CHECK-NEXT:    [[TMP44:%.*]] = load i32, i32* [[ARRAYIDX67]], align 4
; CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP44]], 1
; CHECK-NEXT:    store i32 [[INC]], i32* [[ARRAYIDX67]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %0 = bitcast i64* %mat_ptr to i8*
  %1 = bitcast i64* %vec_ptr to i8*
  %2 = bitcast i32* %cnt_ptr to i8*
  %3 = bitcast i8* %0 to <8 x i64>*
  %4 = load <8 x i64>, <8 x i64>* %3, align 64
  %arrayidx1 = getelementptr inbounds i64, i64* %mat_ptr, i64 8
  %5 = bitcast i64* %arrayidx1 to i8*
  %6 = bitcast i8* %5 to <8 x i64>*
  %7 = load <8 x i64>, <8 x i64>* %6, align 64
  %arrayidx3 = getelementptr inbounds i64, i64* %mat_ptr, i64 16
  %8 = bitcast i64* %arrayidx3 to i8*
  %9 = bitcast i8* %8 to <8 x i64>*
  %10 = load <8 x i64>, <8 x i64>* %9, align 64
  %arrayidx5 = getelementptr inbounds i64, i64* %mat_ptr, i64 24
  %11 = bitcast i64* %arrayidx5 to i8*
  %12 = bitcast i8* %11 to <8 x i64>*
  %13 = load <8 x i64>, <8 x i64>* %12, align 64
  %arrayidx7 = getelementptr inbounds i64, i64* %mat_ptr, i64 32
  %14 = bitcast i64* %arrayidx7 to i8*
  %15 = bitcast i8* %14 to <8 x i64>*
  %16 = load <8 x i64>, <8 x i64>* %15, align 64
  %arrayidx9 = getelementptr inbounds i64, i64* %mat_ptr, i64 40
  %17 = bitcast i64* %arrayidx9 to i8*
  %18 = bitcast i8* %17 to <8 x i64>*
  %19 = load <8 x i64>, <8 x i64>* %18, align 64
  %arrayidx11 = getelementptr inbounds i64, i64* %mat_ptr, i64 48
  %20 = bitcast i64* %arrayidx11 to i8*
  %21 = bitcast i8* %20 to <8 x i64>*
  %22 = load <8 x i64>, <8 x i64>* %21, align 64
  %arrayidx13 = getelementptr inbounds i64, i64* %mat_ptr, i64 56
  %23 = bitcast i64* %arrayidx13 to i8*
  %24 = bitcast i8* %23 to <8 x i64>*
  %25 = load <8 x i64>, <8 x i64>* %24, align 64
  %arrayidx15 = getelementptr inbounds i64, i64* %vec_ptr, i64 %offset
  %26 = bitcast i64* %arrayidx15 to i8*
  %27 = load i8, i8* %26, align 8
  %28 = bitcast i8 %27 to <8 x i1>
  %29 = select <8 x i1> %28, <8 x i64> %4, <8 x i64> zeroinitializer
  %arrayidx19 = getelementptr inbounds i8, i8* %26, i64 1
  %30 = load i8, i8* %arrayidx19, align 1
  %xor.i.i151 = xor <8 x i64> %29, %7
  %31 = bitcast i8 %30 to <8 x i1>
  %32 = select <8 x i1> %31, <8 x i64> %xor.i.i151, <8 x i64> %29
  %arrayidx24 = getelementptr inbounds i8, i8* %26, i64 2
  %33 = load i8, i8* %arrayidx24, align 2
  %xor.i.i150 = xor <8 x i64> %32, %10
  %34 = bitcast i8 %33 to <8 x i1>
  %35 = select <8 x i1> %34, <8 x i64> %xor.i.i150, <8 x i64> %32
  %arrayidx29 = getelementptr inbounds i8, i8* %26, i64 3
  %36 = load i8, i8* %arrayidx29, align 1
  %xor.i.i149 = xor <8 x i64> %35, %13
  %37 = bitcast i8 %36 to <8 x i1>
  %38 = select <8 x i1> %37, <8 x i64> %xor.i.i149, <8 x i64> %35
  %arrayidx34 = getelementptr inbounds i8, i8* %26, i64 4
  %39 = load i8, i8* %arrayidx34, align 4
  %xor.i.i148 = xor <8 x i64> %38, %16
  %40 = bitcast i8 %39 to <8 x i1>
  %41 = select <8 x i1> %40, <8 x i64> %xor.i.i148, <8 x i64> %38
  %arrayidx39 = getelementptr inbounds i8, i8* %26, i64 5
  %42 = load i8, i8* %arrayidx39, align 1
  %xor.i.i147 = xor <8 x i64> %41, %19
  %43 = bitcast i8 %42 to <8 x i1>
  %44 = select <8 x i1> %43, <8 x i64> %xor.i.i147, <8 x i64> %41
  %arrayidx44 = getelementptr inbounds i8, i8* %26, i64 6
  %45 = load i8, i8* %arrayidx44, align 2
  %xor.i.i146 = xor <8 x i64> %44, %22
  %46 = bitcast i8 %45 to <8 x i1>
  %47 = select <8 x i1> %46, <8 x i64> %xor.i.i146, <8 x i64> %44
  %arrayidx49 = getelementptr inbounds i8, i8* %26, i64 7
  %48 = load i8, i8* %arrayidx49, align 1
  %xor.i.i = xor <8 x i64> %47, %25
  %49 = bitcast i8 %48 to <8 x i1>
  %50 = select <8 x i1> %49, <8 x i64> %xor.i.i, <8 x i64> %47
  %shuffle.i145 = shufflevector <8 x i64> %50, <8 x i64> poison, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %extract = shufflevector <8 x i64> %50, <8 x i64> poison, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
  %xor.i144 = xor <4 x i64> %extract, %shuffle.i145
  %shuffle.i = shufflevector <4 x i64> %xor.i144, <4 x i64> poison, <2 x i32> <i32 0, i32 1>
  %extract59 = shufflevector <4 x i64> %xor.i144, <4 x i64> poison, <2 x i32> <i32 2, i32 3>
  %xor.i143 = xor <2 x i64> %extract59, %shuffle.i
  %51 = bitcast <2 x i64> %xor.i143 to <4 x i32>
  %permil = shufflevector <4 x i32> %51, <4 x i32> poison, <4 x i32> <i32 2, i32 3, i32 2, i32 3>
  %52 = bitcast <4 x i32> %permil to <2 x i64>
  %xor.i = xor <2 x i64> %52, %xor.i143
  %53 = extractelement <2 x i64> %xor.i, i64 0
  %shr = lshr i64 %53, 32
  %or = or i64 %53, %shr
  %shr62 = lshr i64 %or, 16
  %and63 = and i64 %or, %shr62
  %and64 = and i64 %and63, 255
  %shr65 = lshr i64 %and63, 8
  %and66 = and i64 %shr65, 255
  %add = add nuw nsw i64 %and64, %and66
  %arrayidx67 = getelementptr inbounds i32, i32* %cnt_ptr, i64 %add
  %54 = load i32, i32* %arrayidx67, align 4
  %inc = add nsw i32 %54, 1
  store i32 %inc, i32* %arrayidx67, align 4
  ret void
}

