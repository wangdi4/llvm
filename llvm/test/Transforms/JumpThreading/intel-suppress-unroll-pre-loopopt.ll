; RUN: opt < %s -jump-threading -S | FileCheck %s
; RUN: opt < %s -passes=jump-threading -S | FileCheck %s

; Verify that a loop of trip count 2 is not 'unrolled' by jump threading if
; function has 'pre_loopopt' attribute.

; CHECK: for.body

define dso_local void @foo(i32* nocapture %p) "pre_loopopt" {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %p, i64 %indvars.iv
  %0 = trunc i64 %indvars.iv to i32
  store i32 %0, i32* %arrayidx, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp eq i64 %indvars.iv, 0
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body
  ret void
}

; Verify that loops gets 'unrolled' without 'pre_loopopt' attribute.
; CHECK-LABEL: foo1
; CHECK-NOT: for.body
; CHECK: store
; CHECK: store

define dso_local void @foo1(i32* nocapture %p) {
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %p, i64 %indvars.iv
  %0 = trunc i64 %indvars.iv to i32
  store i32 %0, i32* %arrayidx, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp eq i64 %indvars.iv, 0
  br i1 %cmp, label %for.body, label %for.cond.cleanup

for.cond.cleanup:                                 ; preds = %for.body
  ret void
}
