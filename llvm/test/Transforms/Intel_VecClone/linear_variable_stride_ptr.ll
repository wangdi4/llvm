; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -passes="vec-clone" -S < %s | FileCheck %s

; Test to check that VecClone calculates stride correctly for variable stride
; pointer case. Stride value should be loaded from C0 and cast to the same type
; as the loop index.

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: mustprogress noinline nounwind uwtable
define dso_local noundef i64 @_Z3foosPl(i16 noundef signext %c, i64* noundef %x) local_unnamed_addr #0 {
; CHECK:  define dso_local noundef <8 x i64> @_ZGVbN8uls0__Z3foosPl(i16 noundef signext [[C0:%.*]], i64* noundef [[X0:%.*]]) local_unnamed_addr #1 {
; CHECK-LABEL: simd.loop.preheader:
; CHECK-NEXT:    [[LOAD_X0:%.*]] = load i64*, i64** [[ALLOCA_X0:%.*]], align 8
; CHECK-NEXT:    [[LOAD_C0:%.*]] = load i16, i16* [[ALLOCA_C0:%.*]], align 2
; CHECK-NEXT:    br label [[SIMD_LOOP_HEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.header:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, %simd.loop.preheader ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[STRIDE_CAST0:%.*]] = zext i16 [[LOAD_C0]] to i32
; Stride calculation is here
; CHECK-NEXT:    [[STRIDE_MUL0:%.*]] = mul i32 [[STRIDE_CAST0]], [[INDEX0]]
; CHECK-NEXT:    [[LOAD_X_GEP0:%.*]] = getelementptr i64, i64* [[LOAD_X0]], i32 [[STRIDE_MUL0]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i64, i64* [[LOAD_X_GEP0]], align 8
; CHECK-NEXT:    [[ADD0:%.*]] = add nsw i64 [[TMP0]], 1
; CHECK-NEXT:    [[RET_CAST_GEP0:%.*]] = getelementptr i64, i64* [[RET_CAST0:%.*]], i32 [[INDEX0]]
; CHECK-NEXT:    store i64 [[ADD0]], i64* [[RET_CAST_GEP0]], align 8
; CHECK-NEXT:    br label [[SIMD_LOOP_LATCH0]]
entry:
  %0 = load i64, i64* %x, align 8
  %add = add nsw i64 %0, 1
  ret i64 %add
}

attributes #0 = { "vector-variants"="_ZGVbN8uls0__Z3foosPl" }
