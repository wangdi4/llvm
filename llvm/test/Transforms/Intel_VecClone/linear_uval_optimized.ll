; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -opaque-pointers=0 -passes="vec-clone" -S < %s | FileCheck %s

; Check code generated from VecClone for uval vector variant for optimized LLVM
; Stride should be applied to value loaded from the linear arg.

; Function Attrs: argmemonly mustprogress nofree noinline norecurse nosync nounwind readonly willreturn uwtable
define dso_local noundef i64 @_Z3fooRl(i64* nocapture noundef nonnull readonly align 8 dereferenceable(8) %x) local_unnamed_addr #0 {
; CHECK:  define dso_local noundef <8 x i64> @_ZGVbN8U2__Z3fooRl(i64* nocapture noundef nonnull readonly align 8 dereferenceable(8) [[X0:%.*]]) local_unnamed_addr #1 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ALLOCA_X0:%.*]] = alloca i64*, align 8
; CHECK-NEXT:    store i64* [[X0]], i64** [[ALLOCA_X0]], align 8
; CHECK-NEXT:    [[VEC_RETVAL0:%.*]] = alloca <8 x i64>, align 64
; CHECK-NEXT:    [[RET_CAST0:%.*]] = bitcast <8 x i64>* [[VEC_RETVAL0]] to i64*
; CHECK-NEXT:    [[ALLOCA_FAKE_X0:%.*]] = alloca <8 x i64>, align 64
; CHECK-NEXT:    %load.x1 = load i64*, i64** %alloca.x, align 8
; CHECK-NEXT:    %load.elem.x = load i64, i64* %load.x1, align 4
; CHECK-NEXT:    %.splatinsert = insertelement <8 x i64> poison, i64 %load.elem.x, i64 0
; CHECK-NEXT:    %.splat = shufflevector <8 x i64> %.splatinsert, <8 x i64> poison, <8 x i32> zeroinitializer
; CHECK-NEXT:    store <8 x i64> %.splat, <8 x i64>* [[ALLOCA_FAKE_X0]], align 64
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.begin.region:
; CHECK-NEXT:    [[ENTRY_REGION0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 8), "QUAL.OMP.LINEAR:TYPED"(i64** [[ALLOCA_X0]], i64* null, i32 1, i32 2) ]
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.preheader:
; CHECK-NEXT:    [[LOAD_X0:%.*]] = load i64*, i64** [[ALLOCA_X0]], align 8
; CHECK-NEXT:    br label [[SIMD_LOOP_HEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.header:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, [[SIMD_LOOP_PREHEADER0]] ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast <8 x i64>* [[ALLOCA_FAKE_X0]] to i64*
; CHECK-NEXT:    [[ALLOCA_FAKE_X0_GEP:%.*]] = getelementptr i64, i64* [[TMP0]], i32 [[INDEX0]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i64, i64* [[ALLOCA_FAKE_X0_GEP]], align 8
; CHECK-NEXT:    [[PHI_CAST0:%.*]] = zext i32 [[INDEX0]] to i64
; CHECK-NEXT:    [[STRIDE_MUL0:%.*]] = mul i64 2, [[PHI_CAST0]]
; CHECK-NEXT:    [[STRIDE_ADD0:%.*]] = add i64 [[TMP1]], [[STRIDE_MUL0]]
; CHECK-NEXT:    [[ADD0:%.*]] = add nsw i64 [[STRIDE_ADD0]], 1
; CHECK-NEXT:    [[RET_CAST_GEP0:%.*]] = getelementptr i64, i64* [[RET_CAST0]], i32 [[INDEX0]]
; CHECK-NEXT:    store i64 [[ADD0]], i64* [[RET_CAST_GEP0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.latch:
; CHECK-NEXT:    [[INDVAR0]] = add nuw nsw i32 [[INDEX0]], 1
; CHECK-NEXT:    [[VL_COND0:%.*]] = icmp ult i32 [[INDVAR0]], 8
; CHECK-NEXT:    br i1 [[VL_COND0]], label [[SIMD_LOOP_HEADER0]], label [[SIMD_END_REGION0:%.*]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  simd.end.region:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[ENTRY_REGION0]]) [ "DIR.OMP.END.SIMD"() ]
; CHECK-NEXT:    br label [[RETURN0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  return:
; CHECK-NEXT:    [[VEC_RET0:%.*]] = load <8 x i64>, <8 x i64>* [[VEC_RETVAL0]], align 64
; CHECK-NEXT:    ret <8 x i64> [[VEC_RET0]]
; CHECK-NEXT:  }
;
entry:
  %0 = load i64, i64* %x, align 8
  %add = add nsw i64 %0, 1
  ret i64 %add
}

attributes #0 = { argmemonly mustprogress nofree noinline norecurse nosync nounwind readonly willreturn uwtable "approx-func-fp-math"="true" "denormal-fp-math"="preserve-sign,preserve-sign" "frame-pointer"="none" "loopopt-pipeline"="full" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="skylake-avx512" "target-features"="+adx,+aes,+avx,+avx2,+avx512bw,+avx512cd,+avx512dq,+avx512f,+avx512vl,+bmi,+bmi2,+clflushopt,+clwb,+crc32,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+pku,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "unsafe-fp-math"="true" "vector-variants"="_ZGVbN8U2__Z3fooRl" }

