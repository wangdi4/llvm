; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vec-clone -S < %s | FileCheck %s
; RUN: opt -passes="vec-clone" -S < %s | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nofree norecurse nosync nounwind uwtable willreturn writeonly mustprogress
define dso_local void @foo1(i32* nocapture nonnull align 4 dereferenceable(4) %p, i32 %i) local_unnamed_addr #0 {
; CHECK:  define dso_local void @_ZGVbN2vl_foo1(<2 x i32*> nocapture nonnull align 4 dereferenceable(4) [[P0:%.*]], i32 [[I0:%.*]]) local_unnamed_addr #1 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ALLOCA_I0:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[I0]], i32* [[ALLOCA_I0]], align 4
; CHECK-NEXT:    [[VEC_P0:%.*]] = alloca <2 x i32*>, align 16
; CHECK-NEXT:    [[VEC_P_CAST0:%.*]] = bitcast <2 x i32*>* [[VEC_P0]] to i32**
; CHECK-NEXT:    store <2 x i32*> [[P0]], <2 x i32*>* [[VEC_P0]], align 16
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.begin.region:
; CHECK-NEXT:    [[ENTRY_REGION0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 2), "QUAL.OMP.LINEAR"(i32* [[ALLOCA_I0]], i32 1) ]
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.preheader:
; CHECK-NEXT:    [[LOAD_I0:%.*]] = load i32, i32* [[ALLOCA_I0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, [[SIMD_LOOP_PREHEADER0]] ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_EXIT0:%.*]] ]
; CHECK-NEXT:    [[VEC_P_CAST_GEP0:%.*]] = getelementptr i32*, i32** [[VEC_P_CAST0]], i32 [[INDEX0]]
; CHECK-NEXT:    [[VEC_P_ELEM0:%.*]] = load i32*, i32** [[VEC_P_CAST_GEP0]], align 8
; CHECK-NEXT:    [[STRIDE_MUL0:%.*]] = mul i32 1, [[INDEX0]]
; CHECK-NEXT:    [[STRIDE_ADD0:%.*]] = add i32 [[LOAD_I0]], [[STRIDE_MUL0]]
; CHECK-NEXT:    store i32 [[STRIDE_ADD0]], i32* [[VEC_P_ELEM0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT0]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.exit:
; CHECK-NEXT:    [[INDVAR0]] = add nuw i32 [[INDEX0]], 1
; CHECK-NEXT:    [[VL_COND0:%.*]] = icmp ult i32 [[INDVAR0]], 2
; CHECK-NEXT:    br i1 [[VL_COND0]], label [[SIMD_LOOP0]], label [[SIMD_END_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.end.region:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[ENTRY_REGION0]]) [ "DIR.OMP.END.SIMD"() ]
; CHECK-NEXT:    br label [[RETURN0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  return:
; CHECK-NEXT:    ret void
; CHECK-NEXT:  }
;
entry:
  store i32 %i, i32* %p, align 4
  ret void
}

define dso_local void @foo2(i32* nocapture %p, i32 %i) local_unnamed_addr #0 {
; CHECK:  define dso_local void @_ZGVbN2vl_foo2(<2 x i32*> nocapture [[P0:%.*]], i32 [[I0:%.*]]) local_unnamed_addr #1 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ALLOCA_I0:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[I0]], i32* [[ALLOCA_I0]], align 4
; CHECK-NEXT:    [[VEC_P0:%.*]] = alloca <2 x i32*>, align 16
; CHECK-NEXT:    [[VEC_P_CAST0:%.*]] = bitcast <2 x i32*>* [[VEC_P0]] to i32**
; CHECK-NEXT:    store <2 x i32*> [[P0]], <2 x i32*>* [[VEC_P0]], align 16
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.begin.region:
; CHECK-NEXT:    [[ENTRY_REGION0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 2), "QUAL.OMP.LINEAR"(i32* [[ALLOCA_I0]], i32 1) ]
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.preheader:
; CHECK-NEXT:    [[LOAD_I0:%.*]] = load i32, i32* [[ALLOCA_I0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, [[SIMD_LOOP_PREHEADER0]] ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_EXIT0:%.*]] ]
; CHECK-NEXT:    [[VEC_P_CAST_GEP0:%.*]] = getelementptr i32*, i32** [[VEC_P_CAST0]], i32 [[INDEX0]]
; CHECK-NEXT:    [[VEC_P_ELEM0:%.*]] = load i32*, i32** [[VEC_P_CAST_GEP0]], align 8
; CHECK-NEXT:    [[PTRIDX0:%.*]] = getelementptr inbounds i32, i32* [[VEC_P_ELEM0]]
; CHECK-NEXT:    [[STRIDE_MUL0:%.*]] = mul i32 1, [[INDEX0]]
; CHECK-NEXT:    [[STRIDE_ADD0:%.*]] = add i32 [[LOAD_I0]], [[STRIDE_MUL0]]
; CHECK-NEXT:    store i32 [[STRIDE_ADD0]], i32* [[PTRIDX0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_EXIT0]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.exit:
; CHECK-NEXT:    [[INDVAR0]] = add nuw i32 [[INDEX0]], 1
; CHECK-NEXT:    [[VL_COND0:%.*]] = icmp ult i32 [[INDVAR0]], 2
; CHECK-NEXT:    br i1 [[VL_COND0]], label [[SIMD_LOOP0]], label [[SIMD_END_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.end.region:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[ENTRY_REGION0]]) [ "DIR.OMP.END.SIMD"() ]
; CHECK-NEXT:    br label [[RETURN0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  return:
; CHECK-NEXT:    ret void
; CHECK-NEXT:  }
;
entry:
  %ptridx = getelementptr inbounds i32, i32* %p
  store i32 %i, i32* %ptridx, align 4
  ret void
}

attributes #0 = { nounwind uwtable "frame-pointer"="none" "min-legal-vector-width"="0" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "vector-variants"="_ZGVbN2vl_" }
