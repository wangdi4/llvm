; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vec-clone -S < %s | FileCheck %s
; RUN: opt -passes="vec-clone" -S < %s | FileCheck %s

; Test to check that VecClone calculates stride correctly for variable stride
; integer case. Stride should come from LOAD_C0 (uniform parameter %c)

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: mustprogress nofree noinline norecurse nosync nounwind readnone willreturn uwtable
define dso_local noundef i64 @_Z3fooll(i64 noundef signext %c, i64 noundef %x) local_unnamed_addr #0 {
; CHECK:  define dso_local noundef <8 x i64> @_ZGVbN8uls0__Z3fooll(i64 noundef signext [[C0:%.*]], i64 noundef [[X0:%.*]]) local_unnamed_addr #1 {
; CHECK-LABEL: simd.loop.preheader:
; CHECK-NEXT:    [[LOAD_X0:%.*]] = load i64, i64* [[ALLOCA_X0:%.*]], align 8
; CHECK-NEXT:    [[LOAD_C0:%.*]] = load i64, i64* [[ALLOCA_C0:%.*]], align 8
; CHECK-NEXT:    br label [[SIMD_LOOP_HEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.header:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, %simd.loop.preheader ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[PHI_CAST0:%.*]] = zext i32 [[INDEX0]] to i64
; Stride calculation is here
; CHECK-NEXT:    [[STRIDE_MUL0:%.*]] = mul i64 [[LOAD_C0]], [[PHI_CAST0]]
; CHECK-NEXT:    [[STRIDE_ADD0:%.*]] = add i64 [[LOAD_X0]], [[STRIDE_MUL0]]
; CHECK-NEXT:    [[ADD0:%.*]] = add nsw i64 [[STRIDE_ADD0]], 1
; CHECK-NEXT:    [[RET_CAST_GEP0:%.*]] = getelementptr i64, i64* [[RET_CAST0:%.*]], i32 [[INDEX0]]
; CHECK-NEXT:    store i64 [[ADD0]], i64* [[RET_CAST_GEP0]], align 8
;
entry:
  %add = add nsw i64 %x, 1
  ret i64 %add
}

attributes #0 = { "vector-variants"="_ZGVbN8uls0__Z3fooll" }
