; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -passes="vec-clone" -S < %s | FileCheck %s

; Check code generated from VecClone for val vector variant for unoptimized LLVM
; Since val (reference) arguments are passed as vector, then VecClone can simply
; get the current strided value from the pointer in the argument vector indexed
; by the loop induction variable.

; Function Attrs: mustprogress noinline nounwind optnone uwtable
define dso_local noundef i64 @_Z3fooRl(ptr noundef nonnull align 8 dereferenceable(8) %x) #0 {
;
; CHECK:  define dso_local noundef <8 x i64> @_ZGVbN8L2__Z3fooRl(<8 x ptr> noundef nonnull align 8 dereferenceable(8) [[X0:%.*]]) #1 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[VEC_X0:%.*]] = alloca <8 x ptr>, align 64
; CHECK-NEXT:    [[VEC_RETVAL0:%.*]] = alloca <8 x i64>, align 64
; CHECK-NEXT:    [[X_ADDR0:%.*]] = alloca ptr, align 8
; CHECK-NEXT:    store <8 x ptr> [[X0]], ptr [[VEC_X0]], align 64
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.begin.region:
; CHECK-NEXT:    [[ENTRY_REGION0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 8), "QUAL.OMP.PRIVATE:TYPED"(ptr [[X_ADDR0]], ptr null, i32 1) ]
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.preheader:
; CHECK-NEXT:    br label [[SIMD_LOOP_HEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.header:
; CHECK-NEXT:    [[INDEX0:%.*]] = phi i32 [ 0, [[SIMD_LOOP_PREHEADER0]] ], [ [[INDVAR0:%.*]], [[SIMD_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[VEC_X_GEP0:%.*]] = getelementptr ptr, ptr [[VEC_X0]], i32 [[INDEX0]]
; CHECK-NEXT:    [[VEC_X_ELEM0:%.*]] = load ptr, ptr [[VEC_X_GEP0]], align 8
; CHECK-NEXT:    store ptr [[VEC_X_ELEM0]], ptr [[X_ADDR0]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[X_ADDR0]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr [[TMP0]], align 8
; CHECK-NEXT:    [[ADD0:%.*]] = add nsw i64 [[TMP1]], 1
; CHECK-NEXT:    [[VEC_RETVAL_GEP0:%.*]] = getelementptr i64, ptr [[VEC_RETVAL0]], i32 [[INDEX0]]
; CHECK-NEXT:    store i64 [[ADD0]], ptr [[VEC_RETVAL_GEP0]], align 4
; CHECK-NEXT:    br label [[SIMD_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.latch:
; CHECK-NEXT:    [[INDVAR0]] = add nuw nsw i32 [[INDEX0]], 1
; CHECK-NEXT:    [[VL_COND0:%.*]] = icmp ult i32 [[INDVAR0]], 8
; CHECK-NEXT:    br i1 [[VL_COND0]], label [[SIMD_LOOP_HEADER0]], label [[SIMD_END_REGION0:%.*]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  simd.end.region:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[ENTRY_REGION0]]) [ "DIR.OMP.END.SIMD"() ]
; CHECK-NEXT:    br label [[RETURN0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  return:
; CHECK-NEXT:    [[VEC_RET0:%.*]] = load <8 x i64>, ptr [[VEC_RETVAL0]], align 64
; CHECK-NEXT:    ret <8 x i64> [[VEC_RET0]]
; CHECK-NEXT:  }
;
entry:
  %x.addr = alloca ptr, align 8
  store ptr %x, ptr %x.addr, align 8
  %0 = load ptr, ptr %x.addr, align 8
  %1 = load i64, ptr %0, align 8
  %add = add nsw i64 %1, 1
  ret i64 %add
}

attributes #0 = { mustprogress noinline nounwind optnone uwtable "approx-func-fp-math"="true" "frame-pointer"="all" "loopopt-pipeline"="full" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="skylake-avx512" "target-features"="+adx,+aes,+avx,+avx2,+avx512bw,+avx512cd,+avx512dq,+avx512f,+avx512vl,+bmi,+bmi2,+clflushopt,+clwb,+crc32,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+pku,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "unsafe-fp-math"="true" "vector-variants"="_ZGVbN8L2__Z3fooRl" }
