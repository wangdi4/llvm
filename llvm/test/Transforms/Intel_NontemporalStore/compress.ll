; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -enable-intel-advanced-opts -intel-libirc-allowed -S -passes 'unaligned-nontemporal,verify' < %s | FileCheck %s

target triple = "x86_64-unknown-linux-gnu"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-i128:128-f80:128-n8:16:32:64-S128"

define void @compress(ptr %dest) "target-features"="+avx512f" {
; CHECK-LABEL: define void @compress(
; CHECK-SAME: ptr [[DEST:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ADDR_NT_STORE_ALLOCA:%.*]] = alloca i8, i64 4184, align 64
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [[__NONTEMPORAL_BUFFER_DATA:%.*]], ptr [[ADDR_NT_STORE_ALLOCA]], i32 0, i32 4
; CHECK-NEXT:    [[TMP1:%.*]] = ptrtoint ptr [[DEST]] to i64
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr [[__NONTEMPORAL_BUFFER_DATA]], ptr [[ADDR_NT_STORE_ALLOCA]], i32 0, i32 1
; CHECK-NEXT:    store i64 [[TMP1]], ptr [[TMP2]], align 8
; CHECK-NEXT:    [[TMP3:%.*]] = and i64 [[TMP1]], 63
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr [[__NONTEMPORAL_BUFFER_DATA]], ptr [[ADDR_NT_STORE_ALLOCA]], i32 0, i32 2
; CHECK-NEXT:    store i64 [[TMP3]], ptr [[TMP4]], align 8
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr [[__NONTEMPORAL_BUFFER_DATA]], ptr [[ADDR_NT_STORE_ALLOCA]], i32 0, i32 3
; CHECK-NEXT:    store i64 0, ptr [[TMP5]], align 8
; CHECK-NEXT:    br label [[LOOP:%.*]]
; CHECK:       loop:
; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[INDEX_NEXT:%.*]], [[LOOP_SPLIT:%.*]] ]
; CHECK-NEXT:    [[ADDR:%.*]] = phi ptr [ [[DEST]], [[ENTRY]] ], [ [[ADDR_NEXT:%.*]], [[LOOP_SPLIT]] ]
; CHECK-NEXT:    [[ADDR_NT_BUF_IDX:%.*]] = phi i64 [ 0, [[ENTRY]] ], [ [[ADDR_NT_BUF_POST_PHI:%.*]], [[LOOP_SPLIT]] ]
; CHECK-NEXT:    [[SPLAT_FIRST:%.*]] = insertelement <8 x i64> poison, i64 [[INDEX]], i32 0
; CHECK-NEXT:    [[SPLAT:%.*]] = shufflevector <8 x i64> [[SPLAT_FIRST]], <8 x i64> poison, <8 x i32> zeroinitializer
; CHECK-NEXT:    [[INDEX_VEC:%.*]] = or <8 x i64> [[SPLAT]], <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
; CHECK-NEXT:    [[REM3:%.*]] = urem <8 x i64> [[INDEX_VEC]], <i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3>
; CHECK-NEXT:    [[MASK:%.*]] = icmp ne <8 x i64> [[REM3]], zeroinitializer
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i64, ptr [[TMP0]], i64 [[ADDR_NT_BUF_IDX]]
; CHECK-NEXT:    call void @llvm.masked.compressstore.v8i64(<8 x i64> [[INDEX_VEC]], ptr [[TMP6]], <8 x i1> [[MASK]])
; CHECK-NEXT:    [[MASK_I81:%.*]] = bitcast <8 x i1> [[MASK]] to i8
; CHECK-NEXT:    [[MASK_POPCNT:%.*]] = call i8 @llvm.ctpop.i8(i8 [[MASK_I81]])
; CHECK-NEXT:    [[MASK_POPCNT_ZEXT:%.*]] = zext i8 [[MASK_POPCNT]] to i64
; CHECK-NEXT:    [[ADDR_NT_BUF_IDX2:%.*]] = add nuw nsw i64 [[ADDR_NT_BUF_IDX]], [[MASK_POPCNT_ZEXT]]
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ugt i64 [[ADDR_NT_BUF_IDX2]], 504
; CHECK-NEXT:    br i1 [[TMP7]], label [[ADDR_NT_BUF_DRAIN:%.*]], label [[LOOP_SPLIT]]
; CHECK:       addr.nt_buf_drain:
; CHECK-NEXT:    [[TMP8:%.*]] = mul i64 [[ADDR_NT_BUF_IDX2]], 8
; CHECK-NEXT:    call void @__libirc_nontemporal_store(ptr [[ADDR_NT_STORE_ALLOCA]], i64 [[TMP8]], i32 0)
; CHECK-NEXT:    br label [[LOOP_SPLIT]]
; CHECK:       loop.split:
; CHECK-NEXT:    [[ADDR_NT_BUF_POST_PHI]] = phi i64 [ [[ADDR_NT_BUF_IDX2]], [[LOOP]] ], [ 0, [[ADDR_NT_BUF_DRAIN]] ]
; CHECK-NEXT:    [[MASK_I8:%.*]] = bitcast <8 x i1> [[MASK]] to i8
; CHECK-NEXT:    [[POPCNT:%.*]] = call i8 @llvm.ctpop.i8(i8 [[MASK_I8]])
; CHECK-NEXT:    [[ADDR_NEXT]] = getelementptr inbounds i64, ptr [[ADDR]], i8 [[POPCNT]]
; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw nsw i64 [[INDEX]], 8
; CHECK-NEXT:    [[COND:%.*]] = icmp eq i64 [[INDEX_NEXT]], 1048576
; CHECK-NEXT:    br i1 [[COND]], label [[EXIT:%.*]], label [[LOOP]]
; CHECK:       exit:
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 [[ADDR_NT_BUF_POST_PHI]], 8
; CHECK-NEXT:    call void @__libirc_nontemporal_store(ptr [[ADDR_NT_STORE_ALLOCA]], i64 [[TMP9]], i32 1)
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %index = phi i64 [ 0, %entry ], [ %index.next, %loop ]
  %addr = phi ptr [ %dest, %entry ], [ %addr.next, %loop ]
  %splat.first = insertelement <8 x i64> poison, i64 %index, i32 0
  %splat = shufflevector <8 x i64> %splat.first, <8 x i64> poison, <8 x i32> zeroinitializer
  %index.vec = or <8 x i64> %splat, <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>
  %rem3 = urem <8 x i64> %index.vec, <i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3, i64 3>
  %mask = icmp ne <8 x i64> %rem3, zeroinitializer
  call void @llvm.masked.compressstore.v8i64(<8 x i64> %index.vec, ptr %addr, <8 x i1> %mask), !nontemporal !0
  %mask.i8 = bitcast <8 x i1> %mask to i8
  %popcnt = call i8 @llvm.ctpop.i8(i8 %mask.i8)
  %addr.next = getelementptr inbounds i64, ptr %addr, i8 %popcnt
  %index.next = add nuw nsw i64 %index, 8
  %cond = icmp eq i64 %index.next, 1048576
  br i1 %cond, label %exit, label %loop

exit:
  ret void
}

declare void @llvm.masked.compressstore.v8i64(<8 x i64>, ptr, <8 x i1>)
declare i8 @llvm.ctpop.i8(i8)

!0 = !{i32 1}
