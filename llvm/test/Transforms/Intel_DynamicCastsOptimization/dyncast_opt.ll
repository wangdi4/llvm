; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -S -passes=optimize-dyn-casts -whole-program-assume -disable-whole-program-visibility | FileCheck %s


; Source code:
;
; class GrandParent {
;  public:
;   virtual int f() { return 30; };
; };
;
; class VirtualGrandParent {
;  public:
;   virtual void g(){};
; };
;
; class Parent1 : public GrandParent, public virtual VirtualGrandParent {};
;
; class Parent2 : public GrandParent, public virtual VirtualGrandParent {};
;
; class Derived1 : public Parent1, public Parent2 {
;  public:
;   int f() { return 60; }
; };
;
; class Parent3 {
;   public:
;     virtual int k() { return 100; }
; };
;
; class Derived2 : public Parent3{
;  public:
;   int k() { return 50; }
; };
;
; __attribute__((noinline))
; extern "C" int test1(Parent1 * p) {
;   Derived1 *res = dynamic_cast<Derived1 *>(p);
;   if (res != nullptr) {
;     return 1;
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test2(Parent1 * p) {
;   Parent2 *res = dynamic_cast<Parent2 *>(p);
;   if (res != nullptr) {
;     return 2;
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test3(VirtualGrandParent * p) {
;   Derived1 *res = dynamic_cast<Derived1 *>(p);
;   if (res != nullptr) {
;     return 3;
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test4(GrandParent * p) {
;   Derived1 *res = dynamic_cast<Derived1 *>(p);
;   if (res != nullptr) {
;     return 4;
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test5(Parent2 * p) {
;   Derived1 *res = dynamic_cast<Derived1 *>(p);
;   if (res != nullptr) {
;     return res->f();
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test6(VirtualGrandParent * p) {
;   Derived1 *res = dynamic_cast<Derived1 *>(p);
;   if (res != nullptr) {
;     return res->f();
;   }
;   return 0;
; }
;
; __attribute__((noinline))
; extern "C" int test7(GrandParent * p) {
;   Parent1 *res = dynamic_cast<Parent1 *>(p);
;   if (res != nullptr) {
;     return 7;
;   }
;   return 0;
; }
;
; int main() {
;   int res = 0;
;   Derived1 d;
;   Parent1 *p1 = &d;
;
;   res += test1(p1);
;   res += test2(p1);
;
;   VirtualGrandParent *vgp1 = &d;
;   res += test3(vgp1);
;
;   GrandParent *gp1 = p1;
;   res += test4(gp1);
;
;   Parent2 *p2 = &d;
;   res += test5(p2);
;
;   VirtualGrandParent *vgp2 = &d;
;   res += test6(vgp2);
;
;   Parent1 p;
;   GrandParent *gp2 = &p;
;   res += test7(gp2);
;
;   return res;
; }

; Classes hierarchy:
;
; +--------------------+          +---------------+
; |                    |          |               |
; | VirtualGrandParent |          |  GrandParent  |
; |                    |          |               |
; +------+-----------+-+          +-+---------+---+
;        |           |              |         |
;     Virtual        |              |         |
;        |      Virtual             |         |
;        |           |              |         |
;  +-----v-----+     |              |    +----v------+
;  |           |     |              |    |           |
;  |  Parent1  |     +-------------------> Parent2   |
;  |           | <------------------+    |           |
;  +------+----+                         +-----+-----+
;         |                                    |
;         |                                    |
;         |                                    |
;         |             +------------+         |
;         |             |            |         |
;         +------------->  Derived1 <----------+
;                       |            |
;                       +------------+


source_filename = "ld-temp.o"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%class.Parent1 = type { %class.GrandParent, %class.GrandParent }
%class.GrandParent = type { i32 (...)** }
%class.Derived1 = type { %class.Parent1.base, %class.Parent1.base, %class.GrandParent }
%class.Parent1.base = type { %class.GrandParent }

$_ZN11GrandParent1fEv = comdat any

$_ZN18VirtualGrandParent1gEv = comdat any

$_ZN8Derived11fEv = comdat any

$_ZThn8_N8Derived11fEv = comdat any

$_ZTI7Parent1 = comdat any

$_ZTI8Derived1 = comdat any

$_ZTS8Derived1 = comdat any

$_ZTI7Parent2 = comdat any

$_ZTS7Parent2 = comdat any

$_ZTI11GrandParent = comdat any

$_ZTI18VirtualGrandParent = comdat any

$_ZTS18VirtualGrandParent = comdat any

$_ZTS11GrandParent = comdat any

$_ZTS7Parent1 = comdat any

$_ZTV8Derived1 = comdat any

$_ZTV7Parent1 = comdat any

@_ZTI7Parent1 = internal dso_local constant { i8*, i8*, i32, i32, i8*, i64, i8*, i64 } { i8* bitcast (i8** getelementptr inbounds (i8*, i8** @_ZTVN10__cxxabiv121__vmi_class_type_infoE, i64 2) to i8*), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @_ZTS7Parent1, i32 0, i32 0), i32 0, i32 2, i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i64 2, i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i64 -6141 }, comdat
@_ZTI8Derived1 = internal dso_local constant { i8*, i8*, i32, i32, i8*, i64, i8*, i64 } { i8* bitcast (i8** getelementptr inbounds (i8*, i8** @_ZTVN10__cxxabiv121__vmi_class_type_infoE, i64 2) to i8*), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @_ZTS8Derived1, i32 0, i32 0), i32 3, i32 2, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i64 2, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent2 to i8*), i64 2050 }, comdat
@_ZTVN10__cxxabiv121__vmi_class_type_infoE = external global i8*
@_ZTS8Derived1 = internal dso_local constant [10 x i8] c"8Derived1\00", comdat
@_ZTI7Parent2 = internal dso_local constant { i8*, i8*, i32, i32, i8*, i64, i8*, i64 } { i8* bitcast (i8** getelementptr inbounds (i8*, i8** @_ZTVN10__cxxabiv121__vmi_class_type_infoE, i64 2) to i8*), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @_ZTS7Parent2, i32 0, i32 0), i32 0, i32 2, i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i64 2, i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i64 -6141 }, comdat
@_ZTS7Parent2 = internal dso_local constant [9 x i8] c"7Parent2\00", comdat
@_ZTI11GrandParent = internal dso_local constant { i8*, i8* } { i8* bitcast (i8** getelementptr inbounds (i8*, i8** @_ZTVN10__cxxabiv117__class_type_infoE, i64 2) to i8*), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @_ZTS11GrandParent, i32 0, i32 0) }, comdat
@_ZTI18VirtualGrandParent = internal dso_local constant { i8*, i8* } { i8* bitcast (i8** getelementptr inbounds (i8*, i8** @_ZTVN10__cxxabiv117__class_type_infoE, i64 2) to i8*), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @_ZTS18VirtualGrandParent, i32 0, i32 0) }, comdat
@_ZTVN10__cxxabiv117__class_type_infoE = external global i8*
@_ZTS18VirtualGrandParent = internal dso_local constant [21 x i8] c"18VirtualGrandParent\00", comdat
@_ZTS11GrandParent = internal dso_local constant [14 x i8] c"11GrandParent\00", comdat
@_ZTS7Parent1 = internal dso_local constant [9 x i8] c"7Parent1\00", comdat
@_ZTV8Derived1 = internal dso_local unnamed_addr constant { [4 x i8*], [4 x i8*], [4 x i8*] } { [4 x i8*] [i8* inttoptr (i64 16 to i8*), i8* null, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i8* bitcast (i32 (%class.Derived1*)* @_ZN8Derived11fEv to i8*)], [4 x i8*] [i8* inttoptr (i64 8 to i8*), i8* inttoptr (i64 -8 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i8* bitcast (i32 (%class.Derived1*)* @_ZThn8_N8Derived11fEv to i8*)], [4 x i8*] [i8* null, i8* inttoptr (i64 -16 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i8* bitcast (void (%class.GrandParent*)* @_ZN18VirtualGrandParent1gEv to i8*)] }, comdat, align 8, !type !0, !type !1, !type !2, !type !3, !type !4, !type !5
@_ZTV7Parent1 = internal dso_local unnamed_addr constant { [4 x i8*], [4 x i8*] } { [4 x i8*] [i8* inttoptr (i64 8 to i8*), i8* null, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast (i32 (%class.GrandParent*)* @_ZN11GrandParent1fEv to i8*)], [4 x i8*] [i8* null, i8* inttoptr (i64 -8 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast (void (%class.GrandParent*)* @_ZN18VirtualGrandParent1gEv to i8*)] }, comdat, align 8, !type !0, !type !6, !type !3

; Derived1 class is final.
; Hint >= 0 so we can optmimize this dynamic_cast.
; Function Attrs: noinline nounwind readonly uwtable
define internal dso_local i32 @test1(%class.Parent1* readonly %p) #0 {
; CHECK-LABEL: @test1(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.Parent1* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[IF_END:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.Parent1* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i8***
; CHECK-NEXT:    [[TMP3:%.*]] = load i8**, i8*** [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8*, i8** [[TMP3]], i32 -1
; CHECK-NEXT:    [[TMP5:%.*]] = load i8*, i8** [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i8* [[TMP5]], bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*)
; CHECK-NEXT:    [[TMP7:%.*]] = select i1 [[TMP6]], i8* [[TMP1]], i8* null
; CHECK-NEXT:    [[TMP8:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 0) #6
; CHECK-NEXT:    [[PHITMP:%.*]] = icmp eq i8* [[TMP7]], null
; CHECK-NEXT:    br i1 [[PHITMP]], label [[IF_END]], label [[CLEANUP:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ 0, [[IF_END]] ], [ 1, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.Parent1* %p, null
  br i1 %0, label %if.end, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.Parent1* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 0) #6
  %phitmp = icmp eq i8* %2, null
  br i1 %phitmp, label %if.end, label %cleanup

if.end:                                           ; preds = %dynamic_cast.notnull, %entry
  br label %cleanup

cleanup:                                          ; preds = %if.end, %dynamic_cast.notnull
  %retval.0 = phi i32 [ 0, %if.end ], [ 1, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Function Attrs: nounwind readonly
declare i8* @__dynamic_cast(i8*, i8*, i8*, i64) local_unnamed_addr #1

; Parent2 is not final, optimization will not be performed.
; Function Attrs: noinline nounwind readonly uwtable
define internal dso_local i32 @test2(%class.Parent1* readonly %p) #0 {
; CHECK-LABEL: @test2(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.Parent1* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[IF_END:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.Parent1* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent2 to i8*), i64 -2) #6
; CHECK-NEXT:    [[PHITMP:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[PHITMP]], label [[IF_END]], label [[CLEANUP:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ 0, [[IF_END]] ], [ 2, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.Parent1* %p, null
  br i1 %0, label %if.end, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.Parent1* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent2 to i8*), i64 -2) #6
  %phitmp = icmp eq i8* %2, null
  br i1 %phitmp, label %if.end, label %cleanup

if.end:                                           ; preds = %dynamic_cast.notnull, %entry
  br label %cleanup

cleanup:                                          ; preds = %if.end, %dynamic_cast.notnull
  %retval.0 = phi i32 [ 0, %if.end ], [ 2, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Derived1 class is final. Hint < 0 so we are not able to easily calculate
; casted pointer ourselves. That is why we need to check that we don't need
; the result of dynamic_cast, but we only need to know if it is successful or
; not. Here this condition is satisfied, that is why call will be optimized.
; Function Attrs: noinline nounwind readonly uwtable
define internal dso_local i32 @test3(%class.GrandParent* readonly %p) #0 {
; CHECK-LABEL: @test3(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.GrandParent* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[IF_END:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.GrandParent* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i8***
; CHECK-NEXT:    [[TMP3:%.*]] = load i8**, i8*** [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8*, i8** [[TMP3]], i32 -1
; CHECK-NEXT:    [[TMP5:%.*]] = load i8*, i8** [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = icmp ne i8* [[TMP5]], bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*)
; CHECK-NEXT:    [[TMP7:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -1) #6
; CHECK-NEXT:    [[PHITMP:%.*]] = icmp eq i8* [[TMP7]], null
; CHECK-NEXT:    br i1 [[TMP6]], label [[IF_END]], label [[CLEANUP:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ 0, [[IF_END]] ], [ 3, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.GrandParent* %p, null
  br i1 %0, label %if.end, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.GrandParent* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -1) #6
  %phitmp = icmp eq i8* %2, null
  br i1 %phitmp, label %if.end, label %cleanup

if.end:                                           ; preds = %dynamic_cast.notnull, %entry
  br label %cleanup

cleanup:                                          ; preds = %if.end, %dynamic_cast.notnull
  %retval.0 = phi i32 [ 0, %if.end ], [ 3, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Derived1 class is final. Hint < 0 so we are not able to easily calculate
; casted pointer ourselves. That is why we need to check that we don't need
; the result of dynamic_cast, but we only need to know if it is successful or
; not. Here this condition is satisfied, that is why call will be optimized.
; Function Attrs: noinline nounwind readonly uwtable
define internal dso_local i32 @test4(%class.GrandParent* readonly %p) #0 {
; CHECK-LABEL: @test4(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.GrandParent* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[IF_END:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.GrandParent* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i8***
; CHECK-NEXT:    [[TMP3:%.*]] = load i8**, i8*** [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8*, i8** [[TMP3]], i32 -1
; CHECK-NEXT:    [[TMP5:%.*]] = load i8*, i8** [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = icmp ne i8* [[TMP5]], bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*)
; CHECK-NEXT:    [[TMP7:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -3) #6
; CHECK-NEXT:    [[PHITMP:%.*]] = icmp eq i8* [[TMP7]], null
; CHECK-NEXT:    br i1 [[TMP6]], label [[IF_END]], label [[CLEANUP:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ 0, [[IF_END]] ], [ 4, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.GrandParent* %p, null
  br i1 %0, label %if.end, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.GrandParent* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -3) #6
  %phitmp = icmp eq i8* %2, null
  br i1 %phitmp, label %if.end, label %cleanup

if.end:                                           ; preds = %dynamic_cast.notnull, %entry
  br label %cleanup

cleanup:                                          ; preds = %if.end, %dynamic_cast.notnull
  %retval.0 = phi i32 [ 0, %if.end ], [ 4, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Derived1 class is final.
; We can notice here that result of dynamic_cast res5 is needed because
; res5->Foo() call is made using it. Hint > 0 so we will be able to easily
; calculate result of dynamic_cast = p2 - hint. That is why optimization
; could be performed.
; Function Attrs: noinline uwtable
define internal dso_local i32 @test5(%class.Parent1* %p) #2 {
; CHECK-LABEL: @test5(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.Parent1* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[CLEANUP:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.Parent1* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i8* [[TMP1]] to i8***
; CHECK-NEXT:    [[TMP3:%.*]] = load i8**, i8*** [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr i8*, i8** [[TMP3]], i32 -1
; CHECK-NEXT:    [[TMP5:%.*]] = load i8*, i8** [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i8* [[TMP5]], bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*)
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, i8* [[TMP1]], i64 -8
; CHECK-NEXT:    [[TMP8:%.*]] = select i1 [[TMP6]], i8* [[TMP7]], i8* null
; CHECK-NEXT:    [[TMP9:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent2 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 8) #6
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i8* [[TMP8]], null
; CHECK-NEXT:    br i1 [[CMP]], label [[CLEANUP]], label [[IF_THEN:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8* [[TMP8]] to %class.Derived1*
; CHECK-NEXT:    [[TMP11:%.*]] = bitcast i8* [[TMP8]] to i32 (%class.Derived1*)***
; CHECK-NEXT:    [[VTABLE:%.*]] = load i32 (%class.Derived1*)**, i32 (%class.Derived1*)*** [[TMP11]], align 8, !tbaa !9
; CHECK-NEXT:    [[TMP12:%.*]] = load i32 (%class.Derived1*)*, i32 (%class.Derived1*)** [[VTABLE]], align 8
; CHECK-NEXT:    [[CALL:%.*]] = tail call i32 [[TMP12]](%class.Derived1* nonnull [[TMP10]])
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ [[CALL]], [[IF_THEN]] ], [ 0, [[ENTRY:%.*]] ], [ 0, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.Parent1* %p, null
  br i1 %0, label %cleanup, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.Parent1* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent2 to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 8) #6
  %cmp = icmp eq i8* %2, null
  br i1 %cmp, label %cleanup, label %if.then

if.then:                                          ; preds = %dynamic_cast.notnull
  %3 = bitcast i8* %2 to %class.Derived1*
  %4 = bitcast i8* %2 to i32 (%class.Derived1*)***
  %vtable = load i32 (%class.Derived1*)**, i32 (%class.Derived1*)*** %4, align 8, !tbaa !9
  %5 = load i32 (%class.Derived1*)*, i32 (%class.Derived1*)** %vtable, align 8
  %call = tail call i32 %5(%class.Derived1* nonnull %3)
  br label %cleanup

cleanup:                                          ; preds = %if.then, %dynamic_cast.notnull, %entry
  %retval.0 = phi i32 [ %call, %if.then ], [ 0, %entry ], [ 0, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Negative hint and there are other uses than comparison with null that is
; why dynamic_cast will not be optimized.
; Function Attrs: noinline uwtable
define internal dso_local i32 @test6(%class.GrandParent* %p) #2 {
; CHECK-LABEL: @test6(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.GrandParent* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[CLEANUP:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.GrandParent* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -1) #6
; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[CMP]], label [[CLEANUP]], label [[IF_THEN:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i8* [[TMP2]] to %class.Derived1*
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i8* [[TMP2]] to i32 (%class.Derived1*)***
; CHECK-NEXT:    [[VTABLE:%.*]] = load i32 (%class.Derived1*)**, i32 (%class.Derived1*)*** [[TMP4]], align 8, !tbaa !9
; CHECK-NEXT:    [[TMP5:%.*]] = load i32 (%class.Derived1*)*, i32 (%class.Derived1*)** [[VTABLE]], align 8
; CHECK-NEXT:    [[CALL:%.*]] = tail call i32 [[TMP5]](%class.Derived1* nonnull [[TMP3]])
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ [[CALL]], [[IF_THEN]] ], [ 0, [[ENTRY:%.*]] ], [ 0, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.GrandParent* %p, null
  br i1 %0, label %cleanup, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.GrandParent* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8* }* @_ZTI18VirtualGrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI8Derived1 to i8*), i64 -1) #6
  %cmp = icmp eq i8* %2, null
  br i1 %cmp, label %cleanup, label %if.then

if.then:                                          ; preds = %dynamic_cast.notnull
  %3 = bitcast i8* %2 to %class.Derived1*
  %4 = bitcast i8* %2 to i32 (%class.Derived1*)***
  %vtable = load i32 (%class.Derived1*)**, i32 (%class.Derived1*)*** %4, align 8, !tbaa !9
  %5 = load i32 (%class.Derived1*)*, i32 (%class.Derived1*)** %vtable, align 8
  %call = tail call i32 %5(%class.Derived1* nonnull %3)
  br label %cleanup

cleanup:                                          ; preds = %if.then, %dynamic_cast.notnull, %entry
  %retval.0 = phi i32 [ %call, %if.then ], [ 0, %entry ], [ 0, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Parent1 is not final class. Optimization will not be performed.
; Function Attrs: noinline nounwind readonly uwtable
define internal dso_local i32 @test7(%class.GrandParent* readonly %p) #0 {
; CHECK-LABEL: @test7(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp eq %class.GrandParent* [[P:%.*]], null
; CHECK-NEXT:    br i1 [[TMP0]], label [[IF_END:%.*]], label [[DYNAMIC_CAST_NOTNULL:%.*]]
; CHECK:       dynamic_cast.notnull:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast %class.GrandParent* [[P]] to i8*
; CHECK-NEXT:    [[TMP2:%.*]] = tail call i8* @__dynamic_cast(i8* [[TMP1]], i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i64 0) #6
; CHECK-NEXT:    [[PHITMP:%.*]] = icmp eq i8* [[TMP2]], null
; CHECK-NEXT:    br i1 [[PHITMP]], label [[IF_END]], label [[CLEANUP:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    br label [[CLEANUP]]
; CHECK:       cleanup:
; CHECK-NEXT:    [[RETVAL_0:%.*]] = phi i32 [ 0, [[IF_END]] ], [ 7, [[DYNAMIC_CAST_NOTNULL]] ]
; CHECK-NEXT:    ret i32 [[RETVAL_0]]
;
entry:
  %0 = icmp eq %class.GrandParent* %p, null
  br i1 %0, label %if.end, label %dynamic_cast.notnull

dynamic_cast.notnull:                             ; preds = %entry
  %1 = bitcast %class.GrandParent* %p to i8*
  %2 = tail call i8* @__dynamic_cast(i8* %1, i8* bitcast ({ i8*, i8* }* @_ZTI11GrandParent to i8*), i8* bitcast ({ i8*, i8*, i32, i32, i8*, i64, i8*, i64 }* @_ZTI7Parent1 to i8*), i64 0) #6
  %phitmp = icmp eq i8* %2, null
  br i1 %phitmp, label %if.end, label %cleanup

if.end:                                           ; preds = %dynamic_cast.notnull, %entry
  br label %cleanup

cleanup:                                          ; preds = %if.end, %dynamic_cast.notnull
  %retval.0 = phi i32 [ 0, %if.end ], [ 7, %dynamic_cast.notnull ]
  ret i32 %retval.0
}

; Function Attrs: norecurse uwtable
define dso_local i32 @main() #3 {
; CHECK-LABEL: @main(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[D:%.*]] = alloca [[CLASS_DERIVED1:%.*]], align 8
; CHECK-NEXT:    [[P:%.*]] = alloca [[CLASS_PARENT1:%.*]], align 8
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast %class.Derived1* [[D]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull [[TMP0]]) #6
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 2, i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 0, i32 0, i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 1, i32 0, i32 0
; CHECK-NEXT:    store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 0, i64 3) to i32 (...)**), i32 (...)*** [[TMP2]], align 8, !tbaa !9
; CHECK-NEXT:    store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 2, i64 3) to i32 (...)**), i32 (...)*** [[TMP1]], align 8, !tbaa !9
; CHECK-NEXT:    store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 1, i64 3) to i32 (...)**), i32 (...)*** [[TMP3]], align 8, !tbaa !9
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast %class.Derived1* [[D]] to %class.Parent1*
; CHECK-NEXT:    [[CALL:%.*]] = call i32 @test1(%class.Parent1* nonnull [[TMP4]])
; CHECK-NEXT:    [[CALL1:%.*]] = call i32 @test2(%class.Parent1* nonnull [[TMP4]])
; CHECK-NEXT:    [[ADD2:%.*]] = add nsw i32 [[CALL1]], [[CALL]]
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast %class.Derived1* [[D]] to i8**
; CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 2
; CHECK-NEXT:    [[CALL3:%.*]] = call i32 @test3(%class.GrandParent* nonnull [[ADD_PTR]])
; CHECK-NEXT:    [[ADD4:%.*]] = add nsw i32 [[ADD2]], [[CALL3]]
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 0, i32 0
; CHECK-NEXT:    [[CALL5:%.*]] = call i32 @test4(%class.GrandParent* nonnull [[TMP6]])
; CHECK-NEXT:    [[ADD6:%.*]] = add nsw i32 [[ADD4]], [[CALL5]]
; CHECK-NEXT:    [[ADD_PTR8:%.*]] = getelementptr inbounds [[CLASS_DERIVED1]], %class.Derived1* [[D]], i64 0, i32 1
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast %class.Parent1.base* [[ADD_PTR8]] to %class.Parent1*
; CHECK-NEXT:    [[CALL11:%.*]] = call i32 @test5(%class.Parent1* nonnull [[TMP7]])
; CHECK-NEXT:    [[ADD12:%.*]] = add nsw i32 [[ADD6]], [[CALL11]]
; CHECK-NEXT:    [[VTABLE14:%.*]] = load i8*, i8** [[TMP5]], align 8, !tbaa !9
; CHECK-NEXT:    [[VBASE_OFFSET_PTR15:%.*]] = getelementptr i8, i8* [[VTABLE14]], i64 -24
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast i8* [[VBASE_OFFSET_PTR15]] to i64*
; CHECK-NEXT:    [[VBASE_OFFSET16:%.*]] = load i64, i64* [[TMP8]], align 8
; CHECK-NEXT:    [[ADD_PTR17:%.*]] = getelementptr inbounds i8, i8* [[TMP0]], i64 [[VBASE_OFFSET16]]
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i8* [[ADD_PTR17]] to %class.GrandParent*
; CHECK-NEXT:    [[CALL20:%.*]] = call i32 @test6(%class.GrandParent* [[TMP9]])
; CHECK-NEXT:    [[ADD21:%.*]] = add nsw i32 [[ADD12]], [[CALL20]]
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast %class.Parent1* [[P]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull [[TMP10]]) #6
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[CLASS_PARENT1]], %class.Parent1* [[P]], i64 0, i32 1, i32 0
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds [[CLASS_PARENT1]], %class.Parent1* [[P]], i64 0, i32 0, i32 0
; CHECK-NEXT:    store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*] }* @_ZTV7Parent1, i64 0, inrange i32 0, i64 3) to i32 (...)**), i32 (...)*** [[TMP12]], align 8, !tbaa !9
; CHECK-NEXT:    store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*] }* @_ZTV7Parent1, i64 0, inrange i32 1, i64 3) to i32 (...)**), i32 (...)*** [[TMP11]], align 8, !tbaa !9
; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[CLASS_PARENT1]], %class.Parent1* [[P]], i64 0, i32 0
; CHECK-NEXT:    [[CALL22:%.*]] = call i32 @test7(%class.GrandParent* nonnull [[TMP13]])
; CHECK-NEXT:    [[ADD23:%.*]] = add nsw i32 [[ADD21]], [[CALL22]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull [[TMP10]]) #6
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull [[TMP0]]) #6
; CHECK-NEXT:    ret i32 [[ADD23]]
;
entry:
  %d = alloca %class.Derived1, align 8
  %p = alloca %class.Parent1, align 8
  %0 = bitcast %class.Derived1* %d to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %0) #6
  %1 = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 2, i32 0
  %2 = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 0, i32 0, i32 0
  %3 = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 1, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 0, i64 3) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !9
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 2, i64 3) to i32 (...)**), i32 (...)*** %1, align 8, !tbaa !9
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*], [4 x i8*] }* @_ZTV8Derived1, i64 0, inrange i32 1, i64 3) to i32 (...)**), i32 (...)*** %3, align 8, !tbaa !9
  %4 = bitcast %class.Derived1* %d to %class.Parent1*
  %call = call i32 @test1(%class.Parent1* nonnull %4)
  %call1 = call i32 @test2(%class.Parent1* nonnull %4)
  %add2 = add nsw i32 %call1, %call
  %5 = bitcast %class.Derived1* %d to i8**
  %add.ptr = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 2
  %call3 = call i32 @test3(%class.GrandParent* nonnull %add.ptr)
  %add4 = add nsw i32 %add2, %call3
  %6 = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 0, i32 0
  %call5 = call i32 @test4(%class.GrandParent* nonnull %6)
  %add6 = add nsw i32 %add4, %call5
  %add.ptr8 = getelementptr inbounds %class.Derived1, %class.Derived1* %d, i64 0, i32 1
  %7 = bitcast %class.Parent1.base* %add.ptr8 to %class.Parent1*
  %call11 = call i32 @test5(%class.Parent1* nonnull %7)
  %add12 = add nsw i32 %add6, %call11
  %vtable14 = load i8*, i8** %5, align 8, !tbaa !9
  %vbase.offset.ptr15 = getelementptr i8, i8* %vtable14, i64 -24
  %8 = bitcast i8* %vbase.offset.ptr15 to i64*
  %vbase.offset16 = load i64, i64* %8, align 8
  %add.ptr17 = getelementptr inbounds i8, i8* %0, i64 %vbase.offset16
  %9 = bitcast i8* %add.ptr17 to %class.GrandParent*
  %call20 = call i32 @test6(%class.GrandParent* %9)
  %add21 = add nsw i32 %add12, %call20
  %10 = bitcast %class.Parent1* %p to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %10) #6
  %11 = getelementptr inbounds %class.Parent1, %class.Parent1* %p, i64 0, i32 1, i32 0
  %12 = getelementptr inbounds %class.Parent1, %class.Parent1* %p, i64 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*] }* @_ZTV7Parent1, i64 0, inrange i32 0, i64 3) to i32 (...)**), i32 (...)*** %12, align 8, !tbaa !9
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*], [4 x i8*] }, { [4 x i8*], [4 x i8*] }* @_ZTV7Parent1, i64 0, inrange i32 1, i64 3) to i32 (...)**), i32 (...)*** %11, align 8, !tbaa !9
  %13 = getelementptr inbounds %class.Parent1, %class.Parent1* %p, i64 0, i32 0
  %call22 = call i32 @test7(%class.GrandParent* nonnull %13)
  %add23 = add nsw i32 %add21, %call22
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %10) #6
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %0) #6
  ret i32 %add23
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture) #4

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture) #4

; Function Attrs: norecurse nounwind uwtable
define internal dso_local i32 @_ZN11GrandParent1fEv(%class.GrandParent* %this) unnamed_addr #5 comdat align 2 {
; CHECK-LABEL: @_ZN11GrandParent1fEv(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    ret i32 30
;
entry:
  ret i32 30
}

; Function Attrs: norecurse nounwind uwtable
define internal dso_local void @_ZN18VirtualGrandParent1gEv(%class.GrandParent* %this) unnamed_addr #5 comdat align 2 {
; CHECK-LABEL: @_ZN18VirtualGrandParent1gEv(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    ret void
;
entry:
  ret void
}

; Function Attrs: norecurse nounwind uwtable
define internal dso_local i32 @_ZN8Derived11fEv(%class.Derived1* %this) unnamed_addr #5 comdat align 2 {
; CHECK-LABEL: @_ZN8Derived11fEv(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    ret i32 60
;
entry:
  ret i32 60
}

; Function Attrs: norecurse uwtable
define internal dso_local i32 @_ZThn8_N8Derived11fEv(%class.Derived1* %this) unnamed_addr #3 comdat align 2 {
; CHECK-LABEL: @_ZThn8_N8Derived11fEv(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    ret i32 60
;
entry:
  ret i32 60
}

attributes #0 = { noinline nounwind readonly uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind readonly }
attributes #2 = { noinline uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { argmemonly nounwind }
attributes #5 = { norecurse nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind }

!llvm.ident = !{!7}
!llvm.module.flags = !{!8}

!0 = !{i64 24, !"_ZTS11GrandParent"}
!1 = !{i64 56, !"_ZTS11GrandParent"}
!2 = !{i64 88, !"_ZTS18VirtualGrandParent"}
!3 = !{i64 24, !"_ZTS7Parent1"}
!4 = !{i64 56, !"_ZTS7Parent2"}
!5 = !{i64 24, !"_ZTS8Derived1"}
!6 = !{i64 56, !"_ZTS18VirtualGrandParent"}
!7 = !{!"clang version 6.0.0"}
!8 = !{i32 1, !"wchar_size", i32 4}
!9 = !{!10, !10, i64 0}
!10 = !{!"vtable pointer", !11, i64 0}
!11 = !{!"Simple C++ TBAA"}
