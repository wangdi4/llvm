; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Test to verify the functionality of VPOParoptGuardMemoryMotion and VPORenameOperands passes.

; Test src:
; struct point {
;   int x;
;   int y;
; };
;
; #pragma omp declare reduction(min : struct point : \
;         omp_out.x = omp_in.x > omp_out.x  ? omp_out.x : omp_in.x, \
;         omp_out.y = omp_in.y > omp_out.y  ? omp_out.y : omp_in.y ) \
;         initializer( omp_priv = { INT_MAX, INT_MAX } )
;
; #pragma omp declare reduction(max : struct point : \
;         omp_out.x = omp_in.x < omp_out.x  ? omp_out.x : omp_in.x,  \
;         omp_out.y = omp_in.y < omp_out.y  ? omp_out.y : omp_in.y ) \
;         initializer( omp_priv = { 0, 0 } )
;
; void find_enclosing_rectangle ( int n, struct point points[] )
; {
;   struct point minp = { INT_MAX, INT_MAX }, maxp = {0,0};
;   int i;
;
; #pragma omp simd reduction(min:minp) reduction(max:maxp)
;   for ( i = 0; i < n; i++ ) {
;     if ( points[i].x < minp.x ) minp.x = points[i].x;
;     if ( points[i].y < minp.y ) minp.y = points[i].y;
;     if ( points[i].x > maxp.x ) maxp.x = points[i].x;
;     if ( points[i].y > maxp.y ) maxp.y = points[i].y;
;   }
; }

; RUN: opt -opaque-pointers=0 -enable-new-pm=0 -vpo-paropt-guard-memory-motion -vpo-cfg-restructuring -vpo-rename-operands -S %s -o %t1.ll && FileCheck --input-file=%t1.ll %s
; RUN: opt -opaque-pointers=0 -enable-new-pm=0 -vpo-restore-operands -S %t1.ll -o %t2.ll && FileCheck --input-file=%t2.ll %s --check-prefix=RESTORE

; RUN: opt -opaque-pointers=0 -passes='function(vpo-paropt-guard-memory-motion,vpo-cfg-restructuring,vpo-rename-operands)' -S %s -o %t1.ll && FileCheck --input-file=%t1.ll %s
; RUN: opt -opaque-pointers=0 -passes='function(vpo-restore-operands)' -S %t1.ll -o %t2.ll && FileCheck --input-file=%t2.ll %s --check-prefix=RESTORE

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.point = type { i32, i32 }
%struct.fast_red_t = type <{ %struct.point, %struct.point }>

; Function Attrs: nounwind uwtable
define dso_local void @find_enclosing_rectangle(i32 noundef %n, %struct.point* noundef %points) local_unnamed_addr #0 {
; CHECK:       @find_enclosing_rectangle(
; CHECK:       omp.inner.for.body.lr.ph:
; CHECK-NEXT:    [[TMP6:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.UDR"(%struct.point* [[TMPCAST_RED:%.*]], i8* null, i8* null, void (%struct.point*, %struct.point*)* @.omp_combiner., void (%struct.point*, %struct.point*)* @.omp_initializer.), "QUAL.OMP.REDUCTION.UDR"(%struct.point* [[TMPCAST68_RED:%.*]], i8* null, i8* null, void (%struct.point*, %struct.point*)* @.omp_combiner..1, void (%struct.point*, %struct.point*)* @.omp_initializer..2), "QUAL.OMP.LINEAR:IV"(i32* [[I_LINEAR_IV:%.*]], i32 1), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null) ]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_LOCAL_072:%.*]] = phi i32 [ 0, [[OMP_INNER_FOR_BODY_LR_PH:%.*]] ], [ [[ADD43:%.*]], [[DIR_VPO_END_GUARD_MEM_MOTION_4:%.*]] ]
; CHECK-NEXT:    br label [[DIR_VPO_GUARD_MEM_MOTION_1:%.*]]
; CHECK:       DIR.VPO.GUARD.MEM.MOTION.1:
; CHECK-NEXT:    store %struct.point* [[TMPCAST_RED]], %struct.point** [[TMPCAST_RED_ADDR:%.*]], align 8
; CHECK-NEXT:    store %struct.point* [[TMPCAST68_RED]], %struct.point** [[TMPCAST68_RED_ADDR:%.*]], align 8
; CHECK-NEXT:    br label [[DIR_VPO_GUARD_MEM_MOTION_1_SPLIT:%.*]]
; CHECK:       DIR.VPO.GUARD.MEM.MOTION.1.split:
; CHECK-NEXT:    [[GUARD_START:%.*]] = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(%struct.point* [[TMPCAST_RED]]), "QUAL.OMP.LIVEIN"(%struct.point* [[TMPCAST68_RED]]), "QUAL.OMP.OPERAND.ADDR"(%struct.point* [[TMPCAST_RED]], %struct.point** [[TMPCAST_RED_ADDR]]), "QUAL.OMP.OPERAND.ADDR"(%struct.point* [[TMPCAST68_RED]], %struct.point** [[TMPCAST68_RED_ADDR]]) ]
; CHECK-NEXT:    [[TMPCAST_RED1:%.*]] = load volatile %struct.point*, %struct.point** [[TMPCAST_RED_ADDR]], align 8
; CHECK-NEXT:    [[TMPCAST68_RED2:%.*]] = load volatile %struct.point*, %struct.point** [[TMPCAST68_RED_ADDR]], align 8
; CHECK-NEXT:    br label [[DIR_VPO_GUARD_MEM_MOTION_2:%.*]]
; CHECK:       DIR.VPO.GUARD.MEM.MOTION.2:
; CHECK-NEXT:    store i32 [[DOTOMP_IV_LOCAL_072]], i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[DOTOMP_IV_LOCAL_072]] to i64
; CHECK-NEXT:    [[X:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[POINTS:%.*]], i64 [[IDXPROM]], i32 0
; CHECK-NEXT:    [[TMP7:%.*]] = load i32, i32* [[X]], align 4
; CHECK-NEXT:    [[X5:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[TMPCAST_RED1]], i64 0, i32 0
; CHECK-NEXT:    [[TMP8:%.*]] = load i32, i32* [[X5]], align 4
; CHECK-NEXT:    [[CMP6:%.*]] = icmp slt i32 [[TMP7]], [[TMP8]]
; CHECK-NEXT:    br i1 [[CMP6]], label [[IF_THEN:%.*]], label [[IF_END:%.*]]
; CHECK:       if.then:
; CHECK-NEXT:    store i32 [[TMP7]], i32* [[X5]], align 4
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    [[TMP9:%.*]] = load i32, i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[IDXPROM11:%.*]] = sext i32 [[TMP9]] to i64
; CHECK-NEXT:    [[Y:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[POINTS]], i64 [[IDXPROM11]], i32 1
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, i32* [[Y]], align 4
; CHECK-NEXT:    [[Y13:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[TMPCAST_RED1]], i64 0, i32 1
; CHECK-NEXT:    [[TMP11:%.*]] = load i32, i32* [[Y13]], align 4
; CHECK-NEXT:    [[CMP14:%.*]] = icmp slt i32 [[TMP10]], [[TMP11]]
; CHECK-NEXT:    br i1 [[CMP14]], label [[IF_THEN15:%.*]], label [[IF_END20:%.*]]
; CHECK:       if.then15:
; CHECK-NEXT:    store i32 [[TMP10]], i32* [[Y13]], align 4
; CHECK-NEXT:    br label [[IF_END20]]
; CHECK:       if.end20:
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[IDXPROM21:%.*]] = sext i32 [[TMP12]] to i64
; CHECK-NEXT:    [[X23:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[POINTS]], i64 [[IDXPROM21]], i32 0
; CHECK-NEXT:    [[TMP13:%.*]] = load i32, i32* [[X23]], align 4
; CHECK-NEXT:    [[X24:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[TMPCAST68_RED2]], i64 0, i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = load i32, i32* [[X24]], align 4
; CHECK-NEXT:    [[CMP25:%.*]] = icmp sgt i32 [[TMP13]], [[TMP14]]
; CHECK-NEXT:    br i1 [[CMP25]], label [[IF_THEN26:%.*]], label [[IF_END31:%.*]]
; CHECK:       if.then26:
; CHECK-NEXT:    store i32 [[TMP13]], i32* [[X24]], align 4
; CHECK-NEXT:    br label [[IF_END31]]
; CHECK:       if.end31:
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[IDXPROM32:%.*]] = sext i32 [[TMP15]] to i64
; CHECK-NEXT:    [[Y34:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[POINTS]], i64 [[IDXPROM32]], i32 1
; CHECK-NEXT:    [[TMP16:%.*]] = load i32, i32* [[Y34]], align 4
; CHECK-NEXT:    [[Y35:%.*]] = getelementptr inbounds %struct.point, %struct.point* [[TMPCAST68_RED2]], i64 0, i32 1
; CHECK-NEXT:    [[TMP17:%.*]] = load i32, i32* [[Y35]], align 4
; CHECK-NEXT:    [[CMP36:%.*]] = icmp sgt i32 [[TMP16]], [[TMP17]]
; CHECK-NEXT:    br i1 [[CMP36]], label [[IF_THEN37:%.*]], label [[OMP_INNER_FOR_INC:%.*]]
; CHECK:       if.then37:
; CHECK-NEXT:    store i32 [[TMP16]], i32* [[Y35]], align 4
; CHECK-NEXT:    br label [[OMP_INNER_FOR_INC]]
; CHECK:       omp.inner.for.inc:
; CHECK-NEXT:    [[ADD43]] = add nsw i32 [[DOTOMP_IV_LOCAL_072]], 1
; CHECK-NEXT:    [[TMP18:%.*]] = load i32, i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[ADD44:%.*]] = add nsw i32 [[TMP18]], 1
; CHECK-NEXT:    store i32 [[ADD44]], i32* [[I_LINEAR_IV]], align 4
; CHECK-NEXT:    [[TMP19:%.*]] = add i32 [[TMP5:%.*]], 1
; CHECK-NEXT:    br label [[DIR_VPO_END_GUARD_MEM_MOTION_3:%.*]]
; CHECK:       DIR.VPO.END.GUARD.MEM.MOTION.3:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[GUARD_START]]) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
; CHECK-NEXT:    br label [[DIR_VPO_END_GUARD_MEM_MOTION_4]]
; CHECK:       DIR.VPO.END.GUARD.MEM.MOTION.4:
; CHECK-NEXT:    [[CMP3_NOT:%.*]] = icmp sgt i32 [[TMP19]], [[ADD43]]
; CHECK-NEXT:    br i1 [[CMP3_NOT]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_COND_DIR_OMP_END_SIMD_3_LOOPEXIT_CRIT_EDGE:%.*]]
; CHECK:       omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge:
; CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP6]]) [ "DIR.OMP.END.SIMD"() ]
; CHECK-NEXT:    br label [[DIR_OMP_END_SIMD_1:%.*]]
;
; Check that after vpo-restore-operands OMP.OPERAND.ADDR clauses are dropped.
; RESTORE:       @find_enclosing_rectangle(
; RESTORE:         [[GUARD_START:%.*]] = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(%struct.point* %tmpcast.red), "QUAL.OMP.LIVEIN"(%struct.point* %tmpcast68.red) ]
;
entry:
  %tmpcast68.red = alloca %struct.point, align 8
  %tmpcast.red = alloca %struct.point, align 8
  %fast_red_struct = alloca %struct.fast_red_t, align 4
  %i.linear.iv = alloca i32, align 4
  %minp = alloca i64, align 8
  %tmpcast = bitcast i64* %minp to %struct.point*
  %maxp = alloca i64, align 8
  %tmpcast68 = bitcast i64* %maxp to %struct.point*
  %i = alloca i32, align 4
  %.omp.iv = alloca i32, align 4
  %.omp.ub = alloca i32, align 4
  %0 = bitcast i64* %minp to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %0) #2
  store i64 9223372034707292159, i64* %minp, align 8
  %1 = bitcast i64* %maxp to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1) #2
  store i64 0, i64* %maxp, align 8
  %2 = bitcast i32* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %2) #2
  %cmp = icmp sgt i32 %n, 0
  br i1 %cmp, label %DIR.OMP.SIMD.267, label %omp.precond.end

DIR.OMP.SIMD.267:                                 ; preds = %entry
  %sub1 = add nsw i32 %n, -1
  %3 = bitcast i32* %.omp.iv to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %3) #2
  %4 = bitcast i32* %.omp.ub to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %4) #2
  store i32 %sub1, i32* %.omp.ub, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.267
  br label %DIR.OMP.SIMD.1.split73

DIR.OMP.SIMD.1.split73:                           ; preds = %DIR.OMP.SIMD.1
  br label %DIR.OMP.SIMD.1.split73.split77

DIR.OMP.SIMD.1.split73.split77:                   ; preds = %DIR.OMP.SIMD.1.split73
  %tmpcast68.fast_red = getelementptr inbounds %struct.fast_red_t, %struct.fast_red_t* %fast_red_struct, i32 0, i32 1
  br label %DIR.OMP.SIMD.1.split73.split76

DIR.OMP.SIMD.1.split73.split76:                   ; preds = %DIR.OMP.SIMD.1.split73.split77
  call void @.omp_initializer..2(%struct.point* %tmpcast68.red, %struct.point* %tmpcast68)
  br label %DIR.OMP.SIMD.1.split73.split74

DIR.OMP.SIMD.1.split73.split74:                   ; preds = %DIR.OMP.SIMD.1.split73.split76
  %tmpcast.fast_red = getelementptr inbounds %struct.fast_red_t, %struct.fast_red_t* %fast_red_struct, i32 0, i32 0
  br label %DIR.OMP.SIMD.1.split73.split

DIR.OMP.SIMD.1.split73.split:                     ; preds = %DIR.OMP.SIMD.1.split73.split74
  call void @.omp_initializer.(%struct.point* %tmpcast.red, %struct.point* %tmpcast)
  br label %DIR.OMP.SIMD.1.split

DIR.OMP.SIMD.1.split:                             ; preds = %DIR.OMP.SIMD.1.split73.split
  %5 = load i32, i32* %.omp.ub, align 4
  br label %DIR.OMP.SIMD.269

DIR.OMP.SIMD.269:                                 ; preds = %DIR.OMP.SIMD.1.split
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.269
  %cmp3.not71 = icmp sgt i32 0, %5
  br i1 %cmp3.not71, label %DIR.OMP.END.SIMD.3.loopexit, label %omp.inner.for.body.lr.ph

omp.inner.for.body.lr.ph:                         ; preds = %DIR.OMP.SIMD.2
  %6 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(),
 "QUAL.OMP.REDUCTION.UDR"(%struct.point* %tmpcast.red, i8* null, i8* null, void (%struct.point*, %struct.point*)* @.omp_combiner., void (%struct.point*, %struct.point*)* @.omp_initializer.),
 "QUAL.OMP.REDUCTION.UDR"(%struct.point* %tmpcast68.red, i8* null, i8* null, void (%struct.point*, %struct.point*)* @.omp_combiner..1, void (%struct.point*, %struct.point*)* @.omp_initializer..2),
 "QUAL.OMP.LINEAR:IV"(i32* %i.linear.iv, i32 1),
 "QUAL.OMP.NORMALIZED.IV"(i8* null),
 "QUAL.OMP.NORMALIZED.UB"(i8* null) ]

  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.inc, %omp.inner.for.body.lr.ph
  %.omp.iv.local.072 = phi i32 [ 0, %omp.inner.for.body.lr.ph ], [ %add43, %omp.inner.for.inc ]
  store i32 %.omp.iv.local.072, i32* %i.linear.iv, align 4
  %idxprom = sext i32 %.omp.iv.local.072 to i64
  %x = getelementptr inbounds %struct.point, %struct.point* %points, i64 %idxprom, i32 0
  %7 = load i32, i32* %x, align 4
  %x5 = getelementptr inbounds %struct.point, %struct.point* %tmpcast.red, i64 0, i32 0
  %8 = load i32, i32* %x5, align 4
  %cmp6 = icmp slt i32 %7, %8
  br i1 %cmp6, label %if.then, label %if.end

if.then:                                          ; preds = %omp.inner.for.body
  store i32 %7, i32* %x5, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %omp.inner.for.body
  %9 = load i32, i32* %i.linear.iv, align 4
  %idxprom11 = sext i32 %9 to i64
  %y = getelementptr inbounds %struct.point, %struct.point* %points, i64 %idxprom11, i32 1
  %10 = load i32, i32* %y, align 4
  %y13 = getelementptr inbounds %struct.point, %struct.point* %tmpcast.red, i64 0, i32 1
  %11 = load i32, i32* %y13, align 4
  %cmp14 = icmp slt i32 %10, %11
  br i1 %cmp14, label %if.then15, label %if.end20

if.then15:                                        ; preds = %if.end
  store i32 %10, i32* %y13, align 4
  br label %if.end20

if.end20:                                         ; preds = %if.then15, %if.end
  %12 = load i32, i32* %i.linear.iv, align 4
  %idxprom21 = sext i32 %12 to i64
  %x23 = getelementptr inbounds %struct.point, %struct.point* %points, i64 %idxprom21, i32 0
  %13 = load i32, i32* %x23, align 4
  %x24 = getelementptr inbounds %struct.point, %struct.point* %tmpcast68.red, i64 0, i32 0
  %14 = load i32, i32* %x24, align 4
  %cmp25 = icmp sgt i32 %13, %14
  br i1 %cmp25, label %if.then26, label %if.end31

if.then26:                                        ; preds = %if.end20
  store i32 %13, i32* %x24, align 4
  br label %if.end31

if.end31:                                         ; preds = %if.then26, %if.end20
  %15 = load i32, i32* %i.linear.iv, align 4
  %idxprom32 = sext i32 %15 to i64
  %y34 = getelementptr inbounds %struct.point, %struct.point* %points, i64 %idxprom32, i32 1
  %16 = load i32, i32* %y34, align 4
  %y35 = getelementptr inbounds %struct.point, %struct.point* %tmpcast68.red, i64 0, i32 1
  %17 = load i32, i32* %y35, align 4
  %cmp36 = icmp sgt i32 %16, %17
  br i1 %cmp36, label %if.then37, label %omp.inner.for.inc

if.then37:                                        ; preds = %if.end31
  store i32 %16, i32* %y35, align 4
  br label %omp.inner.for.inc

omp.inner.for.inc:                                ; preds = %if.then37, %if.end31
  %add43 = add nsw i32 %.omp.iv.local.072, 1
  %18 = load i32, i32* %i.linear.iv, align 4
  %add44 = add nsw i32 %18, 1
  store i32 %add44, i32* %i.linear.iv, align 4
  %19 = add i32 %5, 1
  %cmp3.not = icmp sgt i32 %19, %add43
  br i1 %cmp3.not, label %omp.inner.for.body, label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge: ; preds = %omp.inner.for.inc
  call void @llvm.directive.region.exit(token %6) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.1

DIR.OMP.END.SIMD.1:                               ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge
  %20 = load %struct.point, %struct.point* %tmpcast.red, align 4
  store %struct.point %20, %struct.point* %tmpcast.fast_red, align 4
  br label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75: ; preds = %DIR.OMP.END.SIMD.1
  %21 = load %struct.point, %struct.point* %tmpcast68.red, align 4
  store %struct.point %21, %struct.point* %tmpcast68.fast_red, align 4
  br label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75.split

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75.split: ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75
  %22 = load i32, i32* %i.linear.iv, align 4
  store i32 %22, i32* %i, align 4
  br label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split: ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split75.split
  br label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split: ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split
  call void @.omp_combiner.(%struct.point* %tmpcast, %struct.point* %tmpcast.fast_red)
  br label %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split.split

omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split.split: ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split
  call void @.omp_combiner..1(%struct.point* %tmpcast68, %struct.point* %tmpcast68.fast_red)
  br label %DIR.OMP.END.SIMD.3.loopexit

DIR.OMP.END.SIMD.3.loopexit:                      ; preds = %omp.inner.for.cond.DIR.OMP.END.SIMD.3.loopexit_crit_edge.split.split.split, %DIR.OMP.SIMD.2
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %DIR.OMP.END.SIMD.3.loopexit
  br label %DIR.OMP.END.SIMD.370

DIR.OMP.END.SIMD.370:                             ; preds = %DIR.OMP.END.SIMD.3
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %DIR.OMP.END.SIMD.370, %entry
  %23 = bitcast i32* %.omp.ub to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %23) #2
  %24 = bitcast i32* %.omp.iv to i8*
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %24) #2
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %2) #2
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1) #2
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %0) #2
  ret void
}

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #2

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #2

; Function Attrs: alwaysinline nounwind uwtable
declare hidden void @.omp_combiner.(%struct.point* noalias noundef, %struct.point* noalias noundef) #3

; Function Attrs: alwaysinline nounwind uwtable
declare hidden void @.omp_initializer.(%struct.point* noalias noundef, %struct.point* noalias) #3

; Function Attrs: alwaysinline nounwind uwtable
declare hidden void @.omp_combiner..1(%struct.point* noalias noundef, %struct.point* noalias noundef) #3

; Function Attrs: alwaysinline nounwind uwtable
declare hidden void @.omp_initializer..2(%struct.point* noalias noundef, %struct.point* noalias) #3

; Function Attrs: argmemonly nocallback nofree nosync nounwind willreturn
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1
