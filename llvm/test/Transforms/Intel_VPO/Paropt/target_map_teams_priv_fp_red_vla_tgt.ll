; REQUIRES: asserts
; RUN: opt -bugpoint-enable-legacy-pm -vpo-paropt-handle-firstprivate-on-teams -switch-to-offload -vpo-cfg-restructuring -vpo-paropt -debug-only=WRegionUtils,vpo-paropt-transform -S %s 2>&1 | FileCheck %s -check-prefixes=LOCAL,ALL
; RUN: opt -vpo-paropt-handle-firstprivate-on-teams -switch-to-offload -aa-pipeline=basic-aa -passes='function(vpo-cfg-restructuring),vpo-paropt' -debug-only=WRegionUtils,vpo-paropt-transform -S %s 2>&1 | FileCheck %s -check-prefixes=LOCAL,ALL

; RUN: opt -bugpoint-enable-legacy-pm -vpo-paropt-teams-non-wilocal-vla-alloc-mode=module -vpo-paropt-handle-firstprivate-on-teams -switch-to-offload -vpo-cfg-restructuring -vpo-paropt -debug-only=WRegionUtils,vpo-paropt-transform -S %s 2>&1 | FileCheck %s -check-prefixes=MODULE,ALL
; RUN: opt -vpo-paropt-teams-non-wilocal-vla-alloc-mode=module -vpo-paropt-handle-firstprivate-on-teams -switch-to-offload -aa-pipeline=basic-aa -passes='function(vpo-cfg-restructuring),vpo-paropt' -debug-only=WRegionUtils,vpo-paropt-transform -S %s 2>&1 | FileCheck %s -check-prefixes=MODULE,ALL

; RUN: opt -vpo-paropt-handle-firstprivate-on-teams -bugpoint-enable-legacy-pm -switch-to-offload -vpo-cfg-restructuring -vpo-paropt -disable-output -pass-remarks-missed=openmp %s 2>&1 | FileCheck %s -check-prefix=REMARK
; RUN: opt -vpo-paropt-handle-firstprivate-on-teams -switch-to-offload -aa-pipeline=basic-aa -passes='function(vpo-cfg-restructuring),vpo-paropt' -disable-output -pass-remarks-missed=openmp %s 2>&1 | FileCheck %s -check-prefix=REMARK

; Test src:
;
; #include <stdio.h>
; int main() {
;   long n = 2;
;   int x[n], y[n], z[n];
;
; #pragma omp target map(tofrom:x, y, z)
; #pragma omp teams private(x) firstprivate(y) reduction(+:z)
;     printf("%p %p %p\n", x, y, z);
; }

; The test IR was generated by starting with the above src, removing the error checks
; in clang, and minimizing the IR.

; ALL:       collectNonPointerValuesToBeUsedInOutlinedRegion: Non-pointer values to be passed into the outlined region: 'i64 %n.v1 i64 %n.v2 i64 %n.v '
; ALL:       captureAndAddCollectedNonPointerValuesToSharedClause: Added implicit shared/map(to)/firstprivate clause for: 'ptr addrspace(4) [[NV1_ADDR:%n.v1.addr.*]]'
; ALL:       captureAndAddCollectedNonPointerValuesToSharedClause: Added implicit shared/map(to)/firstprivate clause for: 'ptr addrspace(4) [[NV2_ADDR:%n.v2.addr.*]]'
; ALL:       captureAndAddCollectedNonPointerValuesToSharedClause: Added implicit shared/map(to)/firstprivate clause for: 'ptr addrspace(4) [[NV_ADDR:%n.v.addr.*]]'

; With alloc-mode=module, a single element of the vlas is allocated at module level, but the
; accesses happens as if the allocation happened for the full vla. This is incorrect, but is
; kept-in in case there is a regression from making them work-item local
; (which is also incorrect, but less serious).
; MODULE:    [[VLA:@vla.ascast.priv.__local]] = internal addrspace(3) global i32 0
; MODULE:    [[VLA1:@vla1.ascast.fpriv.__local]] = internal addrspace(3) global i32 0
; MODULE:    [[VLA2:@vla2.ascast.red.__local]] = internal addrspace(3) global i32 0

; Check that the kernel function has arguments for the VLA and the captured VLA size, and the three firstprivate .
; ALL:      define {{.*}} void @__omp_offloading{{.*}}main{{.*}}(ptr addrspace(1) noalias %vla1.ascast, ptr addrspace(1) noalias %vla2.ascast, ptr addrspace(1) noalias %vla.ascast, i64 %n.v.addr.ascast.val, i64 %n.v1.addr.ascast.val, i64 %n.v2.addr.ascast.val, i64 [[NV1_ADDR]].val, i64 [[NV2_ADDR]].val, i64 [[NV_ADDR]].val)

; Check for the firstprivate allocation/initialization of the captured VLA sizes.
; ALL:       [[NV_ADDR]].fpriv = alloca i64, align 8
; ALL:       [[NV2_ADDR]].fpriv = alloca i64, align 8
; ALL:       [[NV1_ADDR]].fpriv = alloca i64, align 8

; ALL:       store i64 [[NV_ADDR]].val, ptr [[NV_ADDR]].fpriv, align 8
; ALL:       store i64 [[NV2_ADDR]].val, ptr [[NV2_ADDR]].fpriv, align 8
; ALL:       store i64 [[NV1_ADDR]].val, ptr [[NV1_ADDR]].fpriv, align 8

; Check that by default, the local copies of the three VLAs is allocated in the stack of the kernel.
; LOCAL:     %vla2.ascast.red = alloca i32, i64 %n.vv2, align 4
; LOCAL:     [[VLA2:%vla2.ascast.red.ascast]] = addrspacecast ptr %vla2.ascast.red to ptr addrspace(4)

; LOCAL:     %vla1.ascast.fpriv = alloca i32, i64 %n.vv1, align 4
; LOCAL:     [[VLA1:%vla1.ascast.fpriv.ascast]] = addrspacecast ptr %vla1.ascast.fpriv to ptr addrspace(4)

; LOCAL:     %vla.ascast.priv = alloca i32, i64 %n.vv, align 4
; LOCAL:     [[VLA:%vla.ascast.priv.ascast]] = addrspacecast ptr %vla.ascast.priv to ptr addrspace(4)

; Check that the private copies are used inside the region.
; LOCAL:       %oclPrint = call i32 (ptr addrspace(2), ...) @_Z18__spirv_ocl_printfPU3AS2cz({{.*}}, ptr addrspace(4) [[VLA]], ptr addrspace(4) [[VLA1]], ptr addrspace(4) [[VLA2]])
; MODULE:      %oclPrint = call i32 (ptr addrspace(2), ...) @_Z18__spirv_ocl_printfPU3AS2cz({{.*}}, ptr addrspace(4) addrspacecast (ptr addrspace(3) [[VLA]] to ptr addrspace(4)), ptr addrspace(4) addrspacecast (ptr addrspace(3) [[VLA1]] to ptr addrspace(4)), ptr addrspace(4) addrspacecast (ptr addrspace(3) [[VLA2]] to ptr addrspace(4)))

; REMARK: remark: <unknown>:0:0: VLAs requested to be team (work group) local will be made thread (work-item) local. Team local VLA allocation is not supported. The experimental flag `-mllvm -vpo-paropt-teams-non-wilocal-vla-alloc-mode=module` can be used to force a team-local allocation, but is not recommended.

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-n8:16:32:64"
target triple = "spir64"
target device_triples = "spir64"

@.str = private unnamed_addr addrspace(1) constant [10 x i8] c"%p %p %p\0A\00", align 1

define protected i32 @main() {
entry:
  %n = alloca i64, align 8
  %n.ascast = addrspacecast ptr %n to ptr addrspace(4)
  %n.v.addr = alloca i64, align 8
  %n.v.addr.ascast = addrspacecast ptr %n.v.addr to ptr addrspace(4)
  %n.v1.addr = alloca i64, align 8
  %n.v1.addr.ascast = addrspacecast ptr %n.v1.addr to ptr addrspace(4)
  %n.v2.addr = alloca i64, align 8
  %n.v2.addr.ascast = addrspacecast ptr %n.v2.addr to ptr addrspace(4)
  store i64 2, ptr addrspace(4) %n.ascast, align 8

  %n.v = load i64, ptr addrspace(4) %n.ascast, align 8
  %vla = alloca i32, i64 %n.v, align 4
  %vla.ascast = addrspacecast ptr %vla to ptr addrspace(4)

  %n.v1 = load i64, ptr addrspace(4) %n.ascast, align 8
  %vla1 = alloca i32, i64 %n.v1, align 4
  %vla1.ascast = addrspacecast ptr %vla1 to ptr addrspace(4)

  %n.v2 = load i64, ptr addrspace(4) %n.ascast, align 8
  %vla2 = alloca i32, i64 %n.v2, align 4
  %vla2.ascast = addrspacecast ptr %vla2 to ptr addrspace(4)

  %map_size1 = mul nuw i64 %n.v1, 4
  %arrayidx = getelementptr inbounds i32, ptr addrspace(4) %vla1.ascast, i64 0
  %map_size2 = mul nuw i64 %n.v2, 4
  %arrayidx5 = getelementptr inbounds i32, ptr addrspace(4) %vla2.ascast, i64 0
  %map_size3 = mul nuw i64 %n.v, 4
  %arrayidx6 = getelementptr inbounds i32, ptr addrspace(4) %vla.ascast, i64 0

  store i64 %n.v, ptr addrspace(4) %n.v.addr.ascast, align 8
  store i64 %n.v1, ptr addrspace(4) %n.v1.addr.ascast, align 8
  store i64 %n.v2, ptr addrspace(4) %n.v2.addr.ascast, align 8

  %dir1 = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(),
    "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 0),
    "QUAL.OMP.MAP.TOFROM"(ptr addrspace(4) %vla1.ascast, ptr addrspace(4) %arrayidx, i64 %map_size1, i64 35, ptr null, ptr null),
    "QUAL.OMP.MAP.TOFROM"(ptr addrspace(4) %vla2.ascast, ptr addrspace(4) %arrayidx5, i64 %map_size2, i64 35, ptr null, ptr null),
    "QUAL.OMP.MAP.TOFROM"(ptr addrspace(4) %vla.ascast, ptr addrspace(4) %arrayidx6, i64 %map_size3, i64 3, ptr null, ptr null),
    "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr addrspace(4) %n.v.addr.ascast, i64 0, i32 1),
    "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr addrspace(4) %n.v1.addr.ascast, i64 0, i32 1),
    "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr addrspace(4) %n.v2.addr.ascast, i64 0, i32 1) ]

  %n.vv = load i64, ptr addrspace(4) %n.v.addr.ascast
  %n.vv1 = load i64, ptr addrspace(4) %n.v1.addr.ascast
  %n.vv2 = load i64, ptr addrspace(4) %n.v2.addr.ascast

  %dir2 = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(),
  "QUAL.OMP.PRIVATE:TYPED"(ptr addrspace(4) %vla.ascast, i32 0, i64 %n.vv),
  "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr addrspace(4) %vla1.ascast, i32 0, i64 %n.vv1),
  "QUAL.OMP.REDUCTION.ADD:TYPED"(ptr addrspace(4) %vla2.ascast, i32 0, i64 %n.vv2) ]

  %call = call spir_func i32 (ptr addrspace(4), ...) @printf(ptr addrspace(4) noundef addrspacecast (ptr addrspace(1) @.str to ptr addrspace(4)), ptr addrspace(4) noundef %vla.ascast, ptr addrspace(4) noundef %vla1.ascast, ptr addrspace(4) noundef %vla2.ascast)

  call void @llvm.directive.region.exit(token %dir2) [ "DIR.OMP.END.TEAMS"() ]
  call void @llvm.directive.region.exit(token %dir1) [ "DIR.OMP.END.TARGET"() ]

  ret i32 0
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare spir_func i32 @printf(ptr addrspace(4) noundef, ...)

!omp_offload.info = !{!0}
!0 = !{i32 0, i32 66313, i32 135942823, !"_Z4main", i32 6, i32 0, i32 0}
