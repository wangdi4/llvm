; RUN: opt -enable-new-pm=0 -O0 -paropt=31 -S %s | FileCheck %s
; RUN: opt -enable-new-pm=1 -passes='default<O0>' -paropt=31 -S %s | FileCheck %s


; RUN: opt -enable-new-pm=0 -O2 -paropt=31 -S %s | FileCheck %s
; RUN: opt -enable-new-pm=1 -passes='default<O2>' -paropt=31 -S %s | FileCheck %s

; RUN: opt -enable-new-pm=0 -O3 -paropt=31 -S %s | FileCheck %s
; RUN: opt -enable-new-pm=1 -passes='default<O3>' -paropt=31 -S %s | FileCheck %s

; The test is just to check that this IR doens't cause a comp-fail. The
; comp-fail was happening in code-extractor after inliner inlined f1 into
; f2, but replaced %C1 on the TARGET directive and inside the region with
; different values.

; Problemeting IR that was being generated by the inliner:
;  %C2 = alloca i8*, align 8
;  %tmpcast = bitcast i8** %C2 to %struct.S*
;  ...
;  %2 = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), ... , "QUAL.OMP.FIRSTPRIVATE"(%struct.S* %tmpcast), ... ]
;  ...
;  call void @f3(i8** %C2)
;  call void @llvm.directive.region.exit(token %2) [ "DIR.OMP.END.TARGET"() ]

; This was resolved by ensuring that -vpo-restore-operands runs after
; the inliner pipeline:

; Correct IR (vpo-restore-operands run after inliner):
;  %C2 = alloca i8*, align 8
;  %tmpcast = bitcast i8** %C2 to %struct.S*
;  ...
;  %2 = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), ... , "QUAL.OMP.FIRSTPRIVATE"(%struct.S* %tmpcast), ... ]
;  ...
;  %C1.cast.i = bitcast %struct.S* %tmpcast to i8**
;  call void @f3(i8** %C1.cast.i)
;  ...
;  call void @llvm.directive.region.exit(token %2) [ "DIR.OMP.END.TARGET"() ]

; CHECK: call i32 @__tgt_target_mapper({{.*}})

target device_triples = "x86_64"

%struct.S = type <{ i64 }>

define void @f1(%struct.S* %C1) {
entry:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 0), "QUAL.OMP.FIRSTPRIVATE"(%struct.S* %C1) ]

  %C1.cast = bitcast %struct.S* %C1 to i8**
  call void @f3(i8** %C1.cast)

  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.TARGET"() ]
  ret void
}

define void @f2() {
entry:
  %C2 = alloca %struct.S, align 8

  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.DATA"() ]

  %C2.cast = bitcast %struct.S* %C2 to i8**
  store i8* undef, i8** %C2.cast, align 8
  call void @f1(%struct.S* %C2)
  br label %exit

exit:                                             ; preds = %entry
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.TARGET.DATA"() ]
  ret void
}

declare void @f3(i8**)

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #0

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #0

attributes #0 = { nounwind }

!omp_offload.info = !{!0}

!0 = !{i32 0, i32 66313, i32 90378038, !"f1", i32 24, i32 0, i32 0}
