; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -S < %s -VPlanDriver -vplan-force-vf=4 2>&1 | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

declare i32 @__intel_indirect_call_i32(i32(i32)*, ...) #2

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #3

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #3
; Function Attrs: nounwind uwtable
define dso_local void @_ZGVbN4_direct(i32* nocapture %a, i32* nocapture readonly %c, i32 (i32)** nocapture readonly %func, i64 %n) local_unnamed_addr #1 {
; CHECK:  define dso_local void @_ZGVbN4_direct(i32* nocapture [[A0:%.*]], i32* nocapture readonly [[C0:%.*]], i32 (i32)** nocapture readonly [[FUNC0:%.*]], i64 [[N0:%.*]]) local_unnamed_addr #2 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  preheader:
; CHECK-NEXT:    [[N_MOD_VF0:%.*]] = urem i64 [[N0]], 4
; CHECK-NEXT:    [[N_VEC0:%.*]] = sub i64 [[N0]], [[N_MOD_VF0]]
; CHECK-NEXT:    [[CMP_ZERO0:%.*]] = icmp eq i64 [[N_VEC0]], 0
; CHECK-NEXT:    br i1 [[CMP_ZERO0]], label [[SCALAR_PH0:%.*]], label [[VECTOR_PH0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.ph:
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ 0, [[VECTOR_PH0]] ], [ [[TMP10:%.*]], [[INDIRECT_CALL_LOOP_EXIT0:%.*]] ]
; CHECK-NEXT:    [[UNI_PHI10:%.*]] = phi i64 [ [[TMP9:%.*]], [[INDIRECT_CALL_LOOP_EXIT0]] ], [ 0, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <4 x i64> [ [[TMP8:%.*]], [[INDIRECT_CALL_LOOP_EXIT0]] ], [ <i64 0, i64 1, i64 2, i64 3>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32 (i32)*, i32 (i32)** [[FUNC0]], i64 [[UNI_PHI10]]
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast i32 (i32)** [[SCALAR_GEP0]] to <4 x i32 (i32)*>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <4 x i32 (i32)*>, <4 x i32 (i32)*>* [[TMP0]], align 8
; CHECK-NEXT:    [[SCALAR_GEP20:%.*]] = getelementptr inbounds i32, i32* [[C0]], i64 [[UNI_PHI10]]
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i32* [[SCALAR_GEP20]] to <4 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD30:%.*]] = load <4 x i32>, <4 x i32>* [[TMP1]], align 4
; CHECK-NEXT:    br label [[INDIRECT_CALL_LOOP_ENTRY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.entry:
; CHECK-NEXT:    [[VECTOR_OF_FUNC_PTRS0:%.*]] = phi <4 x i32 (i32)*> [ [[WIDE_LOAD0]], [[VECTOR_BODY0]] ], [ [[CURRENT_VECTOR_OF_FUNC_PTRS0:%.*]], [[INDIRECT_CALL_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[CUR_INDIRECT_CALL_RETURN0:%.*]] = phi <4 x i32> [ zeroinitializer, [[VECTOR_BODY0]] ], [ [[FINAL_INDIRECT_CALL_RETURN0:%.*]], [[INDIRECT_CALL_LOOP_LATCH0]] ]
; CHECK-NEXT:    [[INDX0:%.*]] = phi i64 [ 0, [[VECTOR_BODY0]] ], [ [[INDX_UPDATED0:%.*]], [[INDIRECT_CALL_LOOP_LATCH0]] ]
; CHECK-NEXT:    [[CURRENT_FPTR0:%.*]] = extractelement <4 x i32 (i32)*> [[VECTOR_OF_FUNC_PTRS0]], i64 [[INDX0]]
; CHECK-NEXT:    [[IS_VISITED0:%.*]] = icmp eq i32 (i32)* [[CURRENT_FPTR0]], null
; CHECK-NEXT:    br i1 [[IS_VISITED0]], label [[INDIRECT_CALL_LOOP_LATCH0]], label [[VECTOR_INDIRECT_CALL0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.indirect.call:
; CHECK-NEXT:    [[CURRENT_FPTR_SPLATINSERT0:%.*]] = insertelement <4 x i32 (i32)*> undef, i32 (i32)* [[CURRENT_FPTR0]], i32 0
; CHECK-NEXT:    [[CURRENT_FPTR_SPLAT0:%.*]] = shufflevector <4 x i32 (i32)*> [[CURRENT_FPTR_SPLATINSERT0]], <4 x i32 (i32)*> undef, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[FUNC_PTR_MASK0:%.*]] = icmp eq <4 x i32 (i32)*> [[CURRENT_FPTR_SPLAT0]], [[VECTOR_OF_FUNC_PTRS0]]
; CHECK-NEXT:    [[VECTOR_FUNC_PTR_MASK0:%.*]] = sext <4 x i1> [[FUNC_PTR_MASK0]] to <4 x i32>
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32 (i32)* [[CURRENT_FPTR0]] to <4 x i32> (<4 x i32>, <4 x i32>)**
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr <4 x i32> (<4 x i32>, <4 x i32>)*, <4 x i32> (<4 x i32>, <4 x i32>)** [[TMP2]], i32 1
; CHECK-NEXT:    [[TMP4:%.*]] = load <4 x i32> (<4 x i32>, <4 x i32>)*, <4 x i32> (<4 x i32>, <4 x i32>)** [[TMP3]], align 8
; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i32> [[TMP4]](<4 x i32> [[WIDE_LOAD30]], <4 x i32> [[VECTOR_FUNC_PTR_MASK0]])
; CHECK-NEXT:    [[INDIRECT_CALL_RETURN_UPDATED0:%.*]] = select <4 x i1> [[FUNC_PTR_MASK0]], <4 x i32> [[TMP5]], <4 x i32> [[CUR_INDIRECT_CALL_RETURN0]]
; CHECK-NEXT:    [[VECTOR_OF_FUNC_PTRS_UPDATED0:%.*]] = select <4 x i1> [[FUNC_PTR_MASK0]], <4 x i32 (i32)*> zeroinitializer, <4 x i32 (i32)*> [[VECTOR_OF_FUNC_PTRS0]]
; CHECK-NEXT:    br label [[INDIRECT_CALL_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.latch:
; CHECK-NEXT:    [[FINAL_INDIRECT_CALL_RETURN0]] = phi <4 x i32> [ [[INDIRECT_CALL_RETURN_UPDATED0]], [[VECTOR_INDIRECT_CALL0]] ], [ [[CUR_INDIRECT_CALL_RETURN0]], [[INDIRECT_CALL_LOOP_ENTRY0]] ]
; CHECK-NEXT:    [[CURRENT_VECTOR_OF_FUNC_PTRS0]] = phi <4 x i32 (i32)*> [ [[VECTOR_OF_FUNC_PTRS_UPDATED0]], [[VECTOR_INDIRECT_CALL0]] ], [ [[VECTOR_OF_FUNC_PTRS0]], [[INDIRECT_CALL_LOOP_ENTRY0]] ]
; CHECK-NEXT:    [[INDX_UPDATED0]] = add i64 [[INDX0]], 1
; CHECK-NEXT:    [[EXITCOND40:%.*]] = icmp eq i64 [[INDX_UPDATED0]], 4
; CHECK-NEXT:    br i1 [[EXITCOND40]], label [[INDIRECT_CALL_LOOP_EXIT0]], label [[INDIRECT_CALL_LOOP_ENTRY0]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.exit:
; CHECK-NEXT:    [[INDIRECT_CALL_RETURN_LCSSA_PHI0:%.*]] = phi <4 x i32> [ [[FINAL_INDIRECT_CALL_RETURN0]], [[INDIRECT_CALL_LOOP_LATCH0]] ]
; CHECK-NEXT:    [[TMP6:%.*]] = load i32, i32* [[A0]], align 4
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <4 x i32> undef, i32 [[TMP6]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT0]], <4 x i32> undef, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP7:%.*]] = add nsw <4 x i32> [[BROADCAST_SPLAT0]], [[INDIRECT_CALL_RETURN_LCSSA_PHI0]]
; CHECK-NEXT:    [[TMP8]] = add nsw <4 x i64> [[VEC_PHI0]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP9]] = add nsw i64 [[UNI_PHI10]], 4
; CHECK-NEXT:    [[TMP10]] = add i64 [[UNI_PHI0]], 4
; CHECK-NEXT:    [[TMP11:%.*]] = icmp eq i64 [[TMP10]], [[N_VEC0]]
; CHECK-NEXT:    br i1 [[TMP11]], label [[VPLANNEDBB0:%.*]], label [[VECTOR_BODY0]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB:
; CHECK-NEXT:    [[TMP12:%.*]] = mul i64 1, [[N_VEC0]]
; CHECK-NEXT:    [[TMP13:%.*]] = add i64 0, [[TMP12]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
entry:
  br label %preheader

preheader:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %iv.phi = phi i64 [ %iv, %for.body ], [ 0, %preheader ]
  %arrayidx1 = getelementptr inbounds i32 (i32)*, i32 (i32)** %func, i64 %iv.phi
  %ld.func = load i32 (i32)*, i32 (i32)** %arrayidx1, align 8
  %arrayidx2 = getelementptr inbounds i32, i32* %c, i64 %iv.phi
  %ld.c = load i32, i32* %arrayidx2, align 4
  %call = call i32 (i32(i32)*, ...) @__intel_indirect_call_i32(i32 (i32)* %ld.func, i32 %ld.c) #2
  %ld.a = load i32, i32* %a, align 4
  %add = add nsw i32 %ld.a, %call
  %iv = add nsw i64 %iv.phi, 1
  %exitcond = icmp eq i64 %iv, %n
  br i1 %exitcond, label %loop.exit, label %for.body

loop.exit:
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %end

end:
  ret void
}

attributes #1 = { "vector-variants"="_ZGVbM4vvvv_direct,_ZGVbN4vvvv_direct" }
attributes #2 = { "vector-variants"="_ZGVbM4v___intel_indirect_call_i32,_ZGVbN4v___intel_indirect_call_i32" }
attributes #3 = { nounwind }


