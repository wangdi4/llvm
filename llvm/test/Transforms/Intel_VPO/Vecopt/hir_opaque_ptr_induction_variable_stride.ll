; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -opaque-pointers -passes='hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec' -vplan-print-after-vpentity-instrs -disable-output < %s 2>&1 | FileCheck %s

; Test checks that a multiplier is used as the operand of the induction-init-step
; for opaque pointer inductions because the pointer element type is treated as i8.
; If not adjusted the stride will be incorrect.

define dso_local noundef i32 @main() local_unnamed_addr #1 {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: main:HIR.#{{[0-9]+}}
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%lp.linear}
; CHECK-DAG:     [[VP1:%.*]] = {%i3.linear.iv}
; CHECK-DAG:     [[VP2:%.*]] = {%0 + 1}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     ptr [[VP_LP_LINEAR:%.*]] = allocate-priv ptr, OrigAlign = 8
; CHECK-NEXT:     i32 [[VP__IND_INIT:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:     i32 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i32 1
; CHECK-NEXT:     ptr [[VP_LOAD:%.*]] = load ptr [[LP_LINEAR0:%.*]]
; CHECK-NEXT:     i64 [[VP3:%.*]] = mul i64 [[VP2]] i64 8
; CHECK-NEXT:     ptr [[VP_LP_LINEAR_IND_INIT:%.*]] = induction-init{getelementptr} ptr [[VP_LOAD]] i64 [[VP3]]
; CHECK-NEXT:     store ptr [[VP_LP_LINEAR_IND_INIT]] ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64 [[VP_LP_LINEAR_IND_INIT_STEP:%.*]] = induction-init-step{getelementptr} i64 [[VP3]]
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
;
entry:
  %lp.linear = alloca ptr, align 8
  %i3.linear.iv = alloca i32, align 4
  %a = alloca [128 x i64], align 16
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %arrayidx1 = getelementptr inbounds [128 x i64], ptr %a, i64 0, i64 1
  %0 = load i64, ptr %arrayidx1, align 8
  %arraydecay = getelementptr inbounds [128 x i64], ptr %a, i64 0, i64 0
  %add = add nsw i64 %0, 1
  store ptr %arraydecay, ptr %lp.linear, align 8
  br label %DIR.OMP.SIMD.126

DIR.OMP.SIMD.126:                                 ; preds = %DIR.OMP.SIMD.1
  %1 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(ptr %lp.linear, i64 0, i32 1, i64 %add), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr null, i32 0), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr null, i32 0), "QUAL.OMP.LINEAR:IV.TYPED"(ptr %i3.linear.iv, i32 0, i32 1, i32 1) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.126, %omp.inner.for.body
  %.omp.iv.local.022 = phi i32 [ 0, %DIR.OMP.SIMD.126 ], [ %add6, %omp.inner.for.body ]
  call void @_Z3bazPPl(ptr noundef nonnull %lp.linear)
  %2 = load ptr, ptr %lp.linear, align 8
  %add.ptr = getelementptr inbounds i64, ptr %2, i64 %add
  store ptr %add.ptr, ptr %lp.linear, align 8
  %add6 = add nuw nsw i32 %.omp.iv.local.022, 1
  %exitcond25.not = icmp eq i32 %add6, 64
  br i1 %exitcond25.not, label %DIR.OMP.END.SIMD.1, label %omp.inner.for.body

DIR.OMP.END.SIMD.1:                               ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %1) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.2

DIR.OMP.END.SIMD.2:                               ; preds = %DIR.OMP.END.SIMD.1
  ret i32 0
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare dso_local void @_Z3bazPPl(i64** noundef) local_unnamed_addr #0

attributes #0 = { nounwind }
