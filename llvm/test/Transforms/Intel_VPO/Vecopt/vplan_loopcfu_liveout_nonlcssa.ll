; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: asserts

; RUN: opt -S -vplan-func-vec -print-after-vplan-func-vec-loop-cfu < %s -disable-output | FileCheck %s
; RUN: opt -S -passes="vplan-func-vec" -print-after-vplan-func-vec-loop-cfu < %s -disable-output | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

;; Test for non-LCSSA form when the LCSSA phi is merged into the loop body by
;; merge loop exits transformation. That happens because Loop Merge Exit
;; transformation isn't preserving LCSSA form and the test would become useless
;; once this is fixed. In fact, we should fix this and add an assert in the
;; LoopCFU transformation for any non-LCSSA uses.
define dso_local void @foo_non_lcssa(i64 %N, i64 *%a, i64 %mask_out_loop) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan IR for: foo_non_lcssa
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     [DA: Div] i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:     [DA: Div] i1 [[VP_SKIP_LOOP:%.*]] = icmp i32 [[VP_LANE]] i64 [[MASK_OUT_LOOP0:%.*]]
; CHECK-NEXT:    SUCCESSORS(2):[[BB1:BB[0-9]+]](i1 [[VP_SKIP_LOOP]]), [[BB2:BB[0-9]+]](!i1 [[VP_SKIP_LOOP]])
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]:
; CHECK-NEXT:       [DA: Div] i1 [[VP_CMP216:%.*]] = icmp i32 [[VP_LANE]] i64 0
; CHECK-NEXT:       [DA: Div] i1 [[VP_CMP216_NOT:%.*]] = not i1 [[VP_CMP216]]
; CHECK-NEXT:      SUCCESSORS(2):[[BB1]](i1 [[VP_CMP216]]), [[BB3:BB[0-9]+]](!i1 [[VP_CMP216]])
; CHECK-NEXT:      PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       [DA: Uni] i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_NEXT:%.*]], [[BB5:BB[0-9]+]] ],  [ i64 0, [[BB3]] ]
; CHECK-NEXT:       [DA: Div] i1 [[VP_LOOP_MASK:%.*]] = phi  [ i1 [[VP_CMP216_NOT]], [[BB3]] ],  [ i1 [[VP_LOOP_MASK_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i1 [[VP_NO_PHI_INST_USE_LIVE_OUT_PREV:%.*]] = phi  [ i1 undef, [[BB3]] ],  [ i1 [[VP_NO_PHI_INST_USE_LIVE_OUT_BLEND:%.*]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_UPDATE_USE_LIVE_OUT_PREV:%.*]] = phi  [ i64 undef, [[BB3]] ],  [ i64 [[VP_PHI_UPDATE_USE_LIVE_OUT_BLEND:%.*]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_USE_LIVE_OUT_PREV:%.*]] = phi  [ i64 undef, [[BB3]] ],  [ i64 [[VP_PHI_USE_LIVE_OUT_BLEND:%.*]], [[BB5]] ]
; CHECK-NEXT:      SUCCESSORS(2):[[BB6:BB[0-9]+]](i1 [[VP_LOOP_MASK]]), [[BB5]](!i1 [[VP_LOOP_MASK]])
; CHECK-NEXT:      PREDECESSORS(2): [[BB3]] [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB6]]:
; CHECK-NEXT:         [DA: Uni] i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:         [DA: Uni] i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:         [DA: Uni] i1 [[VP_SOME_CMP:%.*]] = icmp i64 [[VP_LD]] i64 42
; CHECK-NEXT:         [DA: Uni] i64 [[VP_IV_NEXT]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:        SUCCESSORS(2):[[INTERMEDIATE_BB0:intermediate.bb[0-9]+]](i1 [[VP_SOME_CMP]]), [[BB7:BB[0-9]+]](!i1 [[VP_SOME_CMP]])
; CHECK-NEXT:        PREDECESSORS(1): [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:          [[BB7]]:
; CHECK-NEXT:           [DA: Div] i1 [[VP_EXITCOND:%.*]] = icmp i64 [[VP_IV_NEXT]] i32 [[VP_LANE]]
; CHECK-NEXT:          SUCCESSORS(1):[[NEW_LOOP_LATCH0:new.loop.latch[0-9]+]]
; CHECK-NEXT:          PREDECESSORS(1): [[BB6]]
; CHECK-EMPTY:
; CHECK-NEXT:          [[INTERMEDIATE_BB0]]:
; CHECK-NEXT:           <Empty Block>
; CHECK-NEXT:          SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:          PREDECESSORS(1): [[BB6]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[NEW_LOOP_LATCH0]]:
; CHECK-NEXT:         [DA: Uni] i32 [[VP_EXIT_ID_PHI:%.*]] = phi  [ i32 0, [[BB7]] ],  [ i32 1, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:         [DA: Uni] i1 [[VP_NO_PHI_INST_USE:%.*]] = phi  [ i1 [[VP_SOME_CMP]], [[INTERMEDIATE_BB0]] ],  [ i1 false, [[BB7]] ]
; CHECK-NEXT:         [DA: Uni] i64 [[VP_PHI_UPDATE_USE:%.*]] = phi  [ i64 [[VP_IV_NEXT]], [[INTERMEDIATE_BB0]] ],  [ i64 100, [[BB7]] ]
; CHECK-NEXT:         [DA: Uni] i64 [[VP_PHI_USE:%.*]] = phi  [ i64 [[VP_IV]], [[INTERMEDIATE_BB0]] ],  [ i64 100, [[BB7]] ]
; CHECK-NEXT:         [DA: Div] i1 [[VP_TAKE_BACKEDGE_COND:%.*]] = phi  [ i1 [[VP_EXITCOND]], [[BB7]] ],  [ i1 true, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:        SUCCESSORS(1):[[BB5]]
; CHECK-NEXT:        PREDECESSORS(2): [[BB7]] [[INTERMEDIATE_BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       [DA: Div] i1 [[VP_NO_PHI_INST_USE_LIVE_OUT_BLEND]] = select i1 [[VP_LOOP_MASK]] i1 [[VP_NO_PHI_INST_USE]] i1 [[VP_NO_PHI_INST_USE_LIVE_OUT_PREV]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_UPDATE_USE_LIVE_OUT_BLEND]] = select i1 [[VP_LOOP_MASK]] i64 [[VP_PHI_UPDATE_USE]] i64 [[VP_PHI_UPDATE_USE_LIVE_OUT_PREV]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_USE_LIVE_OUT_BLEND]] = select i1 [[VP_LOOP_MASK]] i64 [[VP_PHI_USE]] i64 [[VP_PHI_USE_LIVE_OUT_PREV]]
; CHECK-NEXT:       [DA: Div] i1 [[VP_TAKE_BACKEDGE_COND_NOT:%.*]] = not i1 [[VP_TAKE_BACKEDGE_COND]]
; CHECK-NEXT:       [DA: Div] i1 [[VP_LOOP_MASK_NEXT]] = and i1 [[VP_TAKE_BACKEDGE_COND_NOT]] i1 [[VP_LOOP_MASK]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP0:%.*]] = all-zero-check i1 [[VP_LOOP_MASK_NEXT]]
; CHECK-NEXT:      SUCCESSORS(2):[[BB8:BB[0-9]+]](i1 [[VP0]]), [[BB4]](!i1 [[VP0]])
; CHECK-NEXT:      PREDECESSORS(2): [[NEW_LOOP_LATCH0]] [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB8]]:
; CHECK-NEXT:       [DA: Div] i1 [[VP_NO_PHI_INST_USE_LCSSA:%.*]] = phi  [ i1 [[VP_NO_PHI_INST_USE_LIVE_OUT_BLEND]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_UPDATE_USE_LCSSA:%.*]] = phi  [ i64 [[VP_PHI_UPDATE_USE_LIVE_OUT_BLEND]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_PHI_USE_LCSSA:%.*]] = phi  [ i64 [[VP_PHI_USE_LIVE_OUT_BLEND]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_USE_A:%.*]] = add i64 [[VP_PHI_USE_LCSSA]] i64 1
; CHECK-NEXT:       [DA: Div] i64 [[VP_USE_B:%.*]] = add i64 [[VP_PHI_UPDATE_USE_LCSSA]] i64 1
; CHECK-NEXT:       [DA: Div] i1 [[VP_USE_C:%.*]] = xor i1 [[VP_NO_PHI_INST_USE_LCSSA]] i1 true
; CHECK-NEXT:      SUCCESSORS(1):[[BB1]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div] void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(3): [[BB0]] [[BB2]] [[BB8]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  %skip_loop = icmp eq i64 %lane, %mask_out_loop
  br i1 %skip_loop, label %exit, label %top_test

top_test:
  %cmp216 = icmp eq i64 %lane, 0
  br i1 %cmp216, label %exit, label %preheader

preheader:
  br label %header

header:
  %iv = phi i64 [ %iv.next, %no_early_exit ], [ 0, %preheader ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %some_cmp = icmp eq i64 %ld, 42
  %iv.next = add nuw nsw i64 %iv, 1
  br i1 %some_cmp, label %loop.exit, label %no_early_exit

no_early_exit:
  %exitcond = icmp eq i64 %iv.next, %lane
  br i1 %exitcond, label %loop.exit, label %header

loop.exit:
  %phi_use = phi i64 [ %iv, %header ], [ 100, %no_early_exit ]
  %phi_update_use = phi i64 [ %iv.next, %header ], [ 100, %no_early_exit ]
  %no_phi_inst_use = phi i1 [%some_cmp, %header ], [ 100, %no_early_exit ]
  %use_a = add i64 %phi_use, 1
  %use_b = add i64 %phi_update_use, 1
  %use_c = xor i1 %no_phi_inst_use, -1
  br label %exit

exit:
  ret void
}

define dso_local void @foo_non_lcssa_from_uniform_sub_loop(i64 %N, i64 *%a, i64 %mask_out_loop) {
; CHECK-LABEL:  VPlan IR for: foo_non_lcssa_from_uniform_sub_loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     [DA: Div] i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div] i64 [[VP_IV:%.*]] = phi  [ i32 [[VP_LANE]], [[BB0]] ],  [ i64 [[VP_IV_NEXT:%.*]], [[BB2:BB[0-9]+]] ]
; CHECK-NEXT:     [DA: Div] i1 [[VP_LOOP_MASK:%.*]] = phi  [ i1 true, [[BB0]] ],  [ i1 [[VP_LOOP_MASK_NEXT:%.*]], [[BB2]] ]
; CHECK-NEXT:     [DA: Div] i64 [[VP_INNER_DEF_LCSSA_LIVE_OUT_PREV:%.*]] = phi  [ i64 undef, [[BB0]] ],  [ i64 [[VP_INNER_DEF_LCSSA_LIVE_OUT_BLEND:%.*]], [[BB2]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[BB3:BB[0-9]+]](i1 [[VP_LOOP_MASK]]), [[BB2]](!i1 [[VP_LOOP_MASK]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       [DA: Div] i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:       [DA: Div] i1 [[VP_SOME_CMP:%.*]] = icmp i64 [[VP_LD]] i64 42
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV_NEXT]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       [DA: Uni] i64 [[VP_INNER_IV:%.*]] = phi  [ i64 0, [[BB3]] ],  [ i64 [[VP_INNER_IV_NEXT:%.*]], [[BB4]] ]
; CHECK-NEXT:       [DA: Uni] i64 [[VP_INNER_IV_NEXT]] = add i64 [[VP_INNER_IV]] i64 1
; CHECK-NEXT:       [DA: Div] i64 [[VP_MUL:%.*]] = mul i64 [[VP_IV]] i64 100
; CHECK-NEXT:       [DA: Div] i64 [[VP_IDX:%.*]] = add i64 [[VP_MUL]] i64 [[VP_INNER_IV]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_GEP:%.*]] = getelementptr i64* [[A0]] i64 [[VP_IDX]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_INNER_DEF:%.*]] = load i64* [[VP_GEP]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP_INNER_EXITCOND:%.*]] = icmp i64 [[VP_INNER_IV_NEXT]] i64 100
; CHECK-NEXT:      SUCCESSORS(2):[[BB5:BB[0-9]+]](i1 [[VP_INNER_EXITCOND]]), [[BB4]](!i1 [[VP_INNER_EXITCOND]])
; CHECK-NEXT:      PREDECESSORS(2): [[BB4]] [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       [DA: Div] i64 [[VP_INNER_DEF_LCSSA:%.*]] = phi  [ i64 [[VP_INNER_DEF]], [[BB4]] ]
; CHECK-NEXT:      SUCCESSORS(1):[[BB2]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div] i64 [[VP_INNER_DEF_LCSSA_LIVE_OUT_BLEND]] = select i1 [[VP_LOOP_MASK]] i64 [[VP_INNER_DEF_LCSSA]] i64 [[VP_INNER_DEF_LCSSA_LIVE_OUT_PREV]]
; CHECK-NEXT:     [DA: Div] i1 [[VP_SOME_CMP_NOT:%.*]] = not i1 [[VP_SOME_CMP]]
; CHECK-NEXT:     [DA: Div] i1 [[VP_LOOP_MASK_NEXT]] = and i1 [[VP_SOME_CMP_NOT]] i1 [[VP_LOOP_MASK]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP0:%.*]] = all-zero-check i1 [[VP_LOOP_MASK_NEXT]]
; CHECK-NEXT:    SUCCESSORS(2):[[BB6:BB[0-9]+]](i1 [[VP0]]), [[BB1]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB5]] [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]:
; CHECK-NEXT:     [DA: Div] i64 [[VP_PHI_USE:%.*]] = phi  [ i64 [[VP_INNER_DEF_LCSSA_LIVE_OUT_BLEND]], [[BB2]] ]
; CHECK-NEXT:     [DA: Div] void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  br label %outer.header

outer.header:
  %iv = phi i64 [ %lane, %entry ], [ %iv.next, %outer.latch ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %some_cmp = icmp eq i64 %ld, 42
  %iv.next = add nuw nsw i64 %iv, 1
  br label %inner.header

inner.header:
  %inner.iv = phi i64 [ 0, %outer.header ], [ %inner.iv.next, %inner.header ]
  %inner.iv.next = add nsw nuw i64 %inner.iv, 1
  %mul = mul nsw nuw i64 %iv, 100
  %idx = add nsw nuw i64 %mul, %inner.iv
  %gep = getelementptr i64, i64* %a, i64 %idx
  ; Might be speculatable and executed without mask. As such, CFU transformation
  ; must blend it as well. This stopped being a special case once we've started
  ; doing LCSSA transformation for the whole VPlan, so the benefit of the test
  ; is mostly for historical purposes.
  %inner.def = load i64, i64 *%gep
  %inner.exitcond = icmp eq i64 %inner.iv.next, 100
  br i1 %inner.exitcond, label %outer.latch, label %inner.header

outer.latch:
  br i1 %some_cmp, label %loop.exit, label %outer.header

loop.exit:
  %phi.use = phi i64 [ %inner.def, %outer.latch ]
  ret void
}

declare i64 @llvm.vplan.laneid()
