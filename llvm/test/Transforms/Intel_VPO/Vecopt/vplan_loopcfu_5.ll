; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test inner loop control flow uniformity for do/while loop without loop index.

; REQUIRES: asserts

; RUN: opt -vplan-print-terminator-inst=false -S -vplan-func-vec -print-after-vplan-func-vec-loop-cfu < %s -disable-output | FileCheck %s
; RUN: opt -vplan-print-terminator-inst=false -S -passes="vplan-func-vec" -print-after-vplan-func-vec-loop-cfu < %s -disable-output | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@A = common local_unnamed_addr global [100 x [100 x i64]] zeroinitializer, align 16

define dso_local void @foo(i32* nocapture %a, i32 %m, i32* nocapture readonly %ub, i32 %k) local_unnamed_addr {
; CHECK-LABEL:  VPlan IR for: foo
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     [DA: Div] i64 [[VP_LANE:%.*]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Div] i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[UB0:%.*]] i64 [[VP_LANE]]
; CHECK-NEXT:     [DA: Div] i32* [[VP_ARRAYIDX2:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_LANE]]
; CHECK-NEXT:     [DA: Div] i32 [[VP__PRE:%.*]] = load i32* [[VP_ARRAYIDX]]
; CHECK-NEXT:     [DA: Div] i32 [[VP_LANE_TRUNC:%.*]] = trunc i64 [[VP_LANE]] to i32
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div] i32 [[VP_REC:%.*]] = phi  [ i32 [[VP__PRE]], [[BB0]] ],  [ i32 [[VP_LD:%.*]], [[BB2:BB[0-9]+]] ]
; CHECK-NEXT:     [DA: Div] i1 [[VP_LOOP_MASK:%.*]] = phi  [ i1 true, [[BB0]] ],  [ i1 [[VP_LOOP_MASK_NEXT:%.*]], [[BB2]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[BB3:BB[0-9]+]](i1 [[VP_LOOP_MASK]]), [[BB2]](!i1 [[VP_LOOP_MASK]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       [DA: Div] i32 [[VP_MUL:%.*]] = mul i32 [[VP_REC]] i32 [[VP_LANE_TRUNC]]
; CHECK-NEXT:       [DA: Div] store i32 [[VP_MUL]] i32* [[VP_ARRAYIDX2]]
; CHECK-NEXT:       [DA: Div] i32 [[VP_LD]] = load i32* [[VP_ARRAYIDX]]
; CHECK-NEXT:       [DA: Div] i1 [[VP_CONTINUE_COND:%.*]] = icmp sgt i32 [[VP_LD]] i32 0
; CHECK-NEXT:      SUCCESSORS(1):[[BB2]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div] i1 [[VP_LOOP_MASK_NEXT]] = and i1 [[VP_CONTINUE_COND]] i1 [[VP_LOOP_MASK]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP0:%.*]] = all-zero-check i1 [[VP_LOOP_MASK_NEXT]]
; CHECK-NEXT:    SUCCESSORS(2):[[BB4:BB[0-9]+]](i1 [[VP0]]), [[BB1]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB3]] [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB5:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]:
; CHECK-NEXT:     [DA: Div] ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB4]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  %arrayidx = getelementptr inbounds i32, i32* %ub, i64 %lane
  %arrayidx2 = getelementptr inbounds i32, i32* %a, i64 %lane
  %.pre = load i32, i32* %arrayidx, align 4
  %lane.trunc = trunc i64 %lane to i32
  br label %header

header:
  %rec = phi i32 [ %.pre, %entry ], [ %ld, %header ]
  %mul = mul nsw i32 %rec, %lane.trunc
  store i32 %mul, i32* %arrayidx2, align 4
  %ld = load i32, i32* %arrayidx, align 4
  %continue.cond = icmp sgt i32 %ld, 0
  br i1 %continue.cond, label %header, label %loop.exit

loop.exit:
  br label %exit

exit:
  ret void
}

declare i64 @llvm.vplan.laneid()
