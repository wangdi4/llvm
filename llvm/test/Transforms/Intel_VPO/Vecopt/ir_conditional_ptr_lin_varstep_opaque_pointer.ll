; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
;
; Test for that induction which has updates under conditions is processed correctly
; (i.e. induction init/final are processed correctly).
; REQUIRES: asserts
; RUN: opt -opaque-pointers -passes=vplan-vec -vplan-force-vf=2 -vplan-entities-dump -vplan-print-after-vpentity-instrs -vplan-dump-induction-init-details -vplan-dump-plan-da -S < %s 2>&1 | FileCheck %s

; CHECK-LABEL: VPlan after insertion of VPEntities instructions:
; CHECK:         i64 [[VP_STEP1:%.*]] = inv-scev-wrapper{ (8 * %step) }
; CHECK-NEXT:    ptr [[VP_IND_INIT1:%.*]] = induction-init{getelementptr, StartVal: ?, EndVal: ?} ptr %k.iv.b i64 [[VP_STEP1]]
; CHECK-NEXT:    i64 [[VP_INIT_STEP1:%.*]] = induction-init-step{getelementptr} i64 [[VP_STEP1]]
; CHECK-NEXT:    i64 [[VP_STEP2:%.*]] = inv-scev-wrapper{ (4 * %step) }
; CHECK-NEXT:    ptr [[VP_IND_INIT2:%.*]] = induction-init{getelementptr, StartVal: ?, EndVal: ?} ptr %k1.iv.b i64 [[VP_STEP2]]
; CHECK-NEXT:    i64 [[VP_INIT_STEP2:%.*]] = induction-init-step{getelementptr} i64 [[VP_STEP2]]
; CHECK:       BB4: # preds: BB2
; CHECK-NEXT:    ptr [[VP_GEP10:%.*]] = getelementptr inbounds i64, ptr [[VP_PHI1:%.*]] i64 %step
; CHECK-NEXT:    ptr [[VP_GEP20:%.*]] = getelementptr inbounds i32, ptr [[VP_PHI2:%.*]] i64 %step
; CHECK:       BB3: # preds: BB2
; CHECK-NEXT:    ptr [[VP_GEP11:%.*]] = getelementptr inbounds i64, ptr [[VP_PHI1:%.*]] i64 %step
; CHECK-NEXT:    ptr [[VP_GEP21:%.*]] = getelementptr inbounds i32, ptr [[VP_PHI2:%.*]] i64 %step
; CHECK:       BB6: # preds: BB5
; CHECK:        ptr [[VP_IND_FINAL1:%.*]] = induction-final{getelementptr} ptr %k.iv.b i64 [[VP_STEP1]]
; CHECK-NEXT:   ptr [[VP_IND_FINAL2:%.*]] = induction-final{getelementptr} ptr %k1.iv.b i64 [[VP_STEP2]]
;
; CHECK:       Printing Divergence info for foo2:for.body.#1
; CHECK:        Uniform: [Shape: Uniform] i64 [[VP_STEP1:%.*]] = inv-scev-wrapper{ (8 * %step) }
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_IND_INIT1:%.*]] = induction-init{getelementptr, StartVal: ?, EndVal: ?} ptr live-in0 i64 [[VP_STEP1]]
; CHECK-NEXT:   Uniform: [Shape: Uniform] i64 [[VP_INIT_STEP1:%.*]] = induction-init-step{getelementptr} i64 [[VP_STEP1]]
; CHECK-NEXT:   Uniform: [Shape: Uniform] i64 [[VP_STEP2:%.*]] = inv-scev-wrapper{ (4 * %step) }
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_INIT_STEP2:%.*]] = induction-init{getelementptr, StartVal: ?, EndVal: ?} ptr live-in1 i64 [[VP_STEP2]]
; CHECK-NEXT:   Uniform: [Shape: Uniform] i64 [[VP_INIT_STEP2:%.*]] = induction-init-step{getelementptr} i64 [[VP_STEP2]]
; CHECK:       Basic Block: BB4
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_GEP10:%.*]] = getelementptr inbounds i64, ptr [[VP_PTR1:%.*]] i64 %step
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_GEP20:%.*]] = getelementptr inbounds i32, ptr [[VP_PTR2:%.*]] i64 %step
; CHECK:       Basic Block: BB3
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_GEP11:%.*]] = getelementptr inbounds i64, ptr [[VP_PTR1:%.*]] i64 %step
; CHECK-NEXT:   Divergent: [Shape: Random] ptr [[VP_GEP21:%.*]] = getelementptr inbounds i32, ptr [[VP_PTR2:%.*]] i64 %step
; CHECK:       Basic Block: BB6
; CHECK:        Uniform: [Shape: Uniform] ptr [[VP_IND_FINAL1:%.*]] = induction-final{getelementptr} ptr %k.iv.b i64 [[VP_STEP1]]
; CHECK-NEXT:   Uniform: [Shape: Uniform] ptr [[VP_IND_FINAL2:%.*]] = induction-final{getelementptr} ptr %k1.iv.b i64 [[VP_STEP2]]
;
; CHECK: define void @foo2(i64 %N, i64 noundef %step) local_unnamed_addr {
; CHECK:      for.body.lr.ph:                                   ; preds = %reg.entry
; CHECK:        [[VP_STEP0:%.*]] = shl i64 %step, 3
; CHECK-NEXT:   [[VP_BCAST_SPLATINSERT0:%.*]] = insertelement <2 x i64> poison, i64 [[VP_STEP0]], i32 0
; CHECK-NEXT:   [[VP_BCAST_SPLAT0:%.*]] = shufflevector <2 x i64> [[VP_BCAST_SPLATINSERT0]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:   [[VP_STEP1:%.*]] = shl i64 %step, 2
; CHECK-NEXT:   [[VP_BCAST_SPLATINSERT1:%.*]] = insertelement <2 x i64> poison, i64 [[VP_STEP1]], i32 0
; CHECK-NEXT:   [[VP_BCAST_SPLAT1:%.*]] = shufflevector <2 x i64> [[VP_BCAST_SPLATINSERT1]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK:      VPlannedBB1:                                      ; preds = %VPlannedBB
; CHECK-NEXT:   [[VP_BCAST_SPLATINSERT2:%.*]] = insertelement <2 x i64> poison, i64 %step, i32 0
; CHECK-NEXT:   [[VP_BCAST_SPLAT2:%.*]] = shufflevector <2 x i64> [[VP_BCAST_SPLATINSERT2]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK:      VPlannedBB2:                                      ; preds = %VPlannedBB1
; CHECK:        [[VP_BCAST_SPLAT0_MUL:%.*]] = mul <2 x i64> [[VP_BCAST_SPLAT0]], <i64 0, i64 1>
; CHECK-NEXT:   [[VP_VECTOR_GEP0:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_IND_START_BCAST_SPLAT0:%.*]], <2 x i64> [[VP_BCAST_SPLAT0_MUL]]
; CHECK-NEXT:   [[VP_STEP0_MUL:%.*]] = mul i64 [[VP_STEP0]], 2
; CHECK-NEXT:   [[VP_IND_STEP_INIT_SPLATINSERT:%.*]] = insertelement <2 x i64> poison, i64 [[VP_STEP0_MUL]], i32 0
; CHECK-NEXT:   [[VP_IND_STEP_INIT_SPLAT:%.*]] = shufflevector <2 x i64> [[VP_IND_STEP_INIT_SPLATINSERT]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK:        [[VP_BCAST_SPLAT1_MUL:%.*]] = mul <2 x i64> [[VP_BCAST_SPLAT1]], <i64 0, i64 1>
; CHECK-NEXT:   [[VP_VECTOR_GEP1:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_IND_START_BCAST_SPLAT1:%.*]], <2 x i64> [[VP_BCAST_SPLAT1_MUL]]
; CHECK-NEXT:   [[VP_STEP1_MUL:%.*]] = mul i64 [[VP_STEP1]], 2
; CHECK-NEXT:   [[VP_IND_STEP_INIT_SPLATINSERT1:%.*]] = insertelement <2 x i64> poison, i64 [[VP_STEP1_MUL]], i32 0
; CHECK-NEXT:   [[VP_IND_STEP_INIT_SPLAT1:%.*]] = shufflevector <2 x i64> [[VP_IND_STEP_INIT_SPLATINSERT1]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK:      VPlannedBB14:                                     ; preds = %vector.body
; CHECK-NEXT:   [[VP_MM_VECTOR_GEP0:%.*]] = getelementptr inbounds i64, <2 x ptr> [[VP_VEC_PHI0:%.*]], <2 x i64> [[VP_BCAST_SPLAT2]]
; CHECK-NEXT:   [[VP_MM_VECTOR_GEP1:%.*]] = getelementptr inbounds i32, <2 x ptr> [[VP_VEC_PHI1:%.*]], <2 x i64> [[VP_BCAST_SPLAT2]]
; CHECK-NEXT:   br label %VPlannedBB18
; CHECK-EMPTY:
; CHECK-NEXT: VPlannedBB18:                                     ; preds = %VPlannedBB14
; CHECK-NEXT:   [[VP_MM_VECTOR_GEP2:%.*]] = getelementptr inbounds i64, <2 x ptr> [[VP_VEC_PHI0]], <2 x i64> [[VP_BCAST_SPLAT2]]
; CHECK-NEXT:   [[VP_MM_VECTOR_GEP3:%.*]] = getelementptr inbounds i32, <2 x ptr> [[VP_VEC_PHI1]], <2 x i64> [[VP_BCAST_SPLAT2]]
; CHECK-NEXT:   br label %VPlannedBB21
; CHECK-EMPTY:
; CHECK-NEXT: VPlannedBB21:                                     ; preds = %VPlannedBB18
; CHECK:        [[VP_MM_VECTOR_GEP4:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_VEC_PHI1]], <2 x i64> [[VP_IND_STEP_INIT_SPLAT1:%.*]]
; CHECK:        [[VP_MM_VECTOR_GEP5:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_VEC_PHI0]], <2 x i64> [[VP_IND_STEP_INIT_SPLAT:%.*]]
; CHECK:      VPlannedBB25:                                     ; preds = %VPlannedBB21
; CHECK:        [[VP_STEP0_NEXT:%.*]] = mul i64 [[VP_STEP0]], [[VP_TRIP_COUNT:%.*]]
; CHECK-NEXT:   [[VP_FINAL_GEP0:%.*]] = getelementptr inbounds i8, ptr %k.iv.b, i64 [[VP_STEP0_NEXT]]
; CHECK-NEXT:   [[VP_STEP1_NEXT:%.*]] = mul i64 [[VP_STEP1]], [[VP_TRIP_COUNT]]
; CHECK-NEXT:   [[VP_FINAL_GEP1:%.*]] = getelementptr inbounds i8, ptr %k1.iv.b, i64 [[VP_STEP1_NEXT]]
;
define void @foo2(i64 %N, i64 noundef %step) local_unnamed_addr #0 {
entry:
  %k = alloca i64*, align 4
  %k1 = alloca i32*, align 4
  store i64* null, i64** %k, align 4
  store i32* null, i32** %k1, align 4
  br label %reg.entry

reg.entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(i64** %k, i32 0, i32 1, i64 %step), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(i32** %k1, i32 0, i32 1, i64 %step) ]
  br label %for.body.lr.ph

for.body.lr.ph:
  %k.iv.b = load i64*, i64** %k, align 4
  %k1.iv.b = load i32*, i32** %k1, align 4
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 1, %for.body.lr.ph ], [ %indvars.iv.next, %latch ]
  %k.iv = phi i64* [ %k.iv.b, %for.body.lr.ph ], [ %k.iv.next, %latch ]
  %k1.iv = phi i32* [ %k1.iv.b, %for.body.lr.ph ], [ %k1.iv.next, %latch ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %ee = icmp eq i64 %indvars.iv.next, 43
  br i1 %ee, label %then, label %else

then:
  %k.iv.n1 = getelementptr inbounds i64, i64* %k.iv, i64 %step
  %k1.iv.n1 = getelementptr inbounds i32, i32* %k1.iv, i64 %step
  br label %latch
else:
  %k.iv.n2 = getelementptr inbounds i64, i64* %k.iv, i64 %step
  %k1.iv.n2 = getelementptr inbounds i32, i32* %k1.iv, i64 %step
  br label %latch

latch:
  %k.iv.next = phi i64* [%k.iv.n1, %then ], [%k.iv.n2, %else ]
  %k1.iv.next = phi i32* [%k1.iv.n1, %then ], [%k1.iv.n2, %else ]
  %exitcond = icmp eq i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body

for.cond.cleanup.loopexit:
  %lcssa.k = phi i64* [%k.iv.next, %latch]
  %lcssa.k1 = phi i32* [%k1.iv.next, %latch]
  br label %for.cond.cleanup

for.cond.cleanup:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}
declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

