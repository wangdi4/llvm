; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -enable-new-pm=0 -vplan-vec -print-after=vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefix=IR-CHECK
; RUN: opt -enable-new-pm=0 -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -print-after=hir-vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefix=HIR-CHECK
; RUN: opt -passes='vplan-vec' -print-after=vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefix=IR-CHECK
; RUN: opt -passes='hir-ssa-deconstruction,print<hir>,hir-vplan-vec,print<hir>' -disable-output < %s 2>&1 | FileCheck %s --check-prefix=HIR-CHECK
;
; LIT test to check vectorization of freeze instruction
;
define dso_local void @foo(i64* noalias nocapture readonly %larr, i64* noalias nocapture %larr2) local_unnamed_addr #0 {
; IR-CHECK:  define dso_local void @foo(i64* noalias nocapture readonly [[LARR0:%.*]], i64* noalias nocapture [[LARR20:%.*]]) local_unnamed_addr {
; IR-CHECK:       vector.body:
; IR-CHECK-NEXT:    [[UNI_PHI10:%.*]] = phi i64 [ 0, [[VECTOR_PH0:%.*]] ], [ [[TMP5:%.*]], [[VECTOR_BODY0:%.*]] ]
; IR-CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VECTOR_PH0]] ], [ [[TMP4:%.*]], [[VECTOR_BODY0]] ]
; IR-CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i64, i64* [[LARR0]], i64 [[UNI_PHI10]]
; IR-CHECK-NEXT:    [[TMP0:%.*]] = bitcast i64* [[SCALAR_GEP0]] to <4 x i64>*
; IR-CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <4 x i64>, <4 x i64>* [[TMP0]], align 8
; IR-CHECK-NEXT:    [[TMP1:%.*]] = freeze <4 x i64> [[WIDE_LOAD0]]
; IR-CHECK-NEXT:    [[TMP2:%.*]] = add nsw <4 x i64> [[TMP1]], [[VEC_PHI0]]
; IR-CHECK-NEXT:    [[SCALAR_GEP20:%.*]] = getelementptr inbounds i64, i64* [[LARR20]], i64 [[UNI_PHI10]]
; IR-CHECK-NEXT:    [[TMP3:%.*]] = bitcast i64* [[SCALAR_GEP20]] to <4 x i64>*
; IR-CHECK-NEXT:    store <4 x i64> [[TMP2]], <4 x i64>* [[TMP3]], align 8
;
; HIR-CHECK:       Function: foo
; HIR-CHECK:               + DO i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; HIR-CHECK-NEXT:          |   %.vec = (<4 x i64>*)(%larr)[i1];
; HIR-CHECK-NEXT:          |   %.vec2 = freeze(%.vec);
; HIR-CHECK-NEXT:          |   (<4 x i64>*)(%larr2)[i1] = i1 + <i64 0, i64 1, i64 2, i64 3> + %.vec2;
; HIR-CHECK-NEXT:          + END LOOP
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4) ]
  br label %for.body

for.body:                                         ; preds = %for.body, %entry
  %l1.07 = phi i64 [ 0, %entry ], [ %inc, %for.body ]
  %arrayidx = getelementptr inbounds i64, i64* %larr, i64 %l1.07
  %0 = load i64, i64* %arrayidx, align 8
  %freeze = freeze i64 %0
  %add = add nsw i64 %freeze, %l1.07
  %arrayidx1 = getelementptr inbounds i64, i64* %larr2, i64 %l1.07
  store i64 %add, i64* %arrayidx1, align 8
  %inc = add nuw nsw i64 %l1.07, 1
  %exitcond = icmp eq i64 %inc, 100
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
