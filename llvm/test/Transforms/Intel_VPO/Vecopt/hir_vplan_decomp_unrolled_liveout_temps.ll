; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to verify correctness of VPlan IR generated by decomposer for
; an unrolled inner loop producing multiple updates to liveout temp.

; Incoming HIR into vectorizer
; BEGIN REGION { modified }
;       %entry.region = @llvm.directive.region.entry(); [ DIR.VPO.AUTO.VEC() ]
;
;       + DO i1 = 0, 1023, 1   <DO_LOOP>
;       |   %0 = (@A)[0][0][i1];
;       |   %1 = (@B)[0][0][i1];
;       |   %add = %1  +  %0;
;       |   (@C)[0][0][i1] = %0 + %1;
;       |   %0 = (@A)[0][1][i1];
;       |   %1 = (@B)[0][1][i1];
;       |   %add = %1  +  %0;
;       |   (@C)[0][1][i1] = %0 + %1;
;       |   %0 = (@A)[0][2][i1];
;       |   %1 = (@B)[0][2][i1];
;       |   %add = %1  +  %0;
;       |   (@C)[0][2][i1] = %0 + %1;
;       |   %0 = (@A)[0][3][i1];
;       |   %1 = (@B)[0][3][i1];
;       |   %add = %1  +  %0;  ----> Only live-out VPInstruction.
;       |   (@C)[0][3][i1] = %0 + %1;
;       + END LOOP
;
;       @llvm.directive.region.exit(%entry.region); [ DIR.VPO.END.AUTO.VEC() ]
; END REGION

; RUN: opt -hir-ssa-deconstruction -hir-pre-vec-complete-unroll -hir-vec-dir-insert -hir-vplan-vec -vplan-print-after-plain-cfg -disable-output < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -hir-ssa-deconstruction -hir-pre-vec-complete-unroll -hir-vec-dir-insert -hir-vplan-vec -vplan-print-after-plain-cfg -disable-output < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-pre-vec-complete-unroll,hir-vec-dir-insert,hir-vplan-vec" -vplan-print-after-plain-cfg -disable-output < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-pre-vec-complete-unroll,hir-vec-dir-insert,hir-vplan-vec" -vplan-print-after-plain-cfg -disable-output < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s


target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@A = dso_local local_unnamed_addr global [4 x [1024 x i32]] zeroinitializer, align 16
@B = dso_local local_unnamed_addr global [4 x [1024 x i32]] zeroinitializer, align 16
@C = dso_local local_unnamed_addr global [4 x [1024 x i32]] zeroinitializer, align 16

; Function Attrs: nofree norecurse nounwind uwtable
define dso_local i32 @foo() local_unnamed_addr {
; CHECK-LABEL:  VPlan after importing plain CFG:
; CHECK:         [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i64 [[VP3:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP4:%.*]], [[BB2]] ]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [4 x [1024 x i32]]* @A i64 0 i64 0 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD:%.*]] = load i32* [[VP_SUBSCRIPT]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds [4 x [1024 x i32]]* @B i64 0 i64 0 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_1:%.*]] = load i32* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:     i32 [[VP5:%.*]] = add i32 [[VP_LOAD_1]] i32 [[VP_LOAD]]
; CHECK-NEXT:     i32 [[VP6:%.*]] = add i32 [[VP_LOAD]] i32 [[VP_LOAD_1]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds [4 x [1024 x i32]]* @C i64 0 i64 0 i64 [[VP3]]
; CHECK-NEXT:     store i32 [[VP6]] i32* [[VP_SUBSCRIPT_2]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds [4 x [1024 x i32]]* @A i64 0 i64 1 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_2:%.*]] = load i32* [[VP_SUBSCRIPT_3]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_4:%.*]] = subscript inbounds [4 x [1024 x i32]]* @B i64 0 i64 1 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_3:%.*]] = load i32* [[VP_SUBSCRIPT_4]]
; CHECK-NEXT:     i32 [[VP7:%.*]] = add i32 [[VP_LOAD_3]] i32 [[VP_LOAD_2]]
; CHECK-NEXT:     i32 [[VP8:%.*]] = add i32 [[VP_LOAD_2]] i32 [[VP_LOAD_3]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_5:%.*]] = subscript inbounds [4 x [1024 x i32]]* @C i64 0 i64 1 i64 [[VP3]]
; CHECK-NEXT:     store i32 [[VP8]] i32* [[VP_SUBSCRIPT_5]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_6:%.*]] = subscript inbounds [4 x [1024 x i32]]* @A i64 0 i64 2 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_4:%.*]] = load i32* [[VP_SUBSCRIPT_6]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_7:%.*]] = subscript inbounds [4 x [1024 x i32]]* @B i64 0 i64 2 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_5:%.*]] = load i32* [[VP_SUBSCRIPT_7]]
; CHECK-NEXT:     i32 [[VP9:%.*]] = add i32 [[VP_LOAD_5]] i32 [[VP_LOAD_4]]
; CHECK-NEXT:     i32 [[VP10:%.*]] = add i32 [[VP_LOAD_4]] i32 [[VP_LOAD_5]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_8:%.*]] = subscript inbounds [4 x [1024 x i32]]* @C i64 0 i64 2 i64 [[VP3]]
; CHECK-NEXT:     store i32 [[VP10]] i32* [[VP_SUBSCRIPT_8]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_9:%.*]] = subscript inbounds [4 x [1024 x i32]]* @A i64 0 i64 3 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_6:%.*]] = load i32* [[VP_SUBSCRIPT_9]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_10:%.*]] = subscript inbounds [4 x [1024 x i32]]* @B i64 0 i64 3 i64 [[VP3]]
; CHECK-NEXT:     i32 [[VP_LOAD_7:%.*]] = load i32* [[VP_SUBSCRIPT_10]]
; CHECK-NEXT:     i32 [[VP11:%.*]] = add i32 [[VP_LOAD_7]] i32 [[VP_LOAD_6]]
; CHECK-NEXT:     i32 [[VP12:%.*]] = add i32 [[VP_LOAD_6]] i32 [[VP_LOAD_7]]
; CHECK-NEXT:     i32* [[VP_SUBSCRIPT_11:%.*]] = subscript inbounds [4 x [1024 x i32]]* @C i64 0 i64 3 i64 [[VP3]]
; CHECK-NEXT:     store i32 [[VP12]] i32* [[VP_SUBSCRIPT_11]]
; CHECK-NEXT:     i64 [[VP4]] = add i64 [[VP3]] i64 1
; CHECK-NEXT:     i1 [[VP13:%.*]] = icmp slt i64 [[VP4]] i64 1024
; CHECK-NEXT:     br i1 [[VP13]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  i32 [[VP11]] -> [[VP14:%.*]] = {%add}
;
entry:
  br label %for.cond1.preheader

for.cond1.preheader:                              ; preds = %for.inc14, %entry
  %indvars.iv31 = phi i64 [ 0, %entry ], [ %indvars.iv.next32, %for.inc14 ]
  br label %for.body3

for.body3:                                        ; preds = %for.body3, %for.cond1.preheader
  %indvars.iv = phi i64 [ 0, %for.cond1.preheader ], [ %indvars.iv.next, %for.body3 ]
  %arrayidx5 = getelementptr inbounds [4 x [1024 x i32]], [4 x [1024 x i32]]* @A, i64 0, i64 %indvars.iv, i64 %indvars.iv31
  %0 = load i32, i32* %arrayidx5, align 4
  %arrayidx9 = getelementptr inbounds [4 x [1024 x i32]], [4 x [1024 x i32]]* @B, i64 0, i64 %indvars.iv, i64 %indvars.iv31
  %1 = load i32, i32* %arrayidx9, align 4
  %add = add nsw i32 %1, %0
  %arrayidx13 = getelementptr inbounds [4 x [1024 x i32]], [4 x [1024 x i32]]* @C, i64 0, i64 %indvars.iv, i64 %indvars.iv31
  store i32 %add, i32* %arrayidx13, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 4
  br i1 %exitcond, label %for.inc14, label %for.body3, !llvm.loop !8

for.inc14:                                        ; preds = %for.body3
  %add.lcssa = phi i32 [ %add, %for.body3 ]
  %indvars.iv.next32 = add nuw nsw i64 %indvars.iv31, 1
  %exitcond33 = icmp eq i64 %indvars.iv.next32, 1024
  br i1 %exitcond33, label %for.end16, label %for.cond1.preheader

for.end16:                                        ; preds = %for.inc14
  %add.lcssa.lcssa = phi i32 [ %add.lcssa, %for.inc14 ]
  ret i32 %add.lcssa.lcssa
}

!8 = distinct !{!8, !9}
!9 = !{!"llvm.loop.unroll.count", i32 4}
