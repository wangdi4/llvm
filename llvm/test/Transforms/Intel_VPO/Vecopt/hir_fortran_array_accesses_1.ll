; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Check VPlan decomposition and codegen approaches for a complex Fortran-based loop nest.

; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-print-after-plain-cfg -vplan-dump-subscript-details -disable-output< %s 2>&1 | FileCheck %s --check-prefix=VPLAN-IR
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-force-vf=2 -enable-vp-value-codegen-hir=false -print-after=VPlanDriverHIR -disable-output < %s 2>&1 | FileCheck %s --check-prefix=MIXED-CG
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-force-vf=2 -enable-vp-value-codegen-hir=true -print-after=VPlanDriverHIR -disable-output < %s 2>&1 | FileCheck %s --check-prefix=VPVALUE-CG

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @interp_(double* noalias nocapture readonly %"interp_$Z", i32* noalias nocapture readonly %"interp_$M", double* noalias %"interp_$U", i32* noalias %"interp_$N") local_unnamed_addr {
; VPLAN-IR-LABEL:  VPlan after importing plain CFG:
; VPLAN-IR-NEXT:  External Defs Start:
; VPLAN-IR-DAG:     [[VP0:%.*]] = {%"interp_$Z"}
; VPLAN-IR-DAG:     [[VP1:%.*]] = {i1 + 1}
; VPLAN-IR-DAG:     [[VP2:%.*]] = {8 * (sext.i32.i64(%"interp_$M5") * sext.i32.i64(%"interp_$M5"))}
; VPLAN-IR-DAG:     [[VP3:%.*]] = {8 * (sext.i32.i64(%"interp_$N6") * sext.i32.i64(%"interp_$N6"))}
; VPLAN-IR-DAG:     [[VP4:%.*]] = {i2 + 1}
; VPLAN-IR-DAG:     [[VP5:%.*]] = {8 * sext.i32.i64(%"interp_$N6")}
; VPLAN-IR-DAG:     [[VP6:%.*]] = {%"interp_$U"}
; VPLAN-IR-DAG:     [[VP7:%.*]] = {8 * sext.i32.i64(%"interp_$M5")}
; VPLAN-IR-DAG:     [[VP8:%.*]] = {2 * i2 + 3}
; VPLAN-IR-DAG:     [[VP9:%.*]] = {2 * i1 + 3}
; VPLAN-IR-NEXT:  External Defs End:
; VPLAN-IR-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; VPLAN-IR-NEXT:     br [[BB1:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB1]]: # preds: [[BB0]]
; VPLAN-IR-NEXT:     br [[BB2:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; VPLAN-IR-NEXT:     i64 [[VP10:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP11:%.*]], [[BB2]] ]
; VPLAN-IR-NEXT:     i64 [[VP12:%.*]] = mul i64 2 i64 [[VP10]]
; VPLAN-IR-NEXT:     i64 [[VP13:%.*]] = add i64 [[VP12]] i64 2
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP9]] : i64 [[VP3]] : double*} {i64 1 : i64 [[VP8]] : i64 [[VP5]] : double*} {i64 0 : i64 [[VP13]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP_LOAD:%.*]] = load double* [[VP_SUBSCRIPT]]
; VPLAN-IR-NEXT:     i64 [[VP14:%.*]] = add i64 [[VP10]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP1]] : i64 [[VP2]] : double*} {i64 0 : i64 [[VP4]] : i64 [[VP7]] : double*} {i64 0 : i64 [[VP14]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP_LOAD_1:%.*]] = load double* [[VP_SUBSCRIPT_1]]
; VPLAN-IR-NEXT:     double [[VP15:%.*]] = fadd double [[VP_LOAD]] double [[VP_LOAD_1]]
; VPLAN-IR-NEXT:     i64 [[VP16:%.*]] = mul i64 2 i64 [[VP10]]
; VPLAN-IR-NEXT:     i64 [[VP17:%.*]] = add i64 [[VP16]] i64 2
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP9]] : i64 [[VP3]] : double*} {i64 1 : i64 [[VP8]] : i64 [[VP5]] : double*} {i64 0 : i64 [[VP17]] : i64 8 : double*}
; VPLAN-IR-NEXT:     store double [[VP15]] double* [[VP_SUBSCRIPT_2]]
; VPLAN-IR-NEXT:     i64 [[VP11]] = add i64 [[VP10]] i64 1
; VPLAN-IR-NEXT:     i1 [[VP18:%.*]] = icmp sle i64 [[VP11]] i64 1023
; VPLAN-IR-NEXT:     br i1 [[VP18]], [[BB2]], [[BB3:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB3]]: # preds: [[BB2]]
; VPLAN-IR-NEXT:     br [[BB4:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB4]]: # preds: [[BB3]]
; VPLAN-IR-NEXT:     br <External Block>
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:  VPlan after importing plain CFG:
; VPLAN-IR-NEXT:  External Defs Start:
; VPLAN-IR-DAG:     [[VP19:%.*]] = {%"interp_$Z"}
; VPLAN-IR-DAG:     [[VP20:%.*]] = {2 * i2 + 3}
; VPLAN-IR-DAG:     [[VP21:%.*]] = {2 * i1 + 3}
; VPLAN-IR-DAG:     [[VP22:%.*]] = {8 * (sext.i32.i64(%"interp_$N6") * sext.i32.i64(%"interp_$N6"))}
; VPLAN-IR-DAG:     [[VP23:%.*]] = {%"interp_$U"}
; VPLAN-IR-DAG:     [[VP24:%.*]] = {i2 + 1}
; VPLAN-IR-DAG:     [[VP25:%.*]] = {8 * sext.i32.i64(%"interp_$N6")}
; VPLAN-IR-DAG:     [[VP26:%.*]] = {8 * (sext.i32.i64(%"interp_$M5") * sext.i32.i64(%"interp_$M5"))}
; VPLAN-IR-DAG:     [[VP27:%.*]] = {i1 + 1}
; VPLAN-IR-DAG:     [[VP28:%.*]] = {8 * sext.i32.i64(%"interp_$M5")}
; VPLAN-IR-NEXT:  External Defs End:
; VPLAN-IR-NEXT:    [[BB5:BB[0-9]+]]: # preds:
; VPLAN-IR-NEXT:     br [[BB6:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB6]]: # preds: [[BB5]]
; VPLAN-IR-NEXT:     br [[BB7:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB7]]: # preds: [[BB6]], [[BB7]]
; VPLAN-IR-NEXT:     i64 [[VP29:%.*]] = phi  [ i64 0, [[BB6]] ],  [ i64 [[VP30:%.*]], [[BB7]] ]
; VPLAN-IR-NEXT:     i64 [[VP31:%.*]] = mul i64 2 i64 [[VP29]]
; VPLAN-IR-NEXT:     i64 [[VP32:%.*]] = add i64 [[VP31]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP21]] : i64 [[VP22]] : double*} {i64 1 : i64 [[VP20]] : i64 [[VP25]] : double*} {i64 0 : i64 [[VP32]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP_LOAD_4:%.*]] = load double* [[VP_SUBSCRIPT_3]]
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_4:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP27]] : i64 [[VP26]] : double*} {i64 0 : i64 [[VP24]] : i64 [[VP28]] : double*} {i64 0 : i64 [[VP29]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP_LOAD_3:%.*]] = load double* [[VP_SUBSCRIPT_4]]
; VPLAN-IR-NEXT:     i64 [[VP39:%.*]] = add i64 [[VP29]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_5:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP27]] : i64 [[VP26]] : double*} {i64 0 : i64 [[VP24]] : i64 [[VP28]] : double*} {i64 0 : i64 [[VP39]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP_LOAD_2:%.*]] = load double* [[VP_SUBSCRIPT_5]]
; VPLAN-IR-NEXT:     double [[VP33:%.*]] = fadd double [[VP_LOAD_3]] double [[VP_LOAD_2]]
; VPLAN-IR-NEXT:     double [[VP38:%.*]] = fmul double [[VP33]] double 5.000000e-01
; VPLAN-IR-NEXT:     double [[VP34:%.*]] = fadd double [[VP_LOAD_4]] double [[VP38]]
; VPLAN-IR-NEXT:     i64 [[VP35:%.*]] = mul i64 2 i64 [[VP29]]
; VPLAN-IR-NEXT:     i64 [[VP36:%.*]] = add i64 [[VP35]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_6:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP21]] : i64 [[VP22]] : double*} {i64 1 : i64 [[VP20]] : i64 [[VP25]] : double*} {i64 0 : i64 [[VP36]] : i64 8 : double*}
; VPLAN-IR-NEXT:     store double [[VP34]] double* [[VP_SUBSCRIPT_6]]
; VPLAN-IR-NEXT:     i64 [[VP30]] = add i64 [[VP29]] i64 1
; VPLAN-IR-NEXT:     i1 [[VP37:%.*]] = icmp sle i64 [[VP30]] i64 1023
; VPLAN-IR-NEXT:     br i1 [[VP37]], [[BB7]], [[BB8:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB8]]: # preds: [[BB7]]
; VPLAN-IR-NEXT:     br [[BB9:BB[0-9]+]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB9]]: # preds: [[BB8]]
; VPLAN-IR-NEXT:     br <External Block>
;
; MIXED-CG-LABEL:  *** IR Dump After VPlan Vectorization Driver HIR ***
; MIXED-CG:         BEGIN REGION { modified }
; MIXED-CG-NEXT:          + DO i1 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; MIXED-CG-NEXT:          |   + DO i2 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; MIXED-CG-NEXT:          |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; MIXED-CG-NEXT:          |   |   |   %.vec = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 2];
; MIXED-CG-NEXT:          |   |   |   %.vec5 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; MIXED-CG-NEXT:          |   |   |   %add86.vec = %.vec  +  %.vec5;
; MIXED-CG-NEXT:          |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 2] = %add86.vec;
; MIXED-CG-NEXT:          |   |   + END LOOP
; MIXED-CG-NEXT:          |   |
; MIXED-CG-NEXT:          |   |
; MIXED-CG-NEXT:          |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; MIXED-CG-NEXT:          |   |   |   %.vec6 = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 1];
; MIXED-CG-NEXT:          |   |   |   %.vec7 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3];
; MIXED-CG-NEXT:          |   |   |   %.vec8 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; MIXED-CG-NEXT:          |   |   |   %add162.vec = %.vec7  +  %.vec8;
; MIXED-CG-NEXT:          |   |   |   %mul163.vec = %add162.vec  *  5.000000e-01;
; MIXED-CG-NEXT:          |   |   |   %add164.vec = %.vec6  +  %mul163.vec;
; MIXED-CG-NEXT:          |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 1] = %add164.vec;
; MIXED-CG-NEXT:          |   |   + END LOOP
; MIXED-CG-NEXT:          |   + END LOOP
; MIXED-CG-NEXT:          + END LOOP
; MIXED-CG-NEXT:    END REGION
;
; VPVALUE-CG-LABEL:  *** IR Dump After VPlan Vectorization Driver HIR ***
; VPVALUE-CG:          BEGIN REGION { modified }
; VPVALUE-CG-NEXT:           + DO i1 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; VPVALUE-CG-NEXT:           |   + DO i2 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; VPVALUE-CG-NEXT:           |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; VPVALUE-CG-NEXT:           |   |   |   %.vec = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 2];
; VPVALUE-CG-NEXT:           |   |   |   %.vec5 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec6 = %.vec  +  %.vec5;
; VPVALUE-CG-NEXT:           |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 2] = %.vec6;
; VPVALUE-CG-NEXT:           |   |   + END LOOP
; VPVALUE-CG-NEXT:           |   |
; VPVALUE-CG-NEXT:           |   |
; VPVALUE-CG-NEXT:           |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; VPVALUE-CG-NEXT:           |   |   |   %.vec7 = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec8 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3];
; VPVALUE-CG-NEXT:           |   |   |   %.vec9 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec10 = %.vec8  +  %.vec9;
; VPVALUE-CG-NEXT:           |   |   |   %.vec11 = %.vec10  *  5.000000e-01;
; VPVALUE-CG-NEXT:           |   |   |   %.vec12 = %.vec7  +  %.vec11;
; VPVALUE-CG-NEXT:           |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 1] = %.vec12;
; VPVALUE-CG-NEXT:           |   |   + END LOOP
; VPVALUE-CG-NEXT:           |   + END LOOP
; VPVALUE-CG-NEXT:           + END LOOP
; VPVALUE-CG-NEXT:     END REGION
;
alloca:
  %"interp_$M5" = load i32, i32* %"interp_$M", align 4
  %"interp_$N6" = load i32, i32* %"interp_$N", align 4
  %int_sext = sext i32 %"interp_$N6" to i64
  %mul = shl nsw i64 %int_sext, 3
  %mul41 = mul nsw i64 %mul, %int_sext
  %int_sext49 = sext i32 %"interp_$M5" to i64
  %mul50 = shl nsw i64 %int_sext49, 3
  %mul54 = mul nsw i64 %mul50, %int_sext49
  %rel = icmp slt i32 %"interp_$M5", 3
  br i1 %rel, label %bb77, label %bb8.preheader

bb8.preheader:                                    ; preds = %alloca
  %wide.trip.count = zext i32 %"interp_$M5" to i64
  %wide.trip.count282 = zext i32 %"interp_$M5" to i64
  %wide.trip.count282.le = zext i32 %"interp_$M5" to i64
  %wide.trip.count282.le.le = zext i32 %"interp_$M5" to i64
  br label %bb12.preheader

bb12.preheader:                                   ; preds = %bb8.preheader, %bb3
  %indvars.iv292 = phi i64 [ 2, %bb8.preheader ], [ %indvars.iv.next293, %bb3 ]
  %indvars.iv292.tr = trunc i64 %indvars.iv292 to i32
  %0 = shl i32 %indvars.iv292.tr, 1
  %1 = add i32 %0, -1
  %int_sext75 = sext i32 %1 to i64
  %2 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 2, i64 1, i64 %mul41, double* %"interp_$U", i64 %int_sext75)
  %3 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 2, i64 1, i64 %mul54, double* %"interp_$Z", i64 %indvars.iv292)
  br label %bb16.preheader

bb16.preheader:                                   ; preds = %bb12.preheader, %bb44
  %indvars.iv284 = phi i64 [ 2, %bb12.preheader ], [ %indvars.iv.next285, %bb44 ]
  %indvars.iv284.tr = trunc i64 %indvars.iv284 to i32
  %4 = shl i32 %indvars.iv284.tr, 1
  %5 = add i32 %4, -1
  %int_sext70 = sext i32 %5 to i64
  %6 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul, double* %2, i64 %int_sext70)
  %7 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul50, double* %3, i64 %indvars.iv284)
  br label %bb16

bb16:                                             ; preds = %bb16, %bb16.preheader
  %indvars.iv = phi i64 [ 2, %bb16.preheader ], [ %indvars.iv.next, %bb16 ]
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %8 = shl i32 %indvars.iv.tr, 1
  %9 = add i32 %8, -1
  %int_sext65 = sext i32 %9 to i64
  %10 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %6, i64 %int_sext65)
  %11 = load double, double* %10, align 8
  %12 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %7, i64 %indvars.iv)
  %13 = load double, double* %12, align 8
  %add86 = fadd double %11, %13
  store double %add86, double* %10, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1026
  br i1 %exitcond, label %bb43.preheader, label %bb16

bb43.preheader:                                   ; preds = %bb16
  %indvars.iv284.tr301 = trunc i64 %indvars.iv284 to i32
  %14 = shl i32 %indvars.iv284.tr301, 1
  %15 = add i32 %14, -1
  %int_sext136 = sext i32 %15 to i64
  %16 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul, double* nonnull %2, i64 %int_sext136)
  %17 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul50, double* nonnull %3, i64 %indvars.iv284)
  br label %bb43

bb43:                                             ; preds = %bb43, %bb43.preheader
  %indvars.iv277 = phi i64 [ 2, %bb43.preheader ], [ %indvars.iv.next278, %bb43 ]
  %indvars.iv277.tr = trunc i64 %indvars.iv277 to i32
  %18 = shl i32 %indvars.iv277.tr, 1
  %19 = add i32 %18, -2
  %int_sext131 = sext i32 %19 to i64
  %20 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %16, i64 %int_sext131)
  %21 = load double, double* %20, align 8
  %22 = add nsw i64 %indvars.iv277, -1
  %23 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %17, i64 %22)
  %24 = load double, double* %23, align 8
  %25 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %17, i64 %indvars.iv277)
  %26 = load double, double* %25, align 8
  %add162 = fadd double %24, %26
  %mul163 = fmul double %add162, 5.000000e-01
  %add164 = fadd double %21, %mul163
  store double %add164, double* %20, align 8
  %indvars.iv.next278 = add nuw nsw i64 %indvars.iv277, 1
  %exitcond283 = icmp eq i64 %indvars.iv.next278, 1026
  br i1 %exitcond283, label %bb44, label %bb43

bb44:                                             ; preds = %bb43
  %indvars.iv.next285 = add nuw nsw i64 %indvars.iv284, 1
  %exitcond291 = icmp eq i64 %indvars.iv.next285, %wide.trip.count282.le
  br i1 %exitcond291, label %bb3, label %bb16.preheader

bb3:                                              ; preds = %bb44
  %indvars.iv.next293 = add nuw nsw i64 %indvars.iv292, 1
  %exitcond299 = icmp eq i64 %indvars.iv.next293, %wide.trip.count282.le.le
  br i1 %exitcond299, label %bb77.loopexit, label %bb12.preheader

bb77.loopexit:                                    ; preds = %bb3
  br label %bb77

bb77:                                             ; preds = %bb77.loopexit, %alloca
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8, i64, i64, double*, i64)

