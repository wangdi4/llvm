; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Check VPlan decomposition and codegen approaches for a complex Fortran-based loop nest.

; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-print-after-plain-cfg -vplan-dump-subscript-details -disable-output< %s 2>&1 | FileCheck %s --check-prefix=VPLAN-IR
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-force-vf=2 -enable-vp-value-codegen-hir=false -print-after=VPlanDriverHIR -disable-output < %s 2>&1 | FileCheck %s --check-prefix=MIXED-CG
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-force-vf=2 -enable-vp-value-codegen-hir=true -print-after=VPlanDriverHIR -disable-output < %s 2>&1 | FileCheck %s --check-prefix=VPVALUE-CG

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @interp_(double* noalias nocapture readonly %"interp_$Z", i32* noalias nocapture readonly %"interp_$M", double* noalias %"interp_$U", i32* noalias %"interp_$N") local_unnamed_addr {
; VPLAN-IR-LABEL:  VPlan after importing plain CFG:
; VPLAN-IR-NEXT:  External Defs Start:
; VPLAN-IR-DAG:     [[VP0:%.*]] = {8 * (sext.i32.i64(%"interp_$M5") * sext.i32.i64(%"interp_$M5"))}
; VPLAN-IR-DAG:     [[VP1:%.*]] = {%"interp_$Z"}
; VPLAN-IR-DAG:     [[VP2:%.*]] = {2 * i1 + 3}
; VPLAN-IR-DAG:     [[VP3:%.*]] = {8 * sext.i32.i64(%"interp_$N6")}
; VPLAN-IR-DAG:     [[VP4:%.*]] = {8 * sext.i32.i64(%"interp_$M5")}
; VPLAN-IR-DAG:     [[VP5:%.*]] = {i1 + 1}
; VPLAN-IR-DAG:     [[VP6:%.*]] = {8 * (sext.i32.i64(%"interp_$N6") * sext.i32.i64(%"interp_$N6"))}
; VPLAN-IR-DAG:     [[VP7:%.*]] = {%"interp_$U"}
; VPLAN-IR-DAG:     [[VP8:%.*]] = {2 * i2 + 3}
; VPLAN-IR-DAG:     [[VP9:%.*]] = {i2 + 1}
; VPLAN-IR-NEXT:  External Defs End:
; VPLAN-IR-NEXT:    [[BB0:BB[0-9]+]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; VPLAN-IR-NEXT:    no PREDECESSORS
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB1]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB0]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB2]]:
; VPLAN-IR-NEXT:     i64 [[VP10:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP11:%.*]], [[BB2]] ]
; VPLAN-IR-NEXT:     i64 [[VP12:%.*]] = mul i64 2 i64 [[VP10]]
; VPLAN-IR-NEXT:     i64 [[VP13:%.*]] = add i64 [[VP12]] i64 2
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP2]] : i64 [[VP6]] : double*} {i64 1 : i64 [[VP8]] : i64 [[VP3]] : double*} {i64 0 : i64 [[VP13]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP14:%.*]] = load double* [[VP_SUBSCRIPT]]
; VPLAN-IR-NEXT:     i64 [[VP15:%.*]] = add i64 [[VP10]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP5]] : i64 [[VP0]] : double*} {i64 0 : i64 [[VP9]] : i64 [[VP4]] : double*} {i64 0 : i64 [[VP15]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP16:%.*]] = load double* [[VP_SUBSCRIPT_1]]
; VPLAN-IR-NEXT:     double [[VP17:%.*]] = fadd double [[VP14]] double [[VP16]]
; VPLAN-IR-NEXT:     i64 [[VP18:%.*]] = mul i64 2 i64 [[VP10]]
; VPLAN-IR-NEXT:     i64 [[VP19:%.*]] = add i64 [[VP18]] i64 2
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP2]] : i64 [[VP6]] : double*} {i64 1 : i64 [[VP8]] : i64 [[VP3]] : double*} {i64 0 : i64 [[VP19]] : i64 8 : double*}
; VPLAN-IR-NEXT:     store double [[VP17]] double* [[VP_SUBSCRIPT_2]]
; VPLAN-IR-NEXT:     i64 [[VP11]] = add i64 [[VP10]] i64 1
; VPLAN-IR-NEXT:     i1 [[VP20:%.*]] = icmp sle i64 [[VP11]] i64 1023
; VPLAN-IR-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP20]]), [[BB3:BB[0-9]+]](!i1 [[VP20]])
; VPLAN-IR-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB3]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB2]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB4]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    no SUCCESSORS
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB3]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:  VPlan after importing plain CFG:
; VPLAN-IR-NEXT:  External Defs Start:
; VPLAN-IR-DAG:     [[VP21:%.*]] = {%"interp_$Z"}
; VPLAN-IR-DAG:     [[VP22:%.*]] = {8 * (sext.i32.i64(%"interp_$N6") * sext.i32.i64(%"interp_$N6"))}
; VPLAN-IR-DAG:     [[VP23:%.*]] = {8 * sext.i32.i64(%"interp_$N6")}
; VPLAN-IR-DAG:     [[VP24:%.*]] = {8 * sext.i32.i64(%"interp_$M5")}
; VPLAN-IR-DAG:     [[VP25:%.*]] = {i1 + 1}
; VPLAN-IR-DAG:     [[VP26:%.*]] = {2 * i1 + 3}
; VPLAN-IR-DAG:     [[VP27:%.*]] = {%"interp_$U"}
; VPLAN-IR-DAG:     [[VP28:%.*]] = {2 * i2 + 3}
; VPLAN-IR-DAG:     [[VP29:%.*]] = {8 * (sext.i32.i64(%"interp_$M5") * sext.i32.i64(%"interp_$M5"))}
; VPLAN-IR-DAG:     [[VP30:%.*]] = {i2 + 1}
; VPLAN-IR-NEXT:  External Defs End:
; VPLAN-IR-NEXT:    [[BB5:BB[0-9]+]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB6:BB[0-9]+]]
; VPLAN-IR-NEXT:    no PREDECESSORS
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB6]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB7:BB[0-9]+]]
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB5]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB7]]:
; VPLAN-IR-NEXT:     i64 [[VP31:%.*]] = phi  [ i64 0, [[BB6]] ],  [ i64 [[VP32:%.*]], [[BB7]] ]
; VPLAN-IR-NEXT:     i64 [[VP33:%.*]] = mul i64 2 i64 [[VP31]]
; VPLAN-IR-NEXT:     i64 [[VP34:%.*]] = add i64 [[VP33]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP26]] : i64 [[VP22]] : double*} {i64 1 : i64 [[VP28]] : i64 [[VP23]] : double*} {i64 0 : i64 [[VP34]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP35:%.*]] = load double* [[VP_SUBSCRIPT_3]]
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_4:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP25]] : i64 [[VP29]] : double*} {i64 0 : i64 [[VP30]] : i64 [[VP24]] : double*} {i64 0 : i64 [[VP31]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP36:%.*]] = load double* [[VP_SUBSCRIPT_4]]
; VPLAN-IR-NEXT:     i64 [[VP37:%.*]] = add i64 [[VP31]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_5:%.*]] = subscript inbounds double* %"interp_$Z" {i64 0 : i64 [[VP25]] : i64 [[VP29]] : double*} {i64 0 : i64 [[VP30]] : i64 [[VP24]] : double*} {i64 0 : i64 [[VP37]] : i64 8 : double*}
; VPLAN-IR-NEXT:     double [[VP38:%.*]] = load double* [[VP_SUBSCRIPT_5]]
; VPLAN-IR-NEXT:     double [[VP39:%.*]] = fadd double [[VP36]] double [[VP38]]
; VPLAN-IR-NEXT:     double [[VP40:%.*]] = fmul double [[VP39]] double 5.000000e-01
; VPLAN-IR-NEXT:     double [[VP41:%.*]] = fadd double [[VP35]] double [[VP40]]
; VPLAN-IR-NEXT:     i64 [[VP42:%.*]] = mul i64 2 i64 [[VP31]]
; VPLAN-IR-NEXT:     i64 [[VP43:%.*]] = add i64 [[VP42]] i64 1
; VPLAN-IR-NEXT:     double* [[VP_SUBSCRIPT_6:%.*]] = subscript inbounds double* %"interp_$U" {i64 1 : i64 [[VP26]] : i64 [[VP22]] : double*} {i64 1 : i64 [[VP28]] : i64 [[VP23]] : double*} {i64 0 : i64 [[VP43]] : i64 8 : double*}
; VPLAN-IR-NEXT:     store double [[VP41]] double* [[VP_SUBSCRIPT_6]]
; VPLAN-IR-NEXT:     i64 [[VP32]] = add i64 [[VP31]] i64 1
; VPLAN-IR-NEXT:     i1 [[VP44:%.*]] = icmp sle i64 [[VP32]] i64 1023
; VPLAN-IR-NEXT:    SUCCESSORS(2):[[BB7]](i1 [[VP44]]), [[BB8:BB[0-9]+]](!i1 [[VP44]])
; VPLAN-IR-NEXT:    PREDECESSORS(2): [[BB6]] [[BB7]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB8]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    SUCCESSORS(1):[[BB9:BB[0-9]+]]
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB7]]
; VPLAN-IR-EMPTY:
; VPLAN-IR-NEXT:    [[BB9]]:
; VPLAN-IR-NEXT:     <Empty Block>
; VPLAN-IR-NEXT:    no SUCCESSORS
; VPLAN-IR-NEXT:    PREDECESSORS(1): [[BB8]]
;
; MIXED-CG-LABEL:  *** IR Dump After VPlan Vectorization Driver HIR ***
; MIXED-CG:         BEGIN REGION { modified }
; MIXED-CG-NEXT:          + DO i1 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; MIXED-CG-NEXT:          |   + DO i2 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; MIXED-CG-NEXT:          |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; MIXED-CG-NEXT:          |   |   |   %.vec = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 2];
; MIXED-CG-NEXT:          |   |   |   %.vec5 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; MIXED-CG-NEXT:          |   |   |   %add86.vec = %.vec  +  %.vec5;
; MIXED-CG-NEXT:          |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 2] = %add86.vec;
; MIXED-CG-NEXT:          |   |   + END LOOP
; MIXED-CG-NEXT:          |   |
; MIXED-CG-NEXT:          |   |
; MIXED-CG-NEXT:          |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; MIXED-CG-NEXT:          |   |   |   %.vec6 = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 1];
; MIXED-CG-NEXT:          |   |   |   %.vec7 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3];
; MIXED-CG-NEXT:          |   |   |   %.vec8 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; MIXED-CG-NEXT:          |   |   |   %add162.vec = %.vec7  +  %.vec8;
; MIXED-CG-NEXT:          |   |   |   %mul163.vec = %add162.vec  *  5.000000e-01;
; MIXED-CG-NEXT:          |   |   |   %add164.vec = %.vec6  +  %mul163.vec;
; MIXED-CG-NEXT:          |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + <i64 0, i64 2> + 1] = %add164.vec;
; MIXED-CG-NEXT:          |   |   + END LOOP
; MIXED-CG-NEXT:          |   + END LOOP
; MIXED-CG-NEXT:          + END LOOP
; MIXED-CG-NEXT:    END REGION
;
; VPVALUE-CG-LABEL:  *** IR Dump After VPlan Vectorization Driver HIR ***
; VPVALUE-CG:          BEGIN REGION { modified }
; VPVALUE-CG-NEXT:           + DO i1 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; VPVALUE-CG-NEXT:           |   + DO i2 = 0, zext.i32.i64(%"interp_$M5") + -3, 1   <DO_LOOP>
; VPVALUE-CG-NEXT:           |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; VPVALUE-CG-NEXT:           |   |   |   %.vec = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 2];
; VPVALUE-CG-NEXT:           |   |   |   %.vec5 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec6 = %.vec  +  %.vec5;
; VPVALUE-CG-NEXT:           |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 2] = %.vec6;
; VPVALUE-CG-NEXT:           |   |   + END LOOP
; VPVALUE-CG-NEXT:           |   |
; VPVALUE-CG-NEXT:           |   |
; VPVALUE-CG-NEXT:           |   |   + DO i3 = 0, 1023, 2   <DO_LOOP> <novectorize>
; VPVALUE-CG-NEXT:           |   |   |   %.vec7 = (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec8 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3];
; VPVALUE-CG-NEXT:           |   |   |   %.vec9 = (<2 x double>*)(%"interp_$Z")[i1 + 1][i2 + 1][i3 + 1];
; VPVALUE-CG-NEXT:           |   |   |   %.vec10 = %.vec8  +  %.vec9;
; VPVALUE-CG-NEXT:           |   |   |   %.vec11 = %.vec10  *  5.000000e-01;
; VPVALUE-CG-NEXT:           |   |   |   %.vec12 = %.vec7  +  %.vec11;
; VPVALUE-CG-NEXT:           |   |   |   (<2 x double>*)(%"interp_$U")[2 * i1 + 3][2 * i2 + 3][2 * i3 + 2 * <i64 0, i64 1> + 1] = %.vec12;
; VPVALUE-CG-NEXT:           |   |   + END LOOP
; VPVALUE-CG-NEXT:           |   + END LOOP
; VPVALUE-CG-NEXT:           + END LOOP
; VPVALUE-CG-NEXT:     END REGION
;
alloca:
  %"interp_$M5" = load i32, i32* %"interp_$M", align 4
  %"interp_$N6" = load i32, i32* %"interp_$N", align 4
  %int_sext = sext i32 %"interp_$N6" to i64
  %mul = shl nsw i64 %int_sext, 3
  %mul41 = mul nsw i64 %mul, %int_sext
  %int_sext49 = sext i32 %"interp_$M5" to i64
  %mul50 = shl nsw i64 %int_sext49, 3
  %mul54 = mul nsw i64 %mul50, %int_sext49
  %rel = icmp slt i32 %"interp_$M5", 3
  br i1 %rel, label %bb77, label %bb8.preheader

bb8.preheader:                                    ; preds = %alloca
  %wide.trip.count = zext i32 %"interp_$M5" to i64
  %wide.trip.count282 = zext i32 %"interp_$M5" to i64
  %wide.trip.count282.le = zext i32 %"interp_$M5" to i64
  %wide.trip.count282.le.le = zext i32 %"interp_$M5" to i64
  br label %bb12.preheader

bb12.preheader:                                   ; preds = %bb8.preheader, %bb3
  %indvars.iv292 = phi i64 [ 2, %bb8.preheader ], [ %indvars.iv.next293, %bb3 ]
  %indvars.iv292.tr = trunc i64 %indvars.iv292 to i32
  %0 = shl i32 %indvars.iv292.tr, 1
  %1 = add i32 %0, -1
  %int_sext75 = sext i32 %1 to i64
  %2 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 2, i64 1, i64 %mul41, double* %"interp_$U", i64 %int_sext75)
  %3 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 2, i64 1, i64 %mul54, double* %"interp_$Z", i64 %indvars.iv292)
  br label %bb16.preheader

bb16.preheader:                                   ; preds = %bb12.preheader, %bb44
  %indvars.iv284 = phi i64 [ 2, %bb12.preheader ], [ %indvars.iv.next285, %bb44 ]
  %indvars.iv284.tr = trunc i64 %indvars.iv284 to i32
  %4 = shl i32 %indvars.iv284.tr, 1
  %5 = add i32 %4, -1
  %int_sext70 = sext i32 %5 to i64
  %6 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul, double* %2, i64 %int_sext70)
  %7 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul50, double* %3, i64 %indvars.iv284)
  br label %bb16

bb16:                                             ; preds = %bb16, %bb16.preheader
  %indvars.iv = phi i64 [ 2, %bb16.preheader ], [ %indvars.iv.next, %bb16 ]
  %indvars.iv.tr = trunc i64 %indvars.iv to i32
  %8 = shl i32 %indvars.iv.tr, 1
  %9 = add i32 %8, -1
  %int_sext65 = sext i32 %9 to i64
  %10 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %6, i64 %int_sext65)
  %11 = load double, double* %10, align 8
  %12 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %7, i64 %indvars.iv)
  %13 = load double, double* %12, align 8
  %add86 = fadd double %11, %13
  store double %add86, double* %10, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1026
  br i1 %exitcond, label %bb43.preheader, label %bb16

bb43.preheader:                                   ; preds = %bb16
  %indvars.iv284.tr301 = trunc i64 %indvars.iv284 to i32
  %14 = shl i32 %indvars.iv284.tr301, 1
  %15 = add i32 %14, -1
  %int_sext136 = sext i32 %15 to i64
  %16 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul, double* nonnull %2, i64 %int_sext136)
  %17 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 1, i64 1, i64 %mul50, double* nonnull %3, i64 %indvars.iv284)
  br label %bb43

bb43:                                             ; preds = %bb43, %bb43.preheader
  %indvars.iv277 = phi i64 [ 2, %bb43.preheader ], [ %indvars.iv.next278, %bb43 ]
  %indvars.iv277.tr = trunc i64 %indvars.iv277 to i32
  %18 = shl i32 %indvars.iv277.tr, 1
  %19 = add i32 %18, -2
  %int_sext131 = sext i32 %19 to i64
  %20 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %16, i64 %int_sext131)
  %21 = load double, double* %20, align 8
  %22 = add nsw i64 %indvars.iv277, -1
  %23 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %17, i64 %22)
  %24 = load double, double* %23, align 8
  %25 = tail call double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8 0, i64 1, i64 8, double* %17, i64 %indvars.iv277)
  %26 = load double, double* %25, align 8
  %add162 = fadd double %24, %26
  %mul163 = fmul double %add162, 5.000000e-01
  %add164 = fadd double %21, %mul163
  store double %add164, double* %20, align 8
  %indvars.iv.next278 = add nuw nsw i64 %indvars.iv277, 1
  %exitcond283 = icmp eq i64 %indvars.iv.next278, 1026
  br i1 %exitcond283, label %bb44, label %bb43

bb44:                                             ; preds = %bb43
  %indvars.iv.next285 = add nuw nsw i64 %indvars.iv284, 1
  %exitcond291 = icmp eq i64 %indvars.iv.next285, %wide.trip.count282.le
  br i1 %exitcond291, label %bb3, label %bb16.preheader

bb3:                                              ; preds = %bb44
  %indvars.iv.next293 = add nuw nsw i64 %indvars.iv292, 1
  %exitcond299 = icmp eq i64 %indvars.iv.next293, %wide.trip.count282.le.le
  br i1 %exitcond299, label %bb77.loopexit, label %bb12.preheader

bb77.loopexit:                                    ; preds = %bb3
  br label %bb77

bb77:                                             ; preds = %bb77.loopexit, %alloca
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare double* @llvm.intel.subscript.p0f64.i64.i64.p0f64.i64(i8, i64, i64, double*, i64)

