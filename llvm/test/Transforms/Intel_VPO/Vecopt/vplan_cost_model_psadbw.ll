; INTEL_FEATURE_SW_ADVANCED
; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: intel_feature_sw_advanced
; RUN: opt < %s -hir-ssa-deconstruction -hir-vec-dir-insert -hir-vplan-vec \
; RUN:     -mattr=+avx2 -disable-output -enable-intel-advanced-opts \
; RUN:     -vplan-cost-model-print-analysis-for-vf=1 | FileCheck %s

target triple = "x86_64-unknown-linux-gnu"

@a = dso_local local_unnamed_addr global [1024 x i8] zeroinitializer, align 64
@b = dso_local local_unnamed_addr global [1024 x i8] zeroinitializer, align 64

; basic case of psadbw pattern.  should not be vectorized.
define dso_local i32 @_Z3foov(i32 %t) {
;
; CHECK-LABEL:  Cost Model for VPlan _Z3foov:HIR.#{{[0-9]+}} with VF = 1:
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB0:BB[0-9]+]]
; CHECK-NEXT:    Cost 0 for br [[BB1:BB[0-9]+]]
; CHECK-NEXT:  [[BB0]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB1]]
; CHECK-NEXT:    Cost 0 for br [[BB2:BB[0-9]+]]
; CHECK-NEXT:  [[BB1]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop preheader [[BB0]] : [[BB1]] for VF = 1 resulted Cost = 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB2]]
; CHECK-NEXT:    Cost Unknown for i32 [[VP0:%.*]] = phi  [ i32 [[S_0100:%.*]], [[BB1]] ],  [ i32 [[VP1:%.*]], [[BB2]] ] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost Unknown for i64 [[VP2:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB2]] ]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD:%.*]] = load i8* [[VP_SUBSCRIPT]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_1:%.*]] = load i8* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP4:%.*]] = zext i8 [[VP_LOAD]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP5:%.*]] = zext i8 [[VP_LOAD_1]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP6:%.*]] = mul i32 [[VP5]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP7:%.*]] = add i32 [[VP4]] i32 [[VP6]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP8:%.*]] = abs i32 [[VP7]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP1]] = add i32 [[VP8]] i32 [[VP0]] *PSADBW* (CarryOut Def)
; CHECK-NEXT:    Cost 1 for i64 [[VP3]] = add i64 [[VP2]] i64 1
; CHECK-NEXT:    Cost 1 for i1 [[VP9:%.*]] = icmp slt i64 [[VP3]] i64 1024
; CHECK-NEXT:    Cost 0 for br i1 [[VP9]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:  [[BB2]]: base cost: 11
; CHECK-NEXT:  Base Cost: 11
; CHECK-NEXT:  Cost decrease due to psadbw pattern heuristic is 11
; CHECK-NEXT:  Total Cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB3]]
; CHECK-NEXT:    Cost 0 for br [[BB4:BB[0-9]+]]
; CHECK-NEXT:  [[BB3]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB4]]
; CHECK-NEXT:    Cost 0 for br <External Block>
; CHECK-NEXT:  [[BB4]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop postexit [[BB3]] : [[BB4]] for VF = 1 resulted Cost = 0
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  ret i32 %add.lcssa

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.010 = phi i32 [ %t, %entry ], [ %add, %for.body ]
  %arrayidx = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %0 = load i8, i8* %arrayidx, align 1
  %conv = zext i8 %0 to i32
  %arrayidx2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %1 = load i8, i8* %arrayidx2, align 1
  %conv3 = zext i8 %1 to i32
  %sub = sub nsw i32 %conv, %conv3
  %2 = icmp slt i32 %sub, 0
  %neg = sub nsw i32 0, %sub
  %3 = select i1 %2, i32 %neg, i32 %sub
  %add = add nuw nsw i32 %3, %s.010
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

; unrolled case with 64-bit acc.  Essential for eembc/denbench tests.
; should not be vectorized.
define dso_local i32 @_Z3goov() {
;
; CHECK-LABEL:  Cost Model for VPlan _Z3goov:HIR.#{{[0-9]+}} with VF = 1:
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB0:BB[0-9]+]]
; CHECK-NEXT:    Cost 0 for br [[BB1:BB[0-9]+]]
; CHECK-NEXT:  [[BB0]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB1]]
; CHECK-NEXT:    Cost 0 for br [[BB2:BB[0-9]+]]
; CHECK-NEXT:  [[BB1]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop preheader [[BB0]] : [[BB1]] for VF = 1 resulted Cost = 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB2]]
; CHECK-NEXT:    Cost Unknown for i64 [[VP0:%.*]] = phi  [ i64 [[S_0620:%.*]], [[BB1]] ],  [ i64 [[VP1:%.*]], [[BB2]] ] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost Unknown for i64 [[VP2:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB2]] ]
; CHECK-NEXT:    Cost Unknown for i64 [[VP4:%.*]] = hir-copy i64 [[VP0]] , OriginPhiId: -1
; CHECK-NEXT:    Cost 2 for i64 [[VP5:%.*]] = mul i64 4 i64 [[VP2]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP5]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD:%.*]] = load i8* [[VP_SUBSCRIPT]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP5]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_1:%.*]] = load i8* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP7:%.*]] = zext i8 [[VP_LOAD]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP8:%.*]] = zext i8 [[VP_LOAD_1]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP9:%.*]] = mul i32 [[VP8]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP10:%.*]] = add i32 [[VP7]] i32 [[VP9]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP11:%.*]] = abs i32 [[VP10]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP13:%.*]] = add i64 [[VP5]] i64 1
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP13]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_2:%.*]] = load i8* [[VP_SUBSCRIPT_2]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP13]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_3:%.*]] = load i8* [[VP_SUBSCRIPT_3]]
; CHECK-NEXT:    Cost 1 for i32 [[VP16:%.*]] = zext i8 [[VP_LOAD_2]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP17:%.*]] = zext i8 [[VP_LOAD_3]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP18:%.*]] = mul i32 [[VP17]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP19:%.*]] = add i32 [[VP16]] i32 [[VP18]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP20:%.*]] = abs i32 [[VP19]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP22:%.*]] = add i64 [[VP5]] i64 2
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_4:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP22]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_4:%.*]] = load i8* [[VP_SUBSCRIPT_4]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_5:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP22]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_5:%.*]] = load i8* [[VP_SUBSCRIPT_5]]
; CHECK-NEXT:    Cost 1 for i32 [[VP25:%.*]] = zext i8 [[VP_LOAD_4]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP26:%.*]] = zext i8 [[VP_LOAD_5]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP27:%.*]] = mul i32 [[VP26]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP28:%.*]] = add i32 [[VP25]] i32 [[VP27]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP29:%.*]] = abs i32 [[VP28]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP31:%.*]] = add i64 [[VP5]] i64 3
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_6:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP31]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_6:%.*]] = load i8* [[VP_SUBSCRIPT_6]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_7:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP31]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_7:%.*]] = load i8* [[VP_SUBSCRIPT_7]]
; CHECK-NEXT:    Cost 1 for i32 [[VP34:%.*]] = zext i8 [[VP_LOAD_6]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP35:%.*]] = zext i8 [[VP_LOAD_7]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP36:%.*]] = mul i32 [[VP35]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP37:%.*]] = add i32 [[VP34]] i32 [[VP36]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP38:%.*]] = abs i32 [[VP37]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i64 [[VP39:%.*]] = zext i32 [[VP29]] to i64 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i64 [[VP40:%.*]] = zext i32 [[VP20]] to i64 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP41:%.*]] = add i64 [[VP39]] i64 [[VP40]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i64 [[VP42:%.*]] = zext i32 [[VP11]] to i64 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP43:%.*]] = add i64 [[VP41]] i64 [[VP42]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP44:%.*]] = add i64 [[VP43]] i64 [[VP4]]
; CHECK-NEXT:    Cost 0 for i64 [[VP45:%.*]] = zext i32 [[VP38]] to i64 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i64 [[VP1]] = add i64 [[VP44]] i64 [[VP45]] *PSADBW* (CarryOut Def)
; CHECK-NEXT:    Cost 1 for i64 [[VP3]] = add i64 [[VP2]] i64 1
; CHECK-NEXT:    Cost 1 for i1 [[VP46:%.*]] = icmp slt i64 [[VP3]] i64 256
; CHECK-NEXT:    Cost 0 for br i1 [[VP46]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:  [[BB2]]: base cost: 43
; CHECK-NEXT:  Base Cost: 43
; CHECK-NEXT:  Cost decrease due to psadbw pattern heuristic is 43
; CHECK-NEXT:  Total Cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB3]]
; CHECK-NEXT:    Cost 0 for br [[BB4:BB[0-9]+]]
; CHECK-NEXT:  [[BB3]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB4]]
; CHECK-NEXT:    Cost 0 for br <External Block>
; CHECK-NEXT:  [[BB4]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop postexit [[BB3]] : [[BB4]] for VF = 1 resulted Cost = 0
;
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.062 = phi i64 [ 0, %entry ], [ %add40, %for.body ]
  %arrayidx = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %0 = load i8, i8* %arrayidx, align 1
  %conv = zext i8 %0 to i32
  %arrayidx2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %1 = load i8, i8* %arrayidx2, align 1
  %conv3 = zext i8 %1 to i32
  %sub = sub nsw i32 %conv, %conv3
  %2 = icmp slt i32 %sub, 0
  %neg = sub nsw i32 0, %sub
  %3 = select i1 %2, i32 %neg, i32 %sub
  %conv4 = zext i32 %3 to i64
  %add = add i64 %s.062, %conv4
  %4 = or i64 %indvars.iv, 1
  %arrayidx7 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %4
  %5 = load i8, i8* %arrayidx7, align 1
  %conv8 = zext i8 %5 to i32
  %arrayidx11 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %4
  %6 = load i8, i8* %arrayidx11, align 1
  %conv12 = zext i8 %6 to i32
  %sub13 = sub nsw i32 %conv8, %conv12
  %7 = icmp slt i32 %sub13, 0
  %neg58 = sub nsw i32 0, %sub13
  %8 = select i1 %7, i32 %neg58, i32 %sub13
  %conv15 = zext i32 %8 to i64
  %add16 = add i64 %add, %conv15
  %9 = or i64 %indvars.iv, 2
  %arrayidx19 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %9
  %10 = load i8, i8* %arrayidx19, align 2
  %conv20 = zext i8 %10 to i32
  %arrayidx23 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %9
  %11 = load i8, i8* %arrayidx23, align 2
  %conv24 = zext i8 %11 to i32
  %sub25 = sub nsw i32 %conv20, %conv24
  %12 = icmp slt i32 %sub25, 0
  %neg59 = sub nsw i32 0, %sub25
  %13 = select i1 %12, i32 %neg59, i32 %sub25
  %conv27 = zext i32 %13 to i64
  %add28 = add i64 %add16, %conv27
  %14 = or i64 %indvars.iv, 3
  %arrayidx31 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %14
  %15 = load i8, i8* %arrayidx31, align 1
  %conv32 = zext i8 %15 to i32
  %arrayidx35 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %14
  %16 = load i8, i8* %arrayidx35, align 1
  %conv36 = zext i8 %16 to i32
  %sub37 = sub nsw i32 %conv32, %conv36
  %17 = icmp slt i32 %sub37, 0
  %neg60 = sub nsw i32 0, %sub37
  %18 = select i1 %17, i32 %neg60, i32 %sub37
  %conv39 = zext i32 %18 to i64
  %add40 = add i64 %add28, %conv39
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 4
  %cmp = icmp ult i64 %indvars.iv, 1020
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  %add40.lcssa = phi i64 [ %add40, %for.body ]
  %conv42 = trunc i64 %add40.lcssa to i32
  ret i32 %conv42
}

; full unroll case: trip count is known and it is 8 or 16. No SLP is possible.
; vectorization should not be blocked for such case.
define dso_local i32 @_Z3toov(i32 %t) {
; CHECK-LABEL:  Cost Model for VPlan _Z3toov:HIR.#{{[0-9]+}} with VF = 1:
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB0:BB[0-9]+]]
; CHECK-NEXT:    Cost 0 for br [[BB1:BB[0-9]+]]
; CHECK-NEXT:  [[BB0]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB1]]
; CHECK-NEXT:    Cost 0 for br [[BB2:BB[0-9]+]]
; CHECK-NEXT:  [[BB1]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop preheader [[BB0]] : [[BB1]] for VF = 1 resulted Cost = 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB2]]
; CHECK-NEXT:    Cost Unknown for i32 [[VP0:%.*]] = phi  [ i32 [[S_0100:%.*]], [[BB1]] ],  [ i32 [[VP1:%.*]], [[BB2]] ]
; CHECK-NEXT:    Cost Unknown for i64 [[VP2:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB2]] ]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD:%.*]] = load i8* [[VP_SUBSCRIPT]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_1:%.*]] = load i8* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP4:%.*]] = zext i8 [[VP_LOAD]] to i32
; CHECK-NEXT:    Cost 1 for i32 [[VP5:%.*]] = zext i8 [[VP_LOAD_1]] to i32
; CHECK-NEXT:    Cost 1 for i32 [[VP6:%.*]] = mul i32 [[VP5]] i32 -1
; CHECK-NEXT:    Cost 1 for i32 [[VP7:%.*]] = add i32 [[VP4]] i32 [[VP6]]
; CHECK-NEXT:    Cost 2 for i32 [[VP8:%.*]] = abs i32 [[VP7]]
; CHECK-NEXT:    Cost 1 for i32 [[VP1]] = add i32 [[VP8]] i32 [[VP0]]
; CHECK-NEXT:    Cost 1 for i64 [[VP3]] = add i64 [[VP2]] i64 1
; CHECK-NEXT:    Cost 1 for i1 [[VP9:%.*]] = icmp slt i64 [[VP3]] i64 16
; CHECK-NEXT:    Cost 0 for br i1 [[VP9]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:  [[BB2]]: base cost: 11
; CHECK-NEXT:  Base Cost: 11
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB3]]
; CHECK-NEXT:    Cost 0 for br [[BB4:BB[0-9]+]]
; CHECK-NEXT:  [[BB3]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB4]]
; CHECK-NEXT:    Cost 0 for br <External Block>
; CHECK-NEXT:  [[BB4]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop postexit [[BB3]] : [[BB4]] for VF = 1 resulted Cost = 0
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  ret i32 %add.lcssa

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.010 = phi i32 [ %t, %entry ], [ %add, %for.body ]
  %arrayidx = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %0 = load i8, i8* %arrayidx, align 1
  %conv = zext i8 %0 to i32
  %arrayidx2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %1 = load i8, i8* %arrayidx2, align 1
  %conv3 = zext i8 %1 to i32
  %sub = sub nsw i32 %conv, %conv3
  %2 = icmp slt i32 %sub, 0
  %neg = sub nsw i32 0, %sub
  %3 = select i1 %2, i32 %neg, i32 %sub
  %add = add nuw nsw i32 %3, %s.010
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}

; Full unroll case: trip count is known and it is 8 or 16 but SLP is expected
; to trigger.  The loop is fully unrolled by after VPlan but before SLP.
; Should not be vectorized.
define dso_local i32 @full_unroll_with_slp(i32 %t) {
; CHECK-LABEL:  Cost Model for VPlan full_unroll_with_slp:HIR.#{{[0-9]+}} with VF = 1:
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB0:BB[0-9]+]]
; CHECK-NEXT:    Cost 0 for br [[BB1:BB[0-9]+]]
; CHECK-NEXT:  [[BB0]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB1]]
; CHECK-NEXT:    Cost 0 for br [[BB2:BB[0-9]+]]
; CHECK-NEXT:  [[BB1]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop preheader [[BB0]] : [[BB1]] for VF = 1 resulted Cost = 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB2]]
; CHECK-NEXT:    Cost Unknown for i32 [[VP0:%.*]] = phi  [ i32 [[S_0100:%.*]], [[BB1]] ],  [ i32 [[VP1:%.*]], [[BB2]] ] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost Unknown for i64 [[VP2:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB2]] ]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD:%.*]] = load i8* [[VP_SUBSCRIPT]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_1:%.*]] = load i8* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP4:%.*]] = zext i8 [[VP_LOAD]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP5:%.*]] = zext i8 [[VP_LOAD_1]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP6:%.*]] = mul i32 [[VP5]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP7:%.*]] = add i32 [[VP4]] i32 [[VP6]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP8:%.*]] = abs i32 [[VP7]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_2:%.*]] = load i8* [[VP_SUBSCRIPT_2]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_3:%.*]] = load i8* [[VP_SUBSCRIPT_3]]
; CHECK-NEXT:    Cost 1 for i32 [[VP9:%.*]] = zext i8 [[VP_LOAD_2]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP10:%.*]] = zext i8 [[VP_LOAD_3]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP11:%.*]] = mul i32 [[VP10]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP12:%.*]] = add i32 [[VP9]] i32 [[VP11]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP13:%.*]] = abs i32 [[VP12]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_4:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_4:%.*]] = load i8* [[VP_SUBSCRIPT_4]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_5:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_5:%.*]] = load i8* [[VP_SUBSCRIPT_5]]
; CHECK-NEXT:    Cost 1 for i32 [[VP14:%.*]] = zext i8 [[VP_LOAD_4]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP15:%.*]] = zext i8 [[VP_LOAD_5]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP16:%.*]] = mul i32 [[VP15]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP17:%.*]] = add i32 [[VP14]] i32 [[VP16]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP18:%.*]] = abs i32 [[VP17]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_6:%.*]] = subscript inbounds [1024 x i8]* @a i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_6:%.*]] = load i8* [[VP_SUBSCRIPT_6]]
; CHECK-NEXT:    Cost 0 for i8* [[VP_SUBSCRIPT_7:%.*]] = subscript inbounds [1024 x i8]* @b i64 0 i64 [[VP2]]
; CHECK-NEXT:    Cost 1 for i8 [[VP_LOAD_7:%.*]] = load i8* [[VP_SUBSCRIPT_7]]
; CHECK-NEXT:    Cost 1 for i32 [[VP19:%.*]] = zext i8 [[VP_LOAD_6]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP20:%.*]] = zext i8 [[VP_LOAD_7]] to i32 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP21:%.*]] = mul i32 [[VP20]] i32 -1 *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP22:%.*]] = add i32 [[VP19]] i32 [[VP21]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 2 for i32 [[VP23:%.*]] = abs i32 [[VP22]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP24:%.*]] = add i32 [[VP13]] i32 [[VP8]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP25:%.*]] = add i32 [[VP24]] i32 [[VP23]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP26:%.*]] = add i32 [[VP25]] i32 [[VP18]] *PSADBW*, CarryOut: [[VP1]]
; CHECK-NEXT:    Cost 1 for i32 [[VP1]] = add i32 [[VP26]] i32 [[VP0]] *PSADBW* (CarryOut Def)
; CHECK-NEXT:    Cost 1 for i64 [[VP3]] = add i64 [[VP2]] i64 1
; CHECK-NEXT:    Cost 1 for i1 [[VP27:%.*]] = icmp slt i64 [[VP3]] i64 16
; CHECK-NEXT:    Cost 0 for br i1 [[VP27]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:  [[BB2]]: base cost: 38
; CHECK-NEXT:  Base Cost: 38
; CHECK-NEXT:  Cost decrease due to psadbw pattern heuristic is 38
; CHECK-NEXT:  Total Cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB3]]
; CHECK-NEXT:    Cost 0 for br [[BB4:BB[0-9]+]]
; CHECK-NEXT:  [[BB3]]: base cost: 0
; CHECK-NEXT:  Analyzing VPBasicBlock [[BB4]]
; CHECK-NEXT:    Cost 0 for br <External Block>
; CHECK-NEXT:  [[BB4]]: base cost: 0
; CHECK-NEXT:  Cost Model for Loop postexit [[BB3]] : [[BB4]] for VF = 1 resulted Cost = 0
;
entry:
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.body
  %add.lcssa = phi i32 [ %add, %for.body ]
  ret i32 %add.lcssa

for.body:                                         ; preds = %for.body, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %s.010 = phi i32 [ %t, %entry ], [ %add, %for.body ]

  %arrayidx1.0 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %val1.0 = load i8, i8* %arrayidx1.0, align 1
  %conv.0 = zext i8 %val1.0 to i32
  %arrayidx2.0 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %val2.0 = load i8, i8* %arrayidx2.0, align 1
  %conv3.0 = zext i8 %val2.0 to i32
  %sub.0 = sub nsw i32 %conv.0, %conv3.0
  %cmp.0 = icmp slt i32 %sub.0, 0
  %neg.0 = sub nsw i32 0, %sub.0
  %sel.0 = select i1 %cmp.0, i32 %neg.0, i32 %sub.0

  %arrayidx1.1 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %val1.1 = load i8, i8* %arrayidx1.1, align 1
  %conv.1 = zext i8 %val1.1 to i32
  %arrayidx2.1 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %val2.1 = load i8, i8* %arrayidx2.1, align 1
  %conv3.1 = zext i8 %val2.1 to i32
  %sub.1 = sub nsw i32 %conv.1, %conv3.1
  %cmp.1 = icmp slt i32 %sub.1, 0
  %neg.1 = sub nsw i32 0, %sub.1
  %sel.1 = select i1 %cmp.1, i32 %neg.1, i32 %sub.1

  %arrayidx1.2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %val1.2 = load i8, i8* %arrayidx1.2, align 1
  %conv.2 = zext i8 %val1.2 to i32
  %arrayidx2.2 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %val2.2 = load i8, i8* %arrayidx2.2, align 1
  %conv3.2 = zext i8 %val2.2 to i32
  %sub.2 = sub nsw i32 %conv.2, %conv3.2
  %cmp.2 = icmp slt i32 %sub.2, 0
  %neg.2 = sub nsw i32 0, %sub.2
  %sel.2 = select i1 %cmp.2, i32 %neg.2, i32 %sub.2

  %arrayidx1.3 = getelementptr inbounds [1024 x i8], [1024 x i8]* @a, i64 0, i64 %indvars.iv
  %val1.3 = load i8, i8* %arrayidx1.3, align 1
  %conv.3 = zext i8 %val1.3 to i32
  %arrayidx2.3 = getelementptr inbounds [1024 x i8], [1024 x i8]* @b, i64 0, i64 %indvars.iv
  %val2.3 = load i8, i8* %arrayidx2.3, align 1
  %conv3.3 = zext i8 %val2.3 to i32
  %sub.3 = sub nsw i32 %conv.3, %conv3.3
  %cmp.3 = icmp slt i32 %sub.3, 0
  %neg.3 = sub nsw i32 0, %sub.3
  %sel.3 = select i1 %cmp.3, i32 %neg.3, i32 %sub.3

  %add.1 = add nuw nsw i32 %sel.0, %sel.1
  %add.2 = add nuw nsw i32 %sel.2, %sel.3
  %add.3 = add nuw nsw i32 %add.1, %add.2

  %add = add nuw nsw i32 %add.3, %s.010
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 16
  br i1 %exitcond, label %for.cond.cleanup, label %for.body
}
; end INTEL_FEATURE_SW_ADVANCED
