; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -opaque-pointers=0 -passes='hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>' -vplan-print-after-vpentity-instrs -disable-output < %s 2>&1 | FileCheck %s

; Test checks that HIR code gen emits code for pointer induction with variable stride

define i32 @main() {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: main:HIR.#{{[0-9]+}}
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%lp.linear}
; CHECK-DAG:     [[VP1:%.*]] = {%0 + 1}
; CHECK-DAG:     [[VP2:%.*]] = {%i6.linear.iv}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i64** [[VP_LP_LINEAR:%.*]] = allocate-priv i64**, OrigAlign = 8
; CHECK-NEXT:     i32 [[VP__IND_INIT:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:     i32 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i32 1
; CHECK-NEXT:     i64* [[VP_LOAD:%.*]] = load i64** [[LP_LINEAR0:%.*]]
; CHECK-NEXT:     i64* [[VP_LP_LINEAR_IND_INIT:%.*]] = induction-init{getelementptr} i64* [[VP_LOAD]] i64 [[VP1]]
; CHECK-NEXT:     store i64* [[VP_LP_LINEAR_IND_INIT]] i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64 [[VP_LP_LINEAR_IND_INIT_STEP:%.*]] = induction-init-step{getelementptr} i64 [[VP1]]
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i32 [[VP3:%.*]] = phi  [ i32 [[VP__IND_INIT]], [[BB1]] ],  [ i32 [[VP4:%.*]], [[BB2]] ]
; CHECK-NEXT:     i64* [[VP5:%.*]] = phi  [ i64* [[VP_LP_LINEAR_IND_INIT]], [[BB1]] ],  [ i64* [[VP6:%.*]], [[BB2]] ]
; CHECK-NEXT:     store i64* [[VP5]] i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64** [[VP_SUBSCRIPT:%.*]] = subscript inbounds i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     call i64** [[VP_SUBSCRIPT]] void (i64**)* @_Z3bazPPl
; CHECK-NEXT:     i64** [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64* [[VP_LOAD_1:%.*]] = load i64** [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:     i64* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds i64* [[VP_LOAD_1]] i64 [[VP1]]
; CHECK-NEXT:     i64** [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     store i64* [[VP_SUBSCRIPT_2]] i64** [[VP_SUBSCRIPT_3]]
; CHECK-NEXT:     i32 [[VP4]] = add i32 [[VP3]] i32 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     i64* [[VP6]] = getelementptr inbounds i64* [[VP5]] i64 [[VP_LP_LINEAR_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP7:%.*]] = icmp slt i32 [[VP4]] i32 64
; CHECK-NEXT:     br i1 [[VP7]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     i32 [[VP__IND_FINAL:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:     i64* [[VP_LOAD_2:%.*]] = load i64** [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64* [[VP_LP_LINEAR_IND_FINAL:%.*]] = induction-final{getelementptr} i64* [[VP_LOAD]] i64 [[VP1]]
; CHECK-NEXT:     store i64* [[VP_LP_LINEAR_IND_FINAL]] i64** [[LP_LINEAR0]]
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK:       Function: main
; CHECK-EMPTY:
; CHECK-NEXT:  BEGIN REGION { modified }
; CHECK-NEXT:        [[PRIV_MEM_BC0:%.*]] = &((i64**)([[PRIV_MEM0:%.*]])[0])
; CHECK-NEXT:        [[DOTUNIFLOAD0:%.*]] = ([[LP_LINEAR0]])[0]
; CHECK-NEXT:        [[IND_VEC_STEP0:%.*]] = [[TMP0:%.*]] + 1  *  <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:        (<4 x i64*>*)([[PRIV_MEM0]])[0] = &((<4 x i64*>)([[DOTUNIFLOAD0]])[%ind.vec.step])
; CHECK-NEXT:        [[IND_STEP_INIT0:%.*]] = [[TMP0]] + 1  *  4
; CHECK-NEXT:        [[PHI_TEMP0:%.*]] = &((<4 x i64*>)([[DOTUNIFLOAD0]])[%ind.vec.step])
; CHECK-NEXT:<{{[0-9]+}}>
; CHECK-NEXT:        + DO i1 = 0, 63, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK-NEXT:        |   (<4 x i64*>*)([[PRIV_MEM0]])[0] = [[PHI_TEMP0]]
; CHECK-NEXT:        |   @_Z3bazPPl(&((i64**)([[PRIV_MEM0]])[0]))
; CHECK-NEXT:        |   [[EXTRACT_1_0:%.*]] = extractelement &((<4 x i64**>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  1
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_1_0]])
; CHECK-NEXT:        |   [[EXTRACT_2_0:%.*]] = extractelement &((<4 x i64**>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  2
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_2_0]])
; CHECK-NEXT:        |   [[EXTRACT_3_0:%.*]] = extractelement &((<4 x i64**>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  3
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_3_0]])
; CHECK-NEXT:        |   [[DOTVEC0:%.*]] = (<4 x i64*>*)([[PRIV_MEM0]])[0]
; CHECK-NEXT:        |   (<4 x i64*>*)([[PRIV_MEM0]])[0] = &((<4 x i64*>)([[DOTVEC0]])[%0 + 1])
; CHECK-NEXT:        |   [[PHI_TEMP0]] = &((<4 x i64*>)([[PHI_TEMP0]])[%ind.step.init])
; CHECK-NEXT:        + END LOOP
; CHECK-NEXT:<{{[0-9]+}}>
; CHECK-NEXT:        [[DOTVEC40:%.*]] = (<4 x i64*>*)([[PRIV_MEM0]])[0]
; CHECK-NEXT:        [[CAST_CRD0:%.*]] = sext.i32.i64(64)
; CHECK-NEXT:        [[TMP1:%.*]] = [[TMP0]] + 1  *  [[CAST_CRD0]]
; CHECK-NEXT:        ([[LP_LINEAR0]])[0] = &((i64*)([[DOTUNIFLOAD0]])[%1])
; CHECK-NEXT:  END REGION
;
entry:
  %lp.linear = alloca i64*, align 8
  %i6.linear.iv = alloca i32, align 4
  %a = alloca [128 x i64], align 16
  %arrayidx = getelementptr inbounds [128 x i64], [128 x i64]* %a, i64 0, i64 3
  store i64 1, i64* %arrayidx, align 8
  %0 = load i64, i64* %arrayidx, align 8
  %add = add nsw i64 %0, 1
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.247
  br label %DIR.OMP.SIMD.148

DIR.OMP.SIMD.148:                                 ; preds = %DIR.OMP.SIMD.1
  %1 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR"(i64** %lp.linear, i64 %add), "QUAL.OMP.LINEAR:IV"(i32* %i6.linear.iv, i32 1) ]
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.148
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.2, %omp.inner.for.body
  %.omp.iv.local.035 = phi i32 [ 0, %DIR.OMP.SIMD.2 ], [ %add8, %omp.inner.for.body ]
  call void @_Z3bazPPl(i64** noundef nonnull %lp.linear) #0
  %2 = load i64*, i64** %lp.linear, align 8
  %add.ptr = getelementptr inbounds i64, i64* %2, i64 %add
  store i64* %add.ptr, i64** %lp.linear, align 8
  %add8 = add nuw nsw i32 %.omp.iv.local.035, 1
  %exitcond43.not = icmp eq i32 %add8, 64
  br i1 %exitcond43.not, label %DIR.OMP.END.SIMD.434, label %omp.inner.for.body

DIR.OMP.END.SIMD.434:                             ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %1) [ "DIR.OMP.END.SIMD"() ]
  br label %for.cond.cleanup12

for.cond.cleanup12:                               ; preds = %DIR.OMP.END.SIMD.434
  ret i32 0
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare dso_local void @_Z3bazPPl(i64** noundef) local_unnamed_addr #0

attributes #0 = { nounwind }
