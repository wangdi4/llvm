; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -passes='hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>' -vplan-print-after-vpentity-instrs -disable-output -vplan-force-vf=4 < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,UF1
; RUN: opt -passes='hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>' -vplan-print-after-vpentity-instrs -disable-output -vplan-force-uf=2 -vplan-force-vf=4 < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,UF2

; Test checks that HIR code gen emits code for pointer induction with variable stride

define i32 @main() {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: main:HIR.#{{[0-9]+}}
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%lp.linear}
; CHECK-DAG:     [[VP1:%.*]] = {%0 + 1}
; CHECK-DAG:     [[VP2:%.*]] = {%i6.linear.iv}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     ptr [[VP_LP_LINEAR:%.*]] = allocate-priv ptr, OrigAlign = 8
; CHECK-NEXT:     i32 [[VP__IND_INIT:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:     i32 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i32 1
; CHECK-NEXT:     ptr [[VP_LOAD:%.*]] = load ptr [[LP_LINEAR0:%.*]]
; CHECK-NEXT:     i64 [[VP1_MUL:%.*]] = mul i64 [[VP1]] i64 8
; CHECK-NEXT:     ptr [[VP_LP_LINEAR_IND_INIT:%.*]] = induction-init{getelementptr} ptr [[VP_LOAD]] i64 [[VP1_MUL]]
; CHECK-NEXT:     store ptr [[VP_LP_LINEAR_IND_INIT]] ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     i64 [[VP_LP_LINEAR_IND_INIT_STEP:%.*]] = induction-init-step{getelementptr} i64 [[VP1_MUL]]
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i32 [[VP3:%.*]] = phi  [ i32 [[VP__IND_INIT]], [[BB1]] ],  [ i32 [[VP4:%.*]], [[BB2]] ]
; CHECK-NEXT:     ptr [[VP5:%.*]] = phi  [ ptr [[VP_LP_LINEAR_IND_INIT]], [[BB1]] ],  [ ptr [[VP6:%.*]], [[BB2]] ]
; CHECK-NEXT:     store ptr [[VP5]] ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     ptr [[VP_SUBSCRIPT:%.*]] = subscript inbounds ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     call ptr [[VP_SUBSCRIPT]] ptr @_Z3bazPPl
; CHECK-NEXT:     ptr [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     ptr [[VP_LOAD_1:%.*]] = load ptr [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:     ptr [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds ptr [[VP_LOAD_1]] i64 [[VP1]]
; CHECK-NEXT:     ptr [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     store ptr [[VP_SUBSCRIPT_2]] ptr [[VP_SUBSCRIPT_3]]
; CHECK-NEXT:     i32 [[VP4]] = add i32 [[VP3]] i32 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     ptr [[VP6]] = getelementptr inbounds i8, ptr [[VP5]] i64 [[VP_LP_LINEAR_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP7:%.*]] = icmp slt i32 [[VP4]] i32 64
; CHECK-NEXT:     br i1 [[VP7]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     i32 [[VP__IND_FINAL:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:     ptr [[VP_LOAD_2:%.*]] = load ptr [[VP_LP_LINEAR]]
; CHECK-NEXT:     ptr [[VP_LP_LINEAR_IND_FINAL:%.*]] = induction-final{getelementptr} ptr [[VP_LOAD]] i64 [[VP1_MUL]]
; CHECK-NEXT:     store ptr [[VP_LP_LINEAR_IND_FINAL]] ptr [[LP_LINEAR0]]
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK:       Function: main
; CHECK-EMPTY:
; CHECK-NEXT:  BEGIN REGION { modified }
; CHECK-NEXT:        [[PRIV_MEM_BC0:%.*]] = &((ptr)([[PRIV_MEM0:%.*]])[0])
; CHECK-NEXT:        [[DOTUNIFLOAD0:%.*]] = ([[LP_LINEAR0]])[0]
; CHECK-NEXT:        [[TMP0_VEC_MUL:%.*]] = [[TMP0:%.*]] + 1 * 8
; CHECK-NEXT:        [[TMP0_SCAL_MUL:%.*]] = [[TMP0]] + 1 * 8
; CHECK-NEXT:        [[IND_VEC_STEP0:%.*]] = [[TMP0_SCAL_MUL]]  *  <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:        (<4 x ptr>*)([[PRIV_MEM0]])[0] = &((<4 x ptr>)([[DOTUNIFLOAD0]])[%ind.vec.step])
; CHECK-NEXT:        [[IND_STEP_INIT0:%.*]] = [[TMP0_SCAL_MUL]] *  4
; CHECK-NEXT:        [[PHI_TEMP0:%.*]] = &((<4 x ptr>)([[DOTUNIFLOAD0]])[%ind.vec.step])
; CHECK-NEXT:<{{[0-9]+}}>
; UF1-NEXT:          + DO i1 = 0, 63, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; UF2-NEXT:          + DO i1 = 0, 63, 8   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; CHECK-NEXT:        |   (<4 x ptr>*)([[PRIV_MEM0]])[0] = [[PHI_TEMP0]]
; CHECK-NEXT:        |   @_Z3bazPPl(&((ptr)([[PRIV_MEM0]])[0]))
; CHECK-NEXT:        |   [[EXTRACT_1_0:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  1
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_1_0]])
; CHECK-NEXT:        |   [[EXTRACT_2_0:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  2
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_2_0]])
; CHECK-NEXT:        |   [[EXTRACT_3_0:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  3
; CHECK-NEXT:        |   @_Z3bazPPl([[EXTRACT_3_0]])
; CHECK-NEXT:        |   [[DOTVEC0:%.*]] = (<4 x ptr>*)([[PRIV_MEM0]])[0]
; CHECK-NEXT:        |   (<4 x ptr>*)([[PRIV_MEM0]])[0] = &((<4 x ptr>)([[DOTVEC0]])[%0 + 1])
; UF1-NEXT:          |   [[PHI_TEMP0]] = &((<4 x ptr>)([[PHI_TEMP0]])[%ind.step.init])
; UF2-NEXT:          |   (<4 x ptr>*)([[PRIV_MEM0]])[0] = &((<4 x ptr>)([[PHI_TEMP0]])[%ind.step.init])
; UF2-NEXT:          |   @_Z3bazPPl(&((ptr)([[PRIV_MEM0]])[0]))
; UF2-NEXT:          |   [[EXTRACT_1_30:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  1
; UF2-NEXT:          |   @_Z3bazPPl([[EXTRACT_1_30]])
; UF2-NEXT:          |   [[EXTRACT_2_40:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  2
; UF2-NEXT:          |   @_Z3bazPPl([[EXTRACT_2_40]])
; UF2-NEXT:          |   [[EXTRACT_3_50:%.*]] = extractelement &((<4 x ptr>)([[PRIV_MEM_BC0]])[<i32 0, i32 1, i32 2, i32 3>]),  3
; UF2-NEXT:          |   @_Z3bazPPl([[EXTRACT_3_50]])
; UF2-NEXT:          |   [[DOTVEC60:%.*]] = (<4 x ptr>*)([[PRIV_MEM0]])[0]
; UF2-NEXT:          |   (<4 x ptr>*)([[PRIV_MEM0]])[0] = &((<4 x ptr>)([[DOTVEC60]])[%0 + 1])

; UF2-NEXT:          |   [[GEP_BASE_COPY0:%.*]] = &((<4 x ptr>)([[PHI_TEMP0]])[%ind.step.init])
; UF2-NEXT:          |   [[PHI_TEMP0]] = &((<4 x ptr>)([[GEP_BASE_COPY0]])[%ind.step.init])
; CHECK-NEXT:        + END LOOP
; CHECK-NEXT:<{{[0-9]+}}>
; CHECK-NEXT:        [[DOTVEC40:%.*]] = (<4 x ptr>*)([[PRIV_MEM0]])[0]
; CHECK-NEXT:        [[CAST_CRD0:%.*]] = sext.i32.i64(64)
; CHECK-NEXT:        [[TMP1:%.*]] = [[TMP0_SCAL_MUL]]  *  [[CAST_CRD0]]
; CHECK-NEXT:        ([[LP_LINEAR0]])[0] = &((i8*)([[DOTUNIFLOAD0]])[%1])
; CHECK-NEXT:  END REGION
;
entry:
  %lp.linear = alloca ptr, align 8
  %i6.linear.iv = alloca i32, align 4
  %a = alloca [128 x i64], align 16
  %arrayidx = getelementptr inbounds [128 x i64], ptr %a, i64 0, i64 3
  store i64 1, ptr %arrayidx, align 8
  %0 = load i64, ptr %arrayidx, align 8
  %add = add nsw i64 %0, 1
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.247
  br label %DIR.OMP.SIMD.148

DIR.OMP.SIMD.148:                                 ; preds = %DIR.OMP.SIMD.1
  %1 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(ptr %lp.linear, ptr null, i32 1, i64 %add), "QUAL.OMP.LINEAR:IV.TYPED"(ptr %i6.linear.iv, i32 0, i32 1, i32 1) ]
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.148
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.2, %omp.inner.for.body
  %.omp.iv.local.035 = phi i32 [ 0, %DIR.OMP.SIMD.2 ], [ %add8, %omp.inner.for.body ]
  call void @_Z3bazPPl(ptr noundef nonnull %lp.linear) #0
  %2 = load ptr, ptr %lp.linear, align 8
  %add.ptr = getelementptr inbounds i64, ptr %2, i64 %add
  store ptr %add.ptr, ptr %lp.linear, align 8
  %add8 = add nuw nsw i32 %.omp.iv.local.035, 1
  %exitcond43.not = icmp eq i32 %add8, 64
  br i1 %exitcond43.not, label %DIR.OMP.END.SIMD.434, label %omp.inner.for.body

DIR.OMP.END.SIMD.434:                             ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %1) [ "DIR.OMP.END.SIMD"() ]
  br label %for.cond.cleanup12

for.cond.cleanup12:                               ; preds = %DIR.OMP.END.SIMD.434
  ret i32 0
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare dso_local void @_Z3bazPPl(ptr noundef) local_unnamed_addr #0

attributes #0 = { nounwind }
