; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: asserts
; RUN: opt -S < %s -VPlanDriver -disable-output -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind uwtable
define dso_local void @divergentInnerLoopIV(i32* nocapture %a, i64* nocapture %b, i64* nocapture %c) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VF:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_ORIG_TRIP_COUNT:%.*]] = orig-trip-count for original loop outer.loop.body (SVAOpBits )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 [[VP_ORIG_TRIP_COUNT]], UF = 1 (SVAOpBits 0->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP_VECTOR_LOOP_IV_NEXT:%.*]], [[BB3:BB[0-9]+]] ] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ],  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB3]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_ADD1:%.*]] = add i64 [[VP_INDVARS_IV]] i64 42 (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB5:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INNER_IV:%.*]] = phi  [ i64 [[VP_ADD1]], [[BB4]] ],  [ i64 [[VP_INNER_IV_ADD:%.*]], [[BB6:BB[0-9]+]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP_LOOP_MASK:%.*]] = phi  [ i1 true, [[BB4]] ],  [ i1 [[VP_LOOP_MASK_NEXT:%.*]], [[BB6]] ] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:    SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[BB6]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP0:%.*]] = block-predicate i1 [[VP_LOOP_MASK]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_A_GEP:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_INNER_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_A_LOAD:%.*]] = load i32* [[VP_A_GEP]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_B_GEP:%.*]] = getelementptr inbounds i64* [[B0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i64 [[VP_INNER_IV]] i64* [[VP_B_GEP]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INNER_IV_ADD]] = add i64 [[VP_INNER_IV]] i64 1 (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP_INNER_EXIT:%.*]] = icmp i64 [[VP_INNER_IV_ADD]] i64 512 (SVAOpBits 0->V 1->V )
; CHECK-NEXT:    SUCCESSORS(1):[[BB6]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP_INNER_EXIT_NOT:%.*]] = not i1 [[VP_INNER_EXIT]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP_LOOP_MASK_NEXT]] = and i1 [[VP_INNER_EXIT_NOT]] i1 [[VP_LOOP_MASK]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] i1 [[VP1:%.*]] = all-zero-check i1 [[VP_LOOP_MASK_NEXT]] (SVAOpBits 0->V )
; CHECK-NEXT:    SUCCESSORS(2):[[BB8:BB[0-9]+]](i1 [[VP1]]), [[BB5]](!i1 [[VP1]])
; CHECK-NEXT:    PREDECESSORS(1): [[BB7]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB8]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV_NEXT]] = add i64 [[VP_VECTOR_LOOP_IV]] i64 [[VP_VF]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp i64 [[VP_VECTOR_LOOP_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB3]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB6]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:     Condition([[BB8]]): [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND]] = icmp i64 [[VP_VECTOR_LOOP_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(2):[[BB9:BB[0-9]+]](i1 [[VP_VECTOR_LOOP_EXITCOND]]), [[BB2]](!i1 [[VP_VECTOR_LOOP_EXITCOND]])
; CHECK-NEXT:    PREDECESSORS(1): [[BB8]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB9]]:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB10:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB10]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB9]]
;
entry:
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %outer.loop.body

outer.loop.body:
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %outer.loop.exit ]
  %add1 = add i64 %indvars.iv, 42
  br label %inner.loop

inner.loop:
  %inner.iv = phi i64 [ %add1, %outer.loop.body ], [ %inner.iv.add, %inner.loop ]
  ; Scalar user of inner IV
  %a.gep = getelementptr inbounds i32, i32* %a, i64 %inner.iv
  %a.load = load i32, i32* %a.gep, align 4
  ; Vector user of inner IV
  %b.gep = getelementptr inbounds i64, i64* %b, i64 %indvars.iv
  store i64 %inner.iv, i64* %b.gep
  %inner.iv.add = add i64 %inner.iv, 1
  %inner.exit = icmp eq i64 %inner.iv.add, 512
  br i1 %inner.exit, label %outer.loop.exit, label %inner.loop

outer.loop.exit:
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %outer.loop.body

DIR.OMP.END.SIMD.3:
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}


; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)
