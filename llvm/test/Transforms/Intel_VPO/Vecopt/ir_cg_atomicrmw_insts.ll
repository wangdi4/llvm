; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Check vector codegen handling of atomicrmw instructions.
; TODO: In some cases atomic operations are not allowed to be reordered, for
; which we need to bail out of vectorization (JIRA: CMPLRLLVM-10743).

; RUN: opt < %s -S -VPlanDriver -vplan-force-vf=2 | FileCheck %s --check-prefix=LLVM-CG

declare token @llvm.directive.region.entry() nounwind
declare void @llvm.directive.region.exit(token) nounwind

define void @test1(i64 %n, i64 addrspace(4)* %arr) {
; LLVM-CG-LABEL: @test1(
; LLVM-CG:       vector.ph:
; LLVM-CG-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <2 x i64 addrspace(4)*> undef, i64 addrspace(4)* [[ARR:%.*]], i32 0
; LLVM-CG-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <2 x i64 addrspace(4)*> [[BROADCAST_SPLATINSERT]], <2 x i64 addrspace(4)*> undef, <2 x i32> zeroinitializer
; LLVM-CG-NEXT:    [[BROADCAST_SPLATINSERT3:%.*]] = insertelement <2 x i64> undef, i64 [[N:%.*]], i32 0
; LLVM-CG-NEXT:    [[BROADCAST_SPLAT4:%.*]] = shufflevector <2 x i64> [[BROADCAST_SPLATINSERT3]], <2 x i64> undef, <2 x i32> zeroinitializer
; LLVM-CG-NEXT:    br label [[VECTOR_BODY:%.*]]
; LLVM-CG:       vector.body:
; LLVM-CG:         [[MM_VECTORGEP:%.*]] = getelementptr inbounds i64, <2 x i64 addrspace(4)*> [[BROADCAST_SPLAT]], <2 x i64> [[VEC_PHI:%.*]]
; LLVM-CG-NEXT:    [[MM_VECTORGEP_EXTRACT_1_:%.*]] = extractelement <2 x i64 addrspace(4)*> [[MM_VECTORGEP]], i32 1
; LLVM-CG-NEXT:    [[MM_VECTORGEP_EXTRACT_0_:%.*]] = extractelement <2 x i64 addrspace(4)*> [[MM_VECTORGEP]], i32 0
; LLVM-CG-NEXT:    [[MM_VECTORGEP1:%.*]] = getelementptr inbounds i64, i64 addrspace(4)* [[ARR]], i64 42
; LLVM-CG-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <2 x i64 addrspace(4)*> undef, i64 addrspace(4)* [[MM_VECTORGEP1]], i32 0
; LLVM-CG-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <2 x i64 addrspace(4)*> [[DOTSPLATINSERT]], <2 x i64 addrspace(4)*> undef, <2 x i32> zeroinitializer
; LLVM-CG-NEXT:    [[DOTSPLAT_EXTRACT_0_:%.*]] = extractelement <2 x i64 addrspace(4)*> [[DOTSPLAT]], i32 0
; LLVM-CG-NEXT:    [[TMP1:%.*]] = atomicrmw volatile add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 1 acquire
; LLVM-CG-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> undef, i64 [[TMP1]], i32 0
; LLVM-CG-NEXT:    [[TMP3:%.*]] = atomicrmw volatile add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 1 acquire
; LLVM-CG-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> [[TMP2]], i64 [[TMP3]], i32 1
; LLVM-CG-NEXT:    [[TMP5:%.*]] = atomicrmw add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 [[UNI_PHI:%.*]] acquire
; LLVM-CG-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> undef, i64 [[TMP5]], i32 0
; LLVM-CG-NEXT:    [[TMP7:%.*]] = atomicrmw add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 [[VEC_PHI_EXTRACT_1_:%.*]] acquire
; LLVM-CG-NEXT:    [[TMP8:%.*]] = insertelement <2 x i64> [[TMP6]], i64 [[TMP7]], i32 1
; LLVM-CG-NEXT:    [[TMP9:%.*]] = atomicrmw add i64 addrspace(4)* [[MM_VECTORGEP_EXTRACT_0_]], i64 [[UNI_PHI]] acquire
; LLVM-CG-NEXT:    [[TMP10:%.*]] = insertelement <2 x i64> undef, i64 [[TMP9]], i32 0
; LLVM-CG-NEXT:    [[TMP11:%.*]] = atomicrmw add i64 addrspace(4)* [[MM_VECTORGEP_EXTRACT_1_]], i64 [[VEC_PHI_EXTRACT_1_]] acquire
; LLVM-CG-NEXT:    [[TMP12:%.*]] = insertelement <2 x i64> [[TMP10]], i64 [[TMP11]], i32 1
; LLVM-CG-NEXT:    [[TMP13:%.*]] = add <2 x i64> [[TMP4]], [[VEC_PHI]]
; LLVM-CG-NEXT:    [[TMP14:%.*]] = add <2 x i64> [[TMP8]], [[VEC_PHI]]
; LLVM-CG-NEXT:    [[TMP15:%.*]] = add <2 x i64> [[TMP12]], [[VEC_PHI]]
; LLVM-CG-NEXT:    [[PREDICATE:%.*]] = extractelement <2 x i1> [[TMP0:%.*]], i64 0
; LLVM-CG-NEXT:    [[TMP16:%.*]] = icmp eq i1 [[PREDICATE]], true
; LLVM-CG-NEXT:    br i1 [[TMP16]], label [[PRED_ATOMICRMW_IF:%.*]], label [[TMP19:%.*]]
; LLVM-CG:       pred.atomicrmw.if:
; LLVM-CG-NEXT:    [[TMP17:%.*]] = atomicrmw volatile add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 1 acquire
; LLVM-CG-NEXT:    [[TMP18:%.*]] = insertelement <2 x i64> undef, i64 [[TMP17]], i32 0
; LLVM-CG-NEXT:    br label [[TMP19]]
; LLVM-CG:       19:
; LLVM-CG-NEXT:    [[TMP20:%.*]] = phi <2 x i64> [ undef, [[VECTOR_BODY]] ], [ [[TMP18]], [[PRED_ATOMICRMW_IF]] ]
; LLVM-CG-NEXT:    br label [[PRED_ATOMICRMW_CONTINUE:%.*]]
; LLVM-CG:       pred.atomicrmw.continue:
; LLVM-CG-NEXT:    [[PREDICATE2:%.*]] = extractelement <2 x i1> [[TMP0]], i64 1
; LLVM-CG-NEXT:    [[TMP21:%.*]] = icmp eq i1 [[PREDICATE2]], true
; LLVM-CG-NEXT:    br i1 [[TMP21]], label [[PRED_ATOMICRMW_IF5:%.*]], label [[TMP24:%.*]]
; LLVM-CG:       pred.atomicrmw.if5:
; LLVM-CG-NEXT:    [[TMP22:%.*]] = atomicrmw volatile add i64 addrspace(4)* [[DOTSPLAT_EXTRACT_0_]], i64 1 acquire
; LLVM-CG-NEXT:    [[TMP23:%.*]] = insertelement <2 x i64> [[TMP20]], i64 [[TMP22]], i32 1
; LLVM-CG-NEXT:    br label [[TMP24]]
;
entry:
  %cmp = icmp sgt i64 %n, 0
  br i1 %cmp, label %for.body.lr.ph, label %exit

for.body.lr.ph:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %iv = phi i64 [ 0, %for.body.lr.ph ], [ %iv.next, %for.latch ]
  %cond = icmp eq i64 %iv, 42
  %var.gep = getelementptr inbounds i64, i64 addrspace(4)* %arr, i64 %iv
  %uni.gep = getelementptr inbounds i64, i64 addrspace(4)* %arr, i64 42

  %atomic.inst.1 = atomicrmw volatile add i64 addrspace(4)* %uni.gep, i64 1 acquire
  %atomic.inst.2 = atomicrmw add i64 addrspace(4)* %uni.gep, i64 %iv acquire
  %atomic.inst.3 = atomicrmw add i64 addrspace(4)* %var.gep, i64 %iv acquire

  %use1 = add i64 %atomic.inst.1, %iv
  %use2 = add i64 %atomic.inst.2, %iv
  %use3 = add i64 %atomic.inst.3, %iv
  br i1 %cond, label %if.then, label %for.latch

if.then:
  %atomic.inst.pred = atomicrmw volatile add i64 addrspace(4)* %uni.gep, i64 1 acquire
  %var.use = add i64 %atomic.inst.pred, %iv
  br label %for.latch

for.latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %for.end, label %for.body

for.end:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"()]
  br label %exit

exit:
  ret void
}
