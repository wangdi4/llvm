; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vplan-vec -vplan-force-vf=2 -vplan-enable-soa -disable-output\
; RUN: -vplan-print-after-transformed-soa-geps --vplan-dump-da-shapes -S %s 2>&1 | FileCheck %s

; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: merge_uniform_strided_soa_geps:simd.loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: [Shape: Uniform]] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: [Shape: SOA Unit Stride, Stride: i64 8]] [1024 x i64]* [[VP_ARR_SOA_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:     [DA: [Shape: SOA Unit Stride, Stride: i64 8]] i8* [[VP_ARR_SOA_PRIV64_BCAST:%.*]] = bitcast [1024 x i64]* [[VP_ARR_SOA_PRIV64]]
; CHECK-NEXT:     [DA: [Shape: Random]] call i64 8192 i8* [[VP_ARR_SOA_PRIV64_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8 [Serial]
; CHECK-NEXT:     [DA: [Shape: Unit Stride, Stride: i64 1]] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:     [DA: [Shape: Uniform]] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: [Shape: Uniform]] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: [Shape: Uniform]] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: [Shape: Unit Stride, Stride: i64 1]] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], [[BB1]] ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:     [DA: [Shape: SOA Unit Stride, Stride: i64 8]] i64* [[VP_UNI_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:     [DA: [Shape: Random]] i64 [[VP_LDSTD:%.*]] = load i64* [[VP_UNI_GEP]]
; CHECK-NEXT:     [DA: [Shape: Uniform]] br i1 true, [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: [Shape: SOA Unit Stride, Stride: i64 8]] i64* [[VP_UNI_ELSE:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 1
; CHECK-NEXT:       [DA: [Shape: SOA Unit Stride, Stride: i64 8]] i64* [[VP_UNI_ELSE_1:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 1
; CHECK-NEXT:       [DA: [Shape: Random]] i64 [[VP_CONST_STEP:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:       [DA: [Shape: SOA Converted]] i64* [[VP0:%.*]] = getelementptr i64* [[VP_UNI_ELSE_1]] i64 0 i64 [[VP_CONST_STEP]]
; CHECK-NEXT:       [DA: [Shape: Random]] i64 [[VP_LD_ELSE:%.*]] = load i64* [[VP_UNI_ELSE]]
; CHECK-NEXT:       [DA: [Shape: Uniform]] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: [Shape: Random]] i64 [[VP_CONST_STEP_1:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:       [DA: [Shape: SOA Converted]] i64* [[VP_STR_IF:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 [[VP_IV1]] i64 [[VP_CONST_STEP_1]]
; CHECK-NEXT:       [DA: [Shape: Uniform]] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB5]], [[BB4]]
; CHECK-NEXT:     [DA: [Shape: Random]] i64* [[VP_PHI_MIX_UNI:%.*]] = phi  [ i64* [[VP0]], [[BB5]] ],  [ i64* [[VP_STR_IF]], [[BB4]] ]
; CHECK-NEXT:     [DA: [Shape: Random]] i64 [[VP_LD:%.*]] = load i64* [[VP_PHI_MIX_UNI]]
; CHECK-NEXT:     [DA: [Shape: Random]] i64* [[VP_GEP_MIX_UNI:%.*]] = getelementptr inbounds i64* [[VP_PHI_MIX_UNI]] i64 [[VP_LD]]
; CHECK-NEXT:     [DA: [Shape: Random]] i64 [[VP_LD_PHI_DERIVED:%.*]] = load i64* [[VP_GEP_MIX_UNI]]
; CHECK-NEXT:     [DA: [Shape: Unit Stride, Stride: i64 1]] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:     [DA: [Shape: Uniform]] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: [Shape: Uniform]] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB2]], [[BB6:BB[0-9]+]]

define void @merge_uniform_strided_soa_geps() {
entry:
  %arr.soa.priv64 = alloca [1024 x i64], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i64]* %arr.soa.priv64)]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.check.phi]
  %uni.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  %ldstd = load i64, i64* %uni.gep, align 4
  br i1 true, label %bb1, label %bb2
bb1:
  %str.if = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
bb2:
  %uni.else = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 1
  %ld.else = load i64, i64* %uni.else, align 4
  br label %simd.check.phi
simd.check.phi:
  %phi.mix.uni = phi i64* [%uni.else, %bb2], [%str.if, %bb1]
  %ld = load i64, i64* %phi.mix.uni, align 4
  %gep.mix.uni = getelementptr inbounds i64, i64* %phi.mix.uni, i64 %ld
  %ld.phi.derived = load i64, i64* %gep.mix.uni, align 4
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end
simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token %0)
declare dso_local i64 @helper(i64*)
