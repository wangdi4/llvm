; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

; RUN: opt -opaque-pointers=0 -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>" -vplan-force-vf=4 -vplan-force-uf=3 -vplan-print-after-unroll -disable-output < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,VPVALCG


; void foo(int *a, int n) {
;   for (int i = 0; i < n; i++) {
;     a[i]++;
;   }
; }

define dso_local void @_Z3fooPii(i32* nocapture %a, i32 %n) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after VPlan loop unrolling:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {sext.i32.i64(%n) + -1}
; CHECK-DAG:     [[VP1:%.*]] = {%a}
; CHECK-NEXT:  External Defs End:

; CHECK:          [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 [[VP_UB_INC:%.*]], UF = 3
; CHECK-NEXT:     [DA: Div] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 {{.*}} i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1:BB[0-9]+]], cloned.[[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div] i64 [[VP2:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP3:%.*]], cloned.[[BB3]] ]
; CHECK-NEXT:     [DA: Div] i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i32* [[A0:%.*]] i64 [[VP2]]
; CHECK-NEXT:     [DA: Div] i32 [[VP_LOAD:%.*]] = load i32* [[VP_SUBSCRIPT]]
; CHECK-NEXT:     [DA: Div] i32 [[VP4:%.*]] = add i32 [[VP_LOAD]] i32 1
; CHECK-NEXT:     [DA: Div] i32* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i32* [[A0]] i64 [[VP2]]
; CHECK-NEXT:     [DA: Div] store i32 [[VP4]] i32* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:     [DA: Div] i64 [[VP5:%.*]] = add i64 [[VP2]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP6:%.*]] = icmp slt i64 [[VP5]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br cloned.[[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    cloned.[[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:     [DA: Div] i32* [[VP7:%.*]] = subscript inbounds i32* [[A0]] i64 [[VP5]]
; CHECK-NEXT:     [DA: Div] i32 [[VP8:%.*]] = load i32* [[VP7]]
; CHECK-NEXT:     [DA: Div] i32 [[VP9:%.*]] = add i32 [[VP8]] i32 1
; CHECK-NEXT:     [DA: Div] i32* [[VP10:%.*]] = subscript inbounds i32* [[A0]] i64 [[VP5]]
; CHECK-NEXT:     [DA: Div] store i32 [[VP9]] i32* [[VP10]]
; CHECK-NEXT:     [DA: Div] i64 [[VP11:%.*]] = add i64 [[VP5]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP12:%.*]] = icmp slt i64 [[VP11]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br cloned.[[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    cloned.[[BB3]]: # preds: cloned.[[BB4]]
; CHECK-NEXT:     [DA: Div] i32* [[VP13:%.*]] = subscript inbounds i32* [[A0]] i64 [[VP11]]
; CHECK-NEXT:     [DA: Div] i32 [[VP14:%.*]] = load i32* [[VP13]]
; CHECK-NEXT:     [DA: Div] i32 [[VP15:%.*]] = add i32 [[VP14]] i32 1
; CHECK-NEXT:     [DA: Div] i32* [[VP16:%.*]] = subscript inbounds i32* [[A0]] i64 [[VP11]]
; CHECK-NEXT:     [DA: Div] store i32 [[VP15]] i32* [[VP16]]
; CHECK-NEXT:     [DA: Div] i64 [[VP3]] = add i64 [[VP11]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP17:%.*]] = icmp slt i64 [[VP3]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP17]], [[BB2]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: cloned.[[BB3]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB6:BB[0-9]+]]

; CHECK:          [DA: Uni] br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP__IND_FINAL]]
; CHECK-EMPTY:

; VPVALCG:       Function: _Z3fooPii
; VPVALCG-EMPTY:
; VPVALCG-NEXT:            BEGIN REGION { modified }
; VPVALCG:                         + DO i1 = 0, {{.*}}, 12 <DO_LOOP>
; VPVALCG-NEXT:                    |   [[DOTVEC0:%.*]] = (<4 x i32>*)([[A0:%.*]])[i1]
; VPVALCG-NEXT:                    |   (<4 x i32>*)([[A0]])[i1] = [[DOTVEC0]] + 1
; VPVALCG-NEXT:                    |   [[DOTVEC20:%.*]] = (<4 x i32>*)([[A0]])[i1 + 4]
; VPVALCG-NEXT:                    |   (<4 x i32>*)([[A0]])[i1 + 4] = [[DOTVEC20]] + 1
; VPVALCG-NEXT:                    |   [[DOTVEC30:%.*]] = (<4 x i32>*)([[A0]])[i1 + 8]
; VPVALCG-NEXT:                    |   (<4 x i32>*)([[A0]])[i1 + 8] = [[DOTVEC30]] + 1
; VPVALCG-NEXT:                    + END LOOP

; VPVALCG:                      + DO i1 = {{.*}}, sext.i32.i64([[N0:%.*]]) + -1, 1
; VPVALCG-NEXT:                 |   [[TMP1:%.*]] = ([[A0]])[i1]
; VPVALCG-NEXT:                 |   ([[A0]])[i1] = [[TMP1]] + 1
; VPVALCG-NEXT:                 + END LOOP
; VPVALCG:                 END REGION
;


entry:
  %cmp = icmp sgt i32 %n, 0
  br i1 %cmp, label %DIR.OMP.SIMD.2, label %omp.precond.end

DIR.OMP.SIMD.2:                                   ; preds = %entry
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null) ]
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.2
  %wide.trip.count = sext i32 %n to i64
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %a, i64 %indvars.iv
  %1 = load i32, i32* %arrayidx, align 4
  %inc = add nsw i32 %1, 1
  store i32 %inc, i32* %arrayidx, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %wide.trip.count
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %omp.inner.for.body

DIR.OMP.END.SIMD.3:                               ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %DIR.OMP.END.SIMD.3, %entry
  ret void
}

declare token @llvm.directive.region.entry() nounwind
declare void @llvm.directive.region.exit(token) nounwind
