; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec,print<hir>" -disable-output -vplan-force-vf=4 < %s 2>&1 | FileCheck %s
;
; LIT test to demonstrate vectorization of triple nested loop in HIR path
; Incoming HIR:
;
;         + DO i1 = 0, 99, 1   <DO_LOOP> <simd>
;         |   + DO i2 = 0, 99, 1   <DO_LOOP>
;         |   |   + DO i3 = 0, 99, 1   <DO_LOOP>
;         |   |   |   (@larr)[0][i1][i2][i3] = i1 + i2 + i3;
;         |   |   + END LOOP
;         |   + END LOOP
;         + END LOOP

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@larr = dso_local local_unnamed_addr global [100 x [100 x [100 x i64]]] zeroinitializer, align 16

; Function Attrs: nofree norecurse nosync nounwind uwtable writeonly
define dso_local void @foo(i64** nocapture readnone %lpp) local_unnamed_addr #0 {
; CHECK:       + DO i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK-NEXT:  |   %phi.temp = 0;
; CHECK-NEXT:  |
; CHECK-NEXT:  |   + DO i2 = 0, 99, 1   <DO_LOOP>
; CHECK-NEXT:  |   |   %phi.temp4 = 0;
; CHECK-NEXT:  |   |
; CHECK-NEXT:  |   |   + DO i3 = 0, 99, 1   <DO_LOOP>
; CHECK-NEXT:  |   |   |   (<4 x i64>*)(@larr)[0][i1 + <i64 0, i64 1, i64 2, i64 3>][i2][i3] = i1 + i2 + i3 + <i64 0, i64 1, i64 2, i64 3>;
; CHECK-NEXT:  |   |   |   %.vec = i3 + 1 < 100;
; CHECK-NEXT:  |   |   |   %phi.temp4 = i3 + 1;
; CHECK-NEXT:  |   |   + END LOOP
; CHECK-NEXT:  |   |
; CHECK-NEXT:  |   |   %.vec7 = i2 + 1 < 100;
; CHECK-NEXT:  |   |   %phi.temp = i2 + 1;
; CHECK-NEXT:  |   + END LOOP
; CHECK-NEXT:  + END LOOP
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.cond1.preheader

for.cond1.preheader:                              ; preds = %entry, %for.inc13
  %l1.030 = phi i64 [ 0, %entry ], [ %inc14, %for.inc13 ]
  br label %for.cond4.preheader

for.cond4.preheader:                              ; preds = %for.cond1.preheader, %for.inc10
  %l2.029 = phi i64 [ 0, %for.cond1.preheader ], [ %inc11, %for.inc10 ]
  %add = add nuw nsw i64 %l2.029, %l1.030
  br label %for.body6

for.body6:                                        ; preds = %for.cond4.preheader, %for.body6
  %l3.028 = phi i64 [ 0, %for.cond4.preheader ], [ %inc, %for.body6 ]
  %add7 = add nuw nsw i64 %add, %l3.028
  %arrayidx9 = getelementptr inbounds [100 x [100 x [100 x i64]]], [100 x [100 x [100 x i64]]]* @larr, i64 0, i64 %l1.030, i64 %l2.029, i64 %l3.028
  store i64 %add7, i64* %arrayidx9, align 8
  %inc = add nuw nsw i64 %l3.028, 1
  %exitcond.not = icmp eq i64 %inc, 100
  br i1 %exitcond.not, label %for.inc10, label %for.body6

for.inc10:                                        ; preds = %for.body6
  %inc11 = add nuw nsw i64 %l2.029, 1
  %exitcond31.not = icmp eq i64 %inc11, 100
  br i1 %exitcond31.not, label %for.inc13, label %for.cond4.preheader

for.inc13:                                        ; preds = %for.inc10
  %inc14 = add nuw nsw i64 %l1.030, 1
  %exitcond32.not = icmp eq i64 %inc14, 100
  br i1 %exitcond32.not, label %for.end15, label %for.cond1.preheader

for.end15:                                        ; preds = %for.inc13
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
