; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vplan-vec -vplan-vec-scenario="n0;v4;m2" -vplan-force-inscan-reduction-vectorization=true -S < %s 2>&1 | FileCheck %s
; RUN: opt -passes="vplan-vec" -vplan-vec-scenario="n0;v4;m2" -vplan-force-inscan-reduction-vectorization=true -S < %s 2>&1 | FileCheck %s

;; Check that store intitalizing the inscan reduction is unmasked for
;; masked mode loop.

;; void foo(float *A, float *B) {
;;   float x = 0.0f;
;; #pragma omp simd reduction(inscan, + : x)
;;   for (int i=0; i<1024; i++) {
;;     x += A[i];
;; #pragma omp scan inclusive(x)
;;     B[i] = x;
;;   }
;; }

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @omp_scan(float* %A, float* %B) {
; CHECK-LABEL:  Single loop scenario:
; CHECK-NEXT:   MainLoop: unmasked, VF=4
; CHECK-NEXT:   PeelLoop: none
; CHECK-NEXT:   Remainders: masked, VF=2,
;
; CHECK:        entry:
; CHECK-NEXT:    [[X_RED0:%.*]] = alloca float, align 4
; CHECK-NEXT:    [[X_RED_VEC0:%.*]] = alloca <4 x float>, align 16
; CHECK:         [[DOTVEC0:%.*]] = alloca <2 x float>, align 8
; CHECK:         br label [[DIR_OMP_SIMD_10:%.*]]
; CHECK-EMPTY:
; CHECK:        VPlannedBB20:
; CHECK-NEXT:    [[UNI_PHI210:%.*]] = phi i64 [ [[UNI_PHI170:%.*]], [[VPLANNEDBB190:%.*]] ], [ [[TMP32:%.*]], [[NEW_LATCH0:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI220:%.*]] = phi <2 x i64> [ [[TMP21:%.*]], [[VPLANNEDBB190]] ], [ [[TMP31:%.*]], [[NEW_LATCH0]] ]
; CHECK-NEXT:    [[VEC_PHI230:%.*]] = phi <2 x float> [ [[RED_INIT_INSERT0:%.*]], [[VPLANNEDBB190]] ], [ [[PREDBLEND0:%.*]], [[NEW_LATCH0]] ]
; CHECK-NEXT:    store <2 x float> zeroinitializer, <2 x float>* [[DOTVEC0]], align 1
; CHECK-NEXT:    [[TMP22:%.*]] = icmp ult i64 [[UNI_PHI210]], 1024
; CHECK-NEXT:    [[TMP23:%.*]] = icmp ult <2 x i64> [[VEC_PHI220]], <i64 1024, i64 1024>
; CHECK-NEXT:    br label [[VPLANNEDBB240:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB24:
; CHECK-NEXT:    [[TMP24:%.*]] = trunc <2 x i64> [[VEC_PHI220]] to <2 x i32>
; CHECK-NEXT:    [[SCALAR_GEP250:%.*]] = getelementptr inbounds float, float* [[A0:%.*]], i64 [[UNI_PHI210]]
; CHECK-NEXT:    [[TMP25:%.*]] = bitcast float* [[SCALAR_GEP250]] to <2 x float>*
; CHECK-NEXT:    [[WIDE_MASKED_LOAD0:%.*]] = call <2 x float> @llvm.masked.load.v2f32.p0v2f32(<2 x float>* [[TMP25]], i32 4, <2 x i1> [[TMP23]], <2 x float> undef)
; CHECK-NEXT:    [[WIDE_LOAD260:%.*]] = load <2 x float>, <2 x float>* [[DOTVEC0]], align 4
; CHECK-NEXT:    [[TMP26:%.*]] = fadd fast <2 x float> [[WIDE_LOAD260]], [[WIDE_MASKED_LOAD0]]
; CHECK-NEXT:    call void @llvm.masked.store.v2f32.p0v2f32(<2 x float> [[TMP26]], <2 x float>* [[DOTVEC0]], i32 4, <2 x i1> [[TMP23]])
; CHECK-NEXT:    br label [[VPLANNEDBB270:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB27:
; CHECK-NEXT:    br label [[VPLANNEDBB280:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB28:
; CHECK-NEXT:    [[WIDE_LOAD290:%.*]] = load <2 x float>, <2 x float>* [[DOTVEC0]], align 1
; CHECK-NEXT:    [[TMP27:%.*]] = shufflevector <2 x float> [[WIDE_LOAD290]], <2 x float> zeroinitializer, <2 x i32> <i32 2, i32 0>
; CHECK-NEXT:    [[TMP28:%.*]] = fadd fast <2 x float> [[WIDE_LOAD290]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = fadd fast <2 x float> [[TMP28]], [[VEC_PHI230]]
; CHECK-NEXT:    [[DOTEXTRACT_1_0:%.*]] = extractelement <2 x float> [[TMP29]], i32 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT340:%.*]] = insertelement <2 x float> poison, float [[DOTEXTRACT_1_0]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT350:%.*]] = shufflevector <2 x float> [[BROADCAST_SPLATINSERT340]], <2 x float> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    call void @llvm.masked.store.v2f32.p0v2f32(<2 x float> [[TMP29]], <2 x float>* [[DOTVEC0]], i32 1, <2 x i1> [[TMP23]])
; CHECK-NEXT:    br label [[VPLANNEDBB300:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB30:
; CHECK-NEXT:    br label [[VPLANNEDBB310:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB31:
; CHECK-NEXT:    [[WIDE_LOAD320:%.*]] = load <2 x float>, <2 x float>* [[DOTVEC0]], align 4
; CHECK-NEXT:    [[SCALAR_GEP330:%.*]] = getelementptr inbounds float, float* [[B0:%.*]], i64 [[UNI_PHI210]]
; CHECK-NEXT:    [[TMP30:%.*]] = bitcast float* [[SCALAR_GEP330]] to <2 x float>*
; CHECK-NEXT:    call void @llvm.masked.store.v2f32.p0v2f32(<2 x float> [[WIDE_LOAD320]], <2 x float>* [[TMP30]], i32 4, <2 x i1> [[TMP23]])
; CHECK-NEXT:    br label [[NEW_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  new_latch:
; CHECK-NEXT:    [[PREDBLEND0]] = select <2 x i1> [[TMP23]], <2 x float> [[BROADCAST_SPLAT350]], <2 x float> [[VEC_PHI230]]
; CHECK-NEXT:    [[TMP31]] = add nuw nsw <2 x i64> [[VEC_PHI220]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP32]] = add nuw nsw i64 [[UNI_PHI210]], 2
; CHECK-NEXT:    [[TMP33:%.*]] = icmp ult <2 x i64> [[TMP31]], <i64 1024, i64 1024>
; CHECK-NEXT:    [[TMP34:%.*]] = bitcast <2 x i1> [[TMP33]] to i2
; CHECK-NEXT:    [[TMP35:%.*]] = icmp eq i2 [[TMP34]], 0
; CHECK-NEXT:    br i1 [[TMP35]], label [[VPLANNEDBB360:%.*]], label [[VPLANNEDBB200:%.*]]
;
entry:
  %x.red = alloca float, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  store float 0.000000e+00, float* %x.red, align 4
  br label %DIR.OMP.SIMD.138

DIR.OMP.SIMD.138:                                 ; preds = %DIR.OMP.SIMD.1
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD:INSCAN"(float* %x.red, i64 1) ]
  br label %DIR.OMP.SIMD.139

DIR.OMP.SIMD.139:                                 ; preds = %DIR.OMP.SIMD.138
  br label %DIR.OMP.END.SCAN.335

DIR.OMP.END.SCAN.335:                             ; preds = %DIR.OMP.END.SCAN.3, %DIR.OMP.SIMD.139
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.139 ], [ %indvars.iv.next, %DIR.OMP.END.SCAN.3 ]
  %1 = trunc i64 %indvars.iv to i32
  %arrayidx = getelementptr inbounds float, float* %A, i64 %indvars.iv
  %2 = load float, float* %arrayidx, align 4
  %3 = load float, float* %x.red, align 4
  %add5 = fadd fast float %3, %2
  store float %add5, float* %x.red, align 4
  br label %DIR.OMP.SCAN.3

DIR.OMP.SCAN.3:                                   ; preds = %DIR.OMP.END.SCAN.335
  %4 = call token @llvm.directive.region.entry() [ "DIR.OMP.SCAN"(), "QUAL.OMP.INCLUSIVE"(float* %x.red, i64 1) ]
  br label %DIR.OMP.SCAN.2

DIR.OMP.SCAN.2:                                   ; preds = %DIR.OMP.SCAN.3
  fence acq_rel
  br label %DIR.OMP.END.SCAN.5

DIR.OMP.END.SCAN.5:                               ; preds = %DIR.OMP.SCAN.2
  call void @llvm.directive.region.exit(token %4) [ "DIR.OMP.END.SCAN"() ]
  br label %DIR.OMP.END.SCAN.3

DIR.OMP.END.SCAN.3:                               ; preds = %DIR.OMP.END.SCAN.5
  %5 = load float, float* %x.red, align 4
  %arrayidx7 = getelementptr inbounds float, float* %B, i64 %indvars.iv
  store float %5, float* %arrayidx7, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.1, label %DIR.OMP.END.SCAN.335, !llvm.loop !0

DIR.OMP.END.SIMD.1:                               ; preds = %DIR.OMP.END.SIMD.7
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %DIR.OMP.END.SIMD.4, %entry
  ret void
}

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)

!0 = distinct !{!0, !1, !2}
!1 = !{!"llvm.loop.vectorize.enable", i1 true}
!2 = !{!"llvm.loop.vectorize.ivdep_loop", i32 0}
