; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -vplan-vec-scenario="n0;v4;m2" \
; RUN: -disable-output -vplan-vec \
; RUN: -print-after=vplan-vec \
; RUN: -vplan-enable-peeling %s 2>&1 | FileCheck %s

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024"
target triple = "x86_64-unknown-linux-gnu"

define void @test_store(i64* nocapture %ary, i32 %c) {
;
; CHECK-LABEL: @test_store(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br i1 false, label [[MERGE_BLK15:%.*]], label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i32> poison, i32 [[C:%.*]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB2:%.*]]
; CHECK:       VPlannedBB2:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB2]] ], [ [[TMP4:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB2]] ], [ [[TMP3:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i64, i64* [[ARY:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[TMP0:%.*]] = sext <4 x i32> [[BROADCAST_SPLAT]] to <4 x i64>
; CHECK-NEXT:    [[TMP1:%.*]] = add <4 x i64> [[TMP0]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i64* [[SCALAR_GEP]] to <4 x i64>*
; CHECK-NEXT:    store <4 x i64> [[TMP1]], <4 x i64>* [[TMP2]], align 8, !intel.preferred_alignment !0
; CHECK-NEXT:    [[TMP3]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP4]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    [[TMP5:%.*]] = icmp ult i64 [[TMP4]], 1024
; CHECK-NEXT:    br i1 [[TMP5]], label [[VECTOR_BODY]], label [[VPLANNEDBB4:%.*]], !llvm.loop [[LOOP1:![0-9]+]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    br label [[VPLANNEDBB5:%.*]]
; CHECK:       VPlannedBB5:
; CHECK-NEXT:    br label [[VPLANNEDBB6:%.*]]
; CHECK:       VPlannedBB6:
; CHECK-NEXT:    br i1 true, label [[FINAL_MERGE:%.*]], label [[MERGE_BLK15]]
; CHECK:       merge.blk15:
; CHECK-NEXT:    [[UNI_PHI7:%.*]] = phi i64 [ 1024, [[VPLANNEDBB6]] ], [ 0, [[VPLANNEDBB]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB8:%.*]]
; CHECK:       VPlannedBB8:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT15:%.*]] = insertelement <2 x i32> poison, i32 [[C]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT16:%.*]] = shufflevector <2 x i32> [[BROADCAST_SPLATINSERT15]], <2 x i32> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB9:%.*]]
; CHECK:       VPlannedBB9:
; CHECK-NEXT:    [[UNI_PHI7IND_START_BCAST_SPLATINSERT:%.*]] = insertelement <2 x i64> poison, i64 [[UNI_PHI7]], i32 0
; CHECK-NEXT:    [[UNI_PHI7IND_START_BCAST_SPLAT:%.*]] = shufflevector <2 x i64> [[UNI_PHI7IND_START_BCAST_SPLATINSERT]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP6:%.*]] = add <2 x i64> [[UNI_PHI7IND_START_BCAST_SPLAT]], <i64 0, i64 1>
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK:       VPlannedBB10:
; CHECK-NEXT:    [[UNI_PHI11:%.*]] = phi i64 [ [[UNI_PHI7]], [[VPLANNEDBB9]] ], [ [[TMP12:%.*]], [[NEW_LATCH:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI12:%.*]] = phi <2 x i64> [ [[TMP6]], [[VPLANNEDBB9]] ], [ [[TMP11:%.*]], [[NEW_LATCH]] ]
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ult <2 x i64> [[VEC_PHI12]], <i64 1024, i64 1024>
; CHECK-NEXT:    br label [[VPLANNEDBB13:%.*]]
; CHECK:       VPlannedBB13:
; CHECK-NEXT:    [[SCALAR_GEP14:%.*]] = getelementptr inbounds i64, i64* [[ARY]], i64 [[UNI_PHI11]]
; CHECK-NEXT:    [[TMP8:%.*]] = sext <2 x i32> [[BROADCAST_SPLAT16]] to <2 x i64>
; CHECK-NEXT:    [[TMP9:%.*]] = add <2 x i64> [[TMP8]], [[VEC_PHI12]]
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i64* [[SCALAR_GEP14]] to <2 x i64>*
; CHECK-NEXT:    call void @llvm.masked.store.v2i64.p0v2i64(<2 x i64> [[TMP9]], <2 x i64>* [[TMP10]], i32 8, <2 x i1> [[TMP7]])
; CHECK-NEXT:    br label [[NEW_LATCH]]
; CHECK:       new_latch:
; CHECK-NEXT:    [[TMP11]] = add nuw nsw <2 x i64> [[VEC_PHI12]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP12]] = add nuw nsw i64 [[UNI_PHI11]], 2
; CHECK-NEXT:    [[TMP13:%.*]] = icmp ult <2 x i64> [[TMP11]], <i64 1024, i64 1024>
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <2 x i1> [[TMP13]] to i2
; CHECK-NEXT:    [[TMP15:%.*]] = icmp eq i2 [[TMP14]], 0
; CHECK-NEXT:    br i1 [[TMP15]], label [[VPLANNEDBB17:%.*]], label [[VPLANNEDBB10]]
; CHECK:       VPlannedBB17:
; CHECK-NEXT:    br label [[VPLANNEDBB18:%.*]]
; CHECK:       VPlannedBB18:
; CHECK-NEXT:    br label [[FINAL_MERGE]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI19:%.*]] = phi i64 [ 1024, [[VPLANNEDBB18]] ], [ 1024, [[VPLANNEDBB6]] ]
; CHECK-NEXT:    br label [[FOR_END:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY:%.*]] ]
; CHECK-NEXT:    [[PTR:%.*]] = getelementptr inbounds i64, i64* [[ARY]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[CC:%.*]] = sext i32 [[C]] to i64
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[CC]], [[INDVARS_IV]]
; CHECK-NEXT:    store i64 [[ADD]], i64* [[PTR]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i64 [[INDVARS_IV_NEXT]], 1024
; CHECK-NEXT:    br label [[FOR_BODY]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %ptr = getelementptr inbounds i64, i64* %ary, i64 %indvars.iv
  %cc = sext i32 %c to i64
  %add = add i64 %cc, %indvars.iv
  store i64 %add, i64* %ptr, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp ult i64 %indvars.iv.next, 1024
  br i1 %cmp, label %for.body, label %for.end

for.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
