; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: asserts
; RUN: opt -S < %s -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -disable-output -vplan-dump-external-defs-hir=false -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind uwtable
define dso_local void @uniformDivergent(i32* nocapture %a, i32* nocapture %b, i64* nocapture %c) local_unnamed_addr {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP0:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP1:%.*]], [[BB2]] ] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i32 [[VP2:%.*]] = load i32* [[A0:%.*]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i32 [[VP3:%.*]] = load i32* [[B0:%.*]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i64* [[C0:%.*]] i64 [[VP0]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP4:%.*]] = load i64* [[VP_SUBSCRIPT]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i32 [[VP5:%.*]] = add i32 [[VP3]] i32 [[VP2]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP6:%.*]] = sext i32 [[VP5]] to i64 (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP7:%.*]] = mul i64 [[VP4]] i64 [[VP6]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64* [[C0]] i64 [[VP0]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i64 [[VP7]] i64* [[VP_SUBSCRIPT_1]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP1]] = add i64 [[VP0]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP8:%.*]] = icmp i64 [[VP1]] i64 1023 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP8]]), [[BB3:BB[0-9]+]](!i1 [[VP8]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
;
entry:
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %omp.inner.for.body ]

  ; Uniform instruction sequence later used in vector context.
  %a.load = load i32, i32* %a, align 4
  %b.load = load i32, i32* %b, align 4
  %uniform.add = add i32 %a.load, %b.load
  %add.sext = sext i32 %uniform.add to i64
  %c.gep = getelementptr inbounds i64, i64* %c, i64 %indvars.iv
  %c.load = load i64, i64* %c.gep, align 4
  %divergent.mul = mul i64 %add.sext, %c.load
  store i64 %divergent.mul, i64* %c.gep, align 4

  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %omp.inner.for.body

DIR.OMP.END.SIMD.3:                               ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define dso_local void @gatherScatter(i32* nocapture %a, i32* nocapture %b) local_unnamed_addr {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=2
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP0:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP1:%.*]], [[BB2]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP2:%.*]] = mul i64 2 i64 [[VP0]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i32* [[A0:%.*]] i64 [[VP2]] (SVAOpBits 0->V 1->V 2->V 3->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP3:%.*]] = load i32* [[VP_SUBSCRIPT]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP4:%.*]] = add i32 [[VP3]] i32 42 (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP5:%.*]] = mul i64 2 i64 [[VP0]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i32* [[B0:%.*]] i64 [[VP5]] (SVAOpBits 0->V 1->V 2->V 3->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP4]] i32* [[VP_SUBSCRIPT_1]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP1]] = add i64 [[VP0]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP6:%.*]] = icmp i64 [[VP1]] i64 1023 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP6]]), [[BB3:BB[0-9]+]](!i1 [[VP6]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
;
entry:
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %omp.inner.for.body ]
  %iv.x.2 = mul i64 %indvars.iv, 2
  %a.gep = getelementptr inbounds i32, i32* %a, i64 %iv.x.2
  %a.load = load i32, i32* %a.gep, align 4
  %add = add i32 %a.load, 42
  %b.gep = getelementptr inbounds i32, i32* %b, i64 %iv.x.2
  store i32 %add, i32* %b.gep
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %omp.inner.for.body

DIR.OMP.END.SIMD.3:                               ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define dso_local i32 @simpleReduction(i32* nocapture %a, i32 %b) local_unnamed_addr {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP__RED_INIT:%.*]] = reduction-init i32 0 i32 [[REDUCTION_PHI0:%.*]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP0:%.*]] = phi  [ i32 [[VP__RED_INIT]], [[BB1]] ],  [ i32 [[VP1:%.*]], [[BB2]] ] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP2:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB2]] ] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i32 [[VP4:%.*]] = load i32* [[A0:%.*]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP1]] = add i32 [[VP0]] i32 [[VP4]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP3]] = add i64 [[VP2]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP5:%.*]] = icmp i64 [[VP3]] i64 1023 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP5]]), [[BB3:BB[0-9]+]](!i1 [[VP5]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] i32 [[VP__RED_FINAL:%.*]] = reduction-final{u_add} i32 [[VP1]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
;
entry:
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %omp.inner.for.body ]
  %reduction.phi = phi i32 [ %b, %DIR.OMP.SIMD.1], [ %reduction.add, %omp.inner.for.body ]
  %uniform.a = load i32, i32* %a, align 4
  %reduction.add = add i32 %reduction.phi, %uniform.a
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %omp.inner.for.body

DIR.OMP.END.SIMD.3:                               ; preds = %omp.inner.for.body
  %lcssa.red.phi = phi i32 [ %reduction.add, %omp.inner.for.body ]
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret i32 %lcssa.red.phi
}

define dso_local void @phiUsedByPhi(i64* nocapture %a, i64* nocapture %b) local_unnamed_addr {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=2
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP0:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP1:%.*]], [[BB3:BB[0-9]+]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP2:%.*]] = hir-copy i64 [[VP0]] , OriginPhiId: -1 (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP3:%.*]] = icmp i64 [[VP0]] i64 42 (SVAOpBits 0->V 1->V )
; CHECK-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP4:%.*]] = block-predicate i1 [[VP3]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i64* [[A0:%.*]] i64 [[VP0]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP5:%.*]] = load i64* [[VP_SUBSCRIPT]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP6:%.*]] = hir-copy i64 [[VP5]] , OriginPhiId: -1 (SVAOpBits 0->V )
; CHECK-NEXT:    SUCCESSORS(1):[[BB3]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP__BLEND_BB4:%.*]] = blend [ i64 [[VP2]], i1 true ], [ i64 [[VP6]], i1 [[VP3]] ] (SVAOpBits 0->V 1->V 2->V 3->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64* [[B0:%.*]] i64 [[VP0]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i64 [[VP__BLEND_BB4]] i64* [[VP_SUBSCRIPT_1]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP1]] = add i64 [[VP0]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP7:%.*]] = icmp i64 [[VP1]] i64 1023 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP7]]), [[BB5:BB[0-9]+]](!i1 [[VP7]])
; CHECK-NEXT:    PREDECESSORS(1): [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:    SUCCESSORS(1):[[BB6:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB5]]
;
entry:
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %if.end, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %indvars.iv.next, %if.end ]
  %cmp = icmp eq i64 %indvars.iv, 42
  br i1 %cmp, label %if.then, label %if.end

if.then:                                          ; preds = %omp.inner.for.body
  %a.gep = getelementptr inbounds i64, i64* %a, i64 %indvars.iv
  %a.load = load i64, i64* %a.gep, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %omp.inner.for.body
  %use.phi = phi i64 [ %a.load, %if.then], [ %indvars.iv, %omp.inner.for.body ]
  %b.gep = getelementptr inbounds i64, i64* %b, i64 %indvars.iv
  store i64 %use.phi, i64* %b.gep
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %DIR.OMP.END.SIMD.3, label %omp.inner.for.body

DIR.OMP.END.SIMD.3:                               ; preds = %if.end
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)

