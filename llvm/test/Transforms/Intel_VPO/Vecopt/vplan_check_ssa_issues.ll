; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
;
; Check that loop exits massaging doesn't break SSA form.
;
; RUN: opt < %s -vplan-func-vec -disable-output -print-after-vplan-func-vec-loop-exit-canon | FileCheck %s
; RUN: opt < %s -passes="vplan-func-vec" -disable-output -print-after-vplan-func-vec-loop-exit-canon | FileCheck %s
;
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

define dso_local void @header_use(i64 %N, i64 *%a, i64 %mask_out_loop) local_unnamed_addr {
; CHECK-LABEL:  VPlan IR for: header_use
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_NEXT_SSA_PHI:%.*]], [[NEW_LOOP_LATCH0:new.loop.latch[0-9]+]] ],  [ i64 0, [[BB0]] ]
; CHECK-NEXT:     i64 [[VP_HEADER_PHI_USE:%.*]] = phi  [ i64 0, [[BB0]] ],  [ i64 [[VP_DEF_SSA_PHI:%.*]], [[NEW_LOOP_LATCH0]] ]
; CHECK-NEXT:     i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:     i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i1 [[VP_CMP:%.*]] = icmp i64 [[N0:%.*]] i64 42
; CHECK-NEXT:    SUCCESSORS(2):[[BB2:BB[0-9]+]](i1 [[VP_CMP]]), [[BB3:BB[0-9]+]](!i1 [[VP_CMP]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]:
; CHECK-NEXT:       i1 [[VP_SIDEEXIT_CMP:%.*]] = icmp i64 [[N0]] i64 13
; CHECK-NEXT:      SUCCESSORS(2):[[INTERMEDIATE_BB0:intermediate.bb[0-9]+]](i1 [[VP_SIDEEXIT_CMP]]), [[BB4]](!i1 [[VP_SIDEEXIT_CMP]])
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       i64 [[VP_DEF:%.*]] = add i64 [[N0]] i64 1
; CHECK-NEXT:       i64 [[VP_IV_NEXT:%.*]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:       i1 [[VP_EXITCOND:%.*]] = icmp i64 [[VP_IV_NEXT]] i64 42
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(2): [[BB3]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[INTERMEDIATE_BB0]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[NEW_LOOP_LATCH0]]:
; CHECK-NEXT:     i64 [[VP_IV_NEXT_SSA_PHI]] = phi  [ i64 [[VP_IV_NEXT]], [[BB4]] ],  [ i64 undef, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i64 [[VP_DEF_SSA_PHI]] = phi  [ i64 [[VP_DEF]], [[BB4]] ],  [ i64 undef, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i32 [[VP_EXIT_ID_PHI:%.*]] = phi  [ i32 0, [[BB4]] ],  [ i32 1, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i1 [[VP_TAKE_BACKEDGE_COND:%.*]] = phi  [ i1 [[VP_EXITCOND]], [[BB4]] ],  [ i1 true, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[CASCADED_IF_BLOCK0:cascaded.if.block[0-9]+]](i1 [[VP_TAKE_BACKEDGE_COND]]), [[BB1]](!i1 [[VP_TAKE_BACKEDGE_COND]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[INTERMEDIATE_BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[CASCADED_IF_BLOCK0]]:
; CHECK-NEXT:     i1 [[VP0:%.*]] = icmp i32 [[VP_EXIT_ID_PHI]] i32 1
; CHECK-NEXT:    SUCCESSORS(2):[[BB5:BB[0-9]+]](i1 [[VP0]]), [[BB6:BB[0-9]+]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(1): [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(2): [[BB6]] [[BB5]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %header.phi.use = phi i64 [ 0, %entry ], [ %def, %latch ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %cmp = icmp eq i64 %N, 42
  br i1 %cmp, label %bb1, label %bb2

bb1:
  %sideexit.cmp = icmp eq i64 %N, 13
  br i1 %sideexit.cmp, label %sideexit, label %latch

bb2:
  br label %latch

latch:
  %def = add nsw i64 %N, 1
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, 42
  br i1 %exitcond, label %loopexit, label %header

sideexit:
  br label %exit

loopexit:
  br label %exit

exit:
  ret void
}

define dso_local void @side_exit_use(i64 %N, i64 *%a, i64 %mask_out_loop) local_unnamed_addr {
; CHECK-LABEL:  VPlan IR for: side_exit_use
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_NEXT_SSA_PHI:%.*]], [[NEW_LOOP_LATCH0:new.loop.latch[0-9]+]] ],  [ i64 0, [[BB0]] ]
; CHECK-NEXT:     i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:     i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i1 [[VP_CMP:%.*]] = icmp i64 [[N0:%.*]] i64 42
; CHECK-NEXT:    SUCCESSORS(2):[[BB2:BB[0-9]+]](i1 [[VP_CMP]]), [[BB3:BB[0-9]+]](!i1 [[VP_CMP]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]:
; CHECK-NEXT:       i64 [[VP_DEF:%.*]] = add i64 [[N0]] i64 1
; CHECK-NEXT:       i1 [[VP_SIDEEXIT_CMP:%.*]] = icmp i64 [[N0]] i64 13
; CHECK-NEXT:      SUCCESSORS(2):[[INTERMEDIATE_BB0:intermediate.bb[0-9]+]](i1 [[VP_SIDEEXIT_CMP]]), [[BB4]](!i1 [[VP_SIDEEXIT_CMP]])
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       i64 [[VP_IV_NEXT:%.*]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:       i1 [[VP_EXITCOND:%.*]] = icmp i64 [[VP_IV_NEXT]] i64 42
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(2): [[BB3]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[INTERMEDIATE_BB0]]:
; CHECK-NEXT:       i64 [[VP_EXIT_USE:%.*]] = phi  [ i64 [[VP_DEF]], [[BB2]] ]
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[NEW_LOOP_LATCH0]]:
; CHECK-NEXT:     i64 [[VP_IV_NEXT_SSA_PHI]] = phi  [ i64 [[VP_IV_NEXT]], [[BB4]] ],  [ i64 undef, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i32 [[VP_EXIT_ID_PHI:%.*]] = phi  [ i32 0, [[BB4]] ],  [ i32 1, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i1 [[VP_TAKE_BACKEDGE_COND:%.*]] = phi  [ i1 [[VP_EXITCOND]], [[BB4]] ],  [ i1 true, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[CASCADED_IF_BLOCK0:cascaded.if.block[0-9]+]](i1 [[VP_TAKE_BACKEDGE_COND]]), [[BB1]](!i1 [[VP_TAKE_BACKEDGE_COND]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[INTERMEDIATE_BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[CASCADED_IF_BLOCK0]]:
; CHECK-NEXT:     i1 [[VP0:%.*]] = icmp i32 [[VP_EXIT_ID_PHI]] i32 1
; CHECK-NEXT:    SUCCESSORS(2):[[BB5:BB[0-9]+]](i1 [[VP0]]), [[BB6:BB[0-9]+]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(1): [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(2): [[BB6]] [[BB5]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %cmp = icmp eq i64 %N, 42
  br i1 %cmp, label %bb1, label %bb2

bb1:
  %def = add nsw i64 %N, 1
  %sideexit.cmp = icmp eq i64 %N, 13
  br i1 %sideexit.cmp, label %sideexit, label %latch

bb2:
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, 42
  br i1 %exitcond, label %loopexit, label %header

sideexit:
  %exit.use = phi i64 [ %def, %bb1 ]
  br label %exit

loopexit:
  br label %exit

exit:
  ret void
}

define dso_local void @exit_use(i64 %N, i64 *%a, i64 %mask_out_loop) local_unnamed_addr {
; CHECK-LABEL:  VPlan IR for: exit_use
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_NEXT_SSA_PHI:%.*]], [[NEW_LOOP_LATCH0:new.loop.latch[0-9]+]] ],  [ i64 0, [[BB0]] ]
; CHECK-NEXT:     i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:     i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i1 [[VP_CMP:%.*]] = icmp i64 [[N0:%.*]] i64 42
; CHECK-NEXT:    SUCCESSORS(2):[[BB2:BB[0-9]+]](i1 [[VP_CMP]]), [[BB3:BB[0-9]+]](!i1 [[VP_CMP]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]:
; CHECK-NEXT:       i1 [[VP_SIDEEXIT_CMP:%.*]] = icmp i64 [[N0]] i64 13
; CHECK-NEXT:      SUCCESSORS(2):[[INTERMEDIATE_BB0:intermediate.bb[0-9]+]](i1 [[VP_SIDEEXIT_CMP]]), [[BB4]](!i1 [[VP_SIDEEXIT_CMP]])
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       i64 [[VP_DEF:%.*]] = add i64 [[N0]] i64 1
; CHECK-NEXT:       i64 [[VP_IV_NEXT:%.*]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:       i1 [[VP_EXITCOND:%.*]] = icmp i64 [[VP_IV_NEXT]] i64 42
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(2): [[BB3]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[INTERMEDIATE_BB0]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[NEW_LOOP_LATCH0]]:
; CHECK-NEXT:     i64 [[VP_IV_NEXT_SSA_PHI]] = phi  [ i64 [[VP_IV_NEXT]], [[BB4]] ],  [ i64 undef, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i64 [[VP_DEF_SSA_PHI:%.*]] = phi  [ i64 [[VP_DEF]], [[BB4]] ],  [ i64 undef, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i32 [[VP_EXIT_ID_PHI:%.*]] = phi  [ i32 0, [[BB4]] ],  [ i32 1, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i1 [[VP_TAKE_BACKEDGE_COND:%.*]] = phi  [ i1 [[VP_EXITCOND]], [[BB4]] ],  [ i1 true, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[CASCADED_IF_BLOCK0:cascaded.if.block[0-9]+]](i1 [[VP_TAKE_BACKEDGE_COND]]), [[BB1]](!i1 [[VP_TAKE_BACKEDGE_COND]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[INTERMEDIATE_BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[CASCADED_IF_BLOCK0]]:
; CHECK-NEXT:     i1 [[VP0:%.*]] = icmp i32 [[VP_EXIT_ID_PHI]] i32 1
; CHECK-NEXT:    SUCCESSORS(2):[[BB5:BB[0-9]+]](i1 [[VP0]]), [[BB6:BB[0-9]+]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(1): [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]:
; CHECK-NEXT:       i64 [[VP_EXIT_USE:%.*]] = phi  [ i64 [[VP_DEF_SSA_PHI]], [[CASCADED_IF_BLOCK0]] ]
; CHECK-NEXT:      SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(2): [[BB6]] [[BB5]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %cmp = icmp eq i64 %N, 42
  br i1 %cmp, label %bb1, label %bb2

bb1:
  %sideexit.cmp = icmp eq i64 %N, 13
  br i1 %sideexit.cmp, label %sideexit, label %latch

bb2:
  br label %latch

latch:
  %def = add nsw i64 %N, 1
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, 42
  br i1 %exitcond, label %loopexit, label %header

sideexit:
  br label %exit

loopexit:
  %exit.use = phi i64 [ %def, %latch ]
  br label %exit

exit:
  ret void
}

define dso_local void @no_ssa_breakage(i64 %N, i64 *%a, i64 %mask_out_loop) local_unnamed_addr {
; CHECK-LABEL:  VPlan IR for: no_ssa_breakage
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     i32 [[VP_LANE:%.*]] = induction-init{add} i32 0 i32 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_NEXT:%.*]], [[NEW_LOOP_LATCH0:new.loop.latch[0-9]+]] ],  [ i64 0, [[BB0]] ]
; CHECK-NEXT:     i64 [[VP_IV_NEXT]] = add i64 [[VP_IV]] i64 1
; CHECK-NEXT:     i64* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i64* [[A0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:     i64 [[VP_LD:%.*]] = load i64* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i1 [[VP_CMP:%.*]] = icmp i64 [[N0:%.*]] i64 42
; CHECK-NEXT:    SUCCESSORS(2):[[BB2:BB[0-9]+]](i1 [[VP_CMP]]), [[BB3:BB[0-9]+]](!i1 [[VP_CMP]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB0]] [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB4:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]:
; CHECK-NEXT:       i1 [[VP_SIDEEXIT_CMP:%.*]] = icmp i64 [[N0]] i64 13
; CHECK-NEXT:      SUCCESSORS(2):[[INTERMEDIATE_BB0:intermediate.bb[0-9]+]](i1 [[VP_SIDEEXIT_CMP]]), [[BB4]](!i1 [[VP_SIDEEXIT_CMP]])
; CHECK-NEXT:      PREDECESSORS(1): [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       i1 [[VP_EXITCOND:%.*]] = icmp i64 [[VP_IV_NEXT]] i64 42
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(2): [[BB3]] [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[INTERMEDIATE_BB0]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[NEW_LOOP_LATCH0]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[NEW_LOOP_LATCH0]]:
; CHECK-NEXT:     i32 [[VP_EXIT_ID_PHI:%.*]] = phi  [ i32 0, [[BB4]] ],  [ i32 1, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:     i1 [[VP_TAKE_BACKEDGE_COND:%.*]] = phi  [ i1 [[VP_EXITCOND]], [[BB4]] ],  [ i1 true, [[INTERMEDIATE_BB0]] ]
; CHECK-NEXT:    SUCCESSORS(2):[[CASCADED_IF_BLOCK0:cascaded.if.block[0-9]+]](i1 [[VP_TAKE_BACKEDGE_COND]]), [[BB1]](!i1 [[VP_TAKE_BACKEDGE_COND]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[INTERMEDIATE_BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[CASCADED_IF_BLOCK0]]:
; CHECK-NEXT:     i1 [[VP0:%.*]] = icmp i32 [[VP_EXIT_ID_PHI]] i32 1
; CHECK-NEXT:    SUCCESSORS(2):[[BB5:BB[0-9]+]](i1 [[VP0]]), [[BB6:BB[0-9]+]](!i1 [[VP0]])
; CHECK-NEXT:    PREDECESSORS(1): [[NEW_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       <Empty Block>
; CHECK-NEXT:      SUCCESSORS(1):[[BB7]]
; CHECK-NEXT:      PREDECESSORS(1): [[CASCADED_IF_BLOCK0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     void [[VP1:%.*]] = ret
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(2): [[BB6]] [[BB5]]
;
entry:
  %lane = call i64 @llvm.vplan.laneid()
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %iv.next = add nuw nsw i64 %iv, 1
  %arrayidx = getelementptr inbounds i64, i64* %a, i64 %iv
  %ld = load i64, i64* %arrayidx
  %cmp = icmp eq i64 %N, 42
  br i1 %cmp, label %bb1, label %bb2

bb1:
  %sideexit.cmp = icmp eq i64 %N, 13
  br i1 %sideexit.cmp, label %sideexit, label %latch

bb2:
  br label %latch

latch:
  %exitcond = icmp eq i64 %iv.next, 42
  br i1 %exitcond, label %loopexit, label %header

sideexit:
  br label %exit

loopexit:
  br label %exit

exit:
  ret void
}

declare i64 @llvm.vplan.laneid()
