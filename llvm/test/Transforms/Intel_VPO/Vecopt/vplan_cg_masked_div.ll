; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt < %s -passes=vplan-vec -vplan-force-vf=2 -vplan-enable-int-divrem-blend-with-safe-value=0 -S | FileCheck %s
; RUN: opt < %s -passes=vplan-vec,intel-ir-optreport-emitter -vplan-force-vf=2 -intel-opt-report=high -disable-output -vplan-enable-int-divrem-blend-with-safe-value=0 2>&1 | FileCheck %s -check-prefixes=OPTREPORT

; RUN: opt %s -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec" -vplan-force-vf=2 -print-after=hir-vplan-vec -vplan-enable-int-divrem-blend-with-safe-value=0 -disable-output 2>&1 | FileCheck %s -check-prefixes=HIR
; RUN: opt %s -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,hir-cg,simplifycfg,intel-ir-optreport-emitter" -vplan-force-vf=2   -intel-opt-report=high -vplan-enable-int-divrem-blend-with-safe-value=0 -disable-output 2>&1 | FileCheck %s -check-prefixes=HIR-OPTREPORT

; RUN: opt < %s -passes=vplan-vec -vplan-force-vf=2  -S | FileCheck %s -check-prefixes=BLENDED
; RUN: opt < %s -passes=vplan-vec,intel-ir-optreport-emitter -vplan-force-vf=2 -intel-opt-report=high -disable-output  2>&1 | FileCheck %s -check-prefixes=OPTREPORT-BLENDED

; RUN: opt %s -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec" -vplan-force-vf=2 -print-after=hir-vplan-vec  -disable-output 2>&1 | FileCheck %s -check-prefixes=HIR-BLENDED
; RUN: opt %s -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,hir-cg,simplifycfg,intel-ir-optreport-emitter" -vplan-force-vf=2   -intel-opt-report=high  -disable-output 2>&1 | FileCheck %s -check-prefixes=HIR-OPTREPORT-BLENDED

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @masked_divergent_div(ptr %p, i64 %n) {
; CHECK:  define void @masked_divergent_div(ptr [[P0:%.*]], i64 [[N0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP18:%.*]], [[VPLANNEDBB60:%.*]] ], [ 0, [[VPLANNEDBB20:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP17:%.*]], [[VPLANNEDBB60]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, ptr [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, ptr [[SCALAR_GEP0]], align 4
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_1_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 1
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_0_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 0
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], zeroinitializer
; CHECK-NEXT:    [[TMP5:%.*]] = xor <2 x i1> [[TMP4]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB40:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB4:
; CHECK-NEXT:    [[PREDICATE0:%.*]] = extractelement <2 x i1> [[TMP5]], i64 0
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i1 [[PREDICATE0]], true
; CHECK-NEXT:    br i1 [[TMP6]], label [[PRED_SDIV_IF0:%.*]], label [[TMP9:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP7:%.*]] = sdiv i32 42, [[WIDE_LOAD_EXTRACT_0_0]]
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i32> undef, i32 [[TMP7]], i32 0
; CHECK-NEXT:    br label [[TMP9]]
; CHECK-EMPTY:
; CHECK-NEXT:  8:
; CHECK-NEXT:    [[TMP10:%.*]] = phi <2 x i32> [ undef, [[VPLANNEDBB40]] ], [ [[TMP8]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[PREDICATE50:%.*]] = extractelement <2 x i1> [[TMP5]], i64 1
; CHECK-NEXT:    [[TMP11:%.*]] = icmp eq i1 [[PREDICATE50]], true
; CHECK-NEXT:    br i1 [[TMP11]], label [[PRED_SDIV_IF130:%.*]], label [[TMP14:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if13:
; CHECK-NEXT:    [[TMP12:%.*]] = sdiv i32 42, [[WIDE_LOAD_EXTRACT_1_0]]
; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> [[TMP10]], i32 [[TMP12]], i32 1
; CHECK-NEXT:    br label [[TMP14]]
; CHECK-EMPTY:
; CHECK-NEXT:  13:
; CHECK-NEXT:    [[TMP15:%.*]] = phi <2 x i32> [ [[TMP10]], [[PRED_SDIV_CONTINUE0]] ], [ [[TMP13]], [[PRED_SDIV_IF130]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE140:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue14:
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP15]], ptr [[SCALAR_GEP0]], i32 4, <2 x i1> [[TMP5]])
; CHECK-NEXT:    br label [[VPLANNEDBB60]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP17]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP18]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP19:%.*]] = icmp uge i64 [[TMP18]], [[TMP2:%.*]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[VPLANNEDBB70:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB7:
; CHECK-NEXT:    [[TMP20:%.*]] = mul i64 1, [[TMP2]]
; CHECK-NEXT:    [[TMP21:%.*]] = add i64 0, [[TMP20]]
;
; OPTREPORT:   remark #15566: 'sdiv': division was scalarized due to fp-model requirements.
;
; HIR-LABEL:  Function: masked_divergent_div
; HIR:             |   [[SERIAL_TEMP0:%.*]] = undef
; HIR-NEXT:        |   [[MASK_0_0:%.*]] = extractelement [[DOTVEC50:%.*]],  0
; HIR-NEXT:        |   if ([[MASK_0_0]] == 1)
; HIR-NEXT:        |   {
; HIR-NEXT:        |      [[EXTRACT_0_60:%.*]] = extractelement [[DOTVEC40:%.*]],  0
; HIR-NEXT:        |      [[DOTSCAL0:%.*]] = 42  /  [[EXTRACT_0_60]]
; HIR-NEXT:        |      [[SERIAL_TEMP0]] = insertelement [[SERIAL_TEMP0]],  [[DOTSCAL0]],  0
; HIR-NEXT:        |   }
; HIR-NEXT:        |   [[MASK_1_0:%.*]] = extractelement [[DOTVEC50]],  1
; HIR-NEXT:        |   if ([[MASK_1_0]] == 1)
; HIR-NEXT:        |   {
; HIR-NEXT:        |      [[EXTRACT_1_0:%.*]] = extractelement [[DOTVEC40]],  1
; HIR-NEXT:        |      [[DOTSCAL70:%.*]] = 42  /  [[EXTRACT_1_0]]
; HIR-NEXT:        |      [[SERIAL_TEMP0]] = insertelement [[SERIAL_TEMP0]],  [[DOTSCAL70]],  1
; HIR-NEXT:        |   }
; HIR-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[SERIAL_TEMP0]], Mask = @{[[DOTVEC50]]}
;
; HIR-OPTREPORT:           remark #15566: 'sdiv': division was scalarized due to fp-model requirements.
;
; BLENDED-LABEL:  define void @masked_divergent_div
; BLENDED:         [[TMP6:%.*]] = select <2 x i1> [[TMP5:%.*]], <2 x i32> [[WIDE_LOAD0:%.*]], <2 x i32> <i32 1, i32 1>
; BLENDED-NEXT:    [[TMP7:%.*]] = sdiv <2 x i32> <i32 42, i32 42>, [[TMP6]]
; BLENDED-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP7]], ptr [[SCALAR_GEP0:%.*]], i32 4, <2 x i1> [[TMP5]])
;
; OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_divergent_div
; OPTREPORT-BLENDED:       =================================================================
;
; HIR-BLENDED-LABEL:  Function: masked_divergent_div
; HIR-BLENDED:             + DO i1 = 0, [[LOOP_UB:%.*]], 2   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; HIR-BLENDED:             |   [[DOTVEC50:%.*]] = [[DOTVEC40:%.*]] != 0
; HIR-BLENDED-NEXT:        |   [[DOTVEC60:%.*]] = ([[DOTVEC40]] != 0) ? [[DOTVEC40]] : 1
; HIR-BLENDED-NEXT:        |   [[DOTVEC70:%.*]] = 42  /  [[DOTVEC60]]
; HIR-BLENDED-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[DOTVEC70]], Mask = @{[[DOTVEC50]]}
; HIR-BLENDED-NEXT:        + END LOOP
;
; HIR-OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_divergent_div
; HIR-OPTREPORT-BLENDED:       =================================================================
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, ptr %p, i64 %iv
  %ld = load i32, ptr %gep
  %cond = icmp eq i32 %ld, 0
  br i1 %cond, label %latch, label %masked

masked:
  %div = sdiv i32 42, %ld
  store i32 %div, ptr %gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_uniform_div(ptr %p, i64 %n, i32 %val) {
; CHECK:  define void @masked_uniform_div(ptr [[P0:%.*]], i64 [[N0:%.*]], i32 [[VAL0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP15:%.*]], [[VPLANNEDBB70:%.*]] ], [ 0, [[VPLANNEDBB20:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP14:%.*]], [[VPLANNEDBB70]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, ptr [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, ptr [[SCALAR_GEP0]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i32 [[VAL0]], 0
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <2 x i1> poison, i1 [[TMP4]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <2 x i1> [[BROADCAST_SPLATINSERT0]], <2 x i1> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP5:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], <i32 42, i32 42>
; CHECK-NEXT:    [[TMP6:%.*]] = or <2 x i1> [[BROADCAST_SPLAT0]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = xor <2 x i1> [[TMP6]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB40:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB4:
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <2 x i1> [[TMP7]] to i2
; CHECK-NEXT:    [[TMP9:%.*]] = icmp ne i2 [[TMP8]], 0
; CHECK-NEXT:    br i1 [[TMP9]], label [[PRED_SDIV_IF0:%.*]], label [[TMP11:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP10:%.*]] = sdiv i32 42, [[VAL0]]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT50:%.*]] = insertelement <2 x i32> poison, i32 [[TMP10]], i64 0
; CHECK-NEXT:    br label [[TMP11]]
; CHECK-EMPTY:
; CHECK-NEXT:  10:
; CHECK-NEXT:    [[TMP12:%.*]] = phi <2 x i32> [ poison, [[VPLANNEDBB40]] ], [ [[BROADCAST_SPLATINSERT50]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[BROADCAST_SPLAT60:%.*]] = shufflevector <2 x i32> [[TMP12]], <2 x i32> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[BROADCAST_SPLAT60]], ptr [[SCALAR_GEP0]], i32 4, <2 x i1> [[TMP7]])
; CHECK-NEXT:    br label [[VPLANNEDBB70]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB7:
; CHECK-NEXT:    [[TMP14]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP15]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP16:%.*]] = icmp uge i64 [[TMP15]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP16]], label [[VPLANNEDBB80:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB8:
; CHECK-NEXT:    [[TMP17:%.*]] = mul i64 1, [[TMP2]]
; CHECK-NEXT:    [[TMP18:%.*]] = add i64 0, [[TMP17]]
;
; HIR-LABEL:  Function: masked_uniform_div
; HIR:             |   [[DOTSCAL0:%.*]] = undef
; HIR-NEXT:        |   if ([[CMP0:%.*]] == 1)
; HIR-NEXT:        |   {
; HIR-NEXT:        |      [[DOTSCAL0]] = 42  /  [[VAL0:%.*]];
; HIR-NEXT:        |   }
; HIR-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[DOTSCAL0]], Mask = @{[[DOTVEC80:%.*]]}
;
; BLENDED-LABEL:  define void @masked_uniform_div
; BLENDED:       VPlannedBB4:
; BLENDED-NEXT:    [[TMP8:%.*]] = bitcast <2 x i1> [[TMP7:%.*]] to i2
; BLENDED-NEXT:    [[TMP9:%.*]] = icmp ne i2 [[TMP8]], 0
; BLENDED-NEXT:    br i1 [[TMP9]], label [[PRED_SDIV_IF0:%.*]], label [[TMP11:%.*]]
; BLENDED-EMPTY:
; BLENDED-NEXT:  pred.sdiv.if:
; BLENDED-NEXT:    [[TMP10:%.*]] = sdiv i32 42, [[VAL0:%.*]]
; BLENDED-NEXT:    [[BROADCAST_SPLATINSERT50:%.*]] = insertelement <2 x i32> poison, i32 [[TMP10]], i64 0
; BLENDED-NEXT:    br label [[TMP11]]
; BLENDED-EMPTY:
; BLENDED-NEXT:  10:
; BLENDED-NEXT:    [[TMP12:%.*]] = phi <2 x i32> [ poison, [[VPLANNEDBB40:%.*]] ], [ [[BROADCAST_SPLATINSERT50]], [[PRED_SDIV_IF0:%.*]] ]
; BLENDED-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; BLENDED-EMPTY:
; BLENDED-NEXT:  pred.sdiv.continue:
; BLENDED-NEXT:    [[BROADCAST_SPLAT60:%.*]] = shufflevector <2 x i32> [[TMP12]], <2 x i32> poison, <2 x i32> zeroinitializer
; BLENDED-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[BROADCAST_SPLAT60]], ptr [[SCALAR_GEP0:%.*]], i32 4, <2 x i1> [[TMP7]])
;
; OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_uniform_div
; OPTREPORT-BLENDED:       =================================================================
;
; HIR-BLENDED-LABEL:  Function: masked_uniform_div
; HIR-BLENDED:             + DO i1 = 0, [[LOOP_UB:%.*]], 2   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; HIR-BLENDED:             |   [[CMP0:%.*]] = [[TMP0:%.*]] != 0
; HIR-BLENDED-NEXT:        |   [[DOTSCAL0:%.*]] = undef
; HIR-BLENDED-NEXT:        |   if ([[CMP0]] == 1)
; HIR-BLENDED-NEXT:        |   {
; HIR-BLENDED-NEXT:        |      [[DOTSCAL0]] = 42  /  [[VAL0:%.*]]
; HIR-BLENDED-NEXT:        |   }
; HIR-BLENDED-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[DOTSCAL0]], Mask = @{[[DOTVEC80:%.*]]}
; HIR-BLENDED-NEXT:        + END LOOP
;
; HIR-OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_uniform_div
; HIR-OPTREPORT-BLENDED:       =================================================================
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, ptr %p, i64 %iv
  %ld = load i32, ptr %gep
  %cond = icmp eq i32 %val, 0
  %cond2 = icmp eq i32 %ld, 42
  %or = or i1 %cond, %cond2
  br i1 %or, label %latch, label %masked

masked:
  %div = sdiv i32 42, %val
  store i32 %div, ptr %gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_safe_speculation_div(ptr %p, i64 %n, i32 %m) {
; CHECK:  define void @masked_safe_speculation_div(ptr [[P0:%.*]], i64 [[N0:%.*]], i32 [[M0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP9:%.*]], [[VPLANNEDBB50:%.*]] ], [ 0, [[VPLANNEDBB20:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP8:%.*]], [[VPLANNEDBB50]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, ptr [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, ptr [[SCALAR_GEP0]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[TMP5:%.*]] = xor <2 x i1> [[TMP4]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB40:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB4:
; CHECK-NEXT:    [[TMP6:%.*]] = sdiv <2 x i32> [[WIDE_LOAD0]], <i32 42, i32 42>
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP6]], ptr [[SCALAR_GEP0]], i32 4, <2 x i1> [[TMP5]])
; CHECK-NEXT:    br label [[VPLANNEDBB50]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[TMP8]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP9]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP10:%.*]] = icmp uge i64 [[TMP9]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP10]], label [[VPLANNEDBB60:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP11:%.*]] = mul i64 1, [[TMP2]]
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 0, [[TMP11]]
;
; HIR-LABEL:  Function: masked_safe_speculation_div
; HIR:             |   [[DOTVEC50:%.*]] = [[DOTVEC40:%.*]] != [[M0:%.*]]
; HIR-NEXT:        |   [[DOTVEC60:%.*]] = [[DOTVEC40]]  /  42
; HIR-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[DOTVEC60]], Mask = @{[[DOTVEC50]]}
;
; BLENDED-LABEL:  define void @masked_safe_speculation_div
; BLENDED:       VPlannedBB4:
; BLENDED-NEXT:    [[TMP6:%.*]] = sdiv <2 x i32> [[WIDE_LOAD0:%.*]], <i32 42, i32 42>
; BLENDED-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP6]], ptr [[SCALAR_GEP0:%.*]], i32 4, <2 x i1> [[TMP5:%.*]])
;
; OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_safe_speculation_div
; OPTREPORT-BLENDED:       =================================================================
;
; HIR-BLENDED-LABEL:  Function: masked_safe_speculation_div
; HIR-BLENDED:             + DO i1 = 0, [[LOOP_UB:%.*]], 2   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; HIR-BLENDED-NEXT:        |   [[DOTVEC40:%.*]] = (<2 x i32>*)([[P0:%.*]])[i1]
; HIR-BLENDED-NEXT:        |   [[DOTVEC50:%.*]] = [[DOTVEC40]] != [[M0:%.*]]
; HIR-BLENDED-NEXT:        |   [[DOTVEC60:%.*]] = [[DOTVEC40]]  /  42
; HIR-BLENDED-NEXT:        |   (<2 x i32>*)([[P0]])[i1] = [[DOTVEC60]], Mask = @{[[DOTVEC50]]}
; HIR-BLENDED-NEXT:        + END LOOP
;
; HIR-OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_safe_speculation_div
; HIR-OPTREPORT-BLENDED:       =================================================================
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, ptr %p, i64 %iv
  %ld = load i32, ptr %gep
  %cond = icmp eq i32 %ld, %m
  br i1 %cond, label %latch, label %masked

masked:
  ; Safe to speculate
  %div = sdiv i32 %ld, 42
  store i32 %div, ptr %gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_unsafe_speculation_div(ptr %p, i64 %n, i32 %m) {
; CHECK:  define void @masked_unsafe_speculation_div(ptr [[P0:%.*]], i64 [[N0:%.*]], i32 [[M0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP18:%.*]], [[VPLANNEDBB60:%.*]] ], [ 0, [[VPLANNEDBB20:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP17:%.*]], [[VPLANNEDBB60]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, ptr [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, ptr [[SCALAR_GEP0]], align 4
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_1_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 1
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_0_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 0
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[TMP5:%.*]] = xor <2 x i1> [[TMP4]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB40:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB4:
; CHECK-NEXT:    [[PREDICATE0:%.*]] = extractelement <2 x i1> [[TMP5]], i64 0
; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i1 [[PREDICATE0]], true
; CHECK-NEXT:    br i1 [[TMP6]], label [[PRED_SDIV_IF0:%.*]], label [[TMP9:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP7:%.*]] = sdiv i32 [[WIDE_LOAD_EXTRACT_0_0]], -1
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i32> undef, i32 [[TMP7]], i32 0
; CHECK-NEXT:    br label [[TMP9]]
; CHECK-EMPTY:
; CHECK-NEXT:  8:
; CHECK-NEXT:    [[TMP10:%.*]] = phi <2 x i32> [ undef, [[VPLANNEDBB40]] ], [ [[TMP8]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[PREDICATE50:%.*]] = extractelement <2 x i1> [[TMP5]], i64 1
; CHECK-NEXT:    [[TMP11:%.*]] = icmp eq i1 [[PREDICATE50]], true
; CHECK-NEXT:    br i1 [[TMP11]], label [[PRED_SDIV_IF130:%.*]], label [[TMP14:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if13:
; CHECK-NEXT:    [[TMP12:%.*]] = sdiv i32 [[WIDE_LOAD_EXTRACT_1_0]], -1
; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> [[TMP10]], i32 [[TMP12]], i32 1
; CHECK-NEXT:    br label [[TMP14]]
; CHECK-EMPTY:
; CHECK-NEXT:  13:
; CHECK-NEXT:    [[TMP15:%.*]] = phi <2 x i32> [ [[TMP10]], [[PRED_SDIV_CONTINUE0]] ], [ [[TMP13]], [[PRED_SDIV_IF130]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE140:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue14:
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP15]], ptr [[SCALAR_GEP0]], i32 4, <2 x i1> [[TMP5]])
; CHECK-NEXT:    br label [[VPLANNEDBB60]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP17]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP18]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP19:%.*]] = icmp uge i64 [[TMP18]], [[TMP2]]
; CHECK-NEXT:    br i1 [[TMP19]], label [[VPLANNEDBB70:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB7:
; CHECK-NEXT:    [[TMP20:%.*]] = mul i64 1, [[TMP2]]
; CHECK-NEXT:    [[TMP21:%.*]] = add i64 0, [[TMP20]]
;
; OPTREPORT:           remark #15566: 'sdiv': division was scalarized due to fp-model requirements.
;
; HIR-LABEL:  Function: masked_unsafe_speculation_div
; HIR:             |   [[SERIAL_TEMP0:%.*]] = undef
; HIR-NEXT:        |   [[MASK_0_0:%.*]] = extractelement [[DOTVEC50:%.*]],  0
; HIR-NEXT:        |   if ([[MASK_0_0]] == 1)
; HIR-NEXT:        |   {
; HIR-NEXT:        |      [[EXTRACT_0_60:%.*]] = extractelement [[DOTVEC40:%.*]],  0
; HIR-NEXT:        |      [[DOTSCAL0:%.*]] = [[EXTRACT_0_60]]  /  -1
; HIR-NEXT:        |      [[SERIAL_TEMP0]] = insertelement [[SERIAL_TEMP0]],  [[DOTSCAL0]],  0
; HIR-NEXT:        |   }
; HIR-NEXT:        |   [[MASK_1_0:%.*]] = extractelement [[DOTVEC50]],  1
; HIR-NEXT:        |   if ([[MASK_1_0]] == 1)
; HIR-NEXT:        |   {
; HIR-NEXT:        |      [[EXTRACT_1_0:%.*]] = extractelement [[DOTVEC40]],  1
; HIR-NEXT:        |      [[DOTSCAL70:%.*]] = [[EXTRACT_1_0]]  /  -1
; HIR-NEXT:        |      [[SERIAL_TEMP0]] = insertelement [[SERIAL_TEMP0]],  [[DOTSCAL70]],  1
; HIR-NEXT:        |   }
; HIR-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[SERIAL_TEMP0]], Mask = @{[[DOTVEC50]]}
;
; HIR-OPTREPORT:           remark #15566: 'sdiv': division was scalarized due to fp-model requirements.
;
; BLENDED-LABEL:  define void @masked_unsafe_speculation_div
; BLENDED:       VPlannedBB4:
; BLENDED-NEXT:    [[TMP6:%.*]] = select <2 x i1> [[TMP5:%.*]], <2 x i32> <i32 -1, i32 -1>, <2 x i32> <i32 1, i32 1>
; BLENDED-NEXT:    [[TMP7:%.*]] = sdiv <2 x i32> [[WIDE_LOAD0:%.*]], [[TMP6]]
; BLENDED-NEXT:    call void @llvm.masked.store.v2i32.p0(<2 x i32> [[TMP7]], ptr [[SCALAR_GEP0:%.*]], i32 4, <2 x i1> [[TMP5:%.*]])
;
; OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_unsafe_speculation_div
; OPTREPORT-BLENDED:       =================================================================
;
; HIR-BLENDED-LABEL:  Function: masked_unsafe_speculation_div
; HIR-BLENDED:             + DO i1 = 0, [[LOOP_UB:%.*]], 2   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; HIR-BLENDED-NEXT:        |   [[DOTVEC40:%.*]] = (<2 x i32>*)([[P0:%.*]])[i1]
; HIR-BLENDED-NEXT:        |   [[DOTVEC50:%.*]] = [[DOTVEC40]] != [[M0:%.*]];
; HIR-BLENDED-NEXT:        |   [[DOTVEC60:%.*]] = ([[DOTVEC40]] != [[M0]]) ? -1 : 1
; HIR-BLENDED-NEXT:        |   [[DOTVEC70:%.*]] = [[DOTVEC40]]  /  [[DOTVEC60]]
; HIR-BLENDED-NEXT:        |   (<2 x i32>*)([[P0:%.*]])[i1] = [[DOTVEC70]], Mask = @{[[DOTVEC50]]}
; HIR-BLENDED-NEXT:        + END LOOP
;
; HIR-OPTREPORT-BLENDED-LABEL:  Global optimization report for : masked_unsafe_speculation_div
; HIR-OPTREPORT-BLENDED:       =================================================================
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, ptr %p, i64 %iv
  %ld = load i32, ptr %gep
  %cond = icmp eq i32 %ld, %m
  br i1 %cond, label %latch, label %masked

masked:
  ; Unsafe to speculate (i.e. INT_MIN sdiv -1 would overflow, which is UB)
  %div = sdiv i32 %ld, -1
  store i32 %div, ptr %gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
