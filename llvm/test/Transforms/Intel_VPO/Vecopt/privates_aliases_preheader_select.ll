; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

;; Test verifies aliases collection for privates through select in loop preheader,
;; and the related instructions are added to VPlan.

; RUN: opt -vplan-print-after-vpentity-instrs -S -vplan-vec -vplan-force-vf=4 -disable-output < %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux"

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)

define void @_ZGVeN16uuu__ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E11AtomicTests(i64 %_arg_m_capacity, i64 addrspace(1)* %ptr, i64 addrspace(4)* %alt, i1 zeroext %cmp.i.i) {
; CHECK:         [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i64* [[VP__SROA_0:%.*]] = allocate-priv i64*, OrigAlign = 8
; CHECK-NEXT:     i8* [[VP__SROA_0_BCAST:%.*]] = bitcast i64* [[VP__SROA_0]]
; CHECK-NEXT:     call i64 8 i8* [[VP__SROA_0_BCAST:%.*]] void (i64, i8*)* @llvm.lifetime.start.p0i8
; CHECK-NEXT:     i64 addrspace(4)* [[VP__SROA_0_0__SROA_CAST:%.*]] = addrspacecast i64* [[VP__SROA_0]]
; CHECK-NEXT:     i64 addrspace(4)* [[VP_SELECT:%.*]] = select i1 [[CMP_I_I0:%.*]] i64 addrspace(4)* [[VP__SROA_0_0__SROA_CAST]] i64 addrspace(4)* [[ALT0:%.*]]
; CHECK:          br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK:        [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK:          store i64 [[_ARG_M_CAPACITY0:%.*]] i64* [[VP__SROA_0]]
; CHECK:          i64 [[VP_COND_I_I:%.*]] = load i64 addrspace(4)* [[VP_SELECT]]
;
entry:
  %.sroa.0 = alloca i64, align 8
  br label %simd.begin.region

simd.begin.region:                                ; preds = %entry
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 16), "QUAL.OMP.UNIFORM"(i64 addrspace(1)* %ptr), "QUAL.OMP.UNIFORM"(i1 %cmp.i.i), "QUAL.OMP.UNIFORM"(i64 addrspace(4)* %alt), "QUAL.OMP.PRIVATE"(i64* %.sroa.0) ]
  br label %simd.loop.preheader

simd.loop.preheader:                              ; preds = %simd.begin.region
  %.sroa.0.0..sroa_cast = addrspacecast i64* %.sroa.0 to i64 addrspace(4)*
  %select = select i1 %cmp.i.i, i64 addrspace(4)* %.sroa.0.0..sroa_cast, i64 addrspace(4)* %alt
  br label %simd.loop.header

simd.loop.header:                                 ; preds = %simd.loop.latch, %simd.loop.preheader
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.latch ]
  store i64 %_arg_m_capacity, i64* %.sroa.0, align 8
  %cond.i.i = load i64, i64 addrspace(4)* %select, align 8
  %add.ptr.i14 = getelementptr inbounds i64, i64 addrspace(1)* %ptr, i32 %index
  store i64 %cond.i.i, i64 addrspace(1)* %add.ptr.i14, align 4
  br label %simd.loop.latch

simd.loop.latch:                                  ; preds = %simd.loop.header
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 16
  br i1 %vl.cond, label %simd.loop.header, label %simd.end.region

simd.end.region:                                  ; preds = %simd.loop.latch
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %return

return:                                           ; preds = %simd.end.region
  ret void
}
