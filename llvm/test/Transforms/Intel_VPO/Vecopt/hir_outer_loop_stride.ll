; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -disable-output -print-after=hir-vplan-vec  -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec" -disable-output -print-after=hir-vplan-vec -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s

; Check stability for merged CFG-based CG.
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -disable-output -print-after=hir-vplan-vec  -vplan-force-vf=4 -vplan-enable-new-cfg-merge-hir < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec" -disable-output -print-after=hir-vplan-vec -vplan-force-vf=4 -vplan-enable-new-cfg-merge-hir < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
;
; LIT test to demonstrate issue with stride information being calculated
; incorrectly when using underlying HIR. Incoming HIR is shown below.
; Note that the store is not unit strided at the i1 loop level that we are
; trying to vectorize at. However, IR based stride information improvement
; works for inner loops only and we incorrectly conclude that the access
; is unit strided(which is true at the inner loop level). The test checks
; generated HIR vector code for a scatter.
;
;     BEGIN REGION { }
;           %tok = @llvm.directive.region.entry(); [ DIR.OMP.SIMD() ]
;
;          + DO i1 = 0, 127, 1   <DO_LOOP> <simd>
;          |   + DO i2 = 0, 127, 1   <DO_LOOP>
;          |   |   (@arr)[0][i1][i2] = i1 + i2;
;          |   + END LOOP
;          + END LOOP
;
;          @llvm.directive.region.exit(%tok); [ DIR.OMP.END.SIMD() ]
;          ret ;
;     END REGION
;
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@arr = dso_local local_unnamed_addr global [128 x [128 x i64]] zeroinitializer, align 16

; Function Attrs: nofree norecurse nosync nounwind uwtable writeonly
define dso_local void @foo() local_unnamed_addr #0 {
; CHECK:       Function: foo
; CHECK-EMPTY:
; CHECK-NEXT:               BEGIN REGION { modified }
; CHECK-NEXT:                     + DO i1 = 0, 127, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK-NEXT:                     |   %phi.temp = 0
; CHECK-NEXT:                     |
; CHECK-NEXT:                     |   + DO i2 = 0, 127, 1   <DO_LOOP>
; CHECK-NEXT:                     |   |   (<4 x i64>*)(@arr)[0][i1 + <i64 0, i64 1, i64 2, i64 3>][i2] = i1 + i2 + <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:                     |   |   %.vec = i2 + 1 < 128
; CHECK-NEXT:                     |   |   %phi.temp = i2 + 1
; CHECK-NEXT:                     |   + END LOOP
; CHECK-NEXT:                     + END LOOP
; CHECK:                          ret
; CHECK-NEXT:               END REGION
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.cond1.preheader
for.cond1.preheader:                              ; preds = %entry, %for.inc5
  %l1.017 = phi i64 [ 0, %entry ], [ %inc6, %for.inc5 ]
  br label %for.body3

for.body3:                                        ; preds = %for.cond1.preheader, %for.body3
  %l2.016 = phi i64 [ 0, %for.cond1.preheader ], [ %inc, %for.body3 ]
  %add = add nuw nsw i64 %l2.016, %l1.017
  %arrayidx4 = getelementptr inbounds [128 x [128 x i64]], [128 x [128 x i64]]* @arr, i64 0, i64 %l1.017, i64 %l2.016
  store i64 %add, i64* %arrayidx4, align 8
  %inc = add nuw nsw i64 %l2.016, 1
  %exitcond.not = icmp eq i64 %inc, 128
  br i1 %exitcond.not, label %for.inc5, label %for.body3

for.inc5:                                         ; preds = %for.body3
  %inc6 = add nuw nsw i64 %l1.017, 1
  %exitcond18.not = icmp eq i64 %inc6, 128
  br i1 %exitcond18.not, label %for.end7, label %for.cond1.preheader

for.end7:                                         ; preds = %for.inc5
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
