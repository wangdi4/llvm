; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -disable-output -disable-vplan-codegen -vplan-vec -vplan-force-vf=4 -vplan-enable-cfg-merge -vplan-print-after-cfg-merge < %s 2>&1 | FileCheck %s
;
; test for basic functionality of cfg merge, in-memory reduction.
;
define float @load_store_reduction_add(float* nocapture %a) {
; CHECK-LABEL:  VPlan after CFG merge before CG:
; CHECK-NEXT:  VPlan IR for: load_store_reduction_add:for.body
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] pushvf VF=4 UF=1
; CHECK-NEXT:     [DA: Uni] pushvf VF=4 UF=1
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Div] float* [[VP_X:%.*]] = allocate-priv float*, OrigAlign = 4
; CHECK-NEXT:     [DA: Div] i8* [[VP_X_BCAST:%.*]] = bitcast float* [[VP_X]]
; CHECK-NEXT:     [DA: Div] call i64 4 i8* [[VP_X_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8 [Serial]
; CHECK-NEXT:     [DA: Div] float [[VP_XRED_INIT:%.*]] = reduction-init float -0.000000e+00
; CHECK-NEXT:     [DA: Div] store float [[VP_XRED_INIT]] float* [[VP_X]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1000, UF = 1
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ],  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB2]] ]
; CHECK-NEXT:     [DA: Div] float [[VP_ADD7:%.*]] = phi  [ float [[VP_XRED_INIT]], [[BB1]] ],  [ float [[VP_ADD:%.*]], [[BB2]] ]
; CHECK-NEXT:     [DA: Div] float* [[VP_A_GEP:%.*]] = getelementptr inbounds float* [[A0:%.*]] i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     [DA: Div] float [[VP_A_LOAD:%.*]] = load float* [[VP_A_GEP]]
; CHECK-NEXT:     [DA: Div] float [[VP_ADD]] = fadd float [[VP_ADD7]] float [[VP_A_LOAD]]
; CHECK-NEXT:     [DA: Div] store float [[VP_ADD]] float* [[VP_X]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp uge i64 [[VP_INDVARS_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB3:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     [DA: Div] float [[VP_LOAD:%.*]] = load float* [[VP_X]]
; CHECK-NEXT:     [DA: Uni] float [[VP_XRED_FINAL:%.*]] = reduction-final{fadd} float [[VP_LOAD]] float [[X_PROMOTED0:%.*]]
; CHECK-NEXT:     [DA: Uni] store float [[VP_XRED_FINAL]] float* [[X0:%.*]]
; CHECK-NEXT:     [DA: Div] i8* [[VP_X_BCAST:%.*]] = bitcast float* [[VP_X]]
; CHECK-NEXT:     [DA: Div] call i64 4 i8* [[VP_X_BCAST]] void (i64, i8*)* @llvm.lifetime.end.p0i8 [Serial]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni] popvf
; CHECK-NEXT:     [DA: Uni] br final.merge
; CHECK-EMPTY:
; CHECK-NEXT:    final.merge: # preds: [[BB4]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP0:%.*]] = phi-merge  [ i64 live-out0, [[BB4]] ]
; CHECK-NEXT:     [DA: Uni] float [[VP1:%.*]] = phi-merge  [ float live-out1, [[BB4]] ]
; CHECK-NEXT:     [DA: Uni] popvf
; CHECK-NEXT:     [DA: Uni] br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP_INDVARS_IV_IND_FINAL]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1   no underlying for float [[VP_XRED_FINAL]]
;
entry:
  %x = alloca float, align 4
  br label %simd.start

simd.start:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 8), "QUAL.OMP.REDUCTION.ADD"(float* %x) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %entry.split
  %x.promoted = load float, float* %x, align 4
  br label %for.body

for.body:                                         ; preds = %for.body, %DIR.QUAL.LIST.END.2
  %indvars.iv = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %indvars.iv.next, %for.body ]
  %add7 = phi float [ %x.promoted, %DIR.QUAL.LIST.END.2 ], [ %add, %for.body ]
  %a.gep = getelementptr inbounds float, float* %a, i64 %indvars.iv
  %a.load = load float, float* %a.gep
  %add = fadd float %add7, %a.load
  store float %add, float* %x, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1000
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  br label %for.end1

for.end1:                                         ; preds = %for.end
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %for.end
  %last.val = load float, float* %x, align 4
  ret float %last.val
}

; Function Attrs: argmemonly nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: argmemonly nounwind
declare void @llvm.directive.region.exit(token)
