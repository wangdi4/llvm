; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -hir-cg -disable-output -print-after=hir-vplan-vec -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -hir-cg -disable-output -print-after=hir-vplan-vec -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec,print<hir>,hir-cg" -disable-output -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec,print<hir>,hir-cg" -disable-output -vplan-force-vf=4 < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s
; LIT test to check that the select mask gets replicated appropriately when the mask is scalar
; and the values being selected are of vector type.
;
; Incoming HIR looks like the following:
;
;         + DO i1 = 0, 127, 1   <DO_LOOP> <simd>
;         |   %ld = (%q)[i1];
;         |   %ld.cast = bitcast.i64.<2 x i32>(%ld);
;         |   %sel = (i1 == 42) ? %ld.cast : <i32 7, i32 9>;
;         |   %sel.cast = bitcast.<2 x i32>.i64(%sel);
;         |   (%q)[i1] = %sel.cast;
;         + END LOOP
;
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @test(i64 *%q) {
; CHECK-LABEL:  Function: test
; CHECK:              + DO i1 = 0, 127, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK-NEXT:         |   %.vec = (<4 x i64>*)(%q)[i1];
; CHECK-NEXT:         |   %.vec2 = bitcast.<4 x i64>.<8 x i32>(%.vec);
; CHECK-NEXT:         |   %.replicated.elts = shufflevector i1 + <i64 0, i64 1, i64 2, i64 3>,  undef,  <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>;
; CHECK-NEXT:         |   %.replicated.elts3 = shufflevector 42,  undef,  <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>;
; CHECK-NEXT:         |   %.vec4 = (%.replicated.elts == %.replicated.elts3) ? %.vec2 : <i32 7, i32 9, i32 7, i32 9, i32 7, i32 9, i32 7, i32 9>;
; CHECK-NEXT:         |   %.vec5 = bitcast.<8 x i32>.<4 x i64>(%.vec4);
; CHECK-NEXT:         |   (<4 x i64>*)(%q)[i1] = %.vec5;
; CHECK-NEXT:         + END LOOP
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ 0, %entry ], [ %iv.next, %header ]

  %cmp = icmp eq i64 %iv, 42

  %p = getelementptr i64, i64 *%q, i64 %iv
  %ld = load i64, i64 *%p

  %ld.cast = bitcast i64 %ld to <2 x i32>
  %sel = select i1 %cmp, <2 x i32> %ld.cast, <2 x i32><i32 7, i32 9>
  %sel.cast = bitcast <2 x i32> %sel to i64

  store i64 %sel.cast, i64 *%p

  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, 128
  br i1 %exitcond, label %exit, label %header

exit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
