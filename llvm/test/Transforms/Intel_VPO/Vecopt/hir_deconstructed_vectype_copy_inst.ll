; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -hir-vplan-vec -disable-output -print-after=hir-vplan-vec  -vplan-force-vf=4 -vplan-print-after-ssa-deconstruction < %s 2>&1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vec-dir-insert,hir-vplan-vec,print<hir>" -disable-output -vplan-force-vf=4 -vplan-print-after-ssa-deconstruction < %s 2>&1 | FileCheck %s
;
; LIT test to check that hir-copy instructions from SSA deconstruction are handled
; correctly. When the copy instruction generated is for a vector type, we were hitting
; an assert when trying to use FixedVectorType::get to get the widened type for
; creating the LVal RegDDRef for the generated copies.
;
; Incoming HIR looks like the following:
;
;           + DO i1 = 0, 99, 1   <DO_LOOP>
;           |   if (%n0 < %n1)
;           |   {
;           |      %0 = (<2 x i64>*)(%larr1)[2 * i1];
;           |      %l2.0 = %0;
;           |   }
;           |   else
;           |   {
;           |      %1 = (<2 x i64>*)(%larr2)[2 * i1];
;           |      %l2.0 = %1;
;           |   }
;           |   %add = %l2.0  +  %l2n;
;           |   (<2 x i64>*)(%larr3)[2 * i1] = %add;
;           + END LOOP
;
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nofree norecurse nosync nounwind uwtable
define dso_local void @foo(i64* noalias nocapture readonly %larr1, i64* noalias nocapture readonly %larr2, i64* noalias nocapture readonly %larr3, <2 x i64> %l2n, i64 %n1, i64 %n0) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after SSA deconstruction:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%larr2}
; CHECK-DAG:     [[VP1:%.*]] = {%larr3}
; CHECK-DAG:     [[VP2:%.*]] = {%larr1}
; CHECK-DAG:     [[VP3:%.*]] = {%l2n}
; CHECK-DAG:     [[VP4:%.*]] = {%l2.0}
; CHECK-DAG:     [[VP5:%.*]] = {if (%n0 < %n1)}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK:          [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 100, UF = 1
; CHECK-NEXT:     [DA: Div] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 {{.*}} i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div] i64 [[VP6:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP7:%.*]], [[BB3]] ]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP5]], [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: Div] i64 [[VP8:%.*]] = mul i64 2 i64 [[VP6]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i64* [[LARR20:%.*]] i64 [[VP8]]
; CHECK-NEXT:       [DA: Div] <2 x i64>* [[VP9:%.*]] = bitcast i64* [[VP_SUBSCRIPT]]
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP_LOAD:%.*]] = load <2 x i64>* [[VP9]]
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP10:%.*]] = hir-copy <2 x i64> [[VP_LOAD]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP11:%.*]] = hir-copy <2 x i64> [[VP10]] , OriginPhiId: 0
; CHECK-NEXT:       [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: Div] i64 [[VP12:%.*]] = mul i64 2 i64 [[VP6]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64* [[LARR10:%.*]] i64 [[VP12]]
; CHECK-NEXT:       [DA: Div] <2 x i64>* [[VP13:%.*]] = bitcast i64* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP_LOAD_1:%.*]] = load <2 x i64>* [[VP13]]
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP14:%.*]] = hir-copy <2 x i64> [[VP_LOAD_1]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] <2 x i64> [[VP15:%.*]] = hir-copy <2 x i64> [[VP14]] , OriginPhiId: 0
; CHECK-NEXT:       [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB4]], [[BB5]]
; CHECK-NEXT:     [DA: Div] <2 x i64> [[VP16:%.*]] = phi  [ <2 x i64> [[VP15]], [[BB4]] ],  [ <2 x i64> [[VP11]], [[BB5]] ]
; CHECK-NEXT:     [DA: Div] <2 x i64> [[VP17:%.*]] = add <2 x i64> [[VP16]] <2 x i64> [[L2N0:%.*]]
; CHECK-NEXT:     [DA: Div] i64 [[VP18:%.*]] = mul i64 2 i64 [[VP6]]
; CHECK-NEXT:     [DA: Div] i64* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds i64* [[LARR30:%.*]] i64 [[VP18]]
; CHECK-NEXT:     [DA: Div] <2 x i64>* [[VP19:%.*]] = bitcast i64* [[VP_SUBSCRIPT_2]]
; CHECK-NEXT:     [DA: Div] store <2 x i64> [[VP17]] <2 x i64>* [[VP19]]
; CHECK-NEXT:     [DA: Div] i64 [[VP7]] = add i64 [[VP6]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP20:%.*]] = icmp slt i64 [[VP7]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP20]], [[BB2]], [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK:       External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP__IND_FINAL]]
; CHECK-EMPTY:
; CHECK:       Function: foo
; CHECK-EMPTY:
; CHECK-NEXT:  BEGIN REGION { modified }
; CHECK:             + DO i1 = 0, 99, 4   <DO_LOOP> <auto-vectorized> <novectorize>
; CHECK-NEXT:        |   if ([[N00:%.*]] < [[N10:%.*]])
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[DOTVEC30:%.*]] = (<8 x i64>*)([[LARR10]])[2 * i1]
; CHECK-NEXT:        |      [[DOTCOPY40:%.*]] = [[DOTVEC30]]
; CHECK-NEXT:        |      [[PHI_TEMP0:%.*]] = [[DOTCOPY40]]
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   else
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[DOTVEC0:%.*]] = (<8 x i64>*)([[LARR20]])[2 * i1]
; CHECK-NEXT:        |      [[DOTCOPY0:%.*]] = [[DOTVEC0]]
; CHECK-NEXT:        |      [[PHI_TEMP0]] = [[DOTCOPY0]]
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   [[DOTREPLICATED0:%.*]] = shufflevector [[L2N0]],  undef,  <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>
; CHECK-NEXT:        |   (<8 x i64>*)([[LARR30]])[2 * i1] = [[PHI_TEMP0]] + [[DOTREPLICATED0]]
; CHECK-NEXT:        + END LOOP
; CHECK:       END REGION
;
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %l1.013 = phi i64 [ 0, %entry ], [ %inc, %if.end ]
  %l1.mul = mul i64 %l1.013, 2
  %cmp1 = icmp slt i64 %n0, %n1
  br i1 %cmp1, label %if.then, label %if.else

if.then:                                          ; preds = %for.body
  %arrayidx = getelementptr inbounds i64, i64* %larr1, i64 %l1.mul
  %arrayidx.bc = bitcast i64* %arrayidx to <2 x i64>*
  %0 = load <2 x i64>, <2 x i64>* %arrayidx.bc, align 16
  br label %if.end

if.else:                                          ; preds = %for.body
  %arrayidx2 = getelementptr inbounds i64, i64* %larr2, i64 %l1.mul
  %arrayidx2.bc = bitcast i64* %arrayidx2 to <2 x i64>*
  %1 = load <2 x i64>, <2 x i64>* %arrayidx2.bc, align 16
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  %l2.0 = phi <2 x i64> [ %0, %if.then ], [ %1, %if.else ]
  %add = add <2 x i64> %l2.0, %l2n
  %arrayidx3 = getelementptr inbounds i64,  i64* %larr3, i64 %l1.mul
  %arrayidx3.bc = bitcast i64* %arrayidx3 to <2 x i64>*
  store <2 x i64> %add, <2 x i64>* %arrayidx3.bc, align 16
  %inc = add nuw nsw i64 %l1.013, 1
  %exitcond.not = icmp eq i64 %inc, 100
  br i1 %exitcond.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  ret void
}
