; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
source_filename = "atg_CMPLRLLVM-22374.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"
;int main () {
;  unsigned int k7 = 63, j = 0, jq = 0, nk = 0, res = 0;
;  unsigned int sr[100], z[100], r[100][100] = {0};
;  init((unsigned int * )sr, 100);
;  init((unsigned int * )z, 100);
;  for (j = 1; j < 77; j++)
;    if (sr[j]) ;; In the IR snippet, the value of sr[j] has been hard-coded to '1'.
;      for (jq = 1; jq < 45; jq++) {
;        z[jq] -= k7 + k7;
;        r[jq][j] = --nk;
;        r[jq + 1][jq] *= z[jq];
;      }
;    return 0;
;}

; RUN: opt -S -load-coalescing %s | FileCheck %s

define dso_local i32 @main() local_unnamed_addr #1 {
; CHECK:  define dso_local i32 @main() local_unnamed_addr #0 {
; CHECK-NEXT:  entry:
; CHECK:         [[NK0:%.*]] = bitcast i32 0 to i32
; CHECK-NEXT:    [[J0:%.*]] = bitcast i64 1 to i64
; CHECK-NEXT:    [[Z_10:%.*]] = getelementptr inbounds [100 x i32], [100 x i32]* [[Z0:%.*]], i64 0, i64 1
; CHECK-NEXT:    [[ARRAYIDX1100:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0:%.*]], i64 0, i64 1, i64 [[J0]]
; CHECK-NEXT:    [[NK10:%.*]] = add i32 [[NK0]], -1
; CHECK-NEXT:    store i32 [[NK10]], i32* [[ARRAYIDX1100]], align 4
; CHECK-NEXT:    [[ARRAYIDX1120:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 2, i64 1
; CHECK-NEXT:    [[GEPLOAD1130:%.*]] = load i32, i32* [[ARRAYIDX1120]], align 4
; CHECK-NEXT:    [[BC10:%.*]] = bitcast i32* [[Z_10]] to <4 x i32>*
; CHECK-NEXT:    [[ARRAYIDX1240:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 2, i64 [[J0]]
; CHECK-NEXT:    [[NK20:%.*]] = add i32 [[NK0]], -2
; CHECK-NEXT:    [[Z_20:%.*]] = getelementptr inbounds [100 x i32], [100 x i32]* [[Z0]], i64 0, i64 5
;
; This store is wrong. Store r[2][1] = --nk; (%j = 1 here) should happen only after store on line # 72, i.e, r[2][1] = r[2][1] * z[1]
;
; CHECK-NEXT:    store i32 [[NK20]], i32* [[ARRAYIDX1240]], align 4
; CHECK-NEXT:    [[ARRAYIDX1270:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 3, i64 2
; CHECK-NEXT:    [[BC30:%.*]] = bitcast i32* [[Z_20]] to <4 x i32>*
; CHECK-NEXT:    [[ARRAYIDX1400:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 3, i64 [[J0]]
; CHECK-NEXT:    [[NK30:%.*]] = add i32 [[NK0]], -3
; CHECK-NEXT:    [[GEPLOAD1280:%.*]] = load i32, i32* [[ARRAYIDX1270]], align 8
; CHECK-NEXT:    [[ARRAYIDX1560:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 4, i64 [[J0]]
; CHECK-NEXT:    [[NK40:%.*]] = add i32 [[NK0]], -4
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <4 x i32>* [[BC10]] to <8 x i32>*
; CHECK-NEXT:    [[COALESCEDLOAD0:%.*]] = load <8 x i32>, <8 x i32>* [[TMP3]], align 4
; CHECK-NEXT:    [[LOADCOALESCINGSHUFFLE_0:%.*]] = shufflevector <8 x i32> [[COALESCEDLOAD0]], <8 x i32> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[LOADCOALESCINGSHUFFLE_10:%.*]] = shufflevector <8 x i32> [[COALESCEDLOAD0]], <8 x i32> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
; CHECK-NEXT:    [[WIDE_ADD_10:%.*]] = add <4 x i32> [[LOADCOALESCINGSHUFFLE_0]], <i32 -126, i32 -126, i32 -126, i32 -126>
; CHECK-NEXT:    store i32 [[NK30]], i32* [[ARRAYIDX1400]], align 4
; CHECK-NEXT:    [[ARRAYIDX1430:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 4, i64 3
; CHECK-NEXT:    store i32 [[NK40]], i32* [[ARRAYIDX1560]], align 4
; CHECK-NEXT:    [[ARRAYIDX1590:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 5, i64 4
; CHECK-NEXT:    [[E10:%.*]] = extractelement <4 x i32> [[WIDE_ADD_10]], i32 0
; CHECK-NEXT:    [[E20:%.*]] = extractelement <4 x i32> [[WIDE_ADD_10]], i32 1
; CHECK-NEXT:    [[E30:%.*]] = extractelement <4 x i32> [[WIDE_ADD_10]], i32 2
; CHECK-NEXT:    [[GEPLOAD1440:%.*]] = load i32, i32* [[ARRAYIDX1430]], align 4
; CHECK-NEXT:    [[E40:%.*]] = extractelement <4 x i32> [[WIDE_ADD_10]], i32 3
; CHECK-NEXT:    [[GEPLOAD1600:%.*]] = load i32, i32* [[ARRAYIDX1590]], align 16
; CHECK-NEXT:    [[ARRAYIDX1720:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 5, i64 [[J0]]
; CHECK-NEXT:    [[NK50:%.*]] = add i32 [[NK0]], -5
; CHECK-NEXT:    [[MUL10:%.*]] = mul i32 [[GEPLOAD1130]], [[E10]]
; CHECK-NEXT:    [[MUL20:%.*]] = mul i32 [[GEPLOAD1280]], [[E20]]
; CHECK-NEXT:    [[MUL30:%.*]] = mul i32 [[GEPLOAD1440]], [[E30]]
; CHECK-NEXT:    [[BC20:%.*]] = bitcast i32* [[Z_10]] to <4 x i32>*
; CHECK-NEXT:    [[MUL40:%.*]] = mul i32 [[GEPLOAD1600]], [[E40]]
; CHECK-NEXT:    store i32 [[NK50]], i32* [[ARRAYIDX1720]], align 4
; CHECK-NEXT:    [[ARRAYIDX1750:%.*]] = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* [[R0]], i64 0, i64 6, i64 5
; CHECK-NEXT:    store i32 [[MUL10]], i32* [[ARRAYIDX1120]], align 4
; CHECK-NEXT:    store i32 [[MUL20]], i32* [[ARRAYIDX1270]], align 8
; CHECK-NEXT:    store i32 [[MUL30]], i32* [[ARRAYIDX1430]], align 4
; CHECK-NEXT:    store <4 x i32> [[WIDE_ADD_10]], <4 x i32>* [[BC20]], align 4
; CHECK-NEXT:    store i32 [[MUL40]], i32* [[ARRAYIDX1590]], align 16
; CHECK     }
;
entry:
  %sr = alloca [100 x i32], align 16
  %z = alloca [100 x i32], align 16
  %r = alloca [100 x [100 x i32]], align 16
  %0 = bitcast [100 x i32]* %sr to i8*
  %1 = bitcast [100 x i32]* %z to i8*
  %2 = bitcast [100 x [100 x i32]]* %r to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 dereferenceable(40000) %2, i8 0, i64 40000, i1 false)
  %nk = bitcast i32 0 to i32
  %j = bitcast i64 1 to i64
  %Z_1 = getelementptr inbounds [100 x i32], [100 x i32]* %z, i64 0, i64 1
  %arrayIdx110 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 1, i64 %j
  %nk1 = add i32 %nk, -1
  store i32 %nk1, i32* %arrayIdx110, align 4
  %arrayIdx112 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 2, i64 1
  %gepload113 = load i32, i32* %arrayIdx112, align 4
  %bc1 = bitcast i32* %Z_1 to <4 x i32>*
  %wide.load.1 = load <4 x i32>, <4 x i32>* %bc1, align 4
  %wide.add.1 = add <4 x i32> %wide.load.1, <i32 -126, i32 -126, i32 -126, i32 -126>
  %e1 = extractelement <4 x i32> %wide.add.1, i32 0
  %mul1 = mul i32 %gepload113, %e1
  store i32 %mul1, i32* %arrayIdx112, align 4
  %arrayIdx124 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 2, i64 %j
  %nk2 = add i32 %nk, -2
  store i32 %nk2, i32* %arrayIdx124, align 4
  %arrayIdx127 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 3, i64 2
  %gepload128 = load i32, i32* %arrayIdx127, align 8
  %e2 = extractelement <4 x i32> %wide.add.1, i32 1
  %mul2 = mul i32 %gepload128, %e2
  store i32 %mul2, i32* %arrayIdx127, align 8
  %arrayIdx140 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 3, i64 %j
  %nk3 = add i32 %nk, -3
  store i32 %nk3, i32* %arrayIdx140, align 4
  %arrayIdx143 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 4, i64 3
  %gepload144 = load i32, i32* %arrayIdx143, align 4
  %e3 = extractelement <4 x i32> %wide.add.1, i32 2
  %mul3 = mul i32 %gepload144, %e3
  store i32 %mul3, i32* %arrayIdx143, align 4
  %bc2 = bitcast i32* %Z_1 to <4 x i32>*
  store <4 x i32> %wide.add.1, <4 x i32>* %bc2, align 4
  %arrayIdx156 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 4, i64 %j
  %nk4 = add i32 %nk, -4
  store i32 %nk4, i32* %arrayIdx156, align 4
  %arrayIdx159 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 5, i64 4
  %gepload160 = load i32, i32* %arrayIdx159, align 16
  %e4 = extractelement <4 x i32> %wide.add.1, i32 3
  %mul4 = mul i32 %gepload160, %e4
  store i32 %mul4, i32* %arrayIdx159, align 16
  %Z_2 = getelementptr inbounds [100 x i32], [100 x i32]* %z, i64 0, i64 5
  %arrayIdx172 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 5, i64 %j
  %nk5 = add i32 %nk, -5
  store i32 %nk5, i32* %arrayIdx172, align 4
  %arrayIdx175 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 6, i64 5
  %gepload176 = load i32, i32* %arrayIdx175, align 4
  %bc3 = bitcast i32* %Z_2 to <4 x i32>*
  %wide.load.2 = load <4 x i32>, <4 x i32>* %bc3, align 4
  %wide.add.2 = add <4 x i32> %wide.load.2, <i32 -126, i32 -126, i32 -126, i32 -126>
  %e5 = extractelement <4 x i32> %wide.add.2, i32 0
  %mul5 = mul i32 %gepload176, %e5
  store i32 %mul5, i32* %arrayIdx175, align 4
  %arrayIdx188 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 6, i64 %j
  %nk6 = add i32 %nk, -6
  store i32 %nk6, i32* %arrayIdx188, align 4
  %arrayIdx191 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 7, i64 6
  %gepload192 = load i32, i32* %arrayIdx191, align 8
  %e6 = extractelement <4 x i32> %wide.add.2, i32 1
  %mul6 = mul i32 %gepload192, %e6
  store i32 %mul6, i32* %arrayIdx191, align 8
  %arrayIdx204 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 7, i64 %j
  %nk7 = add i32 %nk, -7
  store i32 %nk7, i32* %arrayIdx204, align 4
  %arrayIdx207 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 8, i64 7
  %gepload208 = load i32, i32* %arrayIdx207, align 4
  %e7 = extractelement <4 x i32> %wide.add.2, i32 2
  %mul7 = mul i32 %gepload208, %e7
  store i32 %mul7, i32* %arrayIdx207, align 4
  %bc4 = bitcast i32* %Z_2 to <4 x i32>*
  store <4 x i32> %wide.add.2, <4 x i32>* %bc4, align 4
  %arrayIdx220 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 8, i64 %j
  %nk8 = add i32 %nk, -8
  store i32 %nk8, i32* %arrayIdx220, align 4
  %arrayIdx223 = getelementptr inbounds [100 x [100 x i32]], [100 x [100 x i32]]* %r, i64 0, i64 9, i64 8
  %gepload224 = load i32, i32* %arrayIdx223, align 16
  %e8 = extractelement <4 x i32> %wide.add.2, i32 3
  %mul8 = mul i32 %gepload224, %e8
  store i32 %mul8, i32* %arrayIdx223, align 16
  ret i32 0
}

; Function Attrs: argmemonly nounwind willreturn writeonly
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #2

attributes #1 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="none" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="skylake-avx512" "target-features"="+adx,+aes,+avx,+avx2,+avx512bw,+avx512cd,+avx512dq,+avx512f,+avx512vl,+bmi,+bmi2,+clflushopt,+clwb,+cx16,+cx8,+f16c,+fma,+fsgsbase,+fxsr,+invpcid,+lzcnt,+mmx,+movbe,+pclmul,+pku,+popcnt,+prfchw,+rdrnd,+rdseed,+sahf,+sse,+sse2,+sse3,+sse4.1,+sse4.2,+ssse3,+x87,+xsave,+xsavec,+xsaveopt,+xsaves" "unsafe-fp-math"="false" "use-soft-float"="false" }
