; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

; Auto generated checks were manually updated to reflect differences in mixed and
; VPValue based CG modes caused by mixed mode reusing the same ref for assignments
; to the same HIR temp.

; Test to check correctness of VPlan pseudo SSA deconstruction transform and
; vector CG for simple if-else construct based on a uniform condition.

; Incoming HIR
;   BEGIN REGION { }
;         %entry.region = @llvm.directive.region.entry(); [ DIR.VPO.AUTO.VEC() ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP>
;         |   if (%n1 == 0)
;         |   {
;         |      %ld.true = (%arr1)[i1];
;         |      %merge.phi = %ld.true;
;         |   }
;         |   else
;         |   {
;         |      %ld.false = (%arr2)[i1];
;         |      %merge.phi = %ld.false;
;         |   }
;         |   %red.phi = %merge.phi  +  %red.phi; <Safe Reduction>
;         + END LOOP
;
;         @llvm.directive.region.exit(%entry.region); [ DIR.VPO.END.AUTO.VEC() ]
;   END REGION

; RUN: opt -passes="hir-ssa-deconstruction,hir-vec-dir-insert,hir-vplan-vec,print<hir>" -vplan-force-linearization-hir=false -vplan-force-vf=4 -vplan-print-after-ssa-deconstruction -vplan-dump-external-defs-hir=0 -disable-output < %s 2>&1 | FileCheck %s

define void @foo(float* noalias nocapture %arr1, float* noalias nocapture %arr2, i32 %n1) {
; CHECK-LABEL:  VPlan after SSA deconstruction:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK:          [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 100, UF = 1
; CHECK-NEXT:     [DA: Div] float [[VP_RED_INIT:%.*]] = reduction-init float 0.000000e+00
; CHECK-NEXT:     [DA: Div] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 {{.*}} i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Div] float [[VP0:%.*]] = hir-copy float [[VP_RED_INIT]] , OriginPhiId: 0
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div] float [[VP1:%.*]] = phi  [ float [[VP0]], [[BB1]] ],  [ float [[VP2:%.*]], [[BB3]] ]
; CHECK-NEXT:     [DA: Div] i64 [[VP3:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP4:%.*]], [[BB3]] ]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP5:%.*]], [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: Div] float* [[VP_SUBSCRIPT:%.*]] = subscript inbounds float* [[ARR20:%.*]] i64 [[VP3]]
; CHECK-NEXT:       [DA: Div] float [[VP_LOAD:%.*]] = load float* [[VP_SUBSCRIPT]]
; CHECK-NEXT:       [DA: Div] float [[VP6:%.*]] = hir-copy float [[VP_LOAD]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] float [[VP7:%.*]] = hir-copy float [[VP6]] , OriginPhiId: 1
; CHECK-NEXT:       [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: Div] float* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds float* [[ARR10:%.*]] i64 [[VP3]]
; CHECK-NEXT:       [DA: Div] float [[VP_LOAD_1:%.*]] = load float* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:       [DA: Div] float [[VP8:%.*]] = hir-copy float [[VP_LOAD_1]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] float [[VP9:%.*]] = hir-copy float [[VP8]] , OriginPhiId: 1
; CHECK-NEXT:       [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB4]], [[BB5]]
; CHECK-NEXT:     [DA: Div] float [[VP10:%.*]] = phi  [ float [[VP9]], [[BB4]] ],  [ float [[VP7]], [[BB5]] ]
; CHECK-NEXT:     [DA: Div] float [[VP11:%.*]] = fadd float [[VP10]] float [[VP1]]
; CHECK-NEXT:     [DA: Div] i64 [[VP4]] = add i64 [[VP3]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP12:%.*]] = icmp slt i64 [[VP4]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Div] float [[VP2]] = hir-copy float [[VP11]] , OriginPhiId: 0
; CHECK-NEXT:     [DA: Uni] br i1 [[VP12]], [[BB2]], [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni] float [[VP_RED_FINAL:%.*]] = reduction-final{fadd} float [[VP11]] float {{.*}}
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK:       External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP__IND_FINAL]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1   float {{.*}} -> [[VP17:%.*]] = {%red.phi}
; CHECK:       BEGIN REGION { modified }
; CHECK-NEXT:        [[RED_INIT0:%.*]] = 0.000000e+00
; CHECK-NEXT:        [[PHI_TEMP0:%.*]] = [[RED_INIT0]]
; CHECK:             + DO i1 = 0, 99, 4   <DO_LOOP> <auto-vectorized> <novectorize>
; CHECK-NEXT:        |   if ([[N10:%.*]] == 0)
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[DOTVEC50:%.*]] = (<4 x float>*)([[ARR10]])[i1]
; CHECK-NEXT:        |      [[DOTCOPY60:%.*]] = [[DOTVEC50]]
; CHECK-NEXT:        |      [[PHI_TEMP30:%.*]] = [[DOTCOPY60]]
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   else
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[DOTVEC0:%.*]] = (<4 x float>*)([[ARR20]])[i1]
; CHECK-NEXT:        |      [[DOTCOPY20:%.*]] = [[DOTVEC0]]
; CHECK-NEXT:        |      [[PHI_TEMP30]] = [[DOTCOPY20]]
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   [[DOTVEC80:%.*]] = [[PHI_TEMP30]]  +  [[PHI_TEMP0]]
; CHECK-NEXT:        |   [[PHI_TEMP0]] = [[DOTVEC80]]
; CHECK-NEXT:        + END LOOP
; CHECK:             [[RED_PHI0:%.*]] = @llvm.vector.reduce.fadd.v4f32([[RED_PHI0]],  [[DOTVEC80]])
; CHECK:       END REGION
;

entry:
  %tobool = icmp eq i32 %n1, 0
  br label %for.body

for.body:                                         ; preds = %for.inc, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.inc ]
  %red.phi = phi float [0.0, %entry], [%red.add, %for.inc]
  br i1 %tobool, label %if.then, label %if.else

if.then:                                          ; preds = %for.body
  %arrayidx = getelementptr inbounds float, float* %arr1, i64 %indvars.iv
  %ld.true = load float, float* %arrayidx, align 4
  br label %for.inc

if.else:
  %arrayidx2 = getelementptr inbounds float, float* %arr2, i64 %indvars.iv
  %ld.false = load float, float* %arrayidx2, align 4
  br label %for.inc

for.inc:                                          ; preds = %for.body, %if.then
  %merge.phi = phi float [%ld.true, %if.then], [%ld.false, %if.else]
  %red.add = fadd fast float %merge.phi, %red.phi
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 100
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc
  ret void
}

