; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

; Test to check correctness of VPlan pseudo SSA deconstruction transform and
; vector CG for simple if-else construct based on a uniform condition.

; Incoming HIR
;   BEGIN REGION { }
;         %entry.region = @llvm.directive.region.entry(); [ DIR.VPO.AUTO.VEC() ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP>
;         |   if (%n1 == 0)
;         |   {
;         |      %ld.true = (%arr1)[i1];
;         |      %merge.phi = %ld.true;
;         |   }
;         |   else
;         |   {
;         |      %ld.false = (%arr2)[i1];
;         |      %merge.phi = %ld.false;
;         |   }
;         |   %red.phi = %merge.phi  +  %red.phi; <Safe Reduction>
;         + END LOOP
;
;         @llvm.directive.region.exit(%entry.region); [ DIR.VPO.END.AUTO.VEC() ]
;   END REGION


; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -vplan-force-linearization-hir=false -vplan-force-vf=4 -print-after=VPlanDriverHIR -vplan-print-after-ssa-deconstruction -vplan-dump-external-defs-hir=0 -disable-output < %s 2>&1 | FileCheck %s

define void @foo(float* noalias nocapture %arr1, float* noalias nocapture %arr2, i32 %n1) {
; CHECK-LABEL:  VPlan after SSA deconstruction
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:    [[BB0:BB[0-9]+]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; CHECK-NEXT:    no PREDECESSORS
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]:
; CHECK-NEXT:     [DA: Div] float [[VP__RED_INIT:%.*]] = reduction-init float 0.000000e+00
; CHECK-NEXT:     [DA: Div] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]:
; CHECK-NEXT:     [DA: Div] float [[VP0:%.*]] = phi  [ float [[VP__RED_INIT]], [[BB1]] ],  [ float [[VP1:%.*]], [[BB3:BB[0-9]+]] ]
; CHECK-NEXT:     [DA: Div] i64 [[VP2:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP3:%.*]], [[BB3]] ]
; CHECK-NEXT:     [DA: Uni] i1 [[VP4:%.*]] = icmp i32 [[N10:%.*]] i32 0
; CHECK-NEXT:    SUCCESSORS(2):[[BB4:BB[0-9]+]](i1 [[VP4]]), [[BB5:BB[0-9]+]](!i1 [[VP4]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB1]] [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]:
; CHECK-NEXT:       [DA: Div] float* [[VP5:%.*]] = getelementptr inbounds float* [[ARR20:%.*]] i64 [[VP2]]
; CHECK-NEXT:       [DA: Div] float [[VP6:%.*]] = load float* [[VP5]]
; CHECK-NEXT:       [DA: Div] float [[VP7:%.*]] = hir-copy float [[VP6]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] float [[VP8:%.*]] = hir-copy float [[VP0]] , OriginPhiId: 0
; CHECK-NEXT:       [DA: Div] float [[VP9:%.*]] = hir-copy float [[VP7]] , OriginPhiId: 1
; CHECK-NEXT:      SUCCESSORS(1):[[BB3]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]:
; CHECK-NEXT:       [DA: Div] float* [[VP10:%.*]] = getelementptr inbounds float* [[ARR10:%.*]] i64 [[VP2]]
; CHECK-NEXT:       [DA: Div] float [[VP11:%.*]] = load float* [[VP10]]
; CHECK-NEXT:       [DA: Div] float [[VP12:%.*]] = hir-copy float [[VP11]] , OriginPhiId: -1
; CHECK-NEXT:       [DA: Div] float [[VP13:%.*]] = hir-copy float [[VP0]] , OriginPhiId: 0
; CHECK-NEXT:       [DA: Div] float [[VP14:%.*]] = hir-copy float [[VP12]] , OriginPhiId: 1
; CHECK-NEXT:      SUCCESSORS(1):[[BB3]]
; CHECK-NEXT:      PREDECESSORS(1): [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]:
; CHECK-NEXT:     [DA: Div] float [[VP15:%.*]] = phi  [ float [[VP13]], [[BB4]] ],  [ float [[VP8]], [[BB5]] ]
; CHECK-NEXT:     [DA: Div] float [[VP16:%.*]] = phi  [ float [[VP14]], [[BB4]] ],  [ float [[VP9]], [[BB5]] ]
; CHECK-NEXT:     [DA: Div] float [[VP1]] = fadd float [[VP16]] float [[VP15]]
; CHECK-NEXT:     [DA: Div] i64 [[VP3]] = add i64 [[VP2]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP17:%.*]] = icmp i64 [[VP3]] i64 99
; CHECK-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP17]]), [[BB6:BB[0-9]+]](!i1 [[VP17]])
; CHECK-NEXT:    PREDECESSORS(2): [[BB4]] [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]:
; CHECK-NEXT:     [DA: Uni] float [[VP__RED_FINAL:%.*]] = reduction-final{fadd} float [[VP1]] float [[RED_PHI0:%.*]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:    SUCCESSORS(1):[[BB7:BB[0-9]+]]
; CHECK-NEXT:    PREDECESSORS(1): [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]:
; CHECK-NEXT:     <Empty Block>
; CHECK-NEXT:    no SUCCESSORS
; CHECK-NEXT:    PREDECESSORS(1): [[BB6]]
; CHECK-EMPTY:
; CHECK-NEXT:  *** IR Dump After VPlan Vectorization Driver HIR ***
; CHECK-NEXT:  Function: foo
; CHECK-EMPTY:
; CHECK-NEXT:  <0>          BEGIN REGION { modified }
; CHECK-NEXT:  <27>                 [[RED_VAR0:%.*]] = 0.000000e+00
; CHECK-NEXT:  <26>               + DO i1 = 0, 99, 4   <DO_LOOP> <novectorize>
; CHECK-NEXT:  <28>               |   [[BB2]].{{[0-9]+}}:
; CHECK-NEXT:  <29>               |   [[WIDE_CMP_0:%.*]] = [[N10]] == 0
; CHECK-NEXT:  <30>               |   [[UNIFCOND0:%.*]] = extractelement [[WIDE_CMP_0]],  0
; CHECK-NEXT:  <31>               |   if ([[UNIFCOND0]] == 1)
; CHECK-NEXT:  <31>               |   {
; CHECK-NEXT:  <32>               |      goto [[BB4]].{{[0-9]+}}
; CHECK-NEXT:  <31>               |   }
; CHECK-NEXT:  <31>               |   else
; CHECK-NEXT:  <31>               |   {
; CHECK-NEXT:  <33>               |      goto [[BB5]].{{[0-9]+}}
; CHECK-NEXT:  <31>               |   }
; CHECK-NEXT:  <34>               |   [[BB5]].{{[0-9]+}}:
; CHECK-NEXT:  <35>               |   [[LD_FALSE_VEC0:%.*]] = (<4 x float>*)([[ARR20]])[i1]
; CHECK-NEXT:  <36>               |   [[MERGE_PHI_IN1_VEC0:%.*]] = [[LD_FALSE_VEC0]]
; CHECK-NEXT:  <37>               |   [[PHI_TEMP0:%.*]] = [[RED_VAR0]]
; CHECK-NEXT:  <38>               |   [[PHI_TEMP20:%.*]] = [[MERGE_PHI_IN1_VEC0]]
; CHECK-NEXT:  <39>               |   goto [[BB3]].{{[0-9]+}}
; CHECK-NEXT:  <40>               |   [[BB4]].{{[0-9]+}}:
; CHECK-NEXT:  <41>               |   [[LD_TRUE_VEC0:%.*]] = (<4 x float>*)([[ARR10]])[i1]
; CHECK-NEXT:  <42>               |   [[MERGE_PHI_IN1_VEC0]] = [[LD_TRUE_VEC0]]
; CHECK-NEXT:  <43>               |   [[PHI_TEMP0]] = [[RED_VAR0]]
; CHECK-NEXT:  <44>               |   [[PHI_TEMP20]] = [[MERGE_PHI_IN1_VEC0]]
; CHECK-NEXT:  <45>               |   goto [[BB3]].{{[0-9]+}}
; CHECK-NEXT:  <46>               |   [[BB3]].{{[0-9]+}}:
; CHECK-NEXT:  <47>               |   [[RED_VAR0]] = [[PHI_TEMP20]]  +  [[PHI_TEMP0]]
; CHECK-NEXT:  <26>               + END LOOP
; CHECK-NEXT:  <48>                 [[RED_PHI0]] = @llvm.experimental.vector.reduce.v2.fadd.f32.v4f32([[RED_PHI0]],  [[RED_VAR0]])
; CHECK-NEXT:  <0>          END REGION
;


entry:
  %tobool = icmp eq i32 %n1, 0
  br label %for.body

for.body:                                         ; preds = %for.inc, %entry
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.inc ]
  %red.phi = phi float [0.0, %entry], [%red.add, %for.inc]
  br i1 %tobool, label %if.then, label %if.else

if.then:                                          ; preds = %for.body
  %arrayidx = getelementptr inbounds float, float* %arr1, i64 %indvars.iv
  %ld.true = load float, float* %arrayidx, align 4
  br label %for.inc

if.else:
  %arrayidx2 = getelementptr inbounds float, float* %arr2, i64 %indvars.iv
  %ld.false = load float, float* %arrayidx2, align 4
  br label %for.inc

for.inc:                                          ; preds = %for.body, %if.then
  %merge.phi = phi float [%ld.true, %if.then], [%ld.false, %if.else]
  %red.add = fadd fast float %merge.phi, %red.phi
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 100
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc
  ret void
}

