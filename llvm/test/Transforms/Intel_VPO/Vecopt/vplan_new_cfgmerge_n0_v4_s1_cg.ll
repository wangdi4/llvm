; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -vplan-vec-scenario="n0;v4;s1" \
; RUN: -disable-output -vplan-vec \
; RUN: -print-after=vplan-vec \
; RUN: -vplan-enable-peeling %s 2>&1 | FileCheck %s

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024"
target triple = "x86_64-unknown-linux-gnu"

define void @test_store(i64* nocapture %ary, i32 %c) {
;
; CHECK-LABEL: @test_store(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br i1 false, label [[MERGE_BLK17:%.*]], label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i32> poison, i32 [[C:%.*]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB2:%.*]]
; CHECK:       VPlannedBB2:
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB2]] ], [ [[TMP4:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB2]] ], [ [[TMP3:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i64, i64* [[ARY:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[TMP0:%.*]] = sext <4 x i32> [[BROADCAST_SPLAT]] to <4 x i64>
; CHECK-NEXT:    [[TMP1:%.*]] = add <4 x i64> [[TMP0]], [[VEC_PHI]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i64* [[SCALAR_GEP]] to <4 x i64>*
; CHECK-NEXT:    store <4 x i64> [[TMP1]], <4 x i64>* [[TMP2]], align 8, !intel.preferred_alignment !0
; CHECK-NEXT:    [[TMP3]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP4]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    [[TMP5:%.*]] = icmp ult i64 [[TMP4]], 1024
; CHECK-NEXT:    br i1 [[TMP5]], label [[VECTOR_BODY]], label [[VPLANNEDBB4:%.*]], [[LOOP1:!llvm.loop !.*]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    br label [[VPLANNEDBB5:%.*]]
; CHECK:       VPlannedBB5:
; CHECK-NEXT:    br label [[VPLANNEDBB6:%.*]]
; CHECK:       VPlannedBB6:
; CHECK-NEXT:    br i1 true, label [[FINAL_MERGE:%.*]], label [[MERGE_BLK17]]
; CHECK:       merge.blk17:
; CHECK-NEXT:    [[UNI_PHI7:%.*]] = phi i64 [ 1024, [[VPLANNEDBB6]] ], [ 0, [[VPLANNEDBB]] ]
; CHECK-NEXT:    br label [[REMBLK13:%.*]]
; CHECK:       RemBlk13:
; CHECK-NEXT:    br label [[FOR_BODY:%.*]]
; CHECK:       VPlannedBB8:
; CHECK-NEXT:    br label [[FINAL_MERGE]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI9:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[VPLANNEDBB8:%.*]] ], [ 1024, [[VPLANNEDBB6]] ]
; CHECK-NEXT:    br label [[FOR_END:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[UNI_PHI7]], [[REMBLK13]] ], [ [[INDVARS_IV_NEXT]], [[FOR_BODY]] ]
; CHECK-NEXT:    [[PTR:%.*]] = getelementptr inbounds i64, i64* [[ARY]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[CC:%.*]] = sext i32 [[C]] to i64
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[CC]], [[INDVARS_IV]]
; CHECK-NEXT:    store i64 [[ADD]], i64* [[PTR]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i64 [[INDVARS_IV_NEXT]], 1024
; CHECK-NEXT:    br i1 [[CMP]], label [[FOR_BODY]], label [[VPLANNEDBB8]], [[LOOP3:!llvm.loop !.*]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %ptr = getelementptr inbounds i64, i64* %ary, i64 %indvars.iv
  %cc = sext i32 %c to i64
  %add = add i64 %cc, %indvars.iv
  store i64 %add, i64* %ptr, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp ult i64 %indvars.iv.next, 1024
  br i1 %cmp, label %for.body, label %for.end

for.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
