; Test to verify that VPlan vectorizer handles array reduction idioms
; (using array sections) identified in incoming IR.

; C/C++ source
; int foo(int b[1000][1000])
; {
;   int a[1000];
;   int i,j;
; #pragma omp simd reduction(+:a[42:500]) private(j)
;   for (i=0; i<1000; i++) {
;     for (j=42; j<542; j++) {
;       a[j] += b[i][j];
;     }
;   }
;
;   return a[42];
; }

; REQUIRES: asserts
; RUN: opt -passes="vplan-vec" -vplan-force-vf=2 -vplan-print-after-vpentity-instrs -vplan-entities-dump -print-after=vplan-vec -disable-output < %s 2>&1 | FileCheck %s

; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec,print<hir>" -vplan-force-vf=2 -debug-only=HIRLegality -debug-only=vplan-vec -print-after=hir-vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefix=HIRVEC

; RUN: opt -passes=hir-ssa-deconstruction,hir-vplan-vec,hir-optreport-emitter -vplan-force-vf=2 -disable-output -intel-opt-report=high < %s 2>&1 | FileCheck %s --check-prefix=OPTRPTHI

; Array sections with offsets are not supported in HIR path.
; HIRVEC: Non-alloca instruction in reduction clause.
; HIRVEC: VD: Not vectorizing: Cannot prove legality.
; HIRVEC: Function: foo

; OPTRPTHI: remark #15436: loop was not vectorized: HIR: Non-alloca instruction in reduction clause.

define i32 @foo([1000 x [1000 x i32]]* %b) #0 {
; CHECK: VPlan after insertion of VPEntities instructions:
; CHECK: Reduction list
; CHECK:  (+) Start: [500 x i32]* [[A_RED0:%.*]]
; CHECK:   Linked values: [500 x i32]* [[VP_A_RED:%.*]],
; CHECK:  Memory: [500 x i32]* [[A_RED0]]

; CHECK: [500 x i32]* [[VP_A_RED]] = allocate-priv [500 x i32]*, OrigAlign = 16
; CHECK: i32* [[VP_A_RED_GEP_MINUS_OFFSET:%.*]] = getelementptr [500 x i32]* [[VP_A_RED]] i64 0 i64 -42
; CHECK: [1000 x i32]* [[VP_A_RED_GEP_MINUS_OFFSET_BC:%.*]] = bitcast i32* [[VP_A_RED_GEP_MINUS_OFFSET]]
; CHECK: reduction-init-arr i32 0 [500 x i32]* [[VP_A_RED]]
; CHECK: [500 x i32] [[VP_RED_FINAL_ARR:%.*]] = reduction-final-arr{add} [500 x i32]* [[VP_A_RED]] [500 x i32]* [[A_RED0]]
;
; Checks for code generated by LLVM-IR vectorizer.
; CHECK-LABEL: @foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A0:%.*]] = alloca [1000 x i32], align 16
; CHECK-NEXT:    [[A_RED0]] = alloca [500 x i32], align 16
; CHECK-NEXT:    [[A_RED_GEP_MINUS_OFFSET0:%.*]] = getelementptr [500 x i32], [500 x i32]* [[A_RED0]], i64 0, i64 -42
; CHECK:         [[A_RED_VEC0:%.*]] = alloca [2 x [500 x i32]], align 4
; CHECK-NEXT:    [[A_RED_VEC_BC0:%.*]] = bitcast [2 x [500 x i32]]* [[A_RED_VEC0]] to [500 x i32]*
; CHECK-NEXT:    [[A_RED_VEC_BASE_ADDR0:%.*]] = getelementptr [500 x i32], [500 x i32]* [[A_RED_VEC_BC0]], <2 x i32> <i32 0, i32 1>
; CHECK-NEXT:    [[A_RED_VEC_BASE_ADDR_EXTRACT_1_0:%.*]] = extractelement <2 x [500 x i32]*> [[A_RED_VEC_BASE_ADDR0]], i32 1
; CHECK-NEXT:    [[A_RED_VEC_BASE_ADDR_EXTRACT_0_0:%.*]] = extractelement <2 x [500 x i32]*> [[A_RED_VEC_BASE_ADDR0]], i32 0
; CHECK-NEXT:    br label [[DIR_OMP_SIMD_10:%.*]]

; CHECK:       VPlannedBB1:
; CHECK:         [[MM_VECTORGEP0:%.*]] = getelementptr [500 x i32], <2 x [500 x i32]*> [[A_RED_VEC_BASE_ADDR0]], <2 x i64> zeroinitializer, <2 x i64> <i64 -42, i64 -42>
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x i32*> [[MM_VECTORGEP0]] to <2 x [1000 x i32]*>
; CHECK-NEXT:    [[ARR_RED_BASE_ADDR_BC0:%.*]] = bitcast [500 x i32]* [[A_RED_VEC_BASE_ADDR_EXTRACT_0_0]] to i32*
; CHECK-NEXT:    br label [[ARRAY_REDN_INIT_LOOP0:%.*]]

; CHECK:       array.redn.init.loop:
; CHECK-NEXT:    [[CUR_ELEM_IDX0:%.*]] = phi i64 [ 0, [[VPLANNEDBB10:%.*]] ], [ [[NEXT_ELEM_IDX0:%.*]], [[ARRAY_REDN_INIT_LOOP0]] ]
; CHECK-NEXT:    [[CUR_ELEM_PTR0:%.*]] = getelementptr i32, i32* [[ARR_RED_BASE_ADDR_BC0]], i64 [[CUR_ELEM_IDX0]]
; CHECK-NEXT:    store i32 0, i32* [[CUR_ELEM_PTR0]], align 4
; CHECK-NEXT:    [[NEXT_ELEM_IDX0]] = add i64 [[CUR_ELEM_IDX0]], 1
; CHECK-NEXT:    [[INITLOOP_COND0:%.*]] = icmp ult i64 [[NEXT_ELEM_IDX0]], 1000
; CHECK-NEXT:    br i1 [[INITLOOP_COND0]], label [[ARRAY_REDN_INIT_LOOP0]], label [[ARRAY_REDN_INIT_LOOPEXIT0:%.*]]

; CHECK:       array.redn.final.main.loop:
; CHECK-NEXT:    [[MAIN_ELEM_IDX0:%.*]] = phi i64 [ 0, [[VPLANNEDBB140:%.*]] ], [ [[NEXT_MAIN_ELEM_IDX0:%.*]], [[ARRAY_REDN_FINAL_MAIN_LOOP0:%.*]] ]
; CHECK-NEXT:    [[ORIG_ARR_GEP0:%.*]] = getelementptr [500 x i32], [500 x i32]* [[A_RED0]], i64 0, i64 [[MAIN_ELEM_IDX0]]
; CHECK-NEXT:    [[ORIG_ARR_BC0:%.*]] = bitcast i32* [[ORIG_ARR_GEP0]] to <1 x i32>*
; CHECK-NEXT:    [[ORIG_ARR_LD0:%.*]] = load <1 x i32>, <1 x i32>* [[ORIG_ARR_BC0]], align 4
; CHECK-NEXT:    [[PRIV_ARR_GEP_LANE00:%.*]] = getelementptr [500 x i32], [500 x i32]* [[A_RED_VEC_BASE_ADDR_EXTRACT_0_0]], i64 0, i64 [[MAIN_ELEM_IDX0]]
; CHECK-NEXT:    [[PRIV_ARR_BC_LANE00:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE00]] to <1 x i32>*
; CHECK-NEXT:    [[PRIV_ARR_LD_LANE00:%.*]] = load <1 x i32>, <1 x i32>* [[PRIV_ARR_BC_LANE00]], align 4
; CHECK-NEXT:    [[ARR_FIN_RED0:%.*]] = add <1 x i32> [[ORIG_ARR_LD0]], [[PRIV_ARR_LD_LANE00]]
; CHECK-NEXT:    [[PRIV_ARR_GEP_LANE10:%.*]] = getelementptr [500 x i32], [500 x i32]* [[A_RED_VEC_BASE_ADDR_EXTRACT_1_0]], i64 0, i64 [[MAIN_ELEM_IDX0]]
; CHECK-NEXT:    [[PRIV_ARR_BC_LANE10:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE10]] to <1 x i32>*
; CHECK-NEXT:    [[PRIV_ARR_LD_LANE10:%.*]] = load <1 x i32>, <1 x i32>* [[PRIV_ARR_BC_LANE10]], align 4
; CHECK-NEXT:    [[ARR_FIN_RED150:%.*]] = add <1 x i32> [[ARR_FIN_RED0]], [[PRIV_ARR_LD_LANE10]]
; CHECK-NEXT:    store <1 x i32> [[ARR_FIN_RED150]], <1 x i32>* [[ORIG_ARR_BC0]], align 4
; CHECK-NEXT:    [[NEXT_MAIN_ELEM_IDX0]] = add i64 [[MAIN_ELEM_IDX0]], 1
; CHECK-NEXT:    [[FINAL_MAINLOOP_COND0:%.*]] = icmp ult i64 [[NEXT_MAIN_ELEM_IDX0]], 500
; CHECK-NEXT:    br i1 [[FINAL_MAINLOOP_COND0]], label [[ARRAY_REDN_FINAL_MAIN_LOOP0]], label [[ARRAY_REDN_FINAL_REM_LOOP0:%.*]]
;
entry:
  %a = alloca [1000 x i32], align 16
  %a.red = alloca [500 x i32], align 16
  %a.red.gep.minus.offset = getelementptr [500 x i32], [500 x i32]* %a.red, i64 0, i64 -42
  %a.red.bc = bitcast [500 x i32]* %a.red to i8*
  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 16 dereferenceable(2000) %a.red.bc, i8 0, i64 2000, i1 false)
  %a.bc = bitcast [1000 x i32]* %a to i8*
  call void @llvm.memset.p0i8.i64(i8* noundef nonnull align 16 dereferenceable(4000) %a.bc, i8 0, i64 4000, i1 false)
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:
  %a.red.gep.minus.offset.bc = bitcast i32* %a.red.gep.minus.offset to [1000 x i32]*
  br label %DIR.OMP.SIMD.170

DIR.OMP.SIMD.170:                                 ; preds = %DIR.OMP.SIMD.1
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.TYPED"([1000 x i32]* %a.red.gep.minus.offset.bc, i64 0, i64 500, i64 42) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.170, %omp.inner.for.latch
  %indvars.iv59 = phi i64 [ 0, %DIR.OMP.SIMD.170 ], [ %indvars.iv.next60, %omp.inner.for.latch ]
  br label %mem.guard.begin

mem.guard.begin:                                  ; preds = %omp.inner.for.body
  %guard.start = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"([1000 x i32]* %a.red.gep.minus.offset.bc) ]
  br label %for.body15

for.body15:                                       ; preds = %mem.guard.begin, %for.body15
  %indvars.iv = phi i64 [ 42, %mem.guard.begin ], [ %indvars.iv.next, %for.body15 ]
  %arrayidx19 = getelementptr inbounds [1000 x [1000 x i32]], [1000 x [1000 x i32]]* %b, i64 0, i64 %indvars.iv59, i64 %indvars.iv
  %b.ld = load i32, i32* %arrayidx19, align 4
  %arrayidx21 = getelementptr inbounds [1000 x i32], [1000 x i32]* %a.red.gep.minus.offset.bc, i64 0, i64 %indvars.iv
  %a.ld = load i32, i32* %arrayidx21, align 4
  %add22 = add nsw i32 %a.ld, %b.ld
  store i32 %add22, i32* %arrayidx21, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 542
  br i1 %exitcond.not, label %omp.inner.for.inc, label %for.body15

omp.inner.for.inc:                                ; preds = %for.body15
  %indvars.iv.next60 = add nuw nsw i64 %indvars.iv59, 1
  br label %mem.guard.end

mem.guard.end:                                    ; preds = %omp.inner.for.inc
  call void @llvm.directive.region.exit(token %guard.start) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
  br label %omp.inner.for.latch

omp.inner.for.latch:                              ; preds = %mem.guard.end
  %exitcond61.not = icmp eq i64 %indvars.iv.next60, 100
  br i1 %exitcond61.not, label %DIR.OMP.END.SIMD.2, label %omp.inner.for.body

DIR.OMP.END.SIMD.2:                               ; preds = %omp.inner.for.inc
  br label %DIR.OMP.END.SIMD.271

DIR.OMP.END.SIMD.271:                             ; preds = %DIR.OMP.END.SIMD.2
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %DIR.OMP.END.SIMD.271
  ret i32 0
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg)
