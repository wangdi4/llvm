; Test to verify that VPlan vectorizer handles min/max array reduction
; idioms identified in incoming IR.

; C/C++ source
; int test(int init, int n, int *A)
; {
;   int min[9];
;   for (int i = 0; i < 9; i++)
;     min[i] = init;
;
;   #pragma omp simd simdlen(2) reduction(min:min)
;   for (int l1 = 0; l1 < n; l1++) {
;     min[l1] = larr[l1] < A[l1] ? larr[l1] : A[l1];
;   }
;
;   return min[9];
; }

; RUN: opt -opaque-pointers=0 -passes=vplan-vec -vplan-force-vf=2 -vplan-print-after-vpentity-instrs -vplan-entities-dump -print-after=vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,IR
; RUN: opt -opaque-pointers=0 -passes='hir-ssa-deconstruction,hir-vplan-vec,print<hir>' -vplan-force-vf=2 -vplan-print-after-vpentity-instrs -vplan-entities-dump -disable-output < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,HIR

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define i32 @test(i32* nocapture readonly %A, i64 %N, i32 %init) {
; CHECK: VPlan after insertion of VPEntities instructions:
; CHECK: Reduction list
; CHECK:  (SIntMin) Start: [9 x i32]* %min
; CHECK:   Linked values: [9 x i32]* [[VPMINALLOCA:%.*]],
; CHECK:  Memory: [9 x i32]* %min

; CHECK: [9 x i32]* [[VPMINALLOCA]] = allocate-priv [9 x i32]*, OrigAlign = 4
; CHECK: reduction-init-arr i32 2147483647 [9 x i32]* [[VPMINALLOCA]]
; CHECK: [9 x i32] [[VPMINFIN:%.*]] = reduction-final-arr{smin} [9 x i32]* [[VPMINALLOCA]] [9 x i32]* %min

; Checks for code generated by LLVM-IR vectorizer.
; IR-LABEL: @test(
; IR-NEXT:  entry:
; IR-NEXT:    [[MIN:%.*]] = alloca [9 x i32], align 4
; IR-NEXT:    [[MIN_VEC:%.*]] = alloca [2 x [9 x i32]], align 4
; IR-NEXT:    [[MIN_VEC_BC:%.*]] = bitcast [2 x [9 x i32]]* [[MIN_VEC]] to [9 x i32]*
; IR-NEXT:    [[MIN_VEC_BASE_ADDR:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN_VEC_BC]], <2 x i32> <i32 0, i32 1>
; IR-NEXT:    [[MIN_VEC_BASE_ADDR_EXTRACT_1_:%.*]] = extractelement <2 x [9 x i32]*> [[MIN_VEC_BASE_ADDR]], i32 1
; IR-NEXT:    [[MIN_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <2 x [9 x i32]*> [[MIN_VEC_BASE_ADDR]], i32 0
; IR-NEXT:    br label [[FILL_MIN:%.*]]

; IR:       VPlannedBB2:
; IR:         [[ARR_RED_BASE_ADDR_BC:%.*]] = bitcast [9 x i32]* [[MIN_VEC_BASE_ADDR_EXTRACT_0_]] to i32*
; IR-NEXT:    br label [[ARRAY_REDN_INIT_LOOP:%.*]]
; IR:       array.redn.init.loop:
; IR-NEXT:    [[CUR_ELEM_IDX:%.*]] = phi i64 [ 0, [[VPLANNEDBB2:%.*]] ], [ [[NEXT_ELEM_IDX:%.*]], [[ARRAY_REDN_INIT_LOOP]] ]
; IR-NEXT:    [[CUR_ELEM_PTR:%.*]] = getelementptr i32, i32* [[ARR_RED_BASE_ADDR_BC]], i64 [[CUR_ELEM_IDX]]
; IR-NEXT:    store i32 2147483647, i32* [[CUR_ELEM_PTR]], align 4
; IR-NEXT:    [[NEXT_ELEM_IDX]] = add i64 [[CUR_ELEM_IDX]], 1
; IR-NEXT:    [[INITLOOP_COND:%.*]] = icmp ult i64 [[NEXT_ELEM_IDX]], 18
; IR-NEXT:    br i1 [[INITLOOP_COND]], label [[ARRAY_REDN_INIT_LOOP]], label [[ARRAY_REDN_INIT_LOOPEXIT:%.*]]

; IR:       array.redn.final.main.loop:
; IR-NEXT:    [[MAIN_ELEM_IDX:%.*]] = phi i64 [ 0, [[VPLANNEDBB4:%.*]] ], [ [[NEXT_MAIN_ELEM_IDX:%.*]], [[ARRAY_REDN_FINAL_MAIN_LOOP:%.*]] ]
; IR-NEXT:    [[ORIG_ARR_GEP:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[ORIG_ARR_BC:%.*]] = bitcast i32* [[ORIG_ARR_GEP]] to <4 x i32>*
; IR-NEXT:    [[ORIG_ARR_LD:%.*]] = load <4 x i32>, <4 x i32>* [[ORIG_ARR_BC]], align 4
; IR-NEXT:    [[PRIV_ARR_GEP_LANE0:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN_VEC_BASE_ADDR_EXTRACT_0_]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_BC_LANE0:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE0]] to <4 x i32>*
; IR-NEXT:    [[PRIV_ARR_LD_LANE0:%.*]] = load <4 x i32>, <4 x i32>* [[PRIV_ARR_BC_LANE0]], align 4
; IR-NEXT:    [[ARR_FIN_RED:%.*]] = call <4 x i32> @llvm.smin.v4i32(<4 x i32> [[ORIG_ARR_LD]], <4 x i32> [[PRIV_ARR_LD_LANE0]])
; IR-NEXT:    [[PRIV_ARR_GEP_LANE1:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN_VEC_BASE_ADDR_EXTRACT_1_]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_BC_LANE1:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE1]] to <4 x i32>*
; IR-NEXT:    [[PRIV_ARR_LD_LANE1:%.*]] = load <4 x i32>, <4 x i32>* [[PRIV_ARR_BC_LANE1]], align 4
; IR-NEXT:    [[ARR_FIN_RED5:%.*]] = call <4 x i32> @llvm.smin.v4i32(<4 x i32> [[ARR_FIN_RED]], <4 x i32> [[PRIV_ARR_LD_LANE1]])
; IR-NEXT:    store <4 x i32> [[ARR_FIN_RED5]], <4 x i32>* [[ORIG_ARR_BC]], align 4
; IR-NEXT:    [[NEXT_MAIN_ELEM_IDX]] = add i64 [[MAIN_ELEM_IDX]], 4
; IR-NEXT:    [[FINAL_MAINLOOP_COND:%.*]] = icmp ult i64 [[NEXT_MAIN_ELEM_IDX]], 8
; IR-NEXT:    br i1 [[FINAL_MAINLOOP_COND]], label [[ARRAY_REDN_FINAL_MAIN_LOOP]], label [[ARRAY_REDN_FINAL_REM_LOOP:%.*]]
; IR:       array.redn.final.rem.loop:
; IR-NEXT:    [[REM_ELEM_IDX:%.*]] = phi i64 [ 8, [[ARRAY_REDN_FINAL_MAIN_LOOP]] ], [ [[NEXT_REM_ELEM_IDX:%.*]], [[ARRAY_REDN_FINAL_REM_LOOP]] ]
; IR-NEXT:    [[ORIG_ARR_GEP6:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN]], i64 0, i64 [[REM_ELEM_IDX]]
; IR-NEXT:    [[ORIG_ARR_LD7:%.*]] = load i32, i32* [[ORIG_ARR_GEP6]], align 4
; IR-NEXT:    [[PRIV_ARR_GEP_LANE08:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN_VEC_BASE_ADDR_EXTRACT_0_]], i64 0, i64 [[REM_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_LD_LANE09:%.*]] = load i32, i32* [[PRIV_ARR_GEP_LANE08]], align 4
; IR-NEXT:    [[ARR_FIN_RED10:%.*]] = call i32 @llvm.smin.i32(i32 [[ORIG_ARR_LD7]], i32 [[PRIV_ARR_LD_LANE09]])
; IR-NEXT:    [[PRIV_ARR_GEP_LANE111:%.*]] = getelementptr [9 x i32], [9 x i32]* [[MIN_VEC_BASE_ADDR_EXTRACT_1_]], i64 0, i64 [[REM_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_LD_LANE112:%.*]] = load i32, i32* [[PRIV_ARR_GEP_LANE111]], align 4
; IR-NEXT:    [[ARR_FIN_RED13:%.*]] = call i32 @llvm.smin.i32(i32 [[ARR_FIN_RED10]], i32 [[PRIV_ARR_LD_LANE112]])
; IR-NEXT:    store i32 [[ARR_FIN_RED13]], i32* [[ORIG_ARR_GEP6]], align 4
; IR-NEXT:    [[NEXT_REM_ELEM_IDX]] = add i64 [[REM_ELEM_IDX]], 1
; IR-NEXT:    [[FINAL_REMLOOP_COND:%.*]] = icmp ult i64 [[NEXT_REM_ELEM_IDX]], 9
; IR-NEXT:    br i1 [[FINAL_REMLOOP_COND]], label [[ARRAY_REDN_FINAL_REM_LOOP]], label [[ARRAY_REDN_FINAL_EXIT:%.*]]
;
; Checks for code generated by HIR vectorizer.
; HIR-LABEL: Function: test
; HIR:           BEGIN REGION { modified }
; HIR:                %arr.red.base.addr.bc = bitcast.[9 x i32]*.i32*(&(([9 x i32]*)(%priv.mem)[0]));
; HIR:                 + DO i1 = 0, 17, 1   <DO_LOOP>
; HIR-NEXT:            |   (i32*)(%arr.red.base.addr.bc)[i1] = 2147483647;
; HIR-NEXT:            + END LOOP

; HIR:                 %extract.1. = extractelement &((<2 x [9 x i32]*>)(%priv.mem.bc)[<i32 0, i32 1>]),  1;
; HIR-NEXT:            %priv.arr.copy0 = &(([9 x i32]*)(%priv.mem)[0]);
; HIR:                 + DO i1 = 0, 7, 4   <DO_LOOP>
; HIR-NEXT:            |   %orig.arr.ld = (<4 x i32>*)(%min)[0][i1];
; HIR-NEXT:            |   %priv.arr.ld.lane0 = (<4 x i32>*)(%priv.arr.copy0)[0][i1];
; HIR-NEXT:            |   %arr.fin.red = @llvm.smin.v4i32(%orig.arr.ld,  %priv.arr.ld.lane0);
; HIR-NEXT:            |   %priv.arr.ld.lane1 = (<4 x i32>*)(%extract.1.)[0][i1];
; HIR-NEXT:            |   %arr.fin.red8 = @llvm.smin.v4i32(%arr.fin.red,  %priv.arr.ld.lane1);
; HIR-NEXT:            |   (<4 x i32>*)(%min)[0][i1] = %arr.fin.red8;
; HIR-NEXT:            + END LOOP

; HIR:                 %extract.1.13 = extractelement &((<2 x [9 x i32]*>)(%priv.mem.bc)[<i32 0, i32 1>]),  1;
; HIR-NEXT:            %priv.arr.copy010 = &(([9 x i32]*)(%priv.mem)[0]);
; HIR:                 + DO i1 = 8, 8, 1   <DO_LOOP>
; HIR-NEXT:            |   %orig.arr.ld9 = (i32*)(%min)[0][i1];
; HIR-NEXT:            |   %priv.arr.ld.lane011 = (i32*)(%priv.arr.copy010)[0][i1];
; HIR-NEXT:            |   %arr.fin.red12 = @llvm.smin.i32(%orig.arr.ld9,  %priv.arr.ld.lane011);
; HIR-NEXT:            |   %priv.arr.ld.lane114 = (i32*)(%extract.1.13)[0][i1];
; HIR-NEXT:            |   %arr.fin.red15 = @llvm.smin.i32(%arr.fin.red12,  %priv.arr.ld.lane114);
; HIR-NEXT:            |   (i32*)(%min)[0][i1] = %arr.fin.red15;
; HIR-NEXT:            + END LOOP
; HIR:           END REGION
;
entry:
  %min = alloca [9 x i32], align 4
  br label %fill.min

fill.min:
  %arr.begin = getelementptr inbounds [9 x i32], [9 x i32]* %min, i32 0, i32 0
  %arr.end = getelementptr i32, i32* %arr.begin, i32 9
  %red.init.isempty = icmp eq i32* %arr.begin, %arr.end
  br i1 %red.init.isempty, label %begin.simd.1, label %red.init.body

red.init.body:
  %red.curr.ptr = phi i32* [ %arr.begin, %fill.min ], [ %red.next.ptr, %red.init.body ]
  store i32 %init, i32* %red.curr.ptr, align 4
  %red.next.ptr = getelementptr inbounds i32, i32* %red.curr.ptr, i32 1
  %red.init.done = icmp eq i32* %red.next.ptr, %arr.end
  br i1 %red.init.done, label %begin.simd.1, label %red.init.body

begin.simd.1:
  br label %begin.simd

begin.simd:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.MIN:TYPED"([9 x i32]* %min, i32 0, i32 9) ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %begin.simd ]
  %arrayidx = getelementptr inbounds i32, i32* %A, i64 %indvars.iv
  %A.i = load i32, i32* %arrayidx, align 4
  %min.gep = getelementptr inbounds [9 x i32], [9 x i32]* %min, i64 0, i64 %indvars.iv
  %min.ld = load i32, i32* %min.gep, align 4
  %cmp = icmp slt i32 %A.i, %min.ld
  %select = select i1 %cmp, i32 %A.i, i32 %min.ld
  store i32 %select, i32* %min.gep, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp slt i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.body, label %for.cond.cleanup.loopexit

for.cond.cleanup.loopexit:                             ; preds = %for.body
  br label %end.simd

end.simd:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:
  %fin.gep = getelementptr inbounds [9 x i32], [9 x i32]* %min, i32 0, i32 9
  %fin = load i32, i32* %fin.gep, align 4
  ret i32 %fin

}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

