; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt %s -vplan-vec -mtriple=x86_64-unknown-linux-gnu -mcpu=skylake-avx512 -S | FileCheck %s

define void @foo(i32* nocapture readonly %c, void (i32)** nocapture readonly %func) #0 {
; CHECK:  define void @foo(i32* nocapture readonly [[C0:%.*]], void (i32)** nocapture readonly [[FUNC0:%.*]]) #0 {
; CHECK-NEXT:  simd.begin.region:
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  simd.loop.preheader:
; CHECK-NEXT:    br label [[VPLANNEDBB0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB1:
; CHECK-NEXT:    br i1 false, label [[SCALAR_PH0:%.*]], label [[VECTOR_PH0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.ph:
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i32 [ 0, [[VECTOR_PH0]] ], [ [[TMP6:%.*]], [[VPLANNEDBB50:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <16 x i32> [ <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>, [[VECTOR_PH0]] ], [ [[TMP5:%.*]], [[VPLANNEDBB50]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds void (i32)*, void (i32)** [[FUNC0]], i32 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast void (i32)** [[SCALAR_GEP0]] to <16 x void (i32)*>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <16 x void (i32)*>, <16 x void (i32)*>* [[TMP0]], align 8
; CHECK-NEXT:    [[SCALAR_GEP30:%.*]] = getelementptr inbounds i32, i32* [[C0]], i32 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i32* [[SCALAR_GEP30]] to <16 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD40:%.*]] = load <16 x i32>, <16 x i32>* [[TMP1]], align 4
; CHECK-NEXT:    br label [[INDIRECT_CALL_LOOP_ENTRY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.entry:
; CHECK-NEXT:    [[VECTOR_OF_FUNC_PTRS0:%.*]] = phi <16 x void (i32)*> [ [[WIDE_LOAD0]], [[VECTOR_BODY0]] ], [ [[CURRENT_VECTOR_OF_FUNC_PTRS0:%.*]], [[INDIRECT_CALL_LOOP_LATCH0:%.*]] ]
; CHECK-NEXT:    [[INDX0:%.*]] = phi i64 [ 0, [[VECTOR_BODY0]] ], [ [[INDX_UPDATED0:%.*]], [[INDIRECT_CALL_LOOP_LATCH0]] ]
; CHECK-NEXT:    [[CURRENT_FPTR0:%.*]] = extractelement <16 x void (i32)*> [[VECTOR_OF_FUNC_PTRS0]], i64 [[INDX0]]
; CHECK-NEXT:    [[IS_VISITED0:%.*]] = icmp eq void (i32)* [[CURRENT_FPTR0]], null
; CHECK-NEXT:    br i1 [[IS_VISITED0]], label [[INDIRECT_CALL_LOOP_LATCH0]], label [[VECTOR_INDIRECT_CALL0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.indirect.call:
; CHECK-NEXT:    [[CURRENT_FPTR_SPLATINSERT0:%.*]] = insertelement <16 x void (i32)*> poison, void (i32)* [[CURRENT_FPTR0]], i32 0
; CHECK-NEXT:    [[CURRENT_FPTR_SPLAT0:%.*]] = shufflevector <16 x void (i32)*> [[CURRENT_FPTR_SPLATINSERT0]], <16 x void (i32)*> poison, <16 x i32> zeroinitializer
; CHECK-NEXT:    [[FUNC_PTR_MASK0:%.*]] = icmp eq <16 x void (i32)*> [[CURRENT_FPTR_SPLAT0]], [[VECTOR_OF_FUNC_PTRS0]]
; CHECK-NEXT:    [[MASKEXT0:%.*]] = sext <16 x i1> [[FUNC_PTR_MASK0]] to <16 x i32>
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast void (i32)* [[CURRENT_FPTR0]] to void (<16 x i32>, <16 x i32>)**
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr void (<16 x i32>, <16 x i32>)*, void (<16 x i32>, <16 x i32>)** [[TMP2]], i32 0
; CHECK-NEXT:    [[TMP4:%.*]] = load void (<16 x i32>, <16 x i32>)*, void (<16 x i32>, <16 x i32>)** [[TMP3]], align 8
; CHECK-NEXT:    call void [[TMP4]](<16 x i32> [[WIDE_LOAD40]], <16 x i32> [[MASKEXT0]])
; CHECK-NEXT:    [[VECTOR_OF_FUNC_PTRS_UPDATED0:%.*]] = select <16 x i1> [[FUNC_PTR_MASK0]], <16 x void (i32)*> zeroinitializer, <16 x void (i32)*> [[VECTOR_OF_FUNC_PTRS0]]
; CHECK-NEXT:    br label [[INDIRECT_CALL_LOOP_LATCH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.latch:
; CHECK-NEXT:    [[CURRENT_VECTOR_OF_FUNC_PTRS0]] = phi <16 x void (i32)*> [ [[VECTOR_OF_FUNC_PTRS_UPDATED0]], [[VECTOR_INDIRECT_CALL0]] ], [ [[VECTOR_OF_FUNC_PTRS0]], [[INDIRECT_CALL_LOOP_ENTRY0]] ]
; CHECK-NEXT:    [[INDX_UPDATED0]] = add i64 [[INDX0]], 1
; CHECK-NEXT:    [[EXITCOND0:%.*]] = icmp eq i64 [[INDX_UPDATED0]], 16
; CHECK-NEXT:    br i1 [[EXITCOND0]], label [[INDIRECT_CALL_LOOP_EXIT0:%.*]], label [[INDIRECT_CALL_LOOP_ENTRY0]]
; CHECK-EMPTY:
; CHECK-NEXT:  indirect.call.loop.exit:
; CHECK-NEXT:    br label [[VPLANNEDBB50]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[TMP5]] = add nuw <16 x i32> [[VEC_PHI0]], <i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16, i32 16>
; CHECK-NEXT:    [[TMP6]] = add nuw i32 [[UNI_PHI0]], 16
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ult i32 [[TMP6]], 16
; CHECK-NEXT:    br i1 false, label [[VECTOR_BODY0]], label [[VPLANNEDBB60:%.*]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
simd.begin.region:
  %entry.region1 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.exit ]
  %arrayidx1 = getelementptr inbounds void (i32)*, void (i32)** %func, i32 %index
  %ld.func = load void (i32)*, void (i32)** %arrayidx1, align 8
  %arrayidx2 = getelementptr inbounds i32, i32* %c, i32 %index
  %ld.c = load i32, i32* %arrayidx2, align 4
  call void (void (i32) *, i32, ...) @__intel_indirect_call.2(void (i32)* %ld.func, i32 %ld.c) #1
  br label %simd.loop.exit

simd.loop.exit:
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 16
  br i1 %vl.cond, label %simd.loop, label %simd.end.region

simd.end.region:
  call void @llvm.directive.region.exit(token %entry.region1) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

declare void @__intel_indirect_call.2(void (i32) *, i32, ...)

attributes #0 = { "prefer-vector-width"="512" }
attributes #1 = { "vector-variants"="_ZGVeM16v___intel_indirect_call_XXX,_ZGVeN16v___intel_indirect_call_XXX" }
