; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to check that we don't allow using a non-induction recurrency to calculate unconditional last private.
;
; RUN: opt -disable-output -vplan-vec -vplan-force-vf=4 -vplan-print-after-plain-cfg  -debug-only=vploop-analysis -disable-vplan-codegen %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: mustprogress nounwind uwtable
define dso_local i32 @_Z3fooPiS_(i32* nocapture readonly %a, i32* nocapture readonly %b) local_unnamed_addr #0 {

; CHECK-LABEL:  VPlan after importing plain CFG:
; CHECK-NEXT:  VPlan IR for: _Z3fooPiS_:omp.inner.for.body.#{{[0-9]+}}
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:     i32 [[VP0:%.*]] = phi  [ i32 [[S_RED_PROMOTED0:%.*]], [[BB1]] ],  [ i32 [[VP_ADD1:%.*]], [[BB3]] ]
; CHECK-NEXT:     i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     i32 [[VP1:%.*]] = load i32* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i32 [[VP_ADD1]] = add i32 [[VP0]] i32 [[VP1]]
; CHECK-NEXT:     i32* [[VP_ARRAYIDX3:%.*]] = getelementptr inbounds i32* [[B0:%.*]] i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     i32 [[VP2:%.*]] = load i32* [[VP_ARRAYIDX3]]
; CHECK-NEXT:     i1 [[VP_CMP4:%.*]] = icmp sgt i32 [[VP2]] i32 [[VP_ADD1]]
; CHECK-NEXT:     br i1 [[VP_CMP4]], [[BB4:BB[0-9]+]], [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:       i64 [[VP3:%.*]] = add i64 [[VP_INDVARS_IV]] i64 -1
; CHECK-NEXT:       i32* [[VP_ARRAYIDX6:%.*]] = getelementptr inbounds i32* [[B0]] i64 [[VP3]]
; CHECK-NEXT:       i32 [[VP4:%.*]] = load i32* [[VP_ARRAYIDX6]]
; CHECK-NEXT:       i32 [[VP_MUL7:%.*]] = mul i32 [[VP4]] i32 [[VP_ADD1]]
; CHECK-NEXT:       br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]], [[BB4]]
; CHECK-NEXT:     i32 [[VP_COND:%.*]] = phi  [ i32 [[VP_MUL7]], [[BB4]] ],  [ i32 [[VP1]], [[BB2]] ]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 1
; CHECK-NEXT:     i1 [[VP_EXITCOND_NOT:%.*]] = icmp eq i64 [[VP_INDVARS_IV_NEXT]] i64 103
; CHECK-NEXT:     br i1 [[VP_EXITCOND_NOT]], [[BB5:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB3]]
; CHECK-NEXT:     br [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB5]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0     [[ADD1_LCSSA0:%.*]] = phi i32 [ [[ADD10:%.*]], [[COND_END0:%.*]] ] i32 [[VP_ADD1]] -> i32 [[ADD10]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1     [[COND_LCSSA0:%.*]] = phi i32 [ [[COND0:%.*]], [[COND_END0]] ] i32 [[VP_COND]] -> i32 [[COND0]]
;
; CHECK:       Incorrect recurrent operand of unconditional private:
; CHECK-NEXT:  i32 [[VP0]] = phi  [ i32 [[S_RED_PROMOTED0]], [[BB1]] ],  [ i32 [[VP_ADD1]], [[BB3]] ]
;
DIR.OMP.SIMD.136:
  %s.red = alloca i32, align 4
  %v.lpriv = alloca i32, align 4
  %i.linear.iv = alloca i32, align 4
  store i32 0, i32* %s.red, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.136
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LASTPRIVATE:TYPED"(i32* %v.lpriv, i32 0, i32 1), "QUAL.OMP.REDUCTION.ADD:TYPED"(i32* %s.red, i32 0, i32 1), "QUAL.OMP.LINEAR:IV.TYPED"(i32* %i.linear.iv, i32 0, i32 1, i32 1) ]
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.1
  %1 = bitcast i32* %i.linear.iv to i8*
  %s.red.promoted = load i32, i32* %s.red, align 4
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.2, %cond.end
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.2 ], [ %indvars.iv.next, %cond.end ]
  %2 = phi i32 [ %s.red.promoted, %DIR.OMP.SIMD.2 ], [ %add1, %cond.end ]
  %arrayidx = getelementptr inbounds i32, i32* %a, i64 %indvars.iv
  %3 = load i32, i32* %arrayidx, align 4
  %add1 = add nsw i32 %2, %3
  %arrayidx3 = getelementptr inbounds i32, i32* %b, i64 %indvars.iv
  %4 = load i32, i32* %arrayidx3, align 4
  %cmp4 = icmp sgt i32 %4, %add1
  br i1 %cmp4, label %cond.true, label %cond.end

cond.true:                                        ; preds = %omp.inner.for.body
  %5 = add nsw i64 %indvars.iv, -1
  %arrayidx6 = getelementptr inbounds i32, i32* %b, i64 %5
  %6 = load i32, i32* %arrayidx6, align 4
  %mul7 = mul nsw i32 %6, %add1
  br label %cond.end

cond.end:                                         ; preds = %omp.inner.for.body, %cond.true
  %cond = phi i32 [ %mul7, %cond.true ], [ %3, %omp.inner.for.body ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 103
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.237, label %omp.inner.for.body

DIR.OMP.END.SIMD.237:                             ; preds = %cond.end
  %cond.lcssa = phi i32 [ %cond, %cond.end ]
  %add1.lcssa = phi i32 [ %add1, %cond.end ]
  store i32 %cond.lcssa, i32* %v.lpriv
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %DIR.OMP.END.SIMD.237
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.4

DIR.OMP.END.SIMD.4:                               ; preds = %DIR.OMP.END.SIMD.3
  %add11 = add nsw i32 %cond.lcssa, %add1.lcssa
  ret i32 %add11
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)


