; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Test to check that VPlan vectorizer legality recognizes explicit reductions with stores to the
; reduction variable inside the loop and a loop invariant load for starting value, while reduction
; is performed in register (using PHI node).

; RUN: opt -passes=vplan-vec -S < %s | FileCheck %s

define float @load_store_reduction_add(ptr nocapture %a) {
; CHECK-LABEL: @load_store_reduction_add(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X:%.*]] = alloca float, align 4
; CHECK-NEXT:    store float 2.000000e+00, ptr [[X]], align 4
; CHECK-NEXT:    [[X_VEC:%.*]] = alloca <8 x float>, align 32
; CHECK-NEXT:    [[X_VEC_BASE_ADDR:%.*]] = getelementptr float, ptr [[X_VEC]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
; CHECK-NEXT:    [[X_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <8 x ptr> [[X_VEC_BASE_ADDR]], i32 0
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VECTOR_PH:%.*]] ], [ [[TMP4:%.*]], [[VECTOR_BODY:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <8 x i64> [ <i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7>, [[VECTOR_PH]] ], [ [[TMP3:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI3:%.*]] = phi <8 x float> [ zeroinitializer, [[VECTOR_PH]] ], [ [[TMP2:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <8 x float>, ptr [[SCALAR_GEP]], align 4
; CHECK-NEXT:    [[TMP2]] = fadd fast <8 x float> [[VEC_PHI3]], [[WIDE_LOAD]]
; CHECK-NEXT:    store <8 x float> [[TMP2]], ptr [[X_VEC]], align 4
; CHECK-NEXT:    [[TMP3]] = add nuw nsw <8 x i64> [[VEC_PHI]], <i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8, i64 8>
; CHECK-NEXT:    [[TMP4]] = add nuw nsw i64 [[UNI_PHI]], 8
; CHECK-NEXT:    [[TMP5:%.*]] = icmp uge i64 [[TMP4]], 1000
; CHECK-NEXT:    br i1 [[TMP5]], label [[VPLANNEDBB4:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    [[TMP6:%.*]] = call fast float @llvm.vector.reduce.fadd.v8f32(float [[X_PROMOTED:%.*]], <8 x float> [[TMP2]])
; CHECK-NEXT:    store float [[TMP6]], ptr [[X:%.*]], align 1
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 32, ptr [[X_VEC_BASE_ADDR_EXTRACT_0_]])

;
entry:
  %x = alloca float, align 4
  store float 2.000000e+00, ptr %x, align 4
  br label %entry.split

entry.split:                                      ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 8), "QUAL.OMP.REDUCTION.ADD:TYPED"(ptr %x, float zeroinitializer, i32 1) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %entry.split
  %x.promoted = load float, ptr %x, align 4
  br label %for.body

for.body:                                         ; preds = %for.body, %DIR.QUAL.LIST.END.2
  %indvars.iv = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %indvars.iv.next, %for.body ]
  %add7 = phi float [ %x.promoted, %DIR.QUAL.LIST.END.2 ], [ %add, %for.body ]
  %a.gep = getelementptr inbounds float, ptr %a, i64 %indvars.iv
  %a.load = load float, ptr %a.gep
  %add = fadd fast float %add7, %a.load
  store float %add, ptr %x, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1000
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  %add.lcssa = phi float [ %add, %for.body ]
  br label %for.end1

for.end1:                                         ; preds = %for.end
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %for.end
  store float %add.lcssa, ptr %x, align 4
  %x1 = load float, ptr %x, align 4
  ret float %x1
}

; Function Attrs: argmemonly nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: argmemonly nounwind
declare void @llvm.directive.region.exit(token)
