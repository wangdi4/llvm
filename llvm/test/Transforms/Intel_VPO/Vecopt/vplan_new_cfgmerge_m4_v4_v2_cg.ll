; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; The scenario requires static peeling, due to remainder is non-masked vector loop.
; This is enforced by planner: when scenario contains peel but peeling is disabled
; a static peel(1) is enforced.
; RUN: opt -vplan-vec-scenario="m4;v4;v2" \
; RUN: -disable-output -passes=vplan-vec \
; RUN: -print-after=vplan-vec \
; RUN: -vplan-enable-peeling=0 %s 2>&1 | FileCheck %s

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024"
target triple = "x86_64-unknown-linux-gnu"

define void @test_store(ptr nocapture %ary, i32 %c) {
;
; CHECK-LABEL: @test_store(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[PEEL_CHECKZ24:%.*]]
; CHECK:       peel.checkz24:
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i32> poison, i32 [[C:%.*]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    br label [[VPLANNEDBB2:%.*]]
; CHECK:       VPlannedBB2:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1]] ], [ [[TMP6:%.*]], [[NEW_LATCH:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB1]] ], [ [[TMP5:%.*]], [[NEW_LATCH]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = add nuw nsw <4 x i64> [[VEC_PHI]], zeroinitializer
; CHECK-NEXT:    [[DOTEXTRACT_0_:%.*]] = extractelement <4 x i64> [[TMP0]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = icmp ult <4 x i64> [[VEC_PHI]], <i64 1, i64 1, i64 1, i64 1>
; CHECK-NEXT:    br label [[VPLANNEDBB3:%.*]]
; CHECK:       VPlannedBB3:
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i64, ptr [[ARY:%.*]], i64 [[DOTEXTRACT_0_]]
; CHECK-NEXT:    [[TMP2:%.*]] = sext <4 x i32> [[BROADCAST_SPLAT]] to <4 x i64>
; CHECK-NEXT:    [[TMP3:%.*]] = add <4 x i64> [[TMP2]], [[TMP0]]
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0(<4 x i64> [[TMP3]], ptr [[SCALAR_GEP]], i32 8, <4 x i1> [[TMP1]])
; CHECK-NEXT:    br label [[NEW_LATCH]]
; CHECK:       new_latch:
; CHECK-NEXT:    [[TMP5]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP6]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ult <4 x i64> [[TMP5]], <i64 1, i64 1, i64 1, i64 1>
; CHECK-NEXT:    [[TMP8:%.*]] = bitcast <4 x i1> [[TMP7]] to i4
; CHECK-NEXT:    [[TMP9:%.*]] = icmp eq i4 [[TMP8]], 0
; CHECK-NEXT:    br i1 [[TMP9]], label [[VPLANNEDBB4:%.*]], label [[VPLANNEDBB2]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    br label [[VPLANNEDBB5:%.*]]
; CHECK:       VPlannedBB5:
; CHECK-NEXT:    br label [[MERGE_BLK22:%.*]]
; CHECK:       merge.blk22:
; CHECK-NEXT:    [[UNI_PHI6:%.*]] = phi i64 [ 1, [[VPLANNEDBB5]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB7:%.*]]
; CHECK:       VPlannedBB7:
; CHECK-NEXT:    br i1 false, label [[FINAL_MERGE:%.*]], label [[VPLANNEDBB8:%.*]]
; CHECK:       VPlannedBB8:
; CHECK-NEXT:    br i1 false, label [[MERGE_BLK20:%.*]], label [[VPLANNEDBB9:%.*]]
; CHECK:       VPlannedBB9:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT15:%.*]] = insertelement <4 x i32> poison, i32 [[C]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT16:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT15]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK:       VPlannedBB10:
; CHECK-NEXT:    [[UNI_PHI6IND_START_BCAST_SPLATINSERT:%.*]] = insertelement <4 x i64> poison, i64 [[UNI_PHI6]], i64 0
; CHECK-NEXT:    [[UNI_PHI6IND_START_BCAST_SPLAT:%.*]] = shufflevector <4 x i64> [[UNI_PHI6IND_START_BCAST_SPLATINSERT]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP10:%.*]] = add <4 x i64> [[UNI_PHI6IND_START_BCAST_SPLAT]], <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI12:%.*]] = phi i64 [ [[UNI_PHI6]], [[VPLANNEDBB10]] ], [ [[TMP15:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI13:%.*]] = phi <4 x i64> [ [[TMP10]], [[VPLANNEDBB10]] ], [ [[TMP14:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[SCALAR_GEP14:%.*]] = getelementptr inbounds i64, ptr [[ARY]], i64 [[UNI_PHI12]]
; CHECK-NEXT:    [[TMP11:%.*]] = sext <4 x i32> [[BROADCAST_SPLAT16]] to <4 x i64>
; CHECK-NEXT:    [[TMP12:%.*]] = add <4 x i64> [[TMP11]], [[VEC_PHI13]]
; CHECK-NEXT:    store <4 x i64> [[TMP12]], ptr [[SCALAR_GEP14]], align 8
; CHECK-NEXT:    [[TMP14]] = add nuw nsw <4 x i64> [[VEC_PHI13]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP15]] = add nuw nsw i64 [[UNI_PHI12]], 4
; CHECK-NEXT:    [[TMP16:%.*]] = icmp ult i64 [[TMP15]], 1021
; CHECK-NEXT:    br i1 [[TMP16]], label [[VECTOR_BODY]], label [[VPLANNEDBB17:%.*]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB17:
; CHECK-NEXT:    br label [[VPLANNEDBB18:%.*]]
; CHECK:       VPlannedBB18:
; CHECK-NEXT:    br label [[VPLANNEDBB19:%.*]]
; CHECK:       VPlannedBB19:
; CHECK-NEXT:    br i1 false, label [[FINAL_MERGE]], label [[MERGE_BLK20]]
; CHECK:       merge.blk20:
; CHECK-NEXT:    [[UNI_PHI20:%.*]] = phi i64 [ 1021, [[VPLANNEDBB19]] ], [ [[UNI_PHI6]], [[VPLANNEDBB8]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB21:%.*]]
; CHECK:       VPlannedBB21:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT27:%.*]] = insertelement <2 x i32> poison, i32 [[C]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT28:%.*]] = shufflevector <2 x i32> [[BROADCAST_SPLATINSERT27]], <2 x i32> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB22:%.*]]
; CHECK:       VPlannedBB22:
; CHECK-NEXT:    [[UNI_PHI20IND_START_BCAST_SPLATINSERT:%.*]] = insertelement <2 x i64> poison, i64 [[UNI_PHI20]], i64 0
; CHECK-NEXT:    [[UNI_PHI20IND_START_BCAST_SPLAT:%.*]] = shufflevector <2 x i64> [[UNI_PHI20IND_START_BCAST_SPLATINSERT]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP17:%.*]] = add <2 x i64> [[UNI_PHI20IND_START_BCAST_SPLAT]], <i64 0, i64 1>
; CHECK-NEXT:    br label [[VPLANNEDBB23:%.*]]
; CHECK:       VPlannedBB23:
; CHECK-NEXT:    [[UNI_PHI24:%.*]] = phi i64 [ [[UNI_PHI20]], [[VPLANNEDBB22]] ], [ [[TMP22:%.*]], [[VPLANNEDBB23]] ]
; CHECK-NEXT:    [[VEC_PHI25:%.*]] = phi <2 x i64> [ [[TMP17]], [[VPLANNEDBB22]] ], [ [[TMP21:%.*]], [[VPLANNEDBB23]] ]
; CHECK-NEXT:    [[SCALAR_GEP26:%.*]] = getelementptr inbounds i64, ptr [[ARY]], i64 [[UNI_PHI24]]
; CHECK-NEXT:    [[TMP18:%.*]] = sext <2 x i32> [[BROADCAST_SPLAT28]] to <2 x i64>
; CHECK-NEXT:    [[TMP19:%.*]] = add <2 x i64> [[TMP18]], [[VEC_PHI25]]
; CHECK-NEXT:    store <2 x i64> [[TMP19]], ptr [[SCALAR_GEP26]], align 8
; CHECK-NEXT:    [[TMP21]] = add nuw nsw <2 x i64> [[VEC_PHI25]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP22]] = add nuw nsw i64 [[UNI_PHI24]], 2
; CHECK-NEXT:    [[TMP23:%.*]] = icmp ult i64 [[TMP22]], 1023
; CHECK-NEXT:    br i1 [[TMP23]], label [[VPLANNEDBB23]], label [[VPLANNEDBB29:%.*]]
; CHECK:       VPlannedBB29:
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK:       VPlannedBB30:
; CHECK-NEXT:    br label [[FINAL_MERGE]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI31:%.*]] = phi i64 [ 1023, [[VPLANNEDBB30]] ], [ 1021, [[VPLANNEDBB19]] ], [ [[UNI_PHI6]], [[VPLANNEDBB7]] ]
; CHECK-NEXT:    br label [[FOR_END:%.*]]
; CHECK:       for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[FOR_BODY:%.*]] ]
; CHECK-NEXT:    [[PTR:%.*]] = getelementptr inbounds i64, ptr [[ARY]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[CC:%.*]] = sext i32 [[C]] to i64
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[CC]], [[INDVARS_IV]]
; CHECK-NEXT:    store i64 [[ADD]], ptr [[PTR]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[CMP:%.*]] = icmp ult i64 [[INDVARS_IV_NEXT]], 1024
; CHECK-NEXT:    br label [[FOR_BODY]]
; CHECK:       for.end:
; CHECK-NEXT:    ret void
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %ptr = getelementptr inbounds i64, ptr %ary, i64 %indvars.iv
  %cc = sext i32 %c to i64
  %add = add i64 %cc, %indvars.iv
  store i64 %add, ptr %ptr, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp ult i64 %indvars.iv.next, 1024
  br i1 %cmp, label %for.body, label %for.end

for.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
