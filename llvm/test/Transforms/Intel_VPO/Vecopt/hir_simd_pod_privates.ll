; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Check HIR vectorizer codegen support for simple POD privates which are not
; liveout. HIR vector CG creates a new widened alloca for the private memory
; and all accesses are updated to use this new memory. Test checks support
; for both scalar and aggregate type privates.

; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -vplan-force-vf=4 -print-after=hir-vplan-vec -hir-details -hir-cg -mem2reg -simplifycfg -S < %s 2>&1 | FileCheck %s

; Incoming HIR for test_scalar
;   BEGIN REGION { }
;         %tok = @llvm.directive.region.entry(); [ DIR.OMP.SIMD(),  QUAL.OMP.PRIVATE(&((%a)[0])) ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP> <simd>
;         |   %0 = (%iarr)[i1];
;         |   (%a)[0] = %0;
;         |   %priv.ld = (i8*)(%a)[0];
;         + END LOOP
;
;         @llvm.directive.region.exit(%tok); [ DIR.OMP.END.SIMD() ]
;   END REGION

; CHECK-LABEL: Function: test_scalar
; CHECK:  BEGIN REGION { modified }
; CHECK:           %priv.mem.bc = &((i32*)(%priv.mem)[0]);
; CHECK:           <RVAL-REG> &((i32*)(LINEAR <4 x i32>* %priv.mem)[i64 0]) inbounds  {sb:[[PRIV_MEM_SYM:.*]]}
; CHECK:        + DO i64 i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK:        |   %.vec = (<4 x i32>*)(%iarr)[i1];
; CHECK:        |   (<4 x i32>*)(%priv.mem)[0] = %.vec;
; CHECK:        |   <LVAL-REG> {al:4}(<4 x i32>*)(LINEAR <4 x i32>* %priv.mem)[i64 0] inbounds  {sb:[[PRIV_MEM_SYM]]}
; CHECK:        |   %.vec3 = (<4 x i8>*)(%priv.mem.bc)[<i32 0, i32 1, i32 2, i32 3>];
; CHECK:        |   <RVAL-REG> {al:4}(<4 x i8>*)(LINEAR i32* %priv.mem.bc)[<4 x i32> <i32 0, i32 1, i32 2, i32 3>] inbounds  {sb:[[PRIV_MEM_SYM]]}
; CHECK:        + END LOOP
; CHECK:  END REGION

; Incoming HIR for test_array
;   BEGIN REGION { }
;         %tok = @llvm.directive.region.entry(); [ DIR.OMP.SIMD(),  QUAL.OMP.PRIVATE(&((%arr)[0])) ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP> <simd>
;         |   %0 = (%ip)[i1];
;         |   (%arr)[0][i1] = %0;
;         + END LOOP
;
;         @llvm.directive.region.exit(%tok); [ DIR.OMP.END.SIMD() ]
;   END REGION

; CHECK-LABEL: Function: test_array
; CHECK:  BEGIN REGION { modified }
; CHECK:           %priv.mem.bc = &(([100 x i32]*)(%priv.mem)[0]);
; CHECK:           <RVAL-REG> &(([100 x i32]*)(LINEAR [4 x [100 x i32]]* %priv.mem)[i64 0]) inbounds  {sb:[[PRIV_MEM_SYM:.*]]}
; CHECK:        + DO i64 i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK:        |   %.vec = (<4 x i32>*)(%ip)[i1];
; CHECK:        |   %nsbgepcopy = &((<4 x [100 x i32]*>)(%priv.mem.bc)[<i32 0, i32 1, i32 2, i32 3>]);
; CHECK:        |   <RVAL-REG> &((<4 x [100 x i32]*>)(LINEAR [100 x i32]* %priv.mem.bc)[<4 x i32> <i32 0, i32 1, i32 2, i32 3>]) inbounds  {sb:[[PRIV_MEM_SYM]]}
; CHECK:        |   (<4 x i32>*)(%nsbgepcopy)[0][i1 + <i64 0, i64 1, i64 2, i64 3>] = %.vec;
; CHECK:        |   <LVAL-REG> {al:4}(<4 x i32>*)(NON-LINEAR <4 x [100 x i32]*> %nsbgepcopy)[<4 x i64> 0][LINEAR <4 x i64> i1 + <i64 0, i64 1, i64 2, i64 3>] inbounds  {sb:[[PRIV_MEM_SYM]]}
; CHECK:        + END LOOP
; CHECK:  END REGION

; Function Attrs: nounwind uwtable
define void @test_scalar(i32* nocapture readonly %iarr)  {
; CHECK-LABEL: @test_scalar(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[PRIV_MEM:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i32>* [[PRIV_MEM]] to i32*
; CHECK-NEXT:    br label [[LOOP_23:%.*]]
; CHECK:       loop.23:
; CHECK-NEXT:    [[I1_I64_0:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[NEXTIVLOOP_23:%.*]], [[LOOP_23]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i32, i32* [[IARR:%.*]], i64 [[I1_I64_0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[TMP1]] to <4 x i32>*
; CHECK-NEXT:    [[GEPLOAD:%.*]] = load <4 x i32>, <4 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    store <4 x i32> [[GEPLOAD]], <4 x i32>* [[PRIV_MEM]], align 4
; CHECK-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <4 x i32*> poison, i32* [[TMP0]], i32 0
; CHECK-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <4 x i32*> [[DOTSPLATINSERT]], <4 x i32*> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds i32, <4 x i32*> [[DOTSPLAT]], <4 x i64> <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast <4 x i32*> [[TMP3]] to <4 x i8*>
; CHECK-NEXT:    [[TMP5:%.*]] = call <4 x i8> @llvm.masked.gather.v4i8.v4p0i8(<4 x i8*> [[TMP4]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i8> undef)
; CHECK-NEXT:    [[NEXTIVLOOP_23]] = add nuw nsw i64 [[I1_I64_0]], 4
; CHECK-NEXT:    [[CONDLOOP_23:%.*]] = icmp sle i64 [[NEXTIVLOOP_23]], 99
; CHECK-NEXT:    br i1 [[CONDLOOP_23]], label [[LOOP_23]], label [[AFTERLOOP_23:%.*]], [[LOOP0:!llvm.loop !.*]]
; CHECK:       afterloop.23:
; CHECK-NEXT:    ret void
;
entry:
  %a = alloca i32, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"(i32* %a, i32 0, i32 1) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.QUAL.LIST.END.2
  %.omp.iv.05 = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %add1, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %iarr, i64 %.omp.iv.05
  %0 = load i32, i32* %arrayidx, align 4
  ; Unit-strided store to private
  store i32 %0, i32* %a, align 4
  %cast = bitcast i32 *%a to i8 *
  ; Non unit-strided access to private
  %priv.ld = load i8, i8* %cast, align 4
  %add1 = add nuw nsw i64 %.omp.iv.05, 1
  %exitcond = icmp eq i64 %add1, 100
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %omp.loop.exit
  ret void
}

; Function Attrs: nounwind uwtable
define void @test_array(i32* nocapture readonly %ip)  {
; CHECK-LABEL: @test_array(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ARR:%.*]] = alloca [100 x i32], align 4
; CHECK-NEXT:    [[PRIV_MEM:%.*]] = alloca [4 x [100 x i32]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [4 x [100 x i32]]* [[PRIV_MEM]] to [100 x i32]*
; CHECK-NEXT:    br label [[LOOP_22:%.*]]
; CHECK:       loop.22:
; CHECK-NEXT:    [[I1_I64_0:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[NEXTIVLOOP_22:%.*]], [[LOOP_22]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i32, i32* [[IP:%.*]], i64 [[I1_I64_0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[TMP1]] to <4 x i32>*
; CHECK-NEXT:    [[GEPLOAD:%.*]] = load <4 x i32>, <4 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <4 x [100 x i32]*> poison, [100 x i32]* [[TMP0]], i32 0
; CHECK-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <4 x [100 x i32]*> [[DOTSPLATINSERT]], <4 x [100 x i32]*> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [100 x i32], <4 x [100 x i32]*> [[DOTSPLAT]], <4 x i64> <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    [[DOTSPLATINSERT2:%.*]] = insertelement <4 x i64> poison, i64 [[I1_I64_0]], i32 0
; CHECK-NEXT:    [[DOTSPLAT3:%.*]] = shufflevector <4 x i64> [[DOTSPLATINSERT2]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP4:%.*]] = add <4 x i64> <i64 0, i64 1, i64 2, i64 3>, [[DOTSPLAT3]]
; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [100 x i32], <4 x [100 x i32]*> [[TMP3]], <4 x i64> zeroinitializer, <4 x i64> [[TMP4]]
; CHECK-NEXT:    call void @llvm.masked.scatter.v4i32.v4p0i32(<4 x i32> [[GEPLOAD]], <4 x i32*> [[TMP5]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>)
; CHECK-NEXT:    [[NEXTIVLOOP_22]] = add nuw nsw i64 [[I1_I64_0]], 4
; CHECK-NEXT:    [[CONDLOOP_22:%.*]] = icmp sle i64 [[NEXTIVLOOP_22]], 99
; CHECK-NEXT:    br i1 [[CONDLOOP_22]], label [[LOOP_22]], label [[AFTERLOOP_22:%.*]], [[LOOP4:!llvm.loop !.*]]
; CHECK:       afterloop.22:
; CHECK-NEXT:    ret void
;
entry:
  %arr = alloca [100 x i32], align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"([100 x i32]* %arr, i32 0, i32 100) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.QUAL.LIST.END.2
  %.omp.iv.05 = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %add1, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %ip, i64 %.omp.iv.05
  %0 = load i32, i32* %arrayidx, align 4
  %priv.idx = getelementptr inbounds [100 x i32], [100 x i32]* %arr, i64 0, i64 %.omp.iv.05
  store i32 %0, i32* %priv.idx, align 4
  %add1 = add nuw nsw i64 %.omp.iv.05, 1
  %exitcond = icmp eq i64 %add1, 100
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %omp.loop.exit
  ret void
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)
