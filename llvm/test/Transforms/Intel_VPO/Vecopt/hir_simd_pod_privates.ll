; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Check HIR vectorizer codegen support for simple POD privates which are not
; liveout. HIR vector CG creates a new widened alloca for the private memory
; and all accesses are updated to use this new memory. Test checks support
; for both scalar and aggregate type privates.

; RUN: opt -passes='hir-ssa-deconstruction,hir-vplan-vec,print<hir>,hir-cg,mem2reg,simplifycfg' -vplan-force-vf=4 -vplan-enable-hir-private-arrays -hir-details -S < %s 2>&1 | FileCheck %s

; Incoming HIR for test_scalar
;   BEGIN REGION { }
;         %tok = @llvm.directive.region.entry(); [ DIR.OMP.SIMD(),  QUAL.OMP.PRIVATE(&((%a)[0])) ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP> <simd>
;         |   %0 = (%iarr)[i1];
;         |   (%a)[0] = %0;
;         |   %priv.ld = (i8*)(%a)[0];
;         + END LOOP
;
;         @llvm.directive.region.exit(%tok); [ DIR.OMP.END.SIMD() ]
;   END REGION

; CHECK-LABEL: Function: test_scalar
; CHECK:  BEGIN REGION { modified }
; CHECK:           %priv.mem.bc = &((i32*)(%priv.mem)[0]);
; CHECK:        + DO i64 i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK:        |   %.vec = (<4 x i32>*)(%iarr)[i1];
; CHECK:        |   (<4 x i32>*)(%priv.mem)[0] = %.vec;
; CHECK:        |   %.vec3 = (<4 x i8>*)(%priv.mem.bc)[<i32 0, i32 1, i32 2, i32 3>];
; CHECK:        + END LOOP
; CHECK:  END REGION

; Incoming HIR for test_array
;   BEGIN REGION { }
;         %tok = @llvm.directive.region.entry(); [ DIR.OMP.SIMD(),  QUAL.OMP.PRIVATE(&((%arr)[0])) ]
;
;         + DO i1 = 0, 99, 1   <DO_LOOP> <simd>
;         |   %0 = (%ip)[i1];
;         |   (%arr)[0][i1] = %0;
;         + END LOOP
;
;         @llvm.directive.region.exit(%tok); [ DIR.OMP.END.SIMD() ]
;   END REGION

; CHECK-LABEL: Function: test_array
; CHECK:  BEGIN REGION { modified }
; CHECK:           %priv.mem.bc = &(([100 x i32]*)(%priv.mem)[0]);
; CHECK:        + DO i64 i1 = 0, 99, 4   <DO_LOOP> <simd-vectorized> <novectorize>
; CHECK:        |   %.vec = (<4 x i32>*)(%ip)[i1];
; CHECK:        |   %nsbgepcopy = &((<4 x ptr>)(%priv.mem.bc)[<i32 0, i32 1, i32 2, i32 3>]);
; CHECK:        |   (<4 x i32>*)(%nsbgepcopy)[0][i1 + <i64 0, i64 1, i64 2, i64 3>] = %.vec;
; CHECK:        + END LOOP
; CHECK:  END REGION

; Function Attrs: nounwind uwtable
define void @test_scalar(ptr nocapture readonly %iarr)  {
; CHECK-LABEL: @test_scalar(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[PRIV_MEM:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <4 x ptr> poison, ptr [[PRIV_MEM]], i64 0
; CHECK-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <4 x ptr> [[DOTSPLATINSERT]], <4 x ptr> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds i32, <4 x ptr> [[DOTSPLAT]], <4 x i64> <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    br label [[LOOP_22:%.*]]
; CHECK:       loop.22:
; CHECK-NEXT:    [[I1_I64_0:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[NEXTIVLOOP_22:%.*]], [[LOOP_22]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i32, ptr [[IARR:%.*]], i64 [[I1_I64_0]]
; CHECK-NEXT:    [[GEPLOAD:%.*]] = load <4 x i32>, ptr [[TMP1]], align 4
; CHECK-NEXT:    store <4 x i32> [[GEPLOAD]], ptr [[PRIV_MEM]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = call <4 x i8> @llvm.masked.gather.v4i8.v4p0(<4 x ptr> [[TMP0]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i8> poison)
; CHECK-NEXT:    [[NEXTIVLOOP_22]] = add nuw nsw i64 [[I1_I64_0]], 4
; CHECK-NEXT:    [[CONDLOOP_22:%.*]] = icmp sle i64 [[NEXTIVLOOP_22]], 99
; CHECK-NEXT:    br i1 [[CONDLOOP_22]], label [[LOOP_22]], label [[AFTERLOOP_22:%.*]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       afterloop.22:
; CHECK-NEXT:    ret void
;
entry:
  %a = alloca i32, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"(ptr %a, i32 0, i32 1) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.QUAL.LIST.END.2
  %.omp.iv.05 = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %add1, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, ptr %iarr, i64 %.omp.iv.05
  %0 = load i32, ptr %arrayidx, align 4
  ; Unit-strided store to private
  store i32 %0, ptr %a, align 4
  ; Non unit-strided access to private
  %priv.ld = load i8, ptr %a, align 4
  %add1 = add nuw nsw i64 %.omp.iv.05, 1
  %exitcond = icmp eq i64 %add1, 100
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %omp.loop.exit
  ret void
}

; Function Attrs: nounwind uwtable
define void @test_array(ptr nocapture readonly %ip)  {
; CHECK-LABEL: @test_array(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ARR:%.*]] = alloca [100 x i32], align 4
; CHECK-NEXT:    [[PRIV_MEM:%.*]] = alloca [4 x [100 x i32]], align 4
; CHECK-NEXT:    [[DOTSPLATINSERT:%.*]] = insertelement <4 x ptr> poison, ptr [[PRIV_MEM]], i64 0
; CHECK-NEXT:    [[DOTSPLAT:%.*]] = shufflevector <4 x ptr> [[DOTSPLATINSERT]], <4 x ptr> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds [100 x i32], <4 x ptr> [[DOTSPLAT]], <4 x i64> <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    br label [[LOOP_22:%.*]]
; CHECK:       loop.22:
; CHECK-NEXT:    [[I1_I64_0:%.*]] = phi i64 [ 0, [[ENTRY:%.*]] ], [ [[NEXTIVLOOP_22:%.*]], [[LOOP_22]] ]
; CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds i32, ptr [[IP:%.*]], i64 [[I1_I64_0]]
; CHECK-NEXT:    [[GEPLOAD:%.*]] = load <4 x i32>, ptr [[TMP1]], align 4
; CHECK-NEXT:    [[DOTSPLATINSERT2:%.*]] = insertelement <4 x i64> poison, i64 [[I1_I64_0]], i64 0
; CHECK-NEXT:    [[DOTSPLAT3:%.*]] = shufflevector <4 x i64> [[DOTSPLATINSERT2]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP2:%.*]] = add <4 x i64> <i64 0, i64 1, i64 2, i64 3>, [[DOTSPLAT3]]
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [100 x i32], <4 x ptr> [[TMP0]], <4 x i64> zeroinitializer, <4 x i64> [[TMP2]]
; CHECK-NEXT:    call void @llvm.masked.scatter.v4i32.v4p0(<4 x i32> [[GEPLOAD]], <4 x ptr> [[TMP3]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>)
; CHECK-NEXT:    [[NEXTIVLOOP_22]] = add nuw nsw i64 [[I1_I64_0]], 4
; CHECK-NEXT:    [[CONDLOOP_22:%.*]] = icmp sle i64 [[NEXTIVLOOP_22]], 99
; CHECK-NEXT:    br i1 [[CONDLOOP_22]], label [[LOOP_22]], label [[AFTERLOOP_22:%.*]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       afterloop.22:
; CHECK-NEXT:    ret void
;
entry:
  %arr = alloca [100 x i32], align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"(ptr %arr, i32 0, i32 100) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.QUAL.LIST.END.2
  %.omp.iv.05 = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %add1, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, ptr %ip, i64 %.omp.iv.05
  %0 = load i32, ptr %arrayidx, align 4
  %priv.idx = getelementptr inbounds [100 x i32], ptr %arr, i64 0, i64 %.omp.iv.05
  store i32 %0, ptr %priv.idx, align 4
  %add1 = add nuw nsw i64 %.omp.iv.05, 1
  %exitcond = icmp eq i64 %add1, 100
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %omp.loop.exit
  ret void
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)
