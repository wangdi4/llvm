; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt < %s -vplan-vec -vplan-force-vf=2 -S | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @masked_divergent_div(i32 *%p, i64 %n) {
; CHECK:  define void @masked_divergent_div(i32* [[P0:%.*]], i64 [[N0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP17:%.*]], [[VPLANNEDBB50:%.*]] ], [ 0, [[VECTOR_PH0:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP16:%.*]], [[VPLANNEDBB50]] ], [ <i64 0, i64 1>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_1_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 1
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_0_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], zeroinitializer
; CHECK-NEXT:    [[TMP4:%.*]] = xor <2 x i1> [[TMP3]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB3:
; CHECK-NEXT:    [[PREDICATE0:%.*]] = extractelement <2 x i1> [[TMP4]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = icmp eq i1 [[PREDICATE0]], true
; CHECK-NEXT:    br i1 [[TMP5]], label [[PRED_SDIV_IF0:%.*]], label [[TMP8:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP6:%.*]] = sdiv i32 42, [[WIDE_LOAD_EXTRACT_0_0]]
; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> undef, i32 [[TMP6]], i32 0
; CHECK-NEXT:    br label [[TMP8]]
; CHECK-EMPTY:
; CHECK-NEXT:  8:
; CHECK-NEXT:    [[TMP9:%.*]] = phi <2 x i32> [ undef, [[VPLANNEDBB30]] ], [ [[TMP7]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[PREDICATE40:%.*]] = extractelement <2 x i1> [[TMP4]], i64 1
; CHECK-NEXT:    [[TMP10:%.*]] = icmp eq i1 [[PREDICATE40]], true
; CHECK-NEXT:    br i1 [[TMP10]], label [[PRED_SDIV_IF120:%.*]], label [[TMP13:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if12:
; CHECK-NEXT:    [[TMP11:%.*]] = sdiv i32 42, [[WIDE_LOAD_EXTRACT_1_0]]
; CHECK-NEXT:    [[TMP12:%.*]] = insertelement <2 x i32> [[TMP9]], i32 [[TMP11]], i32 1
; CHECK-NEXT:    br label [[TMP13]]
; CHECK-EMPTY:
; CHECK-NEXT:  13:
; CHECK-NEXT:    [[TMP14:%.*]] = phi <2 x i32> [ [[TMP9]], [[PRED_SDIV_CONTINUE0]] ], [ [[TMP12]], [[PRED_SDIV_IF120]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE130:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue13:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0v2i32(<2 x i32> [[TMP14]], <2 x i32>* [[TMP15]], i32 4, <2 x i1> [[TMP4]])
; CHECK-NEXT:    br label [[VPLANNEDBB50]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[TMP16]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP17]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP18:%.*]] = icmp uge i64 [[TMP17]], [[TMP0:%.*]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[VPLANNEDBB60:%.*]], label [[VECTOR_BODY0:%.*]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP19:%.*]] = mul i64 1, [[TMP0]]
; CHECK-NEXT:    [[TMP20:%.*]] = add i64 0, [[TMP19]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, i32 *%p, i64 %iv
  %ld = load i32, i32* %gep
  %cond = icmp eq i32 %ld, 0
  br i1 %cond, label %latch, label %masked

masked:
  %div = sdiv i32 42, %ld
  store i32 %div, i32 *%gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_uniform_div(i32 *%p, i64 %n, i32 %val) {
; CHECK:  define void @masked_uniform_div(i32* [[P0:%.*]], i64 [[N0:%.*]], i32 [[VAL0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP14:%.*]], [[VPLANNEDBB60:%.*]] ], [ 0, [[VECTOR_PH0:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP13:%.*]], [[VPLANNEDBB60]] ], [ <i64 0, i64 1>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq i32 [[VAL0]], 0
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <2 x i1> poison, i1 [[TMP3]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <2 x i1> [[BROADCAST_SPLATINSERT0]], <2 x i1> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], <i32 42, i32 42>
; CHECK-NEXT:    [[TMP5:%.*]] = or <2 x i1> [[BROADCAST_SPLAT0]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = xor <2 x i1> [[TMP5]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB3:
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast <2 x i1> [[TMP6]] to i2
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ne i2 [[TMP7]], 0
; CHECK-NEXT:    br i1 [[TMP8]], label [[PRED_SDIV_IF0:%.*]], label [[TMP10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP9:%.*]] = sdiv i32 42, [[VAL0]]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT40:%.*]] = insertelement <2 x i32> poison, i32 [[TMP9]], i32 0
; CHECK-NEXT:    br label [[TMP10]]
; CHECK-EMPTY:
; CHECK-NEXT:  10:
; CHECK-NEXT:    [[TMP11:%.*]] = phi <2 x i32> [ poison, [[VPLANNEDBB30]] ], [ [[BROADCAST_SPLATINSERT40]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[BROADCAST_SPLAT50:%.*]] = shufflevector <2 x i32> [[TMP11]], <2 x i32> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP12:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0v2i32(<2 x i32> [[BROADCAST_SPLAT50]], <2 x i32>* [[TMP12]], i32 4, <2 x i1> [[TMP6]])
; CHECK-NEXT:    br label [[VPLANNEDBB60]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP13]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP14]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP15:%.*]] = icmp uge i64 [[TMP14]], [[TMP0:%.*]]
; CHECK-NEXT:    br i1 [[TMP15]], label [[VPLANNEDBB70:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB7:
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 1, [[TMP0]]
; CHECK-NEXT:    [[TMP17:%.*]] = add i64 0, [[TMP16]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, i32 *%p, i64 %iv
  %ld = load i32, i32* %gep
  %cond = icmp eq i32 %val, 0
  %cond2 = icmp eq i32 %ld, 42
  %or = or i1 %cond, %cond2
  br i1 %or, label %latch, label %masked

masked:
  %div = sdiv i32 42, %val
  store i32 %div, i32 *%gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_safe_speculation_div(i32 *%p, i64 %n, i32 %m) {
; CHECK:  define void @masked_safe_speculation_div(i32* [[P0:%.*]], i64 [[N0:%.*]], i32 [[M0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP8:%.*]], [[VPLANNEDBB40:%.*]] ], [ 0, [[VECTOR_PH0:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP7:%.*]], [[VPLANNEDBB40]] ], [ <i64 0, i64 1>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[TMP4:%.*]] = xor <2 x i1> [[TMP3]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB3:
; CHECK-NEXT:    [[TMP5:%.*]] = sdiv <2 x i32> [[WIDE_LOAD0]], <i32 42, i32 42>
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0v2i32(<2 x i32> [[TMP5]], <2 x i32>* [[TMP6]], i32 4, <2 x i1> [[TMP4]])
; CHECK-NEXT:    br label [[VPLANNEDBB40]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB4:
; CHECK-NEXT:    [[TMP7]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP8]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP9:%.*]] = icmp uge i64 [[TMP8]], [[TMP0]]
; CHECK-NEXT:    br i1 [[TMP9]], label [[VPLANNEDBB50:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[TMP10:%.*]] = mul i64 1, [[TMP0:%.*]]
; CHECK-NEXT:    [[TMP11:%.*]] = add i64 0, [[TMP10]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, i32 *%p, i64 %iv
  %ld = load i32, i32* %gep
  %cond = icmp eq i32 %ld, %m
  br i1 %cond, label %latch, label %masked

masked:
  ; Safe to speculate
  %div = sdiv i32 %ld, 42
  store i32 %div, i32 *%gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @masked_unsafe_speculation_div(i32 *%p, i64 %n, i32 %m) {
; CHECK:  define void @masked_unsafe_speculation_div(i32* [[P0:%.*]], i64 [[N0:%.*]], i32 [[M0:%.*]]) {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP17:%.*]], [[VPLANNEDBB50:%.*]] ], [ 0, [[VECTOR_PH0:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP16:%.*]], [[VPLANNEDBB50]] ], [ <i64 0, i64 1>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[P0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_1_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 1
; CHECK-NEXT:    [[WIDE_LOAD_EXTRACT_0_0:%.*]] = extractelement <2 x i32> [[WIDE_LOAD0]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = icmp eq <2 x i32> [[WIDE_LOAD0]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[TMP4:%.*]] = xor <2 x i1> [[TMP3]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB3:
; CHECK-NEXT:    [[PREDICATE0:%.*]] = extractelement <2 x i1> [[TMP4]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = icmp eq i1 [[PREDICATE0]], true
; CHECK-NEXT:    br i1 [[TMP5]], label [[PRED_SDIV_IF0:%.*]], label [[TMP8:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if:
; CHECK-NEXT:    [[TMP6:%.*]] = sdiv i32 [[WIDE_LOAD_EXTRACT_0_0]], -1
; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <2 x i32> undef, i32 [[TMP6]], i32 0
; CHECK-NEXT:    br label [[TMP8]]
; CHECK-EMPTY:
; CHECK-NEXT:  8:
; CHECK-NEXT:    [[TMP9:%.*]] = phi <2 x i32> [ undef, [[VPLANNEDBB30]] ], [ [[TMP7]], [[PRED_SDIV_IF0]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue:
; CHECK-NEXT:    [[PREDICATE40:%.*]] = extractelement <2 x i1> [[TMP4]], i64 1
; CHECK-NEXT:    [[TMP10:%.*]] = icmp eq i1 [[PREDICATE40]], true
; CHECK-NEXT:    br i1 [[TMP10]], label [[PRED_SDIV_IF120:%.*]], label [[TMP13:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.if12:
; CHECK-NEXT:    [[TMP11:%.*]] = sdiv i32 [[WIDE_LOAD_EXTRACT_1_0]], -1
; CHECK-NEXT:    [[TMP12:%.*]] = insertelement <2 x i32> [[TMP9]], i32 [[TMP11]], i32 1
; CHECK-NEXT:    br label [[TMP13]]
; CHECK-EMPTY:
; CHECK-NEXT:  13:
; CHECK-NEXT:    [[TMP14:%.*]] = phi <2 x i32> [ [[TMP9]], [[PRED_SDIV_CONTINUE0]] ], [ [[TMP12]], [[PRED_SDIV_IF120]] ]
; CHECK-NEXT:    br label [[PRED_SDIV_CONTINUE130:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.sdiv.continue13:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    call void @llvm.masked.store.v2i32.p0v2i32(<2 x i32> [[TMP14]], <2 x i32>* [[TMP15]], i32 4, <2 x i1> [[TMP4]])
; CHECK-NEXT:    br label [[VPLANNEDBB50]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[TMP16]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP17]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP18:%.*]] = icmp uge i64 [[TMP17]], [[TMP0:%.*]]
; CHECK-NEXT:    br i1 [[TMP18]], label [[VPLANNEDBB60:%.*]], label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP19:%.*]] = mul i64 1, [[TMP0]]
; CHECK-NEXT:    [[TMP20:%.*]] = add i64 0, [[TMP19]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
;
entry:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %header

header:
  %iv = phi i64 [ %iv.next, %latch ], [ 0, %entry ]
  %gep = getelementptr inbounds i32, i32 *%p, i64 %iv
  %ld = load i32, i32* %gep
  %cond = icmp eq i32 %ld, %m
  br i1 %cond, label %latch, label %masked

masked:
  ; Unsafe to speculate (i.e. INT_MIN sdiv -1 would overflow, which is UB)
  %div = sdiv i32 %ld, -1
  store i32 %div, i32 *%gep
  br label %latch

latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %loopexit, label %header

loopexit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
