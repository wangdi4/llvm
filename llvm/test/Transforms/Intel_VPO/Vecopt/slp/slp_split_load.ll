; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt < %s -passes=slp-vectorizer -mtriple=x86_64 -mcpu=skylake -S | FileCheck %s

; This is a test for Split-Load, which is Variable-Width SLP only for Loads.
; It allows for narrower vector loads compared to the rest of the SLP tree.
; Check that we have a 4-wide store and 2x 2-wide loads

@idx = local_unnamed_addr global i64 4, align 4
@src = common global [64 x i64] zeroinitializer, align 1
@res = common local_unnamed_addr global i64 0, align 4

; Function Attrs: noinline nounwind readonly uwtable
define void @foo(ptr nocapture readonly %src, i64 %idx) {
; CHECK-LABEL: define {{[^@]+}}@foo(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[DST:%.*]] = alloca [64 x i64], align 16
; CHECK-NEXT:    [[ARRAYIDXA0:%.*]] = getelementptr inbounds i64, ptr [[SRC:%.*]], i64 0
; CHECK-NEXT:    [[ARRAYIDXB0:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 8
; CHECK-NEXT:    [[ARRAYIDX0:%.*]] = getelementptr inbounds [64 x i64], ptr [[DST]], i64 0, i64 0
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i64>, ptr [[ARRAYIDXA0]], align 1
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i64>, ptr [[ARRAYIDXB0]], align 1
; CHECK-NEXT:    [[SPLITLOADSHUFFLE:%.*]] = shufflevector <2 x i64> [[TMP0]], <2 x i64> [[TMP1]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    store <4 x i64> [[SPLITLOADSHUFFLE]], ptr [[ARRAYIDX0]], align 16
; CHECK-NEXT:    ret void
;
entry:
  %dst = alloca [64 x i64], align 16

; Split load A
  %arrayidxA0 = getelementptr inbounds i64, ptr %src, i64 0
  %A0 = load i64, ptr %arrayidxA0, align 1
  %arrayidxA1 = getelementptr inbounds i64, ptr %src, i64 1
  %A1 = load i64, ptr %arrayidxA1, align 1

; Split load B
  %arrayidxB0 = getelementptr inbounds i64, ptr %src, i64 8
  %B0 = load i64, ptr %arrayidxB0, align 1
  %arrayidxB1 = getelementptr inbounds i64, ptr %src, i64 9
  %B1 = load i64, ptr %arrayidxB1, align 1

; 4 consecutive stores:
  %arrayidx0 = getelementptr inbounds [64 x i64], ptr %dst, i64 0, i64 0
  store i64 %A0, ptr %arrayidx0, align 16
  %arrayidx1 = getelementptr inbounds [64 x i64], ptr %dst, i64 0, i64 1
  store i64 %A1, ptr %arrayidx1, align 16
  %arrayidx2 = getelementptr inbounds [64 x i64], ptr %dst, i64 0, i64 2
  store i64 %B0, ptr %arrayidx2, align 16
  %arrayidx3 = getelementptr inbounds [64 x i64], ptr %dst, i64 0, i64 3
  store i64 %B1, ptr %arrayidx3, align 16
  ret void
}
