; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; Check that superscalar ops are not overestimated with their costs.
; RUN: opt -passes=slp-vectorizer -mattr=+avx2 -mtriple=x86_64 -S -enable-intel-advanced-opts  < %s  | FileCheck %s
; Check that cost of tree with superscalar ops still have non-zero cost,
; so that we do not impede vectorization too much.
; RUN: opt -passes=slp-vectorizer -mattr=+avx2 -mtriple=x86_64 -S -enable-intel-advanced-opts  -slp-threshold=-3 < %s  | FileCheck %s --check-prefix=CHECKMARGIN
; RUN: opt -passes=slp-vectorizer -mattr=+avx2 -mtriple=x86_64 -S < %s  | FileCheck %s --check-prefix=NOADJ

; When advanced optimization enabled (which means target is an IA CPU),
; cost of scalar bitwise operations is adjusted as TTI does not take
; superscalar nature of IA CPUs into account and overestimates their
; cost which adds bias towards vectorization even if it is unprofitable.

define void @fun_novec(ptr %a, i32 %b0, i32 %b1, i32 %c0, i32 %c1, ptr %r) {
; CHECK-LABEL: define void @fun_novec
; CHECK-SAME: (ptr [[A:%.*]], i32 [[B0:%.*]], i32 [[B1:%.*]], i32 [[C0:%.*]], i32 [[C1:%.*]], ptr [[R:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[GEP_A1:%.*]] = getelementptr i32, ptr [[A]], i32 1
; CHECK-NEXT:    [[A0:%.*]] = load i32, ptr [[A]], align 4
; CHECK-NEXT:    [[A1:%.*]] = load i32, ptr [[GEP_A1]], align 4
; CHECK-NEXT:    [[L0_T:%.*]] = and i32 [[A0]], 7
; CHECK-NEXT:    [[L1_T:%.*]] = and i32 [[A1]], 7
; CHECK-NEXT:    [[L0_OR:%.*]] = or i32 [[B0]], [[L0_T]]
; CHECK-NEXT:    [[L1_OR:%.*]] = or i32 [[B1]], [[L1_T]]
; CHECK-NEXT:    [[L0_X:%.*]] = xor i32 [[L0_OR]], [[C0]]
; CHECK-NEXT:    [[L1_X:%.*]] = xor i32 [[L1_OR]], [[C1]]
; CHECK-NEXT:    store i32 [[L0_X]], ptr [[R]], align 4
; CHECK-NEXT:    [[GEP1:%.*]] = getelementptr inbounds i32, ptr [[R]], i64 1
; CHECK-NEXT:    store i32 [[L1_X]], ptr [[GEP1]], align 4
; CHECK-NEXT:    ret void
;
; CHECKMARGIN-LABEL: define void @fun_novec
; CHECKMARGIN-SAME: (ptr [[A:%.*]], i32 [[B0:%.*]], i32 [[B1:%.*]], i32 [[C0:%.*]], i32 [[C1:%.*]], ptr [[R:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECKMARGIN-NEXT:  entry:
; CHECKMARGIN-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A]], align 4
; CHECKMARGIN-NEXT:    [[TMP1:%.*]] = and <2 x i32> [[TMP0]], <i32 7, i32 7>
; CHECKMARGIN-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> poison, i32 [[B0]], i32 0
; CHECKMARGIN-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> [[TMP2]], i32 [[B1]], i32 1
; CHECKMARGIN-NEXT:    [[TMP4:%.*]] = or <2 x i32> [[TMP3]], [[TMP1]]
; CHECKMARGIN-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[C0]], i32 0
; CHECKMARGIN-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[C1]], i32 1
; CHECKMARGIN-NEXT:    [[TMP7:%.*]] = xor <2 x i32> [[TMP4]], [[TMP6]]
; CHECKMARGIN-NEXT:    store <2 x i32> [[TMP7]], ptr [[R]], align 4
; CHECKMARGIN-NEXT:    ret void
;
; NOADJ-LABEL: define void @fun_novec
; NOADJ-SAME: (ptr [[A:%.*]], i32 [[B0:%.*]], i32 [[B1:%.*]], i32 [[C0:%.*]], i32 [[C1:%.*]], ptr [[R:%.*]]) #[[ATTR0:[0-9]+]] {
; NOADJ-NEXT:  entry:
; NOADJ-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A]], align 4
; NOADJ-NEXT:    [[TMP1:%.*]] = and <2 x i32> [[TMP0]], <i32 7, i32 7>
; NOADJ-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> poison, i32 [[B0]], i32 0
; NOADJ-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> [[TMP2]], i32 [[B1]], i32 1
; NOADJ-NEXT:    [[TMP4:%.*]] = or <2 x i32> [[TMP3]], [[TMP1]]
; NOADJ-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[C0]], i32 0
; NOADJ-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[C1]], i32 1
; NOADJ-NEXT:    [[TMP7:%.*]] = xor <2 x i32> [[TMP4]], [[TMP6]]
; NOADJ-NEXT:    store <2 x i32> [[TMP7]], ptr [[R]], align 4
; NOADJ-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1

  %l0.t = and i32 %a0, 7
  %l1.t = and i32 %a1, 7

  %l0.or = or i32 %b0, %l0.t
  %l1.or = or i32 %b1, %l1.t

  %l0.x = xor i32 %l0.or, %c0
  %l1.x = xor i32 %l1.or, %c1

  store i32 %l0.x, ptr %r, align 4
  %gep1 = getelementptr inbounds i32, ptr %r, i64 1
  store i32 %l1.x, ptr %gep1, align 4
  ret void
}
