; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -passes=slp-vectorizer -enable-intel-advanced-opts -mattr=+avx2 -mtriple=x86_64 -slp-threshold=-100 -S < %s  | FileCheck %s

; A collection of tests that represents SLP scheduler related issues
; experienced after MultiNode reordering.

@a = external global i64, align 8
@b = external global i64, align 8
@c = external global i64, align 8
@d = external global i64, align 8

define <2 x i64> @test(i32 %a, i32 %b, i32 %c, i64 %d, i64 %e) {
; CHECK-LABEL: define {{[^@]+}}@test(
; CHECK-NEXT:    [[I04:%.*]] = add i32 [[A:%.*]], [[B:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x i32> poison, i32 [[C:%.*]], i32 1
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[I04]], i32 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext <2 x i32> [[TMP2]] to <2 x i64>
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[D:%.*]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[E:%.*]], i32 1
; CHECK-NEXT:    [[TMP6:%.*]] = add <2 x i64> <i64 -2, i64 -1>, [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = add <2 x i64> [[TMP6]], [[TMP3]]
; CHECK-NEXT:    br label [[BB1:%.*]]
; CHECK:       bb1:
; CHECK-NEXT:    ret <2 x i64> [[TMP7]]
;

; Pair {%i03,%i07} formed multi-node root and next vectorization tree entry
; was pair {%i02,%i06}, also the multi-node trunk.
; For the pair {%i03,%i07} scheduling was skipped because users are in another
; block, but scheduling region for {%i02,%i06} contains instruction %i03 so it
; was scheduled as a single instruction (not as a part of bundle). In such cases
; scheduling data do not have reference back to vectorization tree entry and the
; scheduler assumed it means operand remain original. But multinode reordering
; actually replaced original operands of {%i03,%i07} with the sext instructions.
; Operands reordering is not written back into LLVM IR and is kept in
; vectorization tree entries. Hence walking over %i3 operands taken from IR
; was wrong path and eventually caused a failure on assertion that %i03 turned
; out unscheduled when it had to be.
  %i01 = sext i32 %c to i64
  %i02 = add i64 %e, %i01
  %i03 = add i64 %i02, -1

  %i04 = add i32 %a, %b
  %i05 = sext i32 %i04 to i64
  %i06 = add nsw i64 %i05, %d
  %i07 = add nsw i64 %i06, -2

  br label %bb1
bb1:

  %tmp = insertelement <2 x i64> poison, i64 %i07, i64 0
  %res = insertelement <2 x i64> %tmp, i64 %i03, i64 1
  ret <2 x i64> %res
}


define i64 @recalculate_deps(i32 %arg0, i32 %arg1, ptr %p1, ptr %p2) {
; CHECK-LABEL: define {{[^@]+}}@recalculate_deps(
; CHECK-NEXT:    [[LD1:%.*]] = load i32, ptr [[P1:%.*]], align 8
; CHECK-NEXT:    [[LD2:%.*]] = load i32, ptr [[P2:%.*]], align 8
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x i32> poison, i32 [[ARG1:%.*]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[LD1]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = sext <2 x i32> [[TMP2]] to <2 x i64>
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i32> poison, i32 [[ARG0:%.*]], i32 1
; CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> [[TMP4]], i32 [[LD2]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = sext <2 x i32> [[TMP5]] to <2 x i64>
; CHECK-NEXT:    [[TMP7:%.*]] = sub <2 x i64> <i64 1, i64 1>, [[TMP3]]
; CHECK-NEXT:    [[TMP8:%.*]] = add <2 x i64> <i64 1, i64 1>, [[TMP3]]
; CHECK-NEXT:    [[TMP9:%.*]] = shufflevector <2 x i64> [[TMP7]], <2 x i64> [[TMP8]], <2 x i32> <i32 0, i32 3>
; CHECK-NEXT:    [[TMP10:%.*]] = add <2 x i64> [[TMP9]], [[TMP6]]
; CHECK-NEXT:    [[TMP11:%.*]] = sub <2 x i64> [[TMP9]], [[TMP6]]
; CHECK-NEXT:    [[TMP12:%.*]] = shufflevector <2 x i64> [[TMP10]], <2 x i64> [[TMP11]], <2 x i32> <i32 0, i32 3>
; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> poison, i32 [[LD2]], i32 0
; CHECK-NEXT:    [[TMP14:%.*]] = insertelement <2 x i32> [[TMP13]], i32 [[LD1]], i32 1
; CHECK-NEXT:    [[TMP15:%.*]] = icmp slt <2 x i32> [[TMP14]], <i32 32, i32 32>
; CHECK-NEXT:    [[TMP16:%.*]] = select <2 x i1> [[TMP15]], <2 x i64> zeroinitializer, <2 x i64> [[TMP12]]
; CHECK-NEXT:    [[TMP17:%.*]] = extractelement <2 x i64> [[TMP16]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = extractelement <2 x i64> [[TMP16]], i32 1
; CHECK-NEXT:    [[VRET:%.*]] = mul i64 [[TMP17]], [[TMP18]]
; CHECK-NEXT:    ret i64 [[VRET]]
;

; Vec tree is rooted at {%root0, %root1}
; %mn0.0, %mn0.1, %mn1.0 and %mn1.1 then become MultiNode trunk nodes.
; Started from roots we reached instructions %ld0, %ld1
; before we have built the MultiNode. Since %sext0, and %sext3 are
; their users, they have dependencies calculated at the time of
; scheduling the loads (each scheduled as a single instruction).
; Then MultiNode reordering affected def-use chain for sext{0..3} but
; that has not been taken into account when the instructions
; were scheduled as a bundle because they were looking as already
; having valid dependencies.

  %ld1 = load i32, ptr %p1, align 8
  %ld2 = load i32, ptr %p2, align 8

  %sext0 = sext i32 %arg0 to i64
  %sext1 = sext i32 %ld1 to i64

  %mn1.1 = sub nsw i64 1, %sext0
  %mn0.1 = add nsw i64 %mn1.1, %sext1

  %cmp1 = icmp slt i32 %ld1, 32
  %root1 = select i1 %cmp1, i64 0, i64 %mn0.1

  %sext2 = sext i32 %arg1 to i64
  %sext3 = sext i32 %ld2 to i64

  %mn1.0 = sub nsw i64 1, %sext2
  %mn0.0 = add nsw i64 %mn1.0, %sext3

  %cmp0 = icmp slt i32 %ld2, 32
  %root0 = select i1 %cmp0, i64 0, i64 %mn0.0
  %vret = mul i64 %root0, %root1

  ret i64 %vret
}

define void @reschedule(ptr %dst, ptr %p, i64 %i1, i64 %i2) {
; CHECK-LABEL: define {{[^@]+}}@reschedule(
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x i64> poison, i64 [[I1:%.*]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> [[TMP1]], i64 [[I2:%.*]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = trunc <2 x i64> [[TMP2]] to <2 x i32>
; CHECK-NEXT:    [[TMP4:%.*]] = sub <2 x i32> <i32 1, i32 1>, [[TMP3]]
; CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i32> [[TMP4]], i32 0
; CHECK-NEXT:    [[GEP1:%.*]] = getelementptr inbounds i32, ptr [[P:%.*]], i32 [[TMP5]]
; CHECK-NEXT:    [[LD1:%.*]] = load i32, ptr [[GEP1]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i32> [[TMP4]], i32 1
; CHECK-NEXT:    [[GEP2:%.*]] = getelementptr inbounds i32, ptr [[P]], i32 [[TMP6]]
; CHECK-NEXT:    [[LD2:%.*]] = load i32, ptr [[GEP2]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = and <2 x i32> [[TMP4]], <i32 1, i32 1>
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i32> poison, i32 [[LD1]], i32 0
; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <2 x i32> [[TMP8]], i32 [[LD2]], i32 1
; CHECK-NEXT:    [[TMP10:%.*]] = add <2 x i32> [[TMP7]], [[TMP9]]
; CHECK-NEXT:    store <2 x i32> [[TMP10]], ptr [[DST:%.*]], align 4
; CHECK-NEXT:    ret void
;
  %idx1 = trunc i64 %i1 to i32
  %sub1 = sub i32 1, %idx1
  %gep1 = getelementptr inbounds i32, ptr %p, i32 %sub1
  %ld1 = load i32, ptr %gep1, align 4

  %idx2 = trunc i64 %i2 to i32
  %sub2 = sub i32 1, %idx2
  %gep2 = getelementptr inbounds i32, ptr %p, i32 %sub2
  %ld2 = load i32, ptr %gep2, align 4

; {%v1,%v2} form a single node MultiNode with two operands: {%ld1,%ld2}
; and {%and1,%and2}. Note that {%and1,%and2} depend on %sub1 and %sub2
; respectively and {%ld1,%ld2} also depend on %sub1 and %sub2:
;      sub1            sub2
;      |  \            |  \
;     gep1 and1      gep2 and2
;      |   |           |   |
;     ld1  |          ld2  |
;      |  /            |  /
;       v1              v2

; We build vectorization tree recursively. Reordering swapped the operands so
; we started with {%and1,%and2} and eventually {%sub1,%sub2} was added to the
; tree and scheduled. Since {%ld1,%ld2} depend on {%sub1,%sub2}, dependencies
; for the loads has been calculated and finally scheduled as their users
; {%v1, %v2} were scheduled even though they were not yet in the vect tree.
; Thus by the time we moved on to next MN operand (the loads) they were
; scheduled. This is normal, it just needs rescheduling, but recalculation of
; dependencies should not be forced (they must be correct already) because that
; would mark their users as unscheduled (which is obviously not true).
  %and2 = and i32 %sub2, 1
  %v2 = add i32 %ld2, %and2
  %and1 = and i32 %sub1, 1
  %v1 = add i32 %ld1, %and1

  store i32 %v1, ptr %dst, align 4
  %sta2 = getelementptr inbounds i32, ptr %dst, i64 1
  store i32 %v2, ptr %sta2, align 4
  ret void
}

declare fastcc void @foo()
declare fastcc void @bar()

define i1 @memory_dependencies() {
; CHECK-LABEL: define {{[^@]+}}@memory_dependencies(
; CHECK-NEXT:    [[LDA:%.*]] = load i64, ptr @a, align 8
; CHECK-NEXT:    call fastcc void @foo()
; CHECK-NEXT:    [[OP0_0:%.*]] = load i64, ptr @c, align 8
; CHECK-NEXT:    [[OP0_1:%.*]] = load i64, ptr @d, align 8
; CHECK-NEXT:    call fastcc void @bar()
; CHECK-NEXT:    [[LDB:%.*]] = load i64, ptr @b, align 8
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x i64> poison, i64 [[LDA]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = insertelement <2 x i64> [[TMP1]], i64 [[LDB]], i32 1
; CHECK-NEXT:    [[TMP3:%.*]] = add <2 x i64> <i64 250, i64 250>, [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> poison, i64 [[OP0_0]], i32 0
; CHECK-NEXT:    [[TMP5:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[OP0_1]], i32 1
; CHECK-NEXT:    [[TMP6:%.*]] = add <2 x i64> [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ult <2 x i64> [[TMP6]], [[TMP3]]
; CHECK-NEXT:    [[TMP8:%.*]] = extractelement <2 x i1> [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP9:%.*]] = extractelement <2 x i1> [[TMP7]], i32 1
; CHECK-NEXT:    [[RES:%.*]] = and i1 [[TMP8]], [[TMP9]]
; CHECK-NEXT:    ret i1 [[RES]]
;
; Vectorization tree starts from %cmp1 and %cmp2 instructions.
; Both %mn.* then form a MultiNode root and %op* bocome operands of it.
; Pair {%lda,%ldb} was scheduled earlier via {%op1.0,%op1.1} - operands
; of the compares. Hence dependencies for %op0.0 and %op0.1 were calculated
; at that time (as single instructions).
; Now when there was time to process {%op0.0,%op0.1} as a bundle
; we need to recalculate their dependencies (as we try to schedule them after
; the MN reordering has happened). But MultiNode reordering does not change
; memory dependencies (instructions that may write to memory - here these
; are both foo() and bar() calls).
; We need to preserve memory dependencies calculated earlier.

  %lda = load i64, ptr @a, align 8

  call fastcc void @foo()
  %op0.0 = load i64, ptr @c, align 8
  %op0.1 = load i64, ptr @d, align 8
  call fastcc void @bar()

  %ldb = load i64, ptr @b, align 8

  %op1.0 = add i64 250, %lda
  %op1.1 = add i64 250, %ldb

  %mn.1 = add i64 %op0.0, %op1.0
  %mn.0 = add i64 %op0.1, %op1.1

  %cmp1 = icmp ult i64 %mn.1, %op1.0
  %cmp2 = icmp ult i64 %mn.0, %op1.1

  %res = and i1 %cmp1, %cmp2
  ret i1 %res
}
