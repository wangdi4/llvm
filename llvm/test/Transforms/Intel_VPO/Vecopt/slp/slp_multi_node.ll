; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt  -mtriple=x86_64 -mattr=+avx2 -passes=slp-vectorizer -enable-intel-advanced-opts -slp-multinode -slp-threshold=-1000 -slp-min-reg-size=64 -S < %s  | FileCheck %s

define void @simple(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@simple(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr [[B:%.*]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = add <2 x i32> [[TMP1]], <i32 42, i32 43>
; CHECK-NEXT:    [[TMP3:%.*]] = add <2 x i32> [[TMP2]], [[TMP0]]
; CHECK-NEXT:    store <2 x i32> [[TMP3]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %gep.b1 = getelementptr i32, ptr %b, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1
  %b0 = load i32, ptr %b
  %b1 = load i32, ptr %gep.b1

;  A0  B0  C1  A1
;   \ /     \ /
;    +   C0  +   B1
;     \ /     \ /
;      +       +
; MultiNode reorders B0<->C0.
  %lane0.add1 = add i32 %a0, %b0
  %lane0.add2 = add i32 %lane0.add1, 42

  %lane1.add1 = add i32 43, %a1
  %lane1.add2 = add i32 %lane1.add1, %b1

  %gep1 = getelementptr inbounds i32, ptr %c, i64 1
  store i32 %lane0.add2, ptr %c, align 4
  store i32 %lane1.add2, ptr %gep1, align 4
  ret void
}

; CMPLRLLVM-31486
define void @negative_different_sign_reorder(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@negative_different_sign_reorder(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[GEP_B1:%.*]] = getelementptr i32, ptr [[B:%.*]], i32 1
; CHECK-NEXT:    [[B0:%.*]] = load i32, ptr [[B]], align 4
; CHECK-NEXT:    [[B1:%.*]] = load i32, ptr [[GEP_B1]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x i32> <i32 poison, i32 43>, i32 [[B0]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = add <2 x i32> [[TMP0]], [[TMP1]]
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> <i32 42, i32 poison>, i32 [[B1]], i32 1
; CHECK-NEXT:    [[TMP4:%.*]] = sub <2 x i32> [[TMP3]], [[TMP2]]
; CHECK-NEXT:    store <2 x i32> [[TMP4]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %gep.b1 = getelementptr i32, ptr %b, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1
  %b0 = load i32, ptr %b
  %b1 = load i32, ptr %gep.b1

;    A0  B0  C1  A1
;     \ /     \ /
; C0   +   B1  +
;   \ /      \ /
;    -        -
; MultiNode must not reorder B0<->C0.
  %lane0.add = add i32 %a0, %b0
  %lane0.sub = sub i32 42, %lane0.add

  %lane1.add = add i32 43, %a1
  %lane1.sub = sub i32 %b1, %lane1.add

  %gep1 = getelementptr inbounds i32, ptr %c, i64 1
  store i32 %lane0.sub, ptr %c, align 4
  store i32 %lane1.sub, ptr %gep1, align 4
  ret void
}

define void @wrap_flags_simple(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@wrap_flags_simple(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr [[B:%.*]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = add <2 x i32> [[TMP1]], <i32 42, i32 43>
; CHECK-NEXT:    [[TMP3:%.*]] = add <2 x i32> [[TMP2]], [[TMP0]]
; CHECK-NEXT:    store <2 x i32> [[TMP3]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %gep.b1 = getelementptr i32, ptr %b, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1
  %b0 = load i32, ptr %b
  %b1 = load i32, ptr %gep.b1

;  A0  B0  C1  A1
;   \ /     \ /
;    +   C0  +   B1
;     \ /     \ /
;      +       +
; MultiNode reorders B0<->C0.
  %lane0.add1 = add nsw nuw i32 %a0, %b0
  %lane0.add2 = add nsw nuw i32 %lane0.add1, 42

  %lane1.add1 = add nsw nuw i32 43, %a1
  %lane1.add2 = add nsw nuw i32 %lane1.add1, %b1

  %gep1 = getelementptr inbounds i32, ptr %c, i64 1
  store i32 %lane0.add2, ptr %c, align 4
  store i32 %lane1.add2, ptr %gep1, align 4
  ret void
}

; MultiNode only works on Add/Sub which means FP types aren't affected by the
; wrap flags issue. Also, reassociation itself requires FMF on both operations,
; so we'd have ability to infer something if MultiNodes will ever start
; supporting FP.
define void @fmf_flags_simple(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@fmf_flags_simple(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[GEP_B1:%.*]] = getelementptr float, ptr [[B:%.*]], i64 1
; CHECK-NEXT:    [[B0:%.*]] = load float, ptr [[B]], align 4
; CHECK-NEXT:    [[B1:%.*]] = load float, ptr [[GEP_B1]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x float>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = insertelement <2 x float> <float poison, float 4.300000e+01>, float [[B0]], i32 0
; CHECK-NEXT:    [[TMP2:%.*]] = fadd fast <2 x float> [[TMP1]], [[TMP0]]
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x float> <float 4.200000e+01, float poison>, float [[B1]], i32 1
; CHECK-NEXT:    [[TMP4:%.*]] = fadd fast <2 x float> [[TMP2]], [[TMP3]]
; CHECK-NEXT:    store <2 x float> [[TMP4]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr float, ptr %a, i64 1
  %gep.b1 = getelementptr float, ptr %b, i64 1
  %a0 = load float, ptr %a
  %a1 = load float, ptr %gep.a1
  %b0 = load float, ptr %b
  %b1 = load float, ptr %gep.b1

;  A0  B0  C1  A1
;   \ /     \ /
;    +   C0  +   B1
;     \ /     \ /
;      +       +
; No MultiNode transformation here so far.
  %lane0.add1 = fadd fast float %a0, %b0
  %lane0.add2 = fadd fast float %lane0.add1, 42.0

  %lane1.add1 = fadd fast float 43.0, %a1
  %lane1.add2 = fadd fast float %lane1.add1, %b1

  %gep1 = getelementptr inbounds float, ptr %c, i64 1
  store float %lane0.add2, ptr %c, align 4
  store float %lane1.add2, ptr %gep1, align 4
  ret void
}

define void @wrap_flags_jr33142(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@wrap_flags_jr33142(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr [[B:%.*]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = mul nuw nsw <2 x i32> [[TMP0]], <i32 7, i32 7>
; CHECK-NEXT:    [[TMP3:%.*]] = add <2 x i32> [[TMP1]], <i32 -1, i32 -1>
; CHECK-NEXT:    [[TMP4:%.*]] = add <2 x i32> [[TMP3]], [[TMP2]]
; CHECK-NEXT:    store <2 x i32> [[TMP4]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %gep.b1 = getelementptr i32, ptr %b, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1
  %b0 = load i32, ptr %b
  %b1 = load i32, ptr %gep.b1

;     A0  7       A1  7
;      \ /         \ /
;   B0  *       B1  *
;    \ /         \ /
;     +  -1       +  -1
;      \ /         \ /
;       +           +
; MultiNode is re-associating compute to "(B + -1) + (A * 7)", possibly to
; shorten the dependency chain, and used to keep incorrect wraparound flags.

  %lane0.mul = mul nuw nsw i32 %a0, 7
  %lane1.mul = mul nuw nsw i32 %a1, 7
  %lane0.add1 = add nuw nsw i32 %b0, %lane0.mul
  %lane1.add1 = add nuw nsw i32 %b1, %lane1.mul

  %lane0.add2 = add nsw i32 %lane0.add1, -1
  %lane1.add2 = add nsw i32 %lane1.add1, -1

  %gep1 = getelementptr inbounds i32, ptr %c, i64 1
  store i32 %lane0.add2, ptr %c, align 4
  store i32 %lane1.add2, ptr %gep1, align 4
  ret void
}

define void @wrap_flags_alt_opcode(ptr %a, ptr %b, ptr %c) {
; CHECK-LABEL: define {{[^@]+}}@wrap_flags_alt_opcode(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP0:%.*]] = load <2 x i32>, ptr [[A:%.*]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = load <2 x i32>, ptr [[B:%.*]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = add <2 x i32> [[TMP1]], <i32 42, i32 43>
; CHECK-NEXT:    [[TMP3:%.*]] = sub <2 x i32> [[TMP1]], <i32 42, i32 43>
; CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <2 x i32> [[TMP2]], <2 x i32> [[TMP3]], <2 x i32> <i32 0, i32 3>
; CHECK-NEXT:    [[TMP5:%.*]] = add <2 x i32> [[TMP4]], [[TMP0]]
; CHECK-NEXT:    store <2 x i32> [[TMP5]], ptr [[C:%.*]], align 4
; CHECK-NEXT:    ret void
;
entry:
  %gep.a1 = getelementptr i32, ptr %a, i32 1
  %gep.b1 = getelementptr i32, ptr %b, i32 1
  %a0 = load i32, ptr %a
  %a1 = load i32, ptr %gep.a1
  %b0 = load i32, ptr %b
  %b1 = load i32, ptr %gep.b1

;  A0  B0  A1  C1
;   \ /     \ /
;    +   C0  -   B1
;     \ /     \ /
;      +       +
  %lane0.add1 = add nsw i32 %a0, %b0
  %lane0.add2 = add nsw i32 %lane0.add1, 42

  %lane1.add1 = sub nsw i32 %a1, 43
  %lane1.add2 = add nsw i32 %lane1.add1, %b1

  %gep1 = getelementptr inbounds i32, ptr %c, i64 1
  store i32 %lane0.add2, ptr %c, align 4
  store i32 %lane1.add2, ptr %gep1, align 4
  ret void
}
