; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -opaque-pointers=0 -S -mattr=avx2 -passes=vplan-vec -vplan-enable-peeling < %s | FileCheck %s
; RUN: opt -opaque-pointers=0 -S -mattr=avx2 -passes=vplan-vec -vplan-enable-peeling \
; RUN:     -vplan-enable-general-peeling-cost-model=false < %s \
; RUN: | FileCheck %s

; This test checks to make sure CFGMerger generates a remainder loop for a case
; where we have dynamic peeling (MainLoopVF - 1 is used as the default trip
; count in PeelEvaluator). Previously, this information was used incorrectly and
; RemainderEvaluator's RemainderTC = 0, and thus no remainder was assumed and
; CFGMerger asserted. We must have a remainder loop for dynamic peel cases
; because we won't know the peel loop upper bound and the remaining iterations
; may not be a multiple of VF.

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @test(i64* nocapture %ary) {
; CHECK:       target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
; CHECK-NEXT:  target triple = "x86_64-unknown-linux-gnu"
;
; CHECK:  define void @test(i64* nocapture [[ARY0:%.*]]) #0 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label %[[PEEL_CHECKZ0:.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[PEEL_CHECKZ0]]:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <4 x i64*> poison, i64* [[ARY0]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <4 x i64*> [[BROADCAST_SPLATINSERT0]], <4 x i64*> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP0:%.*]] = ptrtoint <4 x i64*> [[BROADCAST_SPLAT0]] to <4 x i64>
; CHECK-NEXT:    [[DOTEXTRACT_0_0:%.*]] = extractelement <4 x i64> [[TMP0]], i32 0
; CHECK-NEXT:    [[TMP1:%.*]] = udiv i64 [[DOTEXTRACT_0_0]], 8
; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[TMP1]], 3
; CHECK-NEXT:    [[TMP3:%.*]] = urem i64 [[TMP2]], 4
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 0, [[TMP3]]
; CHECK-NEXT:    br i1 [[TMP4]], label %[[MERGE_BLK0:.*]], label %[[PEEL_CHECKV0:.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[PEEL_CHECKV0]]:
; CHECK-NEXT:    [[TMP5:%.*]] = add i64 [[TMP3]], 4
; CHECK-NEXT:    [[TMP6:%.*]] = icmp ugt i64 [[TMP5]], 1027
; CHECK-NEXT:    br i1 [[TMP6]], label %[[MERGE_BLK1:.*]], label %[[PEELBLK0:.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[PEELBLK0]]:
; CHECK-NEXT:    br label [[FOR_BODY_SL_CLONE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB:
; CHECK-NEXT:    br label %[[MERGE_BLK0]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[MERGE_BLK0]]:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ 0, %[[PEEL_CHECKZ0]] ], [ [[INDVARS_IV_NEXT_SL_CLONE0:%.*]], [[VPLANNEDBB0:%.*]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB1:
; CHECK-NEXT:    [[TMP7:%.*]] = add i64 [[TMP3]], 4
; CHECK-NEXT:    [[TMP8:%.*]] = icmp ugt i64 [[TMP7]], 1027
; CHECK-NEXT:    br i1 [[TMP8]], label %[[MERGE_BLK1]], label [[VPLANNEDBB20:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB2:
; CHECK-NEXT:    br label [[VPLANNEDBB30:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB3:
; CHECK-NEXT:    [[UNI_PHIIND_START_BCAST_SPLATINSERT0:%.*]] = insertelement <4 x i64> poison, i64 [[UNI_PHI0]], i64 0
; CHECK-NEXT:    [[UNI_PHIIND_START_BCAST_SPLAT0:%.*]] = shufflevector <4 x i64> [[UNI_PHIIND_START_BCAST_SPLATINSERT0]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP9:%.*]] = add <4 x i64> [[UNI_PHIIND_START_BCAST_SPLAT0]], <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    [[N_ADJST0:%.*]] = sub nuw nsw i64 1027, [[TMP3]]
; CHECK-NEXT:    [[N_MOD_VF0:%.*]] = urem i64 [[N_ADJST0]], 4
; CHECK-NEXT:    [[N_VEC0:%.*]] = sub nuw nsw i64 1027, [[N_MOD_VF0]]
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI50:%.*]] = phi i64 [ [[UNI_PHI0]], [[VPLANNEDBB30]] ], [ [[TMP12:%.*]], [[VECTOR_BODY0]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <4 x i64> [ [[TMP9]], [[VPLANNEDBB30]] ], [ [[TMP11:%.*]], [[VECTOR_BODY0]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i64, i64* [[ARY0]], i64 [[UNI_PHI50]]
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast i64* [[SCALAR_GEP0]] to <4 x i64>*
; CHECK-NEXT:    store <4 x i64> [[VEC_PHI0]], <4 x i64>* [[TMP10]], align 8, !intel.preferred_alignment !0
; CHECK-NEXT:    [[TMP11]] = add nuw nsw <4 x i64> [[VEC_PHI0]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP12]] = add nuw nsw i64 [[UNI_PHI50]], 4
; CHECK-NEXT:    [[TMP13:%.*]] = icmp ult i64 [[TMP12]], [[N_VEC0]]
; CHECK-NEXT:    br i1 [[TMP13]], label [[VECTOR_BODY0]], label [[VPLANNEDBB60:%.*]], !llvm.loop !1
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[TMP14:%.*]] = mul i64 1, [[N_VEC0]]
; CHECK-NEXT:    [[TMP15:%.*]] = add i64 0, [[TMP14]]
; CHECK-NEXT:    br label [[VPLANNEDBB70:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB7:
; CHECK-NEXT:    br label [[VPLANNEDBB80:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB8:
; CHECK-NEXT:    [[TMP16:%.*]] = icmp eq i64 1027, [[N_VEC0]]
; CHECK-NEXT:    br i1 [[TMP16]], label [[FINAL_MERGE0:%.*]], label %[[MERGE_BLK1]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[MERGE_BLK1]]:
; CHECK-NEXT:    [[UNI_PHI90:%.*]] = phi i64 [ [[TMP15]], [[VPLANNEDBB80]] ], [ 0, %[[PEEL_CHECKV0]] ], [ [[UNI_PHI0]], [[VPLANNEDBB10]] ]
; CHECK-NEXT:    br label %[[REMBLK0:.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  [[REMBLK0]]:
; CHECK-NEXT:    br label [[FOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB10:
; CHECK-NEXT:    br label [[FINAL_MERGE0]]
; CHECK-EMPTY:
; CHECK-NEXT:  final.merge:
; CHECK-NEXT:    [[UNI_PHI110:%.*]] = phi i64 [ [[INDVARS_IV_NEXT0:%.*]], [[VPLANNEDBB100:%.*]] ], [ [[TMP15]], [[VPLANNEDBB80]] ]
; CHECK-NEXT:    br label [[FOR_END0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  for.body:
; CHECK-NEXT:    [[INDVARS_IV0:%.*]] = phi i64 [ [[UNI_PHI90]], %[[REMBLK0]] ], [ [[INDVARS_IV_NEXT0]], [[FOR_BODY0]] ]
; CHECK-NEXT:    [[PTR0:%.*]] = getelementptr inbounds i64, i64* [[ARY0]], i64 [[INDVARS_IV0]]
; CHECK-NEXT:    store i64 [[INDVARS_IV0]], i64* [[PTR0]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT0]] = add nuw nsw i64 [[INDVARS_IV0]], 1
; CHECK-NEXT:    [[CMP0:%.*]] = icmp ult i64 [[INDVARS_IV_NEXT0]], 1027
; CHECK-NEXT:    br i1 [[CMP0]], label [[FOR_BODY0]], label [[VPLANNEDBB100]], !llvm.loop !3
; CHECK-EMPTY:
; CHECK-NEXT:  for.body.sl.clone:
; CHECK-NEXT:    [[INDVARS_IV_SL_CLONE0:%.*]] = phi i64 [ 0, %[[PEELBLK0]] ], [ [[INDVARS_IV_NEXT_SL_CLONE0]], [[FOR_BODY_SL_CLONE0]] ]
; CHECK-NEXT:    [[PTR_SL_CLONE0:%.*]] = getelementptr inbounds i64, i64* [[ARY0]], i64 [[INDVARS_IV_SL_CLONE0]]
; CHECK-NEXT:    store i64 [[INDVARS_IV_SL_CLONE0]], i64* [[PTR_SL_CLONE0]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT_SL_CLONE0]] = add nuw nsw i64 [[INDVARS_IV_SL_CLONE0]], 1
; CHECK-NEXT:    [[CMP_SL_CLONE0:%.*]] = icmp ult i64 [[INDVARS_IV_NEXT_SL_CLONE0]], [[TMP3]]
; CHECK-NEXT:    br i1 [[CMP_SL_CLONE0]], label [[FOR_BODY_SL_CLONE0]], label [[VPLANNEDBB0]], !llvm.loop !5
; CHECK-EMPTY:
; CHECK-NEXT:  for.end:
; CHECK-NEXT:    ret void
; CHECK-NEXT:  }
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4) ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %ptr = getelementptr inbounds i64, i64* %ary, i64 %indvars.iv
  store i64 %indvars.iv, i64* %ptr, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp ult i64 %indvars.iv.next, 1027
  br i1 %cmp, label %for.body, label %for.end

for.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
