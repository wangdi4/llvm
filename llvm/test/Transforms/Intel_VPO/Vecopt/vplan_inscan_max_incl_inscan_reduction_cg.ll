; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -passes="vplan-vec" -vplan-force-vf=4 -S < %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

;; float foo(float *A, float *B) {
;;   float x = 1.0f;
;; #pragma omp simd reduction(inscan, max : x)
;; #pragma nounroll
;;   for (int i=0; i<1024; i++) {
;;     x = std::max(A[i], x);
;; #pragma omp scan inclusive(x)
;;     B[i] = x;
;;   }
;;   return x;
;; }

define float @_Z3fooPfS_(ptr %A, ptr %B) {
; CHECK-LABEL: @_Z3fooPfS_(
; CHECK-NEXT:  DIR.OMP.SIMD.1:
; CHECK-NEXT:    [[X_RED:%.*]] = alloca float, align 4
; CHECK-NEXT:    [[I_LINEAR_IV:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store float 1.000000e+00, ptr [[X_RED]], align 4
; CHECK-NEXT:    [[I_LINEAR_IV_VEC:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[I_LINEAR_IV_VEC_BASE_ADDR:%.*]] = getelementptr i32, ptr [[I_LINEAR_IV_VEC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[I_LINEAR_IV_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <4 x ptr> [[I_LINEAR_IV_VEC_BASE_ADDR]], i32 0
; CHECK-NEXT:    [[X_RED_VEC:%.*]] = alloca <4 x float>, align 16
; CHECK-NEXT:    [[X_RED_VEC_BASE_ADDR:%.*]] = getelementptr float, ptr [[X_RED_VEC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[X_RED_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <4 x ptr> [[X_RED_VEC_BASE_ADDR]], i32 0
; CHECK-NEXT:    br label [[DIR_OMP_SIMD_127:%.*]]
; CHECK:       DIR.OMP.SIMD.127:
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 16, ptr [[I_LINEAR_IV_VEC_BASE_ADDR_EXTRACT_0_]])
; CHECK-NEXT:    [[TMP0:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x float> poison, float [[TMP0]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x float> [[BROADCAST_SPLATINSERT]], <4 x float> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP1:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP2:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP3:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    call void @llvm.lifetime.start.p0(i64 16, ptr [[X_RED_VEC_BASE_ADDR_EXTRACT_0_]])
; CHECK-NEXT:    [[TMP4:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP5:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP6:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP7:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP8:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP9:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP10:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP11:%.*]] = load float, ptr [[X_RED]], align 1
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[I_LINEAR_IV]], align 1
; CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[I_LINEAR_IV]], align 1
; CHECK-NEXT:    [[TMP14:%.*]] = load i32, ptr [[I_LINEAR_IV]], align 1
; CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[I_LINEAR_IV]], align 1
; CHECK-NEXT:    [[IND_START_BCAST_SPLATINSERT:%.*]] = insertelement <4 x i32> poison, i32 [[TMP12]], i64 0
; CHECK-NEXT:    [[IND_START_BCAST_SPLAT:%.*]] = shufflevector <4 x i32> [[IND_START_BCAST_SPLATINSERT]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP16:%.*]] = add <4 x i32> [[IND_START_BCAST_SPLAT]], <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    store <4 x i32> [[TMP16]], ptr [[I_LINEAR_IV_VEC]], align 1
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ [[TMP30:%.*]], [[VPLANNEDBB21:%.*]] ], [ 0, [[VPLANNEDBB1]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ [[TMP29:%.*]], [[VPLANNEDBB21]] ], [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB1]] ]
; CHECK-NEXT:    [[UNI_PHI3:%.*]] = phi float [ [[TMP8]], [[VPLANNEDBB1]] ], [ [[DOTEXTRACT_3_:%.*]], [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[UNI_PHI4:%.*]] = phi i32 [ [[TMP12]], [[VPLANNEDBB1]] ], [ [[TMP32:%.*]], [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[VEC_PHI5:%.*]] = phi <4 x i32> [ [[TMP16]], [[VPLANNEDBB1]] ], [ [[TMP31:%.*]], [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT12:%.*]] = insertelement <4 x float> poison, float [[UNI_PHI3]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT13:%.*]] = shufflevector <4 x float> [[BROADCAST_SPLATINSERT12]], <4 x float> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    store <4 x i32> [[VEC_PHI5]], ptr [[I_LINEAR_IV_VEC]], align 1
; CHECK-NEXT:    store <4 x float> [[BROADCAST_SPLAT]], ptr [[X_RED_VEC]], align 1
; CHECK-NEXT:    br label [[VPLANNEDBB6:%.*]]
; CHECK:       VPlannedBB6:
; CHECK-NEXT:    br label [[VPLANNEDBB7:%.*]]
; CHECK:       VPlannedBB7:
; CHECK-NEXT:    [[TMP17:%.*]] = trunc <4 x i64> [[VEC_PHI]] to <4 x i32>
; CHECK-NEXT:    store <4 x i32> [[TMP17]], ptr [[I_LINEAR_IV_VEC]], align 4
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds float, ptr [[A:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x float>, ptr [[SCALAR_GEP]], align 4
; CHECK-NEXT:    [[WIDE_LOAD8:%.*]] = load <4 x float>, ptr [[X_RED_VEC]], align 4
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast olt <4 x float> [[WIDE_LOAD]], [[WIDE_LOAD8]]
; CHECK-NEXT:    [[TMP19:%.*]] = select <4 x i1> [[TMP18]], <4 x float> [[WIDE_LOAD8]], <4 x float> [[WIDE_LOAD]]
; CHECK-NEXT:    store <4 x float> [[TMP19]], ptr [[X_RED_VEC]], align 4
; CHECK-NEXT:    br label [[VPLANNEDBB9:%.*]]
; CHECK:       VPlannedBB9:
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK:       VPlannedBB10:
; CHECK-NEXT:    br label [[VPLANNEDBB11:%.*]]
; CHECK:       VPlannedBB11:
; CHECK-NEXT:    [[WIDE_LOAD11:%.*]] = load <4 x float>, ptr [[X_RED_VEC]], align 1
; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <4 x float> [[WIDE_LOAD11]], <4 x float> [[BROADCAST_SPLAT]], <4 x i32> <i32 4, i32 0, i32 1, i32 2>
; CHECK-NEXT:    [[TMP22:%.*]] = call <4 x float> @llvm.maxnum.v4f32(<4 x float> [[WIDE_LOAD11]], <4 x float> [[TMP20]])
; CHECK-NEXT:    [[TMP23:%.*]] = shufflevector <4 x float> [[TMP22]], <4 x float> [[BROADCAST_SPLAT]], <4 x i32> <i32 4, i32 5, i32 0, i32 1>
; CHECK-NEXT:    [[TMP25:%.*]] = call <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP22]], <4 x float> [[TMP23]])
; CHECK-NEXT:    [[TMP27:%.*]] = call <4 x float> @llvm.maxnum.v4f32(<4 x float> [[TMP25]], <4 x float> [[BROADCAST_SPLAT13]])
; CHECK-NEXT:    [[DOTEXTRACT_3_]] = extractelement <4 x float> [[TMP27]], i32 3
; CHECK-NEXT:    store <4 x float> [[TMP27]], ptr [[X_RED_VEC]], align 1
; CHECK-NEXT:    br label [[VPLANNEDBB15:%.*]]
; CHECK:       VPlannedBB15:
; CHECK-NEXT:    br label [[VPLANNEDBB16:%.*]]
; CHECK:       VPlannedBB16:
; CHECK-NEXT:    br label [[VPLANNEDBB17:%.*]]
; CHECK:       VPlannedBB17:
; CHECK-NEXT:    [[WIDE_LOAD16:%.*]] = load <4 x float>, ptr [[X_RED_VEC]], align 4
; CHECK-NEXT:    [[WIDE_LOAD17:%.*]] = load <4 x i32>, ptr [[I_LINEAR_IV_VEC]], align 4
; CHECK-NEXT:    [[TMP28:%.*]] = sext <4 x i32> [[WIDE_LOAD17]] to <4 x i64>
; CHECK-NEXT:    [[TMP28_EXTRACT_0:%.*]] = extractelement <4 x i64> [[TMP28]], i32 0
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds float, ptr [[B:%.*]], i64 [[TMP28_EXTRACT_0]]
; CHECK-NEXT:    store <4 x float> [[WIDE_LOAD16]], ptr [[SCALAR_GEP]], align 4
; CHECK-NEXT:    [[TMP29]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP30]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    br label [[VPLANNEDBB21:%.*]]
; CHECK:       VPlannedBB21:
; CHECK-NEXT:    br label [[VPLANNEDBB22:%.*]]
; CHECK:       VPlannedBB22:
; CHECK-NEXT:    [[TMP31]] = add <4 x i32> [[VEC_PHI5]], <i32 4, i32 4, i32 4, i32 4>
; CHECK-NEXT:    [[TMP32]] = add i32 [[UNI_PHI4]], 4
; CHECK-NEXT:    [[TMP33:%.*]] = icmp uge i64 [[TMP30]], 1024
; CHECK-NEXT:    br i1 [[TMP33]], label [[VPLANNEDBB23:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB23:
; CHECK-NEXT:    store float [[DOTEXTRACT_3_]], ptr [[X_RED]], align 1
;
DIR.OMP.SIMD.1:
  %x.red = alloca float, align 4
  %i.linear.iv = alloca i32, align 4
  store float 1.000000e+00, ptr %x.red, align 4
  br label %DIR.OMP.SIMD.127

DIR.OMP.SIMD.127:                                 ; preds = %DIR.OMP.SIMD.1
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.MAX:INSCAN.TYPED"(ptr %x.red, float 0.000000e+00, i32 1, i64 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(i8* null, i32 0), "QUAL.OMP.NORMALIZED.UB:TYPED"(i8* null, i32 0), "QUAL.OMP.LINEAR:IV.TYPED"(ptr %i.linear.iv, i32 0, i32 1, i32 1) ]
  br label %DIR.VPO.END.GUARD.MEM.MOTION.426

DIR.VPO.END.GUARD.MEM.MOTION.426:                 ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.4, %DIR.OMP.SIMD.127
  %indvars.iv = phi i64 [ %indvars.iv.next, %DIR.VPO.END.GUARD.MEM.MOTION.4 ], [ 0, %DIR.OMP.SIMD.127 ]
  br label %DIR.VPO.GUARD.MEM.MOTION.2.split

DIR.VPO.GUARD.MEM.MOTION.2.split:                 ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.426
  %guard.start1 = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(ptr %x.red) ]
  br label %DIR.VPO.GUARD.MEM.MOTION.1

DIR.VPO.GUARD.MEM.MOTION.1:                       ; preds = %DIR.VPO.GUARD.MEM.MOTION.2.split
  %1 = trunc i64 %indvars.iv to i32
  store i32 %1, ptr %i.linear.iv, align 4
  %arrayidx = getelementptr inbounds float, ptr %A, i64 %indvars.iv
  %2 = load float, ptr %arrayidx, align 4
  %3 = load float, ptr %x.red, align 4
  %cmp.i = fcmp fast olt float %2, %3
  %4 = select i1 %cmp.i, float %3, float %2
  store float %4, ptr %x.red, align 4
  br label %DIR.VPO.END.GUARD.MEM.MOTION.552

DIR.VPO.END.GUARD.MEM.MOTION.552:                 ; preds = %DIR.VPO.GUARD.MEM.MOTION.1
  call void @llvm.directive.region.exit(token %guard.start1) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
  br label %DIR.OMP.SCAN.4

DIR.OMP.SCAN.4:                                   ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.552
  %5 = call token @llvm.directive.region.entry() [ "DIR.OMP.SCAN"(), "QUAL.OMP.INCLUSIVE"(ptr %x.red, i64 1) ]
  br label %DIR.OMP.SCAN.2

DIR.OMP.SCAN.2:                                   ; preds = %DIR.OMP.SCAN.4
  fence acq_rel
  br label %DIR.OMP.END.SCAN.6

DIR.OMP.END.SCAN.6:                               ; preds = %DIR.OMP.SCAN.2
  call void @llvm.directive.region.exit(token %5) [ "DIR.OMP.END.SCAN"() ]
  br label %DIR.OMP.END.SCAN.9.split

DIR.OMP.END.SCAN.9.split:
  %guard.start2 = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(ptr %x.red) ]
  br label %DIR.OMP.END.SCAN.3

DIR.OMP.END.SCAN.3:                               ; preds = %DIR.OMP.END.SCAN.6
  %6 = load float, ptr %x.red, align 4
  %7 = load i32, ptr %i.linear.iv, align 4
  %idxprom1 = sext i32 %7 to i64
  %arrayidx2 = getelementptr inbounds float, ptr %B, i64 %idxprom1
  store float %6, ptr %arrayidx2, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  br label %DIR.VPO.END.GUARD.MEM.MOTION.8

DIR.VPO.END.GUARD.MEM.MOTION.8:                   ; preds = %DIR.OMP.END.SCAN.3
  call void @llvm.directive.region.exit(token %guard.start2) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
  br label %DIR.VPO.END.GUARD.MEM.MOTION.4

DIR.VPO.END.GUARD.MEM.MOTION.4:                   ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.8
  %exitcond.not = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.5, label %DIR.VPO.END.GUARD.MEM.MOTION.426

DIR.OMP.END.SIMD.5:                               ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.4
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.529

DIR.OMP.END.SIMD.529:                             ; preds = %DIR.OMP.END.SIMD.5
  %8 = load float, ptr %x.red, align 4
  ret float %8
}

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)
