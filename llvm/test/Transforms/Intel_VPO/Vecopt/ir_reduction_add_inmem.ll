; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to verify VPlan's functionality and generated vector code for in-memory
; binop reduction.

; RUN: opt -vplan-vec -vplan-print-after-vpentity-instrs -vplan-force-vf=2 -S < %s 2>&1 | FileCheck %s

define i32 @foo(i32* nocapture readonly %A, i64 %N, i32 %init) {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: foo:for.body
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i32* [[VP_SUM:%.*]] = allocate-priv i32*, OrigAlign = 4
; CHECK-NEXT:     i32 [[VP_LOAD:%.*]] = load i32* [[SUM0:%.*]]
; CHECK-NEXT:     i32 [[VP_SUMRED_INIT:%.*]] = reduction-init i32 0 i32 [[VP_LOAD]]
; CHECK-NEXT:     store i32 [[VP_SUMRED_INIT]] i32* [[VP_SUM]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB2]] ],  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ]
; CHECK-NEXT:     i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     i32 [[VP_A_I:%.*]] = load i32* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i32 [[VP_SUM_LD:%.*]] = load i32* [[VP_SUM]]
; CHECK-NEXT:     i32 [[VP_ADD:%.*]] = add i32 [[VP_A_I]] i32 [[VP_SUM_LD]]
; CHECK-NEXT:     store i32 [[VP_ADD]] i32* [[VP_SUM]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP_EXITCOND:%.*]] = icmp eq i64 [[VP_INDVARS_IV_NEXT]] i64 [[N0:%.*]]
; CHECK-NEXT:     br i1 [[VP_EXITCOND]], [[BB3:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     i32 [[VP_LOAD_1:%.*]] = load i32* [[VP_SUM]]
; CHECK-NEXT:     i32 [[VP_SUMRED_FINAL:%.*]] = reduction-final{u_add} i32 [[VP_LOAD_1]]
; CHECK-NEXT:     store i32 [[VP_SUMRED_FINAL]] i32* [[SUM0]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>

; Checks for generated vector code
; CHECK-LABEL: define i32 @foo
; CHECK:       VPlannedBB:
; CHECK-NEXT:    [[TMP0:%.*]] = and i64 [[N0]], 4294967294
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 0, [[TMP0]]
; CHECK-NEXT:    br i1 [[TMP1]], label [[MERGE_BLK0:%.*]], label [[VPLANNEDBB10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB1:
; CHECK-NEXT:    br label [[VPLANNEDBB20:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB2:
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[SUM0]], align 1
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[SUM0]], align 1
; CHECK-NEXT:    [[RED_INIT_INSERT0:%.*]] = insertelement <2 x i32> zeroinitializer, i32 [[TMP2]], i32 0
; CHECK-NEXT:    store <2 x i32> [[RED_INIT_INSERT0]], <2 x i32>* [[SUM_VEC0:%.*]], align 1
; CHECK-NEXT:    [[TMP4:%.*]] = and i64 [[N0]], 4294967294
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP8:%.*]], [[VECTOR_BODY0]] ], [ 0, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP7:%.*]], [[VECTOR_BODY0]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[A0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP5]], align 4
; CHECK-NEXT:    [[WIDE_LOAD40:%.*]] = load <2 x i32>, <2 x i32>* [[SUM_VEC0]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = add nsw <2 x i32> [[WIDE_LOAD0]], [[WIDE_LOAD40]]
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32>* [[SUM_VEC0]], align 4
; CHECK-NEXT:    [[TMP7]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP8]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP9:%.*]] = icmp uge i64 [[TMP8]], [[TMP4]]
; CHECK-NEXT:    br i1 [[TMP9]], label [[VPLANNEDBB50:%.*]], label [[VECTOR_BODY0]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[WIDE_LOAD60:%.*]] = load <2 x i32>, <2 x i32>* [[SUM_VEC0]], align 1
; CHECK-NEXT:    [[TMP10:%.*]] = call i32 @llvm.vector.reduce.add.v2i32(<2 x i32> [[WIDE_LOAD60]])
; CHECK-NEXT:    store i32 [[TMP10]], i32* [[SUM0]], align 1
; CHECK-NEXT:    [[TMP11:%.*]] = mul i64 1, [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 0, [[TMP11]]
; CHECK-NEXT:    br label [[VPLANNEDBB70:%.*]]
;
entry:
  %sum = alloca i32, align 4
  store i32 %init, i32* %sum, align 4
  br label %begin.simd

begin.simd:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD"(i32* %sum) ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %begin.simd ]
  %arrayidx = getelementptr inbounds i32, i32* %A, i64 %indvars.iv
  %A.i = load i32, i32* %arrayidx, align 4
  %sum.ld = load i32, i32* %sum, align 4
  %add = add nsw i32 %A.i, %sum.ld
  store i32 %add, i32* %sum, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body

for.cond.cleanup.loopexit:                             ; preds = %for.body
  br label %end.simd

end.simd:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:
  %fin = load i32, i32* %sum, align 4
  ret i32 %fin

}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
