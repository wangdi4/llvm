; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; This test checks for widened allocas for the private and wide-stores being generated to
; the widened alloca for stores to the privates (including stores under a mask).

; void foo(long *ip, long *ip2)
; {
;   long index;
;
; #pragma omp simd simdlen(4)
;   for (index = 0; index < 1024; index++) {
;     long val;
;
;     val = index;
;     if (ip[index])
;       val = ip2[index];
;
;     ip[index] = val;
;   }
; }
;
; RUN: opt -VPlanDriver -S -enable-vp-value-codegen=true %s | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind uwtable
define void @foo(i64* nocapture %ip, i64* nocapture readonly %ip2) {
; CHECK:       entry:
; CHECK-NEXT:    [[PRIVATE_MEM0:%.*]] = alloca <4 x i64>, align 32
; CHECK-NEXT:    [[PRIVATE_MEM_BC0:%.*]] = bitcast <4 x i64>* [[PRIVATE_MEM0]] to i64*
; CHECK-NEXT:    [[PRIVATE_MEM_BASE_ADDR0:%.*]] = getelementptr i64, i64* [[PRIVATE_MEM_BC0]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK:       vector.body:
; CHECK:         [[UNI_PHI0:%uni.phi.*]] = phi i64 [ 0, %vector.ph ], [ [[TMP12:%.*]], %vector.body ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, %vector.ph ], [ [[TMP11:%.*]], %vector.body ]
; CHECK:         store <4 x i64> %vec.phi, <4 x i64>* [[PRIVATE_MEM0]], align 8
; CHECK:         [[SCALAR_GEP0:%.*]] = getelementptr inbounds i64, i64* %ip, i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP6:%.*]] = bitcast i64* [[SCALAR_GEP0]] to <4 x i64>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <4 x i64>, <4 x i64>* [[TMP6]], align 8
; CHECK-NEXT:    [[TMP7:%.*]] = icmp eq <4 x i64> [[WIDE_LOAD0]], zeroinitializer
; CHECK-NEXT:    [[TMP8:%.*]] = xor <4 x i1> [[TMP7]], <i1 true, i1 true, i1 true, i1 true>
; CHECK-NEXT:    [[SCALAR_GEP10:%.*]] = getelementptr inbounds i64, i64* %ip2, i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast i64* [[SCALAR_GEP10]] to <4 x i64>*
; CHECK-NEXT:    [[WIDE_MASKED_LOAD0:%.*]] = call <4 x i64> @llvm.masked.load.v4i64.p0v4i64(<4 x i64>* [[TMP9]], i32 8, <4 x i1> [[TMP8]], <4 x i64> undef)
; CHECK-NEXT:    call void @llvm.masked.store.v4i64.p0v4i64(<4 x i64> [[WIDE_MASKED_LOAD0]], <4 x i64>* [[PRIVATE_MEM0]], i32 8, <4 x i1> [[TMP8]])
; CHECK:         [[TMP11]] = add nuw nsw <4 x i64> [[VEC_PHI0]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP12]] = add nuw nsw i64 [[UNI_PHI0]], 4
;
entry:
  %val = alloca i64, align 8
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4), "QUAL.OMP.PRIVATE"(i64* %val) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  %0 = bitcast i64* %val to i8*
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %if.end, %DIR.QUAL.LIST.END.2
  %.omp.iv.012 = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %add3, %if.end ]
  call void @llvm.lifetime.start(i64 8, i8* nonnull %0)
  store i64 %.omp.iv.012, i64* %val, align 8
  %arrayidx = getelementptr inbounds i64, i64* %ip, i64 %.omp.iv.012
  %1 = load i64, i64* %arrayidx, align 8
  %tobool = icmp eq i64 %1, 0
  br i1 %tobool, label %if.end, label %if.then

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx1 = getelementptr inbounds i64, i64* %ip2, i64 %.omp.iv.012
  %2 = load i64, i64* %arrayidx1, align 8
  store i64 %2, i64* %val, align 8
  br label %if.end

if.end:                                           ; preds = %omp.inner.for.body, %if.then
  %3 = phi i64 [ %.omp.iv.012, %omp.inner.for.body ], [ %2, %if.then ]
  store i64 %3, i64* %arrayidx, align 8
  call void @llvm.lifetime.end(i64 8, i8* nonnull %0)
  %add3 = add nuw nsw i64 %.omp.iv.012, 1
  %exitcond = icmp eq i64 %add3, 1024
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %if.end
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:                              ; preds = %omp.loop.exit
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start(i64, i8* nocapture)

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end(i64, i8* nocapture)

; Function Attrs: argmemonly nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: argmemonly nounwind
declare void @llvm.directive.region.exit(token)
