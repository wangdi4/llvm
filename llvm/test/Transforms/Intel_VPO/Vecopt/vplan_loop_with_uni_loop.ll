; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: asserts
; RUN: opt < %s -passes=vplan-vec -disable-output -vplan-dump-da -vplan-force-vf=2 2>&1 | FileCheck %s

; Verify the divergence information for the outermost loop for.body.

define void @test1(ptr nocapture %ptr, i64 %n) {
; CHECK:       Printing Divergence info for Loop at depth 1 containing: [[BB0:BB[0-9]+]]<header>,[[BB1:BB[0-9]+]],[[BB2:BB[0-9]+]]<latch><exiting>
; CHECK-NEXT:      Loop at depth 2 containing: [[BB1]]<header><latch><exiting>
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB0]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_IV:%.*]] = phi  [ i64 [[VP_IV_IND_INIT:%.*]], [[BB3:BB[0-9]+]] ],  [ i64 [[VP_IV_NEXT:%.*]], [[BB2]] ]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB1]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_IV2:%.*]] = phi  [ i64 0, [[BB0]] ],  [ i64 [[VP_IV_NEXT2:%.*]], [[BB1]] ]
; CHECK-NEXT:  Divergent: [Shape: Strided, Stride: ?] i64 [[VP_ROW:%.*]] = mul i64 [[N0:%.*]] i64 [[VP_IV]]
; CHECK-NEXT:  Divergent: [Shape: Strided, Stride: ?] i64 [[VP_IDX:%.*]] = add i64 [[VP_ROW]] i64 [[VP_IV2]]
; CHECK-NEXT:  Divergent: [Shape: Random] i32 [[VP_TRUNC:%.*]] = trunc i64 [[VP_IDX]] to i32
; CHECK-NEXT:  Divergent: [Shape: Random] float [[VP_VAL:%.*]] = sitofp i32 [[VP_TRUNC]] to float
; CHECK-NEXT:  Divergent: [Shape: Strided, Stride: ?] ptr [[VP_ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[PTR0:%.*]] i64 [[VP_IDX]]
; CHECK-NEXT:  Divergent: [Shape: Strided, Stride: ?] store float [[VP_VAL]] ptr [[VP_ARRAYIDX]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_IV_NEXT2]] = add i64 [[VP_IV2]] i64 1
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_EXITCOND2:%.*]] = icmp eq i64 [[VP_IV_NEXT2]] i64 [[N0]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_EXITCOND2]], [[BB2]], [[BB1]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB2]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_IV_NEXT]] = add i64 [[VP_IV]] i64 [[VP_IV_IND_INIT_STEP:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_EXITCOND:%.*]] = icmp uge i64 [[VP_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_EXITCOND]], [[BB4:BB[0-9]+]], [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB4]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB5]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br <External Block>
;
entry:
  %cmp = icmp sgt i64 %n, 0
  br i1 %cmp, label %for.body.lr.ph, label %exit

for.body.lr.ph:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %iv = phi i64 [ 0, %for.body.lr.ph ], [ %iv.next, %for.latch ]
  br label %for.body2

for.body2:
  %iv2 = phi i64 [ 0, %for.body ], [ %iv.next2, %for.body2 ]
  %row = mul i64 %n, %iv
  %idx = add i64 %row, %iv2
  %trunc = trunc i64 %idx to i32
  %val = sitofp i32 %trunc to float
  %arrayidx = getelementptr inbounds float, ptr %ptr, i64 %idx
  store float %val, ptr %arrayidx, align 4
  %iv.next2 = add nuw nsw i64 %iv2, 1
  %exitcond2 = icmp eq i64 %iv.next2, %n
  br i1 %exitcond2, label %for.latch, label %for.body2

for.latch:
  %iv.next = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, %n
  br i1 %exitcond, label %for.end, label %for.body

for.end:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"()]
  br label %exit

exit:
  ret void
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)
