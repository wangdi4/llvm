; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Test that we auto-recognize and handle unconditional liveout private.

; RUN: opt -S -passes="vplan-vec" %s | FileCheck %s

define void @simd_loop(ptr %A, ptr %B) #0 {
; CHECK-LABEL: @simd_loop(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[PRIVATE:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[PRIVATE_VEC:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[PRIVATE_VEC_BASE_ADDR:%.*]] = getelementptr i32, ptr [[PRIVATE_VEC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK:         br label [[DIR_OMP_SIMD_3:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1:%.*]] ], [ [[TMP2:%.*]], [[VECTOR_BODY:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB1]] ], [ [[TMP1:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i32, ptr [[A:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i32>, ptr [[SCALAR_GEP]], align 8
; CHECK-NEXT:    [[TMP1]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP2]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP2]], 1024
; CHECK-NEXT:    br i1 [[TMP3]], label [[VECTOR_BODY]], label [[VPLANNEDBB3:%.*]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB3:
; CHECK-NEXT:    [[EXTRACTED_PRIV:%.*]] = extractelement <4 x i32> [[WIDE_LOAD]], i64 3
; CHECK-NEXT:    call void @llvm.lifetime.end.p0(i64 16, ptr [[PRIVATE_VEC_BC_E:%.*]])
; CHECK-NEXT:    br label [[VPLANNEDBB4:%.*]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    br label [[FINAL_MERGE:%.*]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI5:%.*]] = phi i32 [ [[EXTRACTED_PRIV]], [[VPLANNEDBB4]] ]
; CHECK-NEXT:    [[UNI_PHI6:%.*]] = phi i64 [ 1024, [[VPLANNEDBB4]] ]
; CHECK-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[INDVARS_IV:%.*]] = phi i64 [ [[INDVARS_IV_NEXT:%.*]], [[OMP_INNER_FOR_BODY:%.*]] ]
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr [[A]], i64 [[INDVARS_IV]]
; CHECK-NEXT:    [[PRIV_OUTGOING:%.*]] = load i32, ptr [[ARRAYIDX]], align 8
; CHECK-NEXT:    [[INDVARS_IV_NEXT]] = add nuw nsw i64 [[INDVARS_IV]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp ne i64 [[INDVARS_IV_NEXT]], 1024
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY]]
; CHECK:       omp.loop.exit:
; CHECK-NEXT:    [[DOT_LCSSA:%.*]] = phi i32 [ [[UNI_PHI5]], [[FINAL_MERGE]] ]
; CHECK-NEXT:    store i32 [[DOT_LCSSA]], ptr [[PRIVATE]], align 8
; CHECK-NEXT:    br label [[DIR_OMP_END_SIMD_1:%.*]]
; CHECK:       DIR.OMP.END.SIMD.1:
; CHECK-NEXT:    br label [[DIR_QUAL_LIST_END_2:%.*]]
; CHECK:       DIR.QUAL.LIST.END.2:
; CHECK-NEXT:    ret void
;
entry:
  %private = alloca i32, align 4
  br label %DIR.OMP.SIMD.3

DIR.OMP.SIMD.3:                                   ; preds = %entry
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4), "QUAL.OMP.LASTPRIVATE:TYPED"(ptr %private, i32 0, i32 1) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.3, %omp.inner.for.body
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.3 ], [ %indvars.iv.next, %omp.inner.for.body ]
  %arrayidx = getelementptr inbounds i32, ptr %A, i64 %indvars.iv
  %priv.outgoing = load i32, ptr %arrayidx, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp ne i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %omp.inner.for.body, label %omp.loop.exit

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  %..lcssa = phi i32 [ %priv.outgoing, %omp.inner.for.body ]
  store i32 %..lcssa, ptr %private, align 8
  br label %DIR.OMP.END.SIMD.1

DIR.OMP.END.SIMD.1:                               ; preds = %omp.loop.exit
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.END.SIMD.1
  ret void
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)

