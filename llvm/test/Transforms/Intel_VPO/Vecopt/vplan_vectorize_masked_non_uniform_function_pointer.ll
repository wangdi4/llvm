; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -S < %s -VPlanDriver -vplan-force-vf=2 2>&1 | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

declare i32 @__intel_indirect_call_i32(i32(i32)*, ...) #2

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #3

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #3
; Function Attrs: nounwind uwtable
define dso_local void @_ZGVbN4_direct(i32* nocapture %a, i32* nocapture readonly %c, i32 (i32)** nocapture readonly %func, i64 %n) local_unnamed_addr #1 {
; CHECK:  define dso_local void @_ZGVbN4_direct(i32* nocapture [[A0:%.*]], i32* nocapture readonly [[C0:%.*]], i32 (i32)** nocapture readonly [[FUNC0:%.*]], i64 [[N0:%.*]]) local_unnamed_addr #2 {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    br label [[PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  preheader:
; CHECK-NEXT:    [[N_MOD_VF0:%.*]] = urem i64 [[N0]], 2
; CHECK-NEXT:    [[N_VEC0:%.*]] = sub i64 [[N0]], [[N_MOD_VF0]]
; CHECK-NEXT:    [[CMP_ZERO0:%.*]] = icmp eq i64 [[N_VEC0]], 0
; CHECK-NEXT:    br i1 [[CMP_ZERO0]], label [[SCALAR_PH0:%.*]], label [[VECTOR_PH0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.ph:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <2 x i64> undef, i64 [[N0]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <2 x i64> [[BROADCAST_SPLATINSERT0]], <2 x i64> undef, <2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ 0, [[VECTOR_PH0]] ], [ [[TMP22:%.*]], [[PRED_LOAD_CONTINUE0:%.*]] ]
; CHECK-NEXT:    [[UNI_PHI10:%.*]] = phi i64 [ [[TMP21:%.*]], [[PRED_LOAD_CONTINUE0]] ], [ 0, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP20:%.*]], [[PRED_LOAD_CONTINUE0]] ], [ <i64 0, i64 1>, [[VECTOR_PH0]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = add nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq <2 x i64> [[TMP0]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32 (i32)*, i32 (i32)** [[FUNC0]], i64 [[UNI_PHI10]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32 (i32)** [[SCALAR_GEP0]] to <2 x i32 (i32)*>*
; CHECK-NEXT:    [[WIDE_MASKED_LOAD0:%.*]] = call <2 x i32 (i32)*> @llvm.masked.load.v2p0f_i32i32f.p0v2p0f_i32i32f(<2 x i32 (i32)*>* [[TMP2]], i32 8, <2 x i1> [[TMP1]], <2 x i32 (i32)*> undef)
; CHECK-NEXT:    [[WIDE_MASKED_LOAD_EXTRACT_1_0:%.*]] = extractelement <2 x i32 (i32)*> [[WIDE_MASKED_LOAD0]], i32 1
; CHECK-NEXT:    [[WIDE_MASKED_LOAD_EXTRACT_0_0:%.*]] = extractelement <2 x i32 (i32)*> [[WIDE_MASKED_LOAD0]], i32 0
; CHECK-NEXT:    [[SCALAR_GEP20:%.*]] = getelementptr inbounds i32, i32* [[C0]], i64 [[UNI_PHI10]]
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i32* [[SCALAR_GEP20]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_MASKED_LOAD30:%.*]] = call <2 x i32> @llvm.masked.load.v2i32.p0v2i32(<2 x i32>* [[TMP3]], i32 4, <2 x i1> [[TMP1]], <2 x i32> undef)
; CHECK-NEXT:    [[WIDE_MASKED_LOAD3_EXTRACT_1_0:%.*]] = extractelement <2 x i32> [[WIDE_MASKED_LOAD30]], i32 1
; CHECK-NEXT:    [[WIDE_MASKED_LOAD3_EXTRACT_0_0:%.*]] = extractelement <2 x i32> [[WIDE_MASKED_LOAD30]], i32 0
; CHECK-NEXT:    [[PREDICATE0:%.*]] = extractelement <2 x i1> [[TMP1]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i1 [[PREDICATE0]], true
; CHECK-NEXT:    br i1 [[TMP4]], label [[PRED_CALL_IF0:%.*]], label [[TMP7:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.call.if:
; CHECK-NEXT:    [[TMP5:%.*]] = call i32 (i32 (i32)*, ...) @__intel_indirect_call_i32(i32 (i32)* [[WIDE_MASKED_LOAD_EXTRACT_0_0]], i32 [[WIDE_MASKED_LOAD3_EXTRACT_0_0]])
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> undef, i32 [[TMP5]], i32 0
; CHECK-NEXT:    br label [[TMP7]]
; CHECK-EMPTY:
; CHECK-NEXT:  7:
; CHECK-NEXT:    [[TMP8:%.*]] = phi <2 x i32> [ undef, [[VECTOR_BODY0]] ], [ [[TMP6]], [[PRED_CALL_IF0]] ]
; CHECK-NEXT:    br label [[PRED_CALL_CONTINUE0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.call.continue:
; CHECK-NEXT:    [[PREDICATE40:%.*]] = extractelement <2 x i1> [[TMP1]], i64 1
; CHECK-NEXT:    [[TMP9:%.*]] = icmp eq i1 [[PREDICATE40]], true
; CHECK-NEXT:    br i1 [[TMP9]], label [[PRED_CALL_IF70:%.*]], label [[TMP12:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.call.if7:
; CHECK-NEXT:    [[TMP10:%.*]] = call i32 (i32 (i32)*, ...) @__intel_indirect_call_i32(i32 (i32)* [[WIDE_MASKED_LOAD_EXTRACT_1_0]], i32 [[WIDE_MASKED_LOAD3_EXTRACT_1_0]])
; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <2 x i32> [[TMP8]], i32 [[TMP10]], i32 1
; CHECK-NEXT:    br label [[TMP12]]
; CHECK-EMPTY:
; CHECK-NEXT:  12:
; CHECK-NEXT:    [[TMP13:%.*]] = phi <2 x i32> [ [[TMP8]], [[PRED_CALL_CONTINUE0]] ], [ [[TMP11]], [[PRED_CALL_IF70]] ]
; CHECK-NEXT:    br label [[PRED_CALL_CONTINUE80:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.call.continue8:
; CHECK-NEXT:    [[TMP14:%.*]] = bitcast <2 x i1> [[TMP1]] to i2
; CHECK-NEXT:    [[TMP15:%.*]] = icmp ne i2 [[TMP14]], 0
; CHECK-NEXT:    br i1 [[TMP15]], label [[PRED_LOAD_IF0:%.*]], label [[TMP17:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.load.if:
; CHECK-NEXT:    [[TMP16:%.*]] = load i32, i32* [[A0]], align 4
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT50:%.*]] = insertelement <2 x i32> undef, i32 [[TMP16]], i32 0
; CHECK-NEXT:    br label [[TMP17]]
; CHECK-EMPTY:
; CHECK-NEXT:  17:
; CHECK-NEXT:    [[TMP18:%.*]] = phi <2 x i32> [ undef, [[PRED_CALL_CONTINUE80]] ], [ [[BROADCAST_SPLATINSERT50]], [[PRED_LOAD_IF0]] ]
; CHECK-NEXT:    br label [[PRED_LOAD_CONTINUE0]]
; CHECK-EMPTY:
; CHECK-NEXT:  pred.load.continue:
; CHECK-NEXT:    [[BROADCAST_SPLAT60:%.*]] = shufflevector <2 x i32> [[TMP18]], <2 x i32> undef, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP19:%.*]] = add nsw <2 x i32> [[BROADCAST_SPLAT60]], [[TMP13]]
; CHECK-NEXT:    [[TMP20]] = add nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP21]] = add nsw i64 [[UNI_PHI10]], 2
; CHECK-NEXT:    [[TMP22]] = add i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP23:%.*]] = icmp eq i64 [[TMP22]], [[N_VEC0]]
; CHECK-NEXT:    br i1 [[TMP23]], label [[VPLANNEDBB0:%.*]], label [[VECTOR_BODY0]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB:
; CHECK-NEXT:    [[TMP24:%.*]] = mul i64 1, [[N_VEC0]]
; CHECK-NEXT:    [[TMP25:%.*]] = add i64 0, [[TMP24]]
; CHECK-NEXT:    br label [[MIDDLE_BLOCK0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  middle.block:
; CHECK-NEXT:    [[CMP_N0:%.*]] = icmp eq i64 [[N0]], [[N_VEC0]]
; CHECK-NEXT:    br i1 [[CMP_N0]], label [[LOOP_EXIT0:%.*]], label [[SCALAR_PH0]]
; CHECK-EMPTY:
; CHECK-NEXT:  scalar.ph:
; CHECK-NEXT:    [[BC_RESUME_VAL0:%.*]] = phi i64 [ 0, [[PREHEADER0]] ], [ [[TMP25]], [[MIDDLE_BLOCK0]] ]
; CHECK-NEXT:    br label [[FOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  for.body:
; CHECK-NEXT:    [[IV_PHI0:%.*]] = phi i64 [ [[IV0:%.*]], [[IF_END0:%.*]] ], [ [[BC_RESUME_VAL0]], [[SCALAR_PH0]] ]
; CHECK-NEXT:    [[CHECK0:%.*]] = add nsw i64 [[IV_PHI0]], 2
; CHECK-NEXT:    [[COND0:%.*]] = icmp eq i64 [[CHECK0]], [[N0]]
; CHECK-NEXT:    br i1 [[COND0]], label [[IF_THEN0:%.*]], label [[IF_END0]]
; CHECK-EMPTY:
; CHECK-NEXT:  if.then:
; CHECK-NEXT:    [[ARRAYIDX10:%.*]] = getelementptr inbounds i32 (i32)*, i32 (i32)** [[FUNC0]], i64 [[IV_PHI0]]
; CHECK-NEXT:    [[LD_FUNC0:%.*]] = load i32 (i32)*, i32 (i32)** [[ARRAYIDX10]], align 8
; CHECK-NEXT:    [[ARRAYIDX20:%.*]] = getelementptr inbounds i32, i32* [[C0]], i64 [[IV_PHI0]]
; CHECK-NEXT:    [[LD_C0:%.*]] = load i32, i32* [[ARRAYIDX20]], align 4
; CHECK-NEXT:    [[CALL0:%.*]] = call i32 (i32 (i32)*, ...) @__intel_indirect_call_i32(i32 (i32)* [[LD_FUNC0]], i32 [[LD_C0]]) #0
; CHECK-NEXT:    [[LD_A0:%.*]] = load i32, i32* [[A0]], align 4
; CHECK-NEXT:    [[ADD0:%.*]] = add nsw i32 [[LD_A0]], [[CALL0]]
; CHECK-NEXT:    br label [[IF_END0]]
; CHECK-EMPTY:
; CHECK-NEXT:  if.end:
; CHECK-NEXT:    [[IV0]] = add nsw i64 [[IV_PHI0]], 1
; CHECK-NEXT:    [[EXITCOND0:%.*]] = icmp eq i64 [[IV0]], [[N0]]
; CHECK-NEXT:    br i1 [[EXITCOND0]], label [[LOOP_EXIT0]], label [[FOR_BODY0]], !llvm.loop !2
; CHECK-EMPTY:
; CHECK-NEXT:  loop.exit:
; CHECK-NEXT:    br label [[END0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  end:
; CHECK-NEXT:    ret void
; CHECK-NEXT:  }
;
entry:
  br label %preheader

preheader:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %iv.phi = phi i64 [ %iv, %if.end ], [ 0, %preheader ]
  %check = add nsw i64 %iv.phi, 2
  %cond = icmp eq i64 %check, %n
  br i1 %cond, label %if.then, label %if.end

if.then:
  %arrayidx1 = getelementptr inbounds i32 (i32)*, i32 (i32)** %func, i64 %iv.phi
  %ld.func = load i32 (i32)*, i32 (i32)** %arrayidx1, align 8
  %arrayidx2 = getelementptr inbounds i32, i32* %c, i64 %iv.phi
  %ld.c = load i32, i32* %arrayidx2, align 4
  %call = call i32 (i32(i32)*, ...) @__intel_indirect_call_i32(i32 (i32)* %ld.func, i32 %ld.c) #2
  %ld.a = load i32, i32* %a, align 4
  %add = add nsw i32 %ld.a, %call
  br label %if.end

if.end:
  %iv = add nsw i64 %iv.phi, 1
  %exitcond = icmp eq i64 %iv, %n
  br i1 %exitcond, label %loop.exit, label %for.body

loop.exit:
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %end

end:
  ret void
}

attributes #1 = { "vector-variants"="_ZGVbM4vvvv_direct,_ZGVbN4vvvv_direct" }
attributes #2 = { "vector-variants"="_ZGVbM4v___intel_indirect_call_i32,_ZGVbN4v___intel_indirect_call_i32" }
attributes #3 = { nounwind }


