; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
;
; Test to check that HIR CG does not crash on masked scalar div with scalar operand.
;
; RUN: opt -hir-ssa-deconstruction -hir-temp-cleanup -hir-vec-dir-insert -hir-vplan-vec -vplan-force-vf=2 -disable-output -print-after=hir-vplan-vec %s 2>&1 | FileCheck %s
;
; The incoming HIR contains uniform division, which is scalarized, and we
; crash on the that there is no DDRef generated for its operand. The current logic
; in generateHIR assumes that we always generate vector variant of instruction,
; while that does not happen always.

;    BEGIN REGION { }
;         %entry.region = @llvm.directive.region.entry(); [ DIR.VPO.AUTO.VEC() ]
;         + DO i1 = 0, 1023, 1   <DO_LOOP>
;         |   if ((%lp2)[i1] != 0)
;         |   {
;         |      %v = (%lp1)[0];
;         |      %div = trunc.i64.i8(%v)  /  %n1;
;         |      (%lp2)[i1] = %div;
;         |   }
;         + END LOOP
;         @llvm.directive.region.exit(%entry.region); [ DIR.VPO.END.AUTO.VEC() ]
;    END REGION

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @foo(i64* noalias %lp1, i64* noalias %lp2, i64 noundef %n1) {
; CHECK:       BEGIN REGION { modified }
; CHECK:             + DO i1 = 0, 1023, 2   <DO_LOOP> <auto-vectorized> <novectorize>
; CHECK-NEXT:        |   [[DOTVEC0:%.*]] = (<2 x i64>*)([[LP20:%.*]])[i1]
; CHECK-NEXT:        |   [[DOTVEC10:%.*]] = [[DOTVEC0]] != 0
; CHECK-NEXT:        |   [[TMP0:%.*]] = bitcast.<2 x i1>.i2([[DOTVEC10]])
; CHECK-NEXT:        |   [[CMP0:%.*]] = [[TMP0]] != 0
; CHECK-NEXT:        |   [[DOTUNIFLOAD0:%.*]] = undef
; CHECK-NEXT:        |   if ([[CMP0]] == 1)
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[DOTUNIFLOAD0]] = ([[LP10:%.*]])[0]
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   [[DOTVEC20:%.*]] = [[DOTUNIFLOAD0]]  &  255
; CHECK-NEXT:        |   [[TMP1:%.*]] = bitcast.<2 x i1>.i2([[DOTVEC10]])
; CHECK-NEXT:        |   [[CMP30:%.*]] = [[TMP1]] != 0
; CHECK-NEXT:        |   [[DOTSCAL0:%.*]] = undef
; CHECK-NEXT:        |   if ([[CMP30]] == 1)
; CHECK-NEXT:        |   {
; CHECK-NEXT:        |      [[EXTRACT_0_0:%.*]] = extractelement [[DOTVEC20]],  0
; CHECK-NEXT:        |      [[DOTSCAL0]] = [[EXTRACT_0_0]]  /  [[N10:%.*]];
; CHECK-NEXT:        |   }
; CHECK-NEXT:        |   (<2 x i64>*)([[LP20]])[i1] = [[DOTSCAL0]], Mask = @{[[DOTVEC10]]}
; CHECK-NEXT:        + END LOOP
; CHECK:       END REGION
;
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.inc
  %l1.09 = phi i64 [ 0, %entry ], [ %inc, %for.inc ]
  %arrayidx = getelementptr inbounds i64, i64* %lp2, i64 %l1.09
  %0 = load i64, i64* %arrayidx, align 8
  %tobool.not = icmp eq i64 %0, 0
  br i1 %tobool.not, label %for.inc, label %if.then

if.then:                                          ; preds = %for.body
  %arrayidx1 = getelementptr inbounds i64, i64* %lp1, i64 0
  %v = load i64, i64* %arrayidx1, align 8
  %v1 = and i64 %v, 255
  %div = sdiv i64 %v1, %n1
  store i64 %div, i64* %arrayidx, align 8
  br label %for.inc

for.inc:                                          ; preds = %for.body, %if.then
  %inc = add nuw nsw i64 %l1.09, 1
  %exitcond.not = icmp eq i64 %inc, 1024
  br i1 %exitcond.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.inc
  ret void
}

