; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Test to check VPValue-based LLVM-IR codegen for scalar and aggregate loop privates in the candidate
; SIMD loop.

; RUN: opt -vplan-enable-soa=false -passes=vplan-vec -vplan-force-vf=4 -S < %s | FileCheck %s

; CHECK-LABEL: @foo(
; CHECK-NEXT:  entry:
; CHECK:         [[ARR_PRIV:%.*]] = alloca [1024 x i32], align 4
; CHECK-NEXT:    [[ARR_PRIV_VEC:%.*]] = alloca [4 x [1024 x i32]], align 4
; CHECK-NEXT:    [[ARR_PRIV_VEC_BC:%.*]] = bitcast [4 x [1024 x i32]]* [[ARR_PRIV_VEC]] to [1024 x i32]*
; CHECK-NEXT:    [[ARR_PRIV_VEC_BASE_ADDR:%.*]] = getelementptr [1024 x i32], [1024 x i32]* [[ARR_PRIV_VEC_BC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[SCALAR_PRIV_VEC:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[SCALAR_PRIV_VEC_BC:%.*]] = bitcast <4 x i32>* [[SCALAR_PRIV_VEC]] to i32*
; CHECK-NEXT:    [[SCALAR_PRIV_VEC_BASE_ADDR:%.*]] = getelementptr i32, i32* [[SCALAR_PRIV_VEC_BC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[SCALAR_PRIV_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <4 x i32*> [[SCALAR_PRIV_VEC_BASE_ADDR]], i32 0
; CHECK:       vector.body:
; CHECK:         [[WIDE_LOAD:%.*]] = load <4 x i32>, <4 x i32>* [[SCALAR_PRIV_VEC]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = add <4 x i32> [[WIDE_LOAD]], <i32 42, i32 42, i32 42, i32 42>
; CHECK-NEXT:    store <4 x i32> [[TMP0]], <4 x i32>* [[SCALAR_PRIV_VEC]], align 4
; CHECK-NEXT:    [[MM_VECTORGEP:%.*]] = getelementptr inbounds [1024 x i32], <4 x [1024 x i32]*> [[ARR_PRIV_VEC_BASE_ADDR]], <4 x i64> zeroinitializer, <4 x i64> [[VEC_PHI:%.*]]
; CHECK-NEXT:    [[WIDE_MASKED_GATHER:%.*]] = call <4 x i32> @llvm.masked.gather.v4i32.v4p0i32(<4 x i32*> [[MM_VECTORGEP]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i32> poison)
; CHECK-NEXT:    [[TMP1:%.*]] = add <4 x i32> [[WIDE_MASKED_GATHER]], <i32 42, i32 42, i32 42, i32 42>
; CHECK-NEXT:    call void @llvm.masked.scatter.v4i32.v4p0i32(<4 x i32> [[TMP1]], <4 x i32*> [[MM_VECTORGEP]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>)
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i32, i32* [[SCALAR_PRIV_VEC_BASE_ADDR_EXTRACT_0_]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP]] to <4 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD3:%.*]] = load <4 x i32>, <4 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = add <4 x i32> [[WIDE_LOAD3]], <i32 42, i32 42, i32 42, i32 42>
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i32* [[SCALAR_GEP]] to <4 x i32>*
; CHECK-NEXT:    store <4 x i32> [[TMP3]], <4 x i32>* [[TMP4]], align 4


target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @foo(i32* %iarr) {
entry:
  %scalar.priv = alloca i32, align 4
  %arr.priv = alloca [1024 x i32], align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"(i32* %scalar.priv, i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"([1024 x i32]* %arr.priv, i32 0, i32 1024) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.QUAL.LIST.END.2
  %iv = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %iv.add, %omp.inner.for.body ]
  %scalar.priv.load = load i32, i32* %scalar.priv, align 4
  %use.scalar = add i32 %scalar.priv.load, 42
  store i32 %use.scalar, i32* %scalar.priv, align 4

  %arr.priv.gep = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv, i64 0, i64 %iv
  %arr.priv.load = load i32, i32* %arr.priv.gep, align 4
  %use.arr = add i32 %arr.priv.load, 42
  store i32 %use.arr, i32* %arr.priv.gep, align 4

  %scalar.priv.gep = getelementptr inbounds i32, i32* %scalar.priv, i64 0
  %scalar.priv.load1 = load i32, i32* %scalar.priv.gep, align 4
  %use.scalar1 = add i32 %scalar.priv.load1, 42
  store i32 %use.scalar1, i32* %scalar.priv.gep, align 4

  %iv.add = add nuw nsw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.add, 100
  br i1 %exitcond, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:                                    ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
