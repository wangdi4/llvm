; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vplan-vec -vplan-force-vf=4 -vplan-force-inscan-reduction-vectorization=true -S < %s 2>&1 | FileCheck %s
; RUN: opt -passes="vplan-vec" -vplan-force-vf=4 -vplan-force-inscan-reduction-vectorization=true -S < %s 2>&1 | FileCheck %s

;; void foo(float *A, float *B) {
;;   float x = 0.0f;
;; #pragma omp simd reduction(inscan, + : x)
;;   for (int i=0; i<1024; i++) {
;;     x += A[i];
;; #pragma omp scan inclusive(x)
;;     B[i] = x;
;;   }
;; }

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @omp_scan(float* %A, float* %B) {
;
; CHECK:  define void @omp_scan(float* [[A0:%.*]], float* [[B0:%.*]]) {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[X_RED0:%.*]] = alloca float, align 4
; CHECK:         [[X_RED_VEC0:%.*]] = alloca <4 x float>, align 16
; CHECK:          br label [[DIR_OMP_SIMD_10:%.*]]
; CHECK-EMPTY:
; CHECK:        VPlannedBB1:
; CHECK:         [[TMP1:%.*]] = bitcast <4 x float>* [[X_RED_VEC0]] to i8*
; CHECK:         [[TMP2:%.*]] = load float, float* [[X_RED0]], align 1
; CHECK:         br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ 0, [[VPLANNEDBB10:%.*]] ], [ [[TMP21:%.*]], [[VPLANNEDBB110:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB10]] ], [ [[TMP20:%.*]], [[VPLANNEDBB110]] ]
; CHECK-NEXT:    [[UNI_PHI30:%.*]] = phi float [ [[TMP2]], [[VPLANNEDBB10]] ], [ [[EXTRACT_LAST_VECTOR_LANE0:%.*]], [[VPLANNEDBB110]] ]
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT0:%.*]] = insertelement <4 x float> poison, float [[UNI_PHI30]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT0:%.*]] = shufflevector <4 x float> [[BROADCAST_SPLATINSERT0]], <4 x float> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    store <4 x float> zeroinitializer, <4 x float>* [[X_RED_VEC0]], align 1
; CHECK-NEXT:    [[TRUNC:%.*]] = trunc <4 x i64> [[VEC_PHI0]] to <4 x i32>
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds float, float* [[A0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP12:%.*]] = bitcast float* [[SCALAR_GEP0]] to <4 x float>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <4 x float>, <4 x float>* [[TMP12]], align 4
; CHECK-NEXT:    [[WIDE_LOAD60:%.*]] = load <4 x float>, <4 x float>* [[X_RED_VEC0]], align 4
; CHECK-NEXT:    [[TMP13:%.*]] = fadd fast <4 x float> [[WIDE_LOAD60]], [[WIDE_LOAD0]]
; CHECK-NEXT:    store <4 x float> [[TMP13]], <4 x float>* [[X_RED_VEC0]], align 4
; CHECK-NEXT:    br label [[VPLANNEDBB70:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    br label [[VPLANNEDBB80:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB6:
; CHECK-NEXT:    [[WIDE_LOAD90:%.*]] = load <4 x float>, <4 x float>* [[X_RED_VEC0]], align 1
; CHECK-NEXT:    [[TMP14:%.*]] = shufflevector <4 x float> [[WIDE_LOAD90]], <4 x float> zeroinitializer, <4 x i32> <i32 4, i32 0, i32 1, i32 2>
; CHECK-NEXT:    [[TMP15:%.*]] = fadd fast <4 x float> [[WIDE_LOAD90]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <4 x float> [[TMP15]], <4 x float> zeroinitializer, <4 x i32> <i32 4, i32 5, i32 0, i32 1>
; CHECK-NEXT:    [[TMP17:%.*]] = fadd fast <4 x float> [[TMP15]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = fadd fast <4 x float> [[TMP17]], [[BROADCAST_SPLAT0]]
; CHECK-NEXT:    [[EXTRACT_LAST_VECTOR_LANE0]] = extractelement <4 x float> [[TMP18]], i32 3
; CHECK-NEXT:    store <4 x float> [[TMP18]], <4 x float>* [[X_RED_VEC0]], align 1
; CHECK-NEXT:    br label [[VPLANNEDBB100:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB8:
; CHECK-NEXT:    br label [[VPLANNEDBB110]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB9:
; CHECK-NEXT:    [[WIDE_LOAD120:%.*]] = load <4 x float>, <4 x float>* [[X_RED_VEC0]], align 4
; CHECK-NEXT:    [[MM_SCALARGEP0:%.*]] = getelementptr inbounds float, float* [[B:%.*]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[BITCAST:%.*]] = bitcast float* [[MM_SCALARGEP0]] to <4 x float>*
; CHECK-NEXT:    store <4 x float> [[WIDE_LOAD120]], <4 x float>* [[BITCAST]]
; CHECK-NEXT:    [[TMP20]] = add nuw nsw <4 x i64> [[VEC_PHI0]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP21]] = add nuw nsw i64 [[UNI_PHI0]], 4
; CHECK-NEXT:    [[TMP24:%.*]] = icmp uge i64 [[TMP21]], 1024
; CHECK-NEXT:    br i1 [[TMP24]], label [[VPLANNEDBB160:%.*]], label [[VECTOR_BODY0]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB12:
; CHECK-NEXT:    [[WIDE_LOAD170:%.*]] = load <4 x float>, <4 x float>* [[X_RED_VEC0]], align 1
; CHECK-NEXT:    [[WIDE_LOAD17_EXTRACT_3_0:%.*]] = extractelement <4 x float> [[WIDE_LOAD170]], i32 3
; CHECK-NEXT:    store float [[WIDE_LOAD17_EXTRACT_3_0]], float* [[X_RED0]], align 1
; CHECK:         br label [[VPLANNEDBB190:%.*]]
;
entry:
  %x.red = alloca float, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  store float 0.000000e+00, float* %x.red, align 4
  br label %DIR.OMP.SIMD.138

DIR.OMP.SIMD.138:                                 ; preds = %DIR.OMP.SIMD.1
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD:INSCAN.TYPED"(float* %x.red, float zeroinitializer, i32 1, i64 1) ]
  br label %DIR.OMP.SIMD.139

DIR.OMP.SIMD.139:                                 ; preds = %DIR.OMP.SIMD.138
  br label %DIR.OMP.END.SCAN.335

DIR.OMP.END.SCAN.335:                             ; preds = %DIR.OMP.END.SCAN.3, %DIR.OMP.SIMD.139
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.139 ], [ %indvars.iv.next, %DIR.OMP.END.SCAN.3 ]
  %1 = trunc i64 %indvars.iv to i32
  %arrayidx = getelementptr inbounds float, float* %A, i64 %indvars.iv
  %2 = load float, float* %arrayidx, align 4
  %3 = load float, float* %x.red, align 4
  %add5 = fadd fast float %3, %2
  store float %add5, float* %x.red, align 4
  br label %DIR.OMP.SCAN.3

DIR.OMP.SCAN.3:                                   ; preds = %DIR.OMP.END.SCAN.335
  %4 = call token @llvm.directive.region.entry() [ "DIR.OMP.SCAN"(), "QUAL.OMP.INCLUSIVE"(float* %x.red, i64 1) ]
  br label %DIR.OMP.SCAN.2

DIR.OMP.SCAN.2:                                   ; preds = %DIR.OMP.SCAN.3
  fence acq_rel
  br label %DIR.OMP.END.SCAN.5

DIR.OMP.END.SCAN.5:                               ; preds = %DIR.OMP.SCAN.2
  call void @llvm.directive.region.exit(token %4) [ "DIR.OMP.END.SCAN"() ]
  br label %DIR.OMP.END.SCAN.3

DIR.OMP.END.SCAN.3:                               ; preds = %DIR.OMP.END.SCAN.5
  %5 = load float, float* %x.red, align 4
  %arrayidx7 = getelementptr inbounds float, float* %B, i64 %indvars.iv
  store float %5, float* %arrayidx7, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond.not = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.1, label %DIR.OMP.END.SCAN.335, !llvm.loop !0

DIR.OMP.END.SIMD.1:                               ; preds = %DIR.OMP.END.SIMD.7
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %DIR.OMP.END.SIMD.4, %entry
  ret void
}

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)

!0 = distinct !{!0, !1, !2}
!1 = !{!"llvm.loop.vectorize.enable", i1 true}
!2 = !{!"llvm.loop.vectorize.ivdep_loop", i32 0}
