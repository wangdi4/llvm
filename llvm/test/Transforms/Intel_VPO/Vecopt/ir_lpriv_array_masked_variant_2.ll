; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to check VPlan transformation and CG for last private array with SOA layout in masked mode loop.
; TODO: Add HIR check lines when SOA is supported.
; RUN: opt -S -vplan-vec -vplan-force-vf=2 -vplan-print-after-create-masked-vplan -vplan-enable-masked-variant -vplan-vec-scenario="n0;v2;m2" < %s | FileCheck %s


target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @foo() {
; CHECK-LABEL:  VPlan after emitting masked variant:
; CHECK-NEXT:  VPlan IR for: foo:omp.inner.for.body.i.#{{[0-9]+}}.cloned.masked
; CHECK-NEXT:    [[BB6:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]: # preds: [[BB6]]
; CHECK-NEXT:     [DA: Div] [12 x i16]* [[VP1:%.*]] = allocate-priv [12 x i16]*, OrigAlign = 2
; CHECK-NEXT:     [DA: Div] i8* [[VP2:%.*]] = bitcast [12 x i16]* [[VP1]]
; CHECK-NEXT:     [DA: Div] call i64 24 i8* [[VP2]] void (i64, i8*)* @llvm.lifetime.start.p0i8
; CHECK-NEXT:     [DA: Div] i32 [[VP3:%.*]] = induction-init{add} i32 live-in0 i32 1
; CHECK-NEXT:     [DA: Uni] i32 [[VP4:%.*]] = induction-init-step{add} i32 1
; CHECK-NEXT:     [DA: Uni] br [[BB8:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB8]]: # preds: [[BB7]], new_latch
; CHECK-NEXT:     [DA: Div] i32 [[VP__OMP_IV_I_LOCAL_03_1:%.*]] = phi  [ i32 [[VP_ADD5_I_1:%.*]], new_latch ],  [ i32 [[VP3]], [[BB7]] ]
; CHECK-NEXT:     [DA: Div] i1 [[VP5:%.*]] = icmp ult i32 [[VP__OMP_IV_I_LOCAL_03_1]] i32 undef
; CHECK-NEXT:     [DA: Div] br i1 [[VP5]], [[BB9:BB[0-9]+]], new_latch
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB9]]: # preds: [[BB8]]
; CHECK-NEXT:       [DA: Div] i16* [[VP_ARRAYIDX_I_1:%.*]] = getelementptr inbounds [12 x i16]* [[VP1]] i64 0 i64 1
; CHECK-NEXT:       [DA: Div] store i16 1 i16* [[VP_ARRAYIDX_I_1]]
; CHECK-NEXT:       [DA: Uni] br [[BB10:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB10]]: # preds: [[BB9]]
; CHECK-NEXT:       [DA: Uni] br new_latch
; CHECK-EMPTY:
; CHECK-NEXT:    new_latch: # preds: [[BB10]], [[BB8]]
; CHECK-NEXT:     [DA: Div] i32 [[VP_ADD5_I_1]] = add i32 [[VP__OMP_IV_I_LOCAL_03_1]] i32 [[VP4]]
; CHECK-NEXT:     [DA: Div] i1 [[VP6:%.*]] = icmp ult i32 [[VP_ADD5_I_1]] i32 undef
; CHECK-NEXT:     [DA: Uni] i1 [[VP7:%.*]] = all-zero-check i1 [[VP6]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP7]], [[BB11:BB[0-9]+]], [[BB8]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB11]]: # preds: new_latch
; CHECK-NEXT:     [DA: Uni] i32 [[VP8:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:     [DA: Uni] private-final-array-masked [12 x i16]* [[VP1]] [12 x i16]* [[B3_I_LPRIV0:%.*]] i1 [[VP5]]
; CHECK-NEXT:     [DA: Uni] br [[BB12:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB12]]: # preds: [[BB11]]
; CHECK-NEXT:     [DA: Uni] br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i32 [[VP8]]
;
; CHECK:	VPlannedBB19:                                     ; preds = %VPlannedBB17
; CHECK-NEXT:	  %20 = bitcast <2 x i1> %12 to i2
; CHECK-NEXT:	  %ctlz = call i2 @llvm.ctlz.i2(i2 %20, i1 true)
; CHECK-NEXT:	  %21 = sub i2 1, %ctlz
; CHECK-NEXT:	  br label %array.last.private.loop20
; CHECK-EMPTY:
; CHECK-NEXT:	array.last.private.loop20:                        ; preds = %array.last.private.loop20, %VPlannedBB19
; CHECK-NEXT:	  %22 = phi i64 [ 0, %VPlannedBB19 ], [ %26, %array.last.private.loop20 ]
; CHECK-NEXT:	  %23 = getelementptr [12 x <2 x i16>], [12 x <2 x i16>]* %.soa.vec, i64 0, i64 %22, i2 %21
; CHECK-NEXT:	  %24 = load i16, i16* %23, align 2
; CHECK-NEXT:	  %25 = getelementptr [12 x i16], [12 x i16]* %b3.i.lpriv, i64 0, i64 %22
; CHECK-NEXT:	  store i16 %24, i16* %25, align 2
; CHECK-NEXT:	  %26 = add i64 %22, 1
; CHECK-NEXT:	  %27 = icmp ult i64 %26, 12
; CHECK-NEXT:	  br i1 %27, label %array.last.private.loop20, label %array.last.private.loop.exit21

entry:
  %b3.i.lpriv = alloca [12 x i16], align 1
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LASTPRIVATE:TYPED"([12 x i16]* %b3.i.lpriv, i16 0, i32 12) ]
  br label %omp.inner.for.body.i

omp.inner.for.body.i:                             ; preds = %omp.body.continue.i, %DIR.OMP.SIMD.112
  %.omp.iv.i.local.03 = phi i32 [ %add5.i, %omp.body.continue.i ], [ 0, %DIR.OMP.SIMD.1 ]
  %arrayidx.i = getelementptr inbounds [12 x i16], [12 x i16]* %b3.i.lpriv, i64 0, i64 1
  store i16 1, i16* %arrayidx.i, align 2
  br label %omp.body.continue.i

omp.body.continue.i:                              ; preds = %if.then.i, %omp.inner.for.body.i
  %add5.i = add nuw nsw i32 %.omp.iv.i.local.03, 1
  %exitcond.not = icmp eq i32 %add5.i, undef
  br i1 %exitcond.not, label %omp.inner.for.cond.i.DIR.OMP.END.SIMD.5.i.loopexit_crit_edge, label %omp.inner.for.body.i

omp.inner.for.cond.i.DIR.OMP.END.SIMD.5.i.loopexit_crit_edge: ; preds = %omp.body.continue.i
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
