; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 2
; RUN: opt -passes=vplan-vec -mtriple=x86_64 -mcpu=skylake-avx512 -vec-clone-legalize-enabled -S < %s  | FileCheck %s

; Test case to check that call to vector variant is properly legalized.

%struct.point = type { double, double }

declare nofpclass(nan inf) double @Origin(double noundef nofpclass(nan inf)) local_unnamed_addr #0

define x86_regcallcc nofpclass(nan inf) <8 x double> @_ZGVZN8vu_CallerFunc(<8 x double> noundef nofpclass(nan inf) %x, ptr noundef %vals) local_unnamed_addr #1 {
; CHECK-LABEL: define x86_regcallcc nofpclass(nan inf) <8 x double> @_ZGVZN8vu_CallerFunc
; CHECK-SAME: (<8 x double> noundef nofpclass(nan inf) [[X:%.*]], ptr noundef [[VALS:%.*]]) local_unnamed_addr #[[ATTR1:[0-9]+]] {
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i32 [ 0, [[VPLANNEDBB1:%.*]] ], [ [[TMP2:%.*]], [[VPLANNEDBB4:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <8 x i32> [ <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>, [[VPLANNEDBB1]] ], [ [[TMP1:%.*]], [[VPLANNEDBB4]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr double, ptr [[VEC_X:%.*]], i32 [[UNI_PHI]]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <8 x double>, ptr [[SCALAR_GEP]], align 64
; CHECK-NEXT:    [[PART0:%.*]] = shufflevector <8 x double> [[WIDE_LOAD]], <8 x double> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK-NEXT:    [[PART1:%.*]] = shufflevector <8 x double> [[WIDE_LOAD]], <8 x double> undef, <4 x i32> <i32 4, i32 5, i32 6, i32 7>
; CHECK-NEXT:    [[CALLRES:%.*]] = call x86_regcallcc { <4 x double>, <4 x double> } @_ZGVYN8v_Origin(<4 x double> noundef nofpclass(nan inf) [[PART0]], <4 x double> noundef nofpclass(nan inf) [[PART1]]) #[[ATTR4:[0-9]+]]
; CHECK-NEXT:    [[XTRACT0:%.*]] = extractvalue { <4 x double>, <4 x double> } [[CALLRES]], 0
; CHECK-NEXT:    [[XTRACT1:%.*]] = extractvalue { <4 x double>, <4 x double> } [[CALLRES]], 1
; CHECK-NEXT:    [[COMBINED:%.*]] = shufflevector <4 x double> [[XTRACT0]], <4 x double> [[XTRACT1]], <8 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7>
; CHECK-NEXT:    [[SCALAR_GEP3:%.*]] = getelementptr double, ptr [[VEC_RETVAL:%.*]], i32 [[UNI_PHI]]
; CHECK-NEXT:    store <8 x double> [[COMBINED]], ptr [[SCALAR_GEP3]], align 64
; CHECK-NEXT:    br label [[VPLANNEDBB4]]
;
entry:
  %alloca.vals = alloca ptr, align 8
  store ptr %vals, ptr %alloca.vals, align 8
  %vec.x = alloca <8 x double>, align 64
  %vec.retval = alloca <8 x double>, align 64
  store <8 x double> %x, ptr %vec.x, align 64
  br label %simd.begin.region

simd.begin.region:                                ; preds = %entry
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 8), "QUAL.OMP.UNIFORM:TYPED"(ptr %alloca.vals, ptr null, i32 1) ]
  br label %simd.loop.preheader

simd.loop.preheader:                              ; preds = %simd.begin.region
  %load.vals = load ptr, ptr %alloca.vals, align 8
  br label %simd.loop.header

simd.loop.header:                                 ; preds = %simd.loop.latch, %simd.loop.preheader
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.latch ]
  %vec.x.gep1 = getelementptr double, ptr %vec.x, i32 %index
  %vec.x.elem2 = load double, ptr %vec.x.gep1, align 8
  %call = call fast nofpclass(nan inf) double @Origin(double noundef nofpclass(nan inf) %vec.x.elem2) #2
  %vec.retval.gep = getelementptr double, ptr %vec.retval, i32 %index
  store double %call, ptr %vec.retval.gep, align 8
  br label %simd.loop.latch

simd.loop.latch:                                  ; preds = %simd.loop.header
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 8
  br i1 %vl.cond, label %simd.loop.header, label %simd.end.region, !llvm.loop !0

simd.end.region:                                  ; preds = %simd.loop.latch
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %return

return:                                           ; preds = %simd.end.region
  %vec.ret = load <8 x double>, ptr %vec.retval, align 64
  ret <8 x double> %vec.ret
}

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #2

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #2

attributes #0 = { "vector-variants"="_ZGVYN8v_Origin,_ZGVYM8v_Origin" }
attributes #1 = { "prefer-vector-width"="512" }
attributes #2 = { nounwind }

!0 = distinct !{!0, !1}
!1 = !{!"llvm.loop.unroll.disable"}
