; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

; Test that SOA analyses correctly rejects SOA layout for private when
; its alias is merged by safe select and then by unsafe phi.
; The source code looks like below.
;
; int64_t a[32];
; int64_t b[32];
; int64_t *p1 = a;
; void func(int64_t *ptr, int64_t *alt, bool pred, int64 v) {
;   int64_t *p1 = a;
;   int64_t *p2 = b;
;
;   int64_t *p = pred ? p1 : p2;
;   #pragma omp simd private(a, b) simdlen(16)
;   for (int i = 0; i < 16; i++) {
;      int64_t *p2 = p;
;     int64_t v2 = *p;
;     if (pred) {
;       p = &ptr[i];
;     }
;     *p = v;
;   }
; }
;
; RUN: opt -vplan-dump-soa-info -passes=vplan-vec -vplan-force-vf=4 -disable-output < %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux"

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)

define void @_ZGVeN16uuu__ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E11AtomicTests(i64 %_arg_m_capacity, ptr %ptr, i1 zeroext %cmp.i.i) {
;
; CHECK-LABEL:  SOA profitability:
; CHECK-NEXT:  SOAUnsafe = [[VP_ALT:%.*]] (alt)
; CHECK-NEXT:  SOAUnsafe = [[VP__SROA_0:%.*]] (.sroa.0)
entry:
  %.sroa.0 = alloca [32 x i64], align 8
  %alt= alloca [32 x i64], align 8
  br label %simd.begin.region

simd.begin.region:                                ; preds = %entry
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 16), "QUAL.OMP.UNIFORM:TYPED"(ptr %ptr, i64 0, i32 1), "QUAL.OMP.UNIFORM"(i1 %cmp.i.i), "QUAL.OMP.PRIVATE:TYPED"(ptr %.sroa.0, i64 0, i32 32),"QUAL.OMP.PRIVATE:TYPED"(ptr %alt, i64 0, i32 32) ]
  br label %simd.loop.preheader

simd.loop.preheader:                              ; preds = %simd.begin.region
  %.sroa.0.0..sroa_cast = addrspacecast ptr %.sroa.0 to ptr addrspace(4)
  %alt.cast = addrspacecast ptr %alt to ptr addrspace(4)
  %select = select i1 %cmp.i.i, ptr addrspace(4) %.sroa.0.0..sroa_cast, ptr addrspace(4) %alt.cast
  br label %simd.loop.header

simd.loop.header:                                 ; preds = %simd.loop.latch, %simd.loop.preheader
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.latch ]
  store i64 %_arg_m_capacity, ptr %.sroa.0, align 8
  %cond.i.i = load i64, ptr addrspace(4) %select, align 8
  %sel.cast = addrspacecast ptr addrspace(4) %select to ptr
  br i1 %cmp.i.i, label %t_block, label %simd.loop.latch

t_block:
  %add.ptr.i14 = getelementptr inbounds i64, ptr %ptr, i32 %index
  br label %simd.loop.latch

simd.loop.latch:                                  ; preds = %simd.loop.header
  %st.ptr = phi ptr [%add.ptr.i14, %t_block], [%sel.cast, %simd.loop.header]
  store i64 %cond.i.i, ptr %st.ptr, align 4
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 16
  br i1 %vl.cond, label %simd.loop.header, label %simd.end.region

simd.end.region:                                  ; preds = %simd.loop.latch
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %return

return:                                           ; preds = %simd.end.region
  ret void
}
