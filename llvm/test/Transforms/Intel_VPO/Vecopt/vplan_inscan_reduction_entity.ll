; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
;; Test this for IR path only at this point, as HIR framework bails out both
;; due to unrecognized pragmas and a present atomic instruction.
; RUN: opt -opaque-pointers=0 -disable-output -passes="vplan-vec" -vplan-print-scalvec-results -vplan-entities-dump -vplan-force-vf=2 -S < %s 2>&1 | FileCheck %s
; REQUIRES: asserts

;; void foo(float *A, float *B) {
;;   float x = 0.0f;
;; #pragma omp simd reduction(inscan, + : x)
;;   for (int i=0; i<1024; i++) {
;;     x += A[i];
;; #pragma omp scan inclusive(x)
;;     B[i] = x;
;;   }
;; }

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @omp_scan(float* %A, float* %B) {
;
; CHECK-LABEL:  Reduction list
; CHECK-NEXT:   (+) Start: float* [[X_RED0:%.*]]
; CHECK-NEXT:    Linked values:
; CHECK-NEXT:    inscan ReductionKind: inclusive
; CHECK-NEXT:   Memory: float* [[X_RED0]]
; CHECK-EMPTY:
; CHECK-NEXT:  Induction list
; CHECK-NEXT:   IntInduction(+) Start: i64 0 Step: i64 1 StartVal: i64 0 EndVal: i64 1024 BinOp: [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_NEXT:%.*]] = add i64 [[VP_INDVARS_IV:%.*]] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:    Linked values:
; CHECK-EMPTY:
; CHECK-NEXT:   IntInduction(+) Start: i32 [[VP0:%.*]] Step: i32 1 StartVal: ? EndVal: ? need close form
; CHECK-NEXT:    Linked values:
; CHECK-NEXT:   Memory: i32* [[I_LINEAR_IV0:%.*]]
; CHECK:         [[BB2:BB[0-9]+]]: # preds: [[BB1:BB[0-9]+]]
; CHECK:          [DA: Div, SVA: (FV )] float* [[VP_X_RED:%.*]] = allocate-priv float*, OrigAlign = 4 (SVAOpBits )
; CHECK:          [DA: Uni, SVA: (F  )] float [[VP_LOAD:%.*]] = load float* [[X_RED0]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] float [[VP_X_REDINSCAN_RED_INIT:%.*]] = reduction-init-scalar float 0.000000e+00 float [[VP_LOAD]] (SVAOpBits 0->F 1->F )
; CHECK:          [DA: Uni, SVA: (F  )] br [[BB0:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB0]]: # preds: [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT:%.*]], [[BB2]] ],  [ i64 [[VP_INDVARS_IV_NEXT]], [[BB3]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] float [[VP_INSCAN_ACCUM:%.*]] = phi  [ float [[VP_X_REDINSCAN_RED_INIT]], [[BB2]] ],  [ float [[VP3:%.*]], [[BB3]] ] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP4:%.*]] = phi  [ i32 [[VP_I_LINEAR_IV_IND_INIT:%.*]], [[BB2]] ],  [ i32 [[VP5:%.*]], [[BB3]] ] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP4]] i32* [[VP_I_LINEAR_IV:%.*]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store float 0.000000e+00 float* [[VP_X_RED]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB13:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB13]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB14:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB14]]: # preds: [[BB13]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB15:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB15]]: # preds: [[BB14]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP0]] = trunc i64 [[VP_INDVARS_IV]] to i32 (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP0]] i32* [[VP_I_LINEAR_IV]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] float* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds float* [[A0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP6:%.*]] = load float* [[VP_ARRAYIDX]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP7:%.*]] = load float* [[VP_X_RED]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP_ADD5:%.*]] = fadd float [[VP7]] float [[VP6]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store float [[VP_ADD5]] float* [[VP_X_RED]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB4:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB15]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB44:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB44]]: # preds: [[BB4]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB5:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB44]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP_LOAD_2:%.*]] = load float* [[VP_X_RED]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP_INCL_SCAN:%.*]] = running-inclusive-reduction{fadd} float [[VP_LOAD_2]] float [[VP_INSCAN_ACCUM]] float 0.000000e+00 (SVAOpBits 0->V 1->F 2->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store float [[VP_INCL_SCAN]] float* [[VP_X_RED]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (  L)] float [[VP3]] = extract-last-vector-lane float [[VP_INCL_SCAN]] (SVAOpBits 0->L )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB6:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB5]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB66:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB66]]: # preds: [[BB6]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB23:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB23]]: # preds: [[BB66]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float [[VP8:%.*]] = load float* [[VP_X_RED]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP9:%.*]] = load i32* [[VP_I_LINEAR_IV]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP_IDXPROM6:%.*]] = sext i32 [[VP9]] to i64 (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] float* [[VP_ARRAYIDX7:%.*]] = getelementptr inbounds float* [[B0:%.*]] i64 [[VP_IDXPROM6]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store float [[VP8]] float* [[VP_ARRAYIDX7]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F )] br [[BB20:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB20]]: # preds: [[BB23]]
; CHECK-NEXT:     [DA: Uni, SVA: (F )] br [[BB21:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB21]]: # preds: [[BB20]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP5]] = add i32 [[VP4]] i32 [[VP_I_LINEAR_IV_IND_INIT_STEP:%.*]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp uge i64 [[VP_INDVARS_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB7:BB[0-9]+]], [[BB0]] (SVAOpBits 0->F 1->F 2->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] float [[VP_X_REDINSCAN_RED_FINAL:%.*]] = reduction-final-inscan float [[VP3]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] store float [[VP_X_REDINSCAN_RED_FINAL]] float* [[X_RED0]] (SVAOpBits 0->F 1->F )
; CHECK:          [DA: Uni, SVA: (F  )] br [[BB8:BB[0-9]+]] (SVAOpBits 0->F )
;

entry:
  %x.red = alloca float, align 4
  %i.linear.iv = alloca i32, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %entry
  store float 0.000000e+00, float* %x.red, align 4
  br label %DIR.OMP.SIMD.138

DIR.OMP.SIMD.138:                                 ; preds = %DIR.OMP.SIMD.1
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD:INSCAN.TYPED"(float* %x.red, float zeroinitializer, i32 1, i64 1), "QUAL.OMP.LINEAR:IV.TYPED"(i32* %i.linear.iv, i32 0, i32 1, i32 1) ]
  br label %DIR.VPO.END.GUARD.MEM.MOTION.426

DIR.VPO.END.GUARD.MEM.MOTION.426:                 ; preds = %DIR.OMP.SIMD.138, %DIR.VPO.END.GUARD.MEM.MOTION.4
  %indvars.iv = phi i64 [ 0, %DIR.OMP.SIMD.138 ], [ %indvars.iv.next, %DIR.VPO.END.GUARD.MEM.MOTION.4 ]
  br label %DIR.VPO.GUARD.MEM.MOTION.2

DIR.VPO.GUARD.MEM.MOTION.2:                       ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.426
  %guard.start1 = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(float* %x.red) ]
  br label %DIR.OMP.SIMD.139

DIR.OMP.SIMD.139:                                 ; preds = %DIR.VPO.GUARD.MEM.MOTION.2
  br label %DIR.OMP.END.SCAN.335

DIR.OMP.END.SCAN.335:                             ; preds = %DIR.OMP.SIMD.139
  %1 = trunc i64 %indvars.iv to i32
  store i32 %1, i32* %i.linear.iv, align 4
  %arrayidx = getelementptr inbounds float, float* %A, i64 %indvars.iv
  %2 = load float, float* %arrayidx, align 4
  %3 = load float, float* %x.red, align 4
  %add5 = fadd fast float %3, %2
  store float %add5, float* %x.red, align 4
  br label %DIR.VPO.END.GUARD.MEM.MOTION.552

DIR.VPO.END.GUARD.MEM.MOTION.552:                 ; preds = %DIR.OMP.END.SCAN.335
  call void @llvm.directive.region.exit(token %guard.start1) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
  br label %DIR.OMP.SCAN.3

DIR.OMP.SCAN.3:                                   ; DIR.VPO.END.GUARD.MEM.MOTION.552
  %4 = call token @llvm.directive.region.entry() [ "DIR.OMP.SCAN"(), "QUAL.OMP.INCLUSIVE"(float* %x.red, i64 1) ]
  br label %DIR.OMP.SCAN.2

DIR.OMP.SCAN.2:                                   ; preds = %DIR.OMP.SCAN.3
  fence acq_rel
  br label %DIR.OMP.END.SCAN.5

DIR.OMP.END.SCAN.5:                               ; preds = %DIR.OMP.SCAN.2
  call void @llvm.directive.region.exit(token %4) [ "DIR.OMP.END.SCAN"() ]
  br label %DIR.OMP.END.SCAN.9.split

DIR.OMP.END.SCAN.9.split:
  %guard.start2 = call token @llvm.directive.region.entry() [ "DIR.VPO.GUARD.MEM.MOTION"(), "QUAL.OMP.LIVEIN"(float* %x.red) ]
  br label %DIR.OMP.END.SCAN.3

DIR.OMP.END.SCAN.3:                               ; preds = %DIR.OMP.END.SCAN.5
  %5 = load float, float* %x.red, align 4
  %6 = load i32, i32* %i.linear.iv, align 4
  %idxprom6 = sext i32 %6 to i64
  %arrayidx7 = getelementptr inbounds float, float* %B, i64 %idxprom6
  store float %5, float* %arrayidx7, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  br label %DIR.VPO.END.GUARD.MEM.MOTION.8

DIR.VPO.END.GUARD.MEM.MOTION.8:                   ; preds = %DIR.OMP.END.SCAN.3
  call void @llvm.directive.region.exit(token %guard.start2) [ "DIR.VPO.END.GUARD.MEM.MOTION"() ]
  br label %DIR.VPO.END.GUARD.MEM.MOTION.4

DIR.VPO.END.GUARD.MEM.MOTION.4:                   ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.8
  %exitcond.not = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.1, label %DIR.VPO.END.GUARD.MEM.MOTION.426, !llvm.loop !0

DIR.OMP.END.SIMD.1:                               ; preds = %DIR.VPO.END.GUARD.MEM.MOTION.4
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %DIR.OMP.END.SIMD.1, %entry
  ret void
}

declare token @llvm.directive.region.entry()

declare void @llvm.directive.region.exit(token)

!0 = distinct !{!0, !1, !2}
!1 = !{!"llvm.loop.vectorize.enable", i1 true}
!2 = !{!"llvm.loop.vectorize.ivdep_loop", i32 0}
