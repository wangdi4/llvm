; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -vplan-vec -vplan-force-vf=2 -vplan-enable-soa -disable-output\
; RUN: -vplan-print-after-transformed-soa-geps -S %s 2>&1 | FileCheck %s

define void @merge_uniform_soa_geps() {
; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: merge_uniform_soa_geps:simd.loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VEC_TC_CHECK:%.*]] = icmp eq i64 0 i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VEC_TC_CHECK]], scalar.ph, vector.ph
; CHECK-EMPTY:
; CHECK-NEXT:      vector.ph: # preds: [[BB1]]
; CHECK-NEXT:       [DA: Div] [1024 x i64]* [[VP_ARR_SOA_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:       [DA: Uni] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:       [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]: # preds: [[BB3:BB[0-9]+]], vector.ph
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], vector.ph ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:       [DA: Div] i64* [[VP_UNI_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:       [DA: Div] i64 [[VP_LDSTD:%.*]] = load i64* [[VP_UNI_GEP]]
; CHECK-NEXT:       [DA: Uni] br i1 true, [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_UNI_ELSE:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 1
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_UNI_IF:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]: # preds: [[BB5]], [[BB4]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_PHI_MIX_UNI:%.*]] = phi  [ i64* [[VP_UNI_ELSE]], [[BB5]] ],  [ i64* [[VP_UNI_IF]], [[BB4]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD:%.*]] = load i64* [[VP_PHI_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_CONST_STEP:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:       [DA: Div] i64* [[VP_GEP_MIX_UNI:%.*]] = getelementptr inbounds i64* [[VP_PHI_MIX_UNI]] i64 [[VP_LD]] i64 [[VP_CONST_STEP]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD_PHI_DERIVED:%.*]] = load i64* [[VP_GEP_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP_CMP:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:       [DA: Uni] br i1 [[VP_CMP]], [[BB2]], [[BB6:BB[0-9]+]]
;
entry:
  %arr.soa.priv64 = alloca [1024 x i64], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i64]* %arr.soa.priv64)]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.check.phi]
  %uni.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  %ldstd = load i64, i64* %uni.gep, align 4
  br i1 true, label %bb1, label %bb2
bb1:
  %uni.if = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  br label %simd.check.phi
bb2:
  %uni.else = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 1
  br label %simd.check.phi
simd.check.phi:
  %phi.mix.uni = phi i64* [%uni.else, %bb2], [%uni.if, %bb1]
  %ld = load i64, i64* %phi.mix.uni, align 4
  %gep.mix.uni = getelementptr inbounds i64, i64* %phi.mix.uni, i64 %ld
  %ld.phi.derived = load i64, i64* %gep.mix.uni, align 4
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end
simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @merge_uniform_strided_soa_geps() {
; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: merge_uniform_strided_soa_geps:simd.loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VEC_TC_CHECK:%.*]] = icmp eq i64 0 i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VEC_TC_CHECK]], scalar.ph, vector.ph
; CHECK-EMPTY:
; CHECK-NEXT:      vector.ph: # preds: [[BB1]]
; CHECK-NEXT:       [DA: Div] [1024 x i64]* [[VP_ARR_SOA_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:       [DA: Uni] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:       [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]: # preds: [[BB3:BB[0-9]+]], vector.ph
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], vector.ph ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:       [DA: Div] i64* [[VP_UNI_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:       [DA: Div] i64 [[VP_LDSTD:%.*]] = load i64* [[VP_UNI_GEP]]
; CHECK-NEXT:       [DA: Uni] br i1 true, [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_UNI_ELSE:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 1
; CHECK-NEXT:         [DA: Div] i64* [[VP_UNI_ELSE_1:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 1
; CHECK-NEXT:         [DA: Div] i64 [[VP_CONST_STEP_1:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:         [DA: Div] i64* [[VP0:%.*]] = getelementptr i64* [[VP_UNI_ELSE_1]] i64 0 i64 [[VP_CONST_STEP_1]]
; CHECK-NEXT:         [DA: Div] i64 [[VP_LD_ELSE:%.*]] = load i64* [[VP_UNI_ELSE]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64 [[VP_CONST_STEP_2:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:         [DA: Div] i64* [[VP_STR_IF:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 [[VP_IV1]] i64 [[VP_CONST_STEP_2]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]: # preds: [[BB5]], [[BB4]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_PHI_MIX_UNI:%.*]] = phi  [ i64* [[VP0]], [[BB5]] ],  [ i64* [[VP_STR_IF]], [[BB4]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD:%.*]] = load i64* [[VP_PHI_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_GEP_MIX_UNI:%.*]] = getelementptr inbounds i64* [[VP_PHI_MIX_UNI]] i64 [[VP_LD]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD_PHI_DERIVED:%.*]] = load i64* [[VP_GEP_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP_CMP:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:       [DA: Uni] br i1 [[VP_CMP]], [[BB2]], [[BB6:BB[0-9]+]]
;
entry:
  %arr.soa.priv64 = alloca [1024 x i64], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i64]* %arr.soa.priv64)]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.check.phi]
  %uni.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  %ldstd = load i64, i64* %uni.gep, align 4
  br i1 true, label %bb1, label %bb2
bb1:
  %str.if = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
bb2:
  %uni.else = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 1
  %ld.else = load i64, i64* %uni.else, align 4
  br label %simd.check.phi
simd.check.phi:
  %phi.mix.uni = phi i64* [%uni.else, %bb2], [%str.if, %bb1]
  %ld = load i64, i64* %phi.mix.uni, align 4
  %gep.mix.uni = getelementptr inbounds i64, i64* %phi.mix.uni, i64 %ld
  %ld.phi.derived = load i64, i64* %gep.mix.uni, align 4
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end
simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @merge_str_soa_geps() {
; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: merge_str_soa_geps:simd.loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VEC_TC_CHECK:%.*]] = icmp eq i64 0 i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VEC_TC_CHECK]], scalar.ph, vector.ph
; CHECK-EMPTY:
; CHECK-NEXT:      vector.ph: # preds: [[BB1]]
; CHECK-NEXT:       [DA: Div] [1024 x i64]* [[VP_ARR_SOA_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:       [DA: Uni] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:       [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]: # preds: [[BB3:BB[0-9]+]], vector.ph
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], vector.ph ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:       [DA: Div] i64* [[VP_UNI_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:       [DA: Uni] br i1 true, [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_STR_ELSE:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 [[VP_IV1]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_STR_IF:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 [[VP_IV1]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]: # preds: [[BB5]], [[BB4]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_PHI_MIX_UNI:%.*]] = phi  [ i64* [[VP_STR_ELSE]], [[BB5]] ],  [ i64* [[VP_STR_IF]], [[BB4]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD:%.*]] = load i64* [[VP_PHI_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_GEP_MIX_UNI:%.*]] = getelementptr inbounds i64* [[VP_PHI_MIX_UNI]] i64 [[VP_LD]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD_PHI_DERIVED:%.*]] = load i64* [[VP_GEP_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP_CMP:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:       [DA: Uni] br i1 [[VP_CMP]], [[BB2]], [[BB6:BB[0-9]+]]
;
entry:
  %arr.soa.priv64 = alloca [1024 x i64], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i64]* %arr.soa.priv64)]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.check.phi]
  %uni.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  br i1 true, label %bb1, label %bb2
bb1:
  %str.if = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
bb2:
  %str.else = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
simd.check.phi:
  %phi.mix.uni = phi i64* [%str.else, %bb2], [%str.if, %bb1]
  %ld = load i64, i64* %phi.mix.uni, align 4
  %gep.mix.uni = getelementptr inbounds i64, i64* %phi.mix.uni, i64 %ld
  %ld.phi.derived = load i64, i64* %gep.mix.uni, align 4
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end
simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

define void @merge_aos_soa_geps() {
; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: merge_aos_soa_geps:simd.loop
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VEC_TC_CHECK:%.*]] = icmp eq i64 0 i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VEC_TC_CHECK]], scalar.ph, vector.ph
; CHECK-EMPTY:
; CHECK-NEXT:      vector.ph: # preds: [[BB1]]
; CHECK-NEXT:       [DA: Div] [1024 x i64]* [[VP_ARR_SOA_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:       [DA: Div] [1024 x i64]* [[VP_ARR_AOS_PRIV64:%.*]] = allocate-priv [1024 x i64]*, OrigAlign = 4
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:       [DA: Uni] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:       [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]: # preds: [[BB3:BB[0-9]+]], vector.ph
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], vector.ph ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB3]] ]
; CHECK-NEXT:       [DA: Div] i64* [[VP_UNI_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 0
; CHECK-NEXT:       [DA: Div] i64* [[VP_DIV_GEP:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_AOS_PRIV64]] i64 0 i64 0
; CHECK-NEXT:       [DA: Div] i64 [[VP_CALL:%.*]] = call i64* [[VP_DIV_GEP]] i64 (i64*)* @helper
; CHECK-NEXT:       [DA: Uni] br i1 true, [[BB4:BB[0-9]+]], [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB5]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_UNI_ELSE:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_SOA_PRIV64]] i64 0 i64 [[VP_IV1]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:         [DA: Div] i64* [[VP_AOS_IF:%.*]] = getelementptr inbounds [1024 x i64]* [[VP_ARR_AOS_PRIV64]] i64 0 i64 [[VP_IV1]]
; CHECK-NEXT:         [DA: Uni] br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]: # preds: [[BB5]], [[BB4]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_PHI_MIX_UNI:%.*]] = phi  [ i64* [[VP_DIV_GEP]], [[BB4]] ],  [ i64* [[VP_UNI_ELSE]], [[BB5]] ]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD:%.*]] = load i64* [[VP_PHI_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64* [[VP_GEP_MIX_UNI:%.*]] = getelementptr inbounds i64* [[VP_PHI_MIX_UNI]] i64 [[VP_LD]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_LD_PHI_DERIVED:%.*]] = load i64* [[VP_GEP_MIX_UNI]]
; CHECK-NEXT:       [DA: Div] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:       [DA: Uni] i1 [[VP_CMP:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:       [DA: Uni] br i1 [[VP_CMP]], [[BB2]], [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
;
entry:
  %arr.soa.priv64 = alloca [1024 x i64], align 4
  %arr.aos.priv64 = alloca [1024 x i64], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i64]* %arr.soa.priv64, [1024 x i64]* %arr.aos.priv64)]
  br label %simd.loop.preheader

simd.loop.preheader:
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.check.phi]
  %uni.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 0
  %div.gep = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.aos.priv64, i64 0, i64 0
  %call = call i64 @helper(i64* nonnull %div.gep)
  br i1 true, label %bb1, label %bb2
bb1:
  %aos.if = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.aos.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
bb2:
  %uni.else = getelementptr inbounds [1024 x i64], [1024 x i64]* %arr.soa.priv64, i64 0, i64 %iv1
  br label %simd.check.phi
simd.check.phi:
  %phi.mix.uni = phi i64* [%div.gep, %bb1], [%uni.else, %bb2]
  %ld = load i64, i64* %phi.mix.uni, align 4
  %gep.mix.uni = getelementptr inbounds i64, i64* %phi.mix.uni, i64 %ld
  %ld.phi.derived = load i64, i64* %gep.mix.uni, align 4
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end
simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}



declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token %0)
declare dso_local i64 @helper(i64*)
