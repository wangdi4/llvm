; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to check SVA results for a loop with VLS optimized memory accesses.

; RUN: opt -S < %s -VPlanDriver -disable-output -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s --check-prefix=SVA-IR
; RUN: opt -S < %s -hir-ssa-deconstruction -hir-vec-dir-insert -VPlanDriverHIR -disable-output -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s --check-prefix=SVA-HIR

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @foo(i32* nocapture %ary) {
;  for (i = 0; i < 2048; i += 2) {
;    t0 = ary[i + 0] + 7;
;    t1 = ary[i + 1] + 11;
;    ary[i + 0] = t0;
;    ary[i + 1] = t1;
;  }
; SVA-IR-LABEL:  VPlan after ScalVec analysis:
; SVA-IR-NEXT:  Live-in values:
; SVA-IR-NEXT:  ID: 0 Value: i64 0
; SVA-IR-NEXT:    [[BB0:BB[0-9]+]]:
; SVA-IR-NEXT:     <Empty Block>
; SVA-IR-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; SVA-IR-NEXT:    no PREDECESSORS
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB1]]:
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 2 (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 2 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VF:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_ORIG_TRIP_COUNT:%.*]] = orig-trip-count for original loop for.body (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 [[VP_ORIG_TRIP_COUNT]], UF = 1 (SVAOpBits 0->F )
; SVA-IR-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; SVA-IR-NEXT:    PREDECESSORS(1): [[BB0]]
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB2]]:
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP_VECTOR_LOOP_IV_NEXT:%.*]], [[BB2]] ] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ],  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB2]] ] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[ARY0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP0:%.*]] = load i32* [[VP_ARRAYIDX]] (SVAOpBits 0->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_ADD7:%.*]] = add i32 [[VP0]] i32 7 (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP1:%.*]] = add i64 [[VP_INDVARS_IV]] i64 1 (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_ARRAYIDX4:%.*]] = getelementptr inbounds i32* [[ARY0]] i64 [[VP1]] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP2:%.*]] = load i32* [[VP_ARRAYIDX4]] (SVAOpBits 0->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_ADD11:%.*]] = add i32 [[VP2]] i32 11 (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP_ADD7]] i32* [[VP_ARRAYIDX]] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP_ADD11]] i32* [[VP_ARRAYIDX4]] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]] (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV_NEXT]] = add i64 [[VP_VECTOR_LOOP_IV]] i64 [[VP_VF]] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp i64 [[VP_VECTOR_LOOP_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP_VECTOR_LOOP_EXITCOND]]), [[BB3:BB[0-9]+]](!i1 [[VP_VECTOR_LOOP_EXITCOND]])
; SVA-IR-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB3]]:
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 2 (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; SVA-IR-NEXT:    PREDECESSORS(1): [[BB2]]
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB4]]:
; SVA-IR-NEXT:     <Empty Block>
; SVA-IR-NEXT:    no SUCCESSORS
; SVA-IR-NEXT:    PREDECESSORS(1): [[BB3]]
; SVA-IR-EMPTY:
; SVA-IR-NEXT:  External Uses:
; SVA-IR-NEXT:  Id: 0   no underlying for i64 [[VP_INDVARS_IV_IND_FINAL]]
;
; SVA-HIR-LABEL:  VPlan after ScalVec analysis:
; SVA-HIR-NEXT:  VPlan IR for: Initial VPlan for VF=4
; SVA-HIR-NEXT:  External Defs Start:
; SVA-HIR-DAG:     [[VP0:%.*]] = {%ary}
; SVA-HIR-NEXT:  External Defs End:
; SVA-HIR-NEXT:  Live-in values:
; SVA-HIR-NEXT:  ID: 0 Value: i64 0
; SVA-HIR-NEXT:    [[BB0:BB[0-9]+]]:
; SVA-HIR-NEXT:     <Empty Block>
; SVA-HIR-NEXT:    SUCCESSORS(1):[[BB1:BB[0-9]+]]
; SVA-HIR-NEXT:    no PREDECESSORS
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB1]]:
; SVA-HIR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; SVA-HIR-NEXT:    SUCCESSORS(1):[[BB2:BB[0-9]+]]
; SVA-HIR-NEXT:    PREDECESSORS(1): [[BB0]]
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB2]]:
; SVA-HIR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP1:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP2:%.*]], [[BB2]] ] (SVAOpBits 0->FV 1->FV )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP3:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i32* [[ARY0:%.*]] i64 [[VP3]] (SVAOpBits 0->V 1->V 2->V 3->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP4:%.*]] = load i32* [[VP_SUBSCRIPT]] (SVAOpBits 0->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP5:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP6:%.*]] = add i64 [[VP5]] i64 1 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i32* [[ARY0]] i64 [[VP6]] (SVAOpBits 0->V 1->V 2->V 3->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP7:%.*]] = load i32* [[VP_SUBSCRIPT_1]] (SVAOpBits 0->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP8:%.*]] = add i32 [[VP4]] i32 7 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP9:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds i32* [[ARY0]] i64 [[VP9]] (SVAOpBits 0->V 1->V 2->V 3->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP8]] i32* [[VP_SUBSCRIPT_2]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP10:%.*]] = add i32 [[VP7]] i32 11 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP11:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i64 [[VP12:%.*]] = add i64 [[VP11]] i64 1 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32* [[VP_SUBSCRIPT_3:%.*]] = subscript inbounds i32* [[ARY0]] i64 [[VP12]] (SVAOpBits 0->V 1->V 2->V 3->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP10]] i32* [[VP_SUBSCRIPT_3]] (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP2]] = add i64 [[VP1]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP13:%.*]] = icmp i64 [[VP2]] i64 1023 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:    SUCCESSORS(2):[[BB2]](i1 [[VP13]]), [[BB3:BB[0-9]+]](!i1 [[VP13]])
; SVA-HIR-NEXT:    PREDECESSORS(2): [[BB1]] [[BB2]]
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB3]]:
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:    SUCCESSORS(1):[[BB4:BB[0-9]+]]
; SVA-HIR-NEXT:    PREDECESSORS(1): [[BB2]]
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB4]]:
; SVA-HIR-NEXT:     <Empty Block>
; SVA-HIR-NEXT:    no SUCCESSORS
; SVA-HIR-NEXT:    PREDECESSORS(1): [[BB3]]
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:  External Uses:
; SVA-HIR-NEXT:  Id: 0   no underlying for i64 [[VP__IND_FINAL]]
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4) ]
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %ary, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4
  %add7 = add nsw i32 %0, 7
  %1 = add nsw i64 %indvars.iv, 1
  %arrayidx4 = getelementptr inbounds i32, i32* %ary, i64 %1
  %2 = load i32, i32* %arrayidx4, align 4
  %add11 = add nsw i32 %2, 11
  store i32 %add7, i32* %arrayidx, align 4
  store i32 %add11, i32* %arrayidx4, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 2
  %cmp = icmp ult i64 %indvars.iv.next, 2048
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

