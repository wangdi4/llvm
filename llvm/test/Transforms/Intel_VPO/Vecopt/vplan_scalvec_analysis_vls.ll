; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to check SVA results for a loop with VLS optimized memory accesses.

; RUN: opt -S < %s -vplan-vec -disable-output -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s --check-prefix=SVA-IR
; RUN: opt -S < %s -hir-ssa-deconstruction -hir-vec-dir-insert -hir-vplan-vec -disable-output -vplan-enable-scalvec-analysis -vplan-print-scalvec-results | FileCheck %s --check-prefix=SVA-HIR

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define void @foo(i32* nocapture %ary) {
;  for (i = 0; i < 2048; i += 2) {
;    t0 = ary[i + 0] + 7;
;    t1 = ary[i + 1] + 11;
;    ary[i + 0] = t0;
;    ary[i + 1] = t1;
;  }
; SVA-IR-LABEL:  VPlan after ScalVec analysis:
; SVA-IR-NEXT:  VPlan IR for: foo:for.body.#{{[0-9]+}}
; SVA-IR-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_ORIG_TRIP_COUNT:%.*]] = orig-trip-count for original loop for.body (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] pushvf VF=4 UF=1 (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] pushvf VF=4 UF=1 (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB1:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB1]]: # preds: [[BB0]]
; SVA-IR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 2 (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 2 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VF:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 [[VP_ORIG_TRIP_COUNT]], UF = 1 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB2:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP_VECTOR_LOOP_IV_NEXT:%.*]], [[BB2]] ] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ],  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB2]] ] (SVAOpBits 0->FV 1->FV )
; SVA-IR-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[ARY0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_LOAD:%.*]] = vls-load i32* [[VP_ARRAYIDX]], group_size=2, align=4 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP0:%.*]] = vls-extract <8 x i32> [[VP_VLS_LOAD]], group_size=2, offset=0 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP1:%.*]] = vls-extract <8 x i32> [[VP_VLS_LOAD]], group_size=2, offset=1 (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_ADD7:%.*]] = add i32 [[VP0]] i32 7 (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_ADD11:%.*]] = add i32 [[VP1]] i32 11 (SVAOpBits 0->V 1->V )
; SVA-IR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_INSERT:%.*]] = vls-insert <8 x i32> undef i32 [[VP_ADD7]], group_size=2, offset=0 (SVAOpBits 0->F 1->V )
; SVA-IR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_INSERT_1:%.*]] = vls-insert <8 x i32> [[VP_VLS_INSERT]] i32 [[VP_ADD11]], group_size=2, offset=1 (SVAOpBits 0->F 1->V )
; SVA-IR-NEXT:     [DA: Div, SVA: RetVal:(F  ), Inst:( V )] vls-store <8 x i32> [[VP_VLS_INSERT_1]] i32* [[VP_ARRAYIDX]], group_size=2, align=4 (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]] (SVAOpBits 0->FV 1->FV )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_LOOP_IV_NEXT]] = add i64 [[VP_VECTOR_LOOP_IV]] i64 [[VP_VF]] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp ult i64 [[VP_VECTOR_LOOP_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB2]], [[BB3:BB[0-9]+]] (SVAOpBits 0->F 1->F 2->F )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB3]]: # preds: [[BB2]]
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 2 (SVAOpBits 0->F 1->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB4:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    [[BB4]]: # preds: [[BB3]]
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] popvf (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br final.merge (SVAOpBits 0->F )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:    final.merge: # preds: [[BB4]]
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP2:%.*]] = phi-merge  [ i64 live-out0, [[BB4]] ] (SVAOpBits 0->F )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] popvf (SVAOpBits )
; SVA-IR-NEXT:     [DA: Uni, SVA: (F  )] br <External Block> (SVAOpBits )
; SVA-IR-EMPTY:
; SVA-IR-NEXT:  External Uses:
; SVA-IR-NEXT:  Id: 0   no underlying for i64 [[VP_INDVARS_IV_IND_FINAL]]
;
; SVA-HIR-LABEL:  VPlan after ScalVec analysis:
; SVA-HIR-NEXT:  VPlan IR for: Initial VPlan for VF=4
; SVA-HIR-NEXT:  External Defs Start:
; SVA-HIR-DAG:     [[VP0:%.*]] = {%ary}
; SVA-HIR-NEXT:  External Defs End:
; SVA-HIR-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB1:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB1]]: # preds: [[BB0]]
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1 (SVAOpBits 0->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB2:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP1:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP2:%.*]], [[BB2]] ] (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP3:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i32* [[ARY0:%.*]] i64 [[VP3]] (SVAOpBits 0->F 1->F 2->F 3->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_LOAD:%.*]] = vls-load i32* [[VP_SUBSCRIPT]], group_size=2, align=4 (SVAOpBits 0->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_LOAD:%.*]] = vls-extract <8 x i32> [[VP_VLS_LOAD]], group_size=2, offset=0 (SVAOpBits 0->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP_LOAD_1:%.*]] = vls-extract <8 x i32> [[VP_VLS_LOAD]], group_size=2, offset=1 (SVAOpBits 0->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP4:%.*]] = add i32 [[VP_LOAD]] i32 7 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP5:%.*]] = mul i64 2 i64 [[VP1]] (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i32* [[ARY0]] i64 [[VP5]] (SVAOpBits 0->F 1->F 2->F 3->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP6:%.*]] = add i32 [[VP_LOAD_1]] i32 11 (SVAOpBits 0->V 1->V )
; SVA-HIR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_INSERT:%.*]] = vls-insert <8 x i32> undef i32 [[VP4]], group_size=2, offset=0 (SVAOpBits 0->F 1->V )
; SVA-HIR-NEXT:     [DA: Uni, SVA: RetVal:(F  ), Inst:( V )] <8 x i32> [[VP_VLS_INSERT_1:%.*]] = vls-insert <8 x i32> [[VP_VLS_INSERT]] i32 [[VP6]], group_size=2, offset=1 (SVAOpBits 0->F 1->V )
; SVA-HIR-NEXT:     [DA: Div, SVA: RetVal:(F  ), Inst:( V )] vls-store <8 x i32> [[VP_VLS_INSERT_1]] i32* [[VP_SUBSCRIPT_1]], group_size=2, align=4 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP2]] = add i64 [[VP1]] i64 [[VP__IND_INIT_STEP]] (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP7:%.*]] = icmp slt i64 [[VP2]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] br i1 [[VP7]], [[BB2]], [[BB3:BB[0-9]+]] (SVAOpBits 0->F 1->F 2->F )
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB3]]: # preds: [[BB2]]
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] br [[BB4:BB[0-9]+]] (SVAOpBits 0->F )
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:    [[BB4]]: # preds: [[BB3]]
; SVA-HIR-NEXT:     [DA: Uni, SVA: (F  )] br <External Block> (SVAOpBits )
; SVA-HIR-EMPTY:
; SVA-HIR-NEXT:  External Uses:
; SVA-HIR-NEXT:  Id: 0   no underlying for i64 [[VP__IND_FINAL]]
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4) ]
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %arrayidx = getelementptr inbounds i32, i32* %ary, i64 %indvars.iv
  %0 = load i32, i32* %arrayidx, align 4
  %add7 = add nsw i32 %0, 7
  %1 = add nsw i64 %indvars.iv, 1
  %arrayidx4 = getelementptr inbounds i32, i32* %ary, i64 %1
  %2 = load i32, i32* %arrayidx4, align 4
  %add11 = add nsw i32 %2, 11
  store i32 %add7, i32* %arrayidx, align 4
  store i32 %add11, i32* %arrayidx4, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 2
  %cmp = icmp ult i64 %indvars.iv.next, 2048
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

