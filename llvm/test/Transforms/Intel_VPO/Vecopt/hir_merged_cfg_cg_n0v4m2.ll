; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test for basic functionality of HIR vectorizer CG for merged CFG.
; Vec Scenario:
;    - No peel
;    - Main vector loop with VF=4
;    - Masked vector remainder with VF=2

; Input HIR
; BEGIN REGION { }
;       %entry.region = @llvm.directive.region.entry(); [ DIR.OMP.SIMD() ]
;
;       + DO i1 = 0, 1023, 1   <DO_LOOP> <simd>
;       |   (%ary)[i1] = i1 + sext.i32.i64(%c);
;       + END LOOP
;
;       @llvm.directive.region.exit(%entry.region); [ DIR.OMP.END.SIMD() ]
;       ret ;
; END REGION

; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -vplan-enable-new-cfg-merge-hir -vplan-vec-scenario="n0;v4;m2" -vplan-enable-masked-variant-hir -vplan-print-after-create-masked-vplan -print-after=hir-vplan-vec -disable-output < %s 2>&1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec,print<hir>" -vplan-enable-new-cfg-merge-hir -vplan-vec-scenario="n0;v4;m2" -vplan-enable-masked-variant-hir -vplan-print-after-create-masked-vplan -disable-output < %s 2>&1 | FileCheck %s

target datalayout = "e-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024"
target triple = "x86_64-unknown-linux-gnu"

define void @test_store(i64* nocapture %ary, i32 %c) {
; CHECK-LABEL:  VPlan after emitting masked variant:
; CHECK-NEXT:  VPlan IR for: test_store:HIR.#{{[0-9]+}}.cloned.masked
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {(sext i32 %c to i64)}
; CHECK-DAG:     [[VP1:%.*]] = {umax(1, sext.i32.i64(%c)) + -1}
; CHECK-DAG:     [[VP2:%.*]] = {%ary}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP3:%.*]] = add i64 [[VP1]] i64 1
; CHECK-NEXT:     [DA: Div] i64 [[VP4:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP5:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], new_latch
; CHECK-NEXT:     [DA: Div] i64 [[VP6:%.*]] = phi  [ i64 [[VP4]], [[BB1]] ],  [ i64 [[VP7:%.*]], new_latch ]
; CHECK-NEXT:     [DA: Div] i1 [[VP8:%.*]] = icmp ult i64 [[VP6]] i64 [[VP3]]
; CHECK-NEXT:     [DA: Div] br i1 [[VP8]], [[BB3:BB[0-9]+]], new_latch
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:       [DA: Div] i64 [[VP9:%.*]] = add i64 [[VP0]] i64 [[VP6]]
; CHECK-NEXT:       [DA: Div] i64* [[VP10:%.*]] = subscript inbounds i64* [[ARY0:%.*]] i64 [[VP6]]
; CHECK-NEXT:       [DA: Div] store i64 [[VP9]] i64* [[VP10]]
; CHECK-NEXT:       [DA: Uni] br new_latch
; CHECK-EMPTY:
; CHECK-NEXT:    new_latch: # preds: [[BB3]], [[BB2]]
; CHECK-NEXT:     [DA: Div] i64 [[VP7]] = add i64 [[VP6]] i64 [[VP5]]
; CHECK-NEXT:     [DA: Div] i1 [[VP11:%.*]] = icmp ult i64 [[VP7]] i64 [[VP3]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP12:%.*]] = all-zero-check i1 [[VP11]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP12]], [[BB4:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: new_latch
; CHECK-NEXT:     [DA: Uni] i64 [[VP13:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Uni] br [[BB5:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB4]]
; CHECK-NEXT:     [DA: Uni] br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP13]]

; CHECK-LABEL: Function: test_store
; CHECK-EMPTY:
; CHECK-NEXT:  BEGIN REGION { modified }
; CHECK-NEXT:        [[TGU0:%.*]] = umax(1, sext.i32.i64([[C0:%.*]]))  /u  4
; CHECK-NEXT:        [[VEC_TC0:%.*]] = [[TGU0]]  *  4
; CHECK-NEXT:        [[DOTVEC0:%.*]] = 0 == [[VEC_TC0]]
; CHECK-NEXT:        [[PHI_TEMP0:%.*]] = 0
; CHECK-NEXT:        [[EXTRACT_0_0:%.*]] = extractelement [[DOTVEC0]],  0
; CHECK-NEXT:        if ([[EXTRACT_0_0]] == 1)
; CHECK-NEXT:        {
; CHECK-NEXT:           goto [[MERGE_BLK0:merge.blk[0-9]+]].28
; CHECK-NEXT:        }
; CHECK-NEXT:        [[TGU20:%.*]] = umax(1, sext.i32.i64([[C0]]))  /u  4
; CHECK-NEXT:        [[VEC_TC30:%.*]] = [[TGU20]]  *  4
; CHECK-NEXT:        [[LOOP_UB0:%.*]] = [[VEC_TC30]]  -  1

; CHECK:             + DO i1 = 0, [[LOOP_UB0]], 4   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; CHECK-NEXT:        |   (<4 x i64>*)([[ARY0]])[i1] = i1 + sext.i32.i64([[C0]]) + <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:        + END LOOP

; CHECK:             [[IND_FINAL0:%.*]] = 0 + [[VEC_TC30]]
; CHECK-NEXT:        [[DOTVEC40:%.*]] = umax(1, sext.i32.i64([[C0]])) == [[VEC_TC30]]
; CHECK-NEXT:        [[PHI_TEMP0]] = [[IND_FINAL0]]
; CHECK-NEXT:        [[PHI_TEMP60:%.*]] = [[IND_FINAL0]]
; CHECK-NEXT:        [[EXTRACT_0_80:%.*]] = extractelement [[DOTVEC40]],  0
; CHECK-NEXT:        if ([[EXTRACT_0_80]] == 1)
; CHECK-NEXT:        {
; CHECK-NEXT:           goto final.merge.50
; CHECK-NEXT:        }
; CHECK-NEXT:        [[MERGE_BLK0]].28:
; CHECK-NEXT:        [[TMP1:%.*]] = [[PHI_TEMP0]] + <i64 0, i64 1>
; CHECK-NEXT:        [[LOOP_UB90:%.*]] = umax(1, sext.i32.i64([[C0]]))  -  1
; CHECK:             + DO i1 = [[PHI_TEMP0]], [[LOOP_UB90]], 2   <DO_LOOP>  <MAX_TC_EST = 2>  <LEGAL_MAX_TC = 2> <nounroll> <novectorize> <max_trip_count = 2>
; CHECK-NEXT:        |   [[DOTVEC100:%.*]] = i1 + <i64 0, i64 1> <u umax(1, sext.i32.i64([[C0]]))
; CHECK-NEXT:        |   (<2 x i64>*)([[ARY0]])[i1] = i1 + sext.i32.i64([[C0]]) + <i64 0, i64 1>, Mask = @{[[DOTVEC100]]}
; CHECK-NEXT:        |   [[DOTVEC110:%.*]] = i1 + <i64 0, i64 1> + 2 <u umax(1, sext.i32.i64([[C0]]))
; CHECK-NEXT:        |   [[TMP0:%.*]] = bitcast.<2 x i1>.i2([[DOTVEC110]])
; CHECK-NEXT:        |   [[CMP120:%.*]] = [[TMP0]] == 0
; CHECK-NEXT:        |   [[ALL_ZERO_CHECK0:%.*]] = [[CMP120]]
; CHECK-NEXT:        + END LOOP
; CHECK:             [[IND_FINAL130:%.*]] = 0 + umax(1, sext.i32.i64([[C0]]))
; CHECK:             [[PHI_TEMP60]] = [[IND_FINAL130]]
; CHECK-NEXT:        final.merge.50:
; CHECK-NEXT:        ret
; CHECK-NEXT:  END REGION
;
entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"() ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 0, %entry ], [ %indvars.iv.next, %for.body ]
  %ptr = getelementptr inbounds i64, i64* %ary, i64 %indvars.iv
  %cc = sext i32 %c to i64
  %add = add i64 %cc, %indvars.iv
  store i64 %add, i64* %ptr, align 8
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %cmp = icmp ult i64 %indvars.iv.next, %cc
  br i1 %cmp, label %for.body, label %for.end

for.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
