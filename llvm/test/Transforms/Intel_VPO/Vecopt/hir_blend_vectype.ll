; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -hir-ssa-deconstruction -hir-vec-dir-insert -hir-vplan-vec -hir-cg -disable-output -print-after=hir-vplan-vec  -vplan-force-vf=4 -vplan-print-scalvec-results < %s 2>&1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vec-dir-insert,hir-vplan-vec,print<hir>,hir-cg" -disable-output -vplan-force-vf=4 -vplan-print-scalvec-results < %s 2>&1 | FileCheck %s
;
; LIT test to check that hir-copy instructions from SSA deconstruction are handled
; correctly. When the copy instruction generated is for a vector type, we were hitting
; an assert when trying to use FixedVectorType::get to get the widened type for
; creating the LVal RegDDRef for the generated copies.
;
; Incoming HIR looks like the following:
;
;           + DO i1 = 0, 99, 1   <DO_LOOP>
;           |   if (%n0 < i1)
;           |   {
;           |      %0 = (<2 x i64>*)(%larr1)[2 * i1];
;           |      %l2.0 = %0;
;           |   }
;           |   else
;           |   {
;           |      %1 = (<2 x i64>*)(%larr2)[2 * i1];
;           |      %l2.0 = %1;
;           |   }
;           |   %add = %l2.0  +  %l2n;
;           |   (<2 x i64>*)(%larr3)[2 * i1] = %add;
;           + END LOOP
;
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nofree norecurse nosync nounwind uwtable
define dso_local void @foo(i64* noalias nocapture readonly %larr1, i64* noalias nocapture readonly %larr2, i64* noalias nocapture readonly %larr3, <2 x i64> %l2n, i64 %n1, i64 %n0) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after ScalVec analysis:
; CHECK-NEXT:  VPlan IR for: Initial VPlan for VF=4
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%l2.0}
; CHECK-DAG:     [[VP1:%.*]] = {%l2n}
; CHECK-DAG:     [[VP2:%.*]] = {%n0}
; CHECK-DAG:     [[VP3:%.*]] = {%larr1}
; CHECK-DAG:     [[VP4:%.*]] = {%larr3}
; CHECK-DAG:     [[VP5:%.*]] = {%larr2}
; CHECK-NEXT:  External Defs End:
; CHECK:         [[BB2:BB[0-9]+]]: # preds: [[BB1:BB[0-9]+]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP6:%.*]] = phi  [ i64 [[VP__IND_INIT:%.*]], [[BB1]] ],  [ i64 [[VP7:%.*]], [[BB3]] ] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP8:%.*]] = icmp slt i64 [[N00:%.*]] i64 [[VP6]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP__NOT:%.*]] = not i1 [[VP8]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB4:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP9:%.*]] = block-predicate i1 [[VP__NOT]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP10:%.*]] = mul i64 2 i64 [[VP6]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i64* [[LARR20:%.*]] i64 [[VP10]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] <2 x i64>* [[VP11:%.*]] = bitcast i64* [[VP_SUBSCRIPT]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP_LOAD:%.*]] = load <2 x i64>* [[VP11]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP12:%.*]] = hir-copy <2 x i64> [[VP_LOAD]] , OriginPhiId: -1 (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB5:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB4]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP13:%.*]] = block-predicate i1 [[VP8]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP14:%.*]] = mul i64 2 i64 [[VP6]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64* [[LARR10:%.*]] i64 [[VP14]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] <2 x i64>* [[VP15:%.*]] = bitcast i64* [[VP_SUBSCRIPT_1]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP_LOAD_1:%.*]] = load <2 x i64>* [[VP15]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP16:%.*]] = hir-copy <2 x i64> [[VP_LOAD_1]] , OriginPhiId: -1 (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB3]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB5]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP__BLEND_BB4:%.*]] = blend [ <2 x i64> [[VP12]], i1 [[VP__NOT]] ], [ <2 x i64> [[VP16]], i1 [[VP8]] ] (SVAOpBits 0->V 1->V 2->V 3->V )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] <2 x i64> [[VP17:%.*]] = add <2 x i64> [[VP__BLEND_BB4]] <2 x i64> [[L2N0:%.*]] (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP18:%.*]] = mul i64 2 i64 [[VP6]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64* [[VP_SUBSCRIPT_2:%.*]] = subscript inbounds i64* [[LARR30:%.*]] i64 [[VP18]] (SVAOpBits 0->F 1->F 2->F 3->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] <2 x i64>* [[VP19:%.*]] = bitcast i64* [[VP_SUBSCRIPT_2]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store <2 x i64> [[VP17]] <2 x i64>* [[VP19]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (FV )] i64 [[VP7]] = add i64 [[VP6]] i64 [[VP__IND_INIT_STEP:%.*]] (SVAOpBits 0->FV 1->FV )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP20:%.*]] = icmp slt i64 [[VP7]] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br i1 [[VP20]], [[BB2]], [[BB6:BB[0-9]+]] (SVAOpBits 0->F 1->F 2->F )
; CHECK-EMPTY:
; CHECK:       Function: foo
; CHECK:         BEGIN REGION { modified }
; CHECK:              + DO i1 = 0, 99, 4   <DO_LOOP> <auto-vectorized> <novectorize>
; CHECK-NEXT:         |   %.vec5 = undef;
; CHECK-NEXT:         |   %.vec3 = undef;
; CHECK-NEXT:         |   %.vec = %n0 < i1 + <i64 0, i64 1, i64 2, i64 3>;
; CHECK-NEXT:         |   %.vec2 = %.vec  ^  -1;
; CHECK-NEXT:         |   %.replicated.elts = shufflevector %.vec2,  undef,  <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>;
; CHECK-NEXT:         |   %.vec3 = (<8 x i64>*)(%larr2)[2 * i1], Mask = @{%.replicated.elts};
; CHECK-NEXT:         |   %.copy = %.vec3;
; CHECK-NEXT:         |   %.replicated.elts4 = shufflevector %.vec,  undef,  <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>;
; CHECK-NEXT:         |   %.vec5 = (<8 x i64>*)(%larr1)[2 * i1], Mask = @{%.replicated.elts4};
; CHECK-NEXT:         |   %.copy7 = %.vec5;
; CHECK-NEXT:         |   %.replicated.elts8 = shufflevector %.vec,  undef,  <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>;
; CHECK-NEXT:         |   %select = (%.replicated.elts8 == <i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true>) ? %.copy7 : %.copy;
; CHECK-NEXT:         |   %.replicated = shufflevector %l2n,  undef,  <i32 0, i32 1, i32 0, i32 1, i32 0, i32 1, i32 0, i32 1>;
; CHECK-NEXT:         |   (<8 x i64>*)(%larr3)[2 * i1] = %select + %.replicated;
; CHECK-NEXT:         + END LOOP
; CHECK:         END REGION
;
entry:
  br label %for.body

for.body:                                         ; preds = %entry, %for.body
  %l1.013 = phi i64 [ 0, %entry ], [ %inc, %if.end ]
  %l1.mul = mul i64 %l1.013, 2
  %cmp1 = icmp slt i64 %n0, %l1.013
  br i1 %cmp1, label %if.then, label %if.else

if.then:                                          ; preds = %for.body
  %arrayidx = getelementptr inbounds i64, i64* %larr1, i64 %l1.mul
  %arrayidx.bc = bitcast i64* %arrayidx to <2 x i64>*
  %0 = load <2 x i64>, <2 x i64>* %arrayidx.bc, align 16
  br label %if.end

if.else:                                          ; preds = %for.body
  %arrayidx2 = getelementptr inbounds i64, i64* %larr2, i64 %l1.mul
  %arrayidx2.bc = bitcast i64* %arrayidx2 to <2 x i64>*
  %1 = load <2 x i64>, <2 x i64>* %arrayidx2.bc, align 16
  br label %if.end

if.end:                                           ; preds = %if.else, %if.then
  %l2.0 = phi <2 x i64> [ %0, %if.then ], [ %1, %if.else ]
  %add = add <2 x i64> %l2.0, %l2n
  %arrayidx3 = getelementptr inbounds i64,  i64* %larr3, i64 %l1.mul
  %arrayidx3.bc = bitcast i64* %arrayidx3 to <2 x i64>*
  store <2 x i64> %add, <2 x i64>* %arrayidx3.bc, align 16
  %inc = add nuw nsw i64 %l1.013, 1
  %exitcond.not = icmp eq i64 %inc, 100
  br i1 %exitcond.not, label %for.end, label %for.body

for.end:                                          ; preds = %for.body
  ret void
}
