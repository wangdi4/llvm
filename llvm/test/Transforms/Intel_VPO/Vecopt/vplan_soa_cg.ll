; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py

; RUN: opt -vplan-vec -vplan-force-vf=2 -vplan-enable-soa \
; RUN: -vplan-print-after-transformed-soa-geps -S %s 2>&1 | FileCheck %s

define dso_local void @test_memref_transform(i32 %n) {
; CHECK-LABEL:  VPlan after Dump Transformed SOA GEPs:
; CHECK-NEXT:  VPlan IR for: test_memref_transform:for.body
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Div] [1024 x i32]* [[VP_ARR_PRIV:%.*]] = allocate-priv [1024 x i32]*, OrigAlign = 4
; CHECK-NEXT:     [DA: Div] i8* [[VP_ARR_PRIV_BCAST:%.*]] = bitcast [1024 x i32]* [[VP_ARR_PRIV]]
; CHECK-NEXT:     [DA: Div] call i64 4096 i8* [[VP_ARR_PRIV_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8 [Serial]
; CHECK-NEXT:     [DA: Div] i64 [[VP_IV1_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP_IV1_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     [DA: Uni] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 1024, UF = 1
; CHECK-NEXT:     [DA: Uni] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_IV1:%.*]] = phi  [ i64 [[VP_IV1_IND_INIT]], [[BB1]] ],  [ i64 [[VP_IV1_NEXT:%.*]], [[BB2]] ]
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNI_GEP1:%.*]] = getelementptr inbounds [1024 x i32]* [[VP_ARR_PRIV]] i64 0 i64 0
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNI_GEP2:%.*]] = getelementptr inbounds i32* [[VP_UNI_GEP1]] i64 1
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNI_GEP3:%.*]] = getelementptr inbounds i32* [[VP_UNI_GEP2]] i64 2
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNI_GEP4:%.*]] = getelementptr inbounds i32* [[VP_UNI_GEP3]] i64 3
; CHECK-NEXT:     [DA: Div] i32 [[VP_LD_1:%.*]] = load i32* [[VP_UNI_GEP4]]
; CHECK-NEXT:     [DA: Div] store i32 10 i32* [[VP_UNI_GEP4]]
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNIT_STRIDE_GEP1:%.*]] = getelementptr inbounds [1024 x i32]* [[VP_ARR_PRIV]] i64 0 i64 [[VP_IV1]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_CONST_STEP:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNIT_STRIDE_GEP1_1:%.*]] = getelementptr inbounds [1024 x i32]* [[VP_ARR_PRIV]] i64 0 i64 [[VP_IV1]] i64 [[VP_CONST_STEP]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_CONST_STEP_1:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:     [DA: Div] i32* [[VP_UNIT_STRIDE_GEP2:%.*]] = getelementptr inbounds i32* [[VP_UNIT_STRIDE_GEP1]] i64 [[VP_IV1]] i64 [[VP_CONST_STEP_1]]
; CHECK-NEXT:     [DA: Div] i32 [[VP_LD_2:%.*]] = load i32* [[VP_UNIT_STRIDE_GEP1_1]]
; CHECK-NEXT:     [DA: Div] store i32 20 i32* [[VP_UNIT_STRIDE_GEP2]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_SEXT:%.*]] = sext i32 [[VP_LD_1]] to i64
; CHECK-NEXT:     [DA: Div] i64 [[VP_CONST_STEP_2:%.*]] = const-step-vector: { Start:0, Step:1, NumSteps:2}
; CHECK-NEXT:     [DA: Div] i32* [[VP_RND_GEP1:%.*]] = getelementptr inbounds [1024 x i32]* [[VP_ARR_PRIV]] i64 0 i64 [[VP_SEXT]] i64 [[VP_CONST_STEP_2]]
; CHECK-NEXT:     [DA: Div] i32 [[VP_LD_3:%.*]] = load i32* [[VP_RND_GEP1]]
; CHECK-NEXT:     [DA: Div] store i32 30 i32* [[VP_RND_GEP1]]
; CHECK-NEXT:     [DA: Div] i64 [[VP_IV1_NEXT]] = add i64 [[VP_IV1]] i64 [[VP_IV1_IND_INIT_STEP]]
; CHECK-NEXT:     [DA: Uni] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp ult i64 [[VP_IV1_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     [DA: Uni] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     [DA: Uni] i64 [[VP_IV1_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     [DA: Div] i8* [[VP_ARR_PRIV_BCAST1:%.*]] = bitcast [1024 x i32]* [[VP_ARR_PRIV]]
; CHECK-NEXT:     [DA: Div] call i64 4096 i8* [[VP_ARR_PRIV_BCAST1]] void (i64, i8*)* @llvm.lifetime.end.p0i8 [Serial]
; CHECK-NEXT:     [DA: Uni] br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni] br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP_IV1_IND_FINAL]]
;
; CHECK:  define dso_local void @test_memref_transform(i32 [[N0:%.*]]) {
; CHECK-NEXT:  omp.inner.for.body.lr.ph:
; CHECK-NEXT:    [[ARR_PRIV0:%.*]] = alloca [1024 x i32], align 4
; CHECK-NEXT:    [[ARR_PRIV_SOA_VEC0:%.*]] = alloca [1024 x <2 x i32>], align 8
; CHECK-NEXT:    br label [[DIR_OMP_SIMD_10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  DIR.OMP.SIMD.1:
; CHECK-NEXT:    br label [[FOR_PREHEADER0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  for.preheader:
; CHECK-NEXT:    br label [[VPLANNEDBB0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB1:
; CHECK-NEXT:    [[ARR_PRIV_SOA_VEC0_BCAST:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8192, i8* [[ARR_PRIV_SOA_VEC0_BCAST]])
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ 0, [[VPLANNEDBB10]] ], [ [[TMP2:%.*]], [[VECTOR_BODY0]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ <i64 0, i64 1>, [[VPLANNEDBB10]] ], [ [[TMP1:%.*]], [[VECTOR_BODY0]] ]
; CHECK-NEXT:    [[SOA_SCALAR_GEP0:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]], i64 0, i64 0
; CHECK-NEXT:    [[SOA_SCALAR_GEP30:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP0]], i64 1
; CHECK-NEXT:    [[SOA_SCALAR_GEP40:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP30]], i64 2
; CHECK-NEXT:    [[SOA_SCALAR_GEP50:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP40]], i64 3
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP50]], align 4
; CHECK-NEXT:    store <2 x i32> <i32 10, i32 10>, <2 x i32>* [[SOA_SCALAR_GEP50]], align 4
; CHECK-NEXT:    [[SOA_VECTORGEP0:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]], <2 x i64> zeroinitializer, <2 x i64> [[VEC_PHI0]]
; CHECK-NEXT:    [[MM_VECTORGEP0:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]], <2 x i64> zeroinitializer, <2 x i64> [[VEC_PHI0]], <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    [[MM_VECTORGEP60:%.*]] = getelementptr inbounds <2 x i32>, <2 x <2 x i32>*> [[SOA_VECTORGEP0]], <2 x i64> [[VEC_PHI0]], <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    [[WIDE_MASKED_GATHER0:%.*]] = call <2 x i32> @llvm.masked.gather.v2i32.v2p0i32(<2 x i32*> [[MM_VECTORGEP0]], i32 4, <2 x i1> <i1 true, i1 true>, <2 x i32> poison)
; CHECK-NEXT:    call void @llvm.masked.scatter.v2i32.v2p0i32(<2 x i32> <i32 20, i32 20>, <2 x i32*> [[MM_VECTORGEP60]], i32 4, <2 x i1> <i1 true, i1 true>)
; CHECK-NEXT:    [[TMP0:%.*]] = sext <2 x i32> [[WIDE_LOAD0]] to <2 x i64>
; CHECK-NEXT:    [[MM_VECTORGEP70:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]], <2 x i64> zeroinitializer, <2 x i64> [[TMP0]], <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    [[WIDE_MASKED_GATHER80:%.*]] = call <2 x i32> @llvm.masked.gather.v2i32.v2p0i32(<2 x i32*> [[MM_VECTORGEP70]], i32 4, <2 x i1> <i1 true, i1 true>, <2 x i32> poison)
; CHECK-NEXT:    call void @llvm.masked.scatter.v2i32.v2p0i32(<2 x i32> <i32 30, i32 30>, <2 x i32*> [[MM_VECTORGEP70]], i32 4, <2 x i1> <i1 true, i1 true>)
; CHECK-NEXT:    [[TMP1]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP2]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[TMP2]], 1024
; CHECK-NEXT:    br i1 [[TMP3]], label [[VECTOR_BODY0]], label [[VPLANNEDBB90:%.*]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB10:                                     ; preds = %vector.body
; CHECK-NEXT:    [[ARR_PRIV_SOA_VEC0_BCAST1:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV_SOA_VEC0]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8192, i8* [[ARR_PRIV_SOA_VEC0_BCAST1]])
; CHECK-NEXT:    br label %VPlannedBB11
;
omp.inner.for.body.lr.ph:
  %arr.priv = alloca [1024 x i32], align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %omp.inner.for.body.lr.ph
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE:TYPED"([1024 x i32]* %arr.priv, i32 0, i32 1024)]
  br label %for.preheader

for.preheader:
  br label %for.body

for.body:
  %iv1 = phi i64 [ 0, %for.preheader ], [ %iv1.next, %for.body ]

  ; Uniform GEP.
  %uni.gep1 = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv, i64 0, i64 0
  %uni.gep2 = getelementptr inbounds i32, i32* %uni.gep1, i64 1
  %uni.gep3 = getelementptr inbounds i32, i32* %uni.gep2, i64 2
  %uni.gep4 = getelementptr inbounds i32, i32* %uni.gep3, i64 3
  %ld.1 = load i32, i32* %uni.gep4, align 4
  store i32 10, i32* %uni.gep4

  ; Single Unit-strided GEP.
  %unit.stride.gep1 = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv, i64 0, i64 %iv1
  %unit.stride.gep2 = getelementptr inbounds i32, i32* %unit.stride.gep1, i64 %iv1
  %ld.2 = load i32, i32* %unit.stride.gep1, align 4
  store i32 20, i32* %unit.stride.gep2

  ; Random memory location.
  %sext = sext i32 %ld.1 to i64
  %rnd.gep1 = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv, i64 0, i64 %sext
  %ld.3 = load i32, i32* %rnd.gep1, align 4
  store i32 30, i32* %rnd.gep1

  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %for.body, label %for.end

for.end:                                          ; preds = %for.body
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token %0)
