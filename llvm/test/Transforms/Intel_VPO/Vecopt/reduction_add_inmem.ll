; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to verify VPlan's functionality and generated vector code for in-memory
; binop reduction.

; RUN: opt -enable-new-pm=0 -hir-ssa-deconstruction -hir-temp-cleanup -hir-framework -hir-vplan-vec -vplan-print-after-vpentity-instrs -print-after=hir-vplan-vec -vplan-force-vf=2 -disable-output %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s --check-prefix=HIR
; RUN: opt -enable-new-pm=0 -hir-ssa-deconstruction -hir-temp-cleanup -hir-framework -hir-vplan-vec -vplan-print-after-vpentity-instrs -print-after=hir-vplan-vec -vplan-force-vf=2 -disable-output %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s --check-prefix=HIR
; RUN: opt -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>" -vplan-print-after-vpentity-instrs -vplan-force-vf=2 -disable-output %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s --check-prefix=HIR
; RUN: opt -passes="hir-ssa-deconstruction,hir-temp-cleanup,hir-vplan-vec,print<hir>" -vplan-print-after-vpentity-instrs -vplan-force-vf=2 -disable-output %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s --check-prefix=HIR
; RUN: opt -enable-new-pm=0 -vplan-vec -vplan-print-after-vpentity-instrs -vplan-force-vf=2 -S < %s 2>&1 | FileCheck %s
; RUN: opt -passes=vplan-vec -vplan-print-after-vpentity-instrs -vplan-force-vf=2 -S < %s 2>&1 | FileCheck %s

define i32 @foo(i32* nocapture readonly %A, i64 %N, i32 %init) {
; HIR-LABEL:  VPlan after insertion of VPEntities instructions:
; HIR-NEXT:  VPlan IR for: foo:HIR.#{{[0-9]+}}
; HIR-NEXT:  External Defs Start:
; HIR-DAG:     [[VP0:%.*]] = {%sum}
; HIR-DAG:     [[VP1:%.*]] = {%A}
; HIR-DAG:     [[VP2:%.*]] = {%N + -1}
; HIR-NEXT:  External Defs End:
; HIR-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; HIR-NEXT:     br [[BB1:BB[0-9]+]]
; HIR:         [[BB1]]: # preds: [[BB0]]
; HIR-NEXT:     i32* [[VP_SUM:%.*]] = allocate-priv i32*, OrigAlign = 4
; HIR-NEXT:     i64 [[VP3:%.*]] = add i64 [[VP2]] i64 1
; HIR-NEXT:     i32 [[VP_LOAD:%.*]] = load i32* [[SUM0:%.*]]
; HIR-NEXT:     i32 [[VP_SUMRED_INIT:%.*]] = reduction-init i32 0 i32 [[VP_LOAD]]
; HIR-NEXT:     store i32 [[VP_SUMRED_INIT]] i32* [[VP_SUM]]
; HIR-NEXT:     i64 [[VP__IND_INIT:%.*]] = induction-init{add} i64 0 i64 1
; HIR-NEXT:     i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; HIR-NEXT:     br [[BB2:BB[0-9]+]]
; HIR:         [[BB2]]: # preds: [[BB1]], [[BB2]]
; HIR-NEXT:     i64 [[VP4:%.*]] = phi  [ i64 [[VP__IND_INIT]], [[BB1]] ],  [ i64 [[VP5:%.*]], [[BB2]] ]
; HIR-NEXT:     i32* [[VP_SUBSCRIPT:%.*]] = subscript inbounds i32* [[A0:%.*]] i64 [[VP4]]
; HIR-NEXT:     i32 [[VP_LOAD_1:%.*]] = load i32* [[VP_SUBSCRIPT]]
; HIR-NEXT:     i32 [[VP_LOAD_2:%.*]] = load i32* [[VP_SUM]]
; HIR-NEXT:     i32 [[VP6:%.*]] = add i32 [[VP_LOAD_1]] i32 [[VP_LOAD_2]]
; HIR-NEXT:     store i32 [[VP6]] i32* [[VP_SUM]]
; HIR-NEXT:     i64 [[VP5]] = add i64 [[VP4]] i64 [[VP__IND_INIT_STEP]]
; HIR-NEXT:     i1 [[VP7:%.*]] = icmp slt i64 [[VP5]] i64 [[VP3]]
; HIR-NEXT:     br i1 [[VP7]], [[BB2]], [[BB3:BB[0-9]+]]
; HIR:         [[BB3]]: # preds: [[BB2]]
; HIR-NEXT:     i32 [[VP_LOAD_3:%.*]] = load i32* [[VP_SUM]]
; HIR-NEXT:     i32 [[VP_SUMRED_FINAL:%.*]] = reduction-final{u_add} i32 [[VP_LOAD_3]]
; HIR-NEXT:     store i32 [[VP_SUMRED_FINAL]] i32* [[SUM0]]
; HIR-NEXT:     i64 [[VP__IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; HIR-NEXT:     br [[BB4:BB[0-9]+]]
; === Generated HIR code
; HIR:       BEGIN REGION { modified }
; HIR:                [[PRIV_MEM_BC0:%.*]] = &((i32*)([[PRIV_MEM0:%.*]])[0])
; HIR:                [[DOTUNIFLOAD0:%.*]] = ([[SUM0]])[0]
; HIR-NEXT:           [[RED_INIT0:%.*]] = 0
; HIR-NEXT:           [[RED_INIT_INSERT0:%.*]] = insertelement [[RED_INIT0]],  [[DOTUNIFLOAD0]],  0
; HIR-NEXT:           (<2 x i32>*)([[PRIV_MEM0]])[0] = [[RED_INIT_INSERT0]]
; HIR:                + DO i1 = 0, {{.*}} + -1, 2   <DO_LOOP> <simd-vectorized> <nounroll> <novectorize>
; HIR-NEXT:           |   [[DOTVEC0:%.*]] = (<2 x i32>*)([[A0]])[i1]
; HIR-NEXT:           |   [[DOTVEC30:%.*]] = (<2 x i32>*)([[PRIV_MEM0]])[0]
; HIR-NEXT:           |   (<2 x i32>*)([[PRIV_MEM0]])[0] = [[DOTVEC0]] + [[DOTVEC30]]
; HIR-NEXT:           + END LOOP
; HIR:                [[DOTVEC40:%.*]] = (<2 x i32>*)([[PRIV_MEM0]])[0]
; HIR-NEXT:           [[VEC_REDUCE0:%.*]] = @llvm.vector.reduce.add.v2i32([[DOTVEC40]])
; HIR-NEXT:           ([[SUM0]])[0] = [[VEC_REDUCE0]]
; HIR:       END REGION
;
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: foo:for.body.#{{[0-9]+}}
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i32* [[VP_SUM:%.*]] = allocate-priv i32*, OrigAlign = 4
; CHECK-NEXT:     i8* [[VP_SUM_BCAST:%.*]] = bitcast i32* [[VP_SUM]]
; CHECK-NEXT:     call i64 4 i8* [[VP_SUM_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8
; CHECK-NEXT:     i32 [[VP_LOAD:%.*]] = load i32* [[SUM0:%.*]]
; CHECK-NEXT:     i32 [[VP_SUMRED_INIT:%.*]] = reduction-init i32 0 i32 [[VP_LOAD]]
; CHECK-NEXT:     store i32 [[VP_SUMRED_INIT]] i32* [[VP_SUM]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB2]] ],  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ]
; CHECK-NEXT:     i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     i32 [[VP_A_I:%.*]] = load i32* [[VP_ARRAYIDX]]
; CHECK-NEXT:     i32 [[VP_SUM_LD:%.*]] = load i32* [[VP_SUM]]
; CHECK-NEXT:     i32 [[VP_ADD:%.*]] = add i32 [[VP_A_I]] i32 [[VP_SUM_LD]]
; CHECK-NEXT:     store i32 [[VP_ADD]] i32* [[VP_SUM]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP_EXITCOND:%.*]] = icmp eq i64 [[VP_INDVARS_IV_NEXT]] i64 [[N0:%.*]]
; CHECK-NEXT:     br i1 [[VP_EXITCOND]], [[BB3:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     i32 [[VP_LOAD_1:%.*]] = load i32* [[VP_SUM]]
; CHECK-NEXT:     i32 [[VP_SUMRED_FINAL:%.*]] = reduction-final{u_add} i32 [[VP_LOAD_1]]
; CHECK-NEXT:     store i32 [[VP_SUMRED_FINAL]] i32* [[SUM0]]
; CHECK-NEXT:     i8* [[VP_SUM_BCAST1:%.*]] = bitcast i32* [[VP_SUM]]
; CHECK-NEXT:     call i64 4 i8* [[VP_SUM_BCAST1]] void (i64, i8*)* @llvm.lifetime.end.p0i8
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>

; Checks for generated vector code
; CHECK-LABEL: define i32 @foo
; CHECK:       VPlannedBB:
; CHECK-NEXT:    [[TMP0:%.*]] = and i64 [[N0]], 4294967294
; CHECK-NEXT:    [[TMP1:%.*]] = icmp eq i64 0, [[TMP0]]
; CHECK-NEXT:    br i1 [[TMP1]], label [[MERGE_BLK0:%.*]], label [[VPLANNEDBB10:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB1:
; CHECK-NEXT:    br label [[VPLANNEDBB20:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB2:
; CHECK-NEXT:    [[SUM_VEC_BCAST:%.*]] = bitcast <2 x i32>* [[SUM_VEC:%.*]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8, i8* [[SUM_VEC_BCAST]])
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, i32* [[SUM0]], align 1
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, i32* [[SUM0]], align 1
; CHECK-NEXT:    [[RED_INIT_INSERT0:%.*]] = insertelement <2 x i32> zeroinitializer, i32 [[TMP2]], i32 0
; CHECK-NEXT:    store <2 x i32> [[RED_INIT_INSERT0]], <2 x i32>* [[SUM_VEC0:%.*]], align 1
; CHECK-NEXT:    [[TMP4:%.*]] = and i64 [[N0]], 4294967294
; CHECK-NEXT:    br label [[VECTOR_BODY0:%.*]]
; CHECK-EMPTY:
; CHECK-NEXT:  vector.body:
; CHECK-NEXT:    [[UNI_PHI0:%.*]] = phi i64 [ [[TMP8:%.*]], [[VECTOR_BODY0]] ], [ 0, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[VEC_PHI0:%.*]] = phi <2 x i64> [ [[TMP7:%.*]], [[VECTOR_BODY0]] ], [ <i64 0, i64 1>, [[VPLANNEDBB20]] ]
; CHECK-NEXT:    [[SCALAR_GEP0:%.*]] = getelementptr inbounds i32, i32* [[A0]], i64 [[UNI_PHI0]]
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i32* [[SCALAR_GEP0]] to <2 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD0:%.*]] = load <2 x i32>, <2 x i32>* [[TMP5]], align 4
; CHECK-NEXT:    [[WIDE_LOAD40:%.*]] = load <2 x i32>, <2 x i32>* [[SUM_VEC0]], align 4
; CHECK-NEXT:    [[TMP6:%.*]] = add nsw <2 x i32> [[WIDE_LOAD0]], [[WIDE_LOAD40]]
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32>* [[SUM_VEC0]], align 4
; CHECK-NEXT:    [[TMP7]] = add nuw nsw <2 x i64> [[VEC_PHI0]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP8]] = add nuw nsw i64 [[UNI_PHI0]], 2
; CHECK-NEXT:    [[TMP9:%.*]] = icmp uge i64 [[TMP8]], [[TMP4]]
; CHECK-NEXT:    br i1 [[TMP9]], label [[VPLANNEDBB50:%.*]], label [[VECTOR_BODY0]], !llvm.loop !0
; CHECK-EMPTY:
; CHECK-NEXT:  VPlannedBB5:
; CHECK-NEXT:    [[WIDE_LOAD60:%.*]] = load <2 x i32>, <2 x i32>* [[SUM_VEC0]], align 1
; CHECK-NEXT:    [[TMP10:%.*]] = call i32 @llvm.vector.reduce.add.v2i32(<2 x i32> [[WIDE_LOAD60]])
; CHECK-NEXT:    store i32 [[TMP10]], i32* [[SUM0]], align 1
; CHECK-NEXT:    [[SUM_VEC_BCAST1:%.*]] = bitcast <2 x i32>* [[SUM_VEC:%.*]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8, i8* [[SUM_VEC_BCAST1]])
; CHECK-NEXT:    [[TMP11:%.*]] = mul i64 1, [[TMP4]]
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 0, [[TMP11]]
; CHECK-NEXT:    br label [[VPLANNEDBB70:%.*]]
;
entry:
  %sum = alloca i32, align 4
  store i32 %init, i32* %sum, align 4
  br label %begin.simd

begin.simd:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD"(i32* %sum) ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %begin.simd ]
  %arrayidx = getelementptr inbounds i32, i32* %A, i64 %indvars.iv
  %A.i = load i32, i32* %arrayidx, align 4
  %sum.ld = load i32, i32* %sum, align 4
  %add = add nsw i32 %A.i, %sum.ld
  store i32 %add, i32* %sum, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body

for.cond.cleanup.loopexit:                             ; preds = %for.body
  br label %end.simd

end.simd:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:
  %fin = load i32, i32* %sum, align 4
  ret i32 %fin

}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
