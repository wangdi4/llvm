; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt %s -S -passes=vplan-vec -vplan-force-vf=4 -vplan-enable-all-liveouts \
; RUN: -vplan-print-after-vpentity-instrs -vplan-entities-dump -disable-vplan-codegen | FileCheck %s

define dso_local i64 @_Z3fooPlS_(i64* nocapture %arr1, i64* nocapture %arr2) local_unnamed_addr {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: _Z3fooPlS_:omp.inner.for.body
; CHECK-NEXT:  Loop Entities of the loop with header [[BB0:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Induction list
; CHECK-NEXT:   IntInduction(+) Start: i64 0 Step: i64 1 StartVal: i64 0 EndVal: i64 100 BinOp: i64 [[VP_ADD9:%.*]] = add i64 [[VP__OMP_IV_LOCAL_020:%.*]] i64 [[VP__OMP_IV_LOCAL_020_IND_INIT_STEP:%.*]]
; CHECK-NEXT:    Linked values: i64 [[VP__OMP_IV_LOCAL_020]], i64 [[VP_ADD9]], i64 [[VP__OMP_IV_LOCAL_020_IND_INIT:%.*]], i64 [[VP__OMP_IV_LOCAL_020_IND_INIT_STEP]], i64 [[VP__OMP_IV_LOCAL_020_IND_FINAL:%.*]],
; CHECK:       Private list
; CHECK-EMPTY:
; CHECK-NEXT:    Private tag: InMemory
; CHECK-NEXT:    Linked values: i64* [[RET_LPRIV0:%.*]], i64* [[VP_RET_LPRIV:%.*]], void [[VP_STORE:%.*]], i64 [[VP__PRIV_FINAL:%.*]],
; CHECK-NEXT:   Memory: i64* [[RET_LPRIV0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]]
; CHECK-NEXT:     i64* [[VP_RET_LPRIV]] = allocate-priv i64, OrigAlign = 8
; CHECK-NEXT:     i8* [[VP_RET_LPRIV_BCAST:%.*]] = bitcast i64* [[VP_RET_LPRIV]]
; CHECK-NEXT:     call i64 8 i8* [[VP_RET_LPRIV_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8
; CHECK-NEXT:     i64 [[VP__OMP_IV_LOCAL_020_IND_INIT]] = induction-init{add} i64 0 i64 1
; CHECK-NEXT:     i64 [[VP__OMP_IV_LOCAL_020_IND_INIT_STEP]] = induction-init-step{add} i64 1
; CHECK-NEXT:     i64* [[VP_PRIV_IDX_MEM:%.*]] = allocate-priv i64, OrigAlign = 8
; CHECK-NEXT:     store i64 -1 i64* [[VP_PRIV_IDX_MEM]]
; CHECK-NEXT:     br [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB0]]: # preds: [[BB2]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     i64 [[VP__OMP_IV_LOCAL_020]] = phi  [ i64 [[VP__OMP_IV_LOCAL_020_IND_INIT]], [[BB2]] ],  [ i64 [[VP_ADD9]], [[BB3]] ]
; CHECK-NEXT:     i64* [[VP_PTRIDX:%.*]] = getelementptr inbounds i64* [[ARR10:%.*]] i64 [[VP__OMP_IV_LOCAL_020]]
; CHECK-NEXT:     i64* [[VP_PTRIDX5:%.*]] = getelementptr inbounds i64* [[ARR20:%.*]] i64 [[VP__OMP_IV_LOCAL_020]]
; CHECK-NEXT:     i64 [[VP__PRE:%.*]] = load i64* [[VP_PTRIDX]]
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB0]], [[BB5:BB[0-9]+]]
; CHECK-NEXT:     i64 [[VP0:%.*]] = phi  [ i64 [[VP__PRE]], [[BB0]] ],  [ i64 0, [[BB5]] ]
; CHECK-NEXT:     i64 [[VP_STOREMERGE28:%.*]] = phi  [ i64 0, [[BB0]] ],  [ i64 [[VP_INC:%.*]], [[BB5]] ]
; CHECK-NEXT:     i1 [[VP_TOBOOL:%.*]] = icmp eq i64 [[VP0]] i64 0
; CHECK-NEXT:     br i1 [[VP_TOBOOL]], [[BB5]], [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]: # preds: [[BB4]]
; CHECK-NEXT:       i64* [[VP_PTRIDX2:%.*]] = getelementptr inbounds i64* [[ARR20]] i64 [[VP_STOREMERGE28]]
; CHECK-NEXT:       i64 [[VP1:%.*]] = load i64* [[VP_PTRIDX2]]
; CHECK-NEXT:       i1 [[VP_TOBOOL3:%.*]] = icmp eq i64 [[VP1]] i64 0
; CHECK-NEXT:       br i1 [[VP_TOBOOL3]], [[BB7:BB[0-9]+]], [[BB8:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:        [[BB8]]: # preds: [[BB6]]
; CHECK-NEXT:         i64 [[VP2:%.*]] = load i64* [[VP_PTRIDX5]]
; CHECK-NEXT:         store i64 [[VP__OMP_IV_LOCAL_020]] i64* [[VP_PRIV_IDX_MEM]]
; CHECK-NEXT:         store i64 [[VP2]] i64* [[VP_RET_LPRIV]]
; CHECK-NEXT:         call i64* [[VP_RET_LPRIV]] void (i64*)* @_Z3bazPl
; CHECK-NEXT:         store i64 0 i64* [[VP_PTRIDX5]]
; CHECK-NEXT:         br [[BB7]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB7]]: # preds: [[BB6]], [[BB8]]
; CHECK-NEXT:       store i64 0 i64* [[VP_PTRIDX]]
; CHECK-NEXT:       br [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB4]], [[BB7]]
; CHECK-NEXT:     i64 [[VP_INC]] = add i64 [[VP_STOREMERGE28]] i64 1
; CHECK-NEXT:     i1 [[VP_EXITCOND:%.*]] = icmp eq i64 [[VP_INC]] i64 100
; CHECK-NEXT:     br i1 [[VP_EXITCOND]], [[BB3]], [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB5]]
; CHECK-NEXT:     i64 [[VP_ADD9]] = add i64 [[VP__OMP_IV_LOCAL_020]] i64 [[VP__OMP_IV_LOCAL_020_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP_EXITCOND29:%.*]] = icmp eq i64 [[VP_ADD9]] i64 100
; CHECK-NEXT:     br i1 [[VP_EXITCOND29]], [[BB9:BB[0-9]+]], [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB9]]: # preds: [[BB3]]
; CHECK-NEXT:     i64 [[VP__OMP_IV_LOCAL_020_IND_FINAL]] = induction-final{add} i64 0 i64 1
; CHECK-NEXT:     i64 [[VP_LOADED_PRIV:%.*]] = load i64* [[VP_RET_LPRIV]]
; CHECK-NEXT:     i64 [[VP_LOADED_PRIV_IDX:%.*]] = load i64* [[VP_PRIV_IDX_MEM]]
; CHECK-NEXT:     i64 [[VP__PRIV_FINAL]] = private-final-c-mem i64 [[VP_LOADED_PRIV]] i64 [[VP_LOADED_PRIV_IDX]] i64* [[RET_LPRIV0]]
; CHECK-NEXT:     store i64 [[VP__PRIV_FINAL]] i64* [[RET_LPRIV0]]
; CHECK-NEXT:     i8* [[VP_RET_LPRIV_BCAST1:%.*]] = bitcast i64* [[VP_RET_LPRIV]]
; CHECK-NEXT:     call i64 8 i8* [[VP_RET_LPRIV_BCAST1]] void (i64, i8*)* @llvm.lifetime.end.p0i8
; CHECK-NEXT:     br [[BB10:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB10]]: # preds: [[BB9]]
; CHECK-NEXT:     br <External Block>
;
omp.inner.for.body.lr.ph:
  %ret.lpriv = alloca i64, align 8
  %l1.linear.iv = alloca i64, align 8
  store i64 0, i64* %ret.lpriv, align 8
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %omp.inner.for.body.lr.ph
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LASTPRIVATE:CONDITIONAL"(i64* %ret.lpriv), "QUAL.OMP.LINEAR:IV"(i64* %l1.linear.iv, i32 1), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.1, %for.cond.cleanup
  %.omp.iv.local.020 = phi i64 [ 0, %DIR.OMP.SIMD.1 ], [ %add9, %for.cond.cleanup ]
  %ptridx = getelementptr inbounds i64, i64* %arr1, i64 %.omp.iv.local.020
  %ptridx5 = getelementptr inbounds i64, i64* %arr2, i64 %.omp.iv.local.020
  %.pre = load i64, i64* %ptridx, align 8
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.inc
  %add9 = add nuw nsw i64 %.omp.iv.local.020, 1
  %exitcond29 = icmp eq i64 %add9, 100
  br i1 %exitcond29, label %DIR.OMP.END.SIMD.4, label %omp.inner.for.body

for.body:                                         ; preds = %omp.inner.for.body, %for.inc
  %1 = phi i64 [ %.pre, %omp.inner.for.body ], [ 0, %for.inc ]
  %storemerge28 = phi i64 [ 0, %omp.inner.for.body ], [ %inc, %for.inc ]
  %tobool = icmp eq i64 %1, 0
  br i1 %tobool, label %for.inc, label %if.then

if.then:                                          ; preds = %for.body
  %ptridx2 = getelementptr inbounds i64, i64* %arr2, i64 %storemerge28
  %2 = load i64, i64* %ptridx2, align 8
  %tobool3 = icmp eq i64 %2, 0
  br i1 %tobool3, label %if.end, label %if.then4

if.then4:                                         ; preds = %if.then
  %3 = load i64, i64* %ptridx5, align 8
  store i64 %3, i64* %ret.lpriv, align 8
  call void @_Z3bazPl(i64* nonnull %ret.lpriv)
  store i64 0, i64* %ptridx5, align 8
  br label %if.end

if.end:                                           ; preds = %if.then4, %if.then
  store i64 0, i64* %ptridx, align 8
  br label %for.inc

for.inc:                                          ; preds = %for.body, %if.end
  %inc = add nuw nsw i64 %storemerge28, 1
  %exitcond = icmp eq i64 %inc, 100
  br i1 %exitcond, label %for.cond.cleanup, label %for.body

DIR.OMP.END.SIMD.4:                               ; preds = %for.cond.cleanup
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.2

DIR.OMP.END.SIMD.2:                               ; preds = %DIR.OMP.END.SIMD.4
  %4 = load i64, i64* %ret.lpriv, align 8
  ret i64 %4
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

declare dso_local void @_Z3bazPl(i64*)
