; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
;RUN: opt -S -vplan-vec -vplan-enable-peeling %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind uwtable mustprogress
define dso_local void @_Z7ntstorePd(double* %A, i64 %N) local_unnamed_addr #0 {
; CHECK-LABEL: @_Z7ntstorePd(
; CHECK-NEXT:  DIR.OMP.SIMD.113:
; CHECK-NEXT:    [[I_LINEAR_IV:%.*]] = alloca i64, align 8
; CHECK-NEXT:    br label [[DIR_OMP_SIMD_1:%.*]]
; CHECK:       DIR.OMP.SIMD.1:
; CHECK-NEXT:    br label [[DIR_OMP_SIMD_2:%.*]]
; CHECK:       DIR.OMP.SIMD.2:
; CHECK-NEXT:    call void @llvm.assume(i1 true) [ "align"(double* [[A:%.*]], i64 64) ]
; CHECK-NEXT:    br label [[PEEL_CHECKZ16:%.*]]
; CHECK:       peel.checkz23:
; CHECK-NEXT:    br label [[PEEL_CHECKV17:%.*]]
; CHECK:       peel.checkv24:
; CHECK-NEXT:    [[TMP0:%.*]] = icmp ugt i64 7, [[N:%.*]]
; CHECK-NEXT:    br i1 [[TMP0]], label [[MERGE_BLK12:%.*]], label [[PEELBLK6:%.*]]
; CHECK:       PeelBlk13:
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_SL_CLONE:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br label [[MERGE_BLK14:%.*]]
; CHECK:       merge.blk21:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ [[ADD_SL_CLONE:%.*]], [[VPLANNEDBB:%.*]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[TMP1:%.*]] = icmp ugt i64 7, [[N]]
; CHECK-NEXT:    br i1 [[TMP1]], label [[MERGE_BLK12]], label [[VPLANNEDBB2:%.*]]
; CHECK:       VPlannedBB2:
; CHECK-NEXT:    br label [[VPLANNEDBB3:%.*]]
; CHECK:       VPlannedBB3:
; CHECK-NEXT:    [[UNI_PHIIND_START_BCAST_SPLATINSERT:%.*]] = insertelement <4 x i64> poison, i64 [[UNI_PHI]], i32 0
; CHECK-NEXT:    [[UNI_PHIIND_START_BCAST_SPLAT:%.*]] = shufflevector <4 x i64> [[UNI_PHIIND_START_BCAST_SPLATINSERT]], <4 x i64> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP2:%.*]] = add <4 x i64> [[UNI_PHIIND_START_BCAST_SPLAT]], <i64 0, i64 1, i64 2, i64 3>
; CHECK-NEXT:    [[N_ADJST:%.*]] = sub nuw nsw i64 [[N]], 3
; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[N_ADJST]], 4
; CHECK-NEXT:    [[N_VEC:%.*]] = sub nuw nsw i64 [[N]], [[N_MOD_VF]]
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI5:%.*]] = phi i64 [ [[UNI_PHI]], [[VPLANNEDBB3]] ], [ [[TMP4:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i64> [ [[TMP2]], [[VPLANNEDBB3]] ], [ [[TMP3:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP3]] = add <4 x i64> [[VEC_PHI]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP4]] = add i64 [[UNI_PHI5]], 4
; CHECK-NEXT:    [[TMP5:%.*]] = add nuw nsw <4 x i64> [[VEC_PHI]], <i64 1, i64 1, i64 1, i64 1>
; CHECK-NEXT:    [[DOTEXTRACT_0_:%.*]] = extractelement <4 x i64> [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp <4 x i64> [[TMP5]] to <4 x double>
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[DOTEXTRACT_0_]]
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast double* [[SCALAR_GEP]] to <4 x double>*
; CHECK-NEXT:    store <4 x double> [[TMP6]], <4 x double>* [[TMP7]], align 32, !nontemporal !0
; CHECK-NEXT:    [[TMP8:%.*]] = icmp uge i64 [[TMP4]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP8]], label [[VPLANNEDBB6:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP1:![0-9]+]]
; CHECK:       VPlannedBB6:
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 1, [[N_VEC]]
; CHECK-NEXT:    [[TMP10:%.*]] = add i64 0, [[TMP9]]
; CHECK-NEXT:    br label [[VPLANNEDBB7:%.*]]
; CHECK:       VPlannedBB7:
; CHECK-NEXT:    br label [[VPLANNEDBB8:%.*]]
; CHECK:       VPlannedBB8:
; CHECK-NEXT:    [[TMP11:%.*]] = icmp eq i64 [[N]], [[N_VEC]]
; CHECK-NEXT:    br i1 [[TMP11]], label [[FINAL_MERGE:%.*]], label [[MERGE_BLK12]]
; CHECK:       merge.blk19:
; CHECK-NEXT:    [[UNI_PHI9:%.*]] = phi i64 [ [[TMP10]], [[VPLANNEDBB8]] ], [ 0, [[PEEL_CHECKV17]] ], [ [[UNI_PHI]], [[VPLANNEDBB1]] ]
; CHECK-NEXT:    br label [[REMBLK8:%.*]]
; CHECK:       RemBlk15:
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       VPlannedBB10:
; CHECK-NEXT:    br label [[FINAL_MERGE]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI11:%.*]] = phi i64 [ [[ADD:%.*]], [[VPLANNEDBB10:%.*]] ], [ [[TMP10]], [[VPLANNEDBB8]] ]
; CHECK-NEXT:    br label [[DIR_OMP_END_SIMD_2:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[DOTOMP_IV_LOCAL_08:%.*]] = phi i64 [ [[UNI_PHI9]], [[REMBLK8]] ], [ [[ADD]], [[OMP_INNER_FOR_BODY]] ]
; CHECK-NEXT:    [[ADD]] = add nuw nsw i64 [[DOTOMP_IV_LOCAL_08]], 1
; CHECK-NEXT:    [[CONV:%.*]] = sitofp i64 [[ADD]] to double
; CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[ADD]]
; CHECK-NEXT:    store double [[CONV]], double* [[ARRAYIDX]], align 8, !nontemporal !0
; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[ADD]], [[N]]
; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[VPLANNEDBB10]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP3:![0-9]+]]
; CHECK:       omp.inner.for.body.sl.clone:
; CHECK-NEXT:    [[DOTOMP_IV_LOCAL_08_SL_CLONE:%.*]] = phi i64 [ 0, [[PEELBLK6]] ], [ [[ADD_SL_CLONE]], [[OMP_INNER_FOR_BODY_SL_CLONE]] ]
; CHECK-NEXT:    [[ADD_SL_CLONE]] = add nuw nsw i64 [[DOTOMP_IV_LOCAL_08_SL_CLONE]], 1
; CHECK-NEXT:    [[CONV_SL_CLONE:%.*]] = sitofp i64 [[ADD_SL_CLONE]] to double
; CHECK-NEXT:    [[ARRAYIDX_SL_CLONE:%.*]] = getelementptr inbounds double, double* [[A]], i64 [[ADD_SL_CLONE]]
; CHECK-NEXT:    store double [[CONV_SL_CLONE]], double* [[ARRAYIDX_SL_CLONE]], align 8, !nontemporal !0
; CHECK-NEXT:    [[EXITCOND_NOT_SL_CLONE:%.*]] = icmp eq i64 [[ADD_SL_CLONE]], 3
; CHECK-NEXT:    br i1 [[EXITCOND_NOT_SL_CLONE]], label [[VPLANNEDBB]], label [[OMP_INNER_FOR_BODY_SL_CLONE]], !llvm.loop [[LOOP5:![0-9]+]]
; CHECK:       DIR.OMP.END.SIMD.2:
; CHECK-NEXT:    br label [[DIR_OMP_END_SIMD_3:%.*]]
; CHECK:       DIR.OMP.END.SIMD.3:
; CHECK-NEXT:    ret void
;
DIR.OMP.SIMD.113:
  %i.linear.iv = alloca i64, align 8
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.113
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.ALIGNED:PTR_TO_PTR"(double** null, i32 64), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null), "QUAL.OMP.LINEAR:IV"(i64* %i.linear.iv, i32 1) ]
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.1
  call void @llvm.assume(i1 true) [ "align"(double* %A, i64 64) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.2, %omp.inner.for.body
  %.omp.iv.local.08 = phi i64 [ 0, %DIR.OMP.SIMD.2 ], [ %add, %omp.inner.for.body ]
  %add = add nuw nsw i64 %.omp.iv.local.08, 1
  %conv = sitofp i64 %add to double
  %arrayidx = getelementptr inbounds double, double* %A, i64 %add
  store double %conv, double* %arrayidx, align 8, !nontemporal !0
  %exitcond.not = icmp eq i64 %add, %N
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.2, label %omp.inner.for.body

DIR.OMP.END.SIMD.2:                               ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %DIR.OMP.END.SIMD.2
  ret void
}


declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
declare void @llvm.assume(i1)
attributes #0 = { nounwind "may-have-openmp-directive"="true" "min-legal-vector-width"="0" "no-infs-fp-math"="true" "no-nans-fp-math"="true" "no-signed-zeros-fp-math"="true" "no-trapping-math"="true" "pre_loopopt" "target-cpu"="skylake-avx512" "unsafe-fp-math"="true" }
!0 = !{i32 1}
