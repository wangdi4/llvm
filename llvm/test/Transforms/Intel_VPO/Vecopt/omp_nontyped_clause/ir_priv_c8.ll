; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; Test to check that we allow using a recurrency in a load instruction that is in
; operands chain of unconditional last private.
;
; RUN: opt -disable-output -passes=vplan-vec -vplan-force-vf=4 --vplan-print-after-initial-transforms -disable-vplan-codegen %s 2>&1 | FileCheck %s

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: mustprogress nounwind uwtable
define dso_local i32 @_Z3fooPiS_(i32* %b) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after initial VPlan transforms:
; CHECK-NEXT:  VPlan IR for: _Z3fooPiS_:omp.inner.for.body.#{{[0-9]+}}
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i32* [[VP_V_LPRIV:%.*]] = allocate-priv i32*, OrigAlign = 4
; CHECK-NEXT:     i8* [[VP_V_LPRIV_BCAST:%.*]] = bitcast i32* [[VP_V_LPRIV]]
; CHECK-NEXT:     call i64 4 i8* [[VP_V_LPRIV_BCAST]] void (i64, i8*)* @llvm.lifetime.start.p0i8
; CHECK-NEXT:     i32* [[VP__IND_INIT:%.*]] = induction-init{getelementptr} i32* live-in1 i64 1
; CHECK-NEXT:     i64 [[VP__IND_INIT_STEP:%.*]] = induction-init-step{getelementptr} i64 1
; CHECK-NEXT:     i32 [[VP__OMP_IV_LOCAL_011_IND_INIT:%.*]] = induction-init{add} i32 live-in2 i32 1
; CHECK-NEXT:     i32 [[VP__OMP_IV_LOCAL_011_IND_INIT_STEP:%.*]] = induction-init-step{add} i32 1
; CHECK-NEXT:     i32 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i32 103, UF = 1
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB2]]
; CHECK-NEXT:     i32* [[VP0:%.*]] = phi  [ i32* [[VP__IND_INIT]], [[BB1]] ],  [ i32* [[VP1:%.*]], [[BB2]] ]
; CHECK-NEXT:     i32 [[VP__OMP_IV_LOCAL_011:%.*]] = phi  [ i32 [[VP__OMP_IV_LOCAL_011_IND_INIT]], [[BB1]] ],  [ i32 [[VP_ADD2:%.*]], [[BB2]] ]
; CHECK-NEXT:     i32* [[VP1]] = getelementptr inbounds i32* [[VP0]] i64 [[VP__IND_INIT_STEP]]
; CHECK-NEXT:     i32 [[VP2:%.*]] = load i32* [[VP0]]
; CHECK-NEXT:     i32 [[VP_ADD2]] = add i32 [[VP__OMP_IV_LOCAL_011]] i32 [[VP__OMP_IV_LOCAL_011_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp uge i32 [[VP_ADD2]] i32 [[VP_VECTOR_TRIP_COUNT]]
; CHECK-NEXT:     br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB3:BB[0-9]+]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB2]]
; CHECK-NEXT:     i32* [[VP__IND_FINAL:%.*]] = induction-final{getelementptr} i32* [[B_ADDR_LINEAR_PROMOTED0:%.*]] i64 1
; CHECK-NEXT:     i32 [[VP__OMP_IV_LOCAL_011_IND_FINAL:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:     i32 [[VP__PRIV_FINAL:%.*]] = private-final-uc i32 [[VP2]]
; CHECK-NEXT:     i8* [[VP_V_LPRIV_BCAST1:%.*]] = bitcast i32* [[VP_V_LPRIV]]
; CHECK-NEXT:     call i64 4 i8* [[VP_V_LPRIV_BCAST1]] void (i64, i8*)* @llvm.lifetime.end.p0i8
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0     [[DOTLCSSA0:%.*]] = phi i32 [ [[TMP2:%.*]], [[OMP_INNER_FOR_BODY0:%.*]] ] i32 [[VP__PRIV_FINAL]] -> i32 [[TMP2]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1   no underlying for i32* [[VP__IND_FINAL]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 2   no underlying for i32 [[VP__OMP_IV_LOCAL_011_IND_FINAL]]
;
DIR.OMP.SIMD.118:
  %v.lpriv = alloca i32, align 4
  %b.addr.linear = alloca i32*, align 8
  %i.linear.iv = alloca i32, align 4
  store i32* %b, i32** %b.addr.linear, align 8
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %DIR.OMP.SIMD.118
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LASTPRIVATE"(i32* %v.lpriv), "QUAL.OMP.LINEAR"(i32** %b.addr.linear, i32 1), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null), "QUAL.OMP.LINEAR:IV"(i32* %i.linear.iv, i32 1) ]
  br label %DIR.OMP.SIMD.2

DIR.OMP.SIMD.2:                                   ; preds = %DIR.OMP.SIMD.1
  %b.addr.linear.promoted = load i32*, i32** %b.addr.linear, align 8
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %DIR.OMP.SIMD.2, %omp.inner.for.body
  %1 = phi i32* [ %b.addr.linear.promoted, %DIR.OMP.SIMD.2 ], [ %incdec.ptr, %omp.inner.for.body ]
  %.omp.iv.local.011 = phi i32 [ 0, %DIR.OMP.SIMD.2 ], [ %add2, %omp.inner.for.body ]
  %incdec.ptr = getelementptr inbounds i32, i32* %1, i64 1
  %2 = load i32, i32* %1, align 4
  %add2 = add nuw nsw i32 %.omp.iv.local.011, 1
  %exitcond.not = icmp eq i32 %add2, 103
  br i1 %exitcond.not, label %DIR.OMP.END.SIMD.219, label %omp.inner.for.body

DIR.OMP.END.SIMD.219:                             ; preds = %omp.inner.for.body
  %.lcssa = phi i32 [ %2, %omp.inner.for.body ]
  store i32 %.lcssa, i32* %v.lpriv
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %DIR.OMP.END.SIMD.219
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.4

DIR.OMP.END.SIMD.4:                               ; preds = %DIR.OMP.END.SIMD.3
  %add1.le = add nsw i32 %.lcssa, 1000
  ret i32 %add1.le
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)


