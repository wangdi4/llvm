; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; Test to check VPlan LLVM-IR vector codegen for privates declared in non-default
; address spaces. During codegen we need to emit a wide alloca in the default
; addrspace and an explicit addrspacecast if the addrspace of generated wide
; alloca does not match the private pointer's addrspace.

; RUN: opt %s -vplan-vec -vplan-force-vf=2 -S | FileCheck %s

define internal void @test_soa(i8** %arr) #3 {
; CHECK-LABEL: @test_soa(
; CHECK-NEXT:  DIR.OMP.SIMD.4:
; CHECK-NEXT:    [[ZII_PRIV:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[ZII_PRIV_ASCAST:%.*]] = addrspacecast i32* [[ZII_PRIV]] to i32 addrspace(4)*
; CHECK-NEXT:    [[ZII_PRIV_ASCAST_VEC:%.*]] = alloca <2 x i32>, align 8
; CHECK-NEXT:    [[ZII_PRIV_ASCAST_VEC_ASCAST:%.*]] = addrspacecast <2 x i32>* [[ZII_PRIV_ASCAST_VEC]] to <2 x i32> addrspace(4)*
; CHECK-NEXT:    [[ZII_PRIV_ASCAST_VEC_ASCAST_BC:%.*]] = bitcast <2 x i32> addrspace(4)* [[ZII_PRIV_ASCAST_VEC_ASCAST]] to i32 addrspace(4)*
; CHECK-NEXT:    [[ZII_PRIV_ASCAST_VEC_ASCAST_BASE_ADDR:%.*]] = getelementptr i32, i32 addrspace(4)* [[ZII_PRIV_ASCAST_VEC_ASCAST_BC]], <2 x i32> <i32 0, i32 1>

; CHECK:       vector.body:
; CHECK:         store <2 x i32> [[VEC_PHI:%.*]], <2 x i32> addrspace(4)* [[ZII_PRIV_ASCAST_VEC_ASCAST]], align 4
;
DIR.OMP.SIMD.4:
  %zii.priv = alloca i32, align 4
  %zii.priv.ascast = addrspacecast i32* %zii.priv to i32 addrspace(4)*
  br label %omp.inner.for.body.lr.ph

DIR.OMP.END.TASKLOOP.8.exitStub:                  ; preds = %DIR.OMP.SIMD.4, %DIR.OMP.END.SIMD.2
  ret void

omp.inner.for.body.lr.ph:                         ; preds = %DIR.OMP.SIMD.4
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"(i32 addrspace(4)* %zii.priv.ascast) ]
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %omp.inner.for.body.lr.ph
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body, %DIR.OMP.SIMD.1
  %indvars.iv = phi i32 [ %indvars.iv.next, %omp.inner.for.body ], [ 0, %DIR.OMP.SIMD.1 ]
  store i32 %indvars.iv, i32 addrspace(4)* %zii.priv.ascast
  %indvars.iv.next = add i32 %indvars.iv, 1
  %cmp = icmp ult i32 1024, %indvars.iv.next
  br i1 %cmp, label %omp.inner.for.cond.omp.loop.exit.split_crit_edge, label %omp.inner.for.body

omp.inner.for.cond.omp.loop.exit.split_crit_edge: ; preds = %omp.inner.for.body
  br label %DIR.OMP.END.SIMD.2

DIR.OMP.END.SIMD.2:                               ; preds = %omp.inner.for.cond.omp.loop.exit.split_crit_edge
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.TASKLOOP.8.exitStub
}


define internal void @test_lifetime_intrins() #3 {
; CHECK-LABEL: @test_lifetime_intrins(
; CHECK-NEXT:  DIR.OMP.SIMD.4:
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV:%.*]] = alloca float, align 4
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST:%.*]] = addrspacecast float* [[XTMP_ASCAST_PRIV]] to float addrspace(4)*
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST_VEC:%.*]] = alloca <2 x float>, align 8
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST:%.*]] = addrspacecast <2 x float>* [[XTMP_ASCAST_PRIV_ASCAST_VEC]] to <2 x float> addrspace(4)*
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BC:%.*]] = bitcast <2 x float> addrspace(4)* [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST]] to float addrspace(4)*
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BASE_ADDR:%.*]] = getelementptr float, float addrspace(4)* [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BC]], <2 x i32> <i32 0, i32 1>
; CHECK-NEXT:    [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BASE_ADDR_EXTRACT_0:%.*]] = extractelement <2 x float addrspace(4)*> [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BASE_ADDR]], i32 0

; CHECK:       vector.body:
; CHECK:         [[TMP0:%.*]] = bitcast float addrspace(4)* [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST_BASE_ADDR_EXTRACT_0]] to i8 addrspace(4)*
; CHECK-NEXT:    [[TMP1:%.*]] = addrspacecast i8 addrspace(4)* [[TMP0]] to i8*
; CHECK-NEXT:    store <2 x float> zeroinitializer, <2 x float> addrspace(4)* [[XTMP_ASCAST_PRIV_ASCAST_VEC_ASCAST]], align 4
;
DIR.OMP.SIMD.4:
  %xtmp.ascast.priv = alloca float, align 4
  %xtmp.ascast.priv.ascast = addrspacecast float* %xtmp.ascast.priv to float addrspace(4)*
  br label %omp.inner.for.body.lr.ph

omp.inner.for.body.lr.ph:                         ; preds = %DIR.OMP.SIMD.5
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"(float addrspace(4)* %xtmp.ascast.priv.ascast) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %omp.inner.for.body.lr.ph, %omp.inner.for.body
  %.omp.iv.ascast.local.021 = phi i32 [ 0, %omp.inner.for.body.lr.ph ], [ %add1, %omp.inner.for.body ]
  %bc = bitcast float addrspace(4)* %xtmp.ascast.priv.ascast to i8 addrspace(4)*
  %bc.ascast = addrspacecast i8 addrspace(4)* %bc to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* %bc.ascast)
  store float 0.000000e+00, float addrspace(4)* %xtmp.ascast.priv.ascast, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* %bc.ascast)
  %add1 = add nsw i32 %.omp.iv.ascast.local.021, 1
  %cmp = icmp ult i32 1024, %add1
  br i1 %cmp, label %omp.inner.for.cond.DIR.OMP.END.SIMD.7.loopexit_crit_edge, label %omp.inner.for.body

omp.inner.for.cond.DIR.OMP.END.SIMD.7.loopexit_crit_edge: ; preds = %omp.inner.for.body
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD

DIR.OMP.END.SIMD:
  ret void
}

declare token @llvm.directive.region.entry() nounwind
declare void @llvm.directive.region.exit(token) nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture)
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture)
