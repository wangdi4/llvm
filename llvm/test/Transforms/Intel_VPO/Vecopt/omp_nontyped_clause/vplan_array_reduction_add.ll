; Test to verify that VPlan vectorizer handles add array reduction
; idioms identified in incoming IR.

; C/C++ source
; int test(int init, int n, int *A)
; {
;   int sum[8];
;   for (int i = 0; i < 8; i++)
;     sum[i] = init;
;
;   #pragma omp simd simdlen(2) reduction(+:sum)
;   for (int l1 = 0; l1 < n; l1++) {
;     sum[l1] += A[l1];
;   }
;
;   return sum[8];
; }

; RUN: opt -vplan-vec -vplan-force-vf=2 -vplan-print-after-vpentity-instrs -vplan-entities-dump -print-after=vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefixes=IR
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -vplan-force-vf=2 -vplan-print-after-vpentity-instrs -vplan-entities-dump -print-after=hir-vplan-vec -disable-output < %s 2>&1 | FileCheck %s --check-prefixes=CHECK,HIR

target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define i32 @test(i32* nocapture readonly %A, i64 %N, i32 %init) {
; CHECK: VPlan after insertion of VPEntities instructions:
; CHECK: Reduction list
; CHECK:  (+) Start: [8 x i32]* %sum
; CHECK:   Linked values: [8 x i32]* [[VPSUMALLOCA:%.*]],
; CHECK:  Memory: [8 x i32]* %sum

; CHECK: [8 x i32]* [[VPSUMALLOCA]] = allocate-priv [8 x i32]*, OrigAlign = 4
; CHECK: reduction-init-arr i32 0 [8 x i32]* [[VPSUMALLOCA]]
; CHECK: [8 x i32] [[VPSUMFIN:%.*]] = reduction-final-arr{add} [8 x i32]* [[VPSUMALLOCA]] [8 x i32]* %sum

; Checks for code generated by LLVM-IR vectorizer.
; IR-LABEL: @test(
; IR-NEXT:  entry:
; IR-NEXT:    [[SUM:%.*]] = alloca [8 x i32], align 4
; IR-NEXT:    [[SUM_VEC:%.*]] = alloca [2 x [8 x i32]], align 4
; IR-NEXT:    [[SUM_VEC_BC:%.*]] = bitcast [2 x [8 x i32]]* [[SUM_VEC]] to [8 x i32]*
; IR-NEXT:    [[SUM_VEC_BASE_ADDR:%.*]] = getelementptr [8 x i32], [8 x i32]* [[SUM_VEC_BC]], <2 x i32> <i32 0, i32 1>
; IR-NEXT:    [[SUM_VEC_BASE_ADDR_EXTRACT_1_:%.*]] = extractelement <2 x [8 x i32]*> [[SUM_VEC_BASE_ADDR]], i32 1
; IR-NEXT:    [[SUM_VEC_BASE_ADDR_EXTRACT_0_:%.*]] = extractelement <2 x [8 x i32]*> [[SUM_VEC_BASE_ADDR]], i32 0
; IR-NEXT:    br label [[FILL_SUM:%.*]]

; IR:       VPlannedBB2:
; IR:         [[ARR_RED_BASE_ADDR_BC:%.*]] = bitcast [8 x i32]* [[SUM_VEC_BASE_ADDR_EXTRACT_0_]] to i32*
; IR-NEXT:    br label [[ARRAY_REDN_INIT_LOOP:%.*]]
; IR:       array.redn.init.loop:
; IR-NEXT:    [[CUR_ELEM_IDX:%.*]] = phi i64 [ 0, [[VPLANNEDBB2:%.*]] ], [ [[NEXT_ELEM_IDX:%.*]], [[ARRAY_REDN_INIT_LOOP:%.*]] ]
; IR-NEXT:    [[CUR_ELEM_PTR:%.*]] = getelementptr i32, i32* [[ARR_RED_BASE_ADDR_BC]], i64 [[CUR_ELEM_IDX]]
; IR-NEXT:    store i32 0, i32* [[CUR_ELEM_PTR]], align 4
; IR-NEXT:    [[NEXT_ELEM_IDX]] = add i64 [[CUR_ELEM_IDX]], 1
; IR-NEXT:    [[INITLOOP_COND:%.*]] = icmp ult i64 [[NEXT_ELEM_IDX]], 16
; IR-NEXT:    br i1 [[INITLOOP_COND]], label [[ARRAY_REDN_INIT_LOOP]], label [[ARRAY_REDN_INIT_LOOPEXIT:%.*]]

; IR:       array.redn.final.main.loop:
; IR-NEXT:    [[MAIN_ELEM_IDX:%.*]] = phi i64 [ 0, [[VPLANNEDBB4:%.*]] ], [ [[NEXT_MAIN_ELEM_IDX:%.*]], [[ARRAY_REDN_FINAL_MAIN_LOOP:%.*]] ]
; IR-NEXT:    [[ORIG_ARR_GEP:%.*]] = getelementptr [8 x i32], [8 x i32]* [[SUM]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[ORIG_ARR_BC:%.*]] = bitcast i32* [[ORIG_ARR_GEP]] to <4 x i32>*
; IR-NEXT:    [[ORIG_ARR_LD:%.*]] = load <4 x i32>, <4 x i32>* [[ORIG_ARR_BC]], align 4
; IR-NEXT:    [[PRIV_ARR_GEP_LANE0:%.*]] = getelementptr [8 x i32], [8 x i32]* [[SUM_VEC_BASE_ADDR_EXTRACT_0_]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_BC_LANE0:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE0]] to <4 x i32>*
; IR-NEXT:    [[PRIV_ARR_LD_LANE0:%.*]] = load <4 x i32>, <4 x i32>* [[PRIV_ARR_BC_LANE0]], align 4
; IR-NEXT:    [[ARR_FIN_RED:%.*]] = add <4 x i32> [[ORIG_ARR_LD]], [[PRIV_ARR_LD_LANE0]]
; IR-NEXT:    [[PRIV_ARR_GEP_LANE1:%.*]] = getelementptr [8 x i32], [8 x i32]* [[SUM_VEC_BASE_ADDR_EXTRACT_1_]], i64 0, i64 [[MAIN_ELEM_IDX]]
; IR-NEXT:    [[PRIV_ARR_BC_LANE1:%.*]] = bitcast i32* [[PRIV_ARR_GEP_LANE1]] to <4 x i32>*
; IR-NEXT:    [[PRIV_ARR_LD_LANE1:%.*]] = load <4 x i32>, <4 x i32>* [[PRIV_ARR_BC_LANE1]], align 4
; IR-NEXT:    [[ARR_FIN_RED5:%.*]] = add <4 x i32> [[ARR_FIN_RED]], [[PRIV_ARR_LD_LANE1]]
; IR-NEXT:    store <4 x i32> [[ARR_FIN_RED5]], <4 x i32>* [[ORIG_ARR_BC]], align 4
; IR-NEXT:    [[NEXT_MAIN_ELEM_IDX]] = add i64 [[MAIN_ELEM_IDX]], 4
; IR-NEXT:    [[FINAL_MAINLOOP_COND:%.*]] = icmp ult i64 [[NEXT_MAIN_ELEM_IDX]], 8
; IR-NEXT:    br i1 [[FINAL_MAINLOOP_COND]], label [[ARRAY_REDN_FINAL_MAIN_LOOP]], label [[ARRAY_REDN_FINAL_REM_LOOP:%.*]]
; IR:       array.redn.final.rem.loop:
; IR-NEXT:    br label [[ARRAY_REDN_FINAL_EXIT:%.*]]
;
; Checks for code generated by HIR vectorizer.
; HIR-LABEL: Function: test
; HIR:           BEGIN REGION { modified }
; HIR:                 %arr.red.base.addr.bc = bitcast.[8 x i32]*.i32*(&(([8 x i32]*)(%priv.mem)[0]));
; HIR:                 + DO i1 = 0, 15, 1   <DO_LOOP>
; HIR-NEXT:            |   (i32*)(%arr.red.base.addr.bc)[i1] = 0;
; HIR-NEXT:            + END LOOP

; HIR:                 %extract.1. = extractelement &((<2 x [8 x i32]*>)(%priv.mem.bc)[<i32 0, i32 1>]),  1;
; HIR-NEXT:            %priv.arr.copy0 = &(([8 x i32]*)(%priv.mem)[0]);
; HIR:                 + DO i1 = 0, 7, 4   <DO_LOOP>
; HIR-NEXT:            |   %orig.arr.ld = (<4 x i32>*)(%sum)[0][i1];
; HIR-NEXT:            |   %priv.arr.ld.lane0 = (<4 x i32>*)(%priv.arr.copy0)[0][i1];
; HIR-NEXT:            |   %arr.fin.red = %orig.arr.ld  +  %priv.arr.ld.lane0;
; HIR-NEXT:            |   %priv.arr.ld.lane1 = (<4 x i32>*)(%extract.1.)[0][i1];
; HIR-NEXT:            |   %arr.fin.red7 = %arr.fin.red  +  %priv.arr.ld.lane1;
; HIR-NEXT:            |   (<4 x i32>*)(%sum)[0][i1] = %arr.fin.red7;
; HIR-NEXT:            + END LOOP
; HIR:           END REGION
;
entry:
  %sum = alloca [8 x i32], align 4
  br label %fill.sum

fill.sum:
  %arr.begin = getelementptr inbounds [8 x i32], [8 x i32]* %sum, i32 0, i32 0
  %arr.end = getelementptr i32, i32* %arr.begin, i32 8
  %red.init.isempty = icmp eq i32* %arr.begin, %arr.end
  br i1 %red.init.isempty, label %begin.simd.1, label %red.init.body

red.init.body:
  %red.curr.ptr = phi i32* [ %arr.begin, %fill.sum ], [ %red.next.ptr, %red.init.body ]
  store i32 %init, i32* %red.curr.ptr, align 4
  %red.next.ptr = getelementptr inbounds i32, i32* %red.curr.ptr, i32 1
  %red.init.done = icmp eq i32* %red.next.ptr, %arr.end
  br i1 %red.init.done, label %begin.simd.1, label %red.init.body

begin.simd.1:
  br label %begin.simd

begin.simd:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.ADD"([8 x i32]* %sum) ]
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body ], [ 0, %begin.simd ]
  %arrayidx = getelementptr inbounds i32, i32* %A, i64 %indvars.iv
  %A.i = load i32, i32* %arrayidx, align 4
  %sum.gep = getelementptr inbounds [8 x i32], [8 x i32]* %sum, i64 0, i64 %indvars.iv
  %sum.ld = load i32, i32* %sum.gep, align 4
  %add = add nsw i32 %A.i, %sum.ld
  store i32 %add, i32* %sum.gep, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp slt i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.body, label %for.cond.cleanup.loopexit

for.cond.cleanup.loopexit:                             ; preds = %for.body
  br label %end.simd

end.simd:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.3

DIR.QUAL.LIST.END.3:
  %fin.gep = getelementptr inbounds [8 x i32], [8 x i32]* %sum, i32 0, i32 8
  %fin = load i32, i32* %fin.gep, align 4
  ret i32 %fin

}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
