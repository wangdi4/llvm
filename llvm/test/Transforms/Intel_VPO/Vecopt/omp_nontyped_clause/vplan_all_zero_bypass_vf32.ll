; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; REQUIRES: asserts
; RUN: opt -passes='vplan-vec' -mtriple=x86_64-unknown-linux-gnu -mattr=+avx512vl,+avx512cd\
; RUN:  -enable-intel-advanced-opts -vplan-enable-all-zero-bypass-non-loops -vplan-print-after-all-zero-bypass\
; RUN:  -vplan-force-vf=32 -vplan-all-zero-bypass-region-threshold=1 -disable-vplan-codegen -disable-output < %s 2>&1 | FileCheck %s

; Don't insert the bypass region for VF=32 since probability is very low
; that all lanes are 0.

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #2

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #2

; Function Attrs: nounwind uwtable
define dso_local void @foo(i32* nocapture readonly %a, i32* nocapture %b, i32* nocapture readonly %c) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after all zero bypass insertion:
; CHECK-NEXT:  VPlan IR for: foo:omp.inner.for.body.#{{[0-9]+}}
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB1:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_I_LPRIV:%.*]] = allocate-priv i32*, OrigAlign = 4 (SVAOpBits )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i8* [[VP0:%.*]] = bitcast i32* [[VP_I_LPRIV]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] call i64 4 i8* [[VP0]] void (i64, i8*)* @llvm.lifetime.start.p0i8 (SVAOpBits 0->F 1->F 2->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_INIT:%.*]] = induction-init{add} i64 live-in0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]] = induction-init-step{add} i64 1 (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_VECTOR_TRIP_COUNT:%.*]] = vector-trip-count i64 256, UF = 1 (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB2:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP_INDVARS_IV:%.*]] = phi  [ i64 [[VP_INDVARS_IV_NEXT:%.*]], [[BB3]] ],  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB1]] ] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_ARRAYIDX:%.*]] = getelementptr inbounds i32* [[A0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP1:%.*]] = load i32* [[VP_ARRAYIDX]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP_CMP1:%.*]] = icmp sgt i32 [[VP1]] i32 3 (SVAOpBits 0->V 1->V )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB4:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i1 [[VP2:%.*]] = block-predicate i1 [[VP_CMP1]] (SVAOpBits 0->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_ARRAYIDX3:%.*]] = getelementptr inbounds i32* [[C0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP3:%.*]] = load i32* [[VP_ARRAYIDX3]] (SVAOpBits 0->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB3]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB4]]
; CHECK-NEXT:     [DA: Div, SVA: ( V )] i32 [[VP__BLEND_BB3:%.*]] = blend [ i32 0, i1 true ], [ i32 [[VP3]], i1 [[VP_CMP1]] ] (SVAOpBits 0->V 1->V 2->V 3->V )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i32* [[VP_ARRAYIDX5:%.*]] = getelementptr inbounds i32* [[B0:%.*]] i64 [[VP_INDVARS_IV]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Div, SVA: ( V )] store i32 [[VP__BLEND_BB3]] i32* [[VP_ARRAYIDX5]] (SVAOpBits 0->V 1->F )
; CHECK-NEXT:     [DA: Div, SVA: (F  )] i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i1 [[VP_VECTOR_LOOP_EXITCOND:%.*]] = icmp uge i64 [[VP_INDVARS_IV_NEXT]] i64 [[VP_VECTOR_TRIP_COUNT]] (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br i1 [[VP_VECTOR_LOOP_EXITCOND]], [[BB5:BB[0-9]+]], [[BB2]] (SVAOpBits 0->F 1->F 2->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB3]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] i64 [[VP_INDVARS_IV_IND_FINAL:%.*]] = induction-final{add} i64 0 i64 1 (SVAOpBits 0->F 1->F )
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br [[BB6:BB[0-9]+]] (SVAOpBits 0->F )
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB5]]
; CHECK-NEXT:     [DA: Uni, SVA: (F  )] br <External Block> (SVAOpBits )
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   no underlying for i64 [[VP_INDVARS_IV_IND_FINAL]]
;
omp.inner.for.body.lr.ph:
  %i.lpriv = alloca i32, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %omp.inner.for.body.lr.ph
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null), "QUAL.OMP.LASTPRIVATE"(i32* %i.lpriv) ]
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %if.end, %DIR.OMP.SIMD.1
  %indvars.iv = phi i64 [ %indvars.iv.next, %if.end ], [ 0, %DIR.OMP.SIMD.1 ]
  %arrayidx = getelementptr inbounds i32, i32* %a, i64 %indvars.iv
  %1 = load i32, i32* %arrayidx, align 4
  %cmp1 = icmp sgt i32 %1, 3
  br i1 %cmp1, label %if.then, label %if.end

if.then:                                          ; preds = %omp.inner.for.body
  %arrayidx3 = getelementptr inbounds i32, i32* %c, i64 %indvars.iv
  %2 = load i32, i32* %arrayidx3, align 4
  br label %if.end

if.end:                                           ; preds = %if.then, %omp.inner.for.body
  %3 = phi i32 [ %2, %if.then ], [ 0, %omp.inner.for.body ]
  %arrayidx5 = getelementptr inbounds i32, i32* %b, i64 %indvars.iv
  store i32 %3, i32* %arrayidx5, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 256
  br i1 %exitcond, label %DIR.OMP.END.SIMD.4, label %omp.inner.for.body

DIR.OMP.END.SIMD.4:                               ; preds = %if.end
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.OMP.END.SIMD.2

DIR.OMP.END.SIMD.2:                               ; preds = %DIR.OMP.END.SIMD.4
  ret void
}
