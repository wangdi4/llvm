; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -vplan-enable-soa=false -vplan-vec -vplan-force-vf=4 -S < %s | FileCheck %s

; Check that bitcast of a scalar private to the narrower type isn't used a
; unit-strided memory.

; JIRA: CMPLRLLVM-20884

define void @foo(i32* nocapture %arr) {
; CHECK-LABEL: @foo(
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI1:%.*]] = phi i32 [ 0, [[VECTOR_PH:%.*]] ], [ [[TMP2:%.*]], [[VECTOR_BODY:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i32> [ <i32 0, i32 1, i32 2, i32 3>, [[VECTOR_PH]] ], [ [[TMP1:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast <4 x i32*> [[PRIV_VEC_BASE_ADDR:%.*]] to <4 x i8*>
; CHECK-NEXT:    [[WIDE_MASKED_GATHER:%.*]] = call <4 x i8> @llvm.masked.gather.v4i8.v4p0i8(<4 x i8*> [[TMP0]], i32 4, <4 x i1> <i1 true, i1 true, i1 true, i1 true>, <4 x i8> poison)
; CHECK-NEXT:    [[TMP1]] = add nuw nsw <4 x i32> [[VEC_PHI]], <i32 4, i32 4, i32 4, i32 4>
; CHECK-NEXT:    [[TMP2]] = add nuw nsw i32 [[UNI_PHI1]], 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp uge i32 [[TMP2]], 100
; CHECK-NEXT:    br i1 [[TMP3]], label [[VPLANNEDBB:%.*]], label [[VECTOR_BODY]], !llvm.loop !0
;
entry:
  %priv = alloca i32, align 4
  br label %preheader

preheader:
  %0 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"(i32* %priv) ]
  br label %header

header:
  %iv = phi i32 [ 0, %preheader ], [ %iv.next, %header ]
  %cast = bitcast i32 *%priv to i8 *
  %priv.val = load i8, i8* %cast, align 4
  %iv.next = add nuw nsw i32 %iv, 1
  %exitcond = icmp eq i32 %iv.next, 100
  br i1 %exitcond, label %exit, label %header

exit:
  call void @llvm.directive.region.exit(token %0) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
