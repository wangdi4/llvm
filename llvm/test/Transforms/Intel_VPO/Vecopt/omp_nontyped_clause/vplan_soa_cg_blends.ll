; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -vplan-vec -vplan-force-vf=2 -vplan-enable-soa -S %s | FileCheck %s

define void @uniform_with_undef(i64 *%p, i1 *%uniform.ptr) #0 {
; CHECK-LABEL: @uniform_with_undef(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ARR_SOA_PRIV32:%.*]] = alloca [1024 x i32], align 4
; CHECK-NEXT:    [[ARR_SOA_PRIV32_SOA_VEC:%.*]] = alloca [1024 x <2 x i32>], align 8
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION:%.*]]
; CHECK:       simd.begin.region:
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[TMP15:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_SOA_PRIV32_SOA_VEC]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8192, i8* [[TMP15]])
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1]] ], [ [[TMP13:%.*]], [[VPLANNEDBB21:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <2 x i64> [ <i64 0, i64 1>, [[VPLANNEDBB1]] ], [ [[TMP12:%.*]], [[VPLANNEDBB21]] ]
; CHECK-NEXT:    [[SOA_SCALAR_GEP:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_SOA_PRIV32_SOA_VEC]], i64 0, i64 0
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = icmp sgt <2 x i64> [[VEC_PHI]], zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB3:%.*]]
; CHECK:       VPlannedBB3:
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x i1> [[TMP0]] to i2
; CHECK-NEXT:    [[TMP2:%.*]] = icmp ne i2 [[TMP1]], 0
; CHECK-NEXT:    br i1 [[TMP2]], label [[PRED_LOAD_IF:%.*]], label [[TMP4:%.*]]
; CHECK:       pred.load.if:
; CHECK-NEXT:    [[TMP3:%.*]] = load i1, i1* [[UNIFORM_PTR:%.*]], align 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <2 x i1> poison, i1 [[TMP3]], i32 0
; CHECK-NEXT:    br label [[TMP4]]
; CHECK:       5:
; CHECK-NEXT:    [[TMP5:%.*]] = phi <2 x i1> [ poison, [[VPLANNEDBB3]] ], [ [[BROADCAST_SPLATINSERT]], [[PRED_LOAD_IF]] ]
; CHECK-NEXT:    br label [[PRED_LOAD_CONTINUE:%.*]]
; CHECK:       pred.load.continue:
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <2 x i1> [[TMP5]], <2 x i1> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    [[TMP6:%.*]] = xor <2 x i1> [[BROADCAST_SPLAT]], <i1 true, i1 true>
; CHECK-NEXT:    br label [[VPLANNEDBB4:%.*]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    [[TMP7:%.*]] = and <2 x i1> [[TMP0]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = and <2 x i1> [[TMP0]], [[BROADCAST_SPLAT]]
; CHECK-NEXT:    br label [[VPLANNEDBB5:%.*]]
; CHECK:       VPlannedBB5:
; CHECK-NEXT:    [[SOA_SCALAR_GEP6:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], i64 2
; CHECK-NEXT:    [[SOA_SCALAR_GEP7:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], i64 2
; CHECK-NEXT:    [[MM_VECTORGEP:%.*]] = getelementptr <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP7]], <2 x i64> zeroinitializer, <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    [[WIDE_LOAD8:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP6]], align 4
; CHECK-NEXT:    [[MM_VECTORGEP9:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], <2 x i32> [[WIDE_LOAD]], <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    br label [[VPLANNEDBB10:%.*]]
; CHECK:       VPlannedBB10:
; CHECK-NEXT:    [[SOA_SCALAR_GEP11:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], i64 1
; CHECK-NEXT:    [[SOA_SCALAR_GEP12:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], i64 1
; CHECK-NEXT:    [[MM_VECTORGEP13:%.*]] = getelementptr <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP12]], <2 x i64> zeroinitializer, <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    [[WIDE_LOAD14:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP11]], align 4
; CHECK-NEXT:    [[MM_VECTORGEP15:%.*]] = getelementptr inbounds <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], <2 x i64> [[VEC_PHI]], <2 x i64> <i64 0, i64 1>
; CHECK-NEXT:    br label [[VPLANNEDBB16:%.*]]
; CHECK:       VPlannedBB16:
; CHECK-NEXT:    [[PREDBLEND:%.*]] = select <2 x i1> [[TMP8]], <2 x i64> <i64 1, i64 1>, <2 x i64> <i64 2, i64 2>
; CHECK-NEXT:    [[PREDBLEND17:%.*]] = select <2 x i1> [[TMP8]], <2 x i32*> [[MM_VECTORGEP13]], <2 x i32*> [[MM_VECTORGEP]]
; CHECK-NEXT:    [[PREDBLEND18:%.*]] = select <2 x i1> [[TMP8]], <2 x i32*> [[MM_VECTORGEP15]], <2 x i32*> [[MM_VECTORGEP9]]
; CHECK-NEXT:    [[TMP9:%.*]] = bitcast <2 x i1> [[TMP0]] to i2
; CHECK-NEXT:    [[CTTZ:%.*]] = call i2 @llvm.cttz.i2(i2 [[TMP9]], i1 false)
; CHECK-NEXT:    [[TMP10:%.*]] = extractelement <2 x i64> [[PREDBLEND]], i2 [[CTTZ]]
; CHECK-NEXT:    [[WIDE_MASKED_GATHER:%.*]] = call <2 x i32> @llvm.masked.gather.v2i32.v2p0i32(<2 x i32*> [[PREDBLEND17]], i32 4, <2 x i1> [[TMP0]], <2 x i32> poison)
; CHECK-NEXT:    [[WIDE_MASKED_GATHER19:%.*]] = call <2 x i32> @llvm.masked.gather.v2i32.v2p0i32(<2 x i32*> [[PREDBLEND18]], i32 4, <2 x i1> [[TMP0]], <2 x i32> poison)
; CHECK-NEXT:    [[TMP11:%.*]] = add i64 [[TMP10]], 1
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT22:%.*]] = insertelement <2 x i64> poison, i64 [[TMP11]], i32 0
; CHECK-NEXT:    [[BROADCAST_SPLAT23:%.*]] = shufflevector <2 x i64> [[BROADCAST_SPLATINSERT22]], <2 x i64> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB20:%.*]]
; CHECK:       VPlannedBB20:
; CHECK-NEXT:    br label [[VPLANNEDBB21]]
; CHECK:       VPlannedBB21:
; CHECK-NEXT:    [[PREDBLEND24:%.*]] = select <2 x i1> [[TMP0]], <2 x i64> [[BROADCAST_SPLAT23]], <2 x i64> <i64 -1, i64 -1>
; CHECK-NEXT:    [[TMP12]] = add nuw nsw <2 x i64> [[VEC_PHI]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP13]] = add nuw nsw i64 [[UNI_PHI]], 2
; CHECK-NEXT:    [[TMP14:%.*]] = icmp uge i64 [[TMP13]], 4
; CHECK-NEXT:    br i1 [[TMP14]], label [[VPLANNEDBB25:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB25:
; CHECK-NEXT:    [[TMP16:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_SOA_PRIV32_SOA_VEC]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 8192, i8* [[TMP16]])
; CHECK-NEXT:    br label [[VPLANNEDBB26:%.*]]
; CHECK:       VPlannedBB26:
; CHECK-NEXT:    br label [[FINAL_MERGE:%.*]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI27:%.*]] = phi i64 [ 4, [[VPLANNEDBB26]] ]
; CHECK-NEXT:    br label [[EXIT:%.*]]
; CHECK:       simd.loop:
; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[IV_NEXT:%.*]], [[LATCH:%.*]] ]
; CHECK-NEXT:    [[UNI_GEP32:%.*]] = getelementptr inbounds [1024 x i32], [1024 x i32]* [[ARR_SOA_PRIV32]], i64 0, i64 0
; CHECK-NEXT:    [[LD:%.*]] = load i32, i32* [[UNI_GEP32]], align 4
; CHECK-NEXT:    [[COND:%.*]] = icmp sgt i64 [[IV]], 0
; CHECK-NEXT:    br i1 [[COND]], label [[UNI_START:%.*]], label [[LATCH]]
; CHECK:       uni.start:
; CHECK-NEXT:    [[UNIFORM:%.*]] = load i1, i1* [[UNIFORM_PTR]], align 1
; CHECK-NEXT:    br i1 [[UNIFORM]], label [[IF:%.*]], label [[ELSE:%.*]]
; CHECK:       if:
; CHECK-NEXT:    [[UNI_IF:%.*]] = getelementptr inbounds i32, i32* [[UNI_GEP32]], i64 1
; CHECK-NEXT:    [[LD_IF:%.*]] = load i32, i32* [[UNI_IF]], align 4
; CHECK-NEXT:    [[STR_IF:%.*]] = getelementptr inbounds i32, i32* [[UNI_GEP32]], i64 [[IV]]
; CHECK-NEXT:    br label [[IF_END:%.*]]
; CHECK:       else:
; CHECK-NEXT:    [[UNI_ELSE:%.*]] = getelementptr inbounds i32, i32* [[UNI_GEP32]], i64 2
; CHECK-NEXT:    [[LD_ELSE:%.*]] = load i32, i32* [[UNI_ELSE]], align 4
; CHECK-NEXT:    [[RND_ELSE:%.*]] = getelementptr inbounds i32, i32* [[UNI_GEP32]], i32 [[LD]]
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       if.end:
; CHECK-NEXT:    [[BLEND:%.*]] = phi i64 [ 1, [[IF]] ], [ 2, [[ELSE]] ]
; CHECK-NEXT:    [[BLENDPTRUNI:%.*]] = phi i32* [ [[UNI_IF]], [[IF]] ], [ [[UNI_ELSE]], [[ELSE]] ]
; CHECK-NEXT:    [[BLENDPTRRND:%.*]] = phi i32* [ [[STR_IF]], [[IF]] ], [ [[RND_ELSE]], [[ELSE]] ]
; CHECK-NEXT:    [[LD_UNI:%.*]] = load i32, i32* [[BLENDPTRUNI]], align 4
; CHECK-NEXT:    [[LD_RND:%.*]] = load i32, i32* [[BLENDPTRRND]], align 4
; CHECK-NEXT:    [[VAL:%.*]] = add nuw nsw i64 [[BLEND]], 1
; CHECK-NEXT:    br label [[UNI_END:%.*]]
; CHECK:       uni.end:
; CHECK-NEXT:    br label [[LATCH]]
; CHECK:       latch:
; CHECK-NEXT:    [[ST:%.*]] = phi i64 [ -1, [[SIMD_LOOP:%.*]] ], [ [[VAL]], [[UNI_END]] ]
; CHECK-NEXT:    [[IV_NEXT]] = add nuw nsw i64 [[IV]], 1
; CHECK-NEXT:    [[EXITCOND:%.*]] = icmp eq i64 [[IV_NEXT]], 4
; CHECK-NEXT:    br label [[SIMD_LOOP]]
; CHECK:       exit:
; CHECK-NEXT:    ret void
;
entry:
  %arr.soa.priv32 = alloca [1024 x i32], align 4
  br label %simd.begin.region

simd.begin.region:
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i32]* %arr.soa.priv32) ]
  br label %simd.loop

simd.loop:
  %iv = phi i64 [ 0, %simd.begin.region], [ %iv.next, %latch ]
  %uni.gep32 = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.soa.priv32, i64 0, i64 0
  %ld = load i32, i32* %uni.gep32, align 4
  %cond = icmp sgt i64 %iv, 0
  br i1 %cond, label %uni.start, label %latch

uni.start:
  %uniform = load i1, i1 *%uniform.ptr
  br i1 %uniform, label %if, label %else

if:
  %uni.if = getelementptr inbounds i32, i32* %uni.gep32, i64 1
  %ld.if = load i32, i32* %uni.if, align 4
  %str.if = getelementptr inbounds i32, i32* %uni.gep32, i64 %iv
  br label %if.end

else:
  %uni.else = getelementptr inbounds i32, i32* %uni.gep32, i64 2
  %ld.else = load i32, i32* %uni.else, align 4
  %rnd.else = getelementptr inbounds i32, i32* %uni.gep32, i32 %ld
  br label %if.end

if.end:
  %blend = phi i64 [ 1, %if ], [ 2, %else]
  %blendPtrUni = phi i32* [ %uni.if, %if ], [ %uni.else, %else]
  %blendPtrRnd = phi i32* [ %str.if, %if ], [ %rnd.else, %else]
  %ld.uni = load i32, i32* %blendPtrUni, align 4
  %ld.rnd = load i32, i32* %blendPtrRnd, align 4
  %val = add nsw nuw i64 %blend, 1
  br label %uni.end

uni.end:
  br label %latch

latch:
  %st = phi i64 [ -1, %simd.loop ], [ %val, %uni.end]
  %iv.next = add nsw nuw i64 %iv, 1
  %exitcond = icmp eq i64 %iv.next, 4
  br i1 %exitcond, label %exit, label %simd.loop

exit:
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token %0)
