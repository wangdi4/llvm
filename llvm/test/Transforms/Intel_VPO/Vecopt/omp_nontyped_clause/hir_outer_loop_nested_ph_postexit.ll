; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -vplan-print-after-plain-cfg -disable-output -vplan-force-build < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -hir-ssa-deconstruction -hir-framework -hir-vplan-vec -vplan-print-after-plain-cfg -disable-output -vplan-force-build < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec" -vplan-print-after-plain-cfg -disable-output -vplan-force-build < %s 2>&1 -vplan-enable-new-cfg-merge-hir=0 | FileCheck %s
; RUN: opt -passes="hir-ssa-deconstruction,hir-vplan-vec" -vplan-print-after-plain-cfg -disable-output -vplan-force-build < %s 2>&1 -vplan-enable-new-cfg-merge-hir=1 | FileCheck %s


; Verify that we are able to build a VPlan for an outer loop with a nested loop
; which has pre-header and post-exit in HIR.

; Source code
;
; #include <string.h>
; #include <stdio.h>
;
; #define N 101
;
; float A[N][N];
; float B[N][N];
;
; long ub[N];
;
; long foo(long n, long m, long *ub, float a[N][N], bool vec) {
;   long i, j, ret = 0;
;     #pragma omp simd simdlen(4) linear(i, j)
;     for (i = 0; i < n; i++) {
;       for (j = 0; j < m; j++) {
;         a[i][j] = i;
;         ub[j] = ret+j;
;         ret += 2;
;       }
;     }
;     return ret;
; }

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@A = dso_local local_unnamed_addr global [101 x [101 x float]] zeroinitializer
@B = dso_local local_unnamed_addr global [101 x [101 x float]] zeroinitializer
@ub = dso_local local_unnamed_addr global [101 x i64] zeroinitializer

; Function Attrs: nounwind uwtable
define dso_local i64 @_Z3foollPlPA101_fb(i64 %n, i64 %m, i64* nocapture %ub, [101 x float]* nocapture %a, i1 zeroext %vec) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after importing plain CFG:
; CHECK-NEXT:  VPlan IR for: _Z3foollPlPA101_fb:HIR.#{{[0-9]+}}
; CHECK-NEXT:  External Defs Start:
; CHECK-DAG:     [[VP0:%.*]] = {%ret.021}
; CHECK-DAG:     [[VP1:%.*]] = {%inc.lcssa25}
; CHECK-DAG:     [[VP2:%.*]] = {%n + -1}
; CHECK-DAG:     [[VP3:%.*]] = {%a}
; CHECK-DAG:     [[VP4:%.*]] = {%m + -1}
; CHECK-DAG:     [[VP5:%.*]] = {%ub}
; CHECK-DAG:     [[VP6:%.*]] = {%m}
; CHECK-DAG:     [[VP7:%.*]] = {%.omp.iv.0.out}
; CHECK-DAG:     [[VP8:%.*]] = {%ret.021.out}
; CHECK-NEXT:  External Defs End:
; CHECK-NEXT:    [[BB0:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB1:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:     i64 [[VP9:%.*]] = add i64 [[VP2]] i64 1
; CHECK-NEXT:     br [[BB2:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB2]]: # preds: [[BB1]], [[BB3:BB[0-9]+]]
; CHECK-NEXT:     i64 [[VP10:%.*]] = phi  [ i64 [[RET_0210:%.*]], [[BB1]] ],  [ i64 [[VP11:%.*]], [[BB3]] ]
; CHECK-NEXT:     i64 [[VP12:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP13:%.*]], [[BB3]] ]
; CHECK-NEXT:     i64 [[VP14:%.*]] = hir-copy i64 [[VP10]] , OriginPhiId: -1
; CHECK-NEXT:     i64 [[VP15:%.*]] = hir-copy i64 [[VP12]] , OriginPhiId: -1
; CHECK-NEXT:     i64 [[VP16:%.*]] = hir-copy i64 0 , OriginPhiId: -1
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB2]]
; CHECK-NEXT:     i1 [[VP17:%.*]] = icmp sgt i64 [[M0:%.*]] i64 0
; CHECK-NEXT:     br i1 [[VP17]], [[BB5:BB[0-9]+]], [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB5]]: # preds: [[BB4]]
; CHECK-NEXT:       float [[VP18:%.*]] = sitofp i64 [[VP12]] to float
; CHECK-NEXT:       i64 [[VP19:%.*]] = add i64 [[VP4]] i64 1
; CHECK-NEXT:       br [[BB6:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB6]]: # preds: [[BB5]], [[BB6]]
; CHECK-NEXT:       i64 [[VP20:%.*]] = phi  [ i64 0, [[BB5]] ],  [ i64 [[VP21:%.*]], [[BB6]] ]
; CHECK-NEXT:       float* [[VP_SUBSCRIPT:%.*]] = subscript inbounds [101 x float]* [[A0:%.*]] i64 [[VP12]] i64 [[VP20]]
; CHECK-NEXT:       store float [[VP18]] float* [[VP_SUBSCRIPT]]
; CHECK-NEXT:       i64 [[VP22:%.*]] = mul i64 3 i64 [[VP20]]
; CHECK-NEXT:       i64 [[VP23:%.*]] = add i64 [[VP14]] i64 [[VP22]]
; CHECK-NEXT:       i64* [[VP_SUBSCRIPT_1:%.*]] = subscript inbounds i64* [[UB0:%.*]] i64 [[VP20]]
; CHECK-NEXT:       store i64 [[VP23]] i64* [[VP_SUBSCRIPT_1]]
; CHECK-NEXT:       i64 [[VP24:%.*]] = mul i64 2 i64 [[VP20]]
; CHECK-NEXT:       i64 [[VP25:%.*]] = add i64 [[VP14]] i64 [[VP24]]
; CHECK-NEXT:       i64 [[VP26:%.*]] = add i64 [[VP25]] i64 2
; CHECK-NEXT:       i64 [[VP21]] = add i64 [[VP20]] i64 1
; CHECK-NEXT:       i1 [[VP27:%.*]] = icmp slt i64 [[VP21]] i64 [[VP19]]
; CHECK-NEXT:       br i1 [[VP27]], [[BB6]], [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB7]]: # preds: [[BB6]]
; CHECK-NEXT:       i64 [[VP28:%.*]] = hir-copy i64 [[VP26]] , OriginPhiId: -1
; CHECK-NEXT:       i64 [[VP29:%.*]] = hir-copy i64 [[M0]] , OriginPhiId: -1
; CHECK-NEXT:       br [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB3]]: # preds: [[BB7]], [[BB4]]
; CHECK-NEXT:     i64 [[VP30:%.*]] = phi  [ i64 [[VP29]], [[BB7]] ],  [ i64 [[VP16]], [[BB4]] ]
; CHECK-NEXT:     i64 [[VP11]] = phi  [ i64 [[VP28]], [[BB7]] ],  [ i64 [[VP10]], [[BB4]] ]
; CHECK-NEXT:     i64 [[VP31:%.*]] = hir-copy i64 [[VP11]] , OriginPhiId: -1
; CHECK-NEXT:     i64 [[VP13]] = add i64 [[VP12]] i64 1
; CHECK-NEXT:     i1 [[VP32:%.*]] = icmp slt i64 [[VP13]] i64 [[VP9]]
; CHECK-NEXT:     br i1 [[VP32]], [[BB2]], [[BB8:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB8]]: # preds: [[BB3]]
; CHECK-NEXT:     br [[BB9:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB9]]: # preds: [[BB8]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0   i64 [[VP15]] -> [[VP33:%.*]] = {%.omp.iv.0.out}
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1   i64 [[VP30]] -> [[VP34:%.*]] = {%inc.lcssa25}
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 2   i64 [[VP31]] -> [[VP35:%.*]] = {%ret.021.out}
;
entry:
  %i = alloca i64
  %j = alloca i64
  %0 = bitcast i64* %i to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %0) #2
  %1 = bitcast i64* %j to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %1) #2
  %cmp = icmp sgt i64 %n, 0
  br i1 %cmp, label %DIR.OMP.SIMD.118, label %omp.precond.end

DIR.OMP.SIMD.118:
  %2 = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.SIMDLEN"(i32 4), "QUAL.OMP.LINEAR"(i64* %i, i32 1), "QUAL.OMP.LINEAR"(i64* %j, i32 1), "QUAL.OMP.NORMALIZED.IV"(i8* null), "QUAL.OMP.NORMALIZED.UB"(i8* null) ]
  %cmp622 = icmp sgt i64 %m, 0
  br label %omp.inner.for.body

omp.inner.for.body:
  %.omp.iv.0 = phi i64 [ %add11, %omp.inner.for.inc ], [ 0, %DIR.OMP.SIMD.118 ]
  %ret.021 = phi i64 [ %ret.1.lcssa, %omp.inner.for.inc ], [ 0, %DIR.OMP.SIMD.118 ]
  br i1 %cmp622, label %for.body.lr.ph, label %omp.inner.for.inc

for.body.lr.ph:
  %conv = sitofp i64 %.omp.iv.0 to float
  br label %for.body

for.body:
  %ret.124 = phi i64 [ %ret.021, %for.body.lr.ph ], [ %add10, %for.body ]
  %storemerge23 = phi i64 [ 0, %for.body.lr.ph ], [ %inc, %for.body ]
  %idx7 = getelementptr inbounds [101 x float], [101 x float]* %a, i64 %.omp.iv.0, i64 %storemerge23
  store float %conv, float* %idx7
  %add8 = add nsw i64 %ret.124, %storemerge23
  %idx9 = getelementptr inbounds i64, i64* %ub, i64 %storemerge23
  store i64 %add8, i64* %idx9
  %add10 = add nsw i64 %ret.124, 2
  %inc = add nuw nsw i64 %storemerge23, 1
  %exitcond = icmp eq i64 %inc, %m
  br i1 %exitcond, label %omp.inner.for.inc.loopexit, label %for.body

omp.inner.for.inc.loopexit:
  %add10.lcssa = phi i64 [ %add10, %for.body ]
  br label %omp.inner.for.inc

omp.inner.for.inc:
  %inc.lcssa25 = phi i64 [ 0, %omp.inner.for.body ], [ %m, %omp.inner.for.inc.loopexit ]
  %ret.1.lcssa = phi i64 [ %ret.021, %omp.inner.for.body ], [ %add10.lcssa, %omp.inner.for.inc.loopexit ]
  %add11 = add nuw nsw i64 %.omp.iv.0, 1
  %exitcond26 = icmp eq i64 %add11, %n
  br i1 %exitcond26, label %omp.loop.exit, label %omp.inner.for.body

omp.loop.exit:
  %inc.lcssa25.lcssa = phi i64 [ %inc.lcssa25, %omp.inner.for.inc ]
  %ret.1.lcssa.lcssa = phi i64 [ %ret.1.lcssa, %omp.inner.for.inc ]
  %.omp.iv.0.lcssa = phi i64 [ %.omp.iv.0, %omp.inner.for.inc ]
  store i64 %inc.lcssa25.lcssa, i64* %j
  store i64 %.omp.iv.0.lcssa, i64* %i
  call void @llvm.directive.region.exit(token %2) [ "DIR.OMP.END.SIMD"() ]
  br label %omp.precond.end

omp.precond.end:
  %ret.2 = phi i64 [ %ret.1.lcssa.lcssa, %omp.loop.exit ], [ 0, %entry ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %1) #2
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %0) #2
  ret i64 %ret.2
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture) #1

; Function Attrs: nounwind
declare token @llvm.directive.region.entry() #2

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token) #2

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture) #1

attributes #0 = { nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "may-have-openmp-directive"="true" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "pre_loopopt" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 8.0.0"}
!2 = !{!3, !4, i64 0}
!3 = !{!"array@_ZTSA101_f", !4, i64 0}
!4 = !{!"float", !5, i64 0}
!5 = !{!"omnipotent char", !6, i64 0}
!6 = !{!"Simple C++ TBAA"}
!7 = !{!8, !8, i64 0}
!8 = !{!"long", !5, i64 0}
