; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; RUN: opt -opaque-pointers=0 -passes=vplan-vec -vplan-force-vf=4 -S %s | FileCheck %s

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

define i32 @foo(i32* nocapture readonly %ip) {
; CHECK-LABEL: @foo(
; CHECK-NEXT:    [[MIN:%.*]] = alloca i32, align 4
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i32* [[MIN]] to i8*
; CHECK-NEXT:    store i32 2147483647, i32* [[MIN]], align 4
; CHECK-NEXT:    [[MIN_VEC:%.*]] = alloca <4 x i32>, align 16
; CHECK-NEXT:    [[MIN_VEC_BC:%.*]] = bitcast <4 x i32>* [[MIN_VEC]] to i32*
; CHECK-NEXT:    [[MIN_VEC_BASE_ADDR:%.*]] = getelementptr i32, i32* [[MIN_VEC_BC]], <4 x i32> <i32 0, i32 1, i32 2, i32 3>
; CHECK:         br label [[DIR_OMP_SIMD_1:%.*]]
; CHECK:       DIR.OMP.SIMD.1:
; CHECK-NEXT:    br label [[DIR_QUAL_LIST_END_2:%.*]]
; CHECK:       DIR.QUAL.LIST.END.2:
; CHECK-NEXT:    [[DOTPRE:%.*]] = load i32, i32* [[MIN]], align 4
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i32> poison, i32 [[DOTPRE]], i64 0
; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i32> [[BROADCAST_SPLATINSERT]], <4 x i32> poison, <4 x i32> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[MIN_VEC_BCAST:%.*]] = bitcast i32* [[MIN_VEC_BC_E:%.*]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 16, i8* [[MIN_VEC_BCAST]])
; CHECK-NEXT:    store <4 x i32> [[BROADCAST_SPLAT]], <4 x i32>* [[MIN_VEC]], align 1
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <4 x i32> [ [[BROADCAST_SPLAT]], [[VPLANNEDBB1]] ], [ [[PREDBLEND:%.*]], [[VPLANNEDBB5:%.*]] ]
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1]] ], [ [[TMP5:%.*]], [[VPLANNEDBB5]] ]
; CHECK-NEXT:    [[VEC_PHI3:%.*]] = phi <4 x i64> [ <i64 0, i64 1, i64 2, i64 3>, [[VPLANNEDBB1]] ], [ [[TMP4:%.*]], [[VPLANNEDBB5]] ]
; CHECK-NEXT:    [[SCALAR_GEP:%.*]] = getelementptr inbounds i32, i32* [[IP:%.*]], i64 [[UNI_PHI]]
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast i32* [[SCALAR_GEP]] to <4 x i32>*
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <4 x i32>, <4 x i32>* [[TMP2]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = icmp sgt <4 x i32> [[VEC_PHI]], [[WIDE_LOAD]]
; CHECK-NEXT:    br label [[VPLANNEDBB4:%.*]]
; CHECK:       VPlannedBB4:
; CHECK-NEXT:    call void @llvm.masked.store.v4i32.p0v4i32(<4 x i32> [[WIDE_LOAD]], <4 x i32>* [[MIN_VEC]], i32 4, <4 x i1> [[TMP3]])
; CHECK-NEXT:    br label [[VPLANNEDBB5]]
; CHECK:       VPlannedBB5:
; CHECK-NEXT:    [[PREDBLEND]] = select <4 x i1> [[TMP3]], <4 x i32> [[WIDE_LOAD]], <4 x i32> [[VEC_PHI]]
; CHECK-NEXT:    [[TMP4]] = add nuw nsw <4 x i64> [[VEC_PHI3]], <i64 4, i64 4, i64 4, i64 4>
; CHECK-NEXT:    [[TMP5]] = add nuw nsw i64 [[UNI_PHI]], 4
; CHECK-NEXT:    [[TMP6:%.*]] = icmp uge i64 [[TMP5]], 1024
; CHECK-NEXT:    br i1 [[TMP6]], label [[VPLANNEDBB6:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
; CHECK:       VPlannedBB6:
; CHECK-NEXT:    [[TMP7:%.*]] = call i32 @llvm.vector.reduce.smin.v4i32(<4 x i32> [[PREDBLEND]])
; CHECK-NEXT:    store i32 [[TMP7]], i32* [[MIN]], align 1
; CHECK-NEXT:    [[MIN_VEC_BCAST1:%.*]] = bitcast i32* [[MIN_VEC_BC_E3:%.*]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.end.p0i8(i64 16, i8* [[MIN_VEC_BCAST1]])
; CHECK-NEXT:    br label [[VPLANNEDBB7:%.*]]
; CHECK:       VPlannedBB7:
; CHECK-NEXT:    br label [[FINAL_MERGE:%.*]]
; CHECK:       final.merge:
; CHECK-NEXT:    [[UNI_PHI8:%.*]] = phi i32 [ [[TMP7]], [[VPLANNEDBB7]] ]
; CHECK-NEXT:    [[UNI_PHI9:%.*]] = phi i64 [ 1024, [[VPLANNEDBB7]] ]
; CHECK-NEXT:    br label [[FOR_END:%.*]]
;
  %min = alloca i32, align 4
  %1 = bitcast i32* %min to i8*
  store i32 2147483647, i32* %min, align 4
  br label %DIR.OMP.SIMD.1

DIR.OMP.SIMD.1:                                   ; preds = %0
  %tok = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.REDUCTION.MIN"(i32* %min) ]
  br label %DIR.QUAL.LIST.END.2

DIR.QUAL.LIST.END.2:                              ; preds = %DIR.OMP.SIMD.1
  %.pre = load i32, i32* %min, align 4
  br label %for.body

for.body:                                      ; preds = %6, %DIR.QUAL.LIST.END.2
  %Tmp = phi i32 [ %.pre, %DIR.QUAL.LIST.END.2 ], [ %Res, %for.inc ]
  %indvars.iv = phi i64 [ 0, %DIR.QUAL.LIST.END.2 ], [ %indvars.iv.next, %for.inc ]
  %arrayidx = getelementptr inbounds i32, i32* %ip, i64 %indvars.iv
  %Val = load i32, i32* %arrayidx, align 4
  %cmp1 = icmp sgt i32 %Tmp, %Val
  br i1 %cmp1, label %if.then, label %for.inc

if.then:                                      ; preds = %2
  store i32 %Val, i32* %min, align 4
  br label %for.inc

for.inc:                                      ; preds = %5, %2
  %Res = phi i32 [ %Val, %if.then ], [ %Tmp, %for.body ]
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %exitcond = icmp eq i64 %indvars.iv.next, 1024
  br i1 %exitcond, label %for.end, label %for.body

for.end:                                      ; preds = %6
  %.lcssa = phi i32 [ %Res, %for.inc ]
  br label %DIR.OMP.END.SIMD.3

DIR.OMP.END.SIMD.3:                               ; preds = %8
  call void @llvm.directive.region.exit(token %tok) [ "DIR.OMP.END.SIMD"() ]
  br label %DIR.QUAL.LIST.END.4

DIR.QUAL.LIST.END.4:                              ; preds = %DIR.OMP.END.SIMD.3
  ret i32 %.lcssa
}

declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)
