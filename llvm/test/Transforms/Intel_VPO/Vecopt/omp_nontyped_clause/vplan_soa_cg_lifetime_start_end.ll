; NOTE: Assertions have been autogenerated by utils/update_test_checks.py

; This test checks that the pointer-argument to lifetime.start/end intrinsics is
; correctly handled when we have it coming from either  a GEP or a bitcast instruction.
; RUN: opt -opaque-pointers=0 -passes=vplan-vec -vplan-force-vf=2 -vplan-enable-soa -S %s | FileCheck %s

define void @test_lifetime_start_end() {
; CHECK-LABEL: @test_lifetime_start_end(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ARR_PRIV8:%.*]] = alloca [1024 x i8], align 4
; CHECK-NEXT:    [[ARR_PRIV32:%.*]] = alloca [1024 x i32], align 4
; CHECK-NEXT:    [[ARR_PRIV32_SOA_VEC:%.*]] = alloca [1024 x <2 x i32>], align 8
; CHECK-NEXT:    [[ARR_PRIV8_SOA_VEC:%.*]] = alloca [1024 x <2 x i8>], align 2
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION:%.*]]
; CHECK:       simd.begin.region:
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER:%.*]]
; CHECK:       simd.loop.preheader:
; CHECK-NEXT:    [[UNI_GEP:%.*]] = getelementptr inbounds [1024 x i8], [1024 x i8]* [[ARR_PRIV8]], i64 0, i64 0
; CHECK-NEXT:    [[BC:%.*]] = bitcast [1024 x i32]* [[ARR_PRIV32]] to i8*
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]] to <2 x i8>*
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x i8>* [[TMP0]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8192, i8* [[TMP1]])
; CHECK-NEXT:    [[TMP2:%.*]] = bitcast [1024 x <2 x i8>]* [[ARR_PRIV8_SOA_VEC]] to <2 x i8>*
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <2 x i8>* [[TMP2]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 2048, i8* [[TMP3]])
; CHECK-NEXT:    [[SOA_SCALAR_GEP:%.*]] = getelementptr inbounds [1024 x <2 x i8>], [1024 x <2 x i8>]* [[ARR_PRIV8_SOA_VEC]], i64 0, i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]] to <2 x i8>*
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1]] ], [ [[TMP6:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <2 x i64> [ <i64 0, i64 1>, [[VPLANNEDBB1]] ], [ [[TMP5:%.*]], [[VECTOR_BODY]] ]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x i8>, <2 x i8>* [[SOA_SCALAR_GEP]], align 4
; CHECK-NEXT:    store <2 x i8> <i8 30, i8 30>, <2 x i8>* [[SOA_SCALAR_GEP]], align 1
; CHECK-NEXT:    [[SOA_SCALAR_GEP3:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]], i64 0, i64 0
; CHECK-NEXT:    [[WIDE_LOAD4:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP3]], align 4
; CHECK-NEXT:    store <2 x i32> <i32 30, i32 30>, <2 x i32>* [[SOA_SCALAR_GEP3]], align 4
; CHECK-NEXT:    [[TMP5]] = add nuw nsw <2 x i64> [[VEC_PHI]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP6]] = add nuw nsw i64 [[UNI_PHI]], 2
; CHECK-NEXT:    [[TMP7:%.*]] = icmp ult i64 [[TMP6]], 1024
; CHECK-NEXT:    br i1 [[TMP7]], label [[VECTOR_BODY]], label [[VPLANNEDBB5:%.*]], !llvm.loop [[LOOP0:![0-9]+]]
;
entry:
  %arr.priv8 = alloca [1024 x i8], align 4
  %arr.priv32 = alloca [1024 x i32], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i8]* %arr.priv8, [1024 x i32]* %arr.priv32)]
  br label %simd.loop.preheader

simd.loop.preheader:
  %uni.gep = getelementptr inbounds [1024 x i8], [1024 x i8]* %arr.priv8, i64 0, i64 0
  %bc = bitcast [1024 x i32]* %arr.priv32 to i8*
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %simd.loop]
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %uni.gep)
  call void @llvm.lifetime.start.p0i8(i64 4096, i8* nonnull %bc)
  %ld8 = load i8, i8* %uni.gep, align 4
  store i8 30, i8* %uni.gep

  ; load/store on i32 array.
  %uni.gep32 = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv32, i64 0, i64 0
  %ld32 = load i32, i32* %uni.gep32, align 4
  store i32 30, i32* %uni.gep32
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %uni.gep)
  call void @llvm.lifetime.end.p0i8(i64 4096, i8* nonnull %bc)
  br i1 %cmp, label %simd.loop, label %simd.end

simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

; This test simulates the behavior of AZB which inserts a region around
; bitcasts which are fed into the lifetime.start/end intrinsics and causes
; failure during CG. A utility function is changed to handle proper
; identification of Private memory.
define void @test_lifetime_start_end_with_phi_inputs() {
; CHECK-LABEL: @test_lifetime_start_end_with_phi_inputs(
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[ARR_PRIV32:%.*]] = alloca [1024 x i32], align 4
; CHECK-NEXT:    [[ARR_PRIV32_SOA_VEC:%.*]] = alloca [1024 x <2 x i32>], align 8
; CHECK-NEXT:    br label [[SIMD_BEGIN_REGION:%.*]]
; CHECK:       simd.begin.region:
; CHECK-NEXT:    br label [[SIMD_LOOP_PREHEADER:%.*]]
; CHECK:       simd.loop.preheader:
; CHECK-NEXT:    [[UNI_GEP:%.*]] = getelementptr inbounds [1024 x i32], [1024 x i32]* [[ARR_PRIV32]], i64 0, i64 0
; CHECK-NEXT:    br label [[VPLANNEDBB:%.*]]
; CHECK:       VPlannedBB:
; CHECK-NEXT:    br label [[VPLANNEDBB1:%.*]]
; CHECK:       VPlannedBB1:
; CHECK-NEXT:    [[TMP0:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]] to <2 x i8>*
; CHECK-NEXT:    [[TMP1:%.*]] = bitcast <2 x i8>* [[TMP0]] to i8*
; CHECK-NEXT:    call void @llvm.lifetime.start.p0i8(i64 8192, i8* [[TMP1]])
; CHECK-NEXT:    [[SOA_SCALAR_GEP:%.*]] = getelementptr inbounds [1024 x <2 x i32>], [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]], i64 0, i64 0
; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
; CHECK:       vector.body:
; CHECK-NEXT:    [[UNI_PHI:%.*]] = phi i64 [ 0, [[VPLANNEDBB1]] ], [ [[TMP15:%.*]], [[VPLANNEDBB14:%.*]] ]
; CHECK-NEXT:    [[VEC_PHI:%.*]] = phi <2 x i64> [ <i64 0, i64 1>, [[VPLANNEDBB1]] ], [ [[TMP14:%.*]], [[VPLANNEDBB14]] ]
; CHECK-NEXT:    [[WIDE_LOAD:%.*]] = load <2 x i32>, <2 x i32>* [[SOA_SCALAR_GEP]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq <2 x i64> [[VEC_PHI]], <i64 42, i64 42>
; CHECK-NEXT:    br label [[ALL_ZERO_BYPASS_BEGIN42:%.*]]
; CHECK:       all.zero.bypass.begin42:
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast <2 x i1> [[TMP2]] to i2
; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i2 [[TMP3]], 0
; CHECK-NEXT:    br i1 [[TMP4]], label [[ALL_ZERO_BYPASS_END44:%.*]], label [[VPLANNEDBB3:%.*]]
; CHECK:       VPlannedBB3:
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast [1024 x <2 x i32>]* [[ARR_PRIV32_SOA_VEC]] to <2 x i8>*
; CHECK-NEXT:    br label [[VPLANNEDBB4:%.*]]
; Ignore CHECKs for trivial inner loop
; CHECK:       all.zero.bypass.end44:
; CHECK-NEXT:    [[UNI_PHI11:%.*]] = phi <2 x i8>* [ [[TMP5]], [[VPLANNEDBB10:%.*]] ], [ null, [[ALL_ZERO_BYPASS_BEGIN42]] ]
; CHECK-NEXT:    br label [[VPLANNEDBB12:%.*]]
; CHECK:       VPlannedBB12:
; CHECK-NEXT:    [[TMP13:%.*]] = select <2 x i1> [[TMP2]], <2 x i1> <i1 true, i1 true>, <2 x i1> zeroinitializer
; CHECK-NEXT:    br label [[VPLANNEDBB13:%.*]]
; CHECK:       VPlannedBB13:
; CHECK-NEXT:    br label [[VPLANNEDBB14]]
; CHECK:       VPlannedBB14:
; CHECK-NEXT:    [[TMP14]] = add nuw nsw <2 x i64> [[VEC_PHI]], <i64 2, i64 2>
; CHECK-NEXT:    [[TMP15]] = add nuw nsw i64 [[UNI_PHI]], 2
; CHECK-NEXT:    [[TMP16:%.*]] = icmp ult i64 [[TMP15]], 1024
; CHECK-NEXT:    br i1 [[TMP16]], label [[VECTOR_BODY]], label [[VPLANNEDBB15:%.*]], !llvm.loop [[LOOP2:![0-9]+]]
;
entry:
  %arr.priv32 = alloca [1024 x i32], align 4
  br label %simd.begin.region

simd.begin.region:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.PRIVATE"([1024 x i32]* %arr.priv32)]
  br label %simd.loop.preheader

simd.loop.preheader:
  %uni.gep = getelementptr inbounds [1024 x i32], [1024 x i32]* %arr.priv32, i64 0, i64 0
  br label %simd.loop

simd.loop:
  %iv1 = phi i64 [ 0, %simd.loop.preheader ], [ %iv1.next, %inner.skip]
  %ld8 = load i32, i32* %uni.gep, align 4
  %div.cond = icmp eq i64 %iv1, 42
  br i1 %div.cond, label %inner.ph, label %inner.skip

inner.ph:
  %bc.if = bitcast [1024 x i32]* %arr.priv32 to i8*
  br label %inner.loop

inner.loop:
  %inner.iv = phi i64 [ 0, %inner.ph ], [ %inner.iv.next, %inner.loop ]
  %inner.iv.next = add nuw nsw i64 %inner.iv, 1
  %inner.cmp = icmp ult i64 %inner.iv.next, 125
  br i1 %inner.cmp, label %inner.loop, label %inner.exit

inner.exit:
  br label %lifetime.check.bb

lifetime.check.bb:
  br i1 true, label %lifetime.bb, label %inner.skip

lifetime.bb:
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %bc.if)
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %bc.if)
  br label %inner.skip

inner.skip:
  %iv1.next = add nuw nsw i64 %iv1, 1
  %cmp = icmp ult i64 %iv1.next, 1024
  br i1 %cmp, label %simd.loop, label %simd.end

simd.end:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}

declare void @llvm.lifetime.start.p0i8(i64, i8* nocapture)
declare void @llvm.lifetime.end.p0i8(i64, i8* nocapture)
declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token %0)
