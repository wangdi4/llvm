; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
; This test checks how we set the shapes of inner-loop PHIs.

target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"


;RUN: opt -vplan-vec -disable-output -vplan-dump-da %s 2>&1 | FileCheck %s


define void @kernel_init_gpu_incoming(i64 %ptr1, i64 %ptr2) {
;
; CHECK:       Printing Divergence info for Loop at depth 1 containing: [[BB0:BB[0-9]+]]<header>,[[BB1:BB[0-9]+]],[[BB2:BB[0-9]+]],[[BB3:BB[0-9]+]],[[BB4:BB[0-9]+]],[[BB5:BB[0-9]+]]<latch><exiting>
; CHECK-NEXT:      Loop at depth 2 containing: [[BB2]]<header><latch><exiting>
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB0]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i32 1] i32 [[VP_INDEX:%.*]] = phi  [ i32 [[VP_INDEX_IND_INIT:%.*]], [[BB6:BB[0-9]+]] ],  [ i32 [[VP_INDVAR:%.*]], [[BB5]] ]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i32 1] i64 [[VP_SEXT:%.*]] = sext i32 [[VP_INDEX]] to i64
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_ADD1:%.*]] = add i64 [[VP_SEXT]] i64 [[GLOBAL_IDJ00:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD2:%.*]] = add i64 8 i64 8
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD3:%.*]] = add i64 [[VP_ADD2]] i64 [[LOAD_150:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_ICMP1:%.*]] = icmp ugt i64 [[VP_ADD3]] i64 [[LOAD_160:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_SELECT:%.*]] = select i1 [[VP_ICMP1]] i64 [[LOAD_160]] i64 [[VP_ADD3]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_ICMP2:%.*]] = icmp ult i64 [[VP_ADD2]] i64 [[VP_SELECT]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_ICMP2]], [[BB1]], [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB1]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_ADD7:%.*]] = add i64 [[VP_ADD1]] i64 12
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB2]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_PHI2:%.*]] = phi  [ i64 [[VP_ADD7]], [[BB1]] ],  [ i64 [[VP_ADD_REC:%.*]], [[BB2]] ]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_ADD_REC]] = add i64 [[VP_PHI2]] i64 [[LOAD_150]]
; CHECK-NEXT:  Divergent: [Shape: Random] i1 [[VP_ICMP3:%.*]] = icmp ult i64 [[VP_ADD_REC]] i64 [[VP_SELECT]]
; CHECK-NEXT:  Divergent: [Shape: Random] br i1 [[VP_ICMP3]], [[BB2]], [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB3]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB4]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB5]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i32 [[VP_INDVAR]] = add i32 [[VP_INDEX]] i32 [[VP_INDEX_IND_INIT_STEP:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_VL_COND:%.*]] = icmp ult i32 [[VP_INDVAR]] i32 [[VP_VECTOR_TRIP_COUNT:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_VL_COND]], [[BB0]], [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB7]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i32 [[VP_INDEX_IND_FINAL:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB8:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB8]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br <External Block>
;
  %alloca.7 = alloca i64
  store i64 %ptr1, i64* %alloca.7
  %alloca.8 = alloca i64
  store i64 %ptr2, i64* %alloca.8
  %global_idj0 = call i64 @_Z13get_global_idj(i32 0)
  br label %simd.begin.region

simd.begin.region:                                ; preds = %0
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.UNIFORM"(i64* %alloca.7, i64* %alloca.8) ]
  br label %simd.loop.preheader

simd.loop.preheader:                              ; preds = %simd.begin.region
  %load.15 = load i64, i64* %alloca.7
  %load.16 = load i64, i64* %alloca.8
  br label %simd.loop

simd.loop:                                        ; preds = %simd.loop.exit, %simd.loop.preheader
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.exit ]
  %sext = sext i32 %index to i64
  %add1 = add nuw i64 %sext, %global_idj0
  %add2 = add i64 8, 8
  %add3 = add i64 %add2, %load.15
  %icmp1 = icmp ugt i64 %add3, %load.16
  %select = select i1 %icmp1, i64 %load.16, i64 %add3
  %icmp2 = icmp ult i64 %add2, %select
  br i1 %icmp2, label %BB2, label %loop-exit

BB2:                                              ; preds = %simd.loop
  %add7 = add i64 %add1, 12
  br label %BB1

BB1:                                              ; preds = %BB1, %BB2
  %phi2 = phi i64 [ %add7, %BB2 ], [ %add_rec, %BB1 ]
  %add_rec = add i64 %phi2, %load.15
  %icmp3 = icmp ult i64 %add_rec, %select
  br i1 %icmp3, label %BB1, label %loop-exit.loopexit

loop-exit.loopexit:                               ; preds = %BB1
  br label %loop-exit

loop-exit:                                        ; preds = %loop-exit.loopexit, %simd.loop
  br label %simd.loop.exit

simd.loop.exit:                                   ; preds = %loop-exit
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 16
  br i1 %vl.cond, label %simd.loop, label %simd.end.region

simd.end.region:                                  ; preds = %simd.loop.exit
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %return

return:                                           ; preds = %simd.end.region
  ret void
}

define void @kernel_init_gpu_closed_inner_loop(i64 %ptr1, i64 %ptr2) {
;
; CHECK:       Printing Divergence info for Loop at depth 1 containing: [[BB0:BB[0-9]+]]<header>,[[BB1:BB[0-9]+]],[[BB2:BB[0-9]+]],[[BB3:BB[0-9]+]],[[BB4:BB[0-9]+]],[[BB5:BB[0-9]+]]<latch><exiting>
; CHECK-NEXT:      Loop at depth 2 containing: [[BB2]]<header><latch><exiting>
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB0]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i32 1] i32 [[VP_INDEX:%.*]] = phi  [ i32 [[VP_INDEX_IND_INIT:%.*]], [[BB6:BB[0-9]+]] ],  [ i32 [[VP_INDVAR:%.*]], [[BB5]] ]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i32 1] i64 [[VP_SEXT:%.*]] = sext i32 [[VP_INDEX]] to i64
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_ADD1:%.*]] = add i64 [[VP_SEXT]] i64 [[GLOBAL_IDJ00:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD2:%.*]] = add i64 8 i64 8
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD3:%.*]] = add i64 [[VP_ADD2]] i64 [[LOAD_150:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_ICMP1:%.*]] = icmp ugt i64 [[VP_ADD3]] i64 [[LOAD_160:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_SELECT:%.*]] = select i1 [[VP_ICMP1]] i64 [[LOAD_160]] i64 [[VP_ADD3]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_ICMP2:%.*]] = icmp ult i64 [[VP_ADD2]] i64 [[VP_SELECT]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_ICMP2]], [[BB1]], [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB1]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP_ADD7:%.*]] = add i64 [[VP_ADD1]] i64 12
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_BC:%.*]] = bitcast i64 [[LOAD_150]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB2]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_PHI1:%.*]] = phi  [ i64 [[VP_BC]], [[BB1]] ],  [ i64 [[VP_ADD_REC1:%.*]], [[BB2]] ]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_PHI2:%.*]] = phi  [ i64 0, [[BB1]] ],  [ i64 [[VP_ADD_REC2:%.*]], [[BB2]] ]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD_REC1]] = add i64 [[VP_PHI1]] i64 [[LOAD_150]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i64 [[VP_ADD_REC2]] = add i64 [[VP_PHI2]] i64 [[LOAD_150]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_ICMP3:%.*]] = icmp ult i64 [[VP_ADD2]] i64 [[VP_SELECT]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_ICMP3]], [[BB2]], [[BB3]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB3]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB4]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB4]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB5]]
; CHECK-NEXT:  Divergent: [Shape: Unit Stride, Stride: i64 1] i32 [[VP_INDVAR]] = add i32 [[VP_INDEX]] i32 [[VP_INDEX_IND_INIT_STEP:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i1 [[VP_VL_COND:%.*]] = icmp ult i32 [[VP_INDVAR]] i32 [[VP_VECTOR_TRIP_COUNT:%.*]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br i1 [[VP_VL_COND]], [[BB0]], [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB7]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] i32 [[VP_INDEX_IND_FINAL:%.*]] = induction-final{add} i32 0 i32 1
; CHECK-NEXT:  Uniform: [Shape: Uniform] br [[BB8:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Basic Block: [[BB8]]
; CHECK-NEXT:  Uniform: [Shape: Uniform] br <External Block>
;
  %alloca.7 = alloca i64
  store i64 %ptr1, i64* %alloca.7
  %alloca.8 = alloca i64
  store i64 %ptr2, i64* %alloca.8
  %global_idj0 = call i64 @_Z13get_global_idj(i32 0)
  br label %simd.begin.region

simd.begin.region:                                ; preds = %0
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.UNIFORM"(i64* %alloca.7, i64* %alloca.8) ]
  br label %simd.loop.preheader

simd.loop.preheader:                              ; preds = %simd.begin.region
  %load.15 = load i64, i64* %alloca.7
  %load.16 = load i64, i64* %alloca.8
  br label %simd.loop

simd.loop:                                        ; preds = %simd.loop.exit, %simd.loop.preheader
  %index = phi i32 [ 0, %simd.loop.preheader ], [ %indvar, %simd.loop.exit ]
  %sext = sext i32 %index to i64
  %add1 = add nuw i64 %sext, %global_idj0
  %add2 = add i64 8, 8
  %add3 = add i64 %add2, %load.15
  %icmp1 = icmp ugt i64 %add3, %load.16
  %select = select i1 %icmp1, i64 %load.16, i64 %add3
  %icmp2 = icmp ult i64 %add2, %select
  br i1 %icmp2, label %BB2, label %loop-exit

BB2:                                              ; preds = %simd.loop
  %add7 = add i64 %add1, 12
  %bc = bitcast i64 %load.15 to i64
  br label %BB1

BB1:                                              ; preds = %BB1, %BB2
  %phi1 = phi i64 [ %bc, %BB2], [ %add_rec1, %BB1 ]
  %phi2 = phi i64 [ 0, %BB2 ], [ %add_rec2, %BB1 ]
  %add_rec1 = add i64 %phi1, %load.15
  %add_rec2 = add i64 %phi2, %load.15
  %icmp3 = icmp ult i64 %add2, %select
  br i1 %icmp3, label %BB1, label %loop-exit.loopexit

loop-exit.loopexit:                               ; preds = %BB1
  br label %loop-exit

loop-exit:                                        ; preds = %loop-exit.loopexit, %simd.loop
  br label %simd.loop.exit

simd.loop.exit:                                   ; preds = %loop-exit
  %indvar = add nuw i32 %index, 1
  %vl.cond = icmp ult i32 %indvar, 16
  br i1 %vl.cond, label %simd.loop, label %simd.end.region

simd.end.region:                                  ; preds = %simd.loop.exit
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  br label %return

return:                                           ; preds = %simd.end.region
  ret void
}


declare i64 @_Z13get_global_idj(i32)

; Function Attrs: nounwind
declare token @llvm.directive.region.entry()

; Function Attrs: nounwind
declare void @llvm.directive.region.exit(token)
