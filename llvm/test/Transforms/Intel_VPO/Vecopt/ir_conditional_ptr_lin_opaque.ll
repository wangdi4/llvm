; NOTE: Assertions have been autogenerated by utils/intel_update_vplan_checks.py
;
; Test for that induction which has updates under conditions is processed correctly
; (i.e. induction init/final are processed correctly).
; REQUIRES: asserts
; RUN: opt -opaque-pointers -vplan-vec -vplan-force-vf=2 -vplan-entities-dump -vplan-print-after-vpentity-instrs -vplan-dump-plan-da -S < %s 2>&1 | FileCheck %s
;
@x = dso_local global [10 x i32] zeroinitializer, align 16
define void @foo2(i64 %N) local_unnamed_addr #0 {
; CHECK-LABEL:  VPlan after insertion of VPEntities instructions:
; CHECK-NEXT:  VPlan IR for: foo2:for.body
; CHECK-NEXT:  Loop Entities of the loop with header [[BB0:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:  Induction list
; CHECK-NEXT:   IntInduction(+) Start: i64 1 Step: i64 1 StartVal: i64 1 EndVal: ? BinOp: i64 [[VP_INDVARS_IV_NEXT:%.*]] = add i64 [[VP_INDVARS_IV:%.*]] i64 1 need close form
; CHECK-NEXT:    Linked values: i64 [[VP_INDVARS_IV]], i64 [[VP_INDVARS_IV_NEXT]], i64 [[VP_INDVARS_IV_IND_INIT:%.*]], i64 [[VP_INDVARS_IV_IND_INIT_STEP:%.*]], i64 [[VP0:%.*]], i64 [[VP_INDVARS_IV_IND_FINAL:%.*]],
; CHECK-EMPTY:
; CHECK-NEXT:   PtrInduction(+) Start: ptr [[K_IV_B0:%.*]] Step: i64 16 StartVal: ? EndVal: ? BinOp: ptr [[VP_K_IV_NEXT:%.*]] = phi  [ ptr [[VP_K_IV_N1:%.*]], [[BB1:BB[0-9]+]] ],  [ ptr [[VP_K_IV_N2:%.*]], [[BB2:BB[0-9]+]] ] need close form
; CHECK-NEXT:    Linked values: ptr [[VP_K_IV:%.*]], ptr [[VP_K_IV_NEXT]], ptr [[VP_K_IV_IND_INIT:%.*]], i64 [[VP_K_IV_IND_INIT_STEP:%.*]], ptr [[VP1:%.*]], ptr [[VP_K_IV_IND_FINAL:%.*]],
; CHECK-EMPTY:
; CHECK-NEXT:   PtrInduction(+) Start: ptr [[K1_IV_B0:%.*]] Step: i64 4 StartVal: ? EndVal: ? BinOp: ptr [[VP_K1_IV_NEXT:%.*]] = phi  [ ptr [[VP_K1_IV_N1:%.*]], [[BB1:BB[0-9]+]] ],  [ ptr [[VP_K1_IV_N2:%.*]], [[BB2:BB[0-9]+]] ] need close form
; CHECK-NEXT:    Linked values: ptr [[VP_K1_IV:%.*]], ptr [[VP_K1_IV_NEXT]], ptr [[VP_K1_IV_IND_INIT:%.*]], i64 [[VP_K1_IV_IND_INIT_STEP:%.*]], ptr [[VP2:%.*]], ptr [[VP_K1_IV_IND_FINAL:%.*]],
; CHECK-EMPTY:
; CHECK-NEXT:   PtrInduction(+) Start: ptr [[VP_K2_LOAD0:%.*]] Step: i64 4 StartVal: ? EndVal: ? need close form
; CHECK-NEXT:    Linked values: ptr [[VP_K2_ALLOC_PRIV:%.*]], ptr [[VP_K2_IV_IND_INIT:%.*]], i64 [[VP_K2_IV_IND_INIT_STEP:%.*]], void [[VP_LV0:%.*]], ptr [[VP_K2_IV_IND_FINAL:%.*]],
; CHECK-NEXT:   Memory: ptr %k2
; CHECK:         [[BB3:BB[0-9]+]]: # preds:
; CHECK-NEXT:     br [[BB4:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB4]]: # preds: [[BB3]]
; CHECK-NEXT:     ptr [[VP_K2_ALLOC_PRIV]] = allocate-priv ptr, OrigAlign = 4
; CHECK-NEXT:     call i64 8 ptr [[VP_K2_ALLOC_PRIV]] ptr @llvm.lifetime.start.p0
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT]] = induction-init{add} i64 1 i64 1
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_INIT_STEP]] = induction-init-step{add} i64 1
; CHECK-NEXT:     ptr [[VP_K_IV_IND_INIT]] = induction-init{getelementptr} ptr [[K_IV_B0]] i64 16 
; CHECK-NEXT:     i64 [[VP_K_IV_IND_INIT_STEP]] = induction-init-step{getelementptr} i64 16
; CHECK-NEXT:     ptr [[VP_K1_IV_IND_INIT]] = induction-init{getelementptr} ptr [[K1_IV_B0]] i64 4
; CHECK-NEXT:     i64 [[VP_K1_IV_IND_INIT_STEP]] = induction-init-step{getelementptr} i64 4
; CHECK-NEXT:     ptr [[VP_K2_LOAD:%.*]] = load ptr %k2
; CHECK-NEXT:     ptr [[VP_K2_IV_IND_INIT]] = induction-init{getelementptr} ptr [[VP_K2_LOAD]] i64 4
; CHECK-NEXT:     store ptr [[VP_K2_IV_IND_INIT]] ptr [[VP_K2_ALLOC_PRIV]]
; CHECK-NEXT:     i64 [[VP_K2_IV_IND_INIT_STEP]] = induction-init-step{getelementptr} i64 4
; CHECK-NEXT:     br [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB0]]: # preds: [[BB4]], [[BB5:BB[0-9]+]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV]] = phi  [ i64 [[VP_INDVARS_IV_IND_INIT]], [[BB4]] ],  [ i64 [[VP0]], [[BB5]] ]
; CHECK-NEXT:     ptr [[VP_K_IV]] = phi  [ ptr [[VP_K_IV_IND_INIT]], [[BB4]] ],  [ ptr [[VP1]], [[BB5]] ]
; CHECK-NEXT:     ptr [[VP_K1_IV]] = phi  [ ptr [[VP_K1_IV_IND_INIT]], [[BB4]] ],  [ ptr [[VP2]], [[BB5]] ]
; CHECK-NEXT:     ptr [[VP_K2_IV:%.*]] = phi  [ ptr [[VP_K2_IV_IND_INIT]], [[BB4]] ],  [ ptr [[VP3:%.*]], [[BB5]] ]
; CHECK-NEXT:     store ptr [[VP_K2_IV]] ptr [[VP_K2_ALLOC_PRIV]]
; CHECK-NEXT:     ptr [[VP_K2_LOAD0]] = load ptr [[VP_K2_ALLOC_PRIV]]
; CHECK-NEXT:     i32 [[VP_K2_LOAD1:%.*]] = load ptr [[VP_K2_LOAD0]]
; CHECK-NEXT:     ptr [[VP_K2_GEP0:%.*]] = getelementptr inbounds [10 x i32], ptr @x i64 0 i64 [[VP_INDVARS_IV]]
; CHECK-NEXT:     store i32 [[VP_K2_LOAD1]] ptr [[VP_K2_GEP0]]
; CHECK-NEXT:     i64 [[VP0]] = add i64 [[VP_INDVARS_IV]] i64 [[VP_INDVARS_IV_IND_INIT_STEP]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_NEXT]] = add i64 [[VP_INDVARS_IV]] i64 1
; CHECK-NEXT:     i1 [[VP_EE:%.*]] = icmp eq i64 [[VP_INDVARS_IV_NEXT]] i64 43
; CHECK-NEXT:     br i1 [[VP_EE]], [[BB1]], [[BB2]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB2]]: # preds: [[BB0]]
; CHECK-NEXT:       ptr [[VP_K_IV_N2]] = getelementptr inbounds i64, ptr [[VP_K_IV]] i64 2
; CHECK-NEXT:       ptr [[VP_K1_IV_N2]] = getelementptr inbounds i32, ptr [[VP_K1_IV]] i64 1
; CHECK-NEXT:       br [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:      [[BB1]]: # preds: [[BB0]]
; CHECK-NEXT:       ptr [[VP_K_IV_N1]] = getelementptr inbounds i64, ptr [[VP_K_IV]] i64 2
; CHECK-NEXT:       ptr [[VP_K1_IV_N1]] = getelementptr inbounds i32, ptr [[VP_K1_IV]] i64 1
; CHECK-NEXT:       br [[BB5]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB5]]: # preds: [[BB2]], [[BB1]]
; CHECK-NEXT:     ptr [[VP_K_IV_NEXT]] = phi  [ ptr [[VP_K_IV_N1]], [[BB1]] ],  [ ptr [[VP_K_IV_N2]], [[BB2]] ]
; CHECK-NEXT:     ptr [[VP_K1_IV_NEXT]] = phi  [ ptr [[VP_K1_IV_N1]], [[BB1]] ],  [ ptr [[VP_K1_IV_N2]], [[BB2]] ]
; CHECK-NEXT:     ptr [[VP2]] = getelementptr inbounds i8, ptr [[VP_K1_IV]] i64 [[VP_K1_IV_IND_INIT_STEP]]
; CHECK-NEXT:     ptr [[VP1]] = getelementptr inbounds i8, ptr [[VP_K_IV]] i64 [[VP_K_IV_IND_INIT_STEP]]
; CHECK-NEXT:     i1 [[VP_EXITCOND:%.*]] = icmp eq i64 [[VP0]] i64 [[N0:%.*]]
; CHECK-NEXT:     ptr [[VP3]] = getelementptr inbounds i8, ptr [[VP_K2_IV]] i64 [[VP_K2_IV_IND_INIT_STEP]]
; CHECK-NEXT:     br i1 [[VP_EXITCOND]], [[BB6:BB[0-9]+]], [[BB0]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB6]]: # preds: [[BB5]]
; CHECK-NEXT:     i64 [[VP_INDVARS_IV_IND_FINAL]] = induction-final{add} i64 1 i64 1
; CHECK-NEXT:     ptr [[VP_K_IV_IND_FINAL]] = induction-final{getelementptr} ptr [[K_IV_B0]] i64 16
; CHECK-NEXT:     ptr [[VP_K1_IV_IND_FINAL]] = induction-final{getelementptr} ptr [[K1_IV_B0]] i64 4
; CHECK-NEXT:     ptr [[VP_K2_LOAD1:%.*]] = load ptr [[VP_K2_ALLOC_PRIV]] 
; CHECK-NEXT:     ptr [[VP_K2_IV_IND_FINAL]] = induction-final{getelementptr} ptr [[VP_K2_LOAD]] i64 4
; CHECK-NEXT:     store ptr [[VP_K2_IV_IND_FINAL]] ptr %k2
; CHECK-NEXT:     call i64 8 ptr [[VP_K2_ALLOC_PRIV]] ptr @llvm.lifetime.end.p0
; CHECK-NEXT:     br [[BB7:BB[0-9]+]]
; CHECK-EMPTY:
; CHECK-NEXT:    [[BB7]]: # preds: [[BB6]]
; CHECK-NEXT:     br <External Block>
; CHECK-EMPTY:
; CHECK-NEXT:  External Uses:
; CHECK-NEXT:  Id: 0     [[LCSSA_K0:%.*]] = phi ptr [ [[K_IV_NEXT0:%.*]], [[LATCH0:%.*]] ] ptr [[VP_K_IV_IND_FINAL]] -> ptr [[K_IV_NEXT0]]
; CHECK-EMPTY:
; CHECK-NEXT:  Id: 1     [[LCSSA_K1:%.*]] = phi ptr [ [[K1_IV_NEXT0:%.*]], [[LATCH0:%.*]] ] ptr [[VP_K1_IV_IND_FINAL]] -> ptr [[K1_IV_NEXT0]];
;
; CHECK: Printing Divergence info for foo2:for.body.#1
; CHECK-NEXT: Basic Block: [[BB7:BB[0-9]+]]
; CHECK-NEXT: Uniform: [Shape: Uniform] br [[BB1:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB1]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 8] ptr [[VP0_ALLOC_PRIV:%.*]] = allocate-priv ptr, OrigAlign = 4
; CHECK-NEXT: Divergent: [Shape: Random] call i64 8 ptr [[VP0_ALLOC_PRIV]] ptr @llvm.lifetime.start.p0
; CHECK-NEXT: Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP2_INIT:%.*]] = induction-init{add} i64 live-in2 i64 1
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP2_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 16] ptr [[VP3_INIT:%.*]] = induction-init{getelementptr} ptr live-in0 i64 16
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP3_STEP:%.*]] = induction-init-step{getelementptr} i64 16
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP4_INIT:%.*]] = induction-init{getelementptr} ptr live-in1 i64 4
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP4_STEP:%.*]] = induction-init-step{getelementptr} i64 4
; CHECK-NEXT: Uniform: [Shape: Uniform] ptr [[VP0_LOAD0:%.*]] = load ptr %k2
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP0_INIT:%.*]] = induction-init{getelementptr} ptr [[VP0_LOAD0]] i64 4
; CHECK-NEXT: Divergent: [Shape: Random] store ptr [[VP0_INIT]] ptr [[VP0_ALLOC_PRIV]]
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP0_STEP:%.*]] = induction-init-step{getelementptr} i64 4
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_IV_STEP:%.*]] = induction-init-step{add} i64 1
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_TC:%.*]] = orig-trip-count for original loop for.body
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_VEC_TC:%.*]] = vector-trip-count i64 [[VP_TC]], UF = 1
; CHECK-NEXT: Uniform: [Shape: Uniform] br [[BB2:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB2]]
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_IV_PHI:%.*]] = phi  [ i64 0, [[BB1:BB[0-9]+]] ],  [ i64 [[VP_IV_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT: Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP2_PHI:%.*]] = phi  [ i64 [[VP2_INIT]], [[BB1]] ],  [ i64 [[VP2_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 16] ptr [[VP3_PHI:%.*]] = phi  [ ptr [[VP3_INIT]], [[BB1]] ],  [ ptr [[VP3_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP4_PHI:%.*]] = phi  [ ptr [[VP4_INIT]], [[BB1]] ],  [ ptr [[VP4_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP0_PHI:%.*]] = phi  [ ptr [[VP0_INIT]], [[BB1]] ],  [ ptr [[VP0_NEXT:%.*]], [[BB5]] ]
; CHECK-NEXT: Divergent: [Shape: Random] store ptr [[VP0_PHI]] ptr [[VP0_ALLOC_PRIV]]
; CHECK-NEXT: Divergent: [Shape: Random] ptr [[VP0_LOAD1:%.*]] = load ptr [[VP0_ALLOC_PRIV]]
; CHECK-NEXT: Divergent: [Shape: Random] i32 [[VP0_LOAD2:%.*]] = load ptr [[VP0_LOAD1]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP0_GEP0:%.*]] = getelementptr inbounds [10 x i32], ptr @x i64 0 i64 [[VP2_PHI]]
; CHECK-NEXT: Divergent: [Shape: Random] store i32 [[VP0_LOAD2]] ptr [[VP0_GEP0]]
; CHECK-NEXT: Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP2_NEXT]] = add i64 [[VP2_PHI]] i64 [[VP2_STEP]]
; CHECK-NEXT: Divergent: [Shape: Unit Stride, Stride: i64 1] i64 [[VP2_INC:%.*]] = add i64 [[VP2_PHI]] i64 1
; CHECK-NEXT: Divergent: [Shape: Random] i1 [[VP2_CMP:%.*]] = icmp eq i64 [[VP2_INC]] i64 43
; CHECK-NEXT: Divergent: [Shape: Random] br i1 [[VP2_CMP]], [[BB3:BB[0-9]+]], [[BB4:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB4]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 16] ptr [[VP3_GEP0:%.*]] = getelementptr inbounds i64, ptr [[VP3_PHI]] i64 2
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP4_GEP0:%.*]] = getelementptr inbounds i32, ptr [[VP4_PHI]] i64 1
; CHECK-NEXT: Uniform: [Shape: Uniform] br [[BB5:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB3]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 16] ptr [[VP3_GEP1:%.*]] = getelementptr inbounds i64, ptr [[VP3_PHI]] i64 2
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP4_GEP1:%.*]] = getelementptr inbounds i32, ptr [[VP4_PHI]] i64 1
; CHECK-NEXT: Uniform: [Shape: Uniform] br [[BB5]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB5]]
; CHECK-NEXT: Divergent: [Shape: Random] ptr [[VP3_PHI1:%.*]] = phi  [ ptr [[VP3_GEP1]], [[BB3]] ],  [ ptr [[VP3_GEP0]], [[BB4]] ]
; CHECK-NEXT: Divergent: [Shape: Random] ptr [[VP4_PHI1:%.*]] = phi  [ ptr [[VP4_GEP1]], [[BB3]] ],  [ ptr [[VP4_GEP0]], [[BB4]] ]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP4_NEXT]] = getelementptr inbounds i8, ptr [[VP4_PHI]] i64 [[VP4_STEP]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 16] ptr [[VP3_NEXT]] = getelementptr inbounds i8, ptr [[VP3_PHI]] i64 [[VP3_STEP]]
; CHECK-NEXT: Divergent: [Shape: Strided, Stride: i64 4] ptr [[VP0_NEXT]] = getelementptr inbounds i8, ptr [[VP0_PHI]] i64 [[VP0_STEP]]
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_IV_NEXT]] = add i64 [[VP_IV_PHI]] i64 [[VP_IV_STEP]]
; CHECK-NEXT: Uniform: [Shape: Uniform] i1 [[VP_IV_CMP:%.*]] = icmp uge i64 [[VP_IV_NEXT]] i64 [[VP_VEC_TC]]
; CHECK-NEXT: Uniform: [Shape: Uniform] br i1 [[VP_IV_CMP]], [[BB6:BB[0-9]+]], [[BB7:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB6]]
; CHECK-NEXT: Uniform: [Shape: Uniform] i64 [[VP_IND0:%.*]] = induction-final{add} i64 1 i64 1
; CHECK-NEXT: Uniform: [Shape: Uniform] ptr [[VP_IND1:%.*]] = induction-final{getelementptr} ptr %k.iv.b i64 16
; CHECK-NEXT: Uniform: [Shape: Uniform] ptr [[VP_1_IND1:%.*]] = induction-final{getelementptr} ptr %k1.iv.b i64 4
; CHECK-NEXT: Divergent: [Shape: Random] ptr [[VP0_LOAD3:%.*]] = load ptr [[VP0_ALLOC_PRIV]]
; CHECK-NEXT: Uniform: [Shape: Uniform] ptr [[VP_2_IND1:%.*]] = induction-final{getelementptr} ptr [[VP0_LOAD0]] i64 4
; CHECK-NEXT: Uniform: [Shape: Uniform] store ptr [[VP_2_IND1]] ptr %k2
; CHECK-NEXT: Divergent: [Shape: Random] call i64 8 ptr [[VP0_ALLOC_PRIV]] ptr @llvm.lifetime.end.p0
; CHECK-NEXT: Uniform: [Shape: Uniform] br [[BB8:BB[0-9]+]]
; CHECK-EMPTY: 
; CHECK-NEXT: Basic Block: [[BB8]]
; CHECK-NEXT: Uniform: [Shape: Uniform] br <External Block>
;
; CHECK: define void @foo2(i64 [[N:%.*]]) local_unnamed_addr {
; CHECK-NEXT: entry:
; CHECK-NEXT:   [[VP_K:%.*]] = alloca ptr, align 4
; CHECK-NEXT:   [[VP_K1:%.*]] = alloca ptr, align 4
; CHECK-NEXT:   [[VP_K2:%.*]] = alloca ptr, align 4
; CHECK-NEXT:   store ptr null, ptr [[VP_K]], align 4
; CHECK-NEXT:   store ptr null, ptr [[VP_K1]], align 4
; CHECK-NEXT:   store ptr null, ptr [[VP_K2]], align 4
; CHECK-NEXT:   [[K2_VEC:%.*]] = alloca <2 x ptr>, align 16
; CHECK-NEXT:   [[K2_VEC_BASEADDR:%.*]] = getelementptr ptr, ptr [[K2_VEC]], <2 x i32> <i32 0, i32 1>
; CHECK-NEXT:   [[K2_VEC_BASEADDR_EXTRACT0:%.*]] = extractelement <2 x ptr> [[K2_VEC_BASEADDR]], i32 0
; CHECK-NEXT:   br label [[REG_ENTRY:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: reg.entry:                                        ; preds = %entry
; CHECK-NEXT:   br label [[FOR_BODY_LR_PH:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: for.body.lr.ph:                                   ; preds = %reg.entry
; CHECK-NEXT:   [[VP_K_IV_B:%.*]] = load ptr, ptr [[VP_K]], align 4
; CHECK-NEXT:   [[VP_K1_IV_B:%.*]] = load ptr, ptr [[VP_K1]], align 4
; CHECK-NEXT:   %0 = add i64 [[N]], -1
; CHECK-NEXT:   br label [[VPlannedBB:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB:                                       ; preds = %for.body.lr.ph
; CHECK-NEXT:   %1 = and i64 %0, 4294967294
; CHECK-NEXT:   %2 = icmp eq i64 0, %1
; CHECK-NEXT:   br i1 %2, label [[MERGE_BLK13:%.*]], label [[VPlannedBB1:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB1:                                      ; preds = %VPlannedBB
; CHECK-NEXT:   br label [[VPlannedBB2:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB2:                                      ; preds = %VPlannedBB1
; CHECK-NEXT:   call void @llvm.lifetime.start.p0(i64 16, ptr [[K2_VEC_BASEADDR_EXTRACT0]])
; CHECK-NEXT:   [[VP_K_IV_BIND_START_BCAST_SPLATINSERT:%.*]] = insertelement <2 x ptr> poison, ptr [[VP_K_IV_B]], i32 0
; CHECK-NEXT:   [[VP_K_IV_BIND_START_BCAST_SPLAT:%.*]] = shufflevector <2 x ptr> [[VP_K_IV_BIND_START_BCAST_SPLATINSERT:%.*]], <2 x ptr> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:   [[VP_VECTOR_GEP:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_K_IV_BIND_START_BCAST_SPLAT]], <2 x i64> <i64 0, i64 16>
; CHECK-NEXT:   [[VP_K1_IV_BIND_START_BCAST_SPLATINSERT:%.*]] = insertelement <2 x ptr> poison, ptr [[VP_K1_IV_B]], i32 0
; CHECK-NEXT:   [[VP_K1_IV_BIND_START_BCAST_SPLAT:%.*]] = shufflevector <2 x ptr> [[VP_K1_IV_BIND_START_BCAST_SPLATINSERT:%.*]], <2 x ptr> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:   [[VP_VECTOR_GEP3:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_K1_IV_BIND_START_BCAST_SPLAT]], <2 x i64> <i64 0, i64 4>
; CHECK-NEXT:   %3 = load ptr, ptr %k2, align 1
; CHECK-NEXT:   %4 = load ptr, ptr %k2, align 1
; CHECK-NEXT:   [[VP_IND_START_BCAST_SPLATINSERT:%.*]] = insertelement <2 x ptr> poison, ptr %3, i32 0
; CHECK-NEXT:   [[VP_IND_START_BCAST_SPLAT:%.*]] = shufflevector <2 x ptr> [[VP_IND_START_BCAST_SPLATINSERT]], <2 x ptr> poison, <2 x i32> zeroinitializer
; CHECK-NEXT:   [[VECTOR_GEP4:%.*]] = getelementptr inbounds i8, <2 x ptr> [[VP_IND_START_BCAST_SPLAT]], <2 x i64> <i64 0, i64 4>
; CHECK-NEXT:   store <2 x ptr> [[VECTOR_GEP4]], ptr [[K2_VEC]], align 1
; CHECK-NEXT:   %5 = and i64 %0, 4294967294
; CHECK-NEXT:   br label [[VECTOR_BODY:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: vector.body:                                      ; preds = %VPlannedBB18, %VPlannedBB2
; CHECK-NEXT:   [[VP_UNI_PHI:%.*]] = phi i64 [ 0, [[VPlannedBB2]] ], [ %11, [[VPlannedBB18:%.*]] ]
; CHECK-NEXT:   [[VP_UNI_PHI6:%.*]] = phi i64 [ 1, [[VPlannedBB2]] ], [ %7, [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_VEC_PHI:%.*]] = phi <2 x i64> [ <i64 1, i64 2>, [[VPlannedBB2]] ], [ %6, [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_UNI_PHI7:%.*]] = phi ptr [ [[VP_K_IV_B]], [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP21_EXTRACT0:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_VEC_PHI8:%.*]] = phi <2 x ptr> [ [[VP_VECTOR_GEP]], [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP21:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_UNI_PHI9:%.*]] = phi ptr [ [[VP_K1_IV_B]], [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP20_EXTRACT0:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_VEC_PHI10:%.*]] = phi <2 x ptr> [ [[VP_VECTOR_GEP3]], [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP20:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_UNI_PHI11:%.*]] = phi ptr [ %3, [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP22_EXTRACT0:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   [[VP_VEC_PHI12:%.*]] = phi <2 x ptr> [ [[VECTOR_GEP4]], [[VPlannedBB2]] ], [ [[VP_MM_VECTORGEP22:%.*]], [[VPlannedBB18]] ]
; CHECK-NEXT:   store <2 x ptr> [[VP_VEC_PHI12]], ptr [[K2_VEC]], align 1
; CHECK-NEXT:   [[WIDE_LOAD:%.*]] = load <2 x ptr>, ptr [[K2_VEC]], align 4
; CHECK-NEXT:   [[WIDE_MASKED_GATHER:%.*]] = call <2 x i32> @llvm.masked.gather.v2i32.v2p0(<2 x ptr> [[WIDE_LOAD]], i32 4, <2 x i1> <i1 true, i1 true>, <2 x i32> undef)
; CHECK-NEXT:   [[SCALAR_GEP:%.*]] = getelementptr inbounds [10 x i32], ptr @x, i64 0, i64 [[VP_UNI_PHI6]]
; CHECK-NEXT:   store <2 x i32> [[WIDE_MASKED_GATHER]], ptr [[SCALAR_GEP]], align 8
; CHECK-NEXT:   %6 = add <2 x i64> [[VP_VEC_PHI]], <i64 2, i64 2>
; CHECK-NEXT:   %7 = add i64 [[VP_UNI_PHI6]], 2
; CHECK-NEXT:   %8 = add nuw nsw <2 x i64> [[VP_VEC_PHI]], <i64 1, i64 1>
; CHECK-NEXT:   %9 = icmp eq <2 x i64> %8, <i64 43, i64 43>
; CHECK-NEXT:   %10 = xor <2 x i1> %9, <i1 true, i1 true>
; CHECK-NEXT:   br label [[VPlannedBB13:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB13:                                      ; preds = %vector.body
; CHECK-NEXT:   [[VP_MM_VECTORGEP:%.*]] = getelementptr inbounds i64, <2 x ptr> [[VP_VEC_PHI8]], <2 x i64> <i64 2, i64 2>
; CHECK-NEXT:   [[VP_MM_VECTORGEP14:%.*]] = getelementptr inbounds i32, <2 x ptr> [[VP_VEC_PHI10]], <2 x i64> <i64 1, i64 1>
; CHECK-NEXT:   br label [[VPlannedBB15:%.*]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB15:                                      ; preds = %VPlannedBB13
; CHECK-NEXT:   [[VP_MM_VECTORGEP16:%.*]] = getelementptr inbounds i64, <2 x ptr> [[VP_VEC_PHI8]], <2 x i64> <i64 2, i64 2>
; CHECK-NEXT:   [[VP_MM_VECTORGEP17:%.*]] = getelementptr inbounds i32, <2 x ptr> [[VP_VEC_PHI10]], <2 x i64> <i64 1, i64 1>
; CHECK-NEXT:   br label [[VPlannedBB18]]
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB18:                                     ; preds = %VPlannedBB15
; CHECK-NEXT:   %predblend = select <2 x i1> %9, <2 x ptr> [[VP_MM_VECTORGEP16]], <2 x ptr> [[VP_MM_VECTORGEP]]
; CHECK-NEXT:   %predblend19 = select <2 x i1> %9, <2 x ptr> [[VP_MM_VECTORGEP17]], <2 x ptr> [[VP_MM_VECTORGEP14]]
; CHECK-NEXT:   [[VP_MM_VECTORGEP20]] = getelementptr inbounds i8, <2 x ptr> [[VP_VEC_PHI10]], <2 x i64> <i64 8, i64 8>
; CHECK-NEXT:   [[VP_MM_VECTORGEP20_EXTRACT0]] = extractelement <2 x ptr> [[VP_MM_VECTORGEP20]], i32 0
; CHECK-NEXT:   [[VP_MM_VECTORGEP21]] = getelementptr inbounds i8, <2 x ptr> [[VP_VEC_PHI8]], <2 x i64> <i64 32, i64 32>
; CHECK-NEXT:   [[VP_MM_VECTORGEP21_EXTRACT0]] = extractelement <2 x ptr> [[VP_MM_VECTORGEP21]], i32 0
; CHECK-NEXT:   [[VP_MM_VECTORGEP22]] = getelementptr inbounds i8, <2 x ptr> [[VP_VEC_PHI12]], <2 x i64> <i64 8, i64 8>
; CHECK-NEXT:   [[VP_MM_VECTORGEP22_EXTRACT0]] = extractelement <2 x ptr> [[VP_MM_VECTORGEP22]], i32 0
; CHECK-NEXT:   %11 = add i64 [[VP_UNI_PHI]], 2
; CHECK-NEXT:   %12 = icmp uge i64 %11, %5
; CHECK-NEXT:   br i1 %12, label [[VPlannedBB23:%.*]], label [[VECTOR_BODY]], !llvm.loop !0
; CHECK-EMPTY: 
; CHECK-NEXT: VPlannedBB23:                                     ; preds = %VPlannedBB18
; CHECK-NEXT:   %13 = mul i64 1, %5
; CHECK-NEXT:   %14 = add i64 1, %13
; CHECK-NEXT:   %15 = mul i64 16, %5
; CHECK-NEXT:   [[VP_FINAL_GEP:%.*]] = getelementptr inbounds i8, ptr [[VP_K_IV_B]], i64 %15
; CHECK-NEXT:   %16 = mul i64 4, %5
; CHECK-NEXT:   [[VP_FINAL_GEP24:%.*]] = getelementptr inbounds i8, ptr [[VP_K1_IV_B]], i64 %16
; CHECK-NEXT:   [[WIDE_LOAD25:%.*]] = load <2 x ptr>, ptr [[K2_VEC]], align 1
; CHECK-NEXT:   %17 = mul i64 4, %5
; CHECK-NEXT:   [[FINAL_GEP26:%.*]] = getelementptr inbounds i8, ptr %3, i64 %17
; CHECK-NEXT:   store ptr [[FINAL_GEP26]], ptr %k2, align 1
; CHECK-NEXT:   call void @llvm.lifetime.end.p0(i64 16, ptr [[K2_VEC_BASEADDR_EXTRACT0]])
; CHECK-NEXT:   br label [[VPlannedBB27:%.*]]
;
entry:
  %k = alloca ptr, align 4
  %k1 = alloca ptr, align 4
  %k2 = alloca ptr, align 4
  store ptr null, ptr %k, align 4
  store ptr null, ptr %k1, align 4
  store ptr null, ptr %k2, align 4
  br label %reg.entry

reg.entry:
  %entry.region = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(ptr %k, i64 0, i64 1, i64 2), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(ptr %k1, i32 0, i64 1, i64 1), "QUAL.OMP.LINEAR:PTR_TO_PTR.TYPED"(ptr %k2, i32 0, i64 1, i64 1) ]
  br label %for.body.lr.ph

for.body.lr.ph:
  %k.iv.b = load ptr, ptr %k, align 4
  %k1.iv.b = load ptr, ptr %k1, align 4
  br label %for.body

for.body:
  %indvars.iv = phi i64 [ 1, %for.body.lr.ph ], [ %indvars.iv.next, %latch ]
  %k.iv = phi ptr [ %k.iv.b, %for.body.lr.ph ], [ %k.iv.next, %latch ]
  %k1.iv = phi ptr [ %k1.iv.b, %for.body.lr.ph ], [ %k1.iv.next, %latch ]
  %k2load = load i32*, i32** %k2, align 4
  %k2val = load i32, i32* %k2load, align 4
  %x.ptr = getelementptr inbounds [10 x i32], [10 x i32]* @x, i64 0, i64 %indvars.iv
  store i32 %k2val, i32* %x.ptr, align 4
  %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
  %ee = icmp eq i64 %indvars.iv.next, 43
  br i1 %ee, label %then, label %else

then:
  %k.iv.n1 = getelementptr inbounds i64, ptr %k.iv, i64 2
  %k1.iv.n1 = getelementptr inbounds i32, ptr %k1.iv, i64 1
  br label %latch
else:
  %k.iv.n2 = getelementptr inbounds i64, ptr %k.iv, i64 2
  %k1.iv.n2 = getelementptr inbounds i32, ptr %k1.iv, i64 1
  br label %latch

latch:
  %k.iv.next = phi ptr [%k.iv.n1, %then ], [%k.iv.n2, %else ]
  %k1.iv.next = phi ptr [%k1.iv.n1, %then ], [%k1.iv.n2, %else ]
  %exitcond = icmp eq i64 %indvars.iv.next, %N
  br i1 %exitcond, label %for.cond.cleanup.loopexit, label %for.body

for.cond.cleanup.loopexit:
  %lcssa.k = phi ptr [%k.iv.next, %latch]
  %lcssa.k1 = phi ptr [%k1.iv.next, %latch]
  br label %for.cond.cleanup

for.cond.cleanup:
  call void @llvm.directive.region.exit(token %entry.region) [ "DIR.OMP.END.SIMD"() ]
  ret void
}
declare token @llvm.directive.region.entry()
declare void @llvm.directive.region.exit(token)

