; RUN: opt < %s -addsub-reassoc -S | FileCheck %s

; #1
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #2
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #3
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #4
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #5
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #6
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #7
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]
; #8
; CHECK: [[Chain_T24_187:%.*]] = sub i32 [[l44:%.*]], [[l28:%.*]]
; CHECK-NEXT: [[Chain_T24_185:%.*]] = sub i32 [[Chain_T24_187]]
; CHECK-NEXT: [[Chain1_3:%.*]] = add i32 [[Chain_T24_185]]
; CHECK-NEXT: [[Chain_T24_174178:%.*]] = sub i32 [[l45:%.*]], [[l29:%.*]]
; CHECK-NEXT: [[Chain_T24_173177:%.*]] = sub i32 [[Chain_T24_174178]]
; CHECK-NEXT: [[Chain2_3:%.*]] = add i32 [[Chain_T24_173177]]
; CHECK-NEXT: [[Chain_T24_162166:%.*]] = sub i32 [[l46:%.*]], [[l30:%.*]]
; CHECK-NEXT: [[Chain_T24_161165:%.*]] = sub i32 [[Chain_T24_162166]]
; CHECK-NEXT: [[Chain3_3:%.*]] = add i32 [[Chain_T24_161165]]
; CHECK-NEXT: [[Chain_T24_158:%.*]] = sub i32 [[l47:%.*]], [[l31:%.*]]
; CHECK-NEXT: [[Chain_T24_156:%.*]] = sub i32 [[Chain_T24_158]]
; CHECK-NEXT: [[Chain4_3:%.*]] = add i32 [[Chain_T24_156]]
; CHECK-NEXT: [[Bridge1_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge1_2:%.*]] = add i32 [[Bridge1_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge1_3:%.*]] = add i32 [[Bridge1_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge1_3]]
; CHECK: [[Bridge2_1:%.*]] = add i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge2_2:%.*]] = sub i32 [[Bridge2_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge2_3:%.*]] = sub i32 [[Bridge2_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge2_3]]
; CHECK: [[Bridge3_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge3_2:%.*]] = add i32 [[Bridge3_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge3_3:%.*]] = sub i32 [[Bridge3_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge3_3]]
; CHECK: [[Bridge4_1:%.*]] = sub i32 [[Chain4_3]], [[Chain3_3]]
; CHECK-NEXT: [[Bridge4_2:%.*]] = sub i32 [[Bridge4_1]], [[Chain2_3]]
; CHECK-NEXT: [[Bridge4_3:%.*]] = add i32 [[Bridge4_2]], [[Chain1_3]]
; CHECK-NEXT: store i32 [[Bridge4_3]]

; Function Attrs: nounwind readonly uwtable
define dso_local i32 @x264_pixel_satd_8x8(i8* nocapture readonly %pix1, i32 %i_pix1, i8* nocapture readonly %pix2, i32 %i_pix2) #2 {
entry:
  %idx.ext.i = sext i32 %i_pix1 to i64
  %idx.ext63.i = sext i32 %i_pix2 to i64
  %alloca = alloca [8 x [4 x i32]], align 4
  %gepload = load i8, i8* %pix1, align 1, !tbaa !21
  %gepload154 = load i8, i8* %pix2, align 1, !tbaa !21
  %arrayIdx = getelementptr inbounds i8, i8* %pix1, i64 4
  %gepload155 = load i8, i8* %arrayIdx, align 1, !tbaa !21
  %arrayIdx156 = getelementptr inbounds i8, i8* %pix2, i64 4
  %gepload157 = load i8, i8* %arrayIdx156, align 1, !tbaa !21
  %arrayIdx158 = getelementptr inbounds i8, i8* %pix1, i64 1
  %gepload159 = load i8, i8* %arrayIdx158, align 1, !tbaa !21
  %arrayIdx160 = getelementptr inbounds i8, i8* %pix2, i64 1
  %gepload161 = load i8, i8* %arrayIdx160, align 1, !tbaa !21
  %arrayIdx162 = getelementptr inbounds i8, i8* %pix1, i64 5
  %gepload163 = load i8, i8* %arrayIdx162, align 1, !tbaa !21
  %arrayIdx164 = getelementptr inbounds i8, i8* %pix2, i64 5
  %gepload165 = load i8, i8* %arrayIdx164, align 1, !tbaa !21
  %arrayIdx166 = getelementptr inbounds i8, i8* %pix1, i64 2
  %gepload167 = load i8, i8* %arrayIdx166, align 1, !tbaa !21
  %arrayIdx168 = getelementptr inbounds i8, i8* %pix2, i64 2
  %gepload169 = load i8, i8* %arrayIdx168, align 1, !tbaa !21
  %arrayIdx170 = getelementptr inbounds i8, i8* %pix1, i64 6
  %gepload171 = load i8, i8* %arrayIdx170, align 1, !tbaa !21
  %arrayIdx172 = getelementptr inbounds i8, i8* %pix2, i64 6
  %gepload173 = load i8, i8* %arrayIdx172, align 1, !tbaa !21
  %arrayIdx174 = getelementptr inbounds i8, i8* %pix1, i64 3
  %gepload175 = load i8, i8* %arrayIdx174, align 1, !tbaa !21
  %arrayIdx176 = getelementptr inbounds i8, i8* %pix2, i64 3
  %gepload177 = load i8, i8* %arrayIdx176, align 1, !tbaa !21
  %arrayIdx178 = getelementptr inbounds i8, i8* %pix1, i64 7
  %gepload179 = load i8, i8* %arrayIdx178, align 1, !tbaa !21
  %arrayIdx180 = getelementptr inbounds i8, i8* %pix2, i64 7
  %gepload181 = load i8, i8* %arrayIdx180, align 1, !tbaa !21
  %arrayIdx182 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 0, i64 0
  %0 = zext i8 %gepload175 to i32
  %1 = zext i8 %gepload167 to i32
  %2 = add nuw nsw i32 %0, %1
  %3 = zext i8 %gepload159 to i32
  %4 = add nuw nsw i32 %2, %3
  %5 = zext i8 %gepload to i32
  %6 = add nuw nsw i32 %4, %5
  %7 = zext i8 %gepload179 to i32
  %8 = shl nuw nsw i32 %7, 16
  %9 = or i32 %6, %8
  %10 = zext i8 %gepload171 to i32
  %11 = shl nuw nsw i32 %10, 16
  %12 = add nuw nsw i32 %9, %11
  %13 = zext i8 %gepload163 to i32
  %14 = shl nuw nsw i32 %13, 16
  %15 = add nuw nsw i32 %12, %14
  %16 = zext i8 %gepload155 to i32
  %17 = shl nuw nsw i32 %16, 16
  %18 = add i32 %15, %17
  %19 = zext i8 %gepload181 to i32
  %20 = shl nuw nsw i32 %19, 16
  %21 = sub i32 %18, %20
  %22 = zext i8 %gepload173 to i32
  %23 = shl nuw nsw i32 %22, 16
  %24 = sub i32 %21, %23
  %25 = zext i8 %gepload165 to i32
  %26 = shl nuw nsw i32 %25, 16
  %27 = sub i32 %24, %26
  %28 = zext i8 %gepload157 to i32
  %29 = shl nuw nsw i32 %28, 16
  %30 = sub i32 %27, %29
  %31 = zext i8 %gepload177 to i32
  %32 = sub i32 %30, %31
  %33 = zext i8 %gepload169 to i32
  %34 = sub i32 %32, %33
  %35 = zext i8 %gepload161 to i32
  %36 = sub i32 %34, %35
  %37 = zext i8 %gepload154 to i32
  %38 = sub i32 %36, %37
  store i32 %38, i32* %arrayIdx182, align 4
  %arrayIdx184 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 0, i64 2
  %39 = add nuw nsw i32 %0, %1
  %40 = sub nsw i32 %3, %39
  %41 = add nsw i32 %40, %5
  %42 = sub nsw i32 %41, %8
  %43 = sub nsw i32 %42, %11
  %44 = add nsw i32 %43, %14
  %45 = add i32 %44, %17
  %46 = add i32 %45, %20
  %47 = add i32 %46, %23
  %48 = sub i32 %47, %26
  %49 = sub i32 %48, %29
  %50 = add i32 %49, %31
  %51 = add i32 %50, %33
  %52 = sub i32 %51, %35
  %53 = sub i32 %52, %37
  store i32 %53, i32* %arrayIdx184, align 4
  %arrayIdx202 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 0, i64 1
  %54 = sub nsw i32 %1, %0
  %55 = sub nsw i32 %54, %3
  %56 = add nsw i32 %55, %5
  %57 = sub nsw i32 %56, %8
  %58 = add nsw i32 %57, %11
  %59 = sub nsw i32 %58, %14
  %60 = add i32 %59, %17
  %61 = add i32 %60, %20
  %62 = sub i32 %61, %23
  %63 = add i32 %62, %26
  %64 = sub i32 %63, %29
  %65 = add i32 %64, %31
  %66 = sub i32 %65, %33
  %67 = add i32 %66, %35
  %68 = sub i32 %67, %37
  store i32 %68, i32* %arrayIdx202, align 4
  %arrayIdx220 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 0, i64 3
  %69 = sub nsw i32 %0, %1
  %70 = sub nsw i32 %69, %3
  %71 = add nsw i32 %70, %5
  %72 = add nsw i32 %71, %8
  %73 = sub nsw i32 %72, %11
  %74 = sub nsw i32 %73, %14
  %75 = add i32 %74, %17
  %76 = sub i32 %75, %20
  %77 = add i32 %76, %23
  %78 = add i32 %77, %26
  %79 = sub i32 %78, %29
  %80 = sub i32 %79, %31
  %81 = add i32 %80, %33
  %82 = add i32 %81, %35
  %83 = sub i32 %82, %37
  store i32 %83, i32* %arrayIdx220, align 4
  %arrayIdx237 = getelementptr inbounds i8, i8* %pix1, i64 %idx.ext.i
  %gepload238 = load i8, i8* %arrayIdx237, align 1, !tbaa !21
  %arrayIdx239 = getelementptr inbounds i8, i8* %pix2, i64 %idx.ext63.i
  %gepload240 = load i8, i8* %arrayIdx239, align 1, !tbaa !21
  %84 = add nsw i64 %idx.ext.i, 4
  %arrayIdx241 = getelementptr inbounds i8, i8* %pix1, i64 %84
  %gepload242 = load i8, i8* %arrayIdx241, align 1, !tbaa !21
  %85 = add nsw i64 %idx.ext63.i, 4
  %arrayIdx243 = getelementptr inbounds i8, i8* %pix2, i64 %85
  %gepload244 = load i8, i8* %arrayIdx243, align 1, !tbaa !21
  %86 = add nsw i64 %idx.ext.i, 1
  %arrayIdx245 = getelementptr inbounds i8, i8* %pix1, i64 %86
  %gepload246 = load i8, i8* %arrayIdx245, align 1, !tbaa !21
  %87 = add nsw i64 %idx.ext63.i, 1
  %arrayIdx247 = getelementptr inbounds i8, i8* %pix2, i64 %87
  %gepload248 = load i8, i8* %arrayIdx247, align 1, !tbaa !21
  %88 = add nsw i64 %idx.ext.i, 5
  %arrayIdx249 = getelementptr inbounds i8, i8* %pix1, i64 %88
  %gepload250 = load i8, i8* %arrayIdx249, align 1, !tbaa !21
  %89 = add nsw i64 %idx.ext63.i, 5
  %arrayIdx251 = getelementptr inbounds i8, i8* %pix2, i64 %89
  %gepload252 = load i8, i8* %arrayIdx251, align 1, !tbaa !21
  %90 = add nsw i64 %idx.ext.i, 2
  %arrayIdx253 = getelementptr inbounds i8, i8* %pix1, i64 %90
  %gepload254 = load i8, i8* %arrayIdx253, align 1, !tbaa !21
  %91 = add nsw i64 %idx.ext63.i, 2
  %arrayIdx255 = getelementptr inbounds i8, i8* %pix2, i64 %91
  %gepload256 = load i8, i8* %arrayIdx255, align 1, !tbaa !21
  %92 = add nsw i64 %idx.ext.i, 6
  %arrayIdx257 = getelementptr inbounds i8, i8* %pix1, i64 %92
  %gepload258 = load i8, i8* %arrayIdx257, align 1, !tbaa !21
  %93 = add nsw i64 %idx.ext63.i, 6
  %arrayIdx259 = getelementptr inbounds i8, i8* %pix2, i64 %93
  %gepload260 = load i8, i8* %arrayIdx259, align 1, !tbaa !21
  %94 = add nsw i64 %idx.ext.i, 3
  %arrayIdx261 = getelementptr inbounds i8, i8* %pix1, i64 %94
  %gepload262 = load i8, i8* %arrayIdx261, align 1, !tbaa !21
  %95 = add nsw i64 %idx.ext63.i, 3
  %arrayIdx263 = getelementptr inbounds i8, i8* %pix2, i64 %95
  %gepload264 = load i8, i8* %arrayIdx263, align 1, !tbaa !21
  %96 = add nsw i64 %idx.ext.i, 7
  %arrayIdx265 = getelementptr inbounds i8, i8* %pix1, i64 %96
  %gepload266 = load i8, i8* %arrayIdx265, align 1, !tbaa !21
  %97 = add nsw i64 %idx.ext63.i, 7
  %arrayIdx267 = getelementptr inbounds i8, i8* %pix2, i64 %97
  %gepload268 = load i8, i8* %arrayIdx267, align 1, !tbaa !21
  %arrayIdx270 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 1, i64 0
  %98 = zext i8 %gepload262 to i32
  %99 = zext i8 %gepload254 to i32
  %100 = add nuw nsw i32 %98, %99
  %101 = zext i8 %gepload246 to i32
  %102 = add nuw nsw i32 %100, %101
  %103 = zext i8 %gepload238 to i32
  %104 = add nuw nsw i32 %102, %103
  %105 = zext i8 %gepload266 to i32
  %106 = shl nuw nsw i32 %105, 16
  %107 = or i32 %104, %106
  %108 = zext i8 %gepload258 to i32
  %109 = shl nuw nsw i32 %108, 16
  %110 = add nuw nsw i32 %107, %109
  %111 = zext i8 %gepload250 to i32
  %112 = shl nuw nsw i32 %111, 16
  %113 = add nuw nsw i32 %110, %112
  %114 = zext i8 %gepload242 to i32
  %115 = shl nuw nsw i32 %114, 16
  %116 = add i32 %113, %115
  %117 = zext i8 %gepload268 to i32
  %118 = shl nuw nsw i32 %117, 16
  %119 = sub i32 %116, %118
  %120 = zext i8 %gepload260 to i32
  %121 = shl nuw nsw i32 %120, 16
  %122 = sub i32 %119, %121
  %123 = zext i8 %gepload252 to i32
  %124 = shl nuw nsw i32 %123, 16
  %125 = sub i32 %122, %124
  %126 = zext i8 %gepload244 to i32
  %127 = shl nuw nsw i32 %126, 16
  %128 = sub i32 %125, %127
  %129 = zext i8 %gepload264 to i32
  %130 = sub i32 %128, %129
  %131 = zext i8 %gepload256 to i32
  %132 = sub i32 %130, %131
  %133 = zext i8 %gepload248 to i32
  %134 = sub i32 %132, %133
  %135 = zext i8 %gepload240 to i32
  %136 = sub i32 %134, %135
  store i32 %136, i32* %arrayIdx270, align 4
  %arrayIdx288 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 1, i64 2
  %137 = add nuw nsw i32 %98, %99
  %138 = sub nsw i32 %101, %137
  %139 = add nsw i32 %138, %103
  %140 = sub nsw i32 %139, %106
  %141 = sub nsw i32 %140, %109
  %142 = add nsw i32 %141, %112
  %143 = add i32 %142, %115
  %144 = add i32 %143, %118
  %145 = add i32 %144, %121
  %146 = sub i32 %145, %124
  %147 = sub i32 %146, %127
  %148 = add i32 %147, %129
  %149 = add i32 %148, %131
  %150 = sub i32 %149, %133
  %151 = sub i32 %150, %135
  store i32 %151, i32* %arrayIdx288, align 4
  %arrayIdx306 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 1, i64 1
  %152 = sub nsw i32 %99, %98
  %153 = sub nsw i32 %152, %101
  %154 = add nsw i32 %153, %103
  %155 = sub nsw i32 %154, %106
  %156 = add nsw i32 %155, %109
  %157 = sub nsw i32 %156, %112
  %158 = add i32 %157, %115
  %159 = add i32 %158, %118
  %160 = sub i32 %159, %121
  %161 = add i32 %160, %124
  %162 = sub i32 %161, %127
  %163 = add i32 %162, %129
  %164 = sub i32 %163, %131
  %165 = add i32 %164, %133
  %166 = sub i32 %165, %135
  store i32 %166, i32* %arrayIdx306, align 4
  %arrayIdx324 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 1, i64 3
  %167 = sub nsw i32 %98, %99
  %168 = sub nsw i32 %167, %101
  %169 = add nsw i32 %168, %103
  %170 = add nsw i32 %169, %106
  %171 = sub nsw i32 %170, %109
  %172 = sub nsw i32 %171, %112
  %173 = add i32 %172, %115
  %174 = sub i32 %173, %118
  %175 = add i32 %174, %121
  %176 = add i32 %175, %124
  %177 = sub i32 %176, %127
  %178 = sub i32 %177, %129
  %179 = add i32 %178, %131
  %180 = add i32 %179, %133
  %181 = sub i32 %180, %135
  store i32 %181, i32* %arrayIdx324, align 4
  %182 = shl nsw i64 %idx.ext.i, 1
  %arrayIdx341 = getelementptr inbounds i8, i8* %pix1, i64 %182
  %gepload342 = load i8, i8* %arrayIdx341, align 1, !tbaa !21
  %183 = shl nsw i64 %idx.ext63.i, 1
  %arrayIdx343 = getelementptr inbounds i8, i8* %pix2, i64 %183
  %gepload344 = load i8, i8* %arrayIdx343, align 1, !tbaa !21
  %184 = add nsw i64 %182, 4
  %arrayIdx345 = getelementptr inbounds i8, i8* %pix1, i64 %184
  %gepload346 = load i8, i8* %arrayIdx345, align 1, !tbaa !21
  %185 = add nsw i64 %183, 4
  %arrayIdx347 = getelementptr inbounds i8, i8* %pix2, i64 %185
  %gepload348 = load i8, i8* %arrayIdx347, align 1, !tbaa !21
  %186 = or i64 %182, 1
  %arrayIdx349 = getelementptr inbounds i8, i8* %pix1, i64 %186
  %gepload350 = load i8, i8* %arrayIdx349, align 1, !tbaa !21
  %187 = or i64 %183, 1
  %arrayIdx351 = getelementptr inbounds i8, i8* %pix2, i64 %187
  %gepload352 = load i8, i8* %arrayIdx351, align 1, !tbaa !21
  %188 = add nsw i64 %182, 5
  %arrayIdx353 = getelementptr inbounds i8, i8* %pix1, i64 %188
  %gepload354 = load i8, i8* %arrayIdx353, align 1, !tbaa !21
  %189 = add nsw i64 %183, 5
  %arrayIdx355 = getelementptr inbounds i8, i8* %pix2, i64 %189
  %gepload356 = load i8, i8* %arrayIdx355, align 1, !tbaa !21
  %190 = add nsw i64 %182, 2
  %arrayIdx357 = getelementptr inbounds i8, i8* %pix1, i64 %190
  %gepload358 = load i8, i8* %arrayIdx357, align 1, !tbaa !21
  %191 = add nsw i64 %183, 2
  %arrayIdx359 = getelementptr inbounds i8, i8* %pix2, i64 %191
  %gepload360 = load i8, i8* %arrayIdx359, align 1, !tbaa !21
  %192 = add nsw i64 %182, 6
  %arrayIdx361 = getelementptr inbounds i8, i8* %pix1, i64 %192
  %gepload362 = load i8, i8* %arrayIdx361, align 1, !tbaa !21
  %193 = add nsw i64 %183, 6
  %arrayIdx363 = getelementptr inbounds i8, i8* %pix2, i64 %193
  %gepload364 = load i8, i8* %arrayIdx363, align 1, !tbaa !21
  %194 = add nsw i64 %182, 3
  %arrayIdx365 = getelementptr inbounds i8, i8* %pix1, i64 %194
  %gepload366 = load i8, i8* %arrayIdx365, align 1, !tbaa !21
  %195 = add nsw i64 %183, 3
  %arrayIdx367 = getelementptr inbounds i8, i8* %pix2, i64 %195
  %gepload368 = load i8, i8* %arrayIdx367, align 1, !tbaa !21
  %196 = add nsw i64 %182, 7
  %arrayIdx369 = getelementptr inbounds i8, i8* %pix1, i64 %196
  %gepload370 = load i8, i8* %arrayIdx369, align 1, !tbaa !21
  %197 = add nsw i64 %183, 7
  %arrayIdx371 = getelementptr inbounds i8, i8* %pix2, i64 %197
  %gepload372 = load i8, i8* %arrayIdx371, align 1, !tbaa !21
  %arrayIdx374 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 2, i64 0
  %198 = zext i8 %gepload366 to i32
  %199 = zext i8 %gepload358 to i32
  %200 = add nuw nsw i32 %198, %199
  %201 = zext i8 %gepload350 to i32
  %202 = add nuw nsw i32 %200, %201
  %203 = zext i8 %gepload342 to i32
  %204 = add nuw nsw i32 %202, %203
  %205 = zext i8 %gepload370 to i32
  %206 = shl nuw nsw i32 %205, 16
  %207 = or i32 %204, %206
  %208 = zext i8 %gepload362 to i32
  %209 = shl nuw nsw i32 %208, 16
  %210 = add nuw nsw i32 %207, %209
  %211 = zext i8 %gepload354 to i32
  %212 = shl nuw nsw i32 %211, 16
  %213 = add nuw nsw i32 %210, %212
  %214 = zext i8 %gepload346 to i32
  %215 = shl nuw nsw i32 %214, 16
  %216 = add i32 %213, %215
  %217 = zext i8 %gepload372 to i32
  %218 = shl nuw nsw i32 %217, 16
  %219 = sub i32 %216, %218
  %220 = zext i8 %gepload364 to i32
  %221 = shl nuw nsw i32 %220, 16
  %222 = sub i32 %219, %221
  %223 = zext i8 %gepload356 to i32
  %224 = shl nuw nsw i32 %223, 16
  %225 = sub i32 %222, %224
  %226 = zext i8 %gepload348 to i32
  %227 = shl nuw nsw i32 %226, 16
  %228 = sub i32 %225, %227
  %229 = zext i8 %gepload368 to i32
  %230 = sub i32 %228, %229
  %231 = zext i8 %gepload360 to i32
  %232 = sub i32 %230, %231
  %233 = zext i8 %gepload352 to i32
  %234 = sub i32 %232, %233
  %235 = zext i8 %gepload344 to i32
  %236 = sub i32 %234, %235
  store i32 %236, i32* %arrayIdx374, align 4
  %arrayIdx392 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 2, i64 2
  %237 = add nuw nsw i32 %198, %199
  %238 = sub nsw i32 %201, %237
  %239 = add nsw i32 %238, %203
  %240 = sub nsw i32 %239, %206
  %241 = sub nsw i32 %240, %209
  %242 = add nsw i32 %241, %212
  %243 = add i32 %242, %215
  %244 = add i32 %243, %218
  %245 = add i32 %244, %221
  %246 = sub i32 %245, %224
  %247 = sub i32 %246, %227
  %248 = add i32 %247, %229
  %249 = add i32 %248, %231
  %250 = sub i32 %249, %233
  %251 = sub i32 %250, %235
  store i32 %251, i32* %arrayIdx392, align 4
  %arrayIdx410 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 2, i64 1
  %252 = sub nsw i32 %199, %198
  %253 = sub nsw i32 %252, %201
  %254 = add nsw i32 %253, %203
  %255 = sub nsw i32 %254, %206
  %256 = add nsw i32 %255, %209
  %257 = sub nsw i32 %256, %212
  %258 = add i32 %257, %215
  %259 = add i32 %258, %218
  %260 = sub i32 %259, %221
  %261 = add i32 %260, %224
  %262 = sub i32 %261, %227
  %263 = add i32 %262, %229
  %264 = sub i32 %263, %231
  %265 = add i32 %264, %233
  %266 = sub i32 %265, %235
  store i32 %266, i32* %arrayIdx410, align 4
  %arrayIdx428 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 2, i64 3
  %267 = sub nsw i32 %198, %199
  %268 = sub nsw i32 %267, %201
  %269 = add nsw i32 %268, %203
  %270 = add nsw i32 %269, %206
  %271 = sub nsw i32 %270, %209
  %272 = sub nsw i32 %271, %212
  %273 = add i32 %272, %215
  %274 = sub i32 %273, %218
  %275 = add i32 %274, %221
  %276 = add i32 %275, %224
  %277 = sub i32 %276, %227
  %278 = sub i32 %277, %229
  %279 = add i32 %278, %231
  %280 = add i32 %279, %233
  %281 = sub i32 %280, %235
  store i32 %281, i32* %arrayIdx428, align 4
  %282 = mul nsw i64 %idx.ext.i, 3
  %arrayIdx445 = getelementptr inbounds i8, i8* %pix1, i64 %282
  %gepload446 = load i8, i8* %arrayIdx445, align 1, !tbaa !21
  %283 = mul nsw i64 %idx.ext63.i, 3
  %arrayIdx447 = getelementptr inbounds i8, i8* %pix2, i64 %283
  %gepload448 = load i8, i8* %arrayIdx447, align 1, !tbaa !21
  %284 = add nsw i64 %282, 4
  %arrayIdx449 = getelementptr inbounds i8, i8* %pix1, i64 %284
  %gepload450 = load i8, i8* %arrayIdx449, align 1, !tbaa !21
  %285 = add nsw i64 %283, 4
  %arrayIdx451 = getelementptr inbounds i8, i8* %pix2, i64 %285
  %gepload452 = load i8, i8* %arrayIdx451, align 1, !tbaa !21
  %286 = add nsw i64 %282, 1
  %arrayIdx453 = getelementptr inbounds i8, i8* %pix1, i64 %286
  %gepload454 = load i8, i8* %arrayIdx453, align 1, !tbaa !21
  %287 = add nsw i64 %283, 1
  %arrayIdx455 = getelementptr inbounds i8, i8* %pix2, i64 %287
  %gepload456 = load i8, i8* %arrayIdx455, align 1, !tbaa !21
  %288 = add nsw i64 %282, 5
  %arrayIdx457 = getelementptr inbounds i8, i8* %pix1, i64 %288
  %gepload458 = load i8, i8* %arrayIdx457, align 1, !tbaa !21
  %289 = add nsw i64 %283, 5
  %arrayIdx459 = getelementptr inbounds i8, i8* %pix2, i64 %289
  %gepload460 = load i8, i8* %arrayIdx459, align 1, !tbaa !21
  %290 = add nsw i64 %282, 2
  %arrayIdx461 = getelementptr inbounds i8, i8* %pix1, i64 %290
  %gepload462 = load i8, i8* %arrayIdx461, align 1, !tbaa !21
  %291 = add nsw i64 %283, 2
  %arrayIdx463 = getelementptr inbounds i8, i8* %pix2, i64 %291
  %gepload464 = load i8, i8* %arrayIdx463, align 1, !tbaa !21
  %292 = add nsw i64 %282, 6
  %arrayIdx465 = getelementptr inbounds i8, i8* %pix1, i64 %292
  %gepload466 = load i8, i8* %arrayIdx465, align 1, !tbaa !21
  %293 = add nsw i64 %283, 6
  %arrayIdx467 = getelementptr inbounds i8, i8* %pix2, i64 %293
  %gepload468 = load i8, i8* %arrayIdx467, align 1, !tbaa !21
  %294 = add nsw i64 %282, 3
  %arrayIdx469 = getelementptr inbounds i8, i8* %pix1, i64 %294
  %gepload470 = load i8, i8* %arrayIdx469, align 1, !tbaa !21
  %295 = add nsw i64 %283, 3
  %arrayIdx471 = getelementptr inbounds i8, i8* %pix2, i64 %295
  %gepload472 = load i8, i8* %arrayIdx471, align 1, !tbaa !21
  %296 = add nsw i64 %282, 7
  %arrayIdx473 = getelementptr inbounds i8, i8* %pix1, i64 %296
  %gepload474 = load i8, i8* %arrayIdx473, align 1, !tbaa !21
  %297 = add nsw i64 %283, 7
  %arrayIdx475 = getelementptr inbounds i8, i8* %pix2, i64 %297
  %gepload476 = load i8, i8* %arrayIdx475, align 1, !tbaa !21
  %arrayIdx478 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 3, i64 0
  %298 = zext i8 %gepload470 to i32
  %299 = zext i8 %gepload462 to i32
  %300 = add nuw nsw i32 %298, %299
  %301 = zext i8 %gepload454 to i32
  %302 = add nuw nsw i32 %300, %301
  %303 = zext i8 %gepload446 to i32
  %304 = add nuw nsw i32 %302, %303
  %305 = zext i8 %gepload474 to i32
  %306 = shl nuw nsw i32 %305, 16
  %307 = or i32 %304, %306
  %308 = zext i8 %gepload466 to i32
  %309 = shl nuw nsw i32 %308, 16
  %310 = add nuw nsw i32 %307, %309
  %311 = zext i8 %gepload458 to i32
  %312 = shl nuw nsw i32 %311, 16
  %313 = add nuw nsw i32 %310, %312
  %314 = zext i8 %gepload450 to i32
  %315 = shl nuw nsw i32 %314, 16
  %316 = add i32 %313, %315
  %317 = zext i8 %gepload476 to i32
  %318 = shl nuw nsw i32 %317, 16
  %319 = sub i32 %316, %318
  %320 = zext i8 %gepload468 to i32
  %321 = shl nuw nsw i32 %320, 16
  %322 = sub i32 %319, %321
  %323 = zext i8 %gepload460 to i32
  %324 = shl nuw nsw i32 %323, 16
  %325 = sub i32 %322, %324
  %326 = zext i8 %gepload452 to i32
  %327 = shl nuw nsw i32 %326, 16
  %328 = sub i32 %325, %327
  %329 = zext i8 %gepload472 to i32
  %330 = sub i32 %328, %329
  %331 = zext i8 %gepload464 to i32
  %332 = sub i32 %330, %331
  %333 = zext i8 %gepload456 to i32
  %334 = sub i32 %332, %333
  %335 = zext i8 %gepload448 to i32
  %336 = sub i32 %334, %335
  store i32 %336, i32* %arrayIdx478, align 4
  %arrayIdx496 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 3, i64 2
  %337 = add nuw nsw i32 %298, %299
  %338 = sub nsw i32 %301, %337
  %339 = add nsw i32 %338, %303
  %340 = sub nsw i32 %339, %306
  %341 = sub nsw i32 %340, %309
  %342 = add nsw i32 %341, %312
  %343 = add i32 %342, %315
  %344 = add i32 %343, %318
  %345 = add i32 %344, %321
  %346 = sub i32 %345, %324
  %347 = sub i32 %346, %327
  %348 = add i32 %347, %329
  %349 = add i32 %348, %331
  %350 = sub i32 %349, %333
  %351 = sub i32 %350, %335
  store i32 %351, i32* %arrayIdx496, align 4
  %arrayIdx514 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 3, i64 1
  %352 = sub nsw i32 %299, %298
  %353 = sub nsw i32 %352, %301
  %354 = add nsw i32 %353, %303
  %355 = sub nsw i32 %354, %306
  %356 = add nsw i32 %355, %309
  %357 = sub nsw i32 %356, %312
  %358 = add i32 %357, %315
  %359 = add i32 %358, %318
  %360 = sub i32 %359, %321
  %361 = add i32 %360, %324
  %362 = sub i32 %361, %327
  %363 = add i32 %362, %329
  %364 = sub i32 %363, %331
  %365 = add i32 %364, %333
  %366 = sub i32 %365, %335
  store i32 %366, i32* %arrayIdx514, align 4
  %arrayIdx532 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 3, i64 3
  %367 = sub nsw i32 %298, %299
  %368 = sub nsw i32 %367, %301
  %369 = add nsw i32 %368, %303
  %370 = add nsw i32 %369, %306
  %371 = sub nsw i32 %370, %309
  %372 = sub nsw i32 %371, %312
  %373 = add i32 %372, %315
  %374 = sub i32 %373, %318
  %375 = add i32 %374, %321
  %376 = add i32 %375, %324
  %377 = sub i32 %376, %327
  %378 = sub i32 %377, %329
  %379 = add i32 %378, %331
  %380 = add i32 %379, %333
  %381 = sub i32 %380, %335
  store i32 %381, i32* %arrayIdx532, align 4
  %382 = shl nsw i64 %idx.ext.i, 2
  %arrayIdx549 = getelementptr inbounds i8, i8* %pix1, i64 %382
  %gepload550 = load i8, i8* %arrayIdx549, align 1, !tbaa !21
  %383 = shl nsw i64 %idx.ext63.i, 2
  %arrayIdx551 = getelementptr inbounds i8, i8* %pix2, i64 %383
  %gepload552 = load i8, i8* %arrayIdx551, align 1, !tbaa !21
  %384 = add nsw i64 %382, 4
  %arrayIdx553 = getelementptr inbounds i8, i8* %pix1, i64 %384
  %gepload554 = load i8, i8* %arrayIdx553, align 1, !tbaa !21
  %385 = add nsw i64 %383, 4
  %arrayIdx555 = getelementptr inbounds i8, i8* %pix2, i64 %385
  %gepload556 = load i8, i8* %arrayIdx555, align 1, !tbaa !21
  %386 = or i64 %382, 1
  %arrayIdx557 = getelementptr inbounds i8, i8* %pix1, i64 %386
  %gepload558 = load i8, i8* %arrayIdx557, align 1, !tbaa !21
  %387 = or i64 %383, 1
  %arrayIdx559 = getelementptr inbounds i8, i8* %pix2, i64 %387
  %gepload560 = load i8, i8* %arrayIdx559, align 1, !tbaa !21
  %388 = add nsw i64 %382, 5
  %arrayIdx561 = getelementptr inbounds i8, i8* %pix1, i64 %388
  %gepload562 = load i8, i8* %arrayIdx561, align 1, !tbaa !21
  %389 = add nsw i64 %383, 5
  %arrayIdx563 = getelementptr inbounds i8, i8* %pix2, i64 %389
  %gepload564 = load i8, i8* %arrayIdx563, align 1, !tbaa !21
  %390 = or i64 %382, 2
  %arrayIdx565 = getelementptr inbounds i8, i8* %pix1, i64 %390
  %gepload566 = load i8, i8* %arrayIdx565, align 1, !tbaa !21
  %391 = or i64 %383, 2
  %arrayIdx567 = getelementptr inbounds i8, i8* %pix2, i64 %391
  %gepload568 = load i8, i8* %arrayIdx567, align 1, !tbaa !21
  %392 = add nsw i64 %382, 6
  %arrayIdx569 = getelementptr inbounds i8, i8* %pix1, i64 %392
  %gepload570 = load i8, i8* %arrayIdx569, align 1, !tbaa !21
  %393 = add nsw i64 %383, 6
  %arrayIdx571 = getelementptr inbounds i8, i8* %pix2, i64 %393
  %gepload572 = load i8, i8* %arrayIdx571, align 1, !tbaa !21
  %394 = or i64 %382, 3
  %arrayIdx573 = getelementptr inbounds i8, i8* %pix1, i64 %394
  %gepload574 = load i8, i8* %arrayIdx573, align 1, !tbaa !21
  %395 = or i64 %383, 3
  %arrayIdx575 = getelementptr inbounds i8, i8* %pix2, i64 %395
  %gepload576 = load i8, i8* %arrayIdx575, align 1, !tbaa !21
  %396 = add nsw i64 %382, 7
  %arrayIdx577 = getelementptr inbounds i8, i8* %pix1, i64 %396
  %gepload578 = load i8, i8* %arrayIdx577, align 1, !tbaa !21
  %397 = add nsw i64 %383, 7
  %arrayIdx579 = getelementptr inbounds i8, i8* %pix2, i64 %397
  %gepload580 = load i8, i8* %arrayIdx579, align 1, !tbaa !21
  %arrayIdx582 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 4, i64 0
  %398 = zext i8 %gepload574 to i32
  %399 = zext i8 %gepload566 to i32
  %400 = add nuw nsw i32 %398, %399
  %401 = zext i8 %gepload558 to i32
  %402 = add nuw nsw i32 %400, %401
  %403 = zext i8 %gepload550 to i32
  %404 = add nuw nsw i32 %402, %403
  %405 = zext i8 %gepload578 to i32
  %406 = shl nuw nsw i32 %405, 16
  %407 = or i32 %404, %406
  %408 = zext i8 %gepload570 to i32
  %409 = shl nuw nsw i32 %408, 16
  %410 = add nuw nsw i32 %407, %409
  %411 = zext i8 %gepload562 to i32
  %412 = shl nuw nsw i32 %411, 16
  %413 = add nuw nsw i32 %410, %412
  %414 = zext i8 %gepload554 to i32
  %415 = shl nuw nsw i32 %414, 16
  %416 = add i32 %413, %415
  %417 = zext i8 %gepload580 to i32
  %418 = shl nuw nsw i32 %417, 16
  %419 = sub i32 %416, %418
  %420 = zext i8 %gepload572 to i32
  %421 = shl nuw nsw i32 %420, 16
  %422 = sub i32 %419, %421
  %423 = zext i8 %gepload564 to i32
  %424 = shl nuw nsw i32 %423, 16
  %425 = sub i32 %422, %424
  %426 = zext i8 %gepload556 to i32
  %427 = shl nuw nsw i32 %426, 16
  %428 = sub i32 %425, %427
  %429 = zext i8 %gepload576 to i32
  %430 = sub i32 %428, %429
  %431 = zext i8 %gepload568 to i32
  %432 = sub i32 %430, %431
  %433 = zext i8 %gepload560 to i32
  %434 = sub i32 %432, %433
  %435 = zext i8 %gepload552 to i32
  %436 = sub i32 %434, %435
  store i32 %436, i32* %arrayIdx582, align 4
  %arrayIdx600 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 4, i64 2
  %437 = add nuw nsw i32 %398, %399
  %438 = sub nsw i32 %401, %437
  %439 = add nsw i32 %438, %403
  %440 = sub nsw i32 %439, %406
  %441 = sub nsw i32 %440, %409
  %442 = add nsw i32 %441, %412
  %443 = add i32 %442, %415
  %444 = add i32 %443, %418
  %445 = add i32 %444, %421
  %446 = sub i32 %445, %424
  %447 = sub i32 %446, %427
  %448 = add i32 %447, %429
  %449 = add i32 %448, %431
  %450 = sub i32 %449, %433
  %451 = sub i32 %450, %435
  store i32 %451, i32* %arrayIdx600, align 4
  %arrayIdx618 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 4, i64 1
  %452 = sub nsw i32 %399, %398
  %453 = sub nsw i32 %452, %401
  %454 = add nsw i32 %453, %403
  %455 = sub nsw i32 %454, %406
  %456 = add nsw i32 %455, %409
  %457 = sub nsw i32 %456, %412
  %458 = add i32 %457, %415
  %459 = add i32 %458, %418
  %460 = sub i32 %459, %421
  %461 = add i32 %460, %424
  %462 = sub i32 %461, %427
  %463 = add i32 %462, %429
  %464 = sub i32 %463, %431
  %465 = add i32 %464, %433
  %466 = sub i32 %465, %435
  store i32 %466, i32* %arrayIdx618, align 4
  %arrayIdx636 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 4, i64 3
  %467 = sub nsw i32 %398, %399
  %468 = sub nsw i32 %467, %401
  %469 = add nsw i32 %468, %403
  %470 = add nsw i32 %469, %406
  %471 = sub nsw i32 %470, %409
  %472 = sub nsw i32 %471, %412
  %473 = add i32 %472, %415
  %474 = sub i32 %473, %418
  %475 = add i32 %474, %421
  %476 = add i32 %475, %424
  %477 = sub i32 %476, %427
  %478 = sub i32 %477, %429
  %479 = add i32 %478, %431
  %480 = add i32 %479, %433
  %481 = sub i32 %480, %435
  store i32 %481, i32* %arrayIdx636, align 4
  %482 = mul nsw i64 %idx.ext.i, 5
  %arrayIdx653 = getelementptr inbounds i8, i8* %pix1, i64 %482
  %gepload654 = load i8, i8* %arrayIdx653, align 1, !tbaa !21
  %483 = mul nsw i64 %idx.ext63.i, 5
  %arrayIdx655 = getelementptr inbounds i8, i8* %pix2, i64 %483
  %gepload656 = load i8, i8* %arrayIdx655, align 1, !tbaa !21
  %484 = add nsw i64 %482, 4
  %arrayIdx657 = getelementptr inbounds i8, i8* %pix1, i64 %484
  %gepload658 = load i8, i8* %arrayIdx657, align 1, !tbaa !21
  %485 = add nsw i64 %483, 4
  %arrayIdx659 = getelementptr inbounds i8, i8* %pix2, i64 %485
  %gepload660 = load i8, i8* %arrayIdx659, align 1, !tbaa !21
  %486 = add nsw i64 %482, 1
  %arrayIdx661 = getelementptr inbounds i8, i8* %pix1, i64 %486
  %gepload662 = load i8, i8* %arrayIdx661, align 1, !tbaa !21
  %487 = add nsw i64 %483, 1
  %arrayIdx663 = getelementptr inbounds i8, i8* %pix2, i64 %487
  %gepload664 = load i8, i8* %arrayIdx663, align 1, !tbaa !21
  %488 = add nsw i64 %482, 5
  %arrayIdx665 = getelementptr inbounds i8, i8* %pix1, i64 %488
  %gepload666 = load i8, i8* %arrayIdx665, align 1, !tbaa !21
  %489 = add nsw i64 %483, 5
  %arrayIdx667 = getelementptr inbounds i8, i8* %pix2, i64 %489
  %gepload668 = load i8, i8* %arrayIdx667, align 1, !tbaa !21
  %490 = add nsw i64 %482, 2
  %arrayIdx669 = getelementptr inbounds i8, i8* %pix1, i64 %490
  %gepload670 = load i8, i8* %arrayIdx669, align 1, !tbaa !21
  %491 = add nsw i64 %483, 2
  %arrayIdx671 = getelementptr inbounds i8, i8* %pix2, i64 %491
  %gepload672 = load i8, i8* %arrayIdx671, align 1, !tbaa !21
  %492 = add nsw i64 %482, 6
  %arrayIdx673 = getelementptr inbounds i8, i8* %pix1, i64 %492
  %gepload674 = load i8, i8* %arrayIdx673, align 1, !tbaa !21
  %493 = add nsw i64 %483, 6
  %arrayIdx675 = getelementptr inbounds i8, i8* %pix2, i64 %493
  %gepload676 = load i8, i8* %arrayIdx675, align 1, !tbaa !21
  %494 = add nsw i64 %482, 3
  %arrayIdx677 = getelementptr inbounds i8, i8* %pix1, i64 %494
  %gepload678 = load i8, i8* %arrayIdx677, align 1, !tbaa !21
  %495 = add nsw i64 %483, 3
  %arrayIdx679 = getelementptr inbounds i8, i8* %pix2, i64 %495
  %gepload680 = load i8, i8* %arrayIdx679, align 1, !tbaa !21
  %496 = add nsw i64 %482, 7
  %arrayIdx681 = getelementptr inbounds i8, i8* %pix1, i64 %496
  %gepload682 = load i8, i8* %arrayIdx681, align 1, !tbaa !21
  %497 = add nsw i64 %483, 7
  %arrayIdx683 = getelementptr inbounds i8, i8* %pix2, i64 %497
  %gepload684 = load i8, i8* %arrayIdx683, align 1, !tbaa !21
  %arrayIdx686 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 5, i64 0
  %498 = zext i8 %gepload678 to i32
  %499 = zext i8 %gepload670 to i32
  %500 = add nuw nsw i32 %498, %499
  %501 = zext i8 %gepload662 to i32
  %502 = add nuw nsw i32 %500, %501
  %503 = zext i8 %gepload654 to i32
  %504 = add nuw nsw i32 %502, %503
  %505 = zext i8 %gepload682 to i32
  %506 = shl nuw nsw i32 %505, 16
  %507 = or i32 %504, %506
  %508 = zext i8 %gepload674 to i32
  %509 = shl nuw nsw i32 %508, 16
  %510 = add nuw nsw i32 %507, %509
  %511 = zext i8 %gepload666 to i32
  %512 = shl nuw nsw i32 %511, 16
  %513 = add nuw nsw i32 %510, %512
  %514 = zext i8 %gepload658 to i32
  %515 = shl nuw nsw i32 %514, 16
  %516 = add i32 %513, %515
  %517 = zext i8 %gepload684 to i32
  %518 = shl nuw nsw i32 %517, 16
  %519 = sub i32 %516, %518
  %520 = zext i8 %gepload676 to i32
  %521 = shl nuw nsw i32 %520, 16
  %522 = sub i32 %519, %521
  %523 = zext i8 %gepload668 to i32
  %524 = shl nuw nsw i32 %523, 16
  %525 = sub i32 %522, %524
  %526 = zext i8 %gepload660 to i32
  %527 = shl nuw nsw i32 %526, 16
  %528 = sub i32 %525, %527
  %529 = zext i8 %gepload680 to i32
  %530 = sub i32 %528, %529
  %531 = zext i8 %gepload672 to i32
  %532 = sub i32 %530, %531
  %533 = zext i8 %gepload664 to i32
  %534 = sub i32 %532, %533
  %535 = zext i8 %gepload656 to i32
  %536 = sub i32 %534, %535
  store i32 %536, i32* %arrayIdx686, align 4
  %arrayIdx704 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 5, i64 2
  %537 = add nuw nsw i32 %498, %499
  %538 = sub nsw i32 %501, %537
  %539 = add nsw i32 %538, %503
  %540 = sub nsw i32 %539, %506
  %541 = sub nsw i32 %540, %509
  %542 = add nsw i32 %541, %512
  %543 = add i32 %542, %515
  %544 = add i32 %543, %518
  %545 = add i32 %544, %521
  %546 = sub i32 %545, %524
  %547 = sub i32 %546, %527
  %548 = add i32 %547, %529
  %549 = add i32 %548, %531
  %550 = sub i32 %549, %533
  %551 = sub i32 %550, %535
  store i32 %551, i32* %arrayIdx704, align 4
  %arrayIdx722 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 5, i64 1
  %552 = sub nsw i32 %499, %498
  %553 = sub nsw i32 %552, %501
  %554 = add nsw i32 %553, %503
  %555 = sub nsw i32 %554, %506
  %556 = add nsw i32 %555, %509
  %557 = sub nsw i32 %556, %512
  %558 = add i32 %557, %515
  %559 = add i32 %558, %518
  %560 = sub i32 %559, %521
  %561 = add i32 %560, %524
  %562 = sub i32 %561, %527
  %563 = add i32 %562, %529
  %564 = sub i32 %563, %531
  %565 = add i32 %564, %533
  %566 = sub i32 %565, %535
  store i32 %566, i32* %arrayIdx722, align 4
  %arrayIdx740 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 5, i64 3
  %567 = sub nsw i32 %498, %499
  %568 = sub nsw i32 %567, %501
  %569 = add nsw i32 %568, %503
  %570 = add nsw i32 %569, %506
  %571 = sub nsw i32 %570, %509
  %572 = sub nsw i32 %571, %512
  %573 = add i32 %572, %515
  %574 = sub i32 %573, %518
  %575 = add i32 %574, %521
  %576 = add i32 %575, %524
  %577 = sub i32 %576, %527
  %578 = sub i32 %577, %529
  %579 = add i32 %578, %531
  %580 = add i32 %579, %533
  %581 = sub i32 %580, %535
  store i32 %581, i32* %arrayIdx740, align 4
  %582 = mul nsw i64 %idx.ext.i, 6
  %arrayIdx757 = getelementptr inbounds i8, i8* %pix1, i64 %582
  %gepload758 = load i8, i8* %arrayIdx757, align 1, !tbaa !21
  %583 = mul nsw i64 %idx.ext63.i, 6
  %arrayIdx759 = getelementptr inbounds i8, i8* %pix2, i64 %583
  %gepload760 = load i8, i8* %arrayIdx759, align 1, !tbaa !21
  %584 = add nsw i64 %582, 4
  %arrayIdx761 = getelementptr inbounds i8, i8* %pix1, i64 %584
  %gepload762 = load i8, i8* %arrayIdx761, align 1, !tbaa !21
  %585 = add nsw i64 %583, 4
  %arrayIdx763 = getelementptr inbounds i8, i8* %pix2, i64 %585
  %gepload764 = load i8, i8* %arrayIdx763, align 1, !tbaa !21
  %586 = or i64 %582, 1
  %arrayIdx765 = getelementptr inbounds i8, i8* %pix1, i64 %586
  %gepload766 = load i8, i8* %arrayIdx765, align 1, !tbaa !21
  %587 = or i64 %583, 1
  %arrayIdx767 = getelementptr inbounds i8, i8* %pix2, i64 %587
  %gepload768 = load i8, i8* %arrayIdx767, align 1, !tbaa !21
  %588 = add nsw i64 %582, 5
  %arrayIdx769 = getelementptr inbounds i8, i8* %pix1, i64 %588
  %gepload770 = load i8, i8* %arrayIdx769, align 1, !tbaa !21
  %589 = add nsw i64 %583, 5
  %arrayIdx771 = getelementptr inbounds i8, i8* %pix2, i64 %589
  %gepload772 = load i8, i8* %arrayIdx771, align 1, !tbaa !21
  %590 = add nsw i64 %582, 2
  %arrayIdx773 = getelementptr inbounds i8, i8* %pix1, i64 %590
  %gepload774 = load i8, i8* %arrayIdx773, align 1, !tbaa !21
  %591 = add nsw i64 %583, 2
  %arrayIdx775 = getelementptr inbounds i8, i8* %pix2, i64 %591
  %gepload776 = load i8, i8* %arrayIdx775, align 1, !tbaa !21
  %592 = add nsw i64 %582, 6
  %arrayIdx777 = getelementptr inbounds i8, i8* %pix1, i64 %592
  %gepload778 = load i8, i8* %arrayIdx777, align 1, !tbaa !21
  %593 = add nsw i64 %583, 6
  %arrayIdx779 = getelementptr inbounds i8, i8* %pix2, i64 %593
  %gepload780 = load i8, i8* %arrayIdx779, align 1, !tbaa !21
  %594 = add nsw i64 %582, 3
  %arrayIdx781 = getelementptr inbounds i8, i8* %pix1, i64 %594
  %gepload782 = load i8, i8* %arrayIdx781, align 1, !tbaa !21
  %595 = add nsw i64 %583, 3
  %arrayIdx783 = getelementptr inbounds i8, i8* %pix2, i64 %595
  %gepload784 = load i8, i8* %arrayIdx783, align 1, !tbaa !21
  %596 = add nsw i64 %582, 7
  %arrayIdx785 = getelementptr inbounds i8, i8* %pix1, i64 %596
  %gepload786 = load i8, i8* %arrayIdx785, align 1, !tbaa !21
  %597 = add nsw i64 %583, 7
  %arrayIdx787 = getelementptr inbounds i8, i8* %pix2, i64 %597
  %gepload788 = load i8, i8* %arrayIdx787, align 1, !tbaa !21
  %arrayIdx790 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 6, i64 0
  %598 = zext i8 %gepload782 to i32
  %599 = zext i8 %gepload774 to i32
  %600 = add nuw nsw i32 %598, %599
  %601 = zext i8 %gepload766 to i32
  %602 = add nuw nsw i32 %600, %601
  %603 = zext i8 %gepload758 to i32
  %604 = add nuw nsw i32 %602, %603
  %605 = zext i8 %gepload786 to i32
  %606 = shl nuw nsw i32 %605, 16
  %607 = or i32 %604, %606
  %608 = zext i8 %gepload778 to i32
  %609 = shl nuw nsw i32 %608, 16
  %610 = add nuw nsw i32 %607, %609
  %611 = zext i8 %gepload770 to i32
  %612 = shl nuw nsw i32 %611, 16
  %613 = add nuw nsw i32 %610, %612
  %614 = zext i8 %gepload762 to i32
  %615 = shl nuw nsw i32 %614, 16
  %616 = add i32 %613, %615
  %617 = zext i8 %gepload788 to i32
  %618 = shl nuw nsw i32 %617, 16
  %619 = sub i32 %616, %618
  %620 = zext i8 %gepload780 to i32
  %621 = shl nuw nsw i32 %620, 16
  %622 = sub i32 %619, %621
  %623 = zext i8 %gepload772 to i32
  %624 = shl nuw nsw i32 %623, 16
  %625 = sub i32 %622, %624
  %626 = zext i8 %gepload764 to i32
  %627 = shl nuw nsw i32 %626, 16
  %628 = sub i32 %625, %627
  %629 = zext i8 %gepload784 to i32
  %630 = sub i32 %628, %629
  %631 = zext i8 %gepload776 to i32
  %632 = sub i32 %630, %631
  %633 = zext i8 %gepload768 to i32
  %634 = sub i32 %632, %633
  %635 = zext i8 %gepload760 to i32
  %636 = sub i32 %634, %635
  store i32 %636, i32* %arrayIdx790, align 4
  %arrayIdx808 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 6, i64 2
  %637 = add nuw nsw i32 %598, %599
  %638 = sub nsw i32 %601, %637
  %639 = add nsw i32 %638, %603
  %640 = sub nsw i32 %639, %606
  %641 = sub nsw i32 %640, %609
  %642 = add nsw i32 %641, %612
  %643 = add i32 %642, %615
  %644 = add i32 %643, %618
  %645 = add i32 %644, %621
  %646 = sub i32 %645, %624
  %647 = sub i32 %646, %627
  %648 = add i32 %647, %629
  %649 = add i32 %648, %631
  %650 = sub i32 %649, %633
  %651 = sub i32 %650, %635
  store i32 %651, i32* %arrayIdx808, align 4
  %arrayIdx826 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 6, i64 1
  %652 = sub nsw i32 %599, %598
  %653 = sub nsw i32 %652, %601
  %654 = add nsw i32 %653, %603
  %655 = sub nsw i32 %654, %606
  %656 = add nsw i32 %655, %609
  %657 = sub nsw i32 %656, %612
  %658 = add i32 %657, %615
  %659 = add i32 %658, %618
  %660 = sub i32 %659, %621
  %661 = add i32 %660, %624
  %662 = sub i32 %661, %627
  %663 = add i32 %662, %629
  %664 = sub i32 %663, %631
  %665 = add i32 %664, %633
  %666 = sub i32 %665, %635
  store i32 %666, i32* %arrayIdx826, align 4
  %arrayIdx844 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 6, i64 3
  %667 = sub nsw i32 %598, %599
  %668 = sub nsw i32 %667, %601
  %669 = add nsw i32 %668, %603
  %670 = add nsw i32 %669, %606
  %671 = sub nsw i32 %670, %609
  %672 = sub nsw i32 %671, %612
  %673 = add i32 %672, %615
  %674 = sub i32 %673, %618
  %675 = add i32 %674, %621
  %676 = add i32 %675, %624
  %677 = sub i32 %676, %627
  %678 = sub i32 %677, %629
  %679 = add i32 %678, %631
  %680 = add i32 %679, %633
  %681 = sub i32 %680, %635
  store i32 %681, i32* %arrayIdx844, align 4
  %682 = mul nsw i64 %idx.ext.i, 7
  %arrayIdx861 = getelementptr inbounds i8, i8* %pix1, i64 %682
  %gepload862 = load i8, i8* %arrayIdx861, align 1, !tbaa !21
  %683 = mul nsw i64 %idx.ext63.i, 7
  %arrayIdx863 = getelementptr inbounds i8, i8* %pix2, i64 %683
  %gepload864 = load i8, i8* %arrayIdx863, align 1, !tbaa !21
  %684 = add nsw i64 %682, 4
  %arrayIdx865 = getelementptr inbounds i8, i8* %pix1, i64 %684
  %gepload866 = load i8, i8* %arrayIdx865, align 1, !tbaa !21
  %685 = add nsw i64 %683, 4
  %arrayIdx867 = getelementptr inbounds i8, i8* %pix2, i64 %685
  %gepload868 = load i8, i8* %arrayIdx867, align 1, !tbaa !21
  %686 = add nsw i64 %682, 1
  %arrayIdx869 = getelementptr inbounds i8, i8* %pix1, i64 %686
  %gepload870 = load i8, i8* %arrayIdx869, align 1, !tbaa !21
  %687 = add nsw i64 %683, 1
  %arrayIdx871 = getelementptr inbounds i8, i8* %pix2, i64 %687
  %gepload872 = load i8, i8* %arrayIdx871, align 1, !tbaa !21
  %688 = add nsw i64 %682, 5
  %arrayIdx873 = getelementptr inbounds i8, i8* %pix1, i64 %688
  %gepload874 = load i8, i8* %arrayIdx873, align 1, !tbaa !21
  %689 = add nsw i64 %683, 5
  %arrayIdx875 = getelementptr inbounds i8, i8* %pix2, i64 %689
  %gepload876 = load i8, i8* %arrayIdx875, align 1, !tbaa !21
  %690 = add nsw i64 %682, 2
  %arrayIdx877 = getelementptr inbounds i8, i8* %pix1, i64 %690
  %gepload878 = load i8, i8* %arrayIdx877, align 1, !tbaa !21
  %691 = add nsw i64 %683, 2
  %arrayIdx879 = getelementptr inbounds i8, i8* %pix2, i64 %691
  %gepload880 = load i8, i8* %arrayIdx879, align 1, !tbaa !21
  %692 = add nsw i64 %682, 6
  %arrayIdx881 = getelementptr inbounds i8, i8* %pix1, i64 %692
  %gepload882 = load i8, i8* %arrayIdx881, align 1, !tbaa !21
  %693 = add nsw i64 %683, 6
  %arrayIdx883 = getelementptr inbounds i8, i8* %pix2, i64 %693
  %gepload884 = load i8, i8* %arrayIdx883, align 1, !tbaa !21
  %694 = add nsw i64 %682, 3
  %arrayIdx885 = getelementptr inbounds i8, i8* %pix1, i64 %694
  %gepload886 = load i8, i8* %arrayIdx885, align 1, !tbaa !21
  %695 = add nsw i64 %683, 3
  %arrayIdx887 = getelementptr inbounds i8, i8* %pix2, i64 %695
  %gepload888 = load i8, i8* %arrayIdx887, align 1, !tbaa !21
  %696 = add nsw i64 %682, 7
  %arrayIdx889 = getelementptr inbounds i8, i8* %pix1, i64 %696
  %gepload890 = load i8, i8* %arrayIdx889, align 1, !tbaa !21
  %697 = add nsw i64 %683, 7
  %arrayIdx891 = getelementptr inbounds i8, i8* %pix2, i64 %697
  %gepload892 = load i8, i8* %arrayIdx891, align 1, !tbaa !21
  %arrayIdx894 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 7, i64 0
  %698 = zext i8 %gepload886 to i32
  %699 = zext i8 %gepload878 to i32
  %700 = add nuw nsw i32 %698, %699
  %701 = zext i8 %gepload870 to i32
  %702 = add nuw nsw i32 %700, %701
  %703 = zext i8 %gepload862 to i32
  %704 = add nuw nsw i32 %702, %703
  %705 = zext i8 %gepload890 to i32
  %706 = shl nuw nsw i32 %705, 16
  %707 = or i32 %704, %706
  %708 = zext i8 %gepload882 to i32
  %709 = shl nuw nsw i32 %708, 16
  %710 = add nuw nsw i32 %707, %709
  %711 = zext i8 %gepload874 to i32
  %712 = shl nuw nsw i32 %711, 16
  %713 = add nuw nsw i32 %710, %712
  %714 = zext i8 %gepload866 to i32
  %715 = shl nuw nsw i32 %714, 16
  %716 = add i32 %713, %715
  %717 = zext i8 %gepload892 to i32
  %718 = shl nuw nsw i32 %717, 16
  %719 = sub i32 %716, %718
  %720 = zext i8 %gepload884 to i32
  %721 = shl nuw nsw i32 %720, 16
  %722 = sub i32 %719, %721
  %723 = zext i8 %gepload876 to i32
  %724 = shl nuw nsw i32 %723, 16
  %725 = sub i32 %722, %724
  %726 = zext i8 %gepload868 to i32
  %727 = shl nuw nsw i32 %726, 16
  %728 = sub i32 %725, %727
  %729 = zext i8 %gepload888 to i32
  %730 = sub i32 %728, %729
  %731 = zext i8 %gepload880 to i32
  %732 = sub i32 %730, %731
  %733 = zext i8 %gepload872 to i32
  %734 = sub i32 %732, %733
  %735 = zext i8 %gepload864 to i32
  %736 = sub i32 %734, %735
  store i32 %736, i32* %arrayIdx894, align 4
  %arrayIdx912 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 7, i64 2
  %737 = add nuw nsw i32 %698, %699
  %738 = sub nsw i32 %701, %737
  %739 = add nsw i32 %738, %703
  %740 = sub nsw i32 %739, %706
  %741 = sub nsw i32 %740, %709
  %742 = add nsw i32 %741, %712
  %743 = add i32 %742, %715
  %744 = add i32 %743, %718
  %745 = add i32 %744, %721
  %746 = sub i32 %745, %724
  %747 = sub i32 %746, %727
  %748 = add i32 %747, %729
  %749 = add i32 %748, %731
  %750 = sub i32 %749, %733
  %751 = sub i32 %750, %735
  store i32 %751, i32* %arrayIdx912, align 4
  %arrayIdx930 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 7, i64 1
  %752 = sub nsw i32 %699, %698
  %753 = sub nsw i32 %752, %701
  %754 = add nsw i32 %753, %703
  %755 = sub nsw i32 %754, %706
  %756 = add nsw i32 %755, %709
  %757 = sub nsw i32 %756, %712
  %758 = add i32 %757, %715
  %759 = add i32 %758, %718
  %760 = sub i32 %759, %721
  %761 = add i32 %760, %724
  %762 = sub i32 %761, %727
  %763 = add i32 %762, %729
  %764 = sub i32 %763, %731
  %765 = add i32 %764, %733
  %766 = sub i32 %765, %735
  store i32 %766, i32* %arrayIdx930, align 4
  %arrayIdx948 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 7, i64 3
  %767 = sub nsw i32 %698, %699
  %768 = sub nsw i32 %767, %701
  %769 = add nsw i32 %768, %703
  %770 = add nsw i32 %769, %706
  %771 = sub nsw i32 %770, %709
  %772 = sub nsw i32 %771, %712
  %773 = add i32 %772, %715
  %774 = sub i32 %773, %718
  %775 = add i32 %774, %721
  %776 = add i32 %775, %724
  %777 = sub i32 %776, %727
  %778 = sub i32 %777, %729
  %779 = add i32 %778, %731
  %780 = add i32 %779, %733
  %781 = sub i32 %780, %735
  store i32 %781, i32* %arrayIdx948, align 4
  br label %loop.458

loop.458:                                         ; preds = %loop.458, %entry
  %t301.0 = phi <4 x i32> [ zeroinitializer, %entry ], [ %820, %loop.458 ]
  %t320.0 = phi <4 x i32> [ zeroinitializer, %entry ], [ %859, %loop.458 ]
  %i1.i64.0 = phi i64 [ 0, %entry ], [ %nextivloop.458, %loop.458 ]
  %arrayIdx970 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 0, i64 %i1.i64.0
  %782 = bitcast i32* %arrayIdx970 to <4 x i32>*
  %gepload971 = load <4 x i32>, <4 x i32>* %782, align 4
  %arrayIdx973 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 1, i64 %i1.i64.0
  %783 = bitcast i32* %arrayIdx973 to <4 x i32>*
  %gepload974 = load <4 x i32>, <4 x i32>* %783, align 4
  %arrayIdx976 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 2, i64 %i1.i64.0
  %784 = bitcast i32* %arrayIdx976 to <4 x i32>*
  %gepload977 = load <4 x i32>, <4 x i32>* %784, align 4
  %arrayIdx979 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 3, i64 %i1.i64.0
  %785 = bitcast i32* %arrayIdx979 to <4 x i32>*
  %gepload980 = load <4 x i32>, <4 x i32>* %785, align 4
  %786 = add <4 x i32> %gepload971, %gepload974
  %787 = add <4 x i32> %786, %gepload977
  %788 = add <4 x i32> %787, %gepload980
  %789 = lshr <4 x i32> %788, <i32 15, i32 15, i32 15, i32 15>
  %790 = and <4 x i32> %789, <i32 65537, i32 65537, i32 65537, i32 65537>
  %791 = mul nuw <4 x i32> %790, <i32 65535, i32 65535, i32 65535, i32 65535>
  %792 = add <4 x i32> %788, %791
  %793 = xor <4 x i32> %792, %791
  %794 = sub <4 x i32> %gepload971, %gepload974
  %795 = add <4 x i32> %794, %gepload977
  %796 = sub <4 x i32> %795, %gepload980
  %797 = lshr <4 x i32> %796, <i32 15, i32 15, i32 15, i32 15>
  %798 = and <4 x i32> %797, <i32 65537, i32 65537, i32 65537, i32 65537>
  %799 = mul nuw <4 x i32> %798, <i32 65535, i32 65535, i32 65535, i32 65535>
  %800 = add <4 x i32> %796, %799
  %801 = xor <4 x i32> %800, %799
  %802 = add <4 x i32> %gepload977, %gepload980
  %803 = sub <4 x i32> %786, %802
  %804 = lshr <4 x i32> %803, <i32 15, i32 15, i32 15, i32 15>
  %805 = and <4 x i32> %804, <i32 65537, i32 65537, i32 65537, i32 65537>
  %806 = mul nuw <4 x i32> %805, <i32 65535, i32 65535, i32 65535, i32 65535>
  %807 = add <4 x i32> %786, %806
  %808 = sub <4 x i32> %807, %802
  %809 = xor <4 x i32> %808, %806
  %810 = sub <4 x i32> %794, %gepload977
  %811 = add <4 x i32> %810, %gepload980
  %812 = lshr <4 x i32> %811, <i32 15, i32 15, i32 15, i32 15>
  %813 = and <4 x i32> %812, <i32 65537, i32 65537, i32 65537, i32 65537>
  %814 = mul nuw <4 x i32> %813, <i32 65535, i32 65535, i32 65535, i32 65535>
  %815 = add <4 x i32> %811, %814
  %816 = xor <4 x i32> %815, %814
  %817 = add <4 x i32> %793, %801
  %818 = add <4 x i32> %809, %816
  %819 = add <4 x i32> %818, %t301.0
  %820 = add <4 x i32> %817, %819
  %arrayIdx1014 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 4, i64 %i1.i64.0
  %821 = bitcast i32* %arrayIdx1014 to <4 x i32>*
  %gepload1015 = load <4 x i32>, <4 x i32>* %821, align 4
  %arrayIdx1017 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 5, i64 %i1.i64.0
  %822 = bitcast i32* %arrayIdx1017 to <4 x i32>*
  %gepload1018 = load <4 x i32>, <4 x i32>* %822, align 4
  %arrayIdx1020 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 6, i64 %i1.i64.0
  %823 = bitcast i32* %arrayIdx1020 to <4 x i32>*
  %gepload1021 = load <4 x i32>, <4 x i32>* %823, align 4
  %arrayIdx1023 = getelementptr inbounds [8 x [4 x i32]], [8 x [4 x i32]]* %alloca, i64 0, i64 7, i64 %i1.i64.0
  %824 = bitcast i32* %arrayIdx1023 to <4 x i32>*
  %gepload1024 = load <4 x i32>, <4 x i32>* %824, align 4
  %825 = add <4 x i32> %gepload1015, %gepload1018
  %826 = add <4 x i32> %825, %gepload1021
  %827 = add <4 x i32> %826, %gepload1024
  %828 = lshr <4 x i32> %827, <i32 15, i32 15, i32 15, i32 15>
  %829 = and <4 x i32> %828, <i32 65537, i32 65537, i32 65537, i32 65537>
  %830 = mul nuw <4 x i32> %829, <i32 65535, i32 65535, i32 65535, i32 65535>
  %831 = add <4 x i32> %827, %830
  %832 = xor <4 x i32> %831, %830
  %833 = sub <4 x i32> %gepload1015, %gepload1018
  %834 = add <4 x i32> %833, %gepload1021
  %835 = sub <4 x i32> %834, %gepload1024
  %836 = lshr <4 x i32> %835, <i32 15, i32 15, i32 15, i32 15>
  %837 = and <4 x i32> %836, <i32 65537, i32 65537, i32 65537, i32 65537>
  %838 = mul nuw <4 x i32> %837, <i32 65535, i32 65535, i32 65535, i32 65535>
  %839 = add <4 x i32> %835, %838
  %840 = xor <4 x i32> %839, %838
  %841 = add <4 x i32> %gepload1021, %gepload1024
  %842 = sub <4 x i32> %825, %841
  %843 = lshr <4 x i32> %842, <i32 15, i32 15, i32 15, i32 15>
  %844 = and <4 x i32> %843, <i32 65537, i32 65537, i32 65537, i32 65537>
  %845 = mul nuw <4 x i32> %844, <i32 65535, i32 65535, i32 65535, i32 65535>
  %846 = add <4 x i32> %825, %845
  %847 = sub <4 x i32> %846, %841
  %848 = xor <4 x i32> %847, %845
  %849 = sub <4 x i32> %833, %gepload1021
  %850 = add <4 x i32> %849, %gepload1024
  %851 = lshr <4 x i32> %850, <i32 15, i32 15, i32 15, i32 15>
  %852 = and <4 x i32> %851, <i32 65537, i32 65537, i32 65537, i32 65537>
  %853 = mul nuw <4 x i32> %852, <i32 65535, i32 65535, i32 65535, i32 65535>
  %854 = add <4 x i32> %850, %853
  %855 = xor <4 x i32> %854, %853
  %856 = add <4 x i32> %832, %840
  %857 = add <4 x i32> %848, %855
  %858 = add <4 x i32> %857, %t320.0
  %859 = add <4 x i32> %856, %858
  %nextivloop.458 = add nuw nsw i64 %i1.i64.0, 4
  br i1 false, label %loop.458, label %afterloop.458

afterloop.458:                                    ; preds = %loop.458
  %rdx.shuf1481059 = shufflevector <4 x i32> %859, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %860 = add <4 x i32> %859, %rdx.shuf1481059
  %rdx.shuf1501062 = shufflevector <4 x i32> %860, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %861 = add <4 x i32> %860, %rdx.shuf1501062
  %bin.final1521064 = extractelement <4 x i32> %861, i64 0
  %rdx.shuf1067 = shufflevector <4 x i32> %820, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %862 = add <4 x i32> %820, %rdx.shuf1067
  %rdx.shuf1381070 = shufflevector <4 x i32> %862, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %863 = add <4 x i32> %862, %rdx.shuf1381070
  %bin.final1072 = extractelement <4 x i32> %863, i64 0
  %864 = lshr i32 %bin.final1072, 16
  %865 = and i32 %bin.final1072, 65535
  %866 = add nuw nsw i32 %864, %865
  %867 = lshr i32 %866, 1
  %868 = lshr i32 %bin.final1521064, 16
  %869 = and i32 %bin.final1521064, 65535
  %870 = add nuw nsw i32 %868, %869
  %871 = lshr i32 %870, 1
  %872 = add nuw nsw i32 %867, %871
  ret i32 %872
}

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 7.0.0 (ssh://git-amr-2.devtools.intel.com:29418/dpd_icl-clang cd5be4ea094f77df25a78b0ab0ead6e58960206c) (ssh://git-amr-2.devtools.intel.com:29418/dpd_icl-llvm f515ae58d78783d4a202c33471bf5e00ce0fc49b)"}
!2 = !{!3, !5, i64 56}
!3 = !{!"struct@", !4, i64 0, !4, i64 56, !4, i64 112, !4, i64 168, !8, i64 224, !4, i64 256, !4, i64 312, !4, i64 368, !9, i64 424, !11, i64 480, !4, i64 536, !13, i64 592, !14, i64 600, !14, i64 632, !16, i64 664, !17, i64 672, !9, i64 680, !11, i64 736, !9, i64 792, !11, i64 848, !18, i64 904, !20, i64 960, !20, i64 968, !20, i64 976, !20, i64 984, !20, i64 992, !20, i64 1000, !20, i64 1008, !20, i64 1016, !20, i64 1024, !20, i64 1032, !20, i64 1040, !20, i64 1048}
!4 = !{!"array@_ZTSA7_PFiPhiS_iE", !5, i64 0}
!5 = !{!"pointer@_ZTSPFiPhiS_iE", !6, i64 0}
!6 = !{!"omnipotent char", !7, i64 0}
!7 = !{!"Simple C/C++ TBAA"}
!8 = !{!"array@_ZTSA4_PFiPhiS_iE", !5, i64 0}
!9 = !{!"array@_ZTSA7_PFvPhS_S_S_iPiE", !10, i64 0}
!10 = !{!"pointer@_ZTSPFvPhS_S_S_iPiE", !6, i64 0}
!11 = !{!"array@_ZTSA7_PFvPhS_S_S_S_iPiE", !12, i64 0}
!12 = !{!"pointer@_ZTSPFvPhS_S_S_S_iPiE", !6, i64 0}
!13 = !{!"pointer@_ZTSPFiPhiS_iPiE", !6, i64 0}
!14 = !{!"array@_ZTSA4_PFmPhiE", !15, i64 0}
!15 = !{!"pointer@_ZTSPFmPhiE", !6, i64 0}
!16 = !{!"pointer@_ZTSPFvPKhiS0_iPA4_iE", !6, i64 0}
!17 = !{!"pointer@_ZTSPFfPA4_iS0_iE", !6, i64 0}
!18 = !{!"array@_ZTSA7_PFiPiPtiS0_PsiiE", !19, i64 0}
!19 = !{!"pointer@_ZTSPFiPiPtiS0_PsiiE", !6, i64 0}
!20 = !{!"pointer@_ZTSPFvPhS_PiE", !6, i64 0}
!21 = !{!6, !6, i64 0}
