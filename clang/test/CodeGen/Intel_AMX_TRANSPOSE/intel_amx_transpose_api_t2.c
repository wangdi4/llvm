// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: intel_feature_isa_amx_transpose
// RUN: %clang_cc1 %s -O2 -flax-vector-conversions=none -ffreestanding -triple=x86_64-unknown-unknown  -target-feature +avx512f  -target-feature +amx-bf16  \
// RUN: -target-feature +amx-transpose \
// RUN: -target-feature +amx-avx512 \
// RUN: -target-feature +amx-int8 \
// RUN: -emit-llvm -o - -Werror -pedantic | FileCheck %s --check-prefixes=CHECK

#include <immintrin.h>

char buf[2048];
#define STRIDE 32

char buf2[2048];

// CHECK-LABEL: @test_tile_t2rpntlvwz0(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call { x86_amx, x86_amx } @llvm.x86.t2rpntlvwz0.internal(i16 [[ROW:%.*]], i16 [[COL0:%.*]], i16 [[COL1:%.*]], ptr nonnull @buf, i64 32)
// CHECK-NEXT:    [[TMP1:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = tail call x86_amx @llvm.x86.tilezero.internal(i16 [[ROW]], i16 [[COL0]])
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP2]])
// CHECK-NEXT:    [[TMP9:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP10:%.*]] = tail call x86_amx @llvm.x86.tdpbssd.internal(i16 [[ROW]], i16 [[COL1]], i16 [[COL0]], x86_amx [[TMP7]], x86_amx [[TMP8]], x86_amx [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP10]])
// CHECK-NEXT:    [[TMP12:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP11]])
// CHECK-NEXT:    tail call void @llvm.x86.tilestored64.internal(i16 [[ROW]], i16 [[COL0]], ptr nonnull @buf2, i64 32, x86_amx [[TMP12]])
// CHECK-NEXT:    ret void
//
void test_tile_t2rpntlvwz0(short row, short col0, short col1) {
  __tile1024i tile0 = {row, col0};
  __tile1024i tile1 = {row, col1};
  __tile1024i dst = {row, col0};

  __tile_t2rpntlvwz0(&tile0, &tile1, buf, STRIDE);

  __tile_zero(/* __tile1024i* */&dst);

  __tile_dpbssd(/* __tile1024i* */&dst, tile0, tile1);

  __tile_stored(buf2, (__SIZE_TYPE__)(STRIDE), dst);
}

// CHECK-LABEL: @test_tile_t2rpntlvwz0t1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call { x86_amx, x86_amx } @llvm.x86.t2rpntlvwz0t1.internal(i16 [[ROW:%.*]], i16 [[COL0:%.*]], i16 [[COL1:%.*]], ptr nonnull @buf, i64 32)
// CHECK-NEXT:    [[TMP1:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = tail call x86_amx @llvm.x86.tilezero.internal(i16 [[ROW]], i16 [[COL0]])
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP2]])
// CHECK-NEXT:    [[TMP9:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP10:%.*]] = tail call x86_amx @llvm.x86.tdpbssd.internal(i16 [[ROW]], i16 [[COL1]], i16 [[COL0]], x86_amx [[TMP7]], x86_amx [[TMP8]], x86_amx [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP10]])
// CHECK-NEXT:    [[TMP12:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP11]])
// CHECK-NEXT:    tail call void @llvm.x86.tilestored64.internal(i16 [[ROW]], i16 [[COL0]], ptr nonnull @buf2, i64 32, x86_amx [[TMP12]])
// CHECK-NEXT:    ret void
//
void test_tile_t2rpntlvwz0t1(short row, short col0, short col1) {
  __tile1024i tile0 = {row, col0};
  __tile1024i tile1 = {row, col1};
  __tile1024i dst = {row, col0};

  __tile_t2rpntlvwz0t1(&tile0, &tile1, buf, STRIDE);

  __tile_zero(&dst);

  __tile_dpbssd(&dst, tile0, tile1);

  __tile_stored(buf2, (__SIZE_TYPE__)(STRIDE), dst);
}

// CHECK-LABEL: @test_tile_t2rpntlvwz1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call { x86_amx, x86_amx } @llvm.x86.t2rpntlvwz1.internal(i16 [[ROW:%.*]], i16 [[COL0:%.*]], i16 [[COL1:%.*]], ptr nonnull @buf, i64 32)
// CHECK-NEXT:    [[TMP1:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = tail call x86_amx @llvm.x86.tilezero.internal(i16 [[ROW]], i16 [[COL0]])
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP2]])
// CHECK-NEXT:    [[TMP9:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP10:%.*]] = tail call x86_amx @llvm.x86.tdpbssd.internal(i16 [[ROW]], i16 [[COL1]], i16 [[COL0]], x86_amx [[TMP7]], x86_amx [[TMP8]], x86_amx [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP10]])
// CHECK-NEXT:    [[TMP12:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP11]])
// CHECK-NEXT:    tail call void @llvm.x86.tilestored64.internal(i16 [[ROW]], i16 [[COL0]], ptr nonnull @buf2, i64 32, x86_amx [[TMP12]])
// CHECK-NEXT:    ret void
//
void test_tile_t2rpntlvwz1(short row, short col0, short col1) {
  __tile1024i tile0 = {row, col0};
  __tile1024i tile1 = {row, col1};
  __tile1024i dst = {row, col0};

  __tile_t2rpntlvwz1(&tile0, &tile1, buf, STRIDE);

  __tile_zero(&dst);

  __tile_dpbssd(&dst, tile0, tile1);

  __tile_stored(buf2, (__SIZE_TYPE__)(STRIDE), dst);
}

// CHECK-LABEL: @test_tile_t2rpntlvwz1t1(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = tail call { x86_amx, x86_amx } @llvm.x86.t2rpntlvwz1t1.internal(i16 [[ROW:%.*]], i16 [[COL0:%.*]], i16 [[COL1:%.*]], ptr nonnull @buf, i64 32)
// CHECK-NEXT:    [[TMP1:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 0
// CHECK-NEXT:    [[TMP2:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP1]])
// CHECK-NEXT:    [[TMP3:%.*]] = extractvalue { x86_amx, x86_amx } [[TMP0]], 1
// CHECK-NEXT:    [[TMP4:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP3]])
// CHECK-NEXT:    [[TMP5:%.*]] = tail call x86_amx @llvm.x86.tilezero.internal(i16 [[ROW]], i16 [[COL0]])
// CHECK-NEXT:    [[TMP6:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP5]])
// CHECK-NEXT:    [[TMP7:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP6]])
// CHECK-NEXT:    [[TMP8:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP2]])
// CHECK-NEXT:    [[TMP9:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP4]])
// CHECK-NEXT:    [[TMP10:%.*]] = tail call x86_amx @llvm.x86.tdpbssd.internal(i16 [[ROW]], i16 [[COL1]], i16 [[COL0]], x86_amx [[TMP7]], x86_amx [[TMP8]], x86_amx [[TMP9]])
// CHECK-NEXT:    [[TMP11:%.*]] = tail call <256 x i32> @llvm.x86.cast.tile.to.vector.v256i32(x86_amx [[TMP10]])
// CHECK-NEXT:    [[TMP12:%.*]] = tail call x86_amx @llvm.x86.cast.vector.to.tile.v256i32(<256 x i32> [[TMP11]])
// CHECK-NEXT:    tail call void @llvm.x86.tilestored64.internal(i16 [[ROW]], i16 [[COL0]], ptr nonnull @buf2, i64 32, x86_amx [[TMP12]])
// CHECK-NEXT:    ret void
//
void test_tile_t2rpntlvwz1t1(short row, short col0, short col1) {
  __tile1024i tile0 = {row, col0};
  __tile1024i tile1 = {row, col1};
  __tile1024i dst = {row, col0};

  __tile_t2rpntlvwz1t1(&tile0, &tile1, buf, STRIDE);

  __tile_zero(&dst);

  __tile_dpbssd(&dst, tile0, tile1);

  __tile_stored(buf2, (__SIZE_TYPE__)(STRIDE), dst);
}
