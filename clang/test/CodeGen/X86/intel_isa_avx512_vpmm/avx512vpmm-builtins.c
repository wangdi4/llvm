// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: intel_feature_isa_avx512_vpmm
// RUN: %clang_cc1 -flax-vector-conversions=none -ffreestanding %s -triple=x86_64-linux-gnu -target-feature +avx512vpmm -target-feature +avx512vl -emit-llvm -o - -Wall -Werror | FileCheck %s

#include <immintrin.h>

// CHECK-LABEL: @test_mm128_vmmxf16_ps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[__DST_LOW_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__DST_HIGH_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__B_ADDR_I:%.*]] = alloca <8 x half>, align 16
// CHECK-NEXT:    [[__C_ADDR_I:%.*]] = alloca <8 x half>, align 16
// CHECK-NEXT:    [[__LOW_ADDR_I:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[__HIGH_ADDR_I:%.*]] = alloca <4 x float>, align 16
// CHECK-NEXT:    [[HIGHPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[LOWPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SRC1_ADDR:%.*]] = alloca <8 x half>, align 16
// CHECK-NEXT:    [[SRC2_ADDR:%.*]] = alloca <8 x half>, align 16
// CHECK-NEXT:    store ptr [[HIGHPTR:%.*]], ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[LOWPTR:%.*]], ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    store <8 x half> [[SRC1:%.*]], ptr [[SRC1_ADDR]], align 16
// CHECK-NEXT:    store <8 x half> [[SRC2:%.*]], ptr [[SRC2_ADDR]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load <8 x half>, ptr [[SRC1_ADDR]], align 16
// CHECK-NEXT:    [[TMP3:%.*]] = load <8 x half>, ptr [[SRC2_ADDR]], align 16
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = load <4 x float>, ptr [[TMP4]], align 16
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load <4 x float>, ptr [[TMP6]], align 16
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    store <8 x half> [[TMP2]], ptr [[__B_ADDR_I]], align 16
// CHECK-NEXT:    store <8 x half> [[TMP3]], ptr [[__C_ADDR_I]], align 16
// CHECK-NEXT:    store <4 x float> [[TMP5]], ptr [[__LOW_ADDR_I]], align 16
// CHECK-NEXT:    store <4 x float> [[TMP7]], ptr [[__HIGH_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load <8 x half>, ptr [[__B_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP11:%.*]] = load <8 x half>, ptr [[__C_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP12:%.*]] = load <4 x float>, ptr [[__HIGH_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP13:%.*]] = load <4 x float>, ptr [[__LOW_ADDR_I]], align 16
// CHECK-NEXT:    [[TMP14:%.*]] = call { <4 x float>, <4 x float> } @llvm.x86.vpmm.vmmxf16ps.128(<4 x float> [[TMP12]], <4 x float> [[TMP13]], <8 x half> [[TMP10]], <8 x half> [[TMP11]])
// CHECK-NEXT:    [[TMP15:%.*]] = extractvalue { <4 x float>, <4 x float> } [[TMP14]], 0
// CHECK-NEXT:    store <4 x float> [[TMP15]], ptr [[TMP9]], align 16
// CHECK-NEXT:    [[TMP16:%.*]] = extractvalue { <4 x float>, <4 x float> } [[TMP14]], 1
// CHECK-NEXT:    store <4 x float> [[TMP16]], ptr [[TMP8]], align 16
// CHECK-NEXT:    ret void
//
void test_mm128_vmmxf16_ps(__m128 *HighPtr, __m128 *LowPtr,
                           __m128h Src1, __m128h Src2) {
  _mm128_vmmxf16_ps(LowPtr, HighPtr, Src1, Src2, *LowPtr, *HighPtr);
}

// CHECK-LABEL: @test_mm256_vmmxf16_ps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[__DST_LOW_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__DST_HIGH_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__B_ADDR_I:%.*]] = alloca <16 x half>, align 32
// CHECK-NEXT:    [[__C_ADDR_I:%.*]] = alloca <16 x half>, align 32
// CHECK-NEXT:    [[__LOW_ADDR_I:%.*]] = alloca <8 x float>, align 32
// CHECK-NEXT:    [[__HIGH_ADDR_I:%.*]] = alloca <8 x float>, align 32
// CHECK-NEXT:    [[HIGHPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[LOWPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SRC1_ADDR:%.*]] = alloca <16 x half>, align 32
// CHECK-NEXT:    [[SRC2_ADDR:%.*]] = alloca <16 x half>, align 32
// CHECK-NEXT:    store ptr [[HIGHPTR:%.*]], ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[LOWPTR:%.*]], ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    store <16 x half> [[SRC1:%.*]], ptr [[SRC1_ADDR]], align 32
// CHECK-NEXT:    store <16 x half> [[SRC2:%.*]], ptr [[SRC2_ADDR]], align 32
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load <16 x half>, ptr [[SRC1_ADDR]], align 32
// CHECK-NEXT:    [[TMP3:%.*]] = load <16 x half>, ptr [[SRC2_ADDR]], align 32
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = load <8 x float>, ptr [[TMP4]], align 32
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load <8 x float>, ptr [[TMP6]], align 32
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    store <16 x half> [[TMP2]], ptr [[__B_ADDR_I]], align 32
// CHECK-NEXT:    store <16 x half> [[TMP3]], ptr [[__C_ADDR_I]], align 32
// CHECK-NEXT:    store <8 x float> [[TMP5]], ptr [[__LOW_ADDR_I]], align 32
// CHECK-NEXT:    store <8 x float> [[TMP7]], ptr [[__HIGH_ADDR_I]], align 32
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load <16 x half>, ptr [[__B_ADDR_I]], align 32
// CHECK-NEXT:    [[TMP11:%.*]] = load <16 x half>, ptr [[__C_ADDR_I]], align 32
// CHECK-NEXT:    [[TMP12:%.*]] = load <8 x float>, ptr [[__HIGH_ADDR_I]], align 32
// CHECK-NEXT:    [[TMP13:%.*]] = load <8 x float>, ptr [[__LOW_ADDR_I]], align 32
// CHECK-NEXT:    [[TMP14:%.*]] = call { <8 x float>, <8 x float> } @llvm.x86.vpmm.vmmxf16ps.256(<8 x float> [[TMP12]], <8 x float> [[TMP13]], <16 x half> [[TMP10]], <16 x half> [[TMP11]])
// CHECK-NEXT:    [[TMP15:%.*]] = extractvalue { <8 x float>, <8 x float> } [[TMP14]], 0
// CHECK-NEXT:    store <8 x float> [[TMP15]], ptr [[TMP9]], align 32
// CHECK-NEXT:    [[TMP16:%.*]] = extractvalue { <8 x float>, <8 x float> } [[TMP14]], 1
// CHECK-NEXT:    store <8 x float> [[TMP16]], ptr [[TMP8]], align 32
// CHECK-NEXT:    ret void
//
void test_mm256_vmmxf16_ps(__m256 *HighPtr, __m256 *LowPtr,
                           __m256h Src1, __m256h Src2) {
  _mm256_vmmxf16_ps(LowPtr, HighPtr, Src1, Src2, *LowPtr, *HighPtr);
}

// CHECK-LABEL: @test_mm512_vmmxf16_ps(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[__DST_LOW_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__DST_HIGH_ADDR_I:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__B_ADDR_I:%.*]] = alloca <32 x half>, align 64
// CHECK-NEXT:    [[__C_ADDR_I:%.*]] = alloca <32 x half>, align 64
// CHECK-NEXT:    [[__LOW_ADDR_I:%.*]] = alloca <16 x float>, align 64
// CHECK-NEXT:    [[__HIGH_ADDR_I:%.*]] = alloca <16 x float>, align 64
// CHECK-NEXT:    [[HIGHPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[LOWPTR_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SRC1_ADDR:%.*]] = alloca <32 x half>, align 64
// CHECK-NEXT:    [[SRC2_ADDR:%.*]] = alloca <32 x half>, align 64
// CHECK-NEXT:    store ptr [[HIGHPTR:%.*]], ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    store ptr [[LOWPTR:%.*]], ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    store <32 x half> [[SRC1:%.*]], ptr [[SRC1_ADDR]], align 64
// CHECK-NEXT:    store <32 x half> [[SRC2:%.*]], ptr [[SRC2_ADDR]], align 64
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load <32 x half>, ptr [[SRC1_ADDR]], align 64
// CHECK-NEXT:    [[TMP3:%.*]] = load <32 x half>, ptr [[SRC2_ADDR]], align 64
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[LOWPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = load <16 x float>, ptr [[TMP4]], align 64
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[HIGHPTR_ADDR]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load <16 x float>, ptr [[TMP6]], align 64
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    store <32 x half> [[TMP2]], ptr [[__B_ADDR_I]], align 64
// CHECK-NEXT:    store <32 x half> [[TMP3]], ptr [[__C_ADDR_I]], align 64
// CHECK-NEXT:    store <16 x float> [[TMP5]], ptr [[__LOW_ADDR_I]], align 64
// CHECK-NEXT:    store <16 x float> [[TMP7]], ptr [[__HIGH_ADDR_I]], align 64
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[__DST_HIGH_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[__DST_LOW_ADDR_I]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load <32 x half>, ptr [[__B_ADDR_I]], align 64
// CHECK-NEXT:    [[TMP11:%.*]] = load <32 x half>, ptr [[__C_ADDR_I]], align 64
// CHECK-NEXT:    [[TMP12:%.*]] = load <16 x float>, ptr [[__HIGH_ADDR_I]], align 64
// CHECK-NEXT:    [[TMP13:%.*]] = load <16 x float>, ptr [[__LOW_ADDR_I]], align 64
// CHECK-NEXT:    [[TMP14:%.*]] = call { <16 x float>, <16 x float> } @llvm.x86.vpmm.vmmxf16ps.512(<16 x float> [[TMP12]], <16 x float> [[TMP13]], <32 x half> [[TMP10]], <32 x half> [[TMP11]])
// CHECK-NEXT:    [[TMP15:%.*]] = extractvalue { <16 x float>, <16 x float> } [[TMP14]], 0
// CHECK-NEXT:    store <16 x float> [[TMP15]], ptr [[TMP9]], align 64
// CHECK-NEXT:    [[TMP16:%.*]] = extractvalue { <16 x float>, <16 x float> } [[TMP14]], 1
// CHECK-NEXT:    store <16 x float> [[TMP16]], ptr [[TMP8]], align 64
// CHECK-NEXT:    ret void
//
void test_mm512_vmmxf16_ps(__m512 *HighPtr, __m512 *LowPtr,
                           __m512h Src1, __m512h Src2) {
  _mm512_vmmxf16_ps(LowPtr, HighPtr, Src1, Src2, *LowPtr, *HighPtr);
}
