// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --prefix-filecheck-ir-name _ --version 3
// Don't rotate (generating CFE collapsed loop).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  -fopenmp-loop-rotation-control=0 | FileCheck %s -check-prefix NROT0

// Don't rotate (generating uncollapsed loops).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -fopenmp-targets=spir64 \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  -fopenmp-loop-rotation-control=0 | FileCheck %s -check-prefix UROT0

// Rotate except uncollapsed loops (generating CFE collapsed loop).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  -fopenmp-loop-rotation-control=1 | FileCheck %s -check-prefix NROT1

// Rotate except uncollapsed loops (generating uncollapsed loops).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -fopenmp-targets=spir64 \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  -fopenmp-loop-rotation-control=1 | FileCheck %s -check-prefix UROT1

// The default is currently '1'.
// Rotate except uncollapsed loops (generating CFE collapsed loop).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  | FileCheck %s -check-prefix NROT1

// Rotate except uncollapsed loops (generating uncollapsed loops).
// RUN: %clang_cc1 -std=c++14 -fopenmp -fintel-compatibility \
// RUN:  -fopenmp-late-outline \
// RUN:  -fopenmp-targets=spir64 \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  | FileCheck %s -check-prefix UROT1


// NROT0-LABEL: define dso_local void @_Z5func1ii(
// NROT0-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0:[0-9]+]] {
// NROT0-NEXT:  entry:
// NROT0-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[_TMP1:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i64, align 8
// NROT0-NEXT:    [[DOTOMP_IV:%.*]] = alloca i64, align 8
// NROT0-NEXT:    [[DOTOMP_LB:%.*]] = alloca i64, align 8
// NROT0-NEXT:    [[DOTOMP_UB:%.*]] = alloca i64, align 8
// NROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[J:%.*]] = alloca i32, align 4
// NROT0-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// NROT0-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// NROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// NROT0-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B2_ADDR]], align 4
// NROT0-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT0-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP2]], 0
// NROT0-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[SUB]], 1
// NROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB2]], 1
// NROT0-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// NROT0-NEXT:    [[CONV:%.*]] = sext i32 [[DIV]] to i64
// NROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[SUB3:%.*]] = sub nsw i32 [[TMP3]], 0
// NROT0-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[SUB3]], 1
// NROT0-NEXT:    [[ADD5:%.*]] = add nsw i32 [[SUB4]], 1
// NROT0-NEXT:    [[DIV6:%.*]] = sdiv i32 [[ADD5]], 1
// NROT0-NEXT:    [[CONV7:%.*]] = sext i32 [[DIV6]] to i64
// NROT0-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV]], [[CONV7]]
// NROT0-NEXT:    [[SUB8:%.*]] = sub nsw i64 [[MUL]], 1
// NROT0-NEXT:    store i64 [[SUB8]], ptr [[DOTCAPTURE_EXPR_2]], align 8
// NROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP4]]
// NROT0-NEXT:    br i1 [[CMP]], label [[LAND_LHS_TRUE:%.*]], label [[OMP_PRECOND_END:%.*]]
// NROT0:       land.lhs.true:
// NROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[CMP9:%.*]] = icmp slt i32 0, [[TMP5]]
// NROT0-NEXT:    br i1 [[CMP9]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END]]
// NROT0:       omp.precond.then:
// NROT0-NEXT:    store i64 0, ptr [[DOTOMP_LB]], align 8
// NROT0-NEXT:    [[TMP6:%.*]] = load i64, ptr [[DOTCAPTURE_EXPR_2]], align 8
// NROT0-NEXT:    store i64 [[TMP6]], ptr [[DOTOMP_UB]], align 8
// NROT0-NEXT:    [[TMP7:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.COLLAPSE"(i32 2), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i64 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i64 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i64 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[DOTCAPTURE_EXPR_1]], i32 0, i32 1) ]
// NROT0-NEXT:    [[TMP8:%.*]] = load i64, ptr [[DOTOMP_LB]], align 8
// NROT0-NEXT:    store i64 [[TMP8]], ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// NROT0:       omp.inner.for.cond:
// NROT0-NEXT:    [[TMP9:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    [[TMP10:%.*]] = load i64, ptr [[DOTOMP_UB]], align 8
// NROT0-NEXT:    [[CMP10:%.*]] = icmp sle i64 [[TMP9]], [[TMP10]]
// NROT0-NEXT:    br i1 [[CMP10]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// NROT0:       omp.inner.for.body:
// NROT0-NEXT:    [[TMP11:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[SUB11:%.*]] = sub nsw i32 [[TMP12]], 0
// NROT0-NEXT:    [[SUB12:%.*]] = sub nsw i32 [[SUB11]], 1
// NROT0-NEXT:    [[ADD13:%.*]] = add nsw i32 [[SUB12]], 1
// NROT0-NEXT:    [[DIV14:%.*]] = sdiv i32 [[ADD13]], 1
// NROT0-NEXT:    [[MUL15:%.*]] = mul nsw i32 1, [[DIV14]]
// NROT0-NEXT:    [[CONV16:%.*]] = sext i32 [[MUL15]] to i64
// NROT0-NEXT:    [[DIV17:%.*]] = sdiv i64 [[TMP11]], [[CONV16]]
// NROT0-NEXT:    [[MUL18:%.*]] = mul nsw i64 [[DIV17]], 1
// NROT0-NEXT:    [[ADD19:%.*]] = add nsw i64 0, [[MUL18]]
// NROT0-NEXT:    [[CONV20:%.*]] = trunc i64 [[ADD19]] to i32
// NROT0-NEXT:    store i32 [[CONV20]], ptr [[I]], align 4
// NROT0-NEXT:    [[TMP13:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    [[TMP14:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[SUB21:%.*]] = sub nsw i32 [[TMP15]], 0
// NROT0-NEXT:    [[SUB22:%.*]] = sub nsw i32 [[SUB21]], 1
// NROT0-NEXT:    [[ADD23:%.*]] = add nsw i32 [[SUB22]], 1
// NROT0-NEXT:    [[DIV24:%.*]] = sdiv i32 [[ADD23]], 1
// NROT0-NEXT:    [[MUL25:%.*]] = mul nsw i32 1, [[DIV24]]
// NROT0-NEXT:    [[CONV26:%.*]] = sext i32 [[MUL25]] to i64
// NROT0-NEXT:    [[DIV27:%.*]] = sdiv i64 [[TMP14]], [[CONV26]]
// NROT0-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT0-NEXT:    [[SUB28:%.*]] = sub nsw i32 [[TMP16]], 0
// NROT0-NEXT:    [[SUB29:%.*]] = sub nsw i32 [[SUB28]], 1
// NROT0-NEXT:    [[ADD30:%.*]] = add nsw i32 [[SUB29]], 1
// NROT0-NEXT:    [[DIV31:%.*]] = sdiv i32 [[ADD30]], 1
// NROT0-NEXT:    [[MUL32:%.*]] = mul nsw i32 1, [[DIV31]]
// NROT0-NEXT:    [[CONV33:%.*]] = sext i32 [[MUL32]] to i64
// NROT0-NEXT:    [[MUL34:%.*]] = mul nsw i64 [[DIV27]], [[CONV33]]
// NROT0-NEXT:    [[SUB35:%.*]] = sub nsw i64 [[TMP13]], [[MUL34]]
// NROT0-NEXT:    [[MUL36:%.*]] = mul nsw i64 [[SUB35]], 1
// NROT0-NEXT:    [[ADD37:%.*]] = add nsw i64 0, [[MUL36]]
// NROT0-NEXT:    [[CONV38:%.*]] = trunc i64 [[ADD37]] to i32
// NROT0-NEXT:    store i32 [[CONV38]], ptr [[J]], align 4
// NROT0-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// NROT0:       omp.body.continue:
// NROT0-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// NROT0:       omp.inner.for.inc:
// NROT0-NEXT:    [[TMP17:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    [[ADD39:%.*]] = add nsw i64 [[TMP17]], 1
// NROT0-NEXT:    store i64 [[ADD39]], ptr [[DOTOMP_IV]], align 8
// NROT0-NEXT:    br label [[OMP_INNER_FOR_COND]]
// NROT0:       omp.inner.for.end:
// NROT0-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// NROT0:       omp.loop.exit:
// NROT0-NEXT:    call void @llvm.directive.region.exit(token [[TMP7]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// NROT0-NEXT:    br label [[OMP_PRECOND_END]]
// NROT0:       omp.precond.end:
// NROT0-NEXT:    ret void
//
// UROT0-LABEL: define dso_local void @_Z5func1ii(
// UROT0-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0:[0-9]+]] {
// UROT0-NEXT:  entry:
// UROT0-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[_TMP1:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_IV:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_IV10:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_LB:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_UB:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_LB17:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[DOTOMP_UNCOLLAPSED_UB18:%.*]] = alloca i64, align 8
// UROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[J:%.*]] = alloca i32, align 4
// UROT0-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// UROT0-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// UROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// UROT0-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B2_ADDR]], align 4
// UROT0-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT0-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP2]], 0
// UROT0-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[SUB]], 1
// UROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB2]], 1
// UROT0-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// UROT0-NEXT:    [[CONV:%.*]] = sext i32 [[DIV]] to i64
// UROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT0-NEXT:    [[SUB3:%.*]] = sub nsw i32 [[TMP3]], 0
// UROT0-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[SUB3]], 1
// UROT0-NEXT:    [[ADD5:%.*]] = add nsw i32 [[SUB4]], 1
// UROT0-NEXT:    [[DIV6:%.*]] = sdiv i32 [[ADD5]], 1
// UROT0-NEXT:    [[CONV7:%.*]] = sext i32 [[DIV6]] to i64
// UROT0-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV]], [[CONV7]]
// UROT0-NEXT:    [[SUB8:%.*]] = sub nsw i64 [[MUL]], 1
// UROT0-NEXT:    store i64 [[SUB8]], ptr [[DOTCAPTURE_EXPR_2]], align 8
// UROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP4]]
// UROT0-NEXT:    br i1 [[CMP]], label [[LAND_LHS_TRUE:%.*]], label [[OMP_PRECOND_END:%.*]]
// UROT0:       land.lhs.true:
// UROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT0-NEXT:    [[CMP9:%.*]] = icmp slt i32 0, [[TMP5]]
// UROT0-NEXT:    br i1 [[CMP9]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END]]
// UROT0:       omp.precond.then:
// UROT0-NEXT:    store i64 0, ptr [[DOTOMP_UNCOLLAPSED_LB]], align 8
// UROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT0-NEXT:    [[SUB11:%.*]] = sub nsw i32 [[TMP6]], 0
// UROT0-NEXT:    [[SUB12:%.*]] = sub nsw i32 [[SUB11]], 1
// UROT0-NEXT:    [[ADD13:%.*]] = add nsw i32 [[SUB12]], 1
// UROT0-NEXT:    [[DIV14:%.*]] = sdiv i32 [[ADD13]], 1
// UROT0-NEXT:    [[CONV15:%.*]] = sext i32 [[DIV14]] to i64
// UROT0-NEXT:    [[SUB16:%.*]] = sub nsw i64 [[CONV15]], 1
// UROT0-NEXT:    store i64 [[SUB16]], ptr [[DOTOMP_UNCOLLAPSED_UB]], align 8
// UROT0-NEXT:    store i64 0, ptr [[DOTOMP_UNCOLLAPSED_LB17]], align 8
// UROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT0-NEXT:    [[SUB19:%.*]] = sub nsw i32 [[TMP7]], 0
// UROT0-NEXT:    [[SUB20:%.*]] = sub nsw i32 [[SUB19]], 1
// UROT0-NEXT:    [[ADD21:%.*]] = add nsw i32 [[SUB20]], 1
// UROT0-NEXT:    [[DIV22:%.*]] = sdiv i32 [[ADD21]], 1
// UROT0-NEXT:    [[CONV23:%.*]] = sext i32 [[DIV22]] to i64
// UROT0-NEXT:    [[SUB24:%.*]] = sub nsw i64 [[CONV23]], 1
// UROT0-NEXT:    store i64 [[SUB24]], ptr [[DOTOMP_UNCOLLAPSED_UB18]], align 8
// UROT0-NEXT:    [[TMP8:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.COLLAPSE"(i32 2), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_IV]], i64 0, ptr [[DOTOMP_UNCOLLAPSED_IV10]], i64 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_LB]], i64 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_UB]], i64 0, ptr [[DOTOMP_UNCOLLAPSED_UB18]], i64 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_LB17]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1) ]
// UROT0-NEXT:    [[TMP9:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_LB]], align 8
// UROT0-NEXT:    store i64 [[TMP9]], ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND:%.*]]
// UROT0:       omp.uncollapsed.loop.cond:
// UROT0-NEXT:    [[TMP10:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT0-NEXT:    [[TMP11:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_UB]], align 8
// UROT0-NEXT:    [[CMP25:%.*]] = icmp sle i64 [[TMP10]], [[TMP11]]
// UROT0-NEXT:    br i1 [[CMP25]], label [[OMP_UNCOLLAPSED_LOOP_BODY:%.*]], label [[OMP_UNCOLLAPSED_LOOP_END38:%.*]]
// UROT0:       omp.uncollapsed.loop.body:
// UROT0-NEXT:    [[TMP12:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_LB17]], align 8
// UROT0-NEXT:    store i64 [[TMP12]], ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND26:%.*]]
// UROT0:       omp.uncollapsed.loop.cond26:
// UROT0-NEXT:    [[TMP13:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT0-NEXT:    [[TMP14:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_UB18]], align 8
// UROT0-NEXT:    [[CMP27:%.*]] = icmp sle i64 [[TMP13]], [[TMP14]]
// UROT0-NEXT:    br i1 [[CMP27]], label [[OMP_UNCOLLAPSED_LOOP_BODY28:%.*]], label [[OMP_UNCOLLAPSED_LOOP_END:%.*]]
// UROT0:       omp.uncollapsed.loop.body28:
// UROT0-NEXT:    [[TMP15:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT0-NEXT:    [[MUL29:%.*]] = mul nsw i64 [[TMP15]], 1
// UROT0-NEXT:    [[ADD30:%.*]] = add nsw i64 0, [[MUL29]]
// UROT0-NEXT:    [[CONV31:%.*]] = trunc i64 [[ADD30]] to i32
// UROT0-NEXT:    store i32 [[CONV31]], ptr [[I]], align 4
// UROT0-NEXT:    [[TMP16:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT0-NEXT:    [[MUL32:%.*]] = mul nsw i64 [[TMP16]], 1
// UROT0-NEXT:    [[ADD33:%.*]] = add nsw i64 0, [[MUL32]]
// UROT0-NEXT:    [[CONV34:%.*]] = trunc i64 [[ADD33]] to i32
// UROT0-NEXT:    store i32 [[CONV34]], ptr [[J]], align 4
// UROT0-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// UROT0:       omp.body.continue:
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_INC:%.*]]
// UROT0:       omp.uncollapsed.loop.inc:
// UROT0-NEXT:    [[TMP17:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT0-NEXT:    [[ADD35:%.*]] = add nsw i64 [[TMP17]], 1
// UROT0-NEXT:    store i64 [[ADD35]], ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND26]]
// UROT0:       omp.uncollapsed.loop.end:
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_INC36:%.*]]
// UROT0:       omp.uncollapsed.loop.inc36:
// UROT0-NEXT:    [[TMP18:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT0-NEXT:    [[ADD37:%.*]] = add nsw i64 [[TMP18]], 1
// UROT0-NEXT:    store i64 [[ADD37]], ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT0-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND]]
// UROT0:       omp.uncollapsed.loop.end38:
// UROT0-NEXT:    call void @llvm.directive.region.exit(token [[TMP8]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// UROT0-NEXT:    br label [[OMP_PRECOND_END]]
// UROT0:       omp.precond.end:
// UROT0-NEXT:    ret void
//
// NROT1-LABEL: define dso_local void @_Z5func1ii(
// NROT1-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0:[0-9]+]] {
// NROT1-NEXT:  entry:
// NROT1-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[_TMP1:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i64, align 8
// NROT1-NEXT:    [[DOTOMP_IV:%.*]] = alloca i64, align 8
// NROT1-NEXT:    [[DOTOMP_LB:%.*]] = alloca i64, align 8
// NROT1-NEXT:    [[DOTOMP_UB:%.*]] = alloca i64, align 8
// NROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[J:%.*]] = alloca i32, align 4
// NROT1-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// NROT1-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// NROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// NROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B2_ADDR]], align 4
// NROT1-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT1-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP2]], 0
// NROT1-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[SUB]], 1
// NROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB2]], 1
// NROT1-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// NROT1-NEXT:    [[CONV:%.*]] = sext i32 [[DIV]] to i64
// NROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[SUB3:%.*]] = sub nsw i32 [[TMP3]], 0
// NROT1-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[SUB3]], 1
// NROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[SUB4]], 1
// NROT1-NEXT:    [[DIV6:%.*]] = sdiv i32 [[ADD5]], 1
// NROT1-NEXT:    [[CONV7:%.*]] = sext i32 [[DIV6]] to i64
// NROT1-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV]], [[CONV7]]
// NROT1-NEXT:    [[SUB8:%.*]] = sub nsw i64 [[MUL]], 1
// NROT1-NEXT:    store i64 [[SUB8]], ptr [[DOTCAPTURE_EXPR_2]], align 8
// NROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// NROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP4]]
// NROT1-NEXT:    br i1 [[CMP]], label [[LAND_LHS_TRUE:%.*]], label [[OMP_PRECOND_END:%.*]]
// NROT1:       land.lhs.true:
// NROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[CMP9:%.*]] = icmp slt i32 0, [[TMP5]]
// NROT1-NEXT:    br i1 [[CMP9]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END]]
// NROT1:       omp.precond.then:
// NROT1-NEXT:    store i64 0, ptr [[DOTOMP_LB]], align 8
// NROT1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[DOTCAPTURE_EXPR_2]], align 8
// NROT1-NEXT:    store i64 [[TMP6]], ptr [[DOTOMP_UB]], align 8
// NROT1-NEXT:    [[TMP7:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.COLLAPSE"(i32 2), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i64 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i64 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i64 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[DOTCAPTURE_EXPR_1]], i32 0, i32 1) ]
// NROT1-NEXT:    [[TMP8:%.*]] = load i64, ptr [[DOTOMP_LB]], align 8
// NROT1-NEXT:    store i64 [[TMP8]], ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP9:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[DOTOMP_UB]], align 8
// NROT1-NEXT:    [[CMP10:%.*]] = icmp sle i64 [[TMP9]], [[TMP10]]
// NROT1-NEXT:    br i1 [[CMP10]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// NROT1:       omp.inner.for.body.lh:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// NROT1:       omp.inner.for.body:
// NROT1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[SUB11:%.*]] = sub nsw i32 [[TMP12]], 0
// NROT1-NEXT:    [[SUB12:%.*]] = sub nsw i32 [[SUB11]], 1
// NROT1-NEXT:    [[ADD13:%.*]] = add nsw i32 [[SUB12]], 1
// NROT1-NEXT:    [[DIV14:%.*]] = sdiv i32 [[ADD13]], 1
// NROT1-NEXT:    [[MUL15:%.*]] = mul nsw i32 1, [[DIV14]]
// NROT1-NEXT:    [[CONV16:%.*]] = sext i32 [[MUL15]] to i64
// NROT1-NEXT:    [[DIV17:%.*]] = sdiv i64 [[TMP11]], [[CONV16]]
// NROT1-NEXT:    [[MUL18:%.*]] = mul nsw i64 [[DIV17]], 1
// NROT1-NEXT:    [[ADD19:%.*]] = add nsw i64 0, [[MUL18]]
// NROT1-NEXT:    [[CONV20:%.*]] = trunc i64 [[ADD19]] to i32
// NROT1-NEXT:    store i32 [[CONV20]], ptr [[I]], align 4
// NROT1-NEXT:    [[TMP13:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP14:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[SUB21:%.*]] = sub nsw i32 [[TMP15]], 0
// NROT1-NEXT:    [[SUB22:%.*]] = sub nsw i32 [[SUB21]], 1
// NROT1-NEXT:    [[ADD23:%.*]] = add nsw i32 [[SUB22]], 1
// NROT1-NEXT:    [[DIV24:%.*]] = sdiv i32 [[ADD23]], 1
// NROT1-NEXT:    [[MUL25:%.*]] = mul nsw i32 1, [[DIV24]]
// NROT1-NEXT:    [[CONV26:%.*]] = sext i32 [[MUL25]] to i64
// NROT1-NEXT:    [[DIV27:%.*]] = sdiv i64 [[TMP14]], [[CONV26]]
// NROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// NROT1-NEXT:    [[SUB28:%.*]] = sub nsw i32 [[TMP16]], 0
// NROT1-NEXT:    [[SUB29:%.*]] = sub nsw i32 [[SUB28]], 1
// NROT1-NEXT:    [[ADD30:%.*]] = add nsw i32 [[SUB29]], 1
// NROT1-NEXT:    [[DIV31:%.*]] = sdiv i32 [[ADD30]], 1
// NROT1-NEXT:    [[MUL32:%.*]] = mul nsw i32 1, [[DIV31]]
// NROT1-NEXT:    [[CONV33:%.*]] = sext i32 [[MUL32]] to i64
// NROT1-NEXT:    [[MUL34:%.*]] = mul nsw i64 [[DIV27]], [[CONV33]]
// NROT1-NEXT:    [[SUB35:%.*]] = sub nsw i64 [[TMP13]], [[MUL34]]
// NROT1-NEXT:    [[MUL36:%.*]] = mul nsw i64 [[SUB35]], 1
// NROT1-NEXT:    [[ADD37:%.*]] = add nsw i64 0, [[MUL36]]
// NROT1-NEXT:    [[CONV38:%.*]] = trunc i64 [[ADD37]] to i32
// NROT1-NEXT:    store i32 [[CONV38]], ptr [[J]], align 4
// NROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// NROT1:       omp.body.continue:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// NROT1:       omp.inner.for.inc:
// NROT1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[ADD39:%.*]] = add nsw i64 [[TMP17]], 1
// NROT1-NEXT:    store i64 [[ADD39]], ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// NROT1-NEXT:    [[TMP19:%.*]] = load i64, ptr [[DOTOMP_UB]], align 8
// NROT1-NEXT:    [[CMP40:%.*]] = icmp sle i64 [[TMP18]], [[TMP19]]
// NROT1-NEXT:    br i1 [[CMP40]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// NROT1:       omp.inner.for.end_crit_edge:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_END]]
// NROT1:       omp.inner.for.end:
// NROT1-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// NROT1:       omp.loop.exit:
// NROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP7]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// NROT1-NEXT:    br label [[OMP_PRECOND_END]]
// NROT1:       omp.precond.end:
// NROT1-NEXT:    ret void
//
// UROT1-LABEL: define dso_local void @_Z5func1ii(
// UROT1-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0:[0-9]+]] {
// UROT1-NEXT:  entry:
// UROT1-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[_TMP1:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_IV:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_IV10:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_LB:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_UB:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_LB17:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[DOTOMP_UNCOLLAPSED_UB18:%.*]] = alloca i64, align 8
// UROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[J:%.*]] = alloca i32, align 4
// UROT1-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// UROT1-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// UROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// UROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[B2_ADDR]], align 4
// UROT1-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT1-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP2]], 0
// UROT1-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[SUB]], 1
// UROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB2]], 1
// UROT1-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// UROT1-NEXT:    [[CONV:%.*]] = sext i32 [[DIV]] to i64
// UROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT1-NEXT:    [[SUB3:%.*]] = sub nsw i32 [[TMP3]], 0
// UROT1-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[SUB3]], 1
// UROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[SUB4]], 1
// UROT1-NEXT:    [[DIV6:%.*]] = sdiv i32 [[ADD5]], 1
// UROT1-NEXT:    [[CONV7:%.*]] = sext i32 [[DIV6]] to i64
// UROT1-NEXT:    [[MUL:%.*]] = mul nsw i64 [[CONV]], [[CONV7]]
// UROT1-NEXT:    [[SUB8:%.*]] = sub nsw i64 [[MUL]], 1
// UROT1-NEXT:    store i64 [[SUB8]], ptr [[DOTCAPTURE_EXPR_2]], align 8
// UROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP4]]
// UROT1-NEXT:    br i1 [[CMP]], label [[LAND_LHS_TRUE:%.*]], label [[OMP_PRECOND_END:%.*]]
// UROT1:       land.lhs.true:
// UROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT1-NEXT:    [[CMP9:%.*]] = icmp slt i32 0, [[TMP5]]
// UROT1-NEXT:    br i1 [[CMP9]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END]]
// UROT1:       omp.precond.then:
// UROT1-NEXT:    store i64 0, ptr [[DOTOMP_UNCOLLAPSED_LB]], align 8
// UROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// UROT1-NEXT:    [[SUB11:%.*]] = sub nsw i32 [[TMP6]], 0
// UROT1-NEXT:    [[SUB12:%.*]] = sub nsw i32 [[SUB11]], 1
// UROT1-NEXT:    [[ADD13:%.*]] = add nsw i32 [[SUB12]], 1
// UROT1-NEXT:    [[DIV14:%.*]] = sdiv i32 [[ADD13]], 1
// UROT1-NEXT:    [[CONV15:%.*]] = sext i32 [[DIV14]] to i64
// UROT1-NEXT:    [[SUB16:%.*]] = sub nsw i64 [[CONV15]], 1
// UROT1-NEXT:    store i64 [[SUB16]], ptr [[DOTOMP_UNCOLLAPSED_UB]], align 8
// UROT1-NEXT:    store i64 0, ptr [[DOTOMP_UNCOLLAPSED_LB17]], align 8
// UROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// UROT1-NEXT:    [[SUB19:%.*]] = sub nsw i32 [[TMP7]], 0
// UROT1-NEXT:    [[SUB20:%.*]] = sub nsw i32 [[SUB19]], 1
// UROT1-NEXT:    [[ADD21:%.*]] = add nsw i32 [[SUB20]], 1
// UROT1-NEXT:    [[DIV22:%.*]] = sdiv i32 [[ADD21]], 1
// UROT1-NEXT:    [[CONV23:%.*]] = sext i32 [[DIV22]] to i64
// UROT1-NEXT:    [[SUB24:%.*]] = sub nsw i64 [[CONV23]], 1
// UROT1-NEXT:    store i64 [[SUB24]], ptr [[DOTOMP_UNCOLLAPSED_UB18]], align 8
// UROT1-NEXT:    [[TMP8:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.COLLAPSE"(i32 2), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_IV]], i64 0, ptr [[DOTOMP_UNCOLLAPSED_IV10]], i64 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_LB]], i64 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_UB]], i64 0, ptr [[DOTOMP_UNCOLLAPSED_UB18]], i64 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_UNCOLLAPSED_LB17]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1) ]
// UROT1-NEXT:    [[TMP9:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_LB]], align 8
// UROT1-NEXT:    store i64 [[TMP9]], ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND:%.*]]
// UROT1:       omp.uncollapsed.loop.cond:
// UROT1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_UB]], align 8
// UROT1-NEXT:    [[CMP25:%.*]] = icmp sle i64 [[TMP10]], [[TMP11]]
// UROT1-NEXT:    br i1 [[CMP25]], label [[OMP_UNCOLLAPSED_LOOP_BODY:%.*]], label [[OMP_UNCOLLAPSED_LOOP_END38:%.*]]
// UROT1:       omp.uncollapsed.loop.body:
// UROT1-NEXT:    [[TMP12:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_LB17]], align 8
// UROT1-NEXT:    store i64 [[TMP12]], ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND26:%.*]]
// UROT1:       omp.uncollapsed.loop.cond26:
// UROT1-NEXT:    [[TMP13:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT1-NEXT:    [[TMP14:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_UB18]], align 8
// UROT1-NEXT:    [[CMP27:%.*]] = icmp sle i64 [[TMP13]], [[TMP14]]
// UROT1-NEXT:    br i1 [[CMP27]], label [[OMP_UNCOLLAPSED_LOOP_BODY28:%.*]], label [[OMP_UNCOLLAPSED_LOOP_END:%.*]]
// UROT1:       omp.uncollapsed.loop.body28:
// UROT1-NEXT:    [[TMP15:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT1-NEXT:    [[MUL29:%.*]] = mul nsw i64 [[TMP15]], 1
// UROT1-NEXT:    [[ADD30:%.*]] = add nsw i64 0, [[MUL29]]
// UROT1-NEXT:    [[CONV31:%.*]] = trunc i64 [[ADD30]] to i32
// UROT1-NEXT:    store i32 [[CONV31]], ptr [[I]], align 4
// UROT1-NEXT:    [[TMP16:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT1-NEXT:    [[MUL32:%.*]] = mul nsw i64 [[TMP16]], 1
// UROT1-NEXT:    [[ADD33:%.*]] = add nsw i64 0, [[MUL32]]
// UROT1-NEXT:    [[CONV34:%.*]] = trunc i64 [[ADD33]] to i32
// UROT1-NEXT:    store i32 [[CONV34]], ptr [[J]], align 4
// UROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// UROT1:       omp.body.continue:
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_INC:%.*]]
// UROT1:       omp.uncollapsed.loop.inc:
// UROT1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT1-NEXT:    [[ADD35:%.*]] = add nsw i64 [[TMP17]], 1
// UROT1-NEXT:    store i64 [[ADD35]], ptr [[DOTOMP_UNCOLLAPSED_IV10]], align 8
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND26]]
// UROT1:       omp.uncollapsed.loop.end:
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_INC36:%.*]]
// UROT1:       omp.uncollapsed.loop.inc36:
// UROT1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT1-NEXT:    [[ADD37:%.*]] = add nsw i64 [[TMP18]], 1
// UROT1-NEXT:    store i64 [[ADD37]], ptr [[DOTOMP_UNCOLLAPSED_IV]], align 8
// UROT1-NEXT:    br label [[OMP_UNCOLLAPSED_LOOP_COND]]
// UROT1:       omp.uncollapsed.loop.end38:
// UROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP8]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// UROT1-NEXT:    br label [[OMP_PRECOND_END]]
// UROT1:       omp.precond.end:
// UROT1-NEXT:    ret void
//
void func1(int B1, int B2)
{
  #pragma omp parallel for collapse(2)
  for (int I = 0; I < B1; ++I) {
    for (int J = 0; J < B2; ++J) {
    }
  }
}

// NROT0-LABEL: define dso_local void @_Z5func2ii(
// NROT0-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0]] {
// NROT0-NEXT:  entry:
// NROT0-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// NROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// NROT0-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// NROT0-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// NROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// NROT0-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT0-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP1]], 0
// NROT0-NEXT:    [[SUB1:%.*]] = sub nsw i32 [[SUB]], 1
// NROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB1]], 1
// NROT0-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// NROT0-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[DIV]], 1
// NROT0-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// NROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP2]]
// NROT0-NEXT:    br i1 [[CMP]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END:%.*]]
// NROT0:       omp.precond.then:
// NROT0-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// NROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// NROT0-NEXT:    store i32 [[TMP3]], ptr [[DOTOMP_UB]], align 4
// NROT0-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// NROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// NROT0-NEXT:    store i32 [[TMP5]], ptr [[DOTOMP_IV]], align 4
// NROT0-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// NROT0:       omp.inner.for.cond:
// NROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// NROT0-NEXT:    [[CMP3:%.*]] = icmp sle i32 [[TMP6]], [[TMP7]]
// NROT0-NEXT:    br i1 [[CMP3]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// NROT0:       omp.inner.for.body:
// NROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT0-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP8]], 1
// NROT0-NEXT:    [[ADD4:%.*]] = add nsw i32 0, [[MUL]]
// NROT0-NEXT:    store i32 [[ADD4]], ptr [[I]], align 4
// NROT0-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// NROT0:       omp.body.continue:
// NROT0-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// NROT0:       omp.inner.for.inc:
// NROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT0-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 1
// NROT0-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// NROT0-NEXT:    br label [[OMP_INNER_FOR_COND]]
// NROT0:       omp.inner.for.end:
// NROT0-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// NROT0:       omp.loop.exit:
// NROT0-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// NROT0-NEXT:    br label [[OMP_PRECOND_END]]
// NROT0:       omp.precond.end:
// NROT0-NEXT:    ret void
//
// UROT0-LABEL: define dso_local void @_Z5func2ii(
// UROT0-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0]] {
// UROT0-NEXT:  entry:
// UROT0-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// UROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// UROT0-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// UROT0-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// UROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// UROT0-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT0-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP1]], 0
// UROT0-NEXT:    [[SUB1:%.*]] = sub nsw i32 [[SUB]], 1
// UROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB1]], 1
// UROT0-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// UROT0-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[DIV]], 1
// UROT0-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// UROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP2]]
// UROT0-NEXT:    br i1 [[CMP]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END:%.*]]
// UROT0:       omp.precond.then:
// UROT0-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// UROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// UROT0-NEXT:    store i32 [[TMP3]], ptr [[DOTOMP_UB]], align 4
// UROT0-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// UROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// UROT0-NEXT:    store i32 [[TMP5]], ptr [[DOTOMP_IV]], align 4
// UROT0-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// UROT0:       omp.inner.for.cond:
// UROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// UROT0-NEXT:    [[CMP3:%.*]] = icmp sle i32 [[TMP6]], [[TMP7]]
// UROT0-NEXT:    br i1 [[CMP3]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// UROT0:       omp.inner.for.body:
// UROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT0-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP8]], 1
// UROT0-NEXT:    [[ADD4:%.*]] = add nsw i32 0, [[MUL]]
// UROT0-NEXT:    store i32 [[ADD4]], ptr [[I]], align 4
// UROT0-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// UROT0:       omp.body.continue:
// UROT0-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// UROT0:       omp.inner.for.inc:
// UROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT0-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 1
// UROT0-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// UROT0-NEXT:    br label [[OMP_INNER_FOR_COND]]
// UROT0:       omp.inner.for.end:
// UROT0-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// UROT0:       omp.loop.exit:
// UROT0-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// UROT0-NEXT:    br label [[OMP_PRECOND_END]]
// UROT0:       omp.precond.end:
// UROT0-NEXT:    ret void
//
// NROT1-LABEL: define dso_local void @_Z5func2ii(
// NROT1-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0]] {
// NROT1-NEXT:  entry:
// NROT1-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// NROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// NROT1-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// NROT1-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// NROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// NROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT1-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP1]], 0
// NROT1-NEXT:    [[SUB1:%.*]] = sub nsw i32 [[SUB]], 1
// NROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB1]], 1
// NROT1-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// NROT1-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[DIV]], 1
// NROT1-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// NROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// NROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP2]]
// NROT1-NEXT:    br i1 [[CMP]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END:%.*]]
// NROT1:       omp.precond.then:
// NROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// NROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// NROT1-NEXT:    store i32 [[TMP3]], ptr [[DOTOMP_UB]], align 4
// NROT1-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// NROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// NROT1-NEXT:    store i32 [[TMP5]], ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// NROT1-NEXT:    [[CMP3:%.*]] = icmp sle i32 [[TMP6]], [[TMP7]]
// NROT1-NEXT:    br i1 [[CMP3]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// NROT1:       omp.inner.for.body.lh:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// NROT1:       omp.inner.for.body:
// NROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP8]], 1
// NROT1-NEXT:    [[ADD4:%.*]] = add nsw i32 0, [[MUL]]
// NROT1-NEXT:    store i32 [[ADD4]], ptr [[I]], align 4
// NROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// NROT1:       omp.body.continue:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// NROT1:       omp.inner.for.inc:
// NROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 1
// NROT1-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// NROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// NROT1-NEXT:    [[CMP6:%.*]] = icmp sle i32 [[TMP10]], [[TMP11]]
// NROT1-NEXT:    br i1 [[CMP6]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// NROT1:       omp.inner.for.end_crit_edge:
// NROT1-NEXT:    br label [[OMP_INNER_FOR_END]]
// NROT1:       omp.inner.for.end:
// NROT1-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// NROT1:       omp.loop.exit:
// NROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// NROT1-NEXT:    br label [[OMP_PRECOND_END]]
// NROT1:       omp.precond.end:
// NROT1-NEXT:    ret void
//
// UROT1-LABEL: define dso_local void @_Z5func2ii(
// UROT1-SAME: i32 noundef [[B1:%.*]], i32 noundef [[B2:%.*]]) #[[ATTR0]] {
// UROT1-NEXT:  entry:
// UROT1-NEXT:    [[B1_ADDR:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[B2_ADDR:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// UROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// UROT1-NEXT:    store i32 [[B1]], ptr [[B1_ADDR]], align 4
// UROT1-NEXT:    store i32 [[B2]], ptr [[B2_ADDR]], align 4
// UROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[B1_ADDR]], align 4
// UROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT1-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP1]], 0
// UROT1-NEXT:    [[SUB1:%.*]] = sub nsw i32 [[SUB]], 1
// UROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB1]], 1
// UROT1-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// UROT1-NEXT:    [[SUB2:%.*]] = sub nsw i32 [[DIV]], 1
// UROT1-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// UROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// UROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP2]]
// UROT1-NEXT:    br i1 [[CMP]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END:%.*]]
// UROT1:       omp.precond.then:
// UROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// UROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// UROT1-NEXT:    store i32 [[TMP3]], ptr [[DOTOMP_UB]], align 4
// UROT1-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// UROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// UROT1-NEXT:    store i32 [[TMP5]], ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// UROT1-NEXT:    [[CMP3:%.*]] = icmp sle i32 [[TMP6]], [[TMP7]]
// UROT1-NEXT:    br i1 [[CMP3]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// UROT1:       omp.inner.for.body.lh:
// UROT1-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// UROT1:       omp.inner.for.body:
// UROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP8]], 1
// UROT1-NEXT:    [[ADD4:%.*]] = add nsw i32 0, [[MUL]]
// UROT1-NEXT:    store i32 [[ADD4]], ptr [[I]], align 4
// UROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// UROT1:       omp.body.continue:
// UROT1-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// UROT1:       omp.inner.for.inc:
// UROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 1
// UROT1-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// UROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// UROT1-NEXT:    [[CMP6:%.*]] = icmp sle i32 [[TMP10]], [[TMP11]]
// UROT1-NEXT:    br i1 [[CMP6]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// UROT1:       omp.inner.for.end_crit_edge:
// UROT1-NEXT:    br label [[OMP_INNER_FOR_END]]
// UROT1:       omp.inner.for.end:
// UROT1-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// UROT1:       omp.loop.exit:
// UROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// UROT1-NEXT:    br label [[OMP_PRECOND_END]]
// UROT1:       omp.precond.end:
// UROT1-NEXT:    ret void
//
void func2(int B1, int B2)
{
  #pragma omp parallel for
  for (int I = 0; I < B1; ++I) {
  }
}
