// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --prefix-filecheck-ir-name _
// RUN: %clang_cc1 -verify -triple x86_64-pc-linux-gnu -fopenmp \
// RUN:  -fopenmp-version=51 -fopenmp-loop-rotation-control=0 \
// RUN:  -fopenmp-late-outline -emit-llvm %s -o - \
// RUN:  | FileCheck %s -check-prefix ROT0

// RUN: %clang_cc1 -verify -triple x86_64-pc-linux-gnu -fopenmp \
// RUN:  -fopenmp-version=51 -fopenmp-loop-rotation-control=1 \
// RUN:  -fopenmp-late-outline -emit-llvm %s -o - \
// RUN:  | FileCheck %s -check-prefix ROT1

// expected-no-diagnostics
//
//  The implementation of standalone 'omp tile' completely reuses the community
//  codegen, and is therefore fully covered by the community lit tests.
//
//  When 'omp tile' is used under a late-outlined directive the original loop
//  counters must be handled on the late-outlined directive, otherwise they
//  would end up 'shared' by default.

void body(int);

// ROT0-LABEL: @_Z4foo1iii(
// ROT0-NEXT:  entry:
// ROT0-NEXT:    [[START_ADDR:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[END_ADDR:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTNEW_STEP2:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    store i32 [[START:%.*]], ptr [[START_ADDR]], align 4
// ROT0-NEXT:    store i32 [[END:%.*]], ptr [[END_ADDR]], align 4
// ROT0-NEXT:    store i32 [[STEP:%.*]], ptr [[STEP_ADDR]], align 4
// ROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[START_ADDR]], align 4
// ROT0-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[END_ADDR]], align 4
// ROT0-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[STEP_ADDR]], align 4
// ROT0-NEXT:    store i32 [[TMP2]], ptr [[DOTNEW_STEP2]], align 4
// ROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT0-NEXT:    [[SUB:%.*]] = sub i32 [[TMP3]], [[TMP4]]
// ROT0-NEXT:    [[SUB1:%.*]] = sub i32 [[SUB]], 1
// ROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT0-NEXT:    [[ADD:%.*]] = add i32 [[SUB1]], [[TMP5]]
// ROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT0-NEXT:    [[DIV:%.*]] = udiv i32 [[ADD]], [[TMP6]]
// ROT0-NEXT:    [[SUB2:%.*]] = sub i32 [[DIV]], 1
// ROT0-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND:%.*]]
// ROT0:       for.cond:
// ROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT0-NEXT:    [[ADD3:%.*]] = add i32 [[TMP8]], 1
// ROT0-NEXT:    [[CMP:%.*]] = icmp ult i32 [[TMP7]], [[ADD3]]
// ROT0-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END15:%.*]]
// ROT0:       for.body:
// ROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    store i32 [[TMP9]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4:%.*]]
// ROT0:       for.cond4:
// ROT0-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT0-NEXT:    [[ADD5:%.*]] = add i32 [[TMP11]], 1
// ROT0-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP12]], 5
// ROT0-NEXT:    [[CMP7:%.*]] = icmp ult i32 [[ADD5]], [[ADD6]]
// ROT0-NEXT:    br i1 [[CMP7]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT0:       cond.true:
// ROT0-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT0-NEXT:    [[ADD8:%.*]] = add i32 [[TMP13]], 1
// ROT0-NEXT:    br label [[COND_END:%.*]]
// ROT0:       cond.false:
// ROT0-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD9:%.*]] = add nsw i32 [[TMP14]], 5
// ROT0-NEXT:    br label [[COND_END]]
// ROT0:       cond.end:
// ROT0-NEXT:    [[COND:%.*]] = phi i32 [ [[ADD8]], [[COND_TRUE]] ], [ [[ADD9]], [[COND_FALSE]] ]
// ROT0-NEXT:    [[CMP10:%.*]] = icmp ult i32 [[TMP10]], [[COND]]
// ROT0-NEXT:    br i1 [[CMP10]], label [[FOR_BODY11:%.*]], label [[FOR_END:%.*]]
// ROT0:       for.body11:
// ROT0-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT0-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT0-NEXT:    [[MUL:%.*]] = mul i32 [[TMP16]], [[TMP17]]
// ROT0-NEXT:    [[ADD12:%.*]] = add i32 [[TMP15]], [[MUL]]
// ROT0-NEXT:    store i32 [[ADD12]], ptr [[I]], align 4
// ROT0-NEXT:    [[TMP18:%.*]] = load i32, ptr [[I]], align 4
// ROT0-NEXT:    call void @_Z4bodyi(i32 noundef [[TMP18]])
// ROT0-NEXT:    br label [[FOR_INC:%.*]]
// ROT0:       for.inc:
// ROT0-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP19]], 1
// ROT0-NEXT:    store i32 [[INC]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP3:![0-9]+]]
// ROT0:       for.end:
// ROT0-NEXT:    br label [[FOR_INC13:%.*]]
// ROT0:       for.inc13:
// ROT0-NEXT:    [[TMP20:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD14:%.*]] = add nsw i32 [[TMP20]], 5
// ROT0-NEXT:    store i32 [[ADD14]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP5:![0-9]+]]
// ROT0:       for.end15:
// ROT0-NEXT:    ret void
//
// ROT1-LABEL: @_Z4foo1iii(
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[START_ADDR:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[END_ADDR:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[STEP_ADDR:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTNEW_STEP2:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    store i32 [[START:%.*]], ptr [[START_ADDR]], align 4
// ROT1-NEXT:    store i32 [[END:%.*]], ptr [[END_ADDR]], align 4
// ROT1-NEXT:    store i32 [[STEP:%.*]], ptr [[STEP_ADDR]], align 4
// ROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[START_ADDR]], align 4
// ROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[END_ADDR]], align 4
// ROT1-NEXT:    store i32 [[TMP1]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[STEP_ADDR]], align 4
// ROT1-NEXT:    store i32 [[TMP2]], ptr [[DOTNEW_STEP2]], align 4
// ROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT1-NEXT:    [[SUB:%.*]] = sub i32 [[TMP3]], [[TMP4]]
// ROT1-NEXT:    [[SUB1:%.*]] = sub i32 [[SUB]], 1
// ROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT1-NEXT:    [[ADD:%.*]] = add i32 [[SUB1]], [[TMP5]]
// ROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT1-NEXT:    [[DIV:%.*]] = udiv i32 [[ADD]], [[TMP6]]
// ROT1-NEXT:    [[SUB2:%.*]] = sub i32 [[DIV]], 1
// ROT1-NEXT:    store i32 [[SUB2]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND:%.*]]
// ROT1:       for.cond:
// ROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    [[ADD3:%.*]] = add i32 [[TMP8]], 1
// ROT1-NEXT:    [[CMP:%.*]] = icmp ult i32 [[TMP7]], [[ADD3]]
// ROT1-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END15:%.*]]
// ROT1:       for.body:
// ROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    store i32 [[TMP9]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4:%.*]]
// ROT1:       for.cond4:
// ROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    [[ADD5:%.*]] = add i32 [[TMP11]], 1
// ROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP12]], 5
// ROT1-NEXT:    [[CMP7:%.*]] = icmp ult i32 [[ADD5]], [[ADD6]]
// ROT1-NEXT:    br i1 [[CMP7]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT1:       cond.true:
// ROT1-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    [[ADD8:%.*]] = add i32 [[TMP13]], 1
// ROT1-NEXT:    br label [[COND_END:%.*]]
// ROT1:       cond.false:
// ROT1-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD9:%.*]] = add nsw i32 [[TMP14]], 5
// ROT1-NEXT:    br label [[COND_END]]
// ROT1:       cond.end:
// ROT1-NEXT:    [[COND:%.*]] = phi i32 [ [[ADD8]], [[COND_TRUE]] ], [ [[ADD9]], [[COND_FALSE]] ]
// ROT1-NEXT:    [[CMP10:%.*]] = icmp ult i32 [[TMP10]], [[COND]]
// ROT1-NEXT:    br i1 [[CMP10]], label [[FOR_BODY11:%.*]], label [[FOR_END:%.*]]
// ROT1:       for.body11:
// ROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTNEW_STEP2]], align 4
// ROT1-NEXT:    [[MUL:%.*]] = mul i32 [[TMP16]], [[TMP17]]
// ROT1-NEXT:    [[ADD12:%.*]] = add i32 [[TMP15]], [[MUL]]
// ROT1-NEXT:    store i32 [[ADD12]], ptr [[I]], align 4
// ROT1-NEXT:    [[TMP18:%.*]] = load i32, ptr [[I]], align 4
// ROT1-NEXT:    call void @_Z4bodyi(i32 noundef [[TMP18]])
// ROT1-NEXT:    br label [[FOR_INC:%.*]]
// ROT1:       for.inc:
// ROT1-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP19]], 1
// ROT1-NEXT:    store i32 [[INC]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP3:![0-9]+]]
// ROT1:       for.end:
// ROT1-NEXT:    br label [[FOR_INC13:%.*]]
// ROT1:       for.inc13:
// ROT1-NEXT:    [[TMP20:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD14:%.*]] = add nsw i32 [[TMP20]], 5
// ROT1-NEXT:    store i32 [[ADD14]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP5:![0-9]+]]
// ROT1:       for.end15:
// ROT1-NEXT:    ret void
//
void foo1(int start, int end, int step) {
  int i;
  #pragma omp tile sizes(5)
  for (i = start; i < end; i += step)
    body(i);
}

// ROT0-LABEL: @_Z4foo2v(
// ROT0-NEXT:  entry:
// ROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    store i32 0, ptr [[I]], align 4
// ROT0-NEXT:    store i32 0, ptr [[J]], align 4
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND:%.*]]
// ROT0:       for.cond:
// ROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP0]], 8
// ROT0-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END31:%.*]]
// ROT0:       for.body:
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND1:%.*]]
// ROT0:       for.cond1:
// ROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[CMP2:%.*]] = icmp slt i32 [[TMP1]], 4
// ROT0-NEXT:    br i1 [[CMP2]], label [[FOR_BODY3:%.*]], label [[FOR_END28:%.*]]
// ROT0:       for.body3:
// ROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    store i32 [[TMP2]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4:%.*]]
// ROT0:       for.cond4:
// ROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP4]], 4
// ROT0-NEXT:    [[CMP5:%.*]] = icmp slt i32 8, [[ADD]]
// ROT0-NEXT:    br i1 [[CMP5]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT0:       cond.true:
// ROT0-NEXT:    br label [[COND_END:%.*]]
// ROT0:       cond.false:
// ROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP5]], 4
// ROT0-NEXT:    br label [[COND_END]]
// ROT0:       cond.end:
// ROT0-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD6]], [[COND_FALSE]] ]
// ROT0-NEXT:    [[CMP7:%.*]] = icmp slt i32 [[TMP3]], [[COND]]
// ROT0-NEXT:    br i1 [[CMP7]], label [[FOR_BODY8:%.*]], label [[FOR_END25:%.*]]
// ROT0:       for.body8:
// ROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP6]], 1
// ROT0-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL]]
// ROT0-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    store i32 [[TMP7]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10:%.*]]
// ROT0:       for.cond10:
// ROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP9]], 2
// ROT0-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT0-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT0:       cond.true13:
// ROT0-NEXT:    br label [[COND_END16:%.*]]
// ROT0:       cond.false14:
// ROT0-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP10]], 2
// ROT0-NEXT:    br label [[COND_END16]]
// ROT0:       cond.end16:
// ROT0-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT0-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP8]], [[COND17]]
// ROT0-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT0:       for.body19:
// ROT0-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP11]], 1
// ROT0-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT0-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT0-NEXT:    [[TMP12:%.*]] = load i32, ptr [[I]], align 4
// ROT0-NEXT:    [[TMP13:%.*]] = load i32, ptr [[J]], align 4
// ROT0-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP12]], [[TMP13]]
// ROT0-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]])
// ROT0-NEXT:    br label [[FOR_INC:%.*]]
// ROT0:       for.inc:
// ROT0-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP14]], 1
// ROT0-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP6:![0-9]+]]
// ROT0:       for.end:
// ROT0-NEXT:    br label [[FOR_INC23:%.*]]
// ROT0:       for.inc23:
// ROT0-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP15]], 1
// ROT0-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP7:![0-9]+]]
// ROT0:       for.end25:
// ROT0-NEXT:    br label [[FOR_INC26:%.*]]
// ROT0:       for.inc26:
// ROT0-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP16]], 2
// ROT0-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND1]], !llvm.loop [[LOOP8:![0-9]+]]
// ROT0:       for.end28:
// ROT0-NEXT:    br label [[FOR_INC29:%.*]]
// ROT0:       for.inc29:
// ROT0-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD30:%.*]] = add nsw i32 [[TMP17]], 4
// ROT0-NEXT:    store i32 [[ADD30]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP9:![0-9]+]]
// ROT0:       for.end31:
// ROT0-NEXT:    ret void
//
// ROT1-LABEL: @_Z4foo2v(
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    store i32 0, ptr [[I]], align 4
// ROT1-NEXT:    store i32 0, ptr [[J]], align 4
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND:%.*]]
// ROT1:       for.cond:
// ROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP0]], 8
// ROT1-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END31:%.*]]
// ROT1:       for.body:
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND1:%.*]]
// ROT1:       for.cond1:
// ROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[CMP2:%.*]] = icmp slt i32 [[TMP1]], 4
// ROT1-NEXT:    br i1 [[CMP2]], label [[FOR_BODY3:%.*]], label [[FOR_END28:%.*]]
// ROT1:       for.body3:
// ROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    store i32 [[TMP2]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4:%.*]]
// ROT1:       for.cond4:
// ROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP4]], 4
// ROT1-NEXT:    [[CMP5:%.*]] = icmp slt i32 8, [[ADD]]
// ROT1-NEXT:    br i1 [[CMP5]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT1:       cond.true:
// ROT1-NEXT:    br label [[COND_END:%.*]]
// ROT1:       cond.false:
// ROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP5]], 4
// ROT1-NEXT:    br label [[COND_END]]
// ROT1:       cond.end:
// ROT1-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD6]], [[COND_FALSE]] ]
// ROT1-NEXT:    [[CMP7:%.*]] = icmp slt i32 [[TMP3]], [[COND]]
// ROT1-NEXT:    br i1 [[CMP7]], label [[FOR_BODY8:%.*]], label [[FOR_END25:%.*]]
// ROT1:       for.body8:
// ROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP6]], 1
// ROT1-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL]]
// ROT1-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    store i32 [[TMP7]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10:%.*]]
// ROT1:       for.cond10:
// ROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP9]], 2
// ROT1-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT1-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT1:       cond.true13:
// ROT1-NEXT:    br label [[COND_END16:%.*]]
// ROT1:       cond.false14:
// ROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP10]], 2
// ROT1-NEXT:    br label [[COND_END16]]
// ROT1:       cond.end16:
// ROT1-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT1-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP8]], [[COND17]]
// ROT1-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT1:       for.body19:
// ROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP11]], 1
// ROT1-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT1-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[I]], align 4
// ROT1-NEXT:    [[TMP13:%.*]] = load i32, ptr [[J]], align 4
// ROT1-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP12]], [[TMP13]]
// ROT1-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]])
// ROT1-NEXT:    br label [[FOR_INC:%.*]]
// ROT1:       for.inc:
// ROT1-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP14]], 1
// ROT1-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP6:![0-9]+]]
// ROT1:       for.end:
// ROT1-NEXT:    br label [[FOR_INC23:%.*]]
// ROT1:       for.inc23:
// ROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP15]], 1
// ROT1-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP7:![0-9]+]]
// ROT1:       for.end25:
// ROT1-NEXT:    br label [[FOR_INC26:%.*]]
// ROT1:       for.inc26:
// ROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP16]], 2
// ROT1-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND1]], !llvm.loop [[LOOP8:![0-9]+]]
// ROT1:       for.end28:
// ROT1-NEXT:    br label [[FOR_INC29:%.*]]
// ROT1:       for.inc29:
// ROT1-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD30:%.*]] = add nsw i32 [[TMP17]], 4
// ROT1-NEXT:    store i32 [[ADD30]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP9:![0-9]+]]
// ROT1:       for.end31:
// ROT1-NEXT:    ret void
//
void foo2() {
  #pragma omp tile sizes(4,2)  // evenly divisible
  for (int i = 0; i < 8; ++i)
    for (int j = 0; j < 4; ++j)
      body(i+j);
}

// ROT0-LABEL: @_Z4foo3v(
// ROT0-NEXT:  entry:
// ROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    store i32 0, ptr [[I]], align 4
// ROT0-NEXT:    store i32 0, ptr [[J]], align 4
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND:%.*]]
// ROT0:       for.cond:
// ROT0-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP0]], 8
// ROT0-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END31:%.*]]
// ROT0:       for.body:
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND1:%.*]]
// ROT0:       for.cond1:
// ROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[CMP2:%.*]] = icmp slt i32 [[TMP1]], 4
// ROT0-NEXT:    br i1 [[CMP2]], label [[FOR_BODY3:%.*]], label [[FOR_END28:%.*]]
// ROT0:       for.body3:
// ROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    store i32 [[TMP2]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4:%.*]]
// ROT0:       for.cond4:
// ROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP4]], 3
// ROT0-NEXT:    [[CMP5:%.*]] = icmp slt i32 8, [[ADD]]
// ROT0-NEXT:    br i1 [[CMP5]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT0:       cond.true:
// ROT0-NEXT:    br label [[COND_END:%.*]]
// ROT0:       cond.false:
// ROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP5]], 3
// ROT0-NEXT:    br label [[COND_END]]
// ROT0:       cond.end:
// ROT0-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD6]], [[COND_FALSE]] ]
// ROT0-NEXT:    [[CMP7:%.*]] = icmp slt i32 [[TMP3]], [[COND]]
// ROT0-NEXT:    br i1 [[CMP7]], label [[FOR_BODY8:%.*]], label [[FOR_END25:%.*]]
// ROT0:       for.body8:
// ROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP6]], 1
// ROT0-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL]]
// ROT0-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    store i32 [[TMP7]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10:%.*]]
// ROT0:       for.cond10:
// ROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP9]], 3
// ROT0-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT0-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT0:       cond.true13:
// ROT0-NEXT:    br label [[COND_END16:%.*]]
// ROT0:       cond.false14:
// ROT0-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP10]], 3
// ROT0-NEXT:    br label [[COND_END16]]
// ROT0:       cond.end16:
// ROT0-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT0-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP8]], [[COND17]]
// ROT0-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT0:       for.body19:
// ROT0-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP11]], 1
// ROT0-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT0-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT0-NEXT:    [[TMP12:%.*]] = load i32, ptr [[I]], align 4
// ROT0-NEXT:    [[TMP13:%.*]] = load i32, ptr [[J]], align 4
// ROT0-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP12]], [[TMP13]]
// ROT0-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]])
// ROT0-NEXT:    br label [[FOR_INC:%.*]]
// ROT0:       for.inc:
// ROT0-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP14]], 1
// ROT0-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP10:![0-9]+]]
// ROT0:       for.end:
// ROT0-NEXT:    br label [[FOR_INC23:%.*]]
// ROT0:       for.inc23:
// ROT0-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP15]], 1
// ROT0-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP11:![0-9]+]]
// ROT0:       for.end25:
// ROT0-NEXT:    br label [[FOR_INC26:%.*]]
// ROT0:       for.inc26:
// ROT0-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP16]], 3
// ROT0-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND1]], !llvm.loop [[LOOP12:![0-9]+]]
// ROT0:       for.end28:
// ROT0-NEXT:    br label [[FOR_INC29:%.*]]
// ROT0:       for.inc29:
// ROT0-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD30:%.*]] = add nsw i32 [[TMP17]], 3
// ROT0-NEXT:    store i32 [[ADD30]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP13:![0-9]+]]
// ROT0:       for.end31:
// ROT0-NEXT:    ret void
//
// ROT1-LABEL: @_Z4foo3v(
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    store i32 0, ptr [[I]], align 4
// ROT1-NEXT:    store i32 0, ptr [[J]], align 4
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND:%.*]]
// ROT1:       for.cond:
// ROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP0]], 8
// ROT1-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END31:%.*]]
// ROT1:       for.body:
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND1:%.*]]
// ROT1:       for.cond1:
// ROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[CMP2:%.*]] = icmp slt i32 [[TMP1]], 4
// ROT1-NEXT:    br i1 [[CMP2]], label [[FOR_BODY3:%.*]], label [[FOR_END28:%.*]]
// ROT1:       for.body3:
// ROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    store i32 [[TMP2]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4:%.*]]
// ROT1:       for.cond4:
// ROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP4]], 3
// ROT1-NEXT:    [[CMP5:%.*]] = icmp slt i32 8, [[ADD]]
// ROT1-NEXT:    br i1 [[CMP5]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT1:       cond.true:
// ROT1-NEXT:    br label [[COND_END:%.*]]
// ROT1:       cond.false:
// ROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD6:%.*]] = add nsw i32 [[TMP5]], 3
// ROT1-NEXT:    br label [[COND_END]]
// ROT1:       cond.end:
// ROT1-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD6]], [[COND_FALSE]] ]
// ROT1-NEXT:    [[CMP7:%.*]] = icmp slt i32 [[TMP3]], [[COND]]
// ROT1-NEXT:    br i1 [[CMP7]], label [[FOR_BODY8:%.*]], label [[FOR_END25:%.*]]
// ROT1:       for.body8:
// ROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP6]], 1
// ROT1-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL]]
// ROT1-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    store i32 [[TMP7]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10:%.*]]
// ROT1:       for.cond10:
// ROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP9]], 3
// ROT1-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT1-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT1:       cond.true13:
// ROT1-NEXT:    br label [[COND_END16:%.*]]
// ROT1:       cond.false14:
// ROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP10]], 3
// ROT1-NEXT:    br label [[COND_END16]]
// ROT1:       cond.end16:
// ROT1-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT1-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP8]], [[COND17]]
// ROT1-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT1:       for.body19:
// ROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP11]], 1
// ROT1-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT1-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[I]], align 4
// ROT1-NEXT:    [[TMP13:%.*]] = load i32, ptr [[J]], align 4
// ROT1-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP12]], [[TMP13]]
// ROT1-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]])
// ROT1-NEXT:    br label [[FOR_INC:%.*]]
// ROT1:       for.inc:
// ROT1-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP14]], 1
// ROT1-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP10:![0-9]+]]
// ROT1:       for.end:
// ROT1-NEXT:    br label [[FOR_INC23:%.*]]
// ROT1:       for.inc23:
// ROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP15]], 1
// ROT1-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP11:![0-9]+]]
// ROT1:       for.end25:
// ROT1-NEXT:    br label [[FOR_INC26:%.*]]
// ROT1:       for.inc26:
// ROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP16]], 3
// ROT1-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND1]], !llvm.loop [[LOOP12:![0-9]+]]
// ROT1:       for.end28:
// ROT1-NEXT:    br label [[FOR_INC29:%.*]]
// ROT1:       for.inc29:
// ROT1-NEXT:    [[TMP17:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD30:%.*]] = add nsw i32 [[TMP17]], 3
// ROT1-NEXT:    store i32 [[ADD30]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP13:![0-9]+]]
// ROT1:       for.end31:
// ROT1-NEXT:    ret void
//
void foo3() {
  #pragma omp tile sizes(3,3) // not divisible
  for (int i = 0; i < 8; ++i)
    for (int j = 0; j < 4; ++j)
      body(i+j);
}

// ROT0-LABEL: @_Z4foo4v(
// ROT0-NEXT:  entry:
// ROT0-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT0-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT0-NEXT:    store i32 0, ptr [[I]], align 4
// ROT0-NEXT:    store i32 0, ptr [[J]], align 4
// ROT0-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// ROT0-NEXT:    store i32 1, ptr [[DOTOMP_UB]], align 4
// ROT0-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTFLOOR_0_IV_I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTFLOOR_1_IV_J]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTTILE_0_IV_I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTTILE_1_IV_J]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1) ]
// ROT0-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// ROT0-NEXT:    store i32 [[TMP1]], ptr [[DOTOMP_IV]], align 4
// ROT0-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// ROT0:       omp.inner.for.cond:
// ROT0-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT0-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// ROT0-NEXT:    [[CMP:%.*]] = icmp sle i32 [[TMP2]], [[TMP3]]
// ROT0-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// ROT0:       omp.inner.for.body:
// ROT0-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT0-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP4]], 4
// ROT0-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[MUL]]
// ROT0-NEXT:    store i32 [[ADD]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND:%.*]]
// ROT0:       for.cond:
// ROT0-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[CMP1:%.*]] = icmp slt i32 [[TMP5]], 4
// ROT0-NEXT:    br i1 [[CMP1]], label [[FOR_BODY:%.*]], label [[FOR_END28:%.*]]
// ROT0:       for.body:
// ROT0-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    store i32 [[TMP6]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND2:%.*]]
// ROT0:       for.cond2:
// ROT0-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD3:%.*]] = add nsw i32 [[TMP8]], 4
// ROT0-NEXT:    [[CMP4:%.*]] = icmp slt i32 8, [[ADD3]]
// ROT0-NEXT:    br i1 [[CMP4]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT0:       cond.true:
// ROT0-NEXT:    br label [[COND_END:%.*]]
// ROT0:       cond.false:
// ROT0-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT0-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 4
// ROT0-NEXT:    br label [[COND_END]]
// ROT0:       cond.end:
// ROT0-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD5]], [[COND_FALSE]] ]
// ROT0-NEXT:    [[CMP6:%.*]] = icmp slt i32 [[TMP7]], [[COND]]
// ROT0-NEXT:    br i1 [[CMP6]], label [[FOR_BODY7:%.*]], label [[FOR_END25:%.*]]
// ROT0:       for.body7:
// ROT0-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[MUL8:%.*]] = mul nsw i32 [[TMP10]], 1
// ROT0-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL8]]
// ROT0-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT0-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    store i32 [[TMP11]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10:%.*]]
// ROT0:       for.cond10:
// ROT0-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP13]], 2
// ROT0-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT0-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT0:       cond.true13:
// ROT0-NEXT:    br label [[COND_END16:%.*]]
// ROT0:       cond.false14:
// ROT0-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP14]], 2
// ROT0-NEXT:    br label [[COND_END16]]
// ROT0:       cond.end16:
// ROT0-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT0-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP12]], [[COND17]]
// ROT0-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT0:       for.body19:
// ROT0-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP15]], 1
// ROT0-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT0-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT0-NEXT:    [[TMP16:%.*]] = load i32, ptr [[I]], align 4
// ROT0-NEXT:    [[TMP17:%.*]] = load i32, ptr [[J]], align 4
// ROT0-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP16]], [[TMP17]]
// ROT0-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]]) #[[ATTR3:[0-9]+]]
// ROT0-NEXT:    br label [[FOR_INC:%.*]]
// ROT0:       for.inc:
// ROT0-NEXT:    [[TMP18:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP18]], 1
// ROT0-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP14:![0-9]+]]
// ROT0:       for.end:
// ROT0-NEXT:    br label [[FOR_INC23:%.*]]
// ROT0:       for.inc23:
// ROT0-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP19]], 1
// ROT0-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT0-NEXT:    br label [[FOR_COND2]], !llvm.loop [[LOOP15:![0-9]+]]
// ROT0:       for.end25:
// ROT0-NEXT:    br label [[FOR_INC26:%.*]]
// ROT0:       for.inc26:
// ROT0-NEXT:    [[TMP20:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP20]], 2
// ROT0-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT0-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP16:![0-9]+]]
// ROT0:       for.end28:
// ROT0-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// ROT0:       omp.body.continue:
// ROT0-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// ROT0:       omp.inner.for.inc:
// ROT0-NEXT:    [[TMP21:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT0-NEXT:    [[ADD29:%.*]] = add nsw i32 [[TMP21]], 1
// ROT0-NEXT:    store i32 [[ADD29]], ptr [[DOTOMP_IV]], align 4
// ROT0-NEXT:    br label [[OMP_INNER_FOR_COND]]
// ROT0:       omp.inner.for.end:
// ROT0-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// ROT0:       omp.loop.exit:
// ROT0-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// ROT0-NEXT:    ret void
//
// ROT1-LABEL: @_Z4foo4v(
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTFLOOR_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_0_IV_I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTTILE_1_IV_J:%.*]] = alloca i32, align 4
// ROT1-NEXT:    store i32 0, ptr [[I]], align 4
// ROT1-NEXT:    store i32 0, ptr [[J]], align 4
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// ROT1-NEXT:    store i32 1, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTFLOOR_0_IV_I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTFLOOR_1_IV_J]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTTILE_0_IV_I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTTILE_1_IV_J]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[J]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// ROT1-NEXT:    store i32 [[TMP1]], ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[CMP:%.*]] = icmp sle i32 [[TMP2]], [[TMP3]]
// ROT1-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// ROT1:       omp.inner.for.body.lh:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// ROT1:       omp.inner.for.body:
// ROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP4]], 4
// ROT1-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[MUL]]
// ROT1-NEXT:    store i32 [[ADD]], ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    store i32 0, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND:%.*]]
// ROT1:       for.cond:
// ROT1-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[CMP1:%.*]] = icmp slt i32 [[TMP5]], 4
// ROT1-NEXT:    br i1 [[CMP1]], label [[FOR_BODY:%.*]], label [[FOR_END28:%.*]]
// ROT1:       for.body:
// ROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    store i32 [[TMP6]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND2:%.*]]
// ROT1:       for.cond2:
// ROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD3:%.*]] = add nsw i32 [[TMP8]], 4
// ROT1-NEXT:    [[CMP4:%.*]] = icmp slt i32 8, [[ADD3]]
// ROT1-NEXT:    br i1 [[CMP4]], label [[COND_TRUE:%.*]], label [[COND_FALSE:%.*]]
// ROT1:       cond.true:
// ROT1-NEXT:    br label [[COND_END:%.*]]
// ROT1:       cond.false:
// ROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTFLOOR_0_IV_I]], align 4
// ROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP9]], 4
// ROT1-NEXT:    br label [[COND_END]]
// ROT1:       cond.end:
// ROT1-NEXT:    [[COND:%.*]] = phi i32 [ 8, [[COND_TRUE]] ], [ [[ADD5]], [[COND_FALSE]] ]
// ROT1-NEXT:    [[CMP6:%.*]] = icmp slt i32 [[TMP7]], [[COND]]
// ROT1-NEXT:    br i1 [[CMP6]], label [[FOR_BODY7:%.*]], label [[FOR_END25:%.*]]
// ROT1:       for.body7:
// ROT1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[MUL8:%.*]] = mul nsw i32 [[TMP10]], 1
// ROT1-NEXT:    [[ADD9:%.*]] = add nsw i32 0, [[MUL8]]
// ROT1-NEXT:    store i32 [[ADD9]], ptr [[I]], align 4
// ROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    store i32 [[TMP11]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10:%.*]]
// ROT1:       for.cond10:
// ROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP13]], 2
// ROT1-NEXT:    [[CMP12:%.*]] = icmp slt i32 4, [[ADD11]]
// ROT1-NEXT:    br i1 [[CMP12]], label [[COND_TRUE13:%.*]], label [[COND_FALSE14:%.*]]
// ROT1:       cond.true13:
// ROT1-NEXT:    br label [[COND_END16:%.*]]
// ROT1:       cond.false14:
// ROT1-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD15:%.*]] = add nsw i32 [[TMP14]], 2
// ROT1-NEXT:    br label [[COND_END16]]
// ROT1:       cond.end16:
// ROT1-NEXT:    [[COND17:%.*]] = phi i32 [ 4, [[COND_TRUE13]] ], [ [[ADD15]], [[COND_FALSE14]] ]
// ROT1-NEXT:    [[CMP18:%.*]] = icmp slt i32 [[TMP12]], [[COND17]]
// ROT1-NEXT:    br i1 [[CMP18]], label [[FOR_BODY19:%.*]], label [[FOR_END:%.*]]
// ROT1:       for.body19:
// ROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[MUL20:%.*]] = mul nsw i32 [[TMP15]], 1
// ROT1-NEXT:    [[ADD21:%.*]] = add nsw i32 0, [[MUL20]]
// ROT1-NEXT:    store i32 [[ADD21]], ptr [[J]], align 4
// ROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[I]], align 4
// ROT1-NEXT:    [[TMP17:%.*]] = load i32, ptr [[J]], align 4
// ROT1-NEXT:    [[ADD22:%.*]] = add nsw i32 [[TMP16]], [[TMP17]]
// ROT1-NEXT:    call void @_Z4bodyi(i32 noundef [[ADD22]]) #[[ATTR3:[0-9]+]]
// ROT1-NEXT:    br label [[FOR_INC:%.*]]
// ROT1:       for.inc:
// ROT1-NEXT:    [[TMP18:%.*]] = load i32, ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP18]], 1
// ROT1-NEXT:    store i32 [[INC]], ptr [[DOTTILE_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND10]], !llvm.loop [[LOOP14:![0-9]+]]
// ROT1:       for.end:
// ROT1-NEXT:    br label [[FOR_INC23:%.*]]
// ROT1:       for.inc23:
// ROT1-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    [[INC24:%.*]] = add nsw i32 [[TMP19]], 1
// ROT1-NEXT:    store i32 [[INC24]], ptr [[DOTTILE_0_IV_I]], align 4
// ROT1-NEXT:    br label [[FOR_COND2]], !llvm.loop [[LOOP15:![0-9]+]]
// ROT1:       for.end25:
// ROT1-NEXT:    br label [[FOR_INC26:%.*]]
// ROT1:       for.inc26:
// ROT1-NEXT:    [[TMP20:%.*]] = load i32, ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    [[ADD27:%.*]] = add nsw i32 [[TMP20]], 2
// ROT1-NEXT:    store i32 [[ADD27]], ptr [[DOTFLOOR_1_IV_J]], align 4
// ROT1-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP16:![0-9]+]]
// ROT1:       for.end28:
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// ROT1:       omp.body.continue:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// ROT1:       omp.inner.for.inc:
// ROT1-NEXT:    [[TMP21:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[ADD29:%.*]] = add nsw i32 [[TMP21]], 1
// ROT1-NEXT:    store i32 [[ADD29]], ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP22:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP23:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[CMP30:%.*]] = icmp sle i32 [[TMP22]], [[TMP23]]
// ROT1-NEXT:    br i1 [[CMP30]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// ROT1:       omp.inner.for.end_crit_edge:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END]]
// ROT1:       omp.inner.for.end:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// ROT1:       omp.loop.exit:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// ROT1-NEXT:    ret void
//
void foo4() {
  #pragma omp parallel for
  #pragma omp tile sizes(4,2)
  for (int i = 0; i < 8; ++i)
    for (int j = 0; j < 4; ++j)
      body(i+j);
}
