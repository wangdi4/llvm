// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -emit-llvm -o - -fopenmp -fopenmp-late-outline \
// RUN: -triple x86_64-unknown-linux-gnu -fopenmp-version=51 %s | \
// RUN: FileCheck --check-prefix=CHECK %s

// expected-no-diagnostics

// CHECK-LABEL: @_Z25test_task_depend_iteratorv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[PTR:%.*]] = alloca [4 x i32], align 16
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SIZE:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SAVED_STACK:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[IT:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[COUNTER_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[PTTR:%.*]] = alloca [4 x [4 x i32]], align 16
// CHECK-NEXT:    [[I3:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SIZE7:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SAVED_STACK10:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__VLA_EXPR1:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR12:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[ITT:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[COUNTER_ADDR14:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[IT16:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[COUNTER_ADDR17:%.*]] = alloca i32, align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 16 [[PTR]], ptr align 16 @__const._Z25test_task_depend_iteratorv.ptr, i64 16, i1 false)
// CHECK-NEXT:    [[ARRAY_BEGIN:%.*]] = getelementptr inbounds [4 x i32], ptr [[PTR]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.SHARED:TYPED"(ptr [[PTR]], i32 0, i64 4), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[SIZE]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[SAVED_STACK]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[__VLA_EXPR0]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DEP_COUNTER_ADDR]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[IT]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[COUNTER_ADDR]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP1]], 8
// CHECK-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK:       for.body:
// CHECK-NEXT:    store i32 4, ptr [[SIZE]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[SIZE]], align 4
// CHECK-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP2]], 0
// CHECK-NEXT:    [[TMP3:%.*]] = zext i32 [[SUB]] to i64
// CHECK-NEXT:    [[TMP4:%.*]] = mul nuw i64 [[TMP3]], 1
// CHECK-NEXT:    [[TMP5:%.*]] = add nuw i64 0, [[TMP4]]
// CHECK-NEXT:    [[TMP6:%.*]] = add nuw i64 [[TMP5]], 0
// CHECK-NEXT:    [[TMP7:%.*]] = call ptr @llvm.stacksave.p0()
// CHECK-NEXT:    store ptr [[TMP7]], ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    [[VLA:%.*]] = alloca [[STRUCT_KMP_DEPEND_INFO:%.*]], i64 [[TMP6]], align 16
// CHECK-NEXT:    store i64 [[TMP6]], ptr [[__VLA_EXPR0]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = trunc i64 [[TMP6]] to i32
// CHECK-NEXT:    store i64 0, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[SIZE]], align 4
// CHECK-NEXT:    [[SUB1:%.*]] = sub nsw i32 [[TMP9]], 0
// CHECK-NEXT:    store i32 0, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    br label [[ITER_CONT:%.*]]
// CHECK:       iter.cont:
// CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[TMP11:%.*]] = icmp slt i32 [[TMP10]], [[SUB1]]
// CHECK-NEXT:    br i1 [[TMP11]], label [[ITER_BODY:%.*]], label [[ITER_EXIT:%.*]]
// CHECK:       iter.body:
// CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[TMP12]]
// CHECK-NEXT:    store i32 [[ADD]], ptr [[IT]], align 4
// CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[IT]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP13]] to i64
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [4 x i32], ptr [[PTR]], i64 0, i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP14:%.*]] = ptrtoint ptr [[ARRAYIDX]] to i64
// CHECK-NEXT:    [[TMP15:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP16:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], ptr [[VLA]], i64 [[TMP15]]
// CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP16]], i32 0, i32 0
// CHECK-NEXT:    store i64 [[TMP14]], ptr [[TMP17]], align 8
// CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP16]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP18]], align 8
// CHECK-NEXT:    [[TMP19:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP16]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, ptr [[TMP19]], align 8
// CHECK-NEXT:    [[TMP20:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP21:%.*]] = add nuw i64 [[TMP20]], 1
// CHECK-NEXT:    store i64 [[TMP21]], ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP22:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP22]], 1
// CHECK-NEXT:    store i32 [[INC]], ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    br label [[ITER_CONT]]
// CHECK:       iter.exit:
// CHECK-NEXT:    [[TMP23:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.DEPARRAY"(i32 [[TMP8]], ptr [[VLA]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP23]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    [[TMP24:%.*]] = load ptr, ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr [[TMP24]])
// CHECK-NEXT:    br label [[FOR_INC:%.*]]
// CHECK:       for.inc:
// CHECK-NEXT:    [[TMP25:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[INC2:%.*]] = add nsw i32 [[TMP25]], 1
// CHECK-NEXT:    store i32 [[INC2]], ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP3:![0-9]+]]
// CHECK:       for.end:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    [[ARRAY_BEGIN35:%.*]] = getelementptr inbounds [4 x [4 x i32]], ptr [[PTTR]], i32 0, i32 0, i32 0
// CHECK-NEXT:    [[TMP26:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.SHARED:TYPED"(ptr [[PTTR]], i32 0, i64 16), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I3]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[SIZE7]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[SAVED_STACK10]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[__VLA_EXPR1]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DEP_COUNTER_ADDR12]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[ITT]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[COUNTER_ADDR14]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[IT16]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[COUNTER_ADDR17]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[I3]], align 4
// CHECK-NEXT:    br label [[FOR_COND4:%.*]]
// CHECK:       for.cond4:
// CHECK-NEXT:    [[TMP27:%.*]] = load i32, ptr [[I3]], align 4
// CHECK-NEXT:    [[CMP5:%.*]] = icmp slt i32 [[TMP27]], 8
// CHECK-NEXT:    br i1 [[CMP5]], label [[FOR_BODY6:%.*]], label [[FOR_END34:%.*]]
// CHECK:       for.body6:
// CHECK-NEXT:    store i32 4, ptr [[SIZE7]], align 4
// CHECK-NEXT:    [[TMP28:%.*]] = load i32, ptr [[SIZE7]], align 4
// CHECK-NEXT:    [[SUB8:%.*]] = sub nsw i32 [[TMP28]], 0
// CHECK-NEXT:    [[TMP29:%.*]] = zext i32 [[SUB8]] to i64
// CHECK-NEXT:    [[TMP30:%.*]] = mul nuw i64 [[TMP29]], 1
// CHECK-NEXT:    [[TMP31:%.*]] = add nuw i64 0, [[TMP30]]
// CHECK-NEXT:    [[TMP32:%.*]] = load i32, ptr [[SIZE7]], align 4
// CHECK-NEXT:    [[SUB9:%.*]] = sub nsw i32 [[TMP32]], 0
// CHECK-NEXT:    [[TMP33:%.*]] = zext i32 [[SUB9]] to i64
// CHECK-NEXT:    [[TMP34:%.*]] = mul nuw i64 [[TMP33]], 1
// CHECK-NEXT:    [[TMP35:%.*]] = add nuw i64 [[TMP31]], [[TMP34]]
// CHECK-NEXT:    [[TMP36:%.*]] = add nuw i64 [[TMP35]], 0
// CHECK-NEXT:    [[TMP37:%.*]] = call ptr @llvm.stacksave.p0()
// CHECK-NEXT:    store ptr [[TMP37]], ptr [[SAVED_STACK10]], align 8
// CHECK-NEXT:    [[VLA11:%.*]] = alloca [[STRUCT_KMP_DEPEND_INFO]], i64 [[TMP36]], align 16
// CHECK-NEXT:    store i64 [[TMP36]], ptr [[__VLA_EXPR1]], align 8
// CHECK-NEXT:    [[TMP38:%.*]] = trunc i64 [[TMP36]] to i32
// CHECK-NEXT:    store i64 0, ptr [[DEP_COUNTER_ADDR12]], align 8
// CHECK-NEXT:    [[TMP39:%.*]] = load i32, ptr [[SIZE7]], align 4
// CHECK-NEXT:    [[SUB13:%.*]] = sub nsw i32 [[TMP39]], 0
// CHECK-NEXT:    [[TMP40:%.*]] = load i32, ptr [[SIZE7]], align 4
// CHECK-NEXT:    [[SUB15:%.*]] = sub nsw i32 [[TMP40]], 0
// CHECK-NEXT:    store i32 0, ptr [[COUNTER_ADDR14]], align 4
// CHECK-NEXT:    br label [[ITER_CONT18:%.*]]
// CHECK:       iter.cont18:
// CHECK-NEXT:    [[TMP41:%.*]] = load i32, ptr [[COUNTER_ADDR14]], align 4
// CHECK-NEXT:    [[TMP42:%.*]] = icmp slt i32 [[TMP41]], [[SUB13]]
// CHECK-NEXT:    br i1 [[TMP42]], label [[ITER_BODY19:%.*]], label [[ITER_EXIT31:%.*]]
// CHECK:       iter.body19:
// CHECK-NEXT:    [[TMP43:%.*]] = load i32, ptr [[COUNTER_ADDR14]], align 4
// CHECK-NEXT:    [[ADD20:%.*]] = add nsw i32 0, [[TMP43]]
// CHECK-NEXT:    store i32 [[ADD20]], ptr [[ITT]], align 4
// CHECK-NEXT:    store i32 0, ptr [[COUNTER_ADDR17]], align 4
// CHECK-NEXT:    br label [[ITER_CONT21:%.*]]
// CHECK:       iter.cont21:
// CHECK-NEXT:    [[TMP44:%.*]] = load i32, ptr [[COUNTER_ADDR17]], align 4
// CHECK-NEXT:    [[TMP45:%.*]] = icmp slt i32 [[TMP44]], [[SUB15]]
// CHECK-NEXT:    br i1 [[TMP45]], label [[ITER_BODY22:%.*]], label [[ITER_EXIT29:%.*]]
// CHECK:       iter.body22:
// CHECK-NEXT:    [[TMP46:%.*]] = load i32, ptr [[COUNTER_ADDR17]], align 4
// CHECK-NEXT:    [[ADD23:%.*]] = add nsw i32 0, [[TMP46]]
// CHECK-NEXT:    store i32 [[ADD23]], ptr [[IT16]], align 4
// CHECK-NEXT:    [[TMP47:%.*]] = load i32, ptr [[ITT]], align 4
// CHECK-NEXT:    [[IDXPROM24:%.*]] = sext i32 [[TMP47]] to i64
// CHECK-NEXT:    [[ARRAYIDX25:%.*]] = getelementptr inbounds [4 x [4 x i32]], ptr [[PTTR]], i64 0, i64 [[IDXPROM24]]
// CHECK-NEXT:    [[TMP48:%.*]] = load i32, ptr [[IT16]], align 4
// CHECK-NEXT:    [[IDXPROM26:%.*]] = sext i32 [[TMP48]] to i64
// CHECK-NEXT:    [[ARRAYIDX27:%.*]] = getelementptr inbounds [4 x i32], ptr [[ARRAYIDX25]], i64 0, i64 [[IDXPROM26]]
// CHECK-NEXT:    [[TMP49:%.*]] = ptrtoint ptr [[ARRAYIDX27]] to i64
// CHECK-NEXT:    [[TMP50:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR12]], align 8
// CHECK-NEXT:    [[TMP51:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], ptr [[VLA11]], i64 [[TMP50]]
// CHECK-NEXT:    [[TMP52:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP51]], i32 0, i32 0
// CHECK-NEXT:    store i64 [[TMP49]], ptr [[TMP52]], align 8
// CHECK-NEXT:    [[TMP53:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP51]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP53]], align 8
// CHECK-NEXT:    [[TMP54:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP51]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, ptr [[TMP54]], align 8
// CHECK-NEXT:    [[TMP55:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR12]], align 8
// CHECK-NEXT:    [[TMP56:%.*]] = add nuw i64 [[TMP55]], 1
// CHECK-NEXT:    store i64 [[TMP56]], ptr [[DEP_COUNTER_ADDR12]], align 8
// CHECK-NEXT:    [[TMP57:%.*]] = load i32, ptr [[COUNTER_ADDR17]], align 4
// CHECK-NEXT:    [[INC28:%.*]] = add nsw i32 [[TMP57]], 1
// CHECK-NEXT:    store i32 [[INC28]], ptr [[COUNTER_ADDR17]], align 4
// CHECK-NEXT:    br label [[ITER_CONT21]]
// CHECK:       iter.exit29:
// CHECK-NEXT:    [[TMP58:%.*]] = load i32, ptr [[COUNTER_ADDR14]], align 4
// CHECK-NEXT:    [[INC30:%.*]] = add nsw i32 [[TMP58]], 1
// CHECK-NEXT:    store i32 [[INC30]], ptr [[COUNTER_ADDR14]], align 4
// CHECK-NEXT:    br label [[ITER_CONT18]]
// CHECK:       iter.exit31:
// CHECK-NEXT:    [[TMP59:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.DEPARRAY"(i32 [[TMP38]], ptr [[VLA11]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP59]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    [[TMP60:%.*]] = load ptr, ptr [[SAVED_STACK10]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr [[TMP60]])
// CHECK-NEXT:    br label [[FOR_INC32:%.*]]
// CHECK:       for.inc32:
// CHECK-NEXT:    [[TMP61:%.*]] = load i32, ptr [[I3]], align 4
// CHECK-NEXT:    [[INC33:%.*]] = add nsw i32 [[TMP61]], 1
// CHECK-NEXT:    store i32 [[INC33]], ptr [[I3]], align 4
// CHECK-NEXT:    br label [[FOR_COND4]], !llvm.loop [[LOOP5:![0-9]+]]
// CHECK:       for.end34:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP26]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    ret void
//
void test_task_depend_iterator() {
  int ptr[] = {0, 4, 5, 6};
#pragma omp parallel
  {
    for (int i = 0; i < 8; ++i) {
      int size = 4;
#pragma omp task depend(iterator(it = 0 : size), in : ptr[it])
       {}
    }
  }
  int pttr[4][4];
#pragma omp parallel
  {
    for (int i = 0; i < 8; ++i) {
      int size = 4;
#pragma omp task depend(iterator(itt = 0 : size, it = 0 : size), in : pttr[itt][it])
      {}
    }
  }
}

void print_all_elements(int v, int n);
// CHECK-LABEL: @_Z20parallel_computationi(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[N_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SAVED_STACK:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[OMP_VLA_TMP:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[OMP_VLA_TMP1:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[SAVED_STACK2:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__VLA_EXPR1:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[IT:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[COUNTER_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[N:%.*]], ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = zext i32 [[TMP0]] to i64
// CHECK-NEXT:    [[TMP2:%.*]] = call ptr @llvm.stacksave.p0()
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    [[VLA:%.*]] = alloca i32, i64 [[TMP1]], align 16
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[__VLA_EXPR0]], align 8
// CHECK-NEXT:    store i64 [[TMP1]], ptr [[OMP_VLA_TMP]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.SHARED:TYPED"(ptr [[N_ADDR]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[VLA]], i32 0, i64 [[TMP1]]), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[OMP_VLA_TMP]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[OMP_VLA_TMP1]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[SAVED_STACK2]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[__VLA_EXPR1]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DEP_COUNTER_ADDR]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[IT]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[COUNTER_ADDR]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP4:%.*]] = load i64, ptr [[OMP_VLA_TMP]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SINGLE"() ]
// CHECK-NEXT:    fence acquire
// CHECK-NEXT:    store i32 0, ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP6]], [[TMP7]]
// CHECK-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK:       for.body:
// CHECK-NEXT:    store i64 [[TMP4]], ptr [[OMP_VLA_TMP1]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP8]], 0
// CHECK-NEXT:    [[TMP9:%.*]] = zext i32 [[SUB]] to i64
// CHECK-NEXT:    [[TMP10:%.*]] = mul nuw i64 [[TMP9]], 1
// CHECK-NEXT:    [[TMP11:%.*]] = add nuw i64 0, [[TMP10]]
// CHECK-NEXT:    [[TMP12:%.*]] = add nuw i64 [[TMP11]], 0
// CHECK-NEXT:    [[TMP13:%.*]] = call ptr @llvm.stacksave.p0()
// CHECK-NEXT:    store ptr [[TMP13]], ptr [[SAVED_STACK2]], align 8
// CHECK-NEXT:    [[VLA3:%.*]] = alloca [[STRUCT_KMP_DEPEND_INFO:%.*]], i64 [[TMP12]], align 16
// CHECK-NEXT:    store i64 [[TMP12]], ptr [[__VLA_EXPR1]], align 8
// CHECK-NEXT:    [[TMP14:%.*]] = trunc i64 [[TMP12]] to i32
// CHECK-NEXT:    store i64 0, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[TMP15]], 0
// CHECK-NEXT:    store i32 0, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    br label [[ITER_CONT:%.*]]
// CHECK:       iter.cont:
// CHECK-NEXT:    [[TMP16:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[TMP17:%.*]] = icmp slt i32 [[TMP16]], [[SUB4]]
// CHECK-NEXT:    br i1 [[TMP17]], label [[ITER_BODY:%.*]], label [[ITER_EXIT:%.*]]
// CHECK:       iter.body:
// CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[TMP18]]
// CHECK-NEXT:    store i32 [[ADD]], ptr [[IT]], align 4
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[IT]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP19]] to i64
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr [[VLA]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP20:%.*]] = ptrtoint ptr [[ARRAYIDX]] to i64
// CHECK-NEXT:    [[TMP21:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP22:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], ptr [[VLA3]], i64 [[TMP21]]
// CHECK-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP22]], i32 0, i32 0
// CHECK-NEXT:    store i64 [[TMP20]], ptr [[TMP23]], align 8
// CHECK-NEXT:    [[TMP24:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP22]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, ptr [[TMP24]], align 8
// CHECK-NEXT:    [[TMP25:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], ptr [[TMP22]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, ptr [[TMP25]], align 8
// CHECK-NEXT:    [[TMP26:%.*]] = load i64, ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP27:%.*]] = add nuw i64 [[TMP26]], 1
// CHECK-NEXT:    store i64 [[TMP27]], ptr [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP28:%.*]] = load i32, ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP28]], 1
// CHECK-NEXT:    store i32 [[INC]], ptr [[COUNTER_ADDR]], align 4
// CHECK-NEXT:    br label [[ITER_CONT]]
// CHECK:       iter.exit:
// CHECK-NEXT:    [[TMP29:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.DEPARRAY"(i32 [[TMP14]], ptr [[VLA3]]), "QUAL.OMP.SHARED:TYPED"(ptr [[VLA]], i32 0, i64 [[TMP4]]), "QUAL.OMP.SHARED:TYPED"(ptr [[OMP_VLA_TMP1]], i64 0, i32 1) ]
// CHECK-NEXT:    [[TMP30:%.*]] = load i64, ptr [[OMP_VLA_TMP1]], align 8
// CHECK-NEXT:    [[TMP31:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[IDXPROM5:%.*]] = sext i32 [[TMP31]] to i64
// CHECK-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds i32, ptr [[VLA]], i64 [[IDXPROM5]]
// CHECK-NEXT:    [[TMP32:%.*]] = load i32, ptr [[ARRAYIDX6]], align 4
// CHECK-NEXT:    [[TMP33:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    call void @_Z18print_all_elementsii(i32 noundef [[TMP32]], i32 noundef [[TMP33]]) #[[ATTR2:[0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP29]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    [[TMP34:%.*]] = load ptr, ptr [[SAVED_STACK2]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr [[TMP34]])
// CHECK-NEXT:    br label [[FOR_INC:%.*]]
// CHECK:       for.inc:
// CHECK-NEXT:    [[TMP35:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[INC7:%.*]] = add nsw i32 [[TMP35]], 1
// CHECK-NEXT:    store i32 [[INC7]], ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP6:![0-9]+]]
// CHECK:       for.end:
// CHECK-NEXT:    fence release
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]) [ "DIR.OMP.END.SINGLE"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    [[TMP36:%.*]] = load ptr, ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr [[TMP36]])
// CHECK-NEXT:    ret void
//
void parallel_computation(int n)
{
  int v[n];
  #pragma omp parallel
  #pragma omp single
  {
    for(int i=0; i<n; ++i) {
      #pragma omp task depend(iterator(it = 0:n), in: v[it])
      print_all_elements(v[i], i);
    }
  }
}
// end INTEL_COLLAB
