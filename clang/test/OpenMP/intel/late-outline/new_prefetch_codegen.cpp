// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -opaque-pointers -emit-llvm -o - -fopenmp \
// RUN:  -fopenmp-late-outline -fopenmp-typed-clauses \
// RUN:  -triple i386-unknown-unknown %s \
// RUN:  | FileCheck %s --check-prefix=CHECK-32
//
// RUN: %clang_cc1 -opaque-pointers -emit-llvm -o - -fopenmp \
// RUN:  -fopenmp-late-outline -fopenmp-typed-clauses \
// RUN:  -triple x86_64-unknown-linux-gnu %s | FileCheck %s
//
// RUN: %clang_cc1 -opaque-pointers -emit-llvm -o - -fopenmp \
// RUN:  -fopenmp-late-outline \
// RUN:  -triple x86_64-unknown-linux-gnu %s | FileCheck %s

// RUN: %clang_cc1 -opaque-pointers -emit-llvm -o - -fopenmp \
// RUN:  -fopenmp-late-outline -DMULTI_DATA \
// RUN:  -triple x86_64-unknown-linux-gnu %s | FileCheck %s
//
// RUN: %clang_cc1 -opaque-pointers -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-typed-clauses \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-pch %s -o %t

// RUN: %clang_cc1 -opaque-pointers -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-typed-clauses \
// RUN:  -triple x86_64-unknown-linux-gnu -include-pch %t \
// RUN:  -emit-llvm %s -o - | FileCheck %s
//
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

struct foobar {
  int i;
  double d[10];
  double d2[10][10];

  void check();
};

// CHECK-32-LABEL: @_ZN6foobar5checkEv(
// CHECK-32-NEXT:  entry:
// CHECK-32-NEXT:    [[THIS_ADDR:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    store ptr [[THIS:%.*]], ptr [[THIS_ADDR]], align 4
// CHECK-32-NEXT:    [[THIS1:%.*]] = load ptr, ptr [[THIS_ADDR]], align 4
// CHECK-32-NEXT:    [[D:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR:%.*]], ptr [[THIS1]], i32 0, i32 1
// CHECK-32-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x double], ptr [[D]], i32 0, i32 1
// CHECK-32-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX]], double 0.000000e+00, i32 2, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[D2:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 1
// CHECK-32-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds [10 x double], ptr [[D2]], i32 0, i32 5
// CHECK-32-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX3]], double 0.000000e+00, i32 1, i32 3) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[D24:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 2
// CHECK-32-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[D24]], i32 0, i32 1
// CHECK-32-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX5]], i32 0, i32 0
// CHECK-32-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds double, ptr [[ARRAYDECAY]], i32 0
// CHECK-32-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX6]], double 0.000000e+00, i32 20, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[D27:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 2
// CHECK-32-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[D27]], i32 0, i32 6
// CHECK-32-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX8]], i32 0, i32 8
// CHECK-32-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX9]], double 0.000000e+00, i32 1, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    ret void
//
// CHECK-LABEL: @_ZN6foobar5checkEv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[THIS_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[THIS:%.*]], ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[THIS1:%.*]] = load ptr, ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[D:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR:%.*]], ptr [[THIS1]], i32 0, i32 1
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x double], ptr [[D]], i64 0, i64 1
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX]], double 0.000000e+00, i64 2, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[D2:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 1
// CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds [10 x double], ptr [[D2]], i64 0, i64 5
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX3]], double 0.000000e+00, i64 1, i32 3) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[D24:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 2
// CHECK-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[D24]], i64 0, i64 1
// CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX5]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds double, ptr [[ARRAYDECAY]], i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX6]], double 0.000000e+00, i64 20, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[D27:%.*]] = getelementptr inbounds [[STRUCT_FOOBAR]], ptr [[THIS1]], i32 0, i32 2
// CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[D27]], i64 0, i64 6
// CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX8]], i64 0, i64 8
// CHECK-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX9]], double 0.000000e+00, i64 1, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    ret void
//
void foobar::check() {
    //fields
    #pragma ompx prefetch data(4:d[1:2])
    #pragma ompx prefetch data(3:d[5])
    #pragma ompx prefetch data(4:d2[1:2][:])
    #pragma ompx prefetch data(4:d2[6][8])
}

foobar bar;

// CHECK-32-LABEL: @_Z13test_prefetchm(
// CHECK-32-NEXT:  entry:
// CHECK-32-NEXT:    [[N_ADDR:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[A:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[B:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[FOO1:%.*]] = alloca [10 x i32], align 4
// CHECK-32-NEXT:    [[FOO2:%.*]] = alloca [10 x [10 x i32]], align 4
// CHECK-32-NEXT:    [[P:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    [[SAVED_STACK:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[PTR_BASE:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    [[PBREF:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    store i32 [[N:%.*]], ptr [[N_ADDR]], align 4
// CHECK-32-NEXT:    store i32 1, ptr [[I]], align 4
// CHECK-32-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    store ptr [[ARRAYDECAY]], ptr [[P]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX]], i32 0, i32 1, i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 1
// CHECK-32-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX1]], i32 0, i32 1, i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX2]], i32 0, i32 2, i32 1) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX3]], i32 0, i32 9, i32 2) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 4
// CHECK-32-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX4]], i32 0, i32 8, i32 3) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 3
// CHECK-32-NEXT:    [[SEC_LOWER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX5]] to i32
// CHECK-32-NEXT:    [[TMP5:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[LB_ADD_LEN:%.*]] = add nsw i32 2, [[TMP5]]
// CHECK-32-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 [[LB_ADD_LEN]]
// CHECK-32-NEXT:    [[SEC_UPPER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX6]] to i32
// CHECK-32-NEXT:    [[TMP6:%.*]] = sub i32 [[SEC_UPPER_CAST]], [[SEC_LOWER_CAST]]
// CHECK-32-NEXT:    [[TMP7:%.*]] = sdiv exact i32 [[TMP6]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS:%.*]] = add i32 [[TMP7]], 1
// CHECK-32-NEXT:    [[TMP8:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX5]], i32 0, i32 [[SEC_NUMBER_OF_ELEMENTS]], i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP8]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    [[TMP9:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX7]], i32 0, i32 10, i32 5) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP9]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP10:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 [[TMP10]]
// CHECK-32-NEXT:    [[SEC_LOWER_CAST9:%.*]] = ptrtoint ptr [[ARRAYIDX8]] to i32
// CHECK-32-NEXT:    [[TMP11:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[LB_ADD_LEN10:%.*]] = add nsw i32 [[TMP11]], 4
// CHECK-32-NEXT:    [[ARRAYIDX11:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 [[LB_ADD_LEN10]]
// CHECK-32-NEXT:    [[SEC_UPPER_CAST12:%.*]] = ptrtoint ptr [[ARRAYIDX11]] to i32
// CHECK-32-NEXT:    [[TMP12:%.*]] = sub i32 [[SEC_UPPER_CAST12]], [[SEC_LOWER_CAST9]]
// CHECK-32-NEXT:    [[TMP13:%.*]] = sdiv exact i32 [[TMP12]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS13:%.*]] = add i32 [[TMP13]], 1
// CHECK-32-NEXT:    [[TMP14:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX8]], i32 0, i32 [[SEC_NUMBER_OF_ELEMENTS13]], i32 6) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP14]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 1
// CHECK-32-NEXT:    [[TMP15:%.*]] = load i32, ptr [[A]], align 4
// CHECK-32-NEXT:    [[TMP16:%.*]] = load i32, ptr [[B]], align 4
// CHECK-32-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP15]], [[TMP16]]
// CHECK-32-NEXT:    [[TMP17:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX14]], i32 0, i32 2, i32 1), "QUAL.OMP.IF"(i1 [[CMP]]) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP17]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP18:%.*]] = load i32, ptr [[A]], align 4
// CHECK-32-NEXT:    [[CMP15:%.*]] = icmp eq i32 [[TMP18]], 0
// CHECK-32-NEXT:    [[TMP19:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX16:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 [[TMP19]]
// CHECK-32-NEXT:    [[SEC_LOWER_CAST17:%.*]] = ptrtoint ptr [[ARRAYIDX16]] to i32
// CHECK-32-NEXT:    [[TMP20:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[LB_ADD_LEN18:%.*]] = add nsw i32 [[TMP20]], 2
// CHECK-32-NEXT:    [[ARRAYIDX19:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 [[LB_ADD_LEN18]]
// CHECK-32-NEXT:    [[SEC_UPPER_CAST20:%.*]] = ptrtoint ptr [[ARRAYIDX19]] to i32
// CHECK-32-NEXT:    [[TMP21:%.*]] = sub i32 [[SEC_UPPER_CAST20]], [[SEC_LOWER_CAST17]]
// CHECK-32-NEXT:    [[TMP22:%.*]] = sdiv exact i32 [[TMP21]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS21:%.*]] = add i32 [[TMP22]], 1
// CHECK-32-NEXT:    [[TMP23:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.IF"(i1 [[CMP15]]), "QUAL.OMP.DATA"(ptr [[ARRAYIDX16]], i32 0, i32 [[SEC_NUMBER_OF_ELEMENTS21]], i32 1) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP23]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX22:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 0
// CHECK-32-NEXT:    [[ARRAYIDX23:%.*]] = getelementptr inbounds [10 x [10 x i32]], ptr [[FOO2]], i32 0, i32 0
// CHECK-32-NEXT:    [[ARRAYDECAY24:%.*]] = getelementptr inbounds [10 x i32], ptr [[ARRAYIDX23]], i32 0, i32 0
// CHECK-32-NEXT:    [[ARRAYIDX25:%.*]] = getelementptr inbounds i32, ptr [[ARRAYDECAY24]], i32 0
// CHECK-32-NEXT:    [[TMP24:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX22]], i32 0, i32 1, i32 1), "QUAL.OMP.DATA"(ptr [[ARRAYIDX25]], i32 0, i32 50, i32 1) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP24]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX26:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i32 0, i32 1
// CHECK-32-NEXT:    [[TMP25:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX26]], i32 0, i32 1, i32 3) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP25]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[ARRAYIDX27:%.*]] = getelementptr inbounds [10 x [10 x i32]], ptr [[FOO2]], i32 0, i32 2
// CHECK-32-NEXT:    [[ARRAYIDX28:%.*]] = getelementptr inbounds [10 x i32], ptr [[ARRAYIDX27]], i32 0, i32 3
// CHECK-32-NEXT:    [[TMP26:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX28]], i32 0, i32 1, i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP26]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP27:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-32-NEXT:    [[TMP28:%.*]] = call ptr @llvm.stacksave()
// CHECK-32-NEXT:    store ptr [[TMP28]], ptr [[SAVED_STACK]], align 4
// CHECK-32-NEXT:    [[TMP29:%.*]] = mul nuw i32 1000, [[TMP27]]
// CHECK-32-NEXT:    [[VLA:%.*]] = alloca i16, i32 [[TMP29]], align 2
// CHECK-32-NEXT:    store i32 [[TMP27]], ptr [[__VLA_EXPR0]], align 4
// CHECK-32-NEXT:    [[TMP30:%.*]] = mul nuw i32 10, [[TMP27]]
// CHECK-32-NEXT:    [[TMP31:%.*]] = mul nsw i32 50, [[TMP30]]
// CHECK-32-NEXT:    [[ARRAYIDX29:%.*]] = getelementptr inbounds i16, ptr [[VLA]], i32 [[TMP31]]
// CHECK-32-NEXT:    [[TMP32:%.*]] = mul nsw i32 5, [[TMP27]]
// CHECK-32-NEXT:    [[ARRAYIDX30:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX29]], i32 [[TMP32]]
// CHECK-32-NEXT:    [[ARRAYIDX31:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX30]], i32 0
// CHECK-32-NEXT:    [[SEC_LOWER_CAST32:%.*]] = ptrtoint ptr [[ARRAYIDX31]] to i32
// CHECK-32-NEXT:    [[TMP33:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-32-NEXT:    [[LB_ADD_LEN33:%.*]] = add nsw i32 -1, [[TMP33]]
// CHECK-32-NEXT:    [[TMP34:%.*]] = mul nuw i32 10, [[TMP27]]
// CHECK-32-NEXT:    [[TMP35:%.*]] = mul nsw i32 50, [[TMP34]]
// CHECK-32-NEXT:    [[ARRAYIDX34:%.*]] = getelementptr inbounds i16, ptr [[VLA]], i32 [[TMP35]]
// CHECK-32-NEXT:    [[TMP36:%.*]] = mul nsw i32 7, [[TMP27]]
// CHECK-32-NEXT:    [[ARRAYIDX35:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX34]], i32 [[TMP36]]
// CHECK-32-NEXT:    [[ARRAYIDX36:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX35]], i32 [[LB_ADD_LEN33]]
// CHECK-32-NEXT:    [[SEC_UPPER_CAST37:%.*]] = ptrtoint ptr [[ARRAYIDX36]] to i32
// CHECK-32-NEXT:    [[TMP37:%.*]] = sub i32 [[SEC_UPPER_CAST37]], [[SEC_LOWER_CAST32]]
// CHECK-32-NEXT:    [[TMP38:%.*]] = sdiv exact i32 [[TMP37]], 2
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS38:%.*]] = add i32 [[TMP38]], 1
// CHECK-32-NEXT:    [[TMP39:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX31]], i16 0, i32 [[SEC_NUMBER_OF_ELEMENTS38]], i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP39]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    store ptr [[PTR_BASE]], ptr [[PBREF]], align 4
// CHECK-32-NEXT:    [[TMP40:%.*]] = load ptr, ptr [[PTR_BASE]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX39:%.*]] = getelementptr inbounds i32, ptr [[TMP40]], i32 3
// CHECK-32-NEXT:    [[SEC_LOWER_CAST40:%.*]] = ptrtoint ptr [[ARRAYIDX39]] to i32
// CHECK-32-NEXT:    [[TMP41:%.*]] = load ptr, ptr [[PTR_BASE]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX41:%.*]] = getelementptr inbounds i32, ptr [[TMP41]], i32 12
// CHECK-32-NEXT:    [[SEC_UPPER_CAST42:%.*]] = ptrtoint ptr [[ARRAYIDX41]] to i32
// CHECK-32-NEXT:    [[TMP42:%.*]] = sub i32 [[SEC_UPPER_CAST42]], [[SEC_LOWER_CAST40]]
// CHECK-32-NEXT:    [[TMP43:%.*]] = sdiv exact i32 [[TMP42]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS43:%.*]] = add i32 [[TMP43]], 1
// CHECK-32-NEXT:    [[TMP44:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX39]], i32 0, i32 [[SEC_NUMBER_OF_ELEMENTS43]], i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP44]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP45:%.*]] = load ptr, ptr [[PBREF]], align 4
// CHECK-32-NEXT:    [[TMP46:%.*]] = load ptr, ptr [[TMP45]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX44:%.*]] = getelementptr inbounds i32, ptr [[TMP46]], i32 3
// CHECK-32-NEXT:    [[SEC_LOWER_CAST45:%.*]] = ptrtoint ptr [[ARRAYIDX44]] to i32
// CHECK-32-NEXT:    [[TMP47:%.*]] = load ptr, ptr [[PBREF]], align 4
// CHECK-32-NEXT:    [[TMP48:%.*]] = load ptr, ptr [[TMP47]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX46:%.*]] = getelementptr inbounds i32, ptr [[TMP48]], i32 12
// CHECK-32-NEXT:    [[SEC_UPPER_CAST47:%.*]] = ptrtoint ptr [[ARRAYIDX46]] to i32
// CHECK-32-NEXT:    [[TMP49:%.*]] = sub i32 [[SEC_UPPER_CAST47]], [[SEC_LOWER_CAST45]]
// CHECK-32-NEXT:    [[TMP50:%.*]] = sdiv exact i32 [[TMP49]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS48:%.*]] = add i32 [[TMP50]], 1
// CHECK-32-NEXT:    [[TMP51:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX44]], i32 0, i32 [[SEC_NUMBER_OF_ELEMENTS48]], i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP51]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    call void @_ZN6foobar5checkEv(ptr noundef nonnull align 4 dereferenceable(884) @bar)
// CHECK-32-NEXT:    [[TMP52:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR:%.*]], ptr @bar, i32 0, i32 1, i32 1), double 0.000000e+00, i32 2, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP52]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP53:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 1, i32 5), double 0.000000e+00, i32 1, i32 3) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP53]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP54:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 2, i32 1), double 0.000000e+00, i32 20, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP54]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP55:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 2, i32 6, i32 8), double 0.000000e+00, i32 1, i32 4) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP55]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP56:%.*]] = load ptr, ptr [[SAVED_STACK]], align 4
// CHECK-32-NEXT:    call void @llvm.stackrestore(ptr [[TMP56]])
// CHECK-32-NEXT:    ret void
//
// CHECK-LABEL: @_Z13test_prefetchm(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[N_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[FOO1:%.*]] = alloca [10 x i32], align 16
// CHECK-NEXT:    [[FOO2:%.*]] = alloca [10 x [10 x i32]], align 16
// CHECK-NEXT:    [[P:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SAVED_STACK:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[PTR_BASE:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[PBREF:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store i64 [[N:%.*]], ptr [[N_ADDR]], align 8
// CHECK-NEXT:    store i32 1, ptr [[I]], align 4
// CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    store ptr [[ARRAYDECAY]], ptr [[P]], align 8
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX]], i32 0, i64 1, i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 1
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX1]], i32 0, i64 1, i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX2]], i32 0, i64 2, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX3]], i32 0, i64 9, i32 2) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 4
// CHECK-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX4]], i32 0, i64 8, i32 3) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 3
// CHECK-NEXT:    [[SEC_LOWER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX5]] to i64
// CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP6:%.*]] = sext i32 [[TMP5]] to i64
// CHECK-NEXT:    [[LB_ADD_LEN:%.*]] = add nsw i64 2, [[TMP6]]
// CHECK-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 [[LB_ADD_LEN]]
// CHECK-NEXT:    [[SEC_UPPER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX6]] to i64
// CHECK-NEXT:    [[TMP7:%.*]] = sub i64 [[SEC_UPPER_CAST]], [[SEC_LOWER_CAST]]
// CHECK-NEXT:    [[TMP8:%.*]] = sdiv exact i64 [[TMP7]], 4
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS:%.*]] = add i64 [[TMP8]], 1
// CHECK-NEXT:    [[TMP9:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX5]], i32 0, i64 [[SEC_NUMBER_OF_ELEMENTS]], i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP9]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    [[TMP10:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX7]], i32 0, i64 10, i32 5) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP10]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP12:%.*]] = sext i32 [[TMP11]] to i64
// CHECK-NEXT:    [[ARRAYIDX8:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 [[TMP12]]
// CHECK-NEXT:    [[SEC_LOWER_CAST9:%.*]] = ptrtoint ptr [[ARRAYIDX8]] to i64
// CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP14:%.*]] = sext i32 [[TMP13]] to i64
// CHECK-NEXT:    [[LB_ADD_LEN10:%.*]] = add nsw i64 [[TMP14]], 4
// CHECK-NEXT:    [[ARRAYIDX11:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 [[LB_ADD_LEN10]]
// CHECK-NEXT:    [[SEC_UPPER_CAST12:%.*]] = ptrtoint ptr [[ARRAYIDX11]] to i64
// CHECK-NEXT:    [[TMP15:%.*]] = sub i64 [[SEC_UPPER_CAST12]], [[SEC_LOWER_CAST9]]
// CHECK-NEXT:    [[TMP16:%.*]] = sdiv exact i64 [[TMP15]], 4
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS13:%.*]] = add i64 [[TMP16]], 1
// CHECK-NEXT:    [[TMP17:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX8]], i32 0, i64 [[SEC_NUMBER_OF_ELEMENTS13]], i32 6) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP17]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 1
// CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[A]], align 4
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[B]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP18]], [[TMP19]]
// CHECK-NEXT:    [[TMP20:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX14]], i32 0, i64 2, i32 1), "QUAL.OMP.IF"(i1 [[CMP]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP20]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[A]], align 4
// CHECK-NEXT:    [[CMP15:%.*]] = icmp eq i32 [[TMP21]], 0
// CHECK-NEXT:    [[TMP22:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP23:%.*]] = sext i32 [[TMP22]] to i64
// CHECK-NEXT:    [[ARRAYIDX16:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 [[TMP23]]
// CHECK-NEXT:    [[SEC_LOWER_CAST17:%.*]] = ptrtoint ptr [[ARRAYIDX16]] to i64
// CHECK-NEXT:    [[TMP24:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[TMP25:%.*]] = sext i32 [[TMP24]] to i64
// CHECK-NEXT:    [[LB_ADD_LEN18:%.*]] = add nsw i64 [[TMP25]], 2
// CHECK-NEXT:    [[ARRAYIDX19:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 [[LB_ADD_LEN18]]
// CHECK-NEXT:    [[SEC_UPPER_CAST20:%.*]] = ptrtoint ptr [[ARRAYIDX19]] to i64
// CHECK-NEXT:    [[TMP26:%.*]] = sub i64 [[SEC_UPPER_CAST20]], [[SEC_LOWER_CAST17]]
// CHECK-NEXT:    [[TMP27:%.*]] = sdiv exact i64 [[TMP26]], 4
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS21:%.*]] = add i64 [[TMP27]], 1
// CHECK-NEXT:    [[TMP28:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.IF"(i1 [[CMP15]]), "QUAL.OMP.DATA"(ptr [[ARRAYIDX16]], i32 0, i64 [[SEC_NUMBER_OF_ELEMENTS21]], i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP28]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX22:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX23:%.*]] = getelementptr inbounds [10 x [10 x i32]], ptr [[FOO2]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYDECAY24:%.*]] = getelementptr inbounds [10 x i32], ptr [[ARRAYIDX23]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX25:%.*]] = getelementptr inbounds i32, ptr [[ARRAYDECAY24]], i64 0
// CHECK-NEXT:    [[TMP29:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX22]], i32 0, i64 1, i32 1), "QUAL.OMP.DATA"(ptr [[ARRAYIDX25]], i32 0, i64 50, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP29]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX26:%.*]] = getelementptr inbounds [10 x i32], ptr [[FOO1]], i64 0, i64 1
// CHECK-NEXT:    [[TMP30:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX26]], i32 0, i64 1, i32 3) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP30]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[ARRAYIDX27:%.*]] = getelementptr inbounds [10 x [10 x i32]], ptr [[FOO2]], i64 0, i64 2
// CHECK-NEXT:    [[ARRAYIDX28:%.*]] = getelementptr inbounds [10 x i32], ptr [[ARRAYIDX27]], i64 0, i64 3
// CHECK-NEXT:    [[TMP31:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX28]], i32 0, i64 1, i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP31]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP32:%.*]] = load i64, ptr [[N_ADDR]], align 8
// CHECK-NEXT:    [[TMP33:%.*]] = call ptr @llvm.stacksave()
// CHECK-NEXT:    store ptr [[TMP33]], ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    [[TMP34:%.*]] = mul nuw i64 1000, [[TMP32]]
// CHECK-NEXT:    [[VLA:%.*]] = alloca i16, i64 [[TMP34]], align 16
// CHECK-NEXT:    store i64 [[TMP32]], ptr [[__VLA_EXPR0]], align 8
// CHECK-NEXT:    [[TMP35:%.*]] = mul nuw i64 10, [[TMP32]]
// CHECK-NEXT:    [[TMP36:%.*]] = mul nsw i64 50, [[TMP35]]
// CHECK-NEXT:    [[ARRAYIDX29:%.*]] = getelementptr inbounds i16, ptr [[VLA]], i64 [[TMP36]]
// CHECK-NEXT:    [[TMP37:%.*]] = mul nsw i64 5, [[TMP32]]
// CHECK-NEXT:    [[ARRAYIDX30:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX29]], i64 [[TMP37]]
// CHECK-NEXT:    [[ARRAYIDX31:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX30]], i64 0
// CHECK-NEXT:    [[SEC_LOWER_CAST32:%.*]] = ptrtoint ptr [[ARRAYIDX31]] to i64
// CHECK-NEXT:    [[TMP38:%.*]] = load i64, ptr [[N_ADDR]], align 8
// CHECK-NEXT:    [[LB_ADD_LEN33:%.*]] = add nsw i64 -1, [[TMP38]]
// CHECK-NEXT:    [[TMP39:%.*]] = mul nuw i64 10, [[TMP32]]
// CHECK-NEXT:    [[TMP40:%.*]] = mul nsw i64 50, [[TMP39]]
// CHECK-NEXT:    [[ARRAYIDX34:%.*]] = getelementptr inbounds i16, ptr [[VLA]], i64 [[TMP40]]
// CHECK-NEXT:    [[TMP41:%.*]] = mul nsw i64 7, [[TMP32]]
// CHECK-NEXT:    [[ARRAYIDX35:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX34]], i64 [[TMP41]]
// CHECK-NEXT:    [[ARRAYIDX36:%.*]] = getelementptr inbounds i16, ptr [[ARRAYIDX35]], i64 [[LB_ADD_LEN33]]
// CHECK-NEXT:    [[SEC_UPPER_CAST37:%.*]] = ptrtoint ptr [[ARRAYIDX36]] to i64
// CHECK-NEXT:    [[TMP42:%.*]] = sub i64 [[SEC_UPPER_CAST37]], [[SEC_LOWER_CAST32]]
// CHECK-NEXT:    [[TMP43:%.*]] = sdiv exact i64 [[TMP42]], 2
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS38:%.*]] = add i64 [[TMP43]], 1
// CHECK-NEXT:    [[TMP44:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX31]], i16 0, i64 [[SEC_NUMBER_OF_ELEMENTS38]], i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP44]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    store ptr [[PTR_BASE]], ptr [[PBREF]], align 8
// CHECK-NEXT:    [[TMP45:%.*]] = load ptr, ptr [[PTR_BASE]], align 8
// CHECK-NEXT:    [[ARRAYIDX39:%.*]] = getelementptr inbounds i32, ptr [[TMP45]], i64 3
// CHECK-NEXT:    [[SEC_LOWER_CAST40:%.*]] = ptrtoint ptr [[ARRAYIDX39]] to i64
// CHECK-NEXT:    [[TMP46:%.*]] = load ptr, ptr [[PTR_BASE]], align 8
// CHECK-NEXT:    [[ARRAYIDX41:%.*]] = getelementptr inbounds i32, ptr [[TMP46]], i64 12
// CHECK-NEXT:    [[SEC_UPPER_CAST42:%.*]] = ptrtoint ptr [[ARRAYIDX41]] to i64
// CHECK-NEXT:    [[TMP47:%.*]] = sub i64 [[SEC_UPPER_CAST42]], [[SEC_LOWER_CAST40]]
// CHECK-NEXT:    [[TMP48:%.*]] = sdiv exact i64 [[TMP47]], 4
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS43:%.*]] = add i64 [[TMP48]], 1
// CHECK-NEXT:    [[TMP49:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX39]], i32 0, i64 [[SEC_NUMBER_OF_ELEMENTS43]], i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP49]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP50:%.*]] = load ptr, ptr [[PBREF]], align 8
// CHECK-NEXT:    [[TMP51:%.*]] = load ptr, ptr [[TMP50]], align 8
// CHECK-NEXT:    [[ARRAYIDX44:%.*]] = getelementptr inbounds i32, ptr [[TMP51]], i64 3
// CHECK-NEXT:    [[SEC_LOWER_CAST45:%.*]] = ptrtoint ptr [[ARRAYIDX44]] to i64
// CHECK-NEXT:    [[TMP52:%.*]] = load ptr, ptr [[PBREF]], align 8
// CHECK-NEXT:    [[TMP53:%.*]] = load ptr, ptr [[TMP52]], align 8
// CHECK-NEXT:    [[ARRAYIDX46:%.*]] = getelementptr inbounds i32, ptr [[TMP53]], i64 12
// CHECK-NEXT:    [[SEC_UPPER_CAST47:%.*]] = ptrtoint ptr [[ARRAYIDX46]] to i64
// CHECK-NEXT:    [[TMP54:%.*]] = sub i64 [[SEC_UPPER_CAST47]], [[SEC_LOWER_CAST45]]
// CHECK-NEXT:    [[TMP55:%.*]] = sdiv exact i64 [[TMP54]], 4
// CHECK-NEXT:    [[SEC_NUMBER_OF_ELEMENTS48:%.*]] = add i64 [[TMP55]], 1
// CHECK-NEXT:    [[TMP56:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX44]], i32 0, i64 [[SEC_NUMBER_OF_ELEMENTS48]], i32 0) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP56]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    call void @_ZN6foobar5checkEv(ptr noundef nonnull align 8 dereferenceable(888) @bar)
// CHECK-NEXT:    [[TMP57:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR:%.*]], ptr @bar, i32 0, i32 1, i64 1), double 0.000000e+00, i64 2, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP57]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP58:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 1, i64 5), double 0.000000e+00, i64 1, i32 3) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP58]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP59:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 2, i64 1), double 0.000000e+00, i64 20, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP59]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP60:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr getelementptr inbounds ([[STRUCT_FOOBAR]], ptr @bar, i32 0, i32 2, i64 6, i64 8), double 0.000000e+00, i64 1, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP60]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-NEXT:    [[TMP61:%.*]] = load ptr, ptr [[SAVED_STACK]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore(ptr [[TMP61]])
// CHECK-NEXT:    ret void
//
void test_prefetch(unsigned long n) {
  int i = 1;
  int a;
  int b;
  int foo1[10];
  int foo2[10][10];
  int *p = foo1;

  //sections
  #pragma ompx prefetch data(foo1[:1])
  #pragma ompx prefetch data(0:foo1[1:1])
  #pragma ompx prefetch data(1:foo1[:2])
  #pragma ompx prefetch data(2:foo1[:9])
  #pragma ompx prefetch data(3:foo1[4:8])
  #pragma ompx prefetch data(4:foo1[3:i])
  #pragma ompx prefetch data(5:foo1[:])
  #pragma ompx prefetch data(6:foo1[i:5])

  // if clause
  #pragma ompx prefetch data(1:foo1[1:2]) if (a < b)
  #pragma ompx prefetch if (a == 0) data(1:foo1[i:3])

  // One data clause with two prefetch expressions should generate same IR
  // as prefetch with two data clauses and same expressions.
#ifndef MULTI_DATA
  #pragma ompx prefetch data(1:foo1[:1], foo2[:5][:])
#else
  #pragma ompx prefetch data(1:foo1[:1]) data(1:foo2[:5][:])
#endif

  //subscripts
  #pragma ompx prefetch data(3:foo1[1])
  #pragma ompx prefetch data(foo2[2][3])

  // vlas
  short vla[100][10][n];
  #pragma ompx prefetch data(vla[50][5:3][0:n])

  // pointers
  int *ptr_base;
  int *(&pbref) = ptr_base;
  #pragma ompx prefetch data(ptr_base[3:10])
  #pragma ompx prefetch data(pbref[3:10])

  // fields
  bar.check();
  #pragma ompx prefetch data(4:bar.d[1:2])
  #pragma ompx prefetch data(3:bar.d[5])
  #pragma ompx prefetch data(4:bar.d2[1:2][:])
  #pragma ompx prefetch data(4:bar.d2[6][8])
}

float mathfunc(float);
// CHECK-32-LABEL: @_Z14test_with_simdPfS_(
// CHECK-32-NEXT:  entry:
// CHECK-32-NEXT:    [[PTR_ADDR:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    [[A_ADDR:%.*]] = alloca ptr, align 4
// CHECK-32-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-32-NEXT:    store ptr [[PTR:%.*]], ptr [[PTR_ADDR]], align 4
// CHECK-32-NEXT:    store ptr [[A:%.*]], ptr [[A_ADDR]], align 4
// CHECK-32-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// CHECK-32-NEXT:    store i32 31, ptr [[DOTOMP_UB]], align 4
// CHECK-32-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.SHARED:TYPED"(ptr [[PTR_ADDR]], ptr null, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[A_ADDR]], ptr null, i32 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// CHECK-32-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I]], i32 0, i32 1, i32 1) ]
// CHECK-32-NEXT:    [[TMP2:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// CHECK-32-NEXT:    store i32 [[TMP2]], ptr [[DOTOMP_IV]], align 4
// CHECK-32-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// CHECK-32:       omp.inner.for.cond:
// CHECK-32-NEXT:    [[TMP3:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-32-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// CHECK-32-NEXT:    [[CMP:%.*]] = icmp sle i32 [[TMP3]], [[TMP4]]
// CHECK-32-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// CHECK-32:       omp.inner.for.body:
// CHECK-32-NEXT:    [[TMP5:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-32-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP5]], 1
// CHECK-32-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[MUL]]
// CHECK-32-NEXT:    store i32 [[ADD]], ptr [[I]], align 4
// CHECK-32-NEXT:    [[TMP6:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[A_ADDR]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds float, ptr [[TMP7]], i32 [[TMP6]]
// CHECK-32-NEXT:    [[SEC_LOWER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX]] to i32
// CHECK-32-NEXT:    [[TMP8:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[LB_ADD_LEN:%.*]] = add nsw i32 [[TMP8]], 31
// CHECK-32-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[A_ADDR]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds float, ptr [[TMP9]], i32 [[LB_ADD_LEN]]
// CHECK-32-NEXT:    [[SEC_UPPER_CAST:%.*]] = ptrtoint ptr [[ARRAYIDX1]] to i32
// CHECK-32-NEXT:    [[TMP10:%.*]] = sub i32 [[SEC_UPPER_CAST]], [[SEC_LOWER_CAST]]
// CHECK-32-NEXT:    [[TMP11:%.*]] = sdiv exact i32 [[TMP10]], 4
// CHECK-32-NEXT:    [[SEC_NUMBER_OF_ELEMENTS:%.*]] = add i32 [[TMP11]], 1
// CHECK-32-NEXT:    [[TMP12:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PREFETCH"(), "QUAL.OMP.DATA"(ptr [[ARRAYIDX]], float 0.000000e+00, i32 [[SEC_NUMBER_OF_ELEMENTS]], i32 0) ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP12]]) [ "DIR.OMP.END.PREFETCH"() ]
// CHECK-32-NEXT:    [[TMP13:%.*]] = load ptr, ptr [[A_ADDR]], align 4
// CHECK-32-NEXT:    [[TMP14:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds float, ptr [[TMP13]], i32 [[TMP14]]
// CHECK-32-NEXT:    [[TMP15:%.*]] = load float, ptr [[ARRAYIDX2]], align 4
// CHECK-32-NEXT:    [[CALL:%.*]] = call noundef float @_Z8mathfuncf(float noundef [[TMP15]]) #[[ATTR1:[0-9]+]]
// CHECK-32-NEXT:    [[TMP16:%.*]] = load ptr, ptr [[PTR_ADDR]], align 4
// CHECK-32-NEXT:    [[TMP17:%.*]] = load i32, ptr [[I]], align 4
// CHECK-32-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds float, ptr [[TMP16]], i32 [[TMP17]]
// CHECK-32-NEXT:    store float [[CALL]], ptr [[ARRAYIDX3]], align 4
// CHECK-32-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// CHECK-32:       omp.body.continue:
// CHECK-32-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// CHECK-32:       omp.inner.for.inc:
// CHECK-32-NEXT:    [[TMP18:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-32-NEXT:    [[ADD4:%.*]] = add nsw i32 [[TMP18]], 1
// CHECK-32-NEXT:    store i32 [[ADD4]], ptr [[DOTOMP_IV]], align 4
// CHECK-32-NEXT:    br label [[OMP_INNER_FOR_COND]], !llvm.loop [[LOOP4:![0-9]+]]
// CHECK-32:       omp.inner.for.end:
// CHECK-32-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// CHECK-32:       omp.loop.exit:
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.SIMD"() ]
// CHECK-32-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// CHECK-32-NEXT:    ret void
//
void test_with_simd(float *ptr, float a[]) {
  #pragma omp parallel for simd
  for (int i = 0; i < 32; ++i) {
    #pragma ompx prefetch data(a[i:32])
    ptr[i] = mathfunc(a[i]);
  }
}
#endif
// end INTEL_COLLAB
