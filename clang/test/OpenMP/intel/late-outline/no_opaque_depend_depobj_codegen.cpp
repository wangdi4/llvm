// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --include-generated-funcs --prefix-filecheck-ir-name _
// RUN: %clang_cc1 -no-opaque-pointers -emit-llvm -o - -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-new-depend-ir -triple x86_64-unknown-linux-gnu %s \
// RUN:  -fopenmp-version=51 | FileCheck %s
// RUN: %clang_cc1 -no-opaque-pointers -emit-llvm -o - -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-new-depend-ir -triple x86_64-unknown-linux-gnu %s \
// RUN:  -fopenmp-version=51 -emit-pch -o %t
// RUN: %clang_cc1 -no-opaque-pointers -emit-llvm -o - -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-new-depend-ir -triple x86_64-unknown-linux-gnu %s \
// RUN:  -fopenmp-version=51 -include-pch %t | FileCheck %s

// Verify new IR generation for depend clause and depobj directive.
#ifndef HEADER
#define HEADER

typedef void *omp_depend_t;
void doSomething();
int xxx=0;

void foo1() {
  int aaa,bbb,ccc,ddd,eee,ppp,qqq;
  omp_depend_t obj1;
  omp_depend_t obj2;

  // depobj directive
  #pragma omp depobj(obj1) depend(in:ppp)
  #pragma omp depobj(obj2) depend(out:qqq)
  if (xxx==0) {
    #pragma omp depobj(obj1) update(inout)
    #pragma omp depobj(obj2) destroy
  } else {
    #pragma omp depobj(obj2) update(mutexinoutset)
    #pragma omp depobj(obj1) destroy
  }
#pragma omp parallel
  {
    // depobj dependency type.
    // FIXME: omp_all_memory not yet supported.
    #pragma omp task \
          depend(depobj:obj1) depend(in:aaa) depend(out:bbb) \
          depend(inout:ccc) depend(mutexinoutset:ddd) depend(inoutset:eee)
    {
      doSomething();
    }

    // Reuse dependencies from previous depobj.
    #pragma omp task depend(depobj:obj1)
    {
      doSomething();
    }

    // depend using an array slice.
    {
      short **b, ***c;
      c = &b;

      #pragma omp task depend(in:c[1000:4][100:3][10:2])
      {
        doSomething();
      }
    }
  }
}
#endif // HEADER
// CHECK-LABEL: @_Z4foo1v(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[AAA:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[BBB:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[CCC:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DDD:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[EEE:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[PPP:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[QQQ:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[OBJ1:%.*]] = alloca i8*, align 8
// CHECK-NEXT:    [[OBJ2:%.*]] = alloca i8*, align 8
// CHECK-NEXT:    [[DEPOBJ_SIZE_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[SAVED_STACK:%.*]] = alloca i8*, align 8
// CHECK-NEXT:    [[__VLA_EXPR0:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEPOBJ_SIZE_ADDR7:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[SAVED_STACK8:%.*]] = alloca i8*, align 8
// CHECK-NEXT:    [[__VLA_EXPR1:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR10:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[B:%.*]] = alloca i16**, align 8
// CHECK-NEXT:    [[C:%.*]] = alloca i16***, align 8
// CHECK-NEXT:    [[DOTDEP_ARR_ADDR11:%.*]] = alloca [1 x %struct.kmp_depend_info], align 8
// CHECK-NEXT:    [[DEP_COUNTER_ADDR17:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = call i32 @__kmpc_global_thread_num(%struct.ident_t* @[[GLOB1:[0-9]+]])
// CHECK-NEXT:    [[DOTDEP_ARR_ADDR:%.*]] = call i8* @__kmpc_alloc(i32 [[TMP0]], i64 48, i8* null)
// CHECK-NEXT:    [[TMP1:%.*]] = bitcast i8* [[DOTDEP_ARR_ADDR]] to %struct.kmp_depend_info*
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO:%.*]], %struct.kmp_depend_info* [[TMP1]], i32 0, i32 0
// CHECK-NEXT:    store i64 1, i64* [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP1]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP3]], i32 0, i32 0
// CHECK-NEXT:    [[TMP5:%.*]] = ptrtoint i32* [[PPP]] to i64
// CHECK-NEXT:    store i64 [[TMP5]], i64* [[TMP4]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP3]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP3]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, i8* [[TMP7]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP1]], i64 1
// CHECK-NEXT:    [[TMP9:%.*]] = bitcast %struct.kmp_depend_info* [[TMP8]] to i8*
// CHECK-NEXT:    store i8* [[TMP9]], i8** [[OBJ1]], align 8
// CHECK-NEXT:    [[DOTDEP_ARR_ADDR1:%.*]] = call i8* @__kmpc_alloc(i32 [[TMP0]], i64 48, i8* null)
// CHECK-NEXT:    [[TMP10:%.*]] = bitcast i8* [[DOTDEP_ARR_ADDR1]] to %struct.kmp_depend_info*
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP10]], i32 0, i32 0
// CHECK-NEXT:    store i64 1, i64* [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP10]], i64 1
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP12]], i32 0, i32 0
// CHECK-NEXT:    [[TMP14:%.*]] = ptrtoint i32* [[QQQ]] to i64
// CHECK-NEXT:    store i64 [[TMP14]], i64* [[TMP13]], align 8
// CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP12]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP15]], align 8
// CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP12]], i32 0, i32 2
// CHECK-NEXT:    store i8 3, i8* [[TMP16]], align 8
// CHECK-NEXT:    [[TMP17:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP10]], i64 1
// CHECK-NEXT:    [[TMP18:%.*]] = bitcast %struct.kmp_depend_info* [[TMP17]] to i8*
// CHECK-NEXT:    store i8* [[TMP18]], i8** [[OBJ2]], align 8
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, i32* @xxx, align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP19]], 0
// CHECK-NEXT:    br i1 [[CMP]], label [[IF_THEN:%.*]], label [[IF_ELSE:%.*]]
// CHECK:       if.then:
// CHECK-NEXT:    [[TMP20:%.*]] = bitcast i8** [[OBJ1]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP21:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP20]], align 8
// CHECK-NEXT:    [[TMP22:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP21]], i64 -1
// CHECK-NEXT:    [[TMP23:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP22]], i32 0, i32 0
// CHECK-NEXT:    [[TMP24:%.*]] = load i64, i64* [[TMP23]], align 8
// CHECK-NEXT:    [[TMP25:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP21]], i64 [[TMP24]]
// CHECK-NEXT:    br label [[OMP_BODY:%.*]]
// CHECK:       omp.body:
// CHECK-NEXT:    [[OMP_ELEMENTPAST:%.*]] = phi %struct.kmp_depend_info* [ [[TMP21]], [[IF_THEN]] ], [ [[OMP_ELEMENTNEXT:%.*]], [[OMP_BODY]] ]
// CHECK-NEXT:    [[TMP26:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[OMP_ELEMENTPAST]], i32 0, i32 2
// CHECK-NEXT:    store i8 3, i8* [[TMP26]], align 8
// CHECK-NEXT:    [[OMP_ELEMENTNEXT]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[OMP_ELEMENTPAST]], i64 1
// CHECK-NEXT:    [[OMP_ISEMPTY:%.*]] = icmp eq %struct.kmp_depend_info* [[OMP_ELEMENTNEXT]], [[TMP25]]
// CHECK-NEXT:    br i1 [[OMP_ISEMPTY]], label [[OMP_DONE:%.*]], label [[OMP_BODY]]
// CHECK:       omp.done:
// CHECK-NEXT:    [[TMP27:%.*]] = load i8*, i8** [[OBJ2]], align 8
// CHECK-NEXT:    [[TMP28:%.*]] = bitcast i8* [[TMP27]] to %struct.kmp_depend_info*
// CHECK-NEXT:    [[TMP29:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP28]], i64 -1
// CHECK-NEXT:    [[TMP30:%.*]] = bitcast %struct.kmp_depend_info* [[TMP29]] to i8*
// CHECK-NEXT:    call void @__kmpc_free(i32 [[TMP0]], i8* [[TMP30]], i8* null)
// CHECK-NEXT:    br label [[IF_END:%.*]]
// CHECK:       if.else:
// CHECK-NEXT:    [[TMP31:%.*]] = bitcast i8** [[OBJ2]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP32:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP31]], align 8
// CHECK-NEXT:    [[TMP33:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP32]], i64 -1
// CHECK-NEXT:    [[TMP34:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP33]], i32 0, i32 0
// CHECK-NEXT:    [[TMP35:%.*]] = load i64, i64* [[TMP34]], align 8
// CHECK-NEXT:    [[TMP36:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP32]], i64 [[TMP35]]
// CHECK-NEXT:    br label [[OMP_BODY2:%.*]]
// CHECK:       omp.body2:
// CHECK-NEXT:    [[OMP_ELEMENTPAST3:%.*]] = phi %struct.kmp_depend_info* [ [[TMP32]], [[IF_ELSE]] ], [ [[OMP_ELEMENTNEXT4:%.*]], [[OMP_BODY2]] ]
// CHECK-NEXT:    [[TMP37:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[OMP_ELEMENTPAST3]], i32 0, i32 2
// CHECK-NEXT:    store i8 4, i8* [[TMP37]], align 8
// CHECK-NEXT:    [[OMP_ELEMENTNEXT4]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[OMP_ELEMENTPAST3]], i64 1
// CHECK-NEXT:    [[OMP_ISEMPTY5:%.*]] = icmp eq %struct.kmp_depend_info* [[OMP_ELEMENTNEXT4]], [[TMP36]]
// CHECK-NEXT:    br i1 [[OMP_ISEMPTY5]], label [[OMP_DONE6:%.*]], label [[OMP_BODY2]]
// CHECK:       omp.done6:
// CHECK-NEXT:    [[TMP38:%.*]] = load i8*, i8** [[OBJ1]], align 8
// CHECK-NEXT:    [[TMP39:%.*]] = bitcast i8* [[TMP38]] to %struct.kmp_depend_info*
// CHECK-NEXT:    [[TMP40:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP39]], i64 -1
// CHECK-NEXT:    [[TMP41:%.*]] = bitcast %struct.kmp_depend_info* [[TMP40]] to i8*
// CHECK-NEXT:    call void @__kmpc_free(i32 [[TMP0]], i8* [[TMP41]], i8* null)
// CHECK-NEXT:    br label [[IF_END]]
// CHECK:       if.end:
// CHECK-NEXT:    [[TMP42:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.SHARED"(i32* [[AAA]]), "QUAL.OMP.SHARED"(i32* [[BBB]]), "QUAL.OMP.SHARED"(i32* [[CCC]]), "QUAL.OMP.SHARED"(i32* [[DDD]]), "QUAL.OMP.SHARED"(i32* [[EEE]]), "QUAL.OMP.SHARED"(i8** [[OBJ1]]), "QUAL.OMP.PRIVATE"(i16*** [[B]]), "QUAL.OMP.PRIVATE"(i16**** [[C]]), "QUAL.OMP.PRIVATE"(i64* [[DEPOBJ_SIZE_ADDR]]), "QUAL.OMP.PRIVATE"(i8** [[SAVED_STACK]]), "QUAL.OMP.PRIVATE"(i64* [[__VLA_EXPR0]]), "QUAL.OMP.PRIVATE"(i64* [[DEP_COUNTER_ADDR]]), "QUAL.OMP.PRIVATE"(i64* [[DEPOBJ_SIZE_ADDR7]]), "QUAL.OMP.PRIVATE"(i8** [[SAVED_STACK8]]), "QUAL.OMP.PRIVATE"(i64* [[__VLA_EXPR1]]), "QUAL.OMP.PRIVATE"(i64* [[DEP_COUNTER_ADDR10]]), "QUAL.OMP.PRIVATE"([1 x %struct.kmp_depend_info]* [[DOTDEP_ARR_ADDR11]]), "QUAL.OMP.PRIVATE"(i64* [[DEP_COUNTER_ADDR17]]) ]
// CHECK-NEXT:    [[TMP43:%.*]] = bitcast i8** [[OBJ1]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP44:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP43]], align 8
// CHECK-NEXT:    [[TMP45:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP44]], i64 -1
// CHECK-NEXT:    [[TMP46:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP45]], i32 0, i32 0
// CHECK-NEXT:    [[TMP47:%.*]] = load i64, i64* [[TMP46]], align 8
// CHECK-NEXT:    store i64 0, i64* [[DEPOBJ_SIZE_ADDR]], align 8
// CHECK-NEXT:    [[TMP48:%.*]] = load i64, i64* [[DEPOBJ_SIZE_ADDR]], align 8
// CHECK-NEXT:    [[TMP49:%.*]] = add nuw i64 [[TMP48]], [[TMP47]]
// CHECK-NEXT:    store i64 [[TMP49]], i64* [[DEPOBJ_SIZE_ADDR]], align 8
// CHECK-NEXT:    [[TMP50:%.*]] = load i64, i64* [[DEPOBJ_SIZE_ADDR]], align 8
// CHECK-NEXT:    [[TMP51:%.*]] = add nuw i64 0, [[TMP50]]
// CHECK-NEXT:    [[TMP52:%.*]] = add nuw i64 [[TMP51]], 5
// CHECK-NEXT:    [[TMP53:%.*]] = call i8* @llvm.stacksave()
// CHECK-NEXT:    store i8* [[TMP53]], i8** [[SAVED_STACK]], align 8
// CHECK-NEXT:    [[VLA:%.*]] = alloca [[STRUCT_KMP_DEPEND_INFO]], i64 [[TMP52]], align 16
// CHECK-NEXT:    store i64 [[TMP52]], i64* [[__VLA_EXPR0]], align 8
// CHECK-NEXT:    [[TMP54:%.*]] = trunc i64 [[TMP52]] to i32
// CHECK-NEXT:    [[TMP55:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 0
// CHECK-NEXT:    [[TMP56:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP55]], i32 0, i32 0
// CHECK-NEXT:    [[TMP57:%.*]] = ptrtoint i32* [[AAA]] to i64
// CHECK-NEXT:    store i64 [[TMP57]], i64* [[TMP56]], align 16
// CHECK-NEXT:    [[TMP58:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP55]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP58]], align 8
// CHECK-NEXT:    [[TMP59:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP55]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, i8* [[TMP59]], align 16
// CHECK-NEXT:    [[TMP60:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 1
// CHECK-NEXT:    [[TMP61:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP60]], i32 0, i32 0
// CHECK-NEXT:    [[TMP62:%.*]] = ptrtoint i32* [[BBB]] to i64
// CHECK-NEXT:    store i64 [[TMP62]], i64* [[TMP61]], align 8
// CHECK-NEXT:    [[TMP63:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP60]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP63]], align 8
// CHECK-NEXT:    [[TMP64:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP60]], i32 0, i32 2
// CHECK-NEXT:    store i8 3, i8* [[TMP64]], align 8
// CHECK-NEXT:    [[TMP65:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 2
// CHECK-NEXT:    [[TMP66:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP65]], i32 0, i32 0
// CHECK-NEXT:    [[TMP67:%.*]] = ptrtoint i32* [[CCC]] to i64
// CHECK-NEXT:    store i64 [[TMP67]], i64* [[TMP66]], align 16
// CHECK-NEXT:    [[TMP68:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP65]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP68]], align 8
// CHECK-NEXT:    [[TMP69:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP65]], i32 0, i32 2
// CHECK-NEXT:    store i8 3, i8* [[TMP69]], align 16
// CHECK-NEXT:    [[TMP70:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 3
// CHECK-NEXT:    [[TMP71:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP70]], i32 0, i32 0
// CHECK-NEXT:    [[TMP72:%.*]] = ptrtoint i32* [[DDD]] to i64
// CHECK-NEXT:    store i64 [[TMP72]], i64* [[TMP71]], align 8
// CHECK-NEXT:    [[TMP73:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP70]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP73]], align 8
// CHECK-NEXT:    [[TMP74:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP70]], i32 0, i32 2
// CHECK-NEXT:    store i8 4, i8* [[TMP74]], align 8
// CHECK-NEXT:    [[TMP75:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 4
// CHECK-NEXT:    [[TMP76:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP75]], i32 0, i32 0
// CHECK-NEXT:    [[TMP77:%.*]] = ptrtoint i32* [[EEE]] to i64
// CHECK-NEXT:    store i64 [[TMP77]], i64* [[TMP76]], align 16
// CHECK-NEXT:    [[TMP78:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP75]], i32 0, i32 1
// CHECK-NEXT:    store i64 4, i64* [[TMP78]], align 8
// CHECK-NEXT:    [[TMP79:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP75]], i32 0, i32 2
// CHECK-NEXT:    store i8 8, i8* [[TMP79]], align 16
// CHECK-NEXT:    store i64 5, i64* [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP80:%.*]] = bitcast i8** [[OBJ1]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP81:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP80]], align 8
// CHECK-NEXT:    [[TMP82:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP81]], i64 -1
// CHECK-NEXT:    [[TMP83:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP82]], i32 0, i32 0
// CHECK-NEXT:    [[TMP84:%.*]] = load i64, i64* [[TMP83]], align 8
// CHECK-NEXT:    [[TMP85:%.*]] = mul nuw i64 24, [[TMP84]]
// CHECK-NEXT:    [[TMP86:%.*]] = load i64, i64* [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP87:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA]], i64 [[TMP86]]
// CHECK-NEXT:    [[TMP88:%.*]] = bitcast %struct.kmp_depend_info* [[TMP87]] to i8*
// CHECK-NEXT:    [[TMP89:%.*]] = bitcast %struct.kmp_depend_info* [[TMP81]] to i8*
// CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 [[TMP88]], i8* align 8 [[TMP89]], i64 [[TMP85]], i1 false)
// CHECK-NEXT:    [[TMP90:%.*]] = add nuw i64 [[TMP86]], [[TMP84]]
// CHECK-NEXT:    store i64 [[TMP90]], i64* [[DEP_COUNTER_ADDR]], align 8
// CHECK-NEXT:    [[TMP91:%.*]] = bitcast %struct.kmp_depend_info* [[VLA]] to i8*
// CHECK-NEXT:    [[TMP92:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.DEPARRAY"(i32 [[TMP54]], i8* [[TMP91]]) ]
// CHECK-NEXT:    call void @_Z11doSomethingv() #[[ATTR1:[0-9]+]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP92]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    [[TMP93:%.*]] = load i8*, i8** [[SAVED_STACK]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore(i8* [[TMP93]])
// CHECK-NEXT:    [[TMP94:%.*]] = bitcast i8** [[OBJ1]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP95:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP94]], align 8
// CHECK-NEXT:    [[TMP96:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP95]], i64 -1
// CHECK-NEXT:    [[TMP97:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP96]], i32 0, i32 0
// CHECK-NEXT:    [[TMP98:%.*]] = load i64, i64* [[TMP97]], align 8
// CHECK-NEXT:    store i64 0, i64* [[DEPOBJ_SIZE_ADDR7]], align 8
// CHECK-NEXT:    [[TMP99:%.*]] = load i64, i64* [[DEPOBJ_SIZE_ADDR7]], align 8
// CHECK-NEXT:    [[TMP100:%.*]] = add nuw i64 [[TMP99]], [[TMP98]]
// CHECK-NEXT:    store i64 [[TMP100]], i64* [[DEPOBJ_SIZE_ADDR7]], align 8
// CHECK-NEXT:    [[TMP101:%.*]] = load i64, i64* [[DEPOBJ_SIZE_ADDR7]], align 8
// CHECK-NEXT:    [[TMP102:%.*]] = add nuw i64 0, [[TMP101]]
// CHECK-NEXT:    [[TMP103:%.*]] = add nuw i64 [[TMP102]], 0
// CHECK-NEXT:    [[TMP104:%.*]] = call i8* @llvm.stacksave()
// CHECK-NEXT:    store i8* [[TMP104]], i8** [[SAVED_STACK8]], align 8
// CHECK-NEXT:    [[VLA9:%.*]] = alloca [[STRUCT_KMP_DEPEND_INFO]], i64 [[TMP103]], align 16
// CHECK-NEXT:    store i64 [[TMP103]], i64* [[__VLA_EXPR1]], align 8
// CHECK-NEXT:    [[TMP105:%.*]] = trunc i64 [[TMP103]] to i32
// CHECK-NEXT:    store i64 0, i64* [[DEP_COUNTER_ADDR10]], align 8
// CHECK-NEXT:    [[TMP106:%.*]] = bitcast i8** [[OBJ1]] to %struct.kmp_depend_info**
// CHECK-NEXT:    [[TMP107:%.*]] = load %struct.kmp_depend_info*, %struct.kmp_depend_info** [[TMP106]], align 8
// CHECK-NEXT:    [[TMP108:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP107]], i64 -1
// CHECK-NEXT:    [[TMP109:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP108]], i32 0, i32 0
// CHECK-NEXT:    [[TMP110:%.*]] = load i64, i64* [[TMP109]], align 8
// CHECK-NEXT:    [[TMP111:%.*]] = mul nuw i64 24, [[TMP110]]
// CHECK-NEXT:    [[TMP112:%.*]] = load i64, i64* [[DEP_COUNTER_ADDR10]], align 8
// CHECK-NEXT:    [[TMP113:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[VLA9]], i64 [[TMP112]]
// CHECK-NEXT:    [[TMP114:%.*]] = bitcast %struct.kmp_depend_info* [[TMP113]] to i8*
// CHECK-NEXT:    [[TMP115:%.*]] = bitcast %struct.kmp_depend_info* [[TMP107]] to i8*
// CHECK-NEXT:    call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 [[TMP114]], i8* align 8 [[TMP115]], i64 [[TMP111]], i1 false)
// CHECK-NEXT:    [[TMP116:%.*]] = add nuw i64 [[TMP112]], [[TMP110]]
// CHECK-NEXT:    store i64 [[TMP116]], i64* [[DEP_COUNTER_ADDR10]], align 8
// CHECK-NEXT:    [[TMP117:%.*]] = bitcast %struct.kmp_depend_info* [[VLA9]] to i8*
// CHECK-NEXT:    [[TMP118:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.DEPARRAY"(i32 [[TMP105]], i8* [[TMP117]]) ]
// CHECK-NEXT:    call void @_Z11doSomethingv() #[[ATTR1]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP118]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    [[TMP119:%.*]] = load i8*, i8** [[SAVED_STACK8]], align 8
// CHECK-NEXT:    call void @llvm.stackrestore(i8* [[TMP119]])
// CHECK-NEXT:    store i16*** [[B]], i16**** [[C]], align 8
// CHECK-NEXT:    [[TMP120:%.*]] = getelementptr inbounds [1 x %struct.kmp_depend_info], [1 x %struct.kmp_depend_info]* [[DOTDEP_ARR_ADDR11]], i64 0, i64 0
// CHECK-NEXT:    [[TMP121:%.*]] = load i16***, i16**** [[C]], align 8
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i16**, i16*** [[TMP121]], i64 1000
// CHECK-NEXT:    [[TMP122:%.*]] = load i16**, i16*** [[ARRAYIDX]], align 8
// CHECK-NEXT:    [[ARRAYIDX12:%.*]] = getelementptr inbounds i16*, i16** [[TMP122]], i64 100
// CHECK-NEXT:    [[TMP123:%.*]] = load i16*, i16** [[ARRAYIDX12]], align 8
// CHECK-NEXT:    [[ARRAYIDX13:%.*]] = getelementptr inbounds i16, i16* [[TMP123]], i64 10
// CHECK-NEXT:    [[TMP124:%.*]] = load i16***, i16**** [[C]], align 8
// CHECK-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds i16**, i16*** [[TMP124]], i64 1003
// CHECK-NEXT:    [[TMP125:%.*]] = load i16**, i16*** [[ARRAYIDX14]], align 8
// CHECK-NEXT:    [[ARRAYIDX15:%.*]] = getelementptr inbounds i16*, i16** [[TMP125]], i64 102
// CHECK-NEXT:    [[TMP126:%.*]] = load i16*, i16** [[ARRAYIDX15]], align 8
// CHECK-NEXT:    [[ARRAYIDX16:%.*]] = getelementptr inbounds i16, i16* [[TMP126]], i64 11
// CHECK-NEXT:    [[TMP127:%.*]] = getelementptr i16, i16* [[ARRAYIDX16]], i32 1
// CHECK-NEXT:    [[TMP128:%.*]] = ptrtoint i16* [[ARRAYIDX13]] to i64
// CHECK-NEXT:    [[TMP129:%.*]] = ptrtoint i16* [[TMP127]] to i64
// CHECK-NEXT:    [[TMP130:%.*]] = sub nuw i64 [[TMP129]], [[TMP128]]
// CHECK-NEXT:    [[TMP131:%.*]] = getelementptr [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP120]], i64 0
// CHECK-NEXT:    [[TMP132:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP131]], i32 0, i32 0
// CHECK-NEXT:    [[TMP133:%.*]] = ptrtoint i16* [[ARRAYIDX13]] to i64
// CHECK-NEXT:    store i64 [[TMP133]], i64* [[TMP132]], align 8
// CHECK-NEXT:    [[TMP134:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP131]], i32 0, i32 1
// CHECK-NEXT:    store i64 [[TMP130]], i64* [[TMP134]], align 8
// CHECK-NEXT:    [[TMP135:%.*]] = getelementptr inbounds [[STRUCT_KMP_DEPEND_INFO]], %struct.kmp_depend_info* [[TMP131]], i32 0, i32 2
// CHECK-NEXT:    store i8 1, i8* [[TMP135]], align 8
// CHECK-NEXT:    store i64 1, i64* [[DEP_COUNTER_ADDR17]], align 8
// CHECK-NEXT:    [[TMP136:%.*]] = bitcast %struct.kmp_depend_info* [[TMP120]] to i8*
// CHECK-NEXT:    [[TMP137:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TASK"(), "QUAL.OMP.DEPARRAY"(i32 1, i8* [[TMP136]]) ]
// CHECK-NEXT:    call void @_Z11doSomethingv() #[[ATTR1]]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP137]]) [ "DIR.OMP.END.TASK"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP42]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    ret void
//
// end INTEL_COLLAB
