// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --include-generated-funcs --prefix-filecheck-ir-name _ --version 3

// RUN: %clang_cc1 -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-version=50 -triple x86_64-unknown-linux-gnu -emit-pch %s -o %t

// RUN: %clang_cc1 -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-loop-rotation-control=0 -fopenmp-version=50 \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s | FileCheck %s

// RUN: %clang_cc1 -fopenmp -fopenmp-late-outline \
// RUN:   -fopenmp-loop-rotation-control=0 -fopenmp-version=50 \
// RUN:   -triple x86_64-unknown-linux-gnu -include-pch %t -emit-llvm %s -o - \
// RUN:   | FileCheck %s

// RUN: %clang_cc1 -fopenmp -fopenmp-late-outline \
// RUN:  -fopenmp-loop-rotation-control=1 -fopenmp-version=50 \
// RUN:  -triple x86_64-unknown-linux-gnu -emit-llvm -o - %s \
// RUN:  | FileCheck %s -check-prefix ROT1

// RUN: %clang_cc1 -fopenmp -fopenmp-late-outline \
// RUN:   -fopenmp-loop-rotation-control=1 -fopenmp-version=50 \
// RUN:   -triple x86_64-unknown-linux-gnu -include-pch %t -emit-llvm %s -o - \
// RUN:   | FileCheck %s -check-prefix ROT1

// Verify ompx_places clause accepted with target directives

#ifndef HEADER
#define HEADER

template<typename tx, typename ty>
struct TT{
  tx X;
  ty Y;
};

int global;
extern int global;

extern int func(int i);

class S {
  int bar;
  S();
public:

  S(int foo) : bar(foo) {}
};

int test(int n) {
  int level, start, length, stride;
  int a = 0;
  TT<long, char> d;
  TT<int *, int *> d2;
  int vec[10];

  // Check basic cases.
  #pragma omp target ompx_places(start)
  {}

  #pragma omp target ompx_places(numa_domain,start)
  {}

  #pragma omp target ompx_places(start:length)
  {}

  #pragma omp target teams ompx_places(start:length:stride)
  {}

  #pragma omp target ompx_places(subnuma_domain,start:length:stride)
  {}

  #pragma omp target ompx_places(0)
  {}

  #pragma omp target ompx_places(numa_domain,0)
  {}

  #pragma omp target ompx_places(2:3)
  {}

  #pragma omp target ompx_places(2:3:4)
  {}

  #pragma omp target ompx_places(subnuma_domain,5:6:7)
  {}

  #pragma omp target ompx_places(numa_domain,8:length:9)
  {}

  // Check different argument types and use with other clauses.
  #pragma omp target ompx_places(d.Y:d.X)
  {}

  #pragma omp target ompx_places(func(a):2147483647)
  {}

  #pragma omp target ompx_places(*(d2.X):*(d2.Y):stride)
  {}

  #pragma omp target enter data device(a) map(alloc: d.X) \
      ompx_places(10:20:vec[start])

  #pragma omp target exit data device(a) map(release: d.X) ompx_places(30:40)

  #pragma omp target data use_device_addr(a) ompx_places(start:length)
  {}

  #pragma omp target update device(n) ompx_places(n:global) from(a)
  {}

  #pragma omp target simd ompx_places(start:length)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target parallel for ompx_places(start)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target parallel for simd ompx_places(numa_domain,start)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target parallel loop ompx_places(subnuma_domain,start:length)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target teams distribute ompx_places(start)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target teams distribute simd ompx_places(1:10)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target teams loop ompx_places(2:20:100)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target teams distribute parallel for ompx_places(start:length)
  for(int i=0; i < 10; ++i) {}

  #pragma omp target teams distribute parallel for simd \
      ompx_places(start:length)
  for(int i=0; i < 10; ++i) {}

  return 0;
}

template <typename T, unsigned start, unsigned length, unsigned stride>
T run() {
  #pragma omp target ompx_places(numa_domain,start:length:stride)
  {}
  #pragma omp target ompx_places(subnuma_domain,start:length)
  {}
  #pragma omp target ompx_places(numa_domain,start)
  {}
  #pragma omp target ompx_places(start)
  {}
}

int use_template() { run<void,1,2,3>(); return 0; }
#endif // HEADER
// CHECK-LABEL: define dso_local noundef i32 @_Z4testi(
// CHECK-SAME: i32 noundef [[N:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[N_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[LEVEL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[START:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[LENGTH:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[STRIDE:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[D:%.*]] = alloca [[STRUCT_TT:%.*]], align 8
// CHECK-NEXT:    [[D2:%.*]] = alloca [[STRUCT_TT_0:%.*]], align 8
// CHECK-NEXT:    [[VEC:%.*]] = alloca [10 x i32], align 16
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_5:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_6:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_7:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_8:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_9:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_10:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_11:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_12:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_13:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_14:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_15:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_16:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_17:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_18:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_19:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_20:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_21:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_22:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_23:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_24:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_25:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP6:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV7:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB8:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I12:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_26:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP20:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV21:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB22:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB23:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I27:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_27:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_28:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP35:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV36:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB37:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB38:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I42:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_29:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP50:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV51:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB52:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB53:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I57:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP65:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV66:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB67:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB68:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I72:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP80:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV81:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB82:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB83:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I87:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_30:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_31:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP95:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV96:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB97:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB98:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I102:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_32:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_33:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[_TMP110:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV111:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB112:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB113:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I117:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 [[N]], ptr [[N_ADDR]], align 4
// CHECK-NEXT:    store i32 0, ptr [[A]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// CHECK-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// CHECK-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 0), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP1]], i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP3]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// CHECK-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// CHECK-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 1), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP4]], i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP6:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP6]], ptr [[DOTCAPTURE_EXPR_2]], align 4
// CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP7]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_2]], align 4
// CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// CHECK-NEXT:    [[TMP10:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 2), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP8]], i32 [[TMP9]], i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP10]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP11:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP11]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP12]], ptr [[DOTCAPTURE_EXPR_5]], align 4
// CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[STRIDE]], align 4
// CHECK-NEXT:    store i32 [[TMP13]], ptr [[DOTCAPTURE_EXPR_6]], align 4
// CHECK-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_5]], align 4
// CHECK-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_6]], align 4
// CHECK-NEXT:    [[TMP17:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 3), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP14]], i32 [[TMP15]], i32 [[TMP16]]) ]
// CHECK-NEXT:    [[TMP18:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP18]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP17]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP19]], ptr [[DOTCAPTURE_EXPR_7]], align 4
// CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP20]], ptr [[DOTCAPTURE_EXPR_8]], align 4
// CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[STRIDE]], align 4
// CHECK-NEXT:    store i32 [[TMP21]], ptr [[DOTCAPTURE_EXPR_9]], align 4
// CHECK-NEXT:    [[TMP22:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_7]], align 4
// CHECK-NEXT:    [[TMP23:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_8]], align 4
// CHECK-NEXT:    [[TMP24:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_9]], align 4
// CHECK-NEXT:    [[TMP25:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 4), "QUAL.OMP.SUBDEVICE"(i32 1, i32 [[TMP22]], i32 [[TMP23]], i32 [[TMP24]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP25]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP26:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 5), "QUAL.OMP.SUBDEVICE"(i32 0, i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP26]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP27:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 6), "QUAL.OMP.SUBDEVICE"(i32 0, i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP27]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP28:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 7), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 3, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP28]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP29:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 8), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 3, i32 4) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP29]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP30:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 9), "QUAL.OMP.SUBDEVICE"(i32 1, i32 5, i32 6, i32 7) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP30]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP31:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP31]], ptr [[DOTCAPTURE_EXPR_10]], align 4
// CHECK-NEXT:    [[TMP32:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_10]], align 4
// CHECK-NEXT:    [[TMP33:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 10), "QUAL.OMP.SUBDEVICE"(i32 0, i32 8, i32 [[TMP32]], i32 9) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP33]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[Y:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 1
// CHECK-NEXT:    [[TMP34:%.*]] = load i8, ptr [[Y]], align 8
// CHECK-NEXT:    store i8 [[TMP34]], ptr [[DOTCAPTURE_EXPR_11]], align 1
// CHECK-NEXT:    [[X:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// CHECK-NEXT:    [[TMP35:%.*]] = load i64, ptr [[X]], align 8
// CHECK-NEXT:    store i64 [[TMP35]], ptr [[DOTCAPTURE_EXPR_12]], align 8
// CHECK-NEXT:    [[TMP36:%.*]] = load i8, ptr [[DOTCAPTURE_EXPR_11]], align 1
// CHECK-NEXT:    [[TMP37:%.*]] = load i64, ptr [[DOTCAPTURE_EXPR_12]], align 8
// CHECK-NEXT:    [[TMP38:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 11), "QUAL.OMP.SUBDEVICE"(i32 0, i8 [[TMP36]], i64 [[TMP37]], i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP38]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP39:%.*]] = load i32, ptr [[A]], align 4
// CHECK-NEXT:    [[CALL:%.*]] = call noundef i32 @_Z4funci(i32 noundef [[TMP39]])
// CHECK-NEXT:    store i32 [[CALL]], ptr [[DOTCAPTURE_EXPR_13]], align 4
// CHECK-NEXT:    [[TMP40:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_13]], align 4
// CHECK-NEXT:    [[TMP41:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 12), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP40]], i32 2147483647, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP41]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[X1:%.*]] = getelementptr inbounds [[STRUCT_TT_0]], ptr [[D2]], i32 0, i32 0
// CHECK-NEXT:    [[TMP42:%.*]] = load ptr, ptr [[X1]], align 8
// CHECK-NEXT:    [[TMP43:%.*]] = load i32, ptr [[TMP42]], align 4
// CHECK-NEXT:    store i32 [[TMP43]], ptr [[DOTCAPTURE_EXPR_14]], align 4
// CHECK-NEXT:    [[Y2:%.*]] = getelementptr inbounds [[STRUCT_TT_0]], ptr [[D2]], i32 0, i32 1
// CHECK-NEXT:    [[TMP44:%.*]] = load ptr, ptr [[Y2]], align 8
// CHECK-NEXT:    [[TMP45:%.*]] = load i32, ptr [[TMP44]], align 4
// CHECK-NEXT:    store i32 [[TMP45]], ptr [[DOTCAPTURE_EXPR_15]], align 4
// CHECK-NEXT:    [[TMP46:%.*]] = load i32, ptr [[STRIDE]], align 4
// CHECK-NEXT:    store i32 [[TMP46]], ptr [[DOTCAPTURE_EXPR_16]], align 4
// CHECK-NEXT:    [[TMP47:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_14]], align 4
// CHECK-NEXT:    [[TMP48:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_15]], align 4
// CHECK-NEXT:    [[TMP49:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_16]], align 4
// CHECK-NEXT:    [[TMP50:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 13), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP47]], i32 [[TMP48]], i32 [[TMP49]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP50]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP51:%.*]] = load i32, ptr [[A]], align 4
// CHECK-NEXT:    store i32 [[TMP51]], ptr [[DOTCAPTURE_EXPR_17]], align 4
// CHECK-NEXT:    [[TMP52:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP52]] to i64
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x i32], ptr [[VEC]], i64 0, i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP53:%.*]] = load i32, ptr [[ARRAYIDX]], align 4
// CHECK-NEXT:    store i32 [[TMP53]], ptr [[DOTCAPTURE_EXPR_18]], align 4
// CHECK-NEXT:    [[TMP54:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_17]], align 4
// CHECK-NEXT:    [[TMP55:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_18]], align 4
// CHECK-NEXT:    [[X3:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// CHECK-NEXT:    [[TMP56:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.ENTER.DATA"(), "QUAL.OMP.DEVICE"(i32 [[TMP54]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 10, i32 20, i32 [[TMP55]]), "QUAL.OMP.MAP.TOFROM"(ptr [[D]], ptr [[X3]], i64 8, i64 0, ptr null, ptr null) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP56]]) [ "DIR.OMP.END.TARGET.ENTER.DATA"() ]
// CHECK-NEXT:    [[TMP57:%.*]] = load i32, ptr [[A]], align 4
// CHECK-NEXT:    store i32 [[TMP57]], ptr [[DOTCAPTURE_EXPR_19]], align 4
// CHECK-NEXT:    [[TMP58:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_19]], align 4
// CHECK-NEXT:    [[X4:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// CHECK-NEXT:    [[TMP59:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.EXIT.DATA"(), "QUAL.OMP.DEVICE"(i32 [[TMP58]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 30, i32 40, i32 1), "QUAL.OMP.MAP.TOFROM"(ptr [[D]], ptr [[X4]], i64 8, i64 0, ptr null, ptr null) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP59]]) [ "DIR.OMP.END.TARGET.EXIT.DATA"() ]
// CHECK-NEXT:    [[TMP60:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    [[TMP61:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    [[TMP62:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.DATA"(), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP60]], i32 [[TMP61]], i32 1), "QUAL.OMP.MAP.TOFROM"(ptr [[A]], ptr [[A]], i64 0, i64 64, ptr null, ptr null), "QUAL.OMP.USE_DEVICE_ADDR"(ptr [[A]]) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP62]]) [ "DIR.OMP.END.TARGET.DATA"() ]
// CHECK-NEXT:    [[TMP63:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP63]], ptr [[DOTCAPTURE_EXPR_20]], align 4
// CHECK-NEXT:    [[TMP64:%.*]] = load i32, ptr [[N_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP64]], ptr [[DOTCAPTURE_EXPR_21]], align 4
// CHECK-NEXT:    [[TMP65:%.*]] = load i32, ptr @global, align 4
// CHECK-NEXT:    store i32 [[TMP65]], ptr [[DOTCAPTURE_EXPR_22]], align 4
// CHECK-NEXT:    [[TMP66:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_20]], align 4
// CHECK-NEXT:    [[TMP67:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_21]], align 4
// CHECK-NEXT:    [[TMP68:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_22]], align 4
// CHECK-NEXT:    [[TMP69:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.UPDATE"(), "QUAL.OMP.DEVICE"(i32 [[TMP66]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP67]], i32 [[TMP68]], i32 1), "QUAL.OMP.MAP.FROM"(ptr [[A]], ptr [[A]], i64 4, i64 2, ptr null, ptr null) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP69]]) [ "DIR.OMP.END.TARGET.UPDATE"() ]
// CHECK-NEXT:    [[TMP70:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP70]], ptr [[DOTCAPTURE_EXPR_23]], align 4
// CHECK-NEXT:    [[TMP71:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP71]], ptr [[DOTCAPTURE_EXPR_24]], align 4
// CHECK-NEXT:    [[TMP72:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_23]], align 4
// CHECK-NEXT:    [[TMP73:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_24]], align 4
// CHECK-NEXT:    [[TMP74:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 14), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP72]], i32 [[TMP73]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[TMP]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB]], align 4
// CHECK-NEXT:    [[TMP75:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I]], i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND:%.*]]
// CHECK:       omp.inner.for.cond:
// CHECK-NEXT:    [[TMP76:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[TMP77:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp sle i32 [[TMP76]], [[TMP77]]
// CHECK-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// CHECK:       omp.inner.for.body:
// CHECK-NEXT:    [[TMP78:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP78]], 1
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[MUL]]
// CHECK-NEXT:    store i32 [[ADD]], ptr [[I]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// CHECK:       omp.body.continue:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// CHECK:       omp.inner.for.inc:
// CHECK-NEXT:    [[TMP79:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP79]], 1
// CHECK-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND]], !llvm.loop [[LOOP30:![0-9]+]]
// CHECK:       omp.inner.for.end:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// CHECK:       omp.loop.exit:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP75]]) [ "DIR.OMP.END.SIMD"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP74]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP80:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP80]], ptr [[DOTCAPTURE_EXPR_25]], align 4
// CHECK-NEXT:    [[TMP81:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_25]], align 4
// CHECK-NEXT:    [[TMP82:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 15), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP81]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV7]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB8]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I12]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP6]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB8]], align 4
// CHECK-NEXT:    [[TMP83:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV7]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB8]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I12]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP84:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// CHECK-NEXT:    store i32 [[TMP84]], ptr [[DOTOMP_IV7]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND9:%.*]]
// CHECK:       omp.inner.for.cond9:
// CHECK-NEXT:    [[TMP85:%.*]] = load i32, ptr [[DOTOMP_IV7]], align 4
// CHECK-NEXT:    [[TMP86:%.*]] = load i32, ptr [[DOTOMP_UB8]], align 4
// CHECK-NEXT:    [[CMP10:%.*]] = icmp sle i32 [[TMP85]], [[TMP86]]
// CHECK-NEXT:    br i1 [[CMP10]], label [[OMP_INNER_FOR_BODY11:%.*]], label [[OMP_INNER_FOR_END18:%.*]]
// CHECK:       omp.inner.for.body11:
// CHECK-NEXT:    [[TMP87:%.*]] = load i32, ptr [[DOTOMP_IV7]], align 4
// CHECK-NEXT:    [[MUL13:%.*]] = mul nsw i32 [[TMP87]], 1
// CHECK-NEXT:    [[ADD14:%.*]] = add nsw i32 0, [[MUL13]]
// CHECK-NEXT:    store i32 [[ADD14]], ptr [[I12]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE15:%.*]]
// CHECK:       omp.body.continue15:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC16:%.*]]
// CHECK:       omp.inner.for.inc16:
// CHECK-NEXT:    [[TMP88:%.*]] = load i32, ptr [[DOTOMP_IV7]], align 4
// CHECK-NEXT:    [[ADD17:%.*]] = add nsw i32 [[TMP88]], 1
// CHECK-NEXT:    store i32 [[ADD17]], ptr [[DOTOMP_IV7]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND9]]
// CHECK:       omp.inner.for.end18:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT19:%.*]]
// CHECK:       omp.loop.exit19:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP83]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP82]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP89:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP89]], ptr [[DOTCAPTURE_EXPR_26]], align 4
// CHECK-NEXT:    [[TMP90:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_26]], align 4
// CHECK-NEXT:    [[TMP91:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 16), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP90]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV21]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB22]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB23]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I27]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP20]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB22]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB23]], align 4
// CHECK-NEXT:    [[TMP92:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV21]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB22]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB23]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I27]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP93:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I27]], i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    [[TMP94:%.*]] = load i32, ptr [[DOTOMP_LB22]], align 4
// CHECK-NEXT:    store i32 [[TMP94]], ptr [[DOTOMP_IV21]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND24:%.*]]
// CHECK:       omp.inner.for.cond24:
// CHECK-NEXT:    [[TMP95:%.*]] = load i32, ptr [[DOTOMP_IV21]], align 4
// CHECK-NEXT:    [[TMP96:%.*]] = load i32, ptr [[DOTOMP_UB23]], align 4
// CHECK-NEXT:    [[CMP25:%.*]] = icmp sle i32 [[TMP95]], [[TMP96]]
// CHECK-NEXT:    br i1 [[CMP25]], label [[OMP_INNER_FOR_BODY26:%.*]], label [[OMP_INNER_FOR_END33:%.*]]
// CHECK:       omp.inner.for.body26:
// CHECK-NEXT:    [[TMP97:%.*]] = load i32, ptr [[DOTOMP_IV21]], align 4
// CHECK-NEXT:    [[MUL28:%.*]] = mul nsw i32 [[TMP97]], 1
// CHECK-NEXT:    [[ADD29:%.*]] = add nsw i32 0, [[MUL28]]
// CHECK-NEXT:    store i32 [[ADD29]], ptr [[I27]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE30:%.*]]
// CHECK:       omp.body.continue30:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC31:%.*]]
// CHECK:       omp.inner.for.inc31:
// CHECK-NEXT:    [[TMP98:%.*]] = load i32, ptr [[DOTOMP_IV21]], align 4
// CHECK-NEXT:    [[ADD32:%.*]] = add nsw i32 [[TMP98]], 1
// CHECK-NEXT:    store i32 [[ADD32]], ptr [[DOTOMP_IV21]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND24]], !llvm.loop [[LOOP32:![0-9]+]]
// CHECK:       omp.inner.for.end33:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT34:%.*]]
// CHECK:       omp.loop.exit34:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP93]]) [ "DIR.OMP.END.SIMD"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP92]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP91]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP99:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP99]], ptr [[DOTCAPTURE_EXPR_27]], align 4
// CHECK-NEXT:    [[TMP100:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP100]], ptr [[DOTCAPTURE_EXPR_28]], align 4
// CHECK-NEXT:    [[TMP101:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_27]], align 4
// CHECK-NEXT:    [[TMP102:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_28]], align 4
// CHECK-NEXT:    [[TMP103:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 17), "QUAL.OMP.SUBDEVICE"(i32 1, i32 [[TMP101]], i32 [[TMP102]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV36]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB37]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB38]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I42]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP35]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP104:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV36]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB37]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB38]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I42]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP35]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB37]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB38]], align 4
// CHECK-NEXT:    [[TMP105:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.GENERICLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV36]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB37]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB38]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I42]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP106:%.*]] = load i32, ptr [[DOTOMP_LB37]], align 4
// CHECK-NEXT:    store i32 [[TMP106]], ptr [[DOTOMP_IV36]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND39:%.*]]
// CHECK:       omp.inner.for.cond39:
// CHECK-NEXT:    [[TMP107:%.*]] = load i32, ptr [[DOTOMP_IV36]], align 4
// CHECK-NEXT:    [[TMP108:%.*]] = load i32, ptr [[DOTOMP_UB38]], align 4
// CHECK-NEXT:    [[CMP40:%.*]] = icmp sle i32 [[TMP107]], [[TMP108]]
// CHECK-NEXT:    br i1 [[CMP40]], label [[OMP_INNER_FOR_BODY41:%.*]], label [[OMP_INNER_FOR_END48:%.*]]
// CHECK:       omp.inner.for.body41:
// CHECK-NEXT:    [[TMP109:%.*]] = load i32, ptr [[DOTOMP_IV36]], align 4
// CHECK-NEXT:    [[MUL43:%.*]] = mul nsw i32 [[TMP109]], 1
// CHECK-NEXT:    [[ADD44:%.*]] = add nsw i32 0, [[MUL43]]
// CHECK-NEXT:    store i32 [[ADD44]], ptr [[I42]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE45:%.*]]
// CHECK:       omp.body.continue45:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC46:%.*]]
// CHECK:       omp.inner.for.inc46:
// CHECK-NEXT:    [[TMP110:%.*]] = load i32, ptr [[DOTOMP_IV36]], align 4
// CHECK-NEXT:    [[ADD47:%.*]] = add nsw i32 [[TMP110]], 1
// CHECK-NEXT:    store i32 [[ADD47]], ptr [[DOTOMP_IV36]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND39]]
// CHECK:       omp.inner.for.end48:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT49:%.*]]
// CHECK:       omp.loop.exit49:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP105]]) [ "DIR.OMP.END.GENERICLOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP104]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP103]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP111:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP111]], ptr [[DOTCAPTURE_EXPR_29]], align 4
// CHECK-NEXT:    [[TMP112:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_29]], align 4
// CHECK-NEXT:    [[TMP113:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 18), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP112]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV51]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB52]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB53]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I57]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP50]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP114:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV51]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB52]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB53]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I57]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP50]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB52]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB53]], align 4
// CHECK-NEXT:    [[TMP115:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV51]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB52]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB53]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I57]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP116:%.*]] = load i32, ptr [[DOTOMP_LB52]], align 4
// CHECK-NEXT:    store i32 [[TMP116]], ptr [[DOTOMP_IV51]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND54:%.*]]
// CHECK:       omp.inner.for.cond54:
// CHECK-NEXT:    [[TMP117:%.*]] = load i32, ptr [[DOTOMP_IV51]], align 4
// CHECK-NEXT:    [[TMP118:%.*]] = load i32, ptr [[DOTOMP_UB53]], align 4
// CHECK-NEXT:    [[CMP55:%.*]] = icmp sle i32 [[TMP117]], [[TMP118]]
// CHECK-NEXT:    br i1 [[CMP55]], label [[OMP_INNER_FOR_BODY56:%.*]], label [[OMP_INNER_FOR_END63:%.*]]
// CHECK:       omp.inner.for.body56:
// CHECK-NEXT:    [[TMP119:%.*]] = load i32, ptr [[DOTOMP_IV51]], align 4
// CHECK-NEXT:    [[MUL58:%.*]] = mul nsw i32 [[TMP119]], 1
// CHECK-NEXT:    [[ADD59:%.*]] = add nsw i32 0, [[MUL58]]
// CHECK-NEXT:    store i32 [[ADD59]], ptr [[I57]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE60:%.*]]
// CHECK:       omp.body.continue60:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC61:%.*]]
// CHECK:       omp.inner.for.inc61:
// CHECK-NEXT:    [[TMP120:%.*]] = load i32, ptr [[DOTOMP_IV51]], align 4
// CHECK-NEXT:    [[ADD62:%.*]] = add nsw i32 [[TMP120]], 1
// CHECK-NEXT:    store i32 [[ADD62]], ptr [[DOTOMP_IV51]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND54]]
// CHECK:       omp.inner.for.end63:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT64:%.*]]
// CHECK:       omp.loop.exit64:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP115]]) [ "DIR.OMP.END.DISTRIBUTE"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP114]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP113]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP121:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 19), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 10, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV66]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB67]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB68]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I72]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP65]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP122:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV66]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB67]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB68]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I72]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP65]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB67]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB68]], align 4
// CHECK-NEXT:    [[TMP123:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV66]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB67]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB68]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I72]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP124:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I72]], i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    [[TMP125:%.*]] = load i32, ptr [[DOTOMP_LB67]], align 4
// CHECK-NEXT:    store i32 [[TMP125]], ptr [[DOTOMP_IV66]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND69:%.*]]
// CHECK:       omp.inner.for.cond69:
// CHECK-NEXT:    [[TMP126:%.*]] = load i32, ptr [[DOTOMP_IV66]], align 4
// CHECK-NEXT:    [[TMP127:%.*]] = load i32, ptr [[DOTOMP_UB68]], align 4
// CHECK-NEXT:    [[CMP70:%.*]] = icmp sle i32 [[TMP126]], [[TMP127]]
// CHECK-NEXT:    br i1 [[CMP70]], label [[OMP_INNER_FOR_BODY71:%.*]], label [[OMP_INNER_FOR_END78:%.*]]
// CHECK:       omp.inner.for.body71:
// CHECK-NEXT:    [[TMP128:%.*]] = load i32, ptr [[DOTOMP_IV66]], align 4
// CHECK-NEXT:    [[MUL73:%.*]] = mul nsw i32 [[TMP128]], 1
// CHECK-NEXT:    [[ADD74:%.*]] = add nsw i32 0, [[MUL73]]
// CHECK-NEXT:    store i32 [[ADD74]], ptr [[I72]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE75:%.*]]
// CHECK:       omp.body.continue75:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC76:%.*]]
// CHECK:       omp.inner.for.inc76:
// CHECK-NEXT:    [[TMP129:%.*]] = load i32, ptr [[DOTOMP_IV66]], align 4
// CHECK-NEXT:    [[ADD77:%.*]] = add nsw i32 [[TMP129]], 1
// CHECK-NEXT:    store i32 [[ADD77]], ptr [[DOTOMP_IV66]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND69]], !llvm.loop [[LOOP33:![0-9]+]]
// CHECK:       omp.inner.for.end78:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT79:%.*]]
// CHECK:       omp.loop.exit79:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP124]]) [ "DIR.OMP.END.SIMD"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP123]]) [ "DIR.OMP.END.DISTRIBUTE"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP122]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP121]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP130:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 20), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 20, i32 100), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV81]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB82]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB83]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I87]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP80]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP131:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV81]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB82]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB83]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I87]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP80]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB82]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB83]], align 4
// CHECK-NEXT:    [[TMP132:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.GENERICLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV81]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB82]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB83]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I87]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP133:%.*]] = load i32, ptr [[DOTOMP_LB82]], align 4
// CHECK-NEXT:    store i32 [[TMP133]], ptr [[DOTOMP_IV81]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND84:%.*]]
// CHECK:       omp.inner.for.cond84:
// CHECK-NEXT:    [[TMP134:%.*]] = load i32, ptr [[DOTOMP_IV81]], align 4
// CHECK-NEXT:    [[TMP135:%.*]] = load i32, ptr [[DOTOMP_UB83]], align 4
// CHECK-NEXT:    [[CMP85:%.*]] = icmp sle i32 [[TMP134]], [[TMP135]]
// CHECK-NEXT:    br i1 [[CMP85]], label [[OMP_INNER_FOR_BODY86:%.*]], label [[OMP_INNER_FOR_END93:%.*]]
// CHECK:       omp.inner.for.body86:
// CHECK-NEXT:    [[TMP136:%.*]] = load i32, ptr [[DOTOMP_IV81]], align 4
// CHECK-NEXT:    [[MUL88:%.*]] = mul nsw i32 [[TMP136]], 1
// CHECK-NEXT:    [[ADD89:%.*]] = add nsw i32 0, [[MUL88]]
// CHECK-NEXT:    store i32 [[ADD89]], ptr [[I87]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE90:%.*]]
// CHECK:       omp.body.continue90:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC91:%.*]]
// CHECK:       omp.inner.for.inc91:
// CHECK-NEXT:    [[TMP137:%.*]] = load i32, ptr [[DOTOMP_IV81]], align 4
// CHECK-NEXT:    [[ADD92:%.*]] = add nsw i32 [[TMP137]], 1
// CHECK-NEXT:    store i32 [[ADD92]], ptr [[DOTOMP_IV81]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND84]]
// CHECK:       omp.inner.for.end93:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT94:%.*]]
// CHECK:       omp.loop.exit94:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP132]]) [ "DIR.OMP.END.GENERICLOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP131]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP130]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP138:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP138]], ptr [[DOTCAPTURE_EXPR_30]], align 4
// CHECK-NEXT:    [[TMP139:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP139]], ptr [[DOTCAPTURE_EXPR_31]], align 4
// CHECK-NEXT:    [[TMP140:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_30]], align 4
// CHECK-NEXT:    [[TMP141:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_31]], align 4
// CHECK-NEXT:    [[TMP142:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 21), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP140]], i32 [[TMP141]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV96]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB97]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB98]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I102]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP95]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP143:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV96]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB97]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB98]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I102]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP95]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB97]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB98]], align 4
// CHECK-NEXT:    [[TMP144:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV96]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB97]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB98]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I102]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP145:%.*]] = load i32, ptr [[DOTOMP_LB97]], align 4
// CHECK-NEXT:    store i32 [[TMP145]], ptr [[DOTOMP_IV96]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND99:%.*]]
// CHECK:       omp.inner.for.cond99:
// CHECK-NEXT:    [[TMP146:%.*]] = load i32, ptr [[DOTOMP_IV96]], align 4
// CHECK-NEXT:    [[TMP147:%.*]] = load i32, ptr [[DOTOMP_UB98]], align 4
// CHECK-NEXT:    [[CMP100:%.*]] = icmp sle i32 [[TMP146]], [[TMP147]]
// CHECK-NEXT:    br i1 [[CMP100]], label [[OMP_INNER_FOR_BODY101:%.*]], label [[OMP_INNER_FOR_END108:%.*]]
// CHECK:       omp.inner.for.body101:
// CHECK-NEXT:    [[TMP148:%.*]] = load i32, ptr [[DOTOMP_IV96]], align 4
// CHECK-NEXT:    [[MUL103:%.*]] = mul nsw i32 [[TMP148]], 1
// CHECK-NEXT:    [[ADD104:%.*]] = add nsw i32 0, [[MUL103]]
// CHECK-NEXT:    store i32 [[ADD104]], ptr [[I102]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE105:%.*]]
// CHECK:       omp.body.continue105:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC106:%.*]]
// CHECK:       omp.inner.for.inc106:
// CHECK-NEXT:    [[TMP149:%.*]] = load i32, ptr [[DOTOMP_IV96]], align 4
// CHECK-NEXT:    [[ADD107:%.*]] = add nsw i32 [[TMP149]], 1
// CHECK-NEXT:    store i32 [[ADD107]], ptr [[DOTOMP_IV96]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND99]]
// CHECK:       omp.inner.for.end108:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT109:%.*]]
// CHECK:       omp.loop.exit109:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP144]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP143]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP142]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP150:%.*]] = load i32, ptr [[START]], align 4
// CHECK-NEXT:    store i32 [[TMP150]], ptr [[DOTCAPTURE_EXPR_32]], align 4
// CHECK-NEXT:    [[TMP151:%.*]] = load i32, ptr [[LENGTH]], align 4
// CHECK-NEXT:    store i32 [[TMP151]], ptr [[DOTCAPTURE_EXPR_33]], align 4
// CHECK-NEXT:    [[TMP152:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_32]], align 4
// CHECK-NEXT:    [[TMP153:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_33]], align 4
// CHECK-NEXT:    [[TMP154:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 22), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP152]], i32 [[TMP153]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV111]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB112]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB113]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I117]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP110]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP155:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV111]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB112]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB113]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I117]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP110]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB112]], align 4
// CHECK-NEXT:    store i32 9, ptr [[DOTOMP_UB113]], align 4
// CHECK-NEXT:    [[TMP156:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV111]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB112]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB113]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I117]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP157:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I117]], i32 0, i32 1, i32 1) ]
// CHECK-NEXT:    [[TMP158:%.*]] = load i32, ptr [[DOTOMP_LB112]], align 4
// CHECK-NEXT:    store i32 [[TMP158]], ptr [[DOTOMP_IV111]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND114:%.*]]
// CHECK:       omp.inner.for.cond114:
// CHECK-NEXT:    [[TMP159:%.*]] = load i32, ptr [[DOTOMP_IV111]], align 4
// CHECK-NEXT:    [[TMP160:%.*]] = load i32, ptr [[DOTOMP_UB113]], align 4
// CHECK-NEXT:    [[CMP115:%.*]] = icmp sle i32 [[TMP159]], [[TMP160]]
// CHECK-NEXT:    br i1 [[CMP115]], label [[OMP_INNER_FOR_BODY116:%.*]], label [[OMP_INNER_FOR_END123:%.*]]
// CHECK:       omp.inner.for.body116:
// CHECK-NEXT:    [[TMP161:%.*]] = load i32, ptr [[DOTOMP_IV111]], align 4
// CHECK-NEXT:    [[MUL118:%.*]] = mul nsw i32 [[TMP161]], 1
// CHECK-NEXT:    [[ADD119:%.*]] = add nsw i32 0, [[MUL118]]
// CHECK-NEXT:    store i32 [[ADD119]], ptr [[I117]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE120:%.*]]
// CHECK:       omp.body.continue120:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC121:%.*]]
// CHECK:       omp.inner.for.inc121:
// CHECK-NEXT:    [[TMP162:%.*]] = load i32, ptr [[DOTOMP_IV111]], align 4
// CHECK-NEXT:    [[ADD122:%.*]] = add nsw i32 [[TMP162]], 1
// CHECK-NEXT:    store i32 [[ADD122]], ptr [[DOTOMP_IV111]], align 4
// CHECK-NEXT:    br label [[OMP_INNER_FOR_COND114]], !llvm.loop [[LOOP34:![0-9]+]]
// CHECK:       omp.inner.for.end123:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT124:%.*]]
// CHECK:       omp.loop.exit124:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP157]]) [ "DIR.OMP.END.SIMD"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP156]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP155]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP154]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    ret i32 0
//
//
// CHECK-LABEL: define dso_local noundef i32 @_Z12use_templatev(
// CHECK-SAME: ) #[[ATTR3:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    call void @_Z3runIvLj1ELj2ELj3EET_v()
// CHECK-NEXT:    ret i32 0
//
//
// CHECK-LABEL: define linkonce_odr void @_Z3runIvLj1ELj2ELj3EET_v(
// CHECK-SAME: ) #[[ATTR0]] comdat {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 23), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 2, i32 3) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 24), "QUAL.OMP.SUBDEVICE"(i32 1, i32 1, i32 2, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 25), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 26), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 1, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    ret void
//
//
// ROT1-LABEL: define dso_local noundef i32 @_Z4testi(
// ROT1-SAME: i32 noundef [[N:%.*]]) #[[ATTR0:[0-9]+]] {
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[N_ADDR:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[LEVEL:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[START:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[LENGTH:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[STRIDE:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[A:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[D:%.*]] = alloca [[STRUCT_TT:%.*]], align 8
// ROT1-NEXT:    [[D2:%.*]] = alloca [[STRUCT_TT_0:%.*]], align 8
// ROT1-NEXT:    [[VEC:%.*]] = alloca [10 x i32], align 16
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_4:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_5:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_6:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_7:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_8:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_9:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_10:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_11:%.*]] = alloca i8, align 1
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_12:%.*]] = alloca i64, align 8
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_13:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_14:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_15:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_16:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_17:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_18:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_19:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_20:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_21:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_22:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_23:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_24:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_25:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP7:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV8:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB9:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I13:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_26:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP23:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV24:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB25:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB26:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I30:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_27:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_28:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP40:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV41:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB42:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB43:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I47:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_29:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP57:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV58:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB59:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB60:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I64:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP74:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV75:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB76:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB77:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I81:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP91:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV92:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB93:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB94:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I98:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_30:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_31:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP108:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV109:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB110:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB111:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I115:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_32:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTCAPTURE_EXPR_33:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[_TMP125:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_IV126:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_LB127:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[DOTOMP_UB128:%.*]] = alloca i32, align 4
// ROT1-NEXT:    [[I132:%.*]] = alloca i32, align 4
// ROT1-NEXT:    store i32 [[N]], ptr [[N_ADDR]], align 4
// ROT1-NEXT:    store i32 0, ptr [[A]], align 4
// ROT1-NEXT:    [[TMP0:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP0]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// ROT1-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 0), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP1]], i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP3]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// ROT1-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 1), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP4]], i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP6]], ptr [[DOTCAPTURE_EXPR_2]], align 4
// ROT1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP7]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    [[TMP8:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_2]], align 4
// ROT1-NEXT:    [[TMP9:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// ROT1-NEXT:    [[TMP10:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 2), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP8]], i32 [[TMP9]], i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP10]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP11]], ptr [[DOTCAPTURE_EXPR_4]], align 4
// ROT1-NEXT:    [[TMP12:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP12]], ptr [[DOTCAPTURE_EXPR_5]], align 4
// ROT1-NEXT:    [[TMP13:%.*]] = load i32, ptr [[STRIDE]], align 4
// ROT1-NEXT:    store i32 [[TMP13]], ptr [[DOTCAPTURE_EXPR_6]], align 4
// ROT1-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_4]], align 4
// ROT1-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_5]], align 4
// ROT1-NEXT:    [[TMP16:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_6]], align 4
// ROT1-NEXT:    [[TMP17:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 3), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP14]], i32 [[TMP15]], i32 [[TMP16]]) ]
// ROT1-NEXT:    [[TMP18:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP18]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP17]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP19:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP19]], ptr [[DOTCAPTURE_EXPR_7]], align 4
// ROT1-NEXT:    [[TMP20:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP20]], ptr [[DOTCAPTURE_EXPR_8]], align 4
// ROT1-NEXT:    [[TMP21:%.*]] = load i32, ptr [[STRIDE]], align 4
// ROT1-NEXT:    store i32 [[TMP21]], ptr [[DOTCAPTURE_EXPR_9]], align 4
// ROT1-NEXT:    [[TMP22:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_7]], align 4
// ROT1-NEXT:    [[TMP23:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_8]], align 4
// ROT1-NEXT:    [[TMP24:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_9]], align 4
// ROT1-NEXT:    [[TMP25:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 4), "QUAL.OMP.SUBDEVICE"(i32 1, i32 [[TMP22]], i32 [[TMP23]], i32 [[TMP24]]) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP25]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP26:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 5), "QUAL.OMP.SUBDEVICE"(i32 0, i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP26]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP27:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 6), "QUAL.OMP.SUBDEVICE"(i32 0, i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP27]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP28:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 7), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 3, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP28]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP29:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 8), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 3, i32 4) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP29]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP30:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 9), "QUAL.OMP.SUBDEVICE"(i32 1, i32 5, i32 6, i32 7) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP30]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP31:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP31]], ptr [[DOTCAPTURE_EXPR_10]], align 4
// ROT1-NEXT:    [[TMP32:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_10]], align 4
// ROT1-NEXT:    [[TMP33:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 10), "QUAL.OMP.SUBDEVICE"(i32 0, i32 8, i32 [[TMP32]], i32 9) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP33]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[Y:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 1
// ROT1-NEXT:    [[TMP34:%.*]] = load i8, ptr [[Y]], align 8
// ROT1-NEXT:    store i8 [[TMP34]], ptr [[DOTCAPTURE_EXPR_11]], align 1
// ROT1-NEXT:    [[X:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// ROT1-NEXT:    [[TMP35:%.*]] = load i64, ptr [[X]], align 8
// ROT1-NEXT:    store i64 [[TMP35]], ptr [[DOTCAPTURE_EXPR_12]], align 8
// ROT1-NEXT:    [[TMP36:%.*]] = load i8, ptr [[DOTCAPTURE_EXPR_11]], align 1
// ROT1-NEXT:    [[TMP37:%.*]] = load i64, ptr [[DOTCAPTURE_EXPR_12]], align 8
// ROT1-NEXT:    [[TMP38:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 11), "QUAL.OMP.SUBDEVICE"(i32 0, i8 [[TMP36]], i64 [[TMP37]], i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP38]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP39:%.*]] = load i32, ptr [[A]], align 4
// ROT1-NEXT:    [[CALL:%.*]] = call noundef i32 @_Z4funci(i32 noundef [[TMP39]])
// ROT1-NEXT:    store i32 [[CALL]], ptr [[DOTCAPTURE_EXPR_13]], align 4
// ROT1-NEXT:    [[TMP40:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_13]], align 4
// ROT1-NEXT:    [[TMP41:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 12), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP40]], i32 2147483647, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP41]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[X1:%.*]] = getelementptr inbounds [[STRUCT_TT_0]], ptr [[D2]], i32 0, i32 0
// ROT1-NEXT:    [[TMP42:%.*]] = load ptr, ptr [[X1]], align 8
// ROT1-NEXT:    [[TMP43:%.*]] = load i32, ptr [[TMP42]], align 4
// ROT1-NEXT:    store i32 [[TMP43]], ptr [[DOTCAPTURE_EXPR_14]], align 4
// ROT1-NEXT:    [[Y2:%.*]] = getelementptr inbounds [[STRUCT_TT_0]], ptr [[D2]], i32 0, i32 1
// ROT1-NEXT:    [[TMP44:%.*]] = load ptr, ptr [[Y2]], align 8
// ROT1-NEXT:    [[TMP45:%.*]] = load i32, ptr [[TMP44]], align 4
// ROT1-NEXT:    store i32 [[TMP45]], ptr [[DOTCAPTURE_EXPR_15]], align 4
// ROT1-NEXT:    [[TMP46:%.*]] = load i32, ptr [[STRIDE]], align 4
// ROT1-NEXT:    store i32 [[TMP46]], ptr [[DOTCAPTURE_EXPR_16]], align 4
// ROT1-NEXT:    [[TMP47:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_14]], align 4
// ROT1-NEXT:    [[TMP48:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_15]], align 4
// ROT1-NEXT:    [[TMP49:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_16]], align 4
// ROT1-NEXT:    [[TMP50:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 13), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP47]], i32 [[TMP48]], i32 [[TMP49]]) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP50]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP51:%.*]] = load i32, ptr [[A]], align 4
// ROT1-NEXT:    store i32 [[TMP51]], ptr [[DOTCAPTURE_EXPR_17]], align 4
// ROT1-NEXT:    [[TMP52:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP52]] to i64
// ROT1-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x i32], ptr [[VEC]], i64 0, i64 [[IDXPROM]]
// ROT1-NEXT:    [[TMP53:%.*]] = load i32, ptr [[ARRAYIDX]], align 4
// ROT1-NEXT:    store i32 [[TMP53]], ptr [[DOTCAPTURE_EXPR_18]], align 4
// ROT1-NEXT:    [[TMP54:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_17]], align 4
// ROT1-NEXT:    [[TMP55:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_18]], align 4
// ROT1-NEXT:    [[X3:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// ROT1-NEXT:    [[TMP56:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.ENTER.DATA"(), "QUAL.OMP.DEVICE"(i32 [[TMP54]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 10, i32 20, i32 [[TMP55]]), "QUAL.OMP.MAP.TOFROM"(ptr [[D]], ptr [[X3]], i64 8, i64 0, ptr null, ptr null) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP56]]) [ "DIR.OMP.END.TARGET.ENTER.DATA"() ]
// ROT1-NEXT:    [[TMP57:%.*]] = load i32, ptr [[A]], align 4
// ROT1-NEXT:    store i32 [[TMP57]], ptr [[DOTCAPTURE_EXPR_19]], align 4
// ROT1-NEXT:    [[TMP58:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_19]], align 4
// ROT1-NEXT:    [[X4:%.*]] = getelementptr inbounds [[STRUCT_TT]], ptr [[D]], i32 0, i32 0
// ROT1-NEXT:    [[TMP59:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.EXIT.DATA"(), "QUAL.OMP.DEVICE"(i32 [[TMP58]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 30, i32 40, i32 1), "QUAL.OMP.MAP.TOFROM"(ptr [[D]], ptr [[X4]], i64 8, i64 0, ptr null, ptr null) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP59]]) [ "DIR.OMP.END.TARGET.EXIT.DATA"() ]
// ROT1-NEXT:    [[TMP60:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    [[TMP61:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    [[TMP62:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.DATA"(), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP60]], i32 [[TMP61]], i32 1), "QUAL.OMP.MAP.TOFROM"(ptr [[A]], ptr [[A]], i64 0, i64 64, ptr null, ptr null), "QUAL.OMP.USE_DEVICE_ADDR"(ptr [[A]]) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP62]]) [ "DIR.OMP.END.TARGET.DATA"() ]
// ROT1-NEXT:    [[TMP63:%.*]] = load i32, ptr [[N_ADDR]], align 4
// ROT1-NEXT:    store i32 [[TMP63]], ptr [[DOTCAPTURE_EXPR_20]], align 4
// ROT1-NEXT:    [[TMP64:%.*]] = load i32, ptr [[N_ADDR]], align 4
// ROT1-NEXT:    store i32 [[TMP64]], ptr [[DOTCAPTURE_EXPR_21]], align 4
// ROT1-NEXT:    [[TMP65:%.*]] = load i32, ptr @global, align 4
// ROT1-NEXT:    store i32 [[TMP65]], ptr [[DOTCAPTURE_EXPR_22]], align 4
// ROT1-NEXT:    [[TMP66:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_20]], align 4
// ROT1-NEXT:    [[TMP67:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_21]], align 4
// ROT1-NEXT:    [[TMP68:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_22]], align 4
// ROT1-NEXT:    [[TMP69:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET.UPDATE"(), "QUAL.OMP.DEVICE"(i32 [[TMP66]]), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP67]], i32 [[TMP68]], i32 1), "QUAL.OMP.MAP.FROM"(ptr [[A]], ptr [[A]], i64 4, i64 2, ptr null, ptr null) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP69]]) [ "DIR.OMP.END.TARGET.UPDATE"() ]
// ROT1-NEXT:    [[TMP70:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP70]], ptr [[DOTCAPTURE_EXPR_23]], align 4
// ROT1-NEXT:    [[TMP71:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP71]], ptr [[DOTCAPTURE_EXPR_24]], align 4
// ROT1-NEXT:    [[TMP72:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_23]], align 4
// ROT1-NEXT:    [[TMP73:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_24]], align 4
// ROT1-NEXT:    [[TMP74:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 14), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP72]], i32 [[TMP73]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[TMP]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[TMP75:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I]], i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP76:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP77:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[CMP:%.*]] = icmp sle i32 [[TMP76]], [[TMP77]]
// ROT1-NEXT:    br i1 [[CMP]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// ROT1:       omp.inner.for.body.lh:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// ROT1:       omp.inner.for.body:
// ROT1-NEXT:    [[TMP78:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP78]], 1
// ROT1-NEXT:    [[ADD:%.*]] = add nsw i32 0, [[MUL]]
// ROT1-NEXT:    store i32 [[ADD]], ptr [[I]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// ROT1:       omp.body.continue:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// ROT1:       omp.inner.for.inc:
// ROT1-NEXT:    [[TMP79:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[ADD5:%.*]] = add nsw i32 [[TMP79]], 1
// ROT1-NEXT:    store i32 [[ADD5]], ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP80:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// ROT1-NEXT:    [[TMP81:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// ROT1-NEXT:    [[CMP6:%.*]] = icmp sle i32 [[TMP80]], [[TMP81]]
// ROT1-NEXT:    br i1 [[CMP6]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]], !llvm.loop [[LOOP30:![0-9]+]]
// ROT1:       omp.inner.for.end_crit_edge:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END]]
// ROT1:       omp.inner.for.end:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// ROT1:       omp.loop.exit:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP75]]) [ "DIR.OMP.END.SIMD"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP74]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP82:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP82]], ptr [[DOTCAPTURE_EXPR_25]], align 4
// ROT1-NEXT:    [[TMP83:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_25]], align 4
// ROT1-NEXT:    [[TMP84:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 15), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP83]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV8]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB9]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I13]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP7]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB9]], align 4
// ROT1-NEXT:    [[TMP85:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV8]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB9]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I13]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP86:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// ROT1-NEXT:    store i32 [[TMP86]], ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[TMP87:%.*]] = load i32, ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[TMP88:%.*]] = load i32, ptr [[DOTOMP_UB9]], align 4
// ROT1-NEXT:    [[CMP10:%.*]] = icmp sle i32 [[TMP87]], [[TMP88]]
// ROT1-NEXT:    br i1 [[CMP10]], label [[OMP_INNER_FOR_BODY_LH11:%.*]], label [[OMP_INNER_FOR_END21:%.*]]
// ROT1:       omp.inner.for.body.lh11:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY12:%.*]]
// ROT1:       omp.inner.for.body12:
// ROT1-NEXT:    [[TMP89:%.*]] = load i32, ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[MUL14:%.*]] = mul nsw i32 [[TMP89]], 1
// ROT1-NEXT:    [[ADD15:%.*]] = add nsw i32 0, [[MUL14]]
// ROT1-NEXT:    store i32 [[ADD15]], ptr [[I13]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE16:%.*]]
// ROT1:       omp.body.continue16:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC17:%.*]]
// ROT1:       omp.inner.for.inc17:
// ROT1-NEXT:    [[TMP90:%.*]] = load i32, ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[ADD18:%.*]] = add nsw i32 [[TMP90]], 1
// ROT1-NEXT:    store i32 [[ADD18]], ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[TMP91:%.*]] = load i32, ptr [[DOTOMP_IV8]], align 4
// ROT1-NEXT:    [[TMP92:%.*]] = load i32, ptr [[DOTOMP_UB9]], align 4
// ROT1-NEXT:    [[CMP19:%.*]] = icmp sle i32 [[TMP91]], [[TMP92]]
// ROT1-NEXT:    br i1 [[CMP19]], label [[OMP_INNER_FOR_BODY12]], label [[OMP_INNER_FOR_END_CRIT_EDGE20:%.*]]
// ROT1:       omp.inner.for.end_crit_edge20:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END21]]
// ROT1:       omp.inner.for.end21:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT22:%.*]]
// ROT1:       omp.loop.exit22:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP85]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP84]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP93:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP93]], ptr [[DOTCAPTURE_EXPR_26]], align 4
// ROT1-NEXT:    [[TMP94:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_26]], align 4
// ROT1-NEXT:    [[TMP95:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 16), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP94]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV24]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB25]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB26]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I30]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP23]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB25]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB26]], align 4
// ROT1-NEXT:    [[TMP96:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV24]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB25]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB26]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I30]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP97:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I30]], i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    [[TMP98:%.*]] = load i32, ptr [[DOTOMP_LB25]], align 4
// ROT1-NEXT:    store i32 [[TMP98]], ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[TMP99:%.*]] = load i32, ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[TMP100:%.*]] = load i32, ptr [[DOTOMP_UB26]], align 4
// ROT1-NEXT:    [[CMP27:%.*]] = icmp sle i32 [[TMP99]], [[TMP100]]
// ROT1-NEXT:    br i1 [[CMP27]], label [[OMP_INNER_FOR_BODY_LH28:%.*]], label [[OMP_INNER_FOR_END38:%.*]]
// ROT1:       omp.inner.for.body.lh28:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY29:%.*]]
// ROT1:       omp.inner.for.body29:
// ROT1-NEXT:    [[TMP101:%.*]] = load i32, ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[MUL31:%.*]] = mul nsw i32 [[TMP101]], 1
// ROT1-NEXT:    [[ADD32:%.*]] = add nsw i32 0, [[MUL31]]
// ROT1-NEXT:    store i32 [[ADD32]], ptr [[I30]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE33:%.*]]
// ROT1:       omp.body.continue33:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC34:%.*]]
// ROT1:       omp.inner.for.inc34:
// ROT1-NEXT:    [[TMP102:%.*]] = load i32, ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[ADD35:%.*]] = add nsw i32 [[TMP102]], 1
// ROT1-NEXT:    store i32 [[ADD35]], ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[TMP103:%.*]] = load i32, ptr [[DOTOMP_IV24]], align 4
// ROT1-NEXT:    [[TMP104:%.*]] = load i32, ptr [[DOTOMP_UB26]], align 4
// ROT1-NEXT:    [[CMP36:%.*]] = icmp sle i32 [[TMP103]], [[TMP104]]
// ROT1-NEXT:    br i1 [[CMP36]], label [[OMP_INNER_FOR_BODY29]], label [[OMP_INNER_FOR_END_CRIT_EDGE37:%.*]], !llvm.loop [[LOOP32:![0-9]+]]
// ROT1:       omp.inner.for.end_crit_edge37:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END38]]
// ROT1:       omp.inner.for.end38:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT39:%.*]]
// ROT1:       omp.loop.exit39:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP97]]) [ "DIR.OMP.END.SIMD"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP96]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP95]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP105:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP105]], ptr [[DOTCAPTURE_EXPR_27]], align 4
// ROT1-NEXT:    [[TMP106:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP106]], ptr [[DOTCAPTURE_EXPR_28]], align 4
// ROT1-NEXT:    [[TMP107:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_27]], align 4
// ROT1-NEXT:    [[TMP108:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_28]], align 4
// ROT1-NEXT:    [[TMP109:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 17), "QUAL.OMP.SUBDEVICE"(i32 1, i32 [[TMP107]], i32 [[TMP108]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV41]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB42]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB43]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I47]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP40]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP110:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV41]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB42]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB43]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I47]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP40]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB42]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB43]], align 4
// ROT1-NEXT:    [[TMP111:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.GENERICLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV41]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB42]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB43]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I47]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP112:%.*]] = load i32, ptr [[DOTOMP_LB42]], align 4
// ROT1-NEXT:    store i32 [[TMP112]], ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[TMP113:%.*]] = load i32, ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[TMP114:%.*]] = load i32, ptr [[DOTOMP_UB43]], align 4
// ROT1-NEXT:    [[CMP44:%.*]] = icmp sle i32 [[TMP113]], [[TMP114]]
// ROT1-NEXT:    br i1 [[CMP44]], label [[OMP_INNER_FOR_BODY_LH45:%.*]], label [[OMP_INNER_FOR_END55:%.*]]
// ROT1:       omp.inner.for.body.lh45:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY46:%.*]]
// ROT1:       omp.inner.for.body46:
// ROT1-NEXT:    [[TMP115:%.*]] = load i32, ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[MUL48:%.*]] = mul nsw i32 [[TMP115]], 1
// ROT1-NEXT:    [[ADD49:%.*]] = add nsw i32 0, [[MUL48]]
// ROT1-NEXT:    store i32 [[ADD49]], ptr [[I47]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE50:%.*]]
// ROT1:       omp.body.continue50:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC51:%.*]]
// ROT1:       omp.inner.for.inc51:
// ROT1-NEXT:    [[TMP116:%.*]] = load i32, ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[ADD52:%.*]] = add nsw i32 [[TMP116]], 1
// ROT1-NEXT:    store i32 [[ADD52]], ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[TMP117:%.*]] = load i32, ptr [[DOTOMP_IV41]], align 4
// ROT1-NEXT:    [[TMP118:%.*]] = load i32, ptr [[DOTOMP_UB43]], align 4
// ROT1-NEXT:    [[CMP53:%.*]] = icmp sle i32 [[TMP117]], [[TMP118]]
// ROT1-NEXT:    br i1 [[CMP53]], label [[OMP_INNER_FOR_BODY46]], label [[OMP_INNER_FOR_END_CRIT_EDGE54:%.*]]
// ROT1:       omp.inner.for.end_crit_edge54:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END55]]
// ROT1:       omp.inner.for.end55:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT56:%.*]]
// ROT1:       omp.loop.exit56:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP111]]) [ "DIR.OMP.END.GENERICLOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP110]]) [ "DIR.OMP.END.PARALLEL"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP109]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP119:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP119]], ptr [[DOTCAPTURE_EXPR_29]], align 4
// ROT1-NEXT:    [[TMP120:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_29]], align 4
// ROT1-NEXT:    [[TMP121:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 18), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP120]], i32 1, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV58]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB59]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB60]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I64]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP57]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP122:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV58]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB59]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB60]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I64]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP57]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB59]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB60]], align 4
// ROT1-NEXT:    [[TMP123:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV58]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB59]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB60]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I64]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP124:%.*]] = load i32, ptr [[DOTOMP_LB59]], align 4
// ROT1-NEXT:    store i32 [[TMP124]], ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[TMP125:%.*]] = load i32, ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[TMP126:%.*]] = load i32, ptr [[DOTOMP_UB60]], align 4
// ROT1-NEXT:    [[CMP61:%.*]] = icmp sle i32 [[TMP125]], [[TMP126]]
// ROT1-NEXT:    br i1 [[CMP61]], label [[OMP_INNER_FOR_BODY_LH62:%.*]], label [[OMP_INNER_FOR_END72:%.*]]
// ROT1:       omp.inner.for.body.lh62:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY63:%.*]]
// ROT1:       omp.inner.for.body63:
// ROT1-NEXT:    [[TMP127:%.*]] = load i32, ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[MUL65:%.*]] = mul nsw i32 [[TMP127]], 1
// ROT1-NEXT:    [[ADD66:%.*]] = add nsw i32 0, [[MUL65]]
// ROT1-NEXT:    store i32 [[ADD66]], ptr [[I64]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE67:%.*]]
// ROT1:       omp.body.continue67:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC68:%.*]]
// ROT1:       omp.inner.for.inc68:
// ROT1-NEXT:    [[TMP128:%.*]] = load i32, ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[ADD69:%.*]] = add nsw i32 [[TMP128]], 1
// ROT1-NEXT:    store i32 [[ADD69]], ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[TMP129:%.*]] = load i32, ptr [[DOTOMP_IV58]], align 4
// ROT1-NEXT:    [[TMP130:%.*]] = load i32, ptr [[DOTOMP_UB60]], align 4
// ROT1-NEXT:    [[CMP70:%.*]] = icmp sle i32 [[TMP129]], [[TMP130]]
// ROT1-NEXT:    br i1 [[CMP70]], label [[OMP_INNER_FOR_BODY63]], label [[OMP_INNER_FOR_END_CRIT_EDGE71:%.*]]
// ROT1:       omp.inner.for.end_crit_edge71:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END72]]
// ROT1:       omp.inner.for.end72:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT73:%.*]]
// ROT1:       omp.loop.exit73:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP123]]) [ "DIR.OMP.END.DISTRIBUTE"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP122]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP121]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP131:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 19), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 10, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV75]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB76]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB77]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I81]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP74]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP132:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV75]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB76]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB77]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I81]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP74]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB76]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB77]], align 4
// ROT1-NEXT:    [[TMP133:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV75]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB76]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB77]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I81]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP134:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I81]], i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    [[TMP135:%.*]] = load i32, ptr [[DOTOMP_LB76]], align 4
// ROT1-NEXT:    store i32 [[TMP135]], ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[TMP136:%.*]] = load i32, ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[TMP137:%.*]] = load i32, ptr [[DOTOMP_UB77]], align 4
// ROT1-NEXT:    [[CMP78:%.*]] = icmp sle i32 [[TMP136]], [[TMP137]]
// ROT1-NEXT:    br i1 [[CMP78]], label [[OMP_INNER_FOR_BODY_LH79:%.*]], label [[OMP_INNER_FOR_END89:%.*]]
// ROT1:       omp.inner.for.body.lh79:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY80:%.*]]
// ROT1:       omp.inner.for.body80:
// ROT1-NEXT:    [[TMP138:%.*]] = load i32, ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[MUL82:%.*]] = mul nsw i32 [[TMP138]], 1
// ROT1-NEXT:    [[ADD83:%.*]] = add nsw i32 0, [[MUL82]]
// ROT1-NEXT:    store i32 [[ADD83]], ptr [[I81]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE84:%.*]]
// ROT1:       omp.body.continue84:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC85:%.*]]
// ROT1:       omp.inner.for.inc85:
// ROT1-NEXT:    [[TMP139:%.*]] = load i32, ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[ADD86:%.*]] = add nsw i32 [[TMP139]], 1
// ROT1-NEXT:    store i32 [[ADD86]], ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[TMP140:%.*]] = load i32, ptr [[DOTOMP_IV75]], align 4
// ROT1-NEXT:    [[TMP141:%.*]] = load i32, ptr [[DOTOMP_UB77]], align 4
// ROT1-NEXT:    [[CMP87:%.*]] = icmp sle i32 [[TMP140]], [[TMP141]]
// ROT1-NEXT:    br i1 [[CMP87]], label [[OMP_INNER_FOR_BODY80]], label [[OMP_INNER_FOR_END_CRIT_EDGE88:%.*]], !llvm.loop [[LOOP33:![0-9]+]]
// ROT1:       omp.inner.for.end_crit_edge88:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END89]]
// ROT1:       omp.inner.for.end89:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT90:%.*]]
// ROT1:       omp.loop.exit90:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP134]]) [ "DIR.OMP.END.SIMD"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP133]]) [ "DIR.OMP.END.DISTRIBUTE"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP132]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP131]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP142:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 20), "QUAL.OMP.SUBDEVICE"(i32 0, i32 2, i32 20, i32 100), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV92]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB93]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB94]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I98]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP91]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP143:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV92]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB93]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB94]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I98]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP91]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB93]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB94]], align 4
// ROT1-NEXT:    [[TMP144:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.GENERICLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV92]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB93]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB94]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I98]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP145:%.*]] = load i32, ptr [[DOTOMP_LB93]], align 4
// ROT1-NEXT:    store i32 [[TMP145]], ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[TMP146:%.*]] = load i32, ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[TMP147:%.*]] = load i32, ptr [[DOTOMP_UB94]], align 4
// ROT1-NEXT:    [[CMP95:%.*]] = icmp sle i32 [[TMP146]], [[TMP147]]
// ROT1-NEXT:    br i1 [[CMP95]], label [[OMP_INNER_FOR_BODY_LH96:%.*]], label [[OMP_INNER_FOR_END106:%.*]]
// ROT1:       omp.inner.for.body.lh96:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY97:%.*]]
// ROT1:       omp.inner.for.body97:
// ROT1-NEXT:    [[TMP148:%.*]] = load i32, ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[MUL99:%.*]] = mul nsw i32 [[TMP148]], 1
// ROT1-NEXT:    [[ADD100:%.*]] = add nsw i32 0, [[MUL99]]
// ROT1-NEXT:    store i32 [[ADD100]], ptr [[I98]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE101:%.*]]
// ROT1:       omp.body.continue101:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC102:%.*]]
// ROT1:       omp.inner.for.inc102:
// ROT1-NEXT:    [[TMP149:%.*]] = load i32, ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[ADD103:%.*]] = add nsw i32 [[TMP149]], 1
// ROT1-NEXT:    store i32 [[ADD103]], ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[TMP150:%.*]] = load i32, ptr [[DOTOMP_IV92]], align 4
// ROT1-NEXT:    [[TMP151:%.*]] = load i32, ptr [[DOTOMP_UB94]], align 4
// ROT1-NEXT:    [[CMP104:%.*]] = icmp sle i32 [[TMP150]], [[TMP151]]
// ROT1-NEXT:    br i1 [[CMP104]], label [[OMP_INNER_FOR_BODY97]], label [[OMP_INNER_FOR_END_CRIT_EDGE105:%.*]]
// ROT1:       omp.inner.for.end_crit_edge105:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END106]]
// ROT1:       omp.inner.for.end106:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT107:%.*]]
// ROT1:       omp.loop.exit107:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP144]]) [ "DIR.OMP.END.GENERICLOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP143]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP142]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP152:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP152]], ptr [[DOTCAPTURE_EXPR_30]], align 4
// ROT1-NEXT:    [[TMP153:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP153]], ptr [[DOTCAPTURE_EXPR_31]], align 4
// ROT1-NEXT:    [[TMP154:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_30]], align 4
// ROT1-NEXT:    [[TMP155:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_31]], align 4
// ROT1-NEXT:    [[TMP156:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 21), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP154]], i32 [[TMP155]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV109]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB110]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB111]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I115]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP108]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP157:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV109]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB110]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB111]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I115]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP108]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB110]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB111]], align 4
// ROT1-NEXT:    [[TMP158:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV109]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB110]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB111]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I115]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP159:%.*]] = load i32, ptr [[DOTOMP_LB110]], align 4
// ROT1-NEXT:    store i32 [[TMP159]], ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[TMP160:%.*]] = load i32, ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[TMP161:%.*]] = load i32, ptr [[DOTOMP_UB111]], align 4
// ROT1-NEXT:    [[CMP112:%.*]] = icmp sle i32 [[TMP160]], [[TMP161]]
// ROT1-NEXT:    br i1 [[CMP112]], label [[OMP_INNER_FOR_BODY_LH113:%.*]], label [[OMP_INNER_FOR_END123:%.*]]
// ROT1:       omp.inner.for.body.lh113:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY114:%.*]]
// ROT1:       omp.inner.for.body114:
// ROT1-NEXT:    [[TMP162:%.*]] = load i32, ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[MUL116:%.*]] = mul nsw i32 [[TMP162]], 1
// ROT1-NEXT:    [[ADD117:%.*]] = add nsw i32 0, [[MUL116]]
// ROT1-NEXT:    store i32 [[ADD117]], ptr [[I115]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE118:%.*]]
// ROT1:       omp.body.continue118:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC119:%.*]]
// ROT1:       omp.inner.for.inc119:
// ROT1-NEXT:    [[TMP163:%.*]] = load i32, ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[ADD120:%.*]] = add nsw i32 [[TMP163]], 1
// ROT1-NEXT:    store i32 [[ADD120]], ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[TMP164:%.*]] = load i32, ptr [[DOTOMP_IV109]], align 4
// ROT1-NEXT:    [[TMP165:%.*]] = load i32, ptr [[DOTOMP_UB111]], align 4
// ROT1-NEXT:    [[CMP121:%.*]] = icmp sle i32 [[TMP164]], [[TMP165]]
// ROT1-NEXT:    br i1 [[CMP121]], label [[OMP_INNER_FOR_BODY114]], label [[OMP_INNER_FOR_END_CRIT_EDGE122:%.*]]
// ROT1:       omp.inner.for.end_crit_edge122:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END123]]
// ROT1:       omp.inner.for.end123:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT124:%.*]]
// ROT1:       omp.loop.exit124:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP158]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP157]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP156]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP166:%.*]] = load i32, ptr [[START]], align 4
// ROT1-NEXT:    store i32 [[TMP166]], ptr [[DOTCAPTURE_EXPR_32]], align 4
// ROT1-NEXT:    [[TMP167:%.*]] = load i32, ptr [[LENGTH]], align 4
// ROT1-NEXT:    store i32 [[TMP167]], ptr [[DOTCAPTURE_EXPR_33]], align 4
// ROT1-NEXT:    [[TMP168:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_32]], align 4
// ROT1-NEXT:    [[TMP169:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_33]], align 4
// ROT1-NEXT:    [[TMP170:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 22), "QUAL.OMP.SUBDEVICE"(i32 0, i32 [[TMP168]], i32 [[TMP169]], i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV126]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB127]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB128]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I132]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP125]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP171:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV126]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB127]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB128]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I132]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP125]], i32 0, i32 1) ]
// ROT1-NEXT:    store i32 0, ptr [[DOTOMP_LB127]], align 4
// ROT1-NEXT:    store i32 9, ptr [[DOTOMP_UB128]], align 4
// ROT1-NEXT:    [[TMP172:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV126]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB127]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB128]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I132]], i32 0, i32 1) ]
// ROT1-NEXT:    [[TMP173:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.SIMD"(), "QUAL.OMP.LINEAR:IV.TYPED"(ptr [[I132]], i32 0, i32 1, i32 1) ]
// ROT1-NEXT:    [[TMP174:%.*]] = load i32, ptr [[DOTOMP_LB127]], align 4
// ROT1-NEXT:    store i32 [[TMP174]], ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[TMP175:%.*]] = load i32, ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[TMP176:%.*]] = load i32, ptr [[DOTOMP_UB128]], align 4
// ROT1-NEXT:    [[CMP129:%.*]] = icmp sle i32 [[TMP175]], [[TMP176]]
// ROT1-NEXT:    br i1 [[CMP129]], label [[OMP_INNER_FOR_BODY_LH130:%.*]], label [[OMP_INNER_FOR_END140:%.*]]
// ROT1:       omp.inner.for.body.lh130:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_BODY131:%.*]]
// ROT1:       omp.inner.for.body131:
// ROT1-NEXT:    [[TMP177:%.*]] = load i32, ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[MUL133:%.*]] = mul nsw i32 [[TMP177]], 1
// ROT1-NEXT:    [[ADD134:%.*]] = add nsw i32 0, [[MUL133]]
// ROT1-NEXT:    store i32 [[ADD134]], ptr [[I132]], align 4
// ROT1-NEXT:    br label [[OMP_BODY_CONTINUE135:%.*]]
// ROT1:       omp.body.continue135:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_INC136:%.*]]
// ROT1:       omp.inner.for.inc136:
// ROT1-NEXT:    [[TMP178:%.*]] = load i32, ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[ADD137:%.*]] = add nsw i32 [[TMP178]], 1
// ROT1-NEXT:    store i32 [[ADD137]], ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[TMP179:%.*]] = load i32, ptr [[DOTOMP_IV126]], align 4
// ROT1-NEXT:    [[TMP180:%.*]] = load i32, ptr [[DOTOMP_UB128]], align 4
// ROT1-NEXT:    [[CMP138:%.*]] = icmp sle i32 [[TMP179]], [[TMP180]]
// ROT1-NEXT:    br i1 [[CMP138]], label [[OMP_INNER_FOR_BODY131]], label [[OMP_INNER_FOR_END_CRIT_EDGE139:%.*]], !llvm.loop [[LOOP34:![0-9]+]]
// ROT1:       omp.inner.for.end_crit_edge139:
// ROT1-NEXT:    br label [[OMP_INNER_FOR_END140]]
// ROT1:       omp.inner.for.end140:
// ROT1-NEXT:    br label [[OMP_LOOP_EXIT141:%.*]]
// ROT1:       omp.loop.exit141:
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP173]]) [ "DIR.OMP.END.SIMD"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP172]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP171]]) [ "DIR.OMP.END.TEAMS"() ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP170]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    ret i32 0
//
//
// ROT1-LABEL: define dso_local noundef i32 @_Z12use_templatev(
// ROT1-SAME: ) #[[ATTR3:[0-9]+]] {
// ROT1-NEXT:  entry:
// ROT1-NEXT:    call void @_Z3runIvLj1ELj2ELj3EET_v()
// ROT1-NEXT:    ret i32 0
//
//
// ROT1-LABEL: define linkonce_odr void @_Z3runIvLj1ELj2ELj3EET_v(
// ROT1-SAME: ) #[[ATTR0]] comdat {
// ROT1-NEXT:  entry:
// ROT1-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 23), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 2, i32 3) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 24), "QUAL.OMP.SUBDEVICE"(i32 1, i32 1, i32 2, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 25), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    [[TMP3:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 26), "QUAL.OMP.SUBDEVICE"(i32 0, i32 1, i32 1, i32 1) ]
// ROT1-NEXT:    call void @llvm.directive.region.exit(token [[TMP3]]) [ "DIR.OMP.END.TARGET"() ]
// ROT1-NEXT:    ret void
//
// end INTEL_COLLAB
