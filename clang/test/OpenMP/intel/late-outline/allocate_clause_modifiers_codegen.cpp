// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --include-generated-funcs
// NOTE: Test modified after being autogenerated by
// NOTE:   utils/update_cc_tests_checks.py
// NOTE: to handle these issues:
// NOTE:   1) FileCheck issue with CHECK-LABEL and subsequent use of CHECK for
// NOTE:      same label, which is an error. Change CHECK-LABEL to just CHECK.
// NOTE:   2) When using --include-generated-funcs for autogeneration,
// NOTE:      duplicate identical CHECKs can result in errors during CHECKing,
// NOTE:      claiming a label can't be matched. To correct, autogenerate
// NOTE:      with one set of RUN commands, fix CHECK-LABEL (per note above),
// NOTE:      add other RUN commands back into test.
// NOTE:   3) Move INTEL_COLLAB markers back to the top and the bottom of
// NOTE:      the source file.
// RUN: %clang_cc1 -opaque-pointers -emit-llvm -o - -fopenmp -fopenmp-late-outline -fopenmp-typed-clauses \
// RUN: -triple x86_64-unknown-linux-gnu -fopenmp-version=51 %s | FileCheck %s

// RUN: %clang_cc1 -opaque-pointers -fopenmp -fopenmp-late-outline -fopenmp-typed-clauses \
// RUN: -triple x86_64-unknown-linux-gnu -fopenmp-version=51 \
// RUN: -emit-pch %s -o %t

// RUN: %clang_cc1 -opaque-pointers -fopenmp -fopenmp-late-outline -fopenmp-typed-clauses \
// RUN: -triple x86_64-unknown-linux-gnu -fopenmp-version=51 \
// RUN: -include-pch %t -emit-llvm %s -o - | FileCheck %s
// expected-no-diagnostics
#ifndef HEADER
#define HEADER

typedef enum omp_allocator_handle_t {
  omp_null_allocator = 0,
  omp_default_mem_alloc = 1,
  omp_large_cap_mem_alloc = 2,
  omp_const_mem_alloc = 3,
  omp_high_bw_mem_alloc = 4,
  omp_low_lat_mem_alloc = 5,
  omp_cgroup_mem_alloc = 6,
  omp_pteam_mem_alloc = 7,
  omp_thread_mem_alloc = 8,
  KMP_ALLOCATOR_MAX_HANDLE = __UINTPTR_MAX__
} omp_allocator_handle_t;

int main () {
  bool foo;
  int bar;
  omp_allocator_handle_t MyAlloc = omp_large_cap_mem_alloc;

  // Uses omp_default_mem_alloc with alignment of 1 (natural alignment of bool)
  // since not specified in clause.
  #pragma omp parallel allocate(foo) private(foo)

  // Uses MyAlloc (omp_large_cap_mem_alloc) with alignments of 1 and 4
  // (natural alignments of bool and int) since not specified in clause.
  #pragma omp parallel allocate(allocator(MyAlloc): foo,bar) private(foo,bar)

  // Uses MyAlloc with alignments 2 and 4 - max of natural and specified
  // alignments.
  #pragma omp parallel allocate(allocator(MyAlloc), align(2): foo,bar) \
                       private(foo,bar)

  // Uses omp_pteam_mem_alloc with alignment 8 - max of natural and
  // specified alignment.
  #pragma omp parallel allocate(align(8), allocator(omp_pteam_mem_alloc): \
                       foo,bar) private(foo,bar)

  // Uses omp_default_mem_alloc with alignment 16 - max of natural and
  // specified alignment.
  #pragma omp parallel allocate(align(16): foo) private(foo)
  {}
  return 0;
}

template <typename T, omp_allocator_handle_t MyAlloc,
          unsigned size, unsigned align>
T run(T param) {
  T foo[size];
  #pragma omp parallel allocate(allocator(MyAlloc), \
                       align(align): foo, param) private(foo, param)
  {}
  return foo[0];
}

double template_test() {
  double d;
  d = run<double, omp_large_cap_mem_alloc, 10, 2>(d);
  return d;
}
#endif
// CHECK: define{{.*}}@main(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[FOO:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[BAR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[MYALLOC:%.*]] = alloca i64, align 8
// CHECK-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// CHECK-NEXT:    store i64 2, ptr [[MYALLOC]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 1, ptr [[FOO]]), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], i8 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[BAR]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[MYALLOC]], i64 0, i32 1) ]
// CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr [[MYALLOC]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 1, ptr [[FOO]], i64 [[TMP1]]), "QUAL.OMP.ALLOCATE"(i64 4, ptr [[BAR]], i64 [[TMP1]]), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], i8 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[BAR]], i32 0, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[MYALLOC]], i64 0, i32 1) ]
// CHECK-NEXT:    [[TMP3:%.*]] = load i64, ptr [[MYALLOC]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 2, ptr [[FOO]], i64 [[TMP3]]), "QUAL.OMP.ALLOCATE"(i64 4, ptr [[BAR]], i64 [[TMP3]]), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], i8 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[BAR]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 8, ptr [[FOO]], i64 7), "QUAL.OMP.ALLOCATE"(i64 8, ptr [[BAR]], i64 7), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], i8 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[BAR]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP6:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 16, ptr [[FOO]]), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], i8 0, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP6]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP2]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    ret i32 0
//
//
// CHECK: define{{.*}}@_Z13template_testv(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[D:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load double, ptr [[D]], align 8
// CHECK-NEXT:    [[CALL:%.*]] = call noundef double @_Z3runIdL22omp_allocator_handle_t2ELj10ELj2EET_S1_(double noundef [[TMP0]])
// CHECK-NEXT:    store double [[CALL]], ptr [[D]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[D]], align 8
// CHECK-NEXT:    ret double [[TMP1]]
//
//
// CHECK: define{{.*}}@_Z3runIdL22omp_allocator_handle_t2ELj10ELj2EET_S1_(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[PARAM_ADDR:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[FOO:%.*]] = alloca [10 x double], align 16
// CHECK-NEXT:    store double [[PARAM:%.*]], ptr [[PARAM_ADDR]], align 8
// CHECK:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.ALLOCATE"(i64 8, ptr [[FOO]], i64 2), "QUAL.OMP.ALLOCATE"(i64 8, ptr [[PARAM_ADDR]], i64 2), "QUAL.OMP.PRIVATE:TYPED"(ptr [[FOO]], double 0.000000e+00, i64 10), "QUAL.OMP.PRIVATE:TYPED"(ptr [[PARAM_ADDR]], double 0.000000e+00, i32 1) ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [10 x double], ptr [[FOO]], i64 0, i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = load double, ptr [[ARRAYIDX]], align 16
// CHECK-NEXT:    ret double [[TMP1]]
//
// end INTEL_COLLAB
