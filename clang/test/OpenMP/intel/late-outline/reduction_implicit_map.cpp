// INTEL_COLLAB
// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --function-signature --include-generated-funcs --replace-value-regex "__omp_offloading_[0-9a-z]+_[0-9a-z]+" "reduction_size[.].+[.]" "pl_cond[.].+[.|,]" --prefix-filecheck-ir-name _

// RUN: %clang_cc1 -verify -fopenmp -x c++ \
// RUN:   -fopenmp-late-outline -emit-llvm \
// RUN:   -triple x86_64-pc-linux-gnu \
// RUN:   %s -o - | FileCheck %s

// Test map type with OMP_TGT_MAPTYPE_HOST_MEM 0x8000

int foo(int n) {
  double *e;
  double sum;
  #pragma omp target parallel reduction(+: e[:1])
    *e=10;
  #pragma omp target parallel map(e[:1]) reduction(+: e[:1])
    *e=10;
  #pragma omp target parallel reduction(+: sum)
    sum += e[0];
  return 0;
}
class S2 {
  mutable int a;
public:
  S2():a(0) { }
  S2(S2 &s2):a(s2.a) { }
  S2 &operator +(S2 &s);
  void moo() {
    #pragma omp target parallel reduction(+:a)
    a += 10;
  }
};
int bar() {
 S2 o[5];
#pragma omp target parallel reduction(+:o[0]) // expected-warning {{Type 'S2' is not trivially copyable and not guaranteed to be mapped correctly}}
  for (int i = 0; i < 10; i++);
  double b[10][10][10];
#pragma omp target parallel for reduction(task, +: b[0:2][2:4][1])
  for (long long i = 0; i < 10; ++i);
  o[0].moo();
  return 0;
}
void sum(int* input, int size, int* output)
{
#pragma omp target teams distribute parallel for reduction(+: output[0]) \
                                                 map(to: input [0:size])
  for (int i = 0; i < size; i++)
    output[0] += input[i];
#pragma omp target teams distribute parallel for reduction(+: output[:3])  \
                                                 map(to: input [0:size])
  for (int i = 0; i < size; i++)
    output[0] += input[i];
  int a[10];
#pragma omp target parallel reduction(+: a[:2])
  for (int i = 0; i < size; i++)
    ;
#pragma omp target parallel reduction(+: a[3])
  for (int i = 0; i < size; i++)
    ;
}
int main()
{
  int a = foo(10);
  a = bar();
  const int size = 100;
  int *array = new int[size];
  int result = 0;
  sum(array, size, &result);
  return 0;
}

// CHECK-LABEL: define {{[^@]+}}@_Z3fooi
// CHECK-SAME: (i32 noundef [[N:%.*]]) #[[ATTR0:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[N_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[E:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SUM:%.*]] = alloca double, align 8
// CHECK-NEXT:    [[E_MAP_PTR_TMP:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[E_MAP_PTR_TMP6:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[E_MAP_PTR_TMP8:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store i32 [[N]], ptr [[N_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds double, ptr [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds double, ptr [[TMP3]], i64 0
// CHECK-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 0), "QUAL.OMP.MAP.TOFROM"(ptr [[TMP2]], ptr [[ARRAYIDX1]], i64 8, i64 33315, ptr null, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[E_MAP_PTR_TMP]], ptr null, i32 1) ]
// CHECK-NEXT:    store ptr [[TMP2]], ptr [[E_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[E_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds double, ptr [[TMP5]], i64 0
// CHECK-NEXT:    [[TMP6:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[E_MAP_PTR_TMP]], double 0.000000e+00, i64 1, i64 0) ]
// CHECK-NEXT:    [[TMP7:%.*]] = load ptr, ptr [[E_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    store double 1.000000e+01, ptr [[TMP7]], align 8
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP6]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds double, ptr [[TMP8]], i64 0
// CHECK-NEXT:    [[TMP9:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds double, ptr [[TMP11]], i64 0
// CHECK-NEXT:    [[TMP12:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds double, ptr [[TMP13]], i64 0
// CHECK-NEXT:    [[TMP14:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 1), "QUAL.OMP.MAP.TOFROM"(ptr [[TMP10]], ptr [[ARRAYIDX4]], i64 8, i64 35, ptr null, ptr null), "QUAL.OMP.MAP.TOFROM:CHAIN"(ptr [[TMP12]], ptr [[ARRAYIDX5]], i64 8, i64 515, ptr null, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[E_MAP_PTR_TMP6]], ptr null, i32 1) ]
// CHECK-NEXT:    store ptr [[TMP10]], ptr [[E_MAP_PTR_TMP6]], align 8
// CHECK-NEXT:    [[TMP15:%.*]] = load ptr, ptr [[E_MAP_PTR_TMP6]], align 8
// CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds double, ptr [[TMP15]], i64 0
// CHECK-NEXT:    [[TMP16:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[E_MAP_PTR_TMP6]], double 0.000000e+00, i64 1, i64 0) ]
// CHECK-NEXT:    [[TMP17:%.*]] = load ptr, ptr [[E_MAP_PTR_TMP6]], align 8
// CHECK-NEXT:    store double 1.000000e+01, ptr [[TMP17]], align 8
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP16]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP14]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP18:%.*]] = load ptr, ptr [[E]], align 8
// CHECK-NEXT:    [[TMP19:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 2), "QUAL.OMP.MAP.TOFROM"(ptr [[SUM]], ptr [[SUM]], i64 8, i64 33315, ptr null, ptr null), "QUAL.OMP.MAP.TOFROM"(ptr [[TMP18]], ptr [[TMP18]], i64 0, i64 544, ptr null, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[E_MAP_PTR_TMP8]], ptr null, i32 1) ]
// CHECK-NEXT:    store ptr [[TMP18]], ptr [[E_MAP_PTR_TMP8]], align 8
// CHECK-NEXT:    [[TMP20:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:TYPED"(ptr [[SUM]], double 0.000000e+00, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[E_MAP_PTR_TMP8]], ptr null, i32 1) ]
// CHECK-NEXT:    [[TMP21:%.*]] = load ptr, ptr [[E_MAP_PTR_TMP8]], align 8
// CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds double, ptr [[TMP21]], i64 0
// CHECK-NEXT:    [[TMP22:%.*]] = load double, ptr [[ARRAYIDX9]], align 8
// CHECK-NEXT:    [[TMP23:%.*]] = load double, ptr [[SUM]], align 8
// CHECK-NEXT:    [[ADD:%.*]] = fadd double [[TMP23]], [[TMP22]]
// CHECK-NEXT:    store double [[ADD]], ptr [[SUM]], align 8
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP20]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP19]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    ret i32 0
//
//
// CHECK-LABEL: define {{[^@]+}}@_Z3barv
// CHECK-SAME: () #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[O:%.*]] = alloca [5 x %class.S2], align 16
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[B:%.*]] = alloca [10 x [10 x [10 x double]]], align 16
// CHECK-NEXT:    [[TMP:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DOTOMP_IV:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DOTOMP_LB:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[DOTOMP_UB:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[I11:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[ARRAY_BEGIN:%.*]] = getelementptr inbounds [5 x %class.S2], ptr [[O]], i32 0, i32 0
// CHECK-NEXT:    [[ARRAYCTOR_END:%.*]] = getelementptr inbounds [[CLASS_S2:%.*]], ptr [[ARRAY_BEGIN]], i64 5
// CHECK-NEXT:    br label [[ARRAYCTOR_LOOP:%.*]]
// CHECK:       arrayctor.loop:
// CHECK-NEXT:    [[ARRAYCTOR_CUR:%.*]] = phi ptr [ [[ARRAY_BEGIN]], [[ENTRY:%.*]] ], [ [[ARRAYCTOR_NEXT:%.*]], [[ARRAYCTOR_LOOP]] ]
// CHECK-NEXT:    call void @_ZN2S2C1Ev(ptr noundef nonnull align 4 dereferenceable(4) [[ARRAYCTOR_CUR]])
// CHECK-NEXT:    [[ARRAYCTOR_NEXT]] = getelementptr inbounds [[CLASS_S2]], ptr [[ARRAYCTOR_CUR]], i64 1
// CHECK-NEXT:    [[ARRAYCTOR_DONE:%.*]] = icmp eq ptr [[ARRAYCTOR_NEXT]], [[ARRAYCTOR_END]]
// CHECK-NEXT:    br i1 [[ARRAYCTOR_DONE]], label [[ARRAYCTOR_CONT:%.*]], label [[ARRAYCTOR_LOOP]]
// CHECK:       arrayctor.cont:
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [5 x %class.S2], ptr [[O]], i64 0, i64 0
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 3), "QUAL.OMP.MAP.TOFROM"(ptr [[O]], ptr [[ARRAYIDX]], i64 4, i64 33315, ptr null, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.UDR:ARRSECT.TYPED"(ptr [[O]], [[CLASS_S2]] zeroinitializer, i64 1, i64 0, ptr @_ZTS2S2.omp.def_constr, ptr @_ZTS2S2.omp.destr, ptr @.omp_combiner..1, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 [[TMP2]], 10
// CHECK-NEXT:    br i1 [[CMP]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK:       for.body:
// CHECK-NEXT:    br label [[FOR_INC:%.*]]
// CHECK:       for.inc:
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP3]], 1
// CHECK-NEXT:    store i32 [[INC]], ptr [[I]], align 4
// CHECK-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP13:![0-9]+]]
// CHECK:       for.end:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds [10 x [10 x [10 x double]]], ptr [[B]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYDECAY:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[ARRAYIDX1]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYDECAY]], i64 2
// CHECK-NEXT:    [[ARRAYDECAY3:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX2]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX4:%.*]] = getelementptr inbounds double, ptr [[ARRAYDECAY3]], i64 1
// CHECK-NEXT:    [[TMP4:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 4), "QUAL.OMP.MAP.TOFROM"(ptr [[B]], ptr [[B]], i64 8000, i64 33315, ptr null, ptr null), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I11]], i64 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[TMP]], i64 0, i32 1) ]
// CHECK-NEXT:    store i64 0, ptr [[DOTOMP_LB]], align 8
// CHECK-NEXT:    store i64 9, ptr [[DOTOMP_UB]], align 8
// CHECK-NEXT:    [[ARRAYIDX5:%.*]] = getelementptr inbounds [10 x [10 x [10 x double]]], ptr [[B]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYDECAY6:%.*]] = getelementptr inbounds [10 x [10 x double]], ptr [[ARRAYIDX5]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX7:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYDECAY6]], i64 2
// CHECK-NEXT:    [[ARRAYDECAY8:%.*]] = getelementptr inbounds [10 x double], ptr [[ARRAYIDX7]], i64 0, i64 0
// CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds double, ptr [[ARRAYDECAY8]], i64 1
// CHECK-NEXT:    [[TMP5:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL.LOOP"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.TASK.TYPED"(ptr [[B]], double 0.000000e+00, i64 80, i64 21), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i64 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i64 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i64 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I11]], i64 0, i32 1) ]
// CHECK-NEXT:    [[TMP6:%.*]] = load i64, ptr [[DOTOMP_LB]], align 8
// CHECK-NEXT:    store i64 [[TMP6]], ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[TMP8:%.*]] = load i64, ptr [[DOTOMP_UB]], align 8
// CHECK-NEXT:    [[CMP10:%.*]] = icmp sle i64 [[TMP7]], [[TMP8]]
// CHECK-NEXT:    br i1 [[CMP10]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// CHECK:       omp.inner.for.body.lh:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// CHECK:       omp.inner.for.body:
// CHECK-NEXT:    [[TMP9:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[MUL:%.*]] = mul nsw i64 [[TMP9]], 1
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i64 0, [[MUL]]
// CHECK-NEXT:    store i64 [[ADD]], ptr [[I11]], align 8
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// CHECK:       omp.body.continue:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// CHECK:       omp.inner.for.inc:
// CHECK-NEXT:    [[TMP10:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[ADD12:%.*]] = add nsw i64 [[TMP10]], 1
// CHECK-NEXT:    store i64 [[ADD12]], ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = load i64, ptr [[DOTOMP_IV]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = load i64, ptr [[DOTOMP_UB]], align 8
// CHECK-NEXT:    [[CMP13:%.*]] = icmp sle i64 [[TMP11]], [[TMP12]]
// CHECK-NEXT:    br i1 [[CMP13]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// CHECK:       omp.inner.for.end_crit_edge:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_END]]
// CHECK:       omp.inner.for.end:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// CHECK:       omp.loop.exit:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP5]]) [ "DIR.OMP.END.PARALLEL.LOOP"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP4]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds [5 x %class.S2], ptr [[O]], i64 0, i64 0
// CHECK-NEXT:    call void @_ZN2S23mooEv(ptr noundef nonnull align 4 dereferenceable(4) [[ARRAYIDX14]])
// CHECK-NEXT:    ret i32 0
//
//
// CHECK-LABEL: define {{[^@]+}}@_ZN2S2C1Ev
// CHECK-SAME: (ptr noundef nonnull align 4 dereferenceable(4) [[THIS:%.*]]) unnamed_addr #[[ATTR2:[0-9]+]] comdat align 2 {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[THIS_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[THIS]], ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[THIS1:%.*]] = load ptr, ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    call void @_ZN2S2C2Ev(ptr noundef nonnull align 4 dereferenceable(4) [[THIS1]])
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@.omp_combiner.
// CHECK-SAME: (ptr noalias noundef [[TMP0:%.*]], ptr noalias noundef [[TMP1:%.*]]) #[[ATTR3:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// CHECK-NEXT:    [[CALL:%.*]] = call noundef nonnull align 4 dereferenceable(4) ptr @_ZN2S2plERS_(ptr noundef nonnull align 4 dereferenceable(4) [[TMP3]], ptr noundef nonnull align 4 dereferenceable(4) [[TMP2]])
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[TMP3]], ptr align 4 [[CALL]], i64 4, i1 false)
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@_ZTS2S2.omp.def_constr
// CHECK-SAME: (ptr noundef [[TMP0:%.*]]) #[[ATTR3]] section ".text.startup" {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// CHECK-NEXT:    call void @_ZN2S2C1Ev(ptr noundef nonnull align 4 dereferenceable(4) [[TMP1]])
// CHECK-NEXT:    ret ptr [[TMP1]]
//
//
// CHECK-LABEL: define {{[^@]+}}@_ZTS2S2.omp.destr
// CHECK-SAME: (ptr noundef [[TMP0:%.*]]) #[[ATTR3]] section ".text.startup" {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@.omp_combiner..1
// CHECK-SAME: (ptr noalias noundef [[TMP0:%.*]], ptr noalias noundef [[TMP1:%.*]]) #[[ATTR3]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[DOTADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[DOTADDR1:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[DOTADDR]], align 8
// CHECK-NEXT:    store ptr [[TMP1]], ptr [[DOTADDR1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[DOTADDR1]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[DOTADDR]], align 8
// CHECK-NEXT:    [[CALL:%.*]] = call noundef nonnull align 4 dereferenceable(4) ptr @_ZN2S2plERS_(ptr noundef nonnull align 4 dereferenceable(4) [[TMP3]], ptr noundef nonnull align 4 dereferenceable(4) [[TMP2]])
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 4 [[TMP3]], ptr align 4 [[CALL]], i64 4, i1 false)
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@_ZN2S23mooEv
// CHECK-SAME: (ptr noundef nonnull align 4 dereferenceable(4) [[THIS:%.*]]) #[[ATTR0]] comdat align 2 {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[THIS_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[A:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[THIS]], ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[THIS1:%.*]] = load ptr, ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[A2:%.*]] = getelementptr inbounds [[CLASS_S2:%.*]], ptr [[THIS1]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[A2]], ptr [[A]], align 8
// CHECK-NEXT:    [[A3:%.*]] = getelementptr inbounds [[CLASS_S2]], ptr [[THIS1]], i32 0, i32 0
// CHECK-NEXT:    [[TMP0:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 5), "QUAL.OMP.MAP.TOFROM"(ptr [[A3]], ptr [[A3]], i64 4, i64 33315, ptr null, ptr null) ]
// CHECK-NEXT:    [[TMP1:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:TYPED"(ptr [[A3]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[A3]], align 4
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[TMP2]], 10
// CHECK-NEXT:    store i32 [[ADD]], ptr [[A3]], align 4
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP1]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP0]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@_ZN2S2C2Ev
// CHECK-SAME: (ptr noundef nonnull align 4 dereferenceable(4) [[THIS:%.*]]) unnamed_addr #[[ATTR2]] comdat align 2 {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[THIS_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    store ptr [[THIS]], ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[THIS1:%.*]] = load ptr, ptr [[THIS_ADDR]], align 8
// CHECK-NEXT:    [[A:%.*]] = getelementptr inbounds [[CLASS_S2:%.*]], ptr [[THIS1]], i32 0, i32 0
// CHECK-NEXT:    store i32 0, ptr [[A]], align 4
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@_Z3sumPiiS_
// CHECK-SAME: (ptr noundef [[INPUT:%.*]], i32 noundef [[SIZE:%.*]], ptr noundef [[OUTPUT:%.*]]) #[[ATTR0]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[INPUT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[SIZE_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[OUTPUT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[OUTPUT_MAP_PTR_TMP:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[INPUT_MAP_PTR_TMP:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[TMP:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_0:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_1:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[OUTPUT_MAP_PTR_TMP18:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[INPUT_MAP_PTR_TMP19:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[_TMP21:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_2:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTCAPTURE_EXPR_3:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_IV29:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_LB30:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[DOTOMP_UB31:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I36:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[A:%.*]] = alloca [10 x i32], align 16
// CHECK-NEXT:    [[I52:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[I55:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store ptr [[INPUT]], ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    store i32 [[SIZE]], ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    store ptr [[OUTPUT]], ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds i32, ptr [[TMP0]], i64 0
// CHECK-NEXT:    [[TMP1:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX1:%.*]] = getelementptr inbounds i32, ptr [[TMP4]], i64 0
// CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP6:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX2:%.*]] = getelementptr inbounds i32, ptr [[TMP6]], i64 0
// CHECK-NEXT:    [[TMP7:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    [[CONV:%.*]] = sext i32 [[TMP7]] to i64
// CHECK-NEXT:    [[TMP8:%.*]] = mul nuw i64 [[CONV]], 4
// CHECK-NEXT:    [[TMP9:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 6), "QUAL.OMP.MAP.TOFROM"(ptr [[TMP3]], ptr [[ARRAYIDX1]], i64 4, i64 33315, ptr null, ptr null), "QUAL.OMP.MAP.TO"(ptr [[TMP5]], ptr [[ARRAYIDX2]], i64 [[TMP8]], i64 33, ptr null, ptr null), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_1]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_0]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[OUTPUT_MAP_PTR_TMP]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[INPUT_MAP_PTR_TMP]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[TMP]], i32 0, i32 1) ]
// CHECK-NEXT:    store ptr [[TMP3]], ptr [[OUTPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    store ptr [[TMP5]], ptr [[INPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[ARRAYIDX3:%.*]] = getelementptr inbounds i32, ptr [[TMP10]], i64 0
// CHECK-NEXT:    [[TMP11:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[OUTPUT_MAP_PTR_TMP]], i32 0, i64 1, i64 0), "QUAL.OMP.SHARED:TYPED"(ptr [[INPUT_MAP_PTR_TMP]], ptr null, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_1]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_0]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[TMP]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP12]], ptr [[DOTCAPTURE_EXPR_0]], align 4
// CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// CHECK-NEXT:    [[SUB:%.*]] = sub nsw i32 [[TMP13]], 0
// CHECK-NEXT:    [[SUB4:%.*]] = sub nsw i32 [[SUB]], 1
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[SUB4]], 1
// CHECK-NEXT:    [[DIV:%.*]] = sdiv i32 [[ADD]], 1
// CHECK-NEXT:    [[SUB5:%.*]] = sub nsw i32 [[DIV]], 1
// CHECK-NEXT:    store i32 [[SUB5]], ptr [[DOTCAPTURE_EXPR_1]], align 4
// CHECK-NEXT:    [[TMP14:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_0]], align 4
// CHECK-NEXT:    [[CMP:%.*]] = icmp slt i32 0, [[TMP14]]
// CHECK-NEXT:    br i1 [[CMP]], label [[OMP_PRECOND_THEN:%.*]], label [[OMP_PRECOND_END:%.*]]
// CHECK:       omp.precond.then:
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB]], align 4
// CHECK-NEXT:    [[TMP15:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_1]], align 4
// CHECK-NEXT:    store i32 [[TMP15]], ptr [[DOTOMP_UB]], align 4
// CHECK-NEXT:    [[TMP16:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[ARRAYIDX6:%.*]] = getelementptr inbounds i32, ptr [[TMP16]], i64 0
// CHECK-NEXT:    [[TMP17:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[OUTPUT_MAP_PTR_TMP]], i32 0, i64 1, i64 0), "QUAL.OMP.SHARED:TYPED"(ptr [[INPUT_MAP_PTR_TMP]], ptr null, i32 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP18:%.*]] = load i32, ptr [[DOTOMP_LB]], align 4
// CHECK-NEXT:    store i32 [[TMP18]], ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[TMP19:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// CHECK-NEXT:    [[CMP7:%.*]] = icmp sle i32 [[TMP19]], [[TMP20]]
// CHECK-NEXT:    br i1 [[CMP7]], label [[OMP_INNER_FOR_BODY_LH:%.*]], label [[OMP_INNER_FOR_END:%.*]]
// CHECK:       omp.inner.for.body.lh:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY:%.*]]
// CHECK:       omp.inner.for.body:
// CHECK-NEXT:    [[TMP21:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[MUL:%.*]] = mul nsw i32 [[TMP21]], 1
// CHECK-NEXT:    [[ADD8:%.*]] = add nsw i32 0, [[MUL]]
// CHECK-NEXT:    store i32 [[ADD8]], ptr [[I]], align 4
// CHECK-NEXT:    [[TMP22:%.*]] = load ptr, ptr [[INPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[TMP23:%.*]] = load i32, ptr [[I]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP23]] to i64
// CHECK-NEXT:    [[ARRAYIDX9:%.*]] = getelementptr inbounds i32, ptr [[TMP22]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP24:%.*]] = load i32, ptr [[ARRAYIDX9]], align 4
// CHECK-NEXT:    [[TMP25:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP]], align 8
// CHECK-NEXT:    [[ARRAYIDX10:%.*]] = getelementptr inbounds i32, ptr [[TMP25]], i64 0
// CHECK-NEXT:    [[TMP26:%.*]] = load i32, ptr [[ARRAYIDX10]], align 4
// CHECK-NEXT:    [[ADD11:%.*]] = add nsw i32 [[TMP26]], [[TMP24]]
// CHECK-NEXT:    store i32 [[ADD11]], ptr [[ARRAYIDX10]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE:%.*]]
// CHECK:       omp.body.continue:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC:%.*]]
// CHECK:       omp.inner.for.inc:
// CHECK-NEXT:    [[TMP27:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[ADD12:%.*]] = add nsw i32 [[TMP27]], 1
// CHECK-NEXT:    store i32 [[ADD12]], ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[TMP28:%.*]] = load i32, ptr [[DOTOMP_IV]], align 4
// CHECK-NEXT:    [[TMP29:%.*]] = load i32, ptr [[DOTOMP_UB]], align 4
// CHECK-NEXT:    [[CMP13:%.*]] = icmp sle i32 [[TMP28]], [[TMP29]]
// CHECK-NEXT:    br i1 [[CMP13]], label [[OMP_INNER_FOR_BODY]], label [[OMP_INNER_FOR_END_CRIT_EDGE:%.*]]
// CHECK:       omp.inner.for.end_crit_edge:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_END]]
// CHECK:       omp.inner.for.end:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT:%.*]]
// CHECK:       omp.loop.exit:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP17]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// CHECK-NEXT:    br label [[OMP_PRECOND_END]]
// CHECK:       omp.precond.end:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP11]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP9]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[TMP30:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX14:%.*]] = getelementptr inbounds i32, ptr [[TMP30]], i64 0
// CHECK-NEXT:    [[TMP31:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP32:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP33:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP34:%.*]] = load ptr, ptr [[OUTPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX15:%.*]] = getelementptr inbounds i32, ptr [[TMP34]], i64 0
// CHECK-NEXT:    [[TMP35:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[TMP36:%.*]] = load ptr, ptr [[INPUT_ADDR]], align 8
// CHECK-NEXT:    [[ARRAYIDX16:%.*]] = getelementptr inbounds i32, ptr [[TMP36]], i64 0
// CHECK-NEXT:    [[TMP37:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    [[CONV17:%.*]] = sext i32 [[TMP37]] to i64
// CHECK-NEXT:    [[TMP38:%.*]] = mul nuw i64 [[CONV17]], 4
// CHECK-NEXT:    [[TMP39:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 7), "QUAL.OMP.MAP.TOFROM"(ptr [[TMP33]], ptr [[ARRAYIDX15]], i64 12, i64 33315, ptr null, ptr null), "QUAL.OMP.MAP.TO"(ptr [[TMP35]], ptr [[ARRAYIDX16]], i64 [[TMP38]], i64 33, ptr null, ptr null), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_3]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV29]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB30]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB31]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I36]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_2]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[OUTPUT_MAP_PTR_TMP18]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[INPUT_MAP_PTR_TMP19]], ptr null, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP21]], i32 0, i32 1) ]
// CHECK-NEXT:    store ptr [[TMP33]], ptr [[OUTPUT_MAP_PTR_TMP18]], align 8
// CHECK-NEXT:    store ptr [[TMP35]], ptr [[INPUT_MAP_PTR_TMP19]], align 8
// CHECK-NEXT:    [[TMP40:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP18]], align 8
// CHECK-NEXT:    [[ARRAYIDX20:%.*]] = getelementptr inbounds i32, ptr [[TMP40]], i64 0
// CHECK-NEXT:    [[TMP41:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TEAMS"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[OUTPUT_MAP_PTR_TMP18]], i32 0, i64 3, i64 0), "QUAL.OMP.SHARED:TYPED"(ptr [[INPUT_MAP_PTR_TMP19]], ptr null, i32 1), "QUAL.OMP.SHARED:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_3]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_IV29]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_LB30]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTOMP_UB31]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I36]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[DOTCAPTURE_EXPR_2]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[_TMP21]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP42:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    store i32 [[TMP42]], ptr [[DOTCAPTURE_EXPR_2]], align 4
// CHECK-NEXT:    [[TMP43:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_2]], align 4
// CHECK-NEXT:    [[SUB22:%.*]] = sub nsw i32 [[TMP43]], 0
// CHECK-NEXT:    [[SUB23:%.*]] = sub nsw i32 [[SUB22]], 1
// CHECK-NEXT:    [[ADD24:%.*]] = add nsw i32 [[SUB23]], 1
// CHECK-NEXT:    [[DIV25:%.*]] = sdiv i32 [[ADD24]], 1
// CHECK-NEXT:    [[SUB26:%.*]] = sub nsw i32 [[DIV25]], 1
// CHECK-NEXT:    store i32 [[SUB26]], ptr [[DOTCAPTURE_EXPR_3]], align 4
// CHECK-NEXT:    [[TMP44:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_2]], align 4
// CHECK-NEXT:    [[CMP27:%.*]] = icmp slt i32 0, [[TMP44]]
// CHECK-NEXT:    br i1 [[CMP27]], label [[OMP_PRECOND_THEN28:%.*]], label [[OMP_PRECOND_END50:%.*]]
// CHECK:       omp.precond.then28:
// CHECK-NEXT:    store i32 0, ptr [[DOTOMP_LB30]], align 4
// CHECK-NEXT:    [[TMP45:%.*]] = load i32, ptr [[DOTCAPTURE_EXPR_3]], align 4
// CHECK-NEXT:    store i32 [[TMP45]], ptr [[DOTOMP_UB31]], align 4
// CHECK-NEXT:    [[TMP46:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP18]], align 8
// CHECK-NEXT:    [[ARRAYIDX32:%.*]] = getelementptr inbounds i32, ptr [[TMP46]], i64 0
// CHECK-NEXT:    [[TMP47:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.DISTRIBUTE.PARLOOP"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.PTR_TO_PTR.TYPED"(ptr [[OUTPUT_MAP_PTR_TMP18]], i32 0, i64 3, i64 0), "QUAL.OMP.SHARED:TYPED"(ptr [[INPUT_MAP_PTR_TMP19]], ptr null, i32 1), "QUAL.OMP.NORMALIZED.IV:TYPED"(ptr [[DOTOMP_IV29]], i32 0), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[DOTOMP_LB30]], i32 0, i32 1), "QUAL.OMP.NORMALIZED.UB:TYPED"(ptr [[DOTOMP_UB31]], i32 0), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I36]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP48:%.*]] = load i32, ptr [[DOTOMP_LB30]], align 4
// CHECK-NEXT:    store i32 [[TMP48]], ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[TMP49:%.*]] = load i32, ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[TMP50:%.*]] = load i32, ptr [[DOTOMP_UB31]], align 4
// CHECK-NEXT:    [[CMP33:%.*]] = icmp sle i32 [[TMP49]], [[TMP50]]
// CHECK-NEXT:    br i1 [[CMP33]], label [[OMP_INNER_FOR_BODY_LH34:%.*]], label [[OMP_INNER_FOR_END48:%.*]]
// CHECK:       omp.inner.for.body.lh34:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY35:%.*]]
// CHECK:       omp.inner.for.body35:
// CHECK-NEXT:    [[TMP51:%.*]] = load i32, ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[MUL37:%.*]] = mul nsw i32 [[TMP51]], 1
// CHECK-NEXT:    [[ADD38:%.*]] = add nsw i32 0, [[MUL37]]
// CHECK-NEXT:    store i32 [[ADD38]], ptr [[I36]], align 4
// CHECK-NEXT:    [[TMP52:%.*]] = load ptr, ptr [[INPUT_MAP_PTR_TMP19]], align 8
// CHECK-NEXT:    [[TMP53:%.*]] = load i32, ptr [[I36]], align 4
// CHECK-NEXT:    [[IDXPROM39:%.*]] = sext i32 [[TMP53]] to i64
// CHECK-NEXT:    [[ARRAYIDX40:%.*]] = getelementptr inbounds i32, ptr [[TMP52]], i64 [[IDXPROM39]]
// CHECK-NEXT:    [[TMP54:%.*]] = load i32, ptr [[ARRAYIDX40]], align 4
// CHECK-NEXT:    [[TMP55:%.*]] = load ptr, ptr [[OUTPUT_MAP_PTR_TMP18]], align 8
// CHECK-NEXT:    [[ARRAYIDX41:%.*]] = getelementptr inbounds i32, ptr [[TMP55]], i64 0
// CHECK-NEXT:    [[TMP56:%.*]] = load i32, ptr [[ARRAYIDX41]], align 4
// CHECK-NEXT:    [[ADD42:%.*]] = add nsw i32 [[TMP56]], [[TMP54]]
// CHECK-NEXT:    store i32 [[ADD42]], ptr [[ARRAYIDX41]], align 4
// CHECK-NEXT:    br label [[OMP_BODY_CONTINUE43:%.*]]
// CHECK:       omp.body.continue43:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_INC44:%.*]]
// CHECK:       omp.inner.for.inc44:
// CHECK-NEXT:    [[TMP57:%.*]] = load i32, ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[ADD45:%.*]] = add nsw i32 [[TMP57]], 1
// CHECK-NEXT:    store i32 [[ADD45]], ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[TMP58:%.*]] = load i32, ptr [[DOTOMP_IV29]], align 4
// CHECK-NEXT:    [[TMP59:%.*]] = load i32, ptr [[DOTOMP_UB31]], align 4
// CHECK-NEXT:    [[CMP46:%.*]] = icmp sle i32 [[TMP58]], [[TMP59]]
// CHECK-NEXT:    br i1 [[CMP46]], label [[OMP_INNER_FOR_BODY35]], label [[OMP_INNER_FOR_END_CRIT_EDGE47:%.*]]
// CHECK:       omp.inner.for.end_crit_edge47:
// CHECK-NEXT:    br label [[OMP_INNER_FOR_END48]]
// CHECK:       omp.inner.for.end48:
// CHECK-NEXT:    br label [[OMP_LOOP_EXIT49:%.*]]
// CHECK:       omp.loop.exit49:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP47]]) [ "DIR.OMP.END.DISTRIBUTE.PARLOOP"() ]
// CHECK-NEXT:    br label [[OMP_PRECOND_END50]]
// CHECK:       omp.precond.end50:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP41]]) [ "DIR.OMP.END.TEAMS"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP39]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[ARRAYIDX51:%.*]] = getelementptr inbounds [10 x i32], ptr [[A]], i64 0, i64 0
// CHECK-NEXT:    [[TMP60:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 8), "QUAL.OMP.MAP.TOFROM"(ptr [[A]], ptr [[ARRAYIDX51]], i64 8, i64 33315, ptr null, ptr null), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I52]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP61:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.TYPED"(ptr [[A]], i32 0, i64 2, i64 0), "QUAL.OMP.SHARED:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I52]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[I52]], align 4
// CHECK-NEXT:    br label [[FOR_COND:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[TMP62:%.*]] = load i32, ptr [[I52]], align 4
// CHECK-NEXT:    [[TMP63:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    [[CMP53:%.*]] = icmp slt i32 [[TMP62]], [[TMP63]]
// CHECK-NEXT:    br i1 [[CMP53]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK:       for.body:
// CHECK-NEXT:    br label [[FOR_INC:%.*]]
// CHECK:       for.inc:
// CHECK-NEXT:    [[TMP64:%.*]] = load i32, ptr [[I52]], align 4
// CHECK-NEXT:    [[INC:%.*]] = add nsw i32 [[TMP64]], 1
// CHECK-NEXT:    store i32 [[INC]], ptr [[I52]], align 4
// CHECK-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP15:![0-9]+]]
// CHECK:       for.end:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP61]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP60]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    [[ARRAYIDX54:%.*]] = getelementptr inbounds [10 x i32], ptr [[A]], i64 0, i64 3
// CHECK-NEXT:    [[TMP65:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.TARGET"(), "QUAL.OMP.OFFLOAD.ENTRY.IDX"(i32 9), "QUAL.OMP.MAP.TOFROM"(ptr [[A]], ptr [[ARRAYIDX54]], i64 4, i64 33315, ptr null, ptr null), "QUAL.OMP.FIRSTPRIVATE:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I55]], i32 0, i32 1) ]
// CHECK-NEXT:    [[TMP66:%.*]] = call token @llvm.directive.region.entry() [ "DIR.OMP.PARALLEL"(), "QUAL.OMP.REDUCTION.ADD:ARRSECT.TYPED"(ptr [[A]], i32 0, i64 1, i64 3), "QUAL.OMP.SHARED:TYPED"(ptr [[SIZE_ADDR]], i32 0, i32 1), "QUAL.OMP.PRIVATE:TYPED"(ptr [[I55]], i32 0, i32 1) ]
// CHECK-NEXT:    store i32 0, ptr [[I55]], align 4
// CHECK-NEXT:    br label [[FOR_COND56:%.*]]
// CHECK:       for.cond56:
// CHECK-NEXT:    [[TMP67:%.*]] = load i32, ptr [[I55]], align 4
// CHECK-NEXT:    [[TMP68:%.*]] = load i32, ptr [[SIZE_ADDR]], align 4
// CHECK-NEXT:    [[CMP57:%.*]] = icmp slt i32 [[TMP67]], [[TMP68]]
// CHECK-NEXT:    br i1 [[CMP57]], label [[FOR_BODY58:%.*]], label [[FOR_END61:%.*]]
// CHECK:       for.body58:
// CHECK-NEXT:    br label [[FOR_INC59:%.*]]
// CHECK:       for.inc59:
// CHECK-NEXT:    [[TMP69:%.*]] = load i32, ptr [[I55]], align 4
// CHECK-NEXT:    [[INC60:%.*]] = add nsw i32 [[TMP69]], 1
// CHECK-NEXT:    store i32 [[INC60]], ptr [[I55]], align 4
// CHECK-NEXT:    br label [[FOR_COND56]], !llvm.loop [[LOOP16:![0-9]+]]
// CHECK:       for.end61:
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP66]]) [ "DIR.OMP.END.PARALLEL"() ]
// CHECK-NEXT:    call void @llvm.directive.region.exit(token [[TMP65]]) [ "DIR.OMP.END.TARGET"() ]
// CHECK-NEXT:    ret void
//
//
// CHECK-LABEL: define {{[^@]+}}@main
// CHECK-SAME: () #[[ATTR6:[0-9]+]] {
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[RETVAL:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[A:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[SIZE:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[ARRAY:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[RESULT:%.*]] = alloca i32, align 4
// CHECK-NEXT:    store i32 0, ptr [[RETVAL]], align 4
// CHECK-NEXT:    [[CALL:%.*]] = call noundef i32 @_Z3fooi(i32 noundef 10)
// CHECK-NEXT:    store i32 [[CALL]], ptr [[A]], align 4
// CHECK-NEXT:    [[CALL1:%.*]] = call noundef i32 @_Z3barv()
// CHECK-NEXT:    store i32 [[CALL1]], ptr [[A]], align 4
// CHECK-NEXT:    store i32 100, ptr [[SIZE]], align 4
// CHECK-NEXT:    [[CALL2:%.*]] = call noalias noundef nonnull ptr @_Znam(i64 noundef 400) #[[ATTR8:[0-9]+]]
// CHECK-NEXT:    store ptr [[CALL2]], ptr [[ARRAY]], align 8
// CHECK-NEXT:    store i32 0, ptr [[RESULT]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[ARRAY]], align 8
// CHECK-NEXT:    call void @_Z3sumPiiS_(ptr noundef [[TMP0]], i32 noundef 100, ptr noundef [[RESULT]])
// CHECK-NEXT:    ret i32 0
//
// end  INTEL_COLLAB
