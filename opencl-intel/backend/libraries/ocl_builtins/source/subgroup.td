// Copyright (C) 2022 Intel Corporation
//
// This software and the related documents are Intel copyrighted materials, and
// your use of them is governed by the express license under which they were
// provided to you ("License"). Unless the License provides otherwise, you may
// not use, modify, copy, publish, distribute, disclose or transmit this
// software or the related documents without Intel's prior written permission.
//
// This software and the related documents are provided as is, with no express
// or implied warranties, other than those that are expressly stated in the
// License.

// --- Internal subgroup helpers ---
//
// uint _get_sub_group_leader(gentype vec_mask)
// The vec_mask is the masking parameter generated by Vectorizer, the builtin
// returns the subgroup local id of the first active item in the subgroup, by
// finding the first non-zero element of the vec_mask.
let Attrs = [OVERLOADABLE, CONSTFUNC], NeedForwardDecl = true,
    Types = ExpandTypesByVFAndFlatten<[v1i8, v1u8, v1i16, v1u16, v1i32, v1u32, v1i64, v1u64, v1f16, v1f32, v1f64], [4, 8, 16, 32, 64]>.Tout in {
  def get_sub_group_leader : OclBuiltin<"_get_sub_group_leader", (outs uint:$ret), (ins gentype:$vec_mask)>;
}

defvar int_mask_types = ExpandTypesByVFAndFlatten<[v1i8, v1u8, v1i16, v1u16, v1i32, v1u32, v1i64, v1u64], [4, 8, 16, 32, 64]>.Tout;
defvar fp_mask_types = ExpandTypesByVFAndFlatten<[v1f16, v1f32, v1f64], [4, 8, 16, 32, 64]>.Tout;
// Integer implementation is written in LLVM IR (shared/ll_subgroup_impl.td).
def : OclBuiltinImpl<get_sub_group_leader, int_mask_types, /*IsDeclOnly*/true, [{}]>, SHARED;
// Just call integer variant for fp implementation.
def : OclBuiltinImpl<get_sub_group_leader, fp_mask_types, false, [{
  return _get_sub_group_leader(__builtin_astype($Arg0VarName, $Arg0igentype));
}]>, SHARED;

// --- Dummy subgroup builtins ---
//
// ResolveSubGroupWICall doesn't resolve these builtin when they are contained
// in functions that are NOT called by the kernel.
// So we need to provide fake implementations to avoid "unimplemented" error.
//
// Prototypes
let Types = [v1i32], Attrs = [OVERLOADABLE] in {
defset list<OclBuiltin> dummy_builtins = {
  def get_sub_group_size : OclBuiltin<"get_sub_group_size", (outs uint:$ret), (ins void)>;
  def get_max_sub_group_size : OclBuiltin<"get_max_sub_group_size", (outs uint:$ret), (ins void)>;
  def get_num_sub_groups : OclBuiltin<"get_num_sub_groups", (outs uint:$ret), (ins void)>;
  def get_enqueued_num_sub_groups : OclBuiltin<"get_enqueued_num_sub_groups", (outs uint:$ret), (ins void)>;
  def get_sub_group_id : OclBuiltin<"get_sub_group_id", (outs uint:$ret), (ins void)>;
  def get_sub_group_local_id : OclBuiltin<"get_sub_group_local_id", (outs uint:$ret), (ins void)>;
} // defset dummy_builtins
defset list<OclBuiltin> dummy_no_ret_builtins = {
  def sub_group_barrier : OclBuiltin<"sub_group_barrier", (outs void:$ret), (ins cl_mem_fence_flags:$fence)>;
  def sub_group_barrier_with_scope : OclBuiltin<"sub_group_barrier", (outs void:$ret), (ins cl_mem_fence_flags:$fence, memory_scope:$scope)>;
} // defset dummy_no_ret_builtins
}

// Implementations
foreach bi = dummy_builtins in {
  def : OclBuiltinImpl<bi, bi.Types, /*isDeclOnly*/false, ret_zero_code>, SHARED;
}
foreach bi = dummy_no_ret_builtins in {
  def : OclBuiltinImpl<bi, bi.Types, /*isDeclOnly*/false, ret_void_code>, SHARED;
}

// VectInfos (not needed for dummy subgroup builtins)


// --- subgroup core ---
// https://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_C.html#subgroup-functions
//
// Types
defvar sub_group_core_scalar_types = [v1i32, v1u32, v1i64, v1u64, v1f16, v1f32, v1f64];
// --- cl_khr_subgroup_extended_types ---
// https://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#cl_khr_subgroup_extended_types
// Extended scalar types for broadcast, scan and reduction
defvar sub_group_extended_scalar_types = sub_group_core_scalar_types # [v1i8, v1u8, v1i16, v1u16];
// Extended vector types for broadcast
defvar sub_group_extended_vector_types = ExpandTypesByVFAndFlatten<sub_group_extended_scalar_types, [2, 3, 4, 8, 16]>.Tout;
defvar sub_group_extended_all_types = sub_group_extended_scalar_types # sub_group_extended_vector_types;

// Prototypes
let Attrs = [OVERLOADABLE], VectorAttrs = [KERNEL_CALL_ONCE] in {
  def sub_group_broadcast : OclBuiltin<"sub_group_broadcast", (outs gentype:$ret), (ins gentype:$x, v1u32:$sub_group_local_id), sub_group_extended_all_types>;

  foreach vf = [4, 8, 16, 32, 64] in {
    let NeedForwardDecl = true in {
      defvar mask_type = !cast<OclType>("v" # vf # "u32");
      def sub_group_broadcast_vf # vf : OclBuiltin<"sub_group_broadcast", (outs gentype:$ret), (ins gentype:$x, v1u32:$sub_group_local_id, mask_type:$vec_mask), WidenTypeForList<sub_group_broadcast.Types, vf>.Tout>;

      defvar lid_type = !cast<OclType>("v" # vf # "u32");
      def sub_group_broadcast_assume_uniform_vf # vf : OclBuiltin<"sub_group_broadcast", (outs gentype:$ret), (ins gentype:$x, lid_type:$sub_group_local_ids, mask_type:$vec_mask), WidenTypeForList<sub_group_broadcast.Types, vf>.Tout>;
    }
  }
}

// Implementations
// Fake scalar impl
def : OclBuiltinImpl<sub_group_broadcast, sub_group_broadcast.Types, false, ret_zero_code>, SHARED;
// Vector impl
foreach vf = [4, 8, 16, 32, 64] in {
  defvar sub_group_broadcast_vec = !cast<OclBuiltin>("sub_group_broadcast_vf" # vf);

  // Vector variant of scalar data types.
  // e.g. Widening `int sub_group_broadcast(int, uint)`
  defvar scalar_widened_types = WidenTypeForList<sub_group_extended_scalar_types, vf>.Tout;
  def : OclBuiltinImpl<sub_group_broadcast_vec, scalar_widened_types, false, [{
    return $Arg0VarName[$Arg1VarName];
  }]>, SHARED;

  // Vector variant of vector data types.
  // e.g. Widening `int3 sub_group_broadcast(int3, uint)`
  // Use `vloadn` to get the broadcast value.
  foreach orig_vec_len = [2, 3, 4, 8, 16] in {
    defvar broadcast_expression = !interleave(!listsplat("_t", vf), ",");

    // For `halfn` types, we need to use `vload_halfn`.
    defvar vector_half_widened_types = [!cast<OclType>("v" # !mul(vf, orig_vec_len) # "f16")];
    def : OclBuiltinImpl<sub_group_broadcast_vec, vector_half_widened_types, false, [{
      half$N _t = convert_half$N(vload_half$N($Arg1VarName, (half *)&$Arg0VarName));
      return ($ReturnType)($BROADCAST);
    }], [["$N", !cast<string>(orig_vec_len)], ["$BROADCAST", broadcast_expression]]>, SHARED;

    // For types other than `halfn`, we use `vloadn`.
    defvar non_half_scalar_types = !filter(t, sub_group_extended_scalar_types, !not(!eq(t, v1f16)));
    defvar vector_non_half_widened_types = WidenTypeForList<non_half_scalar_types, !mul(vf, orig_vec_len)>.Tout;
    def : OclBuiltinImpl<sub_group_broadcast_vec, vector_non_half_widened_types, false, [{
      $Arg0BaseType$N _t = vload$N($Arg1VarName, ($Arg0BaseType *)&$Arg0VarName);
      return ($ReturnType)($BROADCAST);
    }], [["$N", !cast<string>(orig_vec_len)], ["$BROADCAST", broadcast_expression]]>, SHARED;
  }

  // This is a variant with "sub_group_local_id" parameter widened by VF.
  // The spec explicitly requires "the value of sub_group_local_id to be
  // equivalent for all active work-items in the subgroup", so we assume it
  // uniform by accessing the first active element, whose index is determined
  // by the helper function _get_sub_group_leader().
  defvar sub_group_broadcast_assume_uniform_vec = !cast<OclBuiltin>("sub_group_broadcast_assume_uniform_vf" # vf);
  def : OclBuiltinImpl<sub_group_broadcast_assume_uniform_vec, sub_group_broadcast_assume_uniform_vec.Types, false, [{
    uint _leader = _get_sub_group_leader($Arg2VarName);
    return sub_group_broadcast($Arg0VarName, $Arg1VarName[_leader], $Arg2VarName);
  }]>, SHARED;
}

// VectInfos
def : VectInfo<sub_group_broadcast.Types, sub_group_broadcast, sub_group_broadcast_vf4, sub_group_broadcast_vf8, sub_group_broadcast_vf16, sub_group_broadcast_vf32, sub_group_broadcast_vf64>;
def : VectInfo<sub_group_broadcast.Types, sub_group_broadcast, sub_group_broadcast_assume_uniform_vf4, sub_group_broadcast_assume_uniform_vf8, sub_group_broadcast_assume_uniform_vf16, sub_group_broadcast_assume_uniform_vf32, sub_group_broadcast_assume_uniform_vf64>;

// --- cl_khr_subgroup_ballot ---
//
// https://www.khronos.org/registry/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#cl_khr_subgroup_ballot
//
// For the sub_group_non_uniform_broadcast and sub_group_broadcast_first
// functions, the generic type name gentype may be one of the supported
// built-in scalar data types char, uchar, short, ushort, int, uint, long,
// ulong, float, double (if double precision is supported), or half (if half
// precision is supported).
//
// For the sub_group_non_uniform_broadcast function, the generic type name
// gentype may additionally be one of the supported built-in vector data
// types charn, ucharn, shortn, ushortn, intn, uintn, longn, ulongn, floatn,
// doublen (if double precision is supported), or halfn (if half precision is
// supported).
//
// TODO: implement
// sub_group_broadcast_first
// sub_group_inverse_ballot
// sub_group_ballot_bit_extract
// sub_group_ballot_bit_count
// sub_group_ballot_inclusive_scan
// sub_group_ballot_exclusive_scan
// get_sub_group_eq_mask
// get_sub_group_ge_mask
// get_sub_group_gt_mask
// get_sub_group_le_mask
// get_sub_group_lt_mask
//
// Note:
// SYCLEqualizer will resolve sub_group_non_uniform_broadcast as sub_group_broadcast.
//
// Prototypes
let Attrs = [OVERLOADABLE], VectorAttrs = [KERNEL_CALL_ONCE], NeedForwardDecl = true in {
  def sub_group_ballot : OclBuiltin<"sub_group_ballot", (outs v4u32:$ret), (ins gentype:$predicate), [v1i32]>;
  def sub_group_ballot_find_lsb : OclBuiltin<"sub_group_ballot_find_lsb", (outs v1u32:$ret), (ins gentype:$value), [v4u32]>;
  def sub_group_ballot_find_msb : OclBuiltin<"sub_group_ballot_find_msb", (outs v1u32:$ret), (ins gentype:$value), [v4u32]>;
  foreach vf = [4, 8, 16, 32, 64] in {
    defvar mask_type = !cast<OclType>("v" # vf # "u32");
    def sub_group_ballot_vf # vf : OclBuiltin<"sub_group_ballot", (outs WidenType<v4u32, vf>.Tout:$ret), (ins gentype:$predicate, mask_type:$vec_mask), [WidenType<v1i32, vf>.Tout]>;
    // The `value` parameter need NOT to be uniform for active items.
    def sub_group_ballot_find_lsb_vf # vf : OclBuiltin<"sub_group_ballot_find_lsb", (outs WidenType<v1u32, vf>.Tout:$ret), (ins gentype:$value, mask_type:$vec_mask), [WidenType<v4u32, vf>.Tout]>;
    def sub_group_ballot_find_msb_vf # vf : OclBuiltin<"sub_group_ballot_find_msb", (outs WidenType<v1u32, vf>.Tout:$ret), (ins gentype:$value, mask_type:$vec_mask), [WidenType<v4u32, vf>.Tout]>;
  }
}

// Implementations
// Fake implementation for scalar version
def : OclBuiltinImpl<sub_group_ballot, sub_group_ballot.Types, false, ret_zero_code>, SHARED;
def : OclBuiltinImpl<sub_group_ballot_find_lsb, sub_group_ballot_find_lsb.Types, false, ret_zero_code>, SHARED;
// Vector implementation
foreach builtin = ["sub_group_ballot", "sub_group_ballot_find_lsb", "sub_group_ballot_find_msb"] in {
foreach vf = [4, 8, 16, 32, 64] in {
  defvar builtin_vec = !cast<OclBuiltin>(builtin # "_vf" # vf);
  // Implementation is written in LLVM IR (shared/ll_subgroup_impl.td).
  def : OclBuiltinImpl<builtin_vec, builtin_vec.Types, /*IsDeclOnly*/true, [{}]>, SHARED;
} // foreach vf
} // foreach builtin

// VectInfos
def : VectInfo<[v1i32], sub_group_ballot, sub_group_ballot_vf4, sub_group_ballot_vf8, sub_group_ballot_vf16, sub_group_ballot_vf32, sub_group_ballot_vf64>;
def : VectInfo<[v4u32], sub_group_ballot_find_lsb, sub_group_ballot_find_lsb_vf4, sub_group_ballot_find_lsb_vf8, sub_group_ballot_find_lsb_vf16, sub_group_ballot_find_lsb_vf32, sub_group_ballot_find_lsb_vf64>;
def : VectInfo<[v4u32], sub_group_ballot_find_msb, sub_group_ballot_find_msb_vf4, sub_group_ballot_find_msb_vf8, sub_group_ballot_find_msb_vf16, sub_group_ballot_find_msb_vf32, sub_group_ballot_find_msb_vf64>;

// --- sub_group_shuffle builtins ---
//
// 
// https://registry.khronos.org/OpenCL/extensions/intel/cl_intel_subgroups.html
// https://registry.khronos.org/OpenCL/specs/3.0-unified/html/OpenCL_Ext.html#cl_khr_subgroup_shuffle
//

defvar sub_group_types = [v1f16];

// Prototypes
let Attrs = [OVERLOADABLE], VectorAttrs = [KERNEL_CALL_ONCE], NeedForwardDecl = true in {
  // scalar
  let Types = [v1f16] in {
    def sub_group_shuffle_vf1 : OclBuiltin<"intel_sub_group_shuffle", (outs gentype:$ret), (ins gentype:$data, v1u32: $sub_group_local_id)>;
    def sub_group_shuffle_xor_vf1 : OclBuiltin<"intel_sub_group_shuffle_xor", (outs gentype:$ret), (ins gentype:$data, v1u32: $sub_group_local_id)>;
    def sub_group_shuffle_up_vf1 : OclBuiltin<"intel_sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$data, gentype:$current, v1u32: $sub_group_local_id)>;
    def sub_group_shuffle_down_vf1 : OclBuiltin<"intel_sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$data, gentype:$next, v1u32: $sub_group_local_id)>;

    def khr_sub_group_shuffle_up_vf1 : OclBuiltin<"sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$data, v1u32: $delta)>;
    def khr_sub_group_shuffle_down_vf1 : OclBuiltin<"sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$data, v1u32: $delta)>;
  }
  // vectorized
  foreach vf = [4, 8, 16, 32, 64] in {
    defvar mask_type = !cast<OclType>("v" # vf # "u32");
    let Types = ExpandTypesByVFAndFlatten<sub_group_types, [vf]>.Tout in {
      def sub_group_shuffle_vf # vf : OclBuiltin<"intel_sub_group_shuffle", (outs gentype:$ret), (ins gentype:$data, mask_type: $sub_group_local_id, mask_type:$vec_mask)>;
      def sub_group_shuffle_xor_vf # vf : OclBuiltin<"intel_sub_group_shuffle_xor", (outs gentype:$ret), (ins gentype:$data, mask_type: $value, mask_type:$vec_mask)>;
      def sub_group_shuffle_up_vf # vf : OclBuiltin<"intel_sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$data, gentype:$current, mask_type: $value, mask_type:$vec_mask)>;
      def sub_group_shuffle_down_vf # vf : OclBuiltin<"intel_sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$data, gentype:$next, mask_type: $value, mask_type:$vec_mask)>;

      def khr_sub_group_shuffle_up_vf # vf : OclBuiltin<"sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$data, mask_type: $delta, mask_type:$vec_mask)>;
      def khr_sub_group_shuffle_down_vf # vf : OclBuiltin<"sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$data, mask_type: $delta, mask_type:$vec_mask)>;
    }
  }

  // Because half type shuffle builtins are implemented via short type builtins.
  // So just declare short builtins here, when all builtin are migrated here,
  // these declarations can be deleted.
  foreach vf = [4, 8, 16, 32, 64] in {
    defvar mask_type = !cast<OclType>("v" # vf # "u32");
    let Types = ExpandTypesByVFAndFlatten<[v1i16], [vf]>.Tout in {
      def sub_group_shuffle_short_vf # vf : OclBuiltin<"intel_sub_group_shuffle", (outs gentype:$ret), (ins gentype:$data, mask_type: $sub_group_local_id, mask_type:$vec_mask)>;
      def sub_group_shuffle_xor_short_vf # vf : OclBuiltin<"intel_sub_group_shuffle_xor", (outs gentype:$ret), (ins gentype:$data, mask_type: $value, mask_type:$vec_mask)>;
      def sub_group_shuffle_up_short_vf # vf : OclBuiltin<"intel_sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$previous, gentype:$current, mask_type: $value, mask_type:$vec_mask)>;
      def sub_group_shuffle_down_short_vf # vf : OclBuiltin<"intel_sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$current, gentype:$next, mask_type: $value, mask_type:$vec_mask)>;
      
      def khr_sub_group_shuffle_up_short_vf # vf : OclBuiltin<"sub_group_shuffle_up", (outs gentype:$ret), (ins gentype:$data, mask_type: $delta, mask_type:$vec_mask)>;
      def khr_sub_group_shuffle_down_short_vf # vf : OclBuiltin<"sub_group_shuffle_down", (outs gentype:$ret), (ins gentype:$data, mask_type: $delta, mask_type:$vec_mask)>;
    }
  }
}
// Implementations
// scalar
foreach bi = [sub_group_shuffle_vf1, sub_group_shuffle_xor_vf1,
              sub_group_shuffle_up_vf1, khr_sub_group_shuffle_up_vf1,
              sub_group_shuffle_down_vf1, khr_sub_group_shuffle_down_vf1] in {
  def : OclBuiltinImpl<bi, sub_group_types, false, [{
    return $Arg0VarName;
  }]>, SHARED;
}

// vectorized
defvar intel_sub_group_shuffle_f16_code = [{
    short$VecLength temp = __builtin_astype($Arg0VarName, short$VecLength);
    temp = $func(temp, $Arg1VarName, $Arg2VarName);
    $Arg0VarName = __builtin_astype(temp, $Arg0Type);
    return $Arg0VarName;
}];

defvar intel_sub_group_shuffle_up_down_f16_code = [{
    short$VecLength temp1 = __builtin_astype($Arg0VarName, short$VecLength);
    short$VecLength temp2 = __builtin_astype($Arg1VarName, short$VecLength);
    temp1 = $func(temp1, temp2, $Arg2VarName, $Arg3VarName);
    $Arg0VarName = __builtin_astype(temp1, $Arg0Type);
    return $Arg0VarName;
}];

foreach vf = [4, 8, 16, 32, 64] in {
  defvar builtin = !cast<OclBuiltin>("sub_group_shuffle_vf" # vf);
  def : OclBuiltinImpl<builtin, builtin.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_f16_code, [["$func", "intel_sub_group_shuffle"]]>, SHARED;

  defvar builtin_xor = !cast<OclBuiltin>("sub_group_shuffle_xor_vf" # vf);
  def : OclBuiltinImpl<builtin_xor, builtin_xor.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_f16_code, [["$func", "intel_sub_group_shuffle_xor"]]>, SHARED;

  defvar builtin_up = !cast<OclBuiltin>("sub_group_shuffle_up_vf" # vf);
  def : OclBuiltinImpl<builtin_up, builtin_up.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_up_down_f16_code, [["$func", "intel_sub_group_shuffle_up"]]>, SHARED;

  defvar builtin_down = !cast<OclBuiltin>("sub_group_shuffle_down_vf" # vf);
  def : OclBuiltinImpl<builtin_down, builtin_down.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_up_down_f16_code, [["$func", "intel_sub_group_shuffle_down"]]>, SHARED;

  defvar builtin_khr_up = !cast<OclBuiltin>("khr_sub_group_shuffle_up_vf" # vf);
  def : OclBuiltinImpl<builtin_khr_up, builtin_khr_up.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_f16_code, [["$func", "sub_group_shuffle_up"]]>, SHARED;

  defvar builtin_khr_down = !cast<OclBuiltin>("khr_sub_group_shuffle_down_vf" # vf);
  def : OclBuiltinImpl<builtin_khr_down, builtin_khr_down.Types, /*isDeclOnly*/false, intel_sub_group_shuffle_f16_code, [["$func", "sub_group_shuffle_down"]]>, SHARED;
}

// VectInfos
foreach suffix = ["", "_xor", "_up", "_down"] in {
  let Types = [v1f16] in {
    def : VectInfo<[], !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf1"), !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf4"), 
                      !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf8"), !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf16"), 
                      !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf32"), !cast<OclBuiltin>("sub_group_shuffle"#suffix#"_vf64")>;
  }
}
foreach suffix = ["_up", "_down"] in {
  let Types = [v1f16] in {
    def : VectInfo<[], !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf1"), !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf4"), 
                      !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf8"), !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf16"), 
                      !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf32"), !cast<OclBuiltin>("khr_sub_group_shuffle"#suffix#"_vf64")>;
  }
}

// AliasMap
foreach vf = [1, 4, 8, 16, 32, 64] in {
  defvar types = WidenType<v1f16, vf>.Tout;
  def : AliasMap<[["sub_group_shuffle_vf" #vf, "sub_group_shuffle"], 
                  ["sub_group_shuffle_xor_vf" #vf, "sub_group_shuffle_xor"]], [types]>;
}

// --- sub_group_reduce/scan_inclusive/scan_exclusive builtins ---
//
// https://registry.khronos.org/OpenCL/extensions/intel/cl_intel_subgroups.html
//

// Prototypes
let Attrs = [OVERLOADABLE], VectorAttrs = [KERNEL_CALL_ONCE], NeedForwardDecl = true in {
  // scalar
  let Types = sub_group_types in {
    foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
      foreach op = ["add", "min", "max", "mul"] in {
        def sub_group_#func#_#op#_vf1 : OclBuiltin<"sub_group_"#func#"_"#op, (outs gentype:$ret), (ins gentype:$src)>;
      }
    }
  }
  // vectorized
  foreach vf = [4, 8, 16, 32, 64] in {
    foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
      foreach op = ["add", "min", "max", "mul"] in {
        let Types = ExpandTypesByVFAndFlatten<sub_group_types, [vf]>.Tout in {
          def sub_group_#func#_#op#_vf#vf : OclBuiltin<"sub_group_"#func#"_"#op, (outs gentype:$ret), (ins gentype:$src, u32gentype:$vec_mask)>;
        }
        // Because half type add/mul builtins are implemented via float type builtins.
        // So just declare float builtins here, when all builtin are migrated here,
        // these declarations can be deleted.
        let Types = ExpandTypesByVFAndFlatten<[v1f32], [vf]>.Tout in {
          def : OclBuiltin<"sub_group_"#func#"_"#op, (outs gentype:$ret), (ins gentype:$src, u32gentype:$vec_mask)>;
        }
      }
    }
  }
}

// Implementations
defvar convert2float_code =
  [{
    float$VecLength temp = convert_float$VecLength($Arg0VarName);
    float$VecLength result = $func(temp, $Arg1VarName);
    return convert_half$VecLength(result);
  }];
defvar scan_exclusive_add_code =
  [{
    half$VecLength helper;
    helper[0] = 0;
    if (vec_mask[0] == 0)
      src[0] = 0;
    for (int i = 1; i < $VecLength; ++i) {
      if (vec_mask[i] != 0)
        src[i] += src[i-1];
      else
        src[i] = src[i-1];
      helper[i] = src[i-1];
    }
    return helper;
  }];
defvar scan_inclusive_add_code =
  [{
    if (vec_mask[0] == 0)
      src[0] = 0;
    for (int i = 1; i < $VecLength; ++i) {
      if (vec_mask[i] != 0)
        src[i] += src[i-1];
      else
        src[i] = src[i-1];
    }
    return src;
  }];

// scalar
foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
  foreach op = ["add", "min", "max", "mul"] in {
    defvar builtin = !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf1");
    def : OclBuiltinImpl<builtin, builtin.Types, /*IsDeclOnly*/false, ret_arg0_code>, SHARED;
  }
}

// vectorized
foreach vf = [4, 8, 16, 32, 64] in {
  foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
    foreach op = ["min", "max", "mul"] in {
      defvar builtin_add = !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf"#vf);
      def : OclBuiltinImpl<builtin_add, builtin_add.Types, /*IsDeclOnly*/false, convert2float_code, [["$func", "sub_group_"#func#"_"#op]]>, SHARED;
    }
  }
  // vectorized reduce/scan add
  defvar builtin_add = !cast<OclBuiltin>("sub_group_reduce_add_vf"#vf);
  // implement half type reduce add with llvm ir in ll_subgroup_impl.td
  def : OclBuiltinImpl<builtin_add, builtin_add.Types, /*IsDeclOnly*/true, [{}]>, SHARED;
  defvar builtin_inclu_add = !cast<OclBuiltin>("sub_group_scan_inclusive_add_vf"#vf);
  def : OclBuiltinImpl<builtin_inclu_add, builtin_inclu_add.Types, /*IsDeclOnly*/false, scan_inclusive_add_code>, SHARED;
  defvar builtin_exclu_add = !cast<OclBuiltin>("sub_group_scan_exclusive_add_vf"#vf);
  def : OclBuiltinImpl<builtin_exclu_add, builtin_exclu_add.Types, /*IsDeclOnly*/false, scan_exclusive_add_code>, SHARED;
}

// VectInfos
let Types = sub_group_types in {
  foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
    foreach op = ["add", "min", "max", "mul"] in {
      def : VectInfo<[], !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf1"), !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf4"),
                         !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf8"), !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf16"),
                         !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf32"), !cast<OclBuiltin>("sub_group_"#func#"_"#op#"_vf64")>;
    }
  }
}

// AliasMap
// Now uniform type builtin implemented as non-uniform
foreach func = ["reduce", "scan_inclusive", "scan_exclusive"] in {
  foreach op = ["add", "min", "max", "mul"] in {
    foreach vf = [1, 4, 8, 16, 32, 64] in {
      defvar types = WidenType<v1f16, vf>.Tout;
      def : AliasMap<[["sub_group_"#func#"_"#op#"_vf"#vf, "sub_group_non_uniform_"#func#"_"#op]], [types]>;
    }
  }
}
