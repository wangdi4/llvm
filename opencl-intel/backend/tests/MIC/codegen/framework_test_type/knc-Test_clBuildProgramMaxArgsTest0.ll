; RUN: llc < %s -mtriple=x86_64-pc-linux -march=y86-64 -mcpu=knc
; XFAIL: win32
; ModuleID = 'Program'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64"
target triple = "x86_64-unknown-linux-gnu"

%struct.PaddedDimId = type <{ [4 x i64] }>
%struct.WorkDim = type { i32, [3 x i64], [3 x i64], [3 x i64], [3 x i64] }

declare void @__sample_test_original(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 addrspace(1)* nocapture) nounwind

declare void @dummybarrier.()

declare void @barrier(i64)

declare i8* @get_special_buffer.()

declare i64 @get_iter_count.()

define void @__sample_test_separated_args(i64 %long0, i64 %long1, i64 %long2, i64 %long3, i64 %long4, i64 %long5, i64 %long6, i64 %long7, i64 %long8, i64 %long9, i64 %long10, i64 %long11, i64 %long12, i64 %long13, i64 %long14, i64 %long15, i64 %long16, i64 %long17, i64 %long18, i64 %long19, i64 %long20, i64 %long21, i64 %long22, i64 %long23, i64 %long24, i64 %long25, i64 %long26, i64 %long27, i64 %long28, i64 %long29, i64 %long30, i64 %long31, i64 %long32, i64 %long33, i64 %long34, i64 %long35, i64 %long36, i64 %long37, i64 %long38, i64 %long39, i64 %long40, i64 %long41, i64 %long42, i64 %long43, i64 %long44, i64 %long45, i64 %long46, i64 %long47, i64 %long48, i64 %long49, i64 %long50, i64 %long51, i64 %long52, i64 %long53, i64 %long54, i64 %long55, i64 %long56, i64 %long57, i64 %long58, i64 %long59, i64 %long60, i64 %long61, i64 %long62, i64 %long63, i64 %long64, i64 %long65, i64 %long66, i64 %long67, i64 %long68, i64 %long69, i64 %long70, i64 %long71, i64 %long72, i64 %long73, i64 %long74, i64 %long75, i64 %long76, i64 %long77, i64 %long78, i64 %long79, i64 %long80, i64 %long81, i64 %long82, i64 %long83, i64 %long84, i64 %long85, i64 %long86, i64 %long87, i64 %long88, i64 %long89, i64 %long90, i64 %long91, i64 %long92, i64 %long93, i64 %long94, i64 %long95, i64 %long96, i64 %long97, i64 %long98, i64 %long99, i64 %long100, i64 %long101, i64 %long102, i64 %long103, i64 %long104, i64 %long105, i64 %long106, i64 %long107, i64 %long108, i64 %long109, i64 %long110, i64 %long111, i64 %long112, i64 %long113, i64 %long114, i64 %long115, i64 %long116, i64 %long117, i64 %long118, i64 %long119, i64 %long120, i64 %long121, i64 %long122, i64 %long123, i64 %long124, i64 %long125, i64 %long126, i64 addrspace(1)* nocapture %result, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind alwaysinline {
entry:
  %add9 = add nsw i64 %long1, %long0
  %add14 = add nsw i64 %add9, %long2
  %add19 = add nsw i64 %add14, %long3
  %add24 = add nsw i64 %add19, %long4
  %add29 = add nsw i64 %add24, %long5
  %add34 = add nsw i64 %add29, %long6
  %add39 = add nsw i64 %add34, %long7
  %add44 = add nsw i64 %add39, %long8
  %add49 = add nsw i64 %add44, %long9
  %add54 = add nsw i64 %add49, %long10
  %add59 = add nsw i64 %add54, %long11
  %add64 = add nsw i64 %add59, %long12
  %add69 = add nsw i64 %add64, %long13
  %add74 = add nsw i64 %add69, %long14
  %add79 = add nsw i64 %add74, %long15
  %add84 = add nsw i64 %add79, %long16
  %add89 = add nsw i64 %add84, %long17
  %add94 = add nsw i64 %add89, %long18
  %add99 = add nsw i64 %add94, %long19
  %add104 = add nsw i64 %add99, %long20
  %add109 = add nsw i64 %add104, %long21
  %add114 = add nsw i64 %add109, %long22
  %add119 = add nsw i64 %add114, %long23
  %add124 = add nsw i64 %add119, %long24
  %add129 = add nsw i64 %add124, %long25
  %add134 = add nsw i64 %add129, %long26
  %add139 = add nsw i64 %add134, %long27
  %add144 = add nsw i64 %add139, %long28
  %add149 = add nsw i64 %add144, %long29
  %add154 = add nsw i64 %add149, %long30
  %add159 = add nsw i64 %add154, %long31
  %add164 = add nsw i64 %add159, %long32
  %add169 = add nsw i64 %add164, %long33
  %add174 = add nsw i64 %add169, %long34
  %add179 = add nsw i64 %add174, %long35
  %add184 = add nsw i64 %add179, %long36
  %add189 = add nsw i64 %add184, %long37
  %add194 = add nsw i64 %add189, %long38
  %add199 = add nsw i64 %add194, %long39
  %add204 = add nsw i64 %add199, %long40
  %add209 = add nsw i64 %add204, %long41
  %add214 = add nsw i64 %add209, %long42
  %add219 = add nsw i64 %add214, %long43
  %add224 = add nsw i64 %add219, %long44
  %add229 = add nsw i64 %add224, %long45
  %add234 = add nsw i64 %add229, %long46
  %add239 = add nsw i64 %add234, %long47
  %add244 = add nsw i64 %add239, %long48
  %add249 = add nsw i64 %add244, %long49
  %add254 = add nsw i64 %add249, %long50
  %add259 = add nsw i64 %add254, %long51
  %add264 = add nsw i64 %add259, %long52
  %add269 = add nsw i64 %add264, %long53
  %add274 = add nsw i64 %add269, %long54
  %add279 = add nsw i64 %add274, %long55
  %add284 = add nsw i64 %add279, %long56
  %add289 = add nsw i64 %add284, %long57
  %add294 = add nsw i64 %add289, %long58
  %add299 = add nsw i64 %add294, %long59
  %add304 = add nsw i64 %add299, %long60
  %add309 = add nsw i64 %add304, %long61
  %add314 = add nsw i64 %add309, %long62
  %add319 = add nsw i64 %add314, %long63
  %add324 = add nsw i64 %add319, %long64
  %add329 = add nsw i64 %add324, %long65
  %add334 = add nsw i64 %add329, %long66
  %add339 = add nsw i64 %add334, %long67
  %add344 = add nsw i64 %add339, %long68
  %add349 = add nsw i64 %add344, %long69
  %add354 = add nsw i64 %add349, %long70
  %add359 = add nsw i64 %add354, %long71
  %add364 = add nsw i64 %add359, %long72
  %add369 = add nsw i64 %add364, %long73
  %add374 = add nsw i64 %add369, %long74
  %add379 = add nsw i64 %add374, %long75
  %add384 = add nsw i64 %add379, %long76
  %add389 = add nsw i64 %add384, %long77
  %add394 = add nsw i64 %add389, %long78
  %add399 = add nsw i64 %add394, %long79
  %add404 = add nsw i64 %add399, %long80
  %add409 = add nsw i64 %add404, %long81
  %add414 = add nsw i64 %add409, %long82
  %add419 = add nsw i64 %add414, %long83
  %add424 = add nsw i64 %add419, %long84
  %add429 = add nsw i64 %add424, %long85
  %add434 = add nsw i64 %add429, %long86
  %add439 = add nsw i64 %add434, %long87
  %add444 = add nsw i64 %add439, %long88
  %add449 = add nsw i64 %add444, %long89
  %add454 = add nsw i64 %add449, %long90
  %add459 = add nsw i64 %add454, %long91
  %add464 = add nsw i64 %add459, %long92
  %add469 = add nsw i64 %add464, %long93
  %add474 = add nsw i64 %add469, %long94
  %add479 = add nsw i64 %add474, %long95
  %add484 = add nsw i64 %add479, %long96
  %add489 = add nsw i64 %add484, %long97
  %add494 = add nsw i64 %add489, %long98
  %add499 = add nsw i64 %add494, %long99
  %add504 = add nsw i64 %add499, %long100
  %add509 = add nsw i64 %add504, %long101
  %add514 = add nsw i64 %add509, %long102
  %add519 = add nsw i64 %add514, %long103
  %add524 = add nsw i64 %add519, %long104
  %add529 = add nsw i64 %add524, %long105
  %add534 = add nsw i64 %add529, %long106
  %add539 = add nsw i64 %add534, %long107
  %add544 = add nsw i64 %add539, %long108
  %add549 = add nsw i64 %add544, %long109
  %add554 = add nsw i64 %add549, %long110
  %add559 = add nsw i64 %add554, %long111
  %add564 = add nsw i64 %add559, %long112
  %add569 = add nsw i64 %add564, %long113
  %add574 = add nsw i64 %add569, %long114
  %add579 = add nsw i64 %add574, %long115
  %add584 = add nsw i64 %add579, %long116
  %add589 = add nsw i64 %add584, %long117
  %add594 = add nsw i64 %add589, %long118
  %add599 = add nsw i64 %add594, %long119
  %add604 = add nsw i64 %add599, %long120
  %add609 = add nsw i64 %add604, %long121
  %add614 = add nsw i64 %add609, %long122
  %add619 = add nsw i64 %add614, %long123
  %add624 = add nsw i64 %add619, %long124
  %add629 = add nsw i64 %add624, %long125
  %add634 = add nsw i64 %add629, %long126
  br label %"Barrier BB"

"Barrier BB":                                     ; preds = %entry, %thenBB
  %CurrWI..0 = phi i64 [ 0, %entry ], [ %"CurrWI++", %thenBB ]
  %check.WI.iter = icmp ult i64 %CurrWI..0, %iterCount
  br i1 %check.WI.iter, label %thenBB, label %elseBB

thenBB:                                           ; preds = %"Barrier BB"
  %"CurrWI++" = add nuw i64 %CurrWI..0, 1
  br label %"Barrier BB"

elseBB:                                           ; preds = %"Barrier BB"
  store i64 %add634, i64 addrspace(1)* %result, align 8
  ret void
}

define void @sample_test(i8* %pBuffer) {
entry:
  %0 = bitcast i8* %pBuffer to i64*
  %1 = load i64* %0, align 8
  %2 = getelementptr i8* %pBuffer, i64 8
  %3 = bitcast i8* %2 to i64*
  %4 = load i64* %3, align 8
  %5 = getelementptr i8* %pBuffer, i64 16
  %6 = bitcast i8* %5 to i64*
  %7 = load i64* %6, align 8
  %8 = getelementptr i8* %pBuffer, i64 24
  %9 = bitcast i8* %8 to i64*
  %10 = load i64* %9, align 8
  %11 = getelementptr i8* %pBuffer, i64 32
  %12 = bitcast i8* %11 to i64*
  %13 = load i64* %12, align 8
  %14 = getelementptr i8* %pBuffer, i64 40
  %15 = bitcast i8* %14 to i64*
  %16 = load i64* %15, align 8
  %17 = getelementptr i8* %pBuffer, i64 48
  %18 = bitcast i8* %17 to i64*
  %19 = load i64* %18, align 8
  %20 = getelementptr i8* %pBuffer, i64 56
  %21 = bitcast i8* %20 to i64*
  %22 = load i64* %21, align 8
  %23 = getelementptr i8* %pBuffer, i64 64
  %24 = bitcast i8* %23 to i64*
  %25 = load i64* %24, align 8
  %26 = getelementptr i8* %pBuffer, i64 72
  %27 = bitcast i8* %26 to i64*
  %28 = load i64* %27, align 8
  %29 = getelementptr i8* %pBuffer, i64 80
  %30 = bitcast i8* %29 to i64*
  %31 = load i64* %30, align 8
  %32 = getelementptr i8* %pBuffer, i64 88
  %33 = bitcast i8* %32 to i64*
  %34 = load i64* %33, align 8
  %35 = getelementptr i8* %pBuffer, i64 96
  %36 = bitcast i8* %35 to i64*
  %37 = load i64* %36, align 8
  %38 = getelementptr i8* %pBuffer, i64 104
  %39 = bitcast i8* %38 to i64*
  %40 = load i64* %39, align 8
  %41 = getelementptr i8* %pBuffer, i64 112
  %42 = bitcast i8* %41 to i64*
  %43 = load i64* %42, align 8
  %44 = getelementptr i8* %pBuffer, i64 120
  %45 = bitcast i8* %44 to i64*
  %46 = load i64* %45, align 8
  %47 = getelementptr i8* %pBuffer, i64 128
  %48 = bitcast i8* %47 to i64*
  %49 = load i64* %48, align 8
  %50 = getelementptr i8* %pBuffer, i64 136
  %51 = bitcast i8* %50 to i64*
  %52 = load i64* %51, align 8
  %53 = getelementptr i8* %pBuffer, i64 144
  %54 = bitcast i8* %53 to i64*
  %55 = load i64* %54, align 8
  %56 = getelementptr i8* %pBuffer, i64 152
  %57 = bitcast i8* %56 to i64*
  %58 = load i64* %57, align 8
  %59 = getelementptr i8* %pBuffer, i64 160
  %60 = bitcast i8* %59 to i64*
  %61 = load i64* %60, align 8
  %62 = getelementptr i8* %pBuffer, i64 168
  %63 = bitcast i8* %62 to i64*
  %64 = load i64* %63, align 8
  %65 = getelementptr i8* %pBuffer, i64 176
  %66 = bitcast i8* %65 to i64*
  %67 = load i64* %66, align 8
  %68 = getelementptr i8* %pBuffer, i64 184
  %69 = bitcast i8* %68 to i64*
  %70 = load i64* %69, align 8
  %71 = getelementptr i8* %pBuffer, i64 192
  %72 = bitcast i8* %71 to i64*
  %73 = load i64* %72, align 8
  %74 = getelementptr i8* %pBuffer, i64 200
  %75 = bitcast i8* %74 to i64*
  %76 = load i64* %75, align 8
  %77 = getelementptr i8* %pBuffer, i64 208
  %78 = bitcast i8* %77 to i64*
  %79 = load i64* %78, align 8
  %80 = getelementptr i8* %pBuffer, i64 216
  %81 = bitcast i8* %80 to i64*
  %82 = load i64* %81, align 8
  %83 = getelementptr i8* %pBuffer, i64 224
  %84 = bitcast i8* %83 to i64*
  %85 = load i64* %84, align 8
  %86 = getelementptr i8* %pBuffer, i64 232
  %87 = bitcast i8* %86 to i64*
  %88 = load i64* %87, align 8
  %89 = getelementptr i8* %pBuffer, i64 240
  %90 = bitcast i8* %89 to i64*
  %91 = load i64* %90, align 8
  %92 = getelementptr i8* %pBuffer, i64 248
  %93 = bitcast i8* %92 to i64*
  %94 = load i64* %93, align 8
  %95 = getelementptr i8* %pBuffer, i64 256
  %96 = bitcast i8* %95 to i64*
  %97 = load i64* %96, align 8
  %98 = getelementptr i8* %pBuffer, i64 264
  %99 = bitcast i8* %98 to i64*
  %100 = load i64* %99, align 8
  %101 = getelementptr i8* %pBuffer, i64 272
  %102 = bitcast i8* %101 to i64*
  %103 = load i64* %102, align 8
  %104 = getelementptr i8* %pBuffer, i64 280
  %105 = bitcast i8* %104 to i64*
  %106 = load i64* %105, align 8
  %107 = getelementptr i8* %pBuffer, i64 288
  %108 = bitcast i8* %107 to i64*
  %109 = load i64* %108, align 8
  %110 = getelementptr i8* %pBuffer, i64 296
  %111 = bitcast i8* %110 to i64*
  %112 = load i64* %111, align 8
  %113 = getelementptr i8* %pBuffer, i64 304
  %114 = bitcast i8* %113 to i64*
  %115 = load i64* %114, align 8
  %116 = getelementptr i8* %pBuffer, i64 312
  %117 = bitcast i8* %116 to i64*
  %118 = load i64* %117, align 8
  %119 = getelementptr i8* %pBuffer, i64 320
  %120 = bitcast i8* %119 to i64*
  %121 = load i64* %120, align 8
  %122 = getelementptr i8* %pBuffer, i64 328
  %123 = bitcast i8* %122 to i64*
  %124 = load i64* %123, align 8
  %125 = getelementptr i8* %pBuffer, i64 336
  %126 = bitcast i8* %125 to i64*
  %127 = load i64* %126, align 8
  %128 = getelementptr i8* %pBuffer, i64 344
  %129 = bitcast i8* %128 to i64*
  %130 = load i64* %129, align 8
  %131 = getelementptr i8* %pBuffer, i64 352
  %132 = bitcast i8* %131 to i64*
  %133 = load i64* %132, align 8
  %134 = getelementptr i8* %pBuffer, i64 360
  %135 = bitcast i8* %134 to i64*
  %136 = load i64* %135, align 8
  %137 = getelementptr i8* %pBuffer, i64 368
  %138 = bitcast i8* %137 to i64*
  %139 = load i64* %138, align 8
  %140 = getelementptr i8* %pBuffer, i64 376
  %141 = bitcast i8* %140 to i64*
  %142 = load i64* %141, align 8
  %143 = getelementptr i8* %pBuffer, i64 384
  %144 = bitcast i8* %143 to i64*
  %145 = load i64* %144, align 8
  %146 = getelementptr i8* %pBuffer, i64 392
  %147 = bitcast i8* %146 to i64*
  %148 = load i64* %147, align 8
  %149 = getelementptr i8* %pBuffer, i64 400
  %150 = bitcast i8* %149 to i64*
  %151 = load i64* %150, align 8
  %152 = getelementptr i8* %pBuffer, i64 408
  %153 = bitcast i8* %152 to i64*
  %154 = load i64* %153, align 8
  %155 = getelementptr i8* %pBuffer, i64 416
  %156 = bitcast i8* %155 to i64*
  %157 = load i64* %156, align 8
  %158 = getelementptr i8* %pBuffer, i64 424
  %159 = bitcast i8* %158 to i64*
  %160 = load i64* %159, align 8
  %161 = getelementptr i8* %pBuffer, i64 432
  %162 = bitcast i8* %161 to i64*
  %163 = load i64* %162, align 8
  %164 = getelementptr i8* %pBuffer, i64 440
  %165 = bitcast i8* %164 to i64*
  %166 = load i64* %165, align 8
  %167 = getelementptr i8* %pBuffer, i64 448
  %168 = bitcast i8* %167 to i64*
  %169 = load i64* %168, align 8
  %170 = getelementptr i8* %pBuffer, i64 456
  %171 = bitcast i8* %170 to i64*
  %172 = load i64* %171, align 8
  %173 = getelementptr i8* %pBuffer, i64 464
  %174 = bitcast i8* %173 to i64*
  %175 = load i64* %174, align 8
  %176 = getelementptr i8* %pBuffer, i64 472
  %177 = bitcast i8* %176 to i64*
  %178 = load i64* %177, align 8
  %179 = getelementptr i8* %pBuffer, i64 480
  %180 = bitcast i8* %179 to i64*
  %181 = load i64* %180, align 8
  %182 = getelementptr i8* %pBuffer, i64 488
  %183 = bitcast i8* %182 to i64*
  %184 = load i64* %183, align 8
  %185 = getelementptr i8* %pBuffer, i64 496
  %186 = bitcast i8* %185 to i64*
  %187 = load i64* %186, align 8
  %188 = getelementptr i8* %pBuffer, i64 504
  %189 = bitcast i8* %188 to i64*
  %190 = load i64* %189, align 8
  %191 = getelementptr i8* %pBuffer, i64 512
  %192 = bitcast i8* %191 to i64*
  %193 = load i64* %192, align 8
  %194 = getelementptr i8* %pBuffer, i64 520
  %195 = bitcast i8* %194 to i64*
  %196 = load i64* %195, align 8
  %197 = getelementptr i8* %pBuffer, i64 528
  %198 = bitcast i8* %197 to i64*
  %199 = load i64* %198, align 8
  %200 = getelementptr i8* %pBuffer, i64 536
  %201 = bitcast i8* %200 to i64*
  %202 = load i64* %201, align 8
  %203 = getelementptr i8* %pBuffer, i64 544
  %204 = bitcast i8* %203 to i64*
  %205 = load i64* %204, align 8
  %206 = getelementptr i8* %pBuffer, i64 552
  %207 = bitcast i8* %206 to i64*
  %208 = load i64* %207, align 8
  %209 = getelementptr i8* %pBuffer, i64 560
  %210 = bitcast i8* %209 to i64*
  %211 = load i64* %210, align 8
  %212 = getelementptr i8* %pBuffer, i64 568
  %213 = bitcast i8* %212 to i64*
  %214 = load i64* %213, align 8
  %215 = getelementptr i8* %pBuffer, i64 576
  %216 = bitcast i8* %215 to i64*
  %217 = load i64* %216, align 8
  %218 = getelementptr i8* %pBuffer, i64 584
  %219 = bitcast i8* %218 to i64*
  %220 = load i64* %219, align 8
  %221 = getelementptr i8* %pBuffer, i64 592
  %222 = bitcast i8* %221 to i64*
  %223 = load i64* %222, align 8
  %224 = getelementptr i8* %pBuffer, i64 600
  %225 = bitcast i8* %224 to i64*
  %226 = load i64* %225, align 8
  %227 = getelementptr i8* %pBuffer, i64 608
  %228 = bitcast i8* %227 to i64*
  %229 = load i64* %228, align 8
  %230 = getelementptr i8* %pBuffer, i64 616
  %231 = bitcast i8* %230 to i64*
  %232 = load i64* %231, align 8
  %233 = getelementptr i8* %pBuffer, i64 624
  %234 = bitcast i8* %233 to i64*
  %235 = load i64* %234, align 8
  %236 = getelementptr i8* %pBuffer, i64 632
  %237 = bitcast i8* %236 to i64*
  %238 = load i64* %237, align 8
  %239 = getelementptr i8* %pBuffer, i64 640
  %240 = bitcast i8* %239 to i64*
  %241 = load i64* %240, align 8
  %242 = getelementptr i8* %pBuffer, i64 648
  %243 = bitcast i8* %242 to i64*
  %244 = load i64* %243, align 8
  %245 = getelementptr i8* %pBuffer, i64 656
  %246 = bitcast i8* %245 to i64*
  %247 = load i64* %246, align 8
  %248 = getelementptr i8* %pBuffer, i64 664
  %249 = bitcast i8* %248 to i64*
  %250 = load i64* %249, align 8
  %251 = getelementptr i8* %pBuffer, i64 672
  %252 = bitcast i8* %251 to i64*
  %253 = load i64* %252, align 8
  %254 = getelementptr i8* %pBuffer, i64 680
  %255 = bitcast i8* %254 to i64*
  %256 = load i64* %255, align 8
  %257 = getelementptr i8* %pBuffer, i64 688
  %258 = bitcast i8* %257 to i64*
  %259 = load i64* %258, align 8
  %260 = getelementptr i8* %pBuffer, i64 696
  %261 = bitcast i8* %260 to i64*
  %262 = load i64* %261, align 8
  %263 = getelementptr i8* %pBuffer, i64 704
  %264 = bitcast i8* %263 to i64*
  %265 = load i64* %264, align 8
  %266 = getelementptr i8* %pBuffer, i64 712
  %267 = bitcast i8* %266 to i64*
  %268 = load i64* %267, align 8
  %269 = getelementptr i8* %pBuffer, i64 720
  %270 = bitcast i8* %269 to i64*
  %271 = load i64* %270, align 8
  %272 = getelementptr i8* %pBuffer, i64 728
  %273 = bitcast i8* %272 to i64*
  %274 = load i64* %273, align 8
  %275 = getelementptr i8* %pBuffer, i64 736
  %276 = bitcast i8* %275 to i64*
  %277 = load i64* %276, align 8
  %278 = getelementptr i8* %pBuffer, i64 744
  %279 = bitcast i8* %278 to i64*
  %280 = load i64* %279, align 8
  %281 = getelementptr i8* %pBuffer, i64 752
  %282 = bitcast i8* %281 to i64*
  %283 = load i64* %282, align 8
  %284 = getelementptr i8* %pBuffer, i64 760
  %285 = bitcast i8* %284 to i64*
  %286 = load i64* %285, align 8
  %287 = getelementptr i8* %pBuffer, i64 768
  %288 = bitcast i8* %287 to i64*
  %289 = load i64* %288, align 8
  %290 = getelementptr i8* %pBuffer, i64 776
  %291 = bitcast i8* %290 to i64*
  %292 = load i64* %291, align 8
  %293 = getelementptr i8* %pBuffer, i64 784
  %294 = bitcast i8* %293 to i64*
  %295 = load i64* %294, align 8
  %296 = getelementptr i8* %pBuffer, i64 792
  %297 = bitcast i8* %296 to i64*
  %298 = load i64* %297, align 8
  %299 = getelementptr i8* %pBuffer, i64 800
  %300 = bitcast i8* %299 to i64*
  %301 = load i64* %300, align 8
  %302 = getelementptr i8* %pBuffer, i64 808
  %303 = bitcast i8* %302 to i64*
  %304 = load i64* %303, align 8
  %305 = getelementptr i8* %pBuffer, i64 816
  %306 = bitcast i8* %305 to i64*
  %307 = load i64* %306, align 8
  %308 = getelementptr i8* %pBuffer, i64 824
  %309 = bitcast i8* %308 to i64*
  %310 = load i64* %309, align 8
  %311 = getelementptr i8* %pBuffer, i64 832
  %312 = bitcast i8* %311 to i64*
  %313 = load i64* %312, align 8
  %314 = getelementptr i8* %pBuffer, i64 840
  %315 = bitcast i8* %314 to i64*
  %316 = load i64* %315, align 8
  %317 = getelementptr i8* %pBuffer, i64 848
  %318 = bitcast i8* %317 to i64*
  %319 = load i64* %318, align 8
  %320 = getelementptr i8* %pBuffer, i64 856
  %321 = bitcast i8* %320 to i64*
  %322 = load i64* %321, align 8
  %323 = getelementptr i8* %pBuffer, i64 864
  %324 = bitcast i8* %323 to i64*
  %325 = load i64* %324, align 8
  %326 = getelementptr i8* %pBuffer, i64 872
  %327 = bitcast i8* %326 to i64*
  %328 = load i64* %327, align 8
  %329 = getelementptr i8* %pBuffer, i64 880
  %330 = bitcast i8* %329 to i64*
  %331 = load i64* %330, align 8
  %332 = getelementptr i8* %pBuffer, i64 888
  %333 = bitcast i8* %332 to i64*
  %334 = load i64* %333, align 8
  %335 = getelementptr i8* %pBuffer, i64 896
  %336 = bitcast i8* %335 to i64*
  %337 = load i64* %336, align 8
  %338 = getelementptr i8* %pBuffer, i64 904
  %339 = bitcast i8* %338 to i64*
  %340 = load i64* %339, align 8
  %341 = getelementptr i8* %pBuffer, i64 912
  %342 = bitcast i8* %341 to i64*
  %343 = load i64* %342, align 8
  %344 = getelementptr i8* %pBuffer, i64 920
  %345 = bitcast i8* %344 to i64*
  %346 = load i64* %345, align 8
  %347 = getelementptr i8* %pBuffer, i64 928
  %348 = bitcast i8* %347 to i64*
  %349 = load i64* %348, align 8
  %350 = getelementptr i8* %pBuffer, i64 936
  %351 = bitcast i8* %350 to i64*
  %352 = load i64* %351, align 8
  %353 = getelementptr i8* %pBuffer, i64 944
  %354 = bitcast i8* %353 to i64*
  %355 = load i64* %354, align 8
  %356 = getelementptr i8* %pBuffer, i64 952
  %357 = bitcast i8* %356 to i64*
  %358 = load i64* %357, align 8
  %359 = getelementptr i8* %pBuffer, i64 960
  %360 = bitcast i8* %359 to i64*
  %361 = load i64* %360, align 8
  %362 = getelementptr i8* %pBuffer, i64 968
  %363 = bitcast i8* %362 to i64*
  %364 = load i64* %363, align 8
  %365 = getelementptr i8* %pBuffer, i64 976
  %366 = bitcast i8* %365 to i64*
  %367 = load i64* %366, align 8
  %368 = getelementptr i8* %pBuffer, i64 984
  %369 = bitcast i8* %368 to i64*
  %370 = load i64* %369, align 8
  %371 = getelementptr i8* %pBuffer, i64 992
  %372 = bitcast i8* %371 to i64*
  %373 = load i64* %372, align 8
  %374 = getelementptr i8* %pBuffer, i64 1000
  %375 = bitcast i8* %374 to i64*
  %376 = load i64* %375, align 8
  %377 = getelementptr i8* %pBuffer, i64 1008
  %378 = bitcast i8* %377 to i64*
  %379 = load i64* %378, align 8
  %380 = getelementptr i8* %pBuffer, i64 1016
  %381 = bitcast i8* %380 to i64 addrspace(1)**
  %382 = load i64 addrspace(1)** %381, align 8
  %383 = getelementptr i8* %pBuffer, i64 1072
  %384 = bitcast i8* %383 to i64*
  %385 = load i64* %384, align 8
  %add9.i = add nsw i64 %4, %1
  %add14.i = add nsw i64 %add9.i, %7
  %add19.i = add nsw i64 %add14.i, %10
  %add24.i = add nsw i64 %add19.i, %13
  %add29.i = add nsw i64 %add24.i, %16
  %add34.i = add nsw i64 %add29.i, %19
  %add39.i = add nsw i64 %add34.i, %22
  %add44.i = add nsw i64 %add39.i, %25
  %add49.i = add nsw i64 %add44.i, %28
  %add54.i = add nsw i64 %add49.i, %31
  %add59.i = add nsw i64 %add54.i, %34
  %add64.i = add nsw i64 %add59.i, %37
  %add69.i = add nsw i64 %add64.i, %40
  %add74.i = add nsw i64 %add69.i, %43
  %add79.i = add nsw i64 %add74.i, %46
  %add84.i = add nsw i64 %add79.i, %49
  %add89.i = add nsw i64 %add84.i, %52
  %add94.i = add nsw i64 %add89.i, %55
  %add99.i = add nsw i64 %add94.i, %58
  %add104.i = add nsw i64 %add99.i, %61
  %add109.i = add nsw i64 %add104.i, %64
  %add114.i = add nsw i64 %add109.i, %67
  %add119.i = add nsw i64 %add114.i, %70
  %add124.i = add nsw i64 %add119.i, %73
  %add129.i = add nsw i64 %add124.i, %76
  %add134.i = add nsw i64 %add129.i, %79
  %add139.i = add nsw i64 %add134.i, %82
  %add144.i = add nsw i64 %add139.i, %85
  %add149.i = add nsw i64 %add144.i, %88
  %add154.i = add nsw i64 %add149.i, %91
  %add159.i = add nsw i64 %add154.i, %94
  %add164.i = add nsw i64 %add159.i, %97
  %add169.i = add nsw i64 %add164.i, %100
  %add174.i = add nsw i64 %add169.i, %103
  %add179.i = add nsw i64 %add174.i, %106
  %add184.i = add nsw i64 %add179.i, %109
  %add189.i = add nsw i64 %add184.i, %112
  %add194.i = add nsw i64 %add189.i, %115
  %add199.i = add nsw i64 %add194.i, %118
  %add204.i = add nsw i64 %add199.i, %121
  %add209.i = add nsw i64 %add204.i, %124
  %add214.i = add nsw i64 %add209.i, %127
  %add219.i = add nsw i64 %add214.i, %130
  %add224.i = add nsw i64 %add219.i, %133
  %add229.i = add nsw i64 %add224.i, %136
  %add234.i = add nsw i64 %add229.i, %139
  %add239.i = add nsw i64 %add234.i, %142
  %add244.i = add nsw i64 %add239.i, %145
  %add249.i = add nsw i64 %add244.i, %148
  %add254.i = add nsw i64 %add249.i, %151
  %add259.i = add nsw i64 %add254.i, %154
  %add264.i = add nsw i64 %add259.i, %157
  %add269.i = add nsw i64 %add264.i, %160
  %add274.i = add nsw i64 %add269.i, %163
  %add279.i = add nsw i64 %add274.i, %166
  %add284.i = add nsw i64 %add279.i, %169
  %add289.i = add nsw i64 %add284.i, %172
  %add294.i = add nsw i64 %add289.i, %175
  %add299.i = add nsw i64 %add294.i, %178
  %add304.i = add nsw i64 %add299.i, %181
  %add309.i = add nsw i64 %add304.i, %184
  %add314.i = add nsw i64 %add309.i, %187
  %add319.i = add nsw i64 %add314.i, %190
  %add324.i = add nsw i64 %add319.i, %193
  %add329.i = add nsw i64 %add324.i, %196
  %add334.i = add nsw i64 %add329.i, %199
  %add339.i = add nsw i64 %add334.i, %202
  %add344.i = add nsw i64 %add339.i, %205
  %add349.i = add nsw i64 %add344.i, %208
  %add354.i = add nsw i64 %add349.i, %211
  %add359.i = add nsw i64 %add354.i, %214
  %add364.i = add nsw i64 %add359.i, %217
  %add369.i = add nsw i64 %add364.i, %220
  %add374.i = add nsw i64 %add369.i, %223
  %add379.i = add nsw i64 %add374.i, %226
  %add384.i = add nsw i64 %add379.i, %229
  %add389.i = add nsw i64 %add384.i, %232
  %add394.i = add nsw i64 %add389.i, %235
  %add399.i = add nsw i64 %add394.i, %238
  %add404.i = add nsw i64 %add399.i, %241
  %add409.i = add nsw i64 %add404.i, %244
  %add414.i = add nsw i64 %add409.i, %247
  %add419.i = add nsw i64 %add414.i, %250
  %add424.i = add nsw i64 %add419.i, %253
  %add429.i = add nsw i64 %add424.i, %256
  %add434.i = add nsw i64 %add429.i, %259
  %add439.i = add nsw i64 %add434.i, %262
  %add444.i = add nsw i64 %add439.i, %265
  %add449.i = add nsw i64 %add444.i, %268
  %add454.i = add nsw i64 %add449.i, %271
  %add459.i = add nsw i64 %add454.i, %274
  %add464.i = add nsw i64 %add459.i, %277
  %add469.i = add nsw i64 %add464.i, %280
  %add474.i = add nsw i64 %add469.i, %283
  %add479.i = add nsw i64 %add474.i, %286
  %add484.i = add nsw i64 %add479.i, %289
  %add489.i = add nsw i64 %add484.i, %292
  %add494.i = add nsw i64 %add489.i, %295
  %add499.i = add nsw i64 %add494.i, %298
  %add504.i = add nsw i64 %add499.i, %301
  %add509.i = add nsw i64 %add504.i, %304
  %add514.i = add nsw i64 %add509.i, %307
  %add519.i = add nsw i64 %add514.i, %310
  %add524.i = add nsw i64 %add519.i, %313
  %add529.i = add nsw i64 %add524.i, %316
  %add534.i = add nsw i64 %add529.i, %319
  %add539.i = add nsw i64 %add534.i, %322
  %add544.i = add nsw i64 %add539.i, %325
  %add549.i = add nsw i64 %add544.i, %328
  %add554.i = add nsw i64 %add549.i, %331
  %add559.i = add nsw i64 %add554.i, %334
  %add564.i = add nsw i64 %add559.i, %337
  %add569.i = add nsw i64 %add564.i, %340
  %add574.i = add nsw i64 %add569.i, %343
  %add579.i = add nsw i64 %add574.i, %346
  %add584.i = add nsw i64 %add579.i, %349
  %add589.i = add nsw i64 %add584.i, %352
  %add594.i = add nsw i64 %add589.i, %355
  %add599.i = add nsw i64 %add594.i, %358
  %add604.i = add nsw i64 %add599.i, %361
  %add609.i = add nsw i64 %add604.i, %364
  %add614.i = add nsw i64 %add609.i, %367
  %add619.i = add nsw i64 %add614.i, %370
  %add624.i = add nsw i64 %add619.i, %373
  %add629.i = add nsw i64 %add624.i, %376
  %add634.i = add nsw i64 %add629.i, %379
  br label %"Barrier BB.i"

"Barrier BB.i":                                   ; preds = %thenBB.i, %entry
  %CurrWI..0.i = phi i64 [ 0, %entry ], [ %"CurrWI++.i", %thenBB.i ]
  %check.WI.iter.i = icmp ult i64 %CurrWI..0.i, %385
  br i1 %check.WI.iter.i, label %thenBB.i, label %__sample_test_separated_args.exit

thenBB.i:                                         ; preds = %"Barrier BB.i"
  %"CurrWI++.i" = add nuw i64 %CurrWI..0.i, 1
  br label %"Barrier BB.i"

__sample_test_separated_args.exit:                ; preds = %"Barrier BB.i"
  store i64 %add634.i, i64 addrspace(1)* %382, align 8
  ret void
}

!opencl.kernels = !{!0}
!opencl.build.options = !{}

!0 = metadata !{void (i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 addrspace(1)*, i8 addrspace(3)*, %struct.WorkDim*, i64*, %struct.PaddedDimId*, %struct.PaddedDimId*, i64*, i64, i8*, i64*)* @__sample_test_separated_args, metadata !1, metadata !1, metadata !"", metadata !"long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long, long __attribute__((address_space(1))) *", metadata !"opencl_sample_test_locals_anchor", metadata !2, metadata !3, metadata !4, metadata !5, metadata !"", void (i8*)* @sample_test}
!1 = metadata !{i32 0, i32 0, i32 0}
!2 = metadata !{i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1}
!3 = metadata !{i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3, i32 3}
!4 = metadata !{metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long", metadata !"long*"}
!5 = metadata !{metadata !"long0", metadata !"long1", metadata !"long2", metadata !"long3", metadata !"long4", metadata !"long5", metadata !"long6", metadata !"long7", metadata !"long8", metadata !"long9", metadata !"long10", metadata !"long11", metadata !"long12", metadata !"long13", metadata !"long14", metadata !"long15", metadata !"long16", metadata !"long17", metadata !"long18", metadata !"long19", metadata !"long20", metadata !"long21", metadata !"long22", metadata !"long23", metadata !"long24", metadata !"long25", metadata !"long26", metadata !"long27", metadata !"long28", metadata !"long29", metadata !"long30", metadata !"long31", metadata !"long32", metadata !"long33", metadata !"long34", metadata !"long35", metadata !"long36", metadata !"long37", metadata !"long38", metadata !"long39", metadata !"long40", metadata !"long41", metadata !"long42", metadata !"long43", metadata !"long44", metadata !"long45", metadata !"long46", metadata !"long47", metadata !"long48", metadata !"long49", metadata !"long50", metadata !"long51", metadata !"long52", metadata !"long53", metadata !"long54", metadata !"long55", metadata !"long56", metadata !"long57", metadata !"long58", metadata !"long59", metadata !"long60", metadata !"long61", metadata !"long62", metadata !"long63", metadata !"long64", metadata !"long65", metadata !"long66", metadata !"long67", metadata !"long68", metadata !"long69", metadata !"long70", metadata !"long71", metadata !"long72", metadata !"long73", metadata !"long74", metadata !"long75", metadata !"long76", metadata !"long77", metadata !"long78", metadata !"long79", metadata !"long80", metadata !"long81", metadata !"long82", metadata !"long83", metadata !"long84", metadata !"long85", metadata !"long86", metadata !"long87", metadata !"long88", metadata !"long89", metadata !"long90", metadata !"long91", metadata !"long92", metadata !"long93", metadata !"long94", metadata !"long95", metadata !"long96", metadata !"long97", metadata !"long98", metadata !"long99", metadata !"long100", metadata !"long101", metadata !"long102", metadata !"long103", metadata !"long104", metadata !"long105", metadata !"long106", metadata !"long107", metadata !"long108", metadata !"long109", metadata !"long110", metadata !"long111", metadata !"long112", metadata !"long113", metadata !"long114", metadata !"long115", metadata !"long116", metadata !"long117", metadata !"long118", metadata !"long119", metadata !"long120", metadata !"long121", metadata !"long122", metadata !"long123", metadata !"long124", metadata !"long125", metadata !"long126", metadata !"result"}
