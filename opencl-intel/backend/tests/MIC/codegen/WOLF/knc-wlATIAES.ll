; XFAIL: win32
; RUN: llc < %s -mtriple=x86_64-pc-linux -march=y86-64 -mcpu=knc
; ModuleID = 'Program'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64"
target triple = "x86_64-pc-win32"

%struct.PaddedDimId = type <{ [4 x i64] }>
%struct.WorkDim = type { i32, [3 x i64], [3 x i64], [3 x i64], [3 x i64] }

declare i32 @__shiftRows_original(i32, i32) nounwind readnone

declare void @__AESEncrypt_original(<4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, i8 addrspace(1)* nocapture, <4 x i8> addrspace(3)* nocapture, <4 x i8> addrspace(3)* nocapture, i32, i32) nounwind

declare i64 @get_group_id(i32)

declare i64 @get_local_id(i32)

declare void @barrier(i64)

declare i32 @__shiftRowsInv_original(i32, i32) nounwind readnone

declare void @__AESDecrypt_original(<4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, i8 addrspace(1)* nocapture, <4 x i8> addrspace(3)* nocapture, <4 x i8> addrspace(3)* nocapture, i32, i32) nounwind

declare void @____Vectorized_.AESEncrypt_original(<4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, i8 addrspace(1)* nocapture, <4 x i8> addrspace(3)* nocapture, <4 x i8> addrspace(3)* nocapture, i32, i32) nounwind

declare void @____Vectorized_.AESDecrypt_original(<4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, <4 x i8> addrspace(1)* nocapture, i8 addrspace(1)* nocapture, <4 x i8> addrspace(3)* nocapture, <4 x i8> addrspace(3)* nocapture, i32, i32) nounwind

define i1 @allOne(i1 %pred) {
entry:
  ret i1 %pred
}

define i1 @allZero(i1 %t) {
entry:
  %pred = xor i1 %t, true
  ret i1 %pred
}

declare void @dummybarrier.()

declare i8* @get_special_buffer.()

declare i64 @get_iter_count.()

declare i64 @get_new_local_id.(i32, i64)

define i32 @shiftRows(i32 %row.coerce, i32 %j, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind readnone {
; <label>:0
  %tmp1 = bitcast i32 %row.coerce to <4 x i8>
  %1 = icmp eq i32 %j, 0
  br i1 %1, label %._crit_edge, label %bb.nph

bb.nph:                                           ; preds = %0, %bb.nph
  %i.03 = phi i32 [ %3, %bb.nph ], [ 0, %0 ]
  %r.02 = phi <4 x i8> [ %2, %bb.nph ], [ %tmp1, %0 ]
  %2 = shufflevector <4 x i8> %r.02, <4 x i8> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  %3 = add i32 %i.03, 1
  %exitcond = icmp eq i32 %3, %j
  br i1 %exitcond, label %._crit_edge, label %bb.nph

._crit_edge:                                      ; preds = %bb.nph, %0
  %r.0.lcssa = phi <4 x i8> [ %tmp1, %0 ], [ %2, %bb.nph ]
  %4 = bitcast <4 x i8> %r.0.lcssa to i32
  ret i32 %4
}

define void @__AESEncrypt_separated_args(<4 x i8> addrspace(1)* nocapture %output, <4 x i8> addrspace(1)* nocapture %input, <4 x i8> addrspace(1)* nocapture %roundKey, i8 addrspace(1)* nocapture %SBox, <4 x i8> addrspace(3)* nocapture %block0, <4 x i8> addrspace(3)* nocapture %block1, i32 %width, i32 %rounds, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind alwaysinline {
FirstBB:
  %tmp81 = icmp ugt i32 %rounds, 1
  %rounds.op = add i32 %rounds, -1
  %tmp82 = select i1 %tmp81, i32 %rounds.op, i32 0
  %0 = shl i32 %rounds, 2
  br label %SyncBB343

SyncBB343:                                        ; preds = %thenBB, %thenBB354, %FirstBB
  %CurrSBIndex..0 = phi i64 [ 0, %FirstBB ], [ %"loadedCurrSB+Stride360", %thenBB354 ], [ %"loadedCurrSB+Stride", %thenBB ]
  %currBarrier.2 = phi i32 [ 12, %FirstBB ], [ %currBarrier.1, %thenBB354 ], [ %currBarrier.1, %thenBB ]
  %CurrWI..0 = phi i64 [ 0, %FirstBB ], [ %"CurrWI++358", %thenBB354 ], [ %"CurrWI++", %thenBB ]
  %1 = load i64* %pWGId, align 8
  %2 = trunc i64 %1 to i32
  %3 = getelementptr i64* %pWGId, i64 1
  %4 = load i64* %3, align 8
  %5 = trunc i64 %4 to i32
  %6 = getelementptr %struct.PaddedDimId* %pLocalIds, i64 %CurrWI..0, i32 0, i64 1
  %7 = load i64* %6, align 8
  %8 = trunc i64 %7 to i32
  %"&pSB[currWI].offset" = getelementptr inbounds i8* %pSpecialBuf, i64 %CurrSBIndex..0
  %CastToValueType = bitcast i8* %"&pSB[currWI].offset" to i32*
  store i32 %8, i32* %CastToValueType, align 4
  %9 = mul i32 %5, %width
  %10 = shl i32 %2, 2
  %11 = add i32 %9, %10
  %12 = and i32 %11, -4
  %13 = add i32 %12, %8
  %"&(pSB[currWI].offset)338" = add nuw i64 %CurrSBIndex..0, 112
  %"&pSB[currWI].offset339" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)338"
  %14 = bitcast i8* %"&pSB[currWI].offset339" to <4 x i8>*
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %14, align 16
  %"&pSB[currWI].offset335.sum" = add i64 %CurrSBIndex..0, 116
  %15 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset335.sum"
  %16 = bitcast i8* %15 to <4 x i8>*
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %16, align 4
  %"&pSB[currWI].offset331.sum" = add i64 %CurrSBIndex..0, 120
  %17 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset331.sum"
  %18 = bitcast i8* %17 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %18, align 8
  %"&pSB[currWI].offset327.sum" = add i64 %CurrSBIndex..0, 124
  %19 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset327.sum"
  %20 = bitcast i8* %19 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %20, align 4
  %21 = zext i32 %13 to i64
  %"&(pSB[currWI].offset)105" = add nuw i64 %CurrSBIndex..0, 8
  %"&pSB[currWI].offset106" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)105"
  %CastToValueType107 = bitcast i8* %"&pSB[currWI].offset106" to i64*
  store i64 %21, i64* %CastToValueType107, align 8
  %22 = getelementptr inbounds <4 x i8> addrspace(1)* %input, i64 %21
  %23 = load <4 x i8> addrspace(1)* %22, align 4
  %24 = and i64 %7, 4294967295
  %25 = getelementptr inbounds <4 x i8> addrspace(3)* %block0, i64 %24
  %"&(pSB[currWI].offset)114" = add nuw i64 %CurrSBIndex..0, 16
  %"&pSB[currWI].offset115" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)114"
  %CastToValueType116 = bitcast i8* %"&pSB[currWI].offset115" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %25, <4 x i8> addrspace(3)** %CastToValueType116, align 8
  store <4 x i8> %23, <4 x i8> addrspace(3)* %25, align 4
  %26 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %24
  %27 = load <4 x i8> addrspace(1)* %26, align 4
  %28 = xor <4 x i8> %23, %27
  %"&(pSB[currWI].offset)128" = add nuw i64 %CurrSBIndex..0, 24
  %"&pSB[currWI].offset129" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)128"
  %CastToValueType130 = bitcast i8* %"&pSB[currWI].offset129" to <4 x i8>*
  store <4 x i8> %28, <4 x i8>* %CastToValueType130, align 4
  store <4 x i8> %28, <4 x i8> addrspace(3)* %25, align 4
  %29 = sub i32 0, %8
  %30 = and i32 %29, 3
  %31 = zext i32 %30 to i64
  %"&(pSB[currWI].offset)322" = add nuw i64 %CurrSBIndex..0, 112
  %"&pSB[currWI].offset323" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)322"
  %CastToValueType324 = bitcast i8* %"&pSB[currWI].offset323" to [4 x <4 x i8>]*
  %32 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType324, i64 0, i64 %31
  %"&(pSB[currWI].offset)132" = add nuw i64 %CurrSBIndex..0, 32
  %"&pSB[currWI].offset133" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)132"
  %CastToValueType134 = bitcast i8* %"&pSB[currWI].offset133" to <4 x i8>**
  store <4 x i8>* %32, <4 x i8>** %CastToValueType134, align 8
  %33 = getelementptr inbounds <4 x i8> addrspace(3)* %block1, i64 %24
  %"&(pSB[currWI].offset)156" = add nuw i64 %CurrSBIndex..0, 40
  %"&pSB[currWI].offset157" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)156"
  %CastToValueType158 = bitcast i8* %"&pSB[currWI].offset157" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %33, <4 x i8> addrspace(3)** %CastToValueType158, align 8
  %tmp75 = sub i64 1, %7
  %"&(pSB[currWI].offset)170" = add nuw i64 %CurrSBIndex..0, 48
  %"&pSB[currWI].offset171" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)170"
  %CastToValueType172 = bitcast i8* %"&pSB[currWI].offset171" to i64*
  store i64 %tmp75, i64* %CastToValueType172, align 8
  %tmp86 = add i32 %8, 4
  %"&(pSB[currWI].offset)179" = add nuw i64 %CurrSBIndex..0, 56
  %"&pSB[currWI].offset180" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)179"
  %CastToValueType181 = bitcast i8* %"&pSB[currWI].offset180" to i32*
  store i32 %tmp86, i32* %CastToValueType181, align 4
  br label %34

; <label>:34                                      ; preds = %SyncBB344, %SyncBB343
  %CurrSBIndex..2 = phi i64 [ %CurrSBIndex..0, %SyncBB343 ], [ %CurrSBIndex..1, %SyncBB344 ]
  %currBarrier.1 = phi i32 [ %currBarrier.2, %SyncBB343 ], [ %currBarrier.0, %SyncBB344 ]
  %CurrWI..2 = phi i64 [ %CurrWI..0, %SyncBB343 ], [ %CurrWI..1, %SyncBB344 ]
  %35 = phi <4 x i8> [ %28, %SyncBB343 ], [ %636, %SyncBB344 ]
  %indvar79 = phi i32 [ 0, %SyncBB343 ], [ %indvar.next80, %SyncBB344 ]
  %"&(pSB[currWI].offset)188" = add nuw i64 %CurrSBIndex..2, 60
  %"&pSB[currWI].offset189" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)188"
  %CastToValueType190 = bitcast i8* %"&pSB[currWI].offset189" to i32*
  store i32 %indvar79, i32* %CastToValueType190, align 4
  %tmp84 = shl i32 %indvar79, 2
  %"&(pSB[currWI].offset)183" = add nuw i64 %CurrSBIndex..2, 56
  %"&pSB[currWI].offset184" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)183"
  %CastToValueType185 = bitcast i8* %"&pSB[currWI].offset184" to i32*
  %loadedValue186 = load i32* %CastToValueType185, align 4
  %tmp87 = add i32 %loadedValue186, %tmp84
  %"&(pSB[currWI].offset)202" = add nuw i64 %CurrSBIndex..2, 64
  %"&pSB[currWI].offset203" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)202"
  %CastToValueType204 = bitcast i8* %"&pSB[currWI].offset203" to i32*
  store i32 %tmp87, i32* %CastToValueType204, align 4
  %36 = bitcast <4 x i8> %35 to i32
  %tmp1.i = bitcast i32 %36 to <4 x i8>
  %37 = extractelement <4 x i8> %tmp1.i, i32 0
  %38 = zext i8 %37 to i64
  %39 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %38
  %40 = load i8 addrspace(1)* %39, align 1
  %41 = insertelement <4 x i8> undef, i8 %40, i32 0
  %42 = extractelement <4 x i8> %tmp1.i, i32 1
  %43 = zext i8 %42 to i64
  %44 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %43
  %45 = load i8 addrspace(1)* %44, align 1
  %46 = insertelement <4 x i8> %41, i8 %45, i32 1
  %47 = extractelement <4 x i8> %tmp1.i, i32 2
  %48 = zext i8 %47 to i64
  %49 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %48
  %50 = load i8 addrspace(1)* %49, align 1
  %51 = insertelement <4 x i8> %46, i8 %50, i32 2
  %52 = extractelement <4 x i8> %tmp1.i, i32 3
  %53 = zext i8 %52 to i64
  %54 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %53
  %55 = load i8 addrspace(1)* %54, align 1
  %56 = insertelement <4 x i8> %51, i8 %55, i32 3
  %57 = bitcast <4 x i8> %56 to i32
  %tmp7 = bitcast i32 %57 to <4 x i8>
  %58 = bitcast <4 x i8> %tmp7 to i32
  %tmp1.i88 = bitcast i32 %58 to <4 x i8>
  %"&(pSB[currWI].offset)211" = add nuw i64 %CurrSBIndex..2, 68
  %"&pSB[currWI].offset212" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)211"
  %CastToValueType213 = bitcast i8* %"&pSB[currWI].offset212" to <4 x i8>*
  store <4 x i8> %tmp1.i88, <4 x i8>* %CastToValueType213, align 4
  %"&pSB[currWI].offset96" = getelementptr inbounds i8* %pSpecialBuf, i64 %CurrSBIndex..2
  %CastToValueType97 = bitcast i8* %"&pSB[currWI].offset96" to i32*
  %loadedValue98 = load i32* %CastToValueType97, align 4
  %59 = icmp eq i32 %loadedValue98, 0
  br i1 %59, label %shiftRows.exit, label %bb.nph.i.preheader

bb.nph.i.preheader:                               ; preds = %34
  %"&(pSB[currWI].offset)215" = add nuw i64 %CurrSBIndex..2, 68
  %"&pSB[currWI].offset216" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)215"
  %CastToValueType217 = bitcast i8* %"&pSB[currWI].offset216" to <4 x i8>*
  %loadedValue218 = load <4 x i8>* %CastToValueType217, align 4
  %"&(pSB[currWI].offset)220" = add nuw i64 %CurrSBIndex..2, 72
  %"&pSB[currWI].offset221" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)220"
  %CastToValueType222 = bitcast i8* %"&pSB[currWI].offset221" to <4 x i8>*
  %"&(pSB[currWI].offset)229" = add nuw i64 %CurrSBIndex..2, 76
  %"&pSB[currWI].offset230" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)229"
  %CastToValueType231 = bitcast i8* %"&pSB[currWI].offset230" to i32*
  %"&pSB[currWI].offset92" = getelementptr inbounds i8* %pSpecialBuf, i64 %CurrSBIndex..2
  %CastToValueType93 = bitcast i8* %"&pSB[currWI].offset92" to i32*
  br label %bb.nph.i

bb.nph.i:                                         ; preds = %bb.nph.i, %bb.nph.i.preheader
  %i.03.i = phi i32 [ %61, %bb.nph.i ], [ 0, %bb.nph.i.preheader ]
  %r.02.i = phi <4 x i8> [ %60, %bb.nph.i ], [ %loadedValue218, %bb.nph.i.preheader ]
  %60 = shufflevector <4 x i8> %r.02.i, <4 x i8> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  store <4 x i8> %60, <4 x i8>* %CastToValueType222, align 4
  %61 = add i32 %i.03.i, 1
  store i32 %61, i32* %CastToValueType231, align 4
  %loadedValue = load i32* %CastToValueType93, align 4
  %exitcond.i = icmp eq i32 %61, %loadedValue
  br i1 %exitcond.i, label %shiftRows.exit.loopexit, label %bb.nph.i

shiftRows.exit.loopexit:                          ; preds = %bb.nph.i
  %"&(pSB[currWI].offset)224" = add nuw i64 %CurrSBIndex..2, 72
  %"&pSB[currWI].offset225" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)224"
  %CastToValueType226 = bitcast i8* %"&pSB[currWI].offset225" to <4 x i8>*
  %loadedValue227 = load <4 x i8>* %CastToValueType226, align 4
  br label %shiftRows.exit

shiftRows.exit:                                   ; preds = %shiftRows.exit.loopexit, %34
  %r.0.lcssa.i = phi <4 x i8> [ %tmp1.i88, %34 ], [ %loadedValue227, %shiftRows.exit.loopexit ]
  %62 = bitcast <4 x i8> %r.0.lcssa.i to i32
  %tmp5 = bitcast i32 %62 to <4 x i8>
  %"&(pSB[currWI].offset)233" = add nuw i64 %CurrSBIndex..2, 80
  %"&pSB[currWI].offset234" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)233"
  %CastToValueType235 = bitcast i8* %"&pSB[currWI].offset234" to <4 x i8>*
  store <4 x i8> %tmp5, <4 x i8>* %CastToValueType235, align 4
  %"&(pSB[currWI].offset)123" = add nuw i64 %CurrSBIndex..2, 16
  %"&pSB[currWI].offset124" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)123"
  %CastToValueType125 = bitcast i8* %"&pSB[currWI].offset124" to <4 x i8> addrspace(3)**
  %loadedValue126 = load <4 x i8> addrspace(3)** %CastToValueType125, align 8
  store <4 x i8> %tmp5, <4 x i8> addrspace(3)* %loadedValue126, align 4
  %"&(pSB[currWI].offset)192" = add nuw i64 %CurrSBIndex..2, 60
  %"&pSB[currWI].offset193" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)192"
  %CastToValueType194 = bitcast i8* %"&pSB[currWI].offset193" to i32*
  %loadedValue195 = load i32* %CastToValueType194, align 4
  %exitcond83 = icmp eq i32 %loadedValue195, %tmp82
  br i1 %exitcond83, label %"Barrier BB89", label %bb.nph65

bb.nph65:                                         ; preds = %shiftRows.exit
  %check.WI.iter = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter, label %thenBB, label %SyncBB

thenBB:                                           ; preds = %bb.nph65
  %"CurrWI++" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride" = add nuw i64 %CurrSBIndex..2, 1712
  %cond = icmp eq i32 %currBarrier.1, 12
  br i1 %cond, label %SyncBB343, label %SyncBB344

SyncBB:                                           ; preds = %bb.nph65, %thenBB347
  %CurrSBIndex..3 = phi i64 [ %"loadedCurrSB+Stride353", %thenBB347 ], [ 0, %bb.nph65 ]
  %CurrWI..3 = phi i64 [ %"CurrWI++351", %thenBB347 ], [ 0, %bb.nph65 ]
  %"&(pSB[currWI].offset)151" = add nuw i64 %CurrSBIndex..3, 32
  %"&pSB[currWI].offset152" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)151"
  %CastToValueType153 = bitcast i8* %"&pSB[currWI].offset152" to <4 x i8>**
  %loadedValue154 = load <4 x i8>** %CastToValueType153, align 8
  %63 = load <4 x i8>* %loadedValue154, align 4
  %64 = load <4 x i8> addrspace(3)* %block0, align 4
  %65 = extractelement <4 x i8> %63, i32 0
  %66 = extractelement <4 x i8> %64, i32 0
  %67 = zext i8 %66 to i32
  %68 = shl i32 %67, 1
  %69 = and i32 %67, 128
  %70 = xor i32 %68, 27
  %71 = icmp eq i32 %69, 0
  %a.1.in = select i1 %71, i32 %68, i32 %70
  %72 = shl i32 %a.1.in, 1
  %73 = and i32 %a.1.in, 128
  %74 = xor i32 %72, 27
  %75 = icmp eq i32 %73, 0
  %a.1.in.1 = select i1 %75, i32 %72, i32 %74
  %76 = shl i32 %a.1.in.1, 1
  %77 = and i32 %a.1.in.1, 128
  %78 = xor i32 %76, 27
  %79 = icmp eq i32 %77, 0
  %a.1.in.2 = select i1 %79, i32 %76, i32 %78
  %80 = shl i32 %a.1.in.2, 1
  %81 = and i32 %a.1.in.2, 128
  %82 = xor i32 %80, 27
  %83 = icmp eq i32 %81, 0
  %a.1.in.3 = select i1 %83, i32 %80, i32 %82
  %84 = shl i32 %a.1.in.3, 1
  %85 = and i32 %a.1.in.3, 128
  %86 = xor i32 %84, 27
  %87 = icmp eq i32 %85, 0
  %a.1.in.4 = select i1 %87, i32 %84, i32 %86
  %88 = shl i32 %a.1.in.4, 1
  %89 = and i32 %a.1.in.4, 128
  %90 = xor i32 %88, 27
  %91 = icmp eq i32 %89, 0
  %a.1.in.5 = select i1 %91, i32 %88, i32 %90
  %92 = shl i32 %a.1.in.5, 1
  %93 = lshr i8 %65, 1
  %94 = zext i8 %93 to i32
  %95 = zext i8 %65 to i32
  %96 = lshr i8 %65, 2
  %97 = lshr i8 %65, 3
  %98 = and i32 %94, 1
  %99 = and i32 %95, 1
  %100 = zext i8 %96 to i32
  %101 = zext i8 %97 to i32
  %102 = icmp eq i32 %98, 0
  %a.1 = trunc i32 %a.1.in to i8
  %103 = icmp eq i32 %99, 0
  %104 = and i32 %100, 1
  %105 = lshr i8 %65, 4
  %106 = lshr i8 %65, 5
  %107 = and i32 %101, 1
  %108 = select i1 %102, i8 0, i8 %a.1
  %109 = select i1 %103, i8 0, i8 %66
  %a.1.1 = trunc i32 %a.1.in.1 to i8
  %110 = icmp eq i32 %104, 0
  %111 = zext i8 %105 to i32
  %112 = zext i8 %106 to i32
  %113 = icmp eq i32 %107, 0
  %a.1.2 = trunc i32 %a.1.in.2 to i8
  %p.1..1 = xor i8 %108, %109
  %114 = select i1 %110, i8 0, i8 %a.1.1
  %115 = and i32 %111, 1
  %116 = lshr i8 %65, 6
  %117 = and i32 %a.1.in.5, 128
  %118 = and i32 %112, 1
  %119 = select i1 %113, i8 0, i8 %a.1.2
  %p.1..2 = xor i8 %114, %p.1..1
  %a.1.3 = trunc i32 %a.1.in.3 to i8
  %120 = icmp eq i32 %115, 0
  %121 = zext i8 %116 to i32
  %122 = icmp eq i32 %117, 0
  %123 = xor i32 %92, 27
  %124 = icmp eq i32 %118, 0
  %a.1.4 = trunc i32 %a.1.in.4 to i8
  %p.1..3 = xor i8 %119, %p.1..2
  %125 = select i1 %120, i8 0, i8 %a.1.3
  %126 = and i32 %121, 1
  %a.1.in.6 = select i1 %122, i32 %92, i32 %123
  %127 = select i1 %124, i8 0, i8 %a.1.4
  %p.1..4 = xor i8 %125, %p.1..3
  %a.1.5 = trunc i32 %a.1.in.5 to i8
  %128 = icmp eq i32 %126, 0
  %129 = icmp sgt i8 %65, -1
  %a.1.6 = trunc i32 %a.1.in.6 to i8
  %p.1..5 = xor i8 %127, %p.1..4
  %130 = select i1 %128, i8 0, i8 %a.1.5
  %131 = select i1 %129, i8 0, i8 %a.1.6
  %p.1..6 = xor i8 %130, %p.1..5
  %p.1..7 = xor i8 %131, %p.1..6
  %"&(pSB[currWI].offset)242" = add nuw i64 %CurrSBIndex..3, 84
  %"&pSB[currWI].offset243" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)242"
  store i8 %p.1..7, i8* %"&pSB[currWI].offset243", align 1
  %"&(pSB[currWI].offset)146" = add nuw i64 %CurrSBIndex..3, 32
  %"&pSB[currWI].offset147" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)146"
  %CastToValueType148 = bitcast i8* %"&pSB[currWI].offset147" to <4 x i8>**
  %loadedValue149 = load <4 x i8>** %CastToValueType148, align 8
  %132 = load <4 x i8>* %loadedValue149, align 4
  %133 = load <4 x i8> addrspace(3)* %block0, align 4
  %134 = extractelement <4 x i8> %132, i32 0
  %135 = extractelement <4 x i8> %133, i32 1
  %136 = zext i8 %135 to i32
  %137 = shl i32 %136, 1
  %138 = and i32 %136, 128
  %139 = xor i32 %137, 27
  %140 = icmp eq i32 %138, 0
  %a.3.in = select i1 %140, i32 %137, i32 %139
  %141 = shl i32 %a.3.in, 1
  %142 = and i32 %a.3.in, 128
  %143 = xor i32 %141, 27
  %144 = icmp eq i32 %142, 0
  %a.3.in.1 = select i1 %144, i32 %141, i32 %143
  %145 = shl i32 %a.3.in.1, 1
  %146 = and i32 %a.3.in.1, 128
  %147 = xor i32 %145, 27
  %148 = icmp eq i32 %146, 0
  %a.3.in.2 = select i1 %148, i32 %145, i32 %147
  %149 = shl i32 %a.3.in.2, 1
  %150 = and i32 %a.3.in.2, 128
  %151 = xor i32 %149, 27
  %152 = icmp eq i32 %150, 0
  %a.3.in.3 = select i1 %152, i32 %149, i32 %151
  %153 = shl i32 %a.3.in.3, 1
  %154 = and i32 %a.3.in.3, 128
  %155 = xor i32 %153, 27
  %156 = icmp eq i32 %154, 0
  %a.3.in.4 = select i1 %156, i32 %153, i32 %155
  %157 = shl i32 %a.3.in.4, 1
  %158 = and i32 %a.3.in.4, 128
  %159 = xor i32 %157, 27
  %160 = icmp eq i32 %158, 0
  %a.3.in.5 = select i1 %160, i32 %157, i32 %159
  %161 = shl i32 %a.3.in.5, 1
  %162 = lshr i8 %134, 1
  %163 = zext i8 %162 to i32
  %164 = zext i8 %134 to i32
  %165 = lshr i8 %134, 2
  %166 = lshr i8 %134, 3
  %167 = and i32 %163, 1
  %168 = and i32 %164, 1
  %169 = zext i8 %165 to i32
  %170 = zext i8 %166 to i32
  %171 = icmp eq i32 %167, 0
  %a.3 = trunc i32 %a.3.in to i8
  %172 = icmp eq i32 %168, 0
  %173 = and i32 %169, 1
  %174 = lshr i8 %134, 4
  %175 = lshr i8 %134, 5
  %176 = and i32 %170, 1
  %177 = select i1 %171, i8 0, i8 %a.3
  %178 = select i1 %172, i8 0, i8 %135
  %a.3.1 = trunc i32 %a.3.in.1 to i8
  %179 = icmp eq i32 %173, 0
  %180 = zext i8 %174 to i32
  %181 = zext i8 %175 to i32
  %182 = icmp eq i32 %176, 0
  %a.3.2 = trunc i32 %a.3.in.2 to i8
  %p.3..1 = xor i8 %177, %178
  %183 = select i1 %179, i8 0, i8 %a.3.1
  %184 = and i32 %180, 1
  %185 = lshr i8 %134, 6
  %186 = and i32 %a.3.in.5, 128
  %187 = and i32 %181, 1
  %188 = select i1 %182, i8 0, i8 %a.3.2
  %p.3..2 = xor i8 %183, %p.3..1
  %a.3.3 = trunc i32 %a.3.in.3 to i8
  %189 = icmp eq i32 %184, 0
  %190 = zext i8 %185 to i32
  %191 = icmp eq i32 %186, 0
  %192 = xor i32 %161, 27
  %193 = icmp eq i32 %187, 0
  %a.3.4 = trunc i32 %a.3.in.4 to i8
  %p.3..3 = xor i8 %188, %p.3..2
  %194 = select i1 %189, i8 0, i8 %a.3.3
  %195 = and i32 %190, 1
  %a.3.in.6 = select i1 %191, i32 %161, i32 %192
  %196 = select i1 %193, i8 0, i8 %a.3.4
  %p.3..4 = xor i8 %194, %p.3..3
  %a.3.5 = trunc i32 %a.3.in.5 to i8
  %197 = icmp eq i32 %195, 0
  %198 = icmp sgt i8 %134, -1
  %a.3.6 = trunc i32 %a.3.in.6 to i8
  %p.3..5 = xor i8 %196, %p.3..4
  %199 = select i1 %197, i8 0, i8 %a.3.5
  %200 = select i1 %198, i8 0, i8 %a.3.6
  %p.3..6 = xor i8 %199, %p.3..5
  %p.3..7 = xor i8 %200, %p.3..6
  %"&(pSB[currWI].offset)246" = add nuw i64 %CurrSBIndex..3, 85
  %"&pSB[currWI].offset247" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)246"
  store i8 %p.3..7, i8* %"&pSB[currWI].offset247", align 1
  %"&(pSB[currWI].offset)141" = add nuw i64 %CurrSBIndex..3, 32
  %"&pSB[currWI].offset142" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)141"
  %CastToValueType143 = bitcast i8* %"&pSB[currWI].offset142" to <4 x i8>**
  %loadedValue144 = load <4 x i8>** %CastToValueType143, align 8
  %201 = load <4 x i8>* %loadedValue144, align 4
  %202 = load <4 x i8> addrspace(3)* %block0, align 4
  %203 = extractelement <4 x i8> %201, i32 0
  %204 = extractelement <4 x i8> %202, i32 2
  %205 = zext i8 %204 to i32
  %206 = shl i32 %205, 1
  %207 = and i32 %205, 128
  %208 = xor i32 %206, 27
  %209 = icmp eq i32 %207, 0
  %a.5.in = select i1 %209, i32 %206, i32 %208
  %210 = shl i32 %a.5.in, 1
  %211 = and i32 %a.5.in, 128
  %212 = xor i32 %210, 27
  %213 = icmp eq i32 %211, 0
  %a.5.in.1 = select i1 %213, i32 %210, i32 %212
  %214 = shl i32 %a.5.in.1, 1
  %215 = and i32 %a.5.in.1, 128
  %216 = xor i32 %214, 27
  %217 = icmp eq i32 %215, 0
  %a.5.in.2 = select i1 %217, i32 %214, i32 %216
  %218 = shl i32 %a.5.in.2, 1
  %219 = and i32 %a.5.in.2, 128
  %220 = xor i32 %218, 27
  %221 = icmp eq i32 %219, 0
  %a.5.in.3 = select i1 %221, i32 %218, i32 %220
  %222 = shl i32 %a.5.in.3, 1
  %223 = and i32 %a.5.in.3, 128
  %224 = xor i32 %222, 27
  %225 = icmp eq i32 %223, 0
  %a.5.in.4 = select i1 %225, i32 %222, i32 %224
  %226 = shl i32 %a.5.in.4, 1
  %227 = and i32 %a.5.in.4, 128
  %228 = xor i32 %226, 27
  %229 = icmp eq i32 %227, 0
  %a.5.in.5 = select i1 %229, i32 %226, i32 %228
  %230 = shl i32 %a.5.in.5, 1
  %231 = lshr i8 %203, 1
  %232 = zext i8 %231 to i32
  %233 = zext i8 %203 to i32
  %234 = lshr i8 %203, 2
  %235 = lshr i8 %203, 3
  %236 = and i32 %232, 1
  %237 = and i32 %233, 1
  %238 = zext i8 %234 to i32
  %239 = zext i8 %235 to i32
  %240 = icmp eq i32 %236, 0
  %a.5 = trunc i32 %a.5.in to i8
  %241 = icmp eq i32 %237, 0
  %242 = and i32 %238, 1
  %243 = lshr i8 %203, 4
  %244 = lshr i8 %203, 5
  %245 = and i32 %239, 1
  %246 = select i1 %240, i8 0, i8 %a.5
  %247 = select i1 %241, i8 0, i8 %204
  %a.5.1 = trunc i32 %a.5.in.1 to i8
  %248 = icmp eq i32 %242, 0
  %249 = zext i8 %243 to i32
  %250 = zext i8 %244 to i32
  %251 = icmp eq i32 %245, 0
  %a.5.2 = trunc i32 %a.5.in.2 to i8
  %p.5..1 = xor i8 %246, %247
  %252 = select i1 %248, i8 0, i8 %a.5.1
  %253 = and i32 %249, 1
  %254 = lshr i8 %203, 6
  %255 = and i32 %a.5.in.5, 128
  %256 = and i32 %250, 1
  %257 = select i1 %251, i8 0, i8 %a.5.2
  %p.5..2 = xor i8 %252, %p.5..1
  %a.5.3 = trunc i32 %a.5.in.3 to i8
  %258 = icmp eq i32 %253, 0
  %259 = zext i8 %254 to i32
  %260 = icmp eq i32 %255, 0
  %261 = xor i32 %230, 27
  %262 = icmp eq i32 %256, 0
  %a.5.4 = trunc i32 %a.5.in.4 to i8
  %p.5..3 = xor i8 %257, %p.5..2
  %263 = select i1 %258, i8 0, i8 %a.5.3
  %264 = and i32 %259, 1
  %a.5.in.6 = select i1 %260, i32 %230, i32 %261
  %265 = select i1 %262, i8 0, i8 %a.5.4
  %p.5..4 = xor i8 %263, %p.5..3
  %a.5.5 = trunc i32 %a.5.in.5 to i8
  %266 = icmp eq i32 %264, 0
  %267 = icmp sgt i8 %203, -1
  %a.5.6 = trunc i32 %a.5.in.6 to i8
  %p.5..5 = xor i8 %265, %p.5..4
  %268 = select i1 %266, i8 0, i8 %a.5.5
  %269 = select i1 %267, i8 0, i8 %a.5.6
  %p.5..6 = xor i8 %268, %p.5..5
  %p.5..7 = xor i8 %269, %p.5..6
  %"&(pSB[currWI].offset)250" = add nuw i64 %CurrSBIndex..3, 86
  %"&pSB[currWI].offset251" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)250"
  store i8 %p.5..7, i8* %"&pSB[currWI].offset251", align 1
  %"&(pSB[currWI].offset)136" = add nuw i64 %CurrSBIndex..3, 32
  %"&pSB[currWI].offset137" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)136"
  %CastToValueType138 = bitcast i8* %"&pSB[currWI].offset137" to <4 x i8>**
  %loadedValue139 = load <4 x i8>** %CastToValueType138, align 8
  %270 = load <4 x i8>* %loadedValue139, align 4
  %271 = load <4 x i8> addrspace(3)* %block0, align 4
  %272 = extractelement <4 x i8> %270, i32 0
  %273 = extractelement <4 x i8> %271, i32 3
  %274 = zext i8 %273 to i32
  %275 = shl i32 %274, 1
  %276 = and i32 %274, 128
  %277 = xor i32 %275, 27
  %278 = icmp eq i32 %276, 0
  %a.7.in = select i1 %278, i32 %275, i32 %277
  %279 = shl i32 %a.7.in, 1
  %280 = and i32 %a.7.in, 128
  %281 = xor i32 %279, 27
  %282 = icmp eq i32 %280, 0
  %a.7.in.1 = select i1 %282, i32 %279, i32 %281
  %283 = shl i32 %a.7.in.1, 1
  %284 = and i32 %a.7.in.1, 128
  %285 = xor i32 %283, 27
  %286 = icmp eq i32 %284, 0
  %a.7.in.2 = select i1 %286, i32 %283, i32 %285
  %287 = shl i32 %a.7.in.2, 1
  %288 = and i32 %a.7.in.2, 128
  %289 = xor i32 %287, 27
  %290 = icmp eq i32 %288, 0
  %a.7.in.3 = select i1 %290, i32 %287, i32 %289
  %291 = shl i32 %a.7.in.3, 1
  %292 = and i32 %a.7.in.3, 128
  %293 = xor i32 %291, 27
  %294 = icmp eq i32 %292, 0
  %a.7.in.4 = select i1 %294, i32 %291, i32 %293
  %295 = shl i32 %a.7.in.4, 1
  %296 = and i32 %a.7.in.4, 128
  %297 = xor i32 %295, 27
  %298 = icmp eq i32 %296, 0
  %a.7.in.5 = select i1 %298, i32 %295, i32 %297
  %299 = shl i32 %a.7.in.5, 1
  %300 = lshr i8 %272, 1
  %301 = zext i8 %300 to i32
  %302 = zext i8 %272 to i32
  %303 = lshr i8 %272, 2
  %304 = lshr i8 %272, 3
  %305 = and i32 %301, 1
  %306 = and i32 %302, 1
  %307 = zext i8 %303 to i32
  %308 = zext i8 %304 to i32
  %309 = icmp eq i32 %305, 0
  %a.7 = trunc i32 %a.7.in to i8
  %310 = icmp eq i32 %306, 0
  %311 = and i32 %307, 1
  %312 = lshr i8 %272, 4
  %313 = lshr i8 %272, 5
  %314 = and i32 %308, 1
  %315 = select i1 %309, i8 0, i8 %a.7
  %316 = select i1 %310, i8 0, i8 %273
  %a.7.1 = trunc i32 %a.7.in.1 to i8
  %317 = icmp eq i32 %311, 0
  %318 = zext i8 %312 to i32
  %319 = zext i8 %313 to i32
  %320 = icmp eq i32 %314, 0
  %a.7.2 = trunc i32 %a.7.in.2 to i8
  %p.7..1 = xor i8 %315, %316
  %321 = select i1 %317, i8 0, i8 %a.7.1
  %322 = and i32 %318, 1
  %323 = lshr i8 %272, 6
  %324 = and i32 %a.7.in.5, 128
  %325 = and i32 %319, 1
  %326 = select i1 %320, i8 0, i8 %a.7.2
  %p.7..2 = xor i8 %321, %p.7..1
  %a.7.3 = trunc i32 %a.7.in.3 to i8
  %327 = icmp eq i32 %322, 0
  %328 = zext i8 %323 to i32
  %329 = icmp eq i32 %324, 0
  %330 = xor i32 %299, 27
  %331 = icmp eq i32 %325, 0
  %a.7.4 = trunc i32 %a.7.in.4 to i8
  %p.7..3 = xor i8 %326, %p.7..2
  %332 = select i1 %327, i8 0, i8 %a.7.3
  %333 = and i32 %328, 1
  %a.7.in.6 = select i1 %329, i32 %299, i32 %330
  %334 = select i1 %331, i8 0, i8 %a.7.4
  %p.7..4 = xor i8 %332, %p.7..3
  %a.7.5 = trunc i32 %a.7.in.5 to i8
  %335 = icmp eq i32 %333, 0
  %336 = icmp sgt i8 %272, -1
  %a.7.6 = trunc i32 %a.7.in.6 to i8
  %p.7..5 = xor i8 %334, %p.7..4
  %337 = select i1 %335, i8 0, i8 %a.7.5
  %338 = select i1 %336, i8 0, i8 %a.7.6
  %p.7..6 = xor i8 %337, %p.7..5
  %p.7..7 = xor i8 %338, %p.7..6
  %"&(pSB[currWI].offset)254" = add nuw i64 %CurrSBIndex..3, 87
  %"&pSB[currWI].offset255" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)254"
  store i8 %p.7..7, i8* %"&pSB[currWI].offset255", align 1
  %"&(pSB[currWI].offset)258" = add nuw i64 %CurrSBIndex..3, 88
  %"&pSB[currWI].offset259" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)258"
  %CastToValueType260 = bitcast i8* %"&pSB[currWI].offset259" to i64*
  %"&(pSB[currWI].offset)174" = add nuw i64 %CurrSBIndex..3, 48
  %"&pSB[currWI].offset175" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)174"
  %CastToValueType176 = bitcast i8* %"&pSB[currWI].offset175" to i64*
  %"&(pSB[currWI].offset)318" = add nuw i64 %CurrSBIndex..3, 112
  %"&pSB[currWI].offset319" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)318"
  %CastToValueType320 = bitcast i8* %"&pSB[currWI].offset319" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)314" = add nuw i64 %CurrSBIndex..3, 112
  %"&pSB[currWI].offset315" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)314"
  %CastToValueType316 = bitcast i8* %"&pSB[currWI].offset315" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)310" = add nuw i64 %CurrSBIndex..3, 112
  %"&pSB[currWI].offset311" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)310"
  %CastToValueType312 = bitcast i8* %"&pSB[currWI].offset311" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)306" = add nuw i64 %CurrSBIndex..3, 112
  %"&pSB[currWI].offset307" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)306"
  %CastToValueType308 = bitcast i8* %"&pSB[currWI].offset307" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)262" = add nuw i64 %CurrSBIndex..3, 96
  %"&pSB[currWI].offset263" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)262"
  %"&(pSB[currWI].offset)271" = add nuw i64 %CurrSBIndex..3, 97
  %"&pSB[currWI].offset272" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)271"
  %"&(pSB[currWI].offset)280" = add nuw i64 %CurrSBIndex..3, 98
  %"&pSB[currWI].offset281" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)280"
  %"&(pSB[currWI].offset)289" = add nuw i64 %CurrSBIndex..3, 99
  %"&pSB[currWI].offset290" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)289"
  br label %339

; <label>:339                                     ; preds = %339, %SyncBB
  %indvar = phi i64 [ 0, %SyncBB ], [ %tmp, %339 ]
  %w.063 = phi i8 [ %p.7..7, %SyncBB ], [ %627, %339 ]
  %z.062 = phi i8 [ %p.5..7, %SyncBB ], [ %626, %339 ]
  %y.061 = phi i8 [ %p.3..7, %SyncBB ], [ %625, %339 ]
  %x.060 = phi i8 [ %p.1..7, %SyncBB ], [ %624, %339 ]
  %tmp = add i64 %indvar, 1
  store i64 %tmp, i64* %CastToValueType260, align 8
  %scevgep = getelementptr <4 x i8> addrspace(3)* %block0, i64 %tmp
  %loadedValue177 = load i64* %CastToValueType176, align 8
  %tmp77 = add i64 %loadedValue177, %indvar
  %340 = and i64 %tmp77, 3
  %341 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType320, i64 0, i64 %340
  %342 = load <4 x i8>* %341, align 4
  %343 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %344 = extractelement <4 x i8> %342, i32 0
  %345 = extractelement <4 x i8> %343, i32 0
  %346 = zext i8 %345 to i32
  %347 = shl i32 %346, 1
  %348 = and i32 %346, 128
  %349 = xor i32 %347, 27
  %350 = icmp eq i32 %348, 0
  %a.9.in = select i1 %350, i32 %347, i32 %349
  %351 = shl i32 %a.9.in, 1
  %352 = and i32 %a.9.in, 128
  %353 = xor i32 %351, 27
  %354 = icmp eq i32 %352, 0
  %a.9.in.1 = select i1 %354, i32 %351, i32 %353
  %355 = shl i32 %a.9.in.1, 1
  %356 = and i32 %a.9.in.1, 128
  %357 = xor i32 %355, 27
  %358 = icmp eq i32 %356, 0
  %a.9.in.2 = select i1 %358, i32 %355, i32 %357
  %359 = shl i32 %a.9.in.2, 1
  %360 = and i32 %a.9.in.2, 128
  %361 = xor i32 %359, 27
  %362 = icmp eq i32 %360, 0
  %a.9.in.3 = select i1 %362, i32 %359, i32 %361
  %363 = shl i32 %a.9.in.3, 1
  %364 = and i32 %a.9.in.3, 128
  %365 = xor i32 %363, 27
  %366 = icmp eq i32 %364, 0
  %a.9.in.4 = select i1 %366, i32 %363, i32 %365
  %367 = shl i32 %a.9.in.4, 1
  %368 = and i32 %a.9.in.4, 128
  %369 = xor i32 %367, 27
  %370 = icmp eq i32 %368, 0
  %a.9.in.5 = select i1 %370, i32 %367, i32 %369
  %371 = shl i32 %a.9.in.5, 1
  %372 = lshr i8 %344, 1
  %373 = zext i8 %372 to i32
  %374 = zext i8 %344 to i32
  %375 = lshr i8 %344, 2
  %376 = lshr i8 %344, 3
  %377 = and i32 %373, 1
  %378 = and i32 %374, 1
  %379 = zext i8 %375 to i32
  %380 = zext i8 %376 to i32
  %381 = icmp eq i32 %377, 0
  %a.9 = trunc i32 %a.9.in to i8
  %382 = icmp eq i32 %378, 0
  %383 = and i32 %379, 1
  %384 = lshr i8 %344, 4
  %385 = lshr i8 %344, 5
  %386 = and i32 %380, 1
  %387 = select i1 %381, i8 0, i8 %a.9
  %388 = select i1 %382, i8 0, i8 %345
  %a.9.1 = trunc i32 %a.9.in.1 to i8
  %389 = icmp eq i32 %383, 0
  %390 = zext i8 %384 to i32
  %391 = zext i8 %385 to i32
  %392 = icmp eq i32 %386, 0
  %a.9.2 = trunc i32 %a.9.in.2 to i8
  %p.9..1 = xor i8 %387, %388
  %393 = select i1 %389, i8 0, i8 %a.9.1
  %394 = and i32 %390, 1
  %395 = lshr i8 %344, 6
  %396 = and i32 %a.9.in.5, 128
  %397 = and i32 %391, 1
  %398 = select i1 %392, i8 0, i8 %a.9.2
  %p.9..2 = xor i8 %393, %p.9..1
  %a.9.3 = trunc i32 %a.9.in.3 to i8
  %399 = icmp eq i32 %394, 0
  %400 = zext i8 %395 to i32
  %401 = icmp eq i32 %396, 0
  %402 = xor i32 %371, 27
  %403 = icmp eq i32 %397, 0
  %a.9.4 = trunc i32 %a.9.in.4 to i8
  %p.9..3 = xor i8 %398, %p.9..2
  %404 = select i1 %399, i8 0, i8 %a.9.3
  %405 = and i32 %400, 1
  %a.9.in.6 = select i1 %401, i32 %371, i32 %402
  %406 = select i1 %403, i8 0, i8 %a.9.4
  %p.9..4 = xor i8 %404, %p.9..3
  %a.9.5 = trunc i32 %a.9.in.5 to i8
  %407 = icmp eq i32 %405, 0
  %408 = icmp sgt i8 %344, -1
  %a.9.6 = trunc i32 %a.9.in.6 to i8
  %p.9..5 = xor i8 %406, %p.9..4
  %409 = select i1 %407, i8 0, i8 %a.9.5
  %410 = select i1 %408, i8 0, i8 %a.9.6
  %p.9..6 = xor i8 %409, %p.9..5
  %p.9..7 = xor i8 %410, %p.9..6
  %411 = and i64 %tmp77, 3
  %412 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType316, i64 0, i64 %411
  %413 = load <4 x i8>* %412, align 4
  %414 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %415 = extractelement <4 x i8> %413, i32 0
  %416 = extractelement <4 x i8> %414, i32 1
  %417 = zext i8 %416 to i32
  %418 = shl i32 %417, 1
  %419 = and i32 %417, 128
  %420 = xor i32 %418, 27
  %421 = icmp eq i32 %419, 0
  %a.11.in = select i1 %421, i32 %418, i32 %420
  %422 = shl i32 %a.11.in, 1
  %423 = and i32 %a.11.in, 128
  %424 = xor i32 %422, 27
  %425 = icmp eq i32 %423, 0
  %a.11.in.1 = select i1 %425, i32 %422, i32 %424
  %426 = shl i32 %a.11.in.1, 1
  %427 = and i32 %a.11.in.1, 128
  %428 = xor i32 %426, 27
  %429 = icmp eq i32 %427, 0
  %a.11.in.2 = select i1 %429, i32 %426, i32 %428
  %430 = shl i32 %a.11.in.2, 1
  %431 = and i32 %a.11.in.2, 128
  %432 = xor i32 %430, 27
  %433 = icmp eq i32 %431, 0
  %a.11.in.3 = select i1 %433, i32 %430, i32 %432
  %434 = shl i32 %a.11.in.3, 1
  %435 = and i32 %a.11.in.3, 128
  %436 = xor i32 %434, 27
  %437 = icmp eq i32 %435, 0
  %a.11.in.4 = select i1 %437, i32 %434, i32 %436
  %438 = shl i32 %a.11.in.4, 1
  %439 = and i32 %a.11.in.4, 128
  %440 = xor i32 %438, 27
  %441 = icmp eq i32 %439, 0
  %a.11.in.5 = select i1 %441, i32 %438, i32 %440
  %442 = shl i32 %a.11.in.5, 1
  %443 = lshr i8 %415, 1
  %444 = zext i8 %443 to i32
  %445 = zext i8 %415 to i32
  %446 = lshr i8 %415, 2
  %447 = lshr i8 %415, 3
  %448 = and i32 %444, 1
  %449 = and i32 %445, 1
  %450 = zext i8 %446 to i32
  %451 = zext i8 %447 to i32
  %452 = icmp eq i32 %448, 0
  %a.11 = trunc i32 %a.11.in to i8
  %453 = icmp eq i32 %449, 0
  %454 = and i32 %450, 1
  %455 = lshr i8 %415, 4
  %456 = lshr i8 %415, 5
  %457 = and i32 %451, 1
  %458 = select i1 %452, i8 0, i8 %a.11
  %459 = select i1 %453, i8 0, i8 %416
  %a.11.1 = trunc i32 %a.11.in.1 to i8
  %460 = icmp eq i32 %454, 0
  %461 = zext i8 %455 to i32
  %462 = zext i8 %456 to i32
  %463 = icmp eq i32 %457, 0
  %a.11.2 = trunc i32 %a.11.in.2 to i8
  %p.11..1 = xor i8 %458, %459
  %464 = select i1 %460, i8 0, i8 %a.11.1
  %465 = and i32 %461, 1
  %466 = lshr i8 %415, 6
  %467 = and i32 %a.11.in.5, 128
  %468 = and i32 %462, 1
  %469 = select i1 %463, i8 0, i8 %a.11.2
  %p.11..2 = xor i8 %464, %p.11..1
  %a.11.3 = trunc i32 %a.11.in.3 to i8
  %470 = icmp eq i32 %465, 0
  %471 = zext i8 %466 to i32
  %472 = icmp eq i32 %467, 0
  %473 = xor i32 %442, 27
  %474 = icmp eq i32 %468, 0
  %a.11.4 = trunc i32 %a.11.in.4 to i8
  %p.11..3 = xor i8 %469, %p.11..2
  %475 = select i1 %470, i8 0, i8 %a.11.3
  %476 = and i32 %471, 1
  %a.11.in.6 = select i1 %472, i32 %442, i32 %473
  %477 = select i1 %474, i8 0, i8 %a.11.4
  %p.11..4 = xor i8 %475, %p.11..3
  %a.11.5 = trunc i32 %a.11.in.5 to i8
  %478 = icmp eq i32 %476, 0
  %479 = icmp sgt i8 %415, -1
  %a.11.6 = trunc i32 %a.11.in.6 to i8
  %p.11..5 = xor i8 %477, %p.11..4
  %480 = select i1 %478, i8 0, i8 %a.11.5
  %481 = select i1 %479, i8 0, i8 %a.11.6
  %p.11..6 = xor i8 %480, %p.11..5
  %p.11..7 = xor i8 %481, %p.11..6
  %482 = and i64 %tmp77, 3
  %483 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType312, i64 0, i64 %482
  %484 = load <4 x i8>* %483, align 4
  %485 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %486 = extractelement <4 x i8> %484, i32 0
  %487 = extractelement <4 x i8> %485, i32 2
  %488 = zext i8 %487 to i32
  %489 = shl i32 %488, 1
  %490 = and i32 %488, 128
  %491 = xor i32 %489, 27
  %492 = icmp eq i32 %490, 0
  %a.13.in = select i1 %492, i32 %489, i32 %491
  %493 = shl i32 %a.13.in, 1
  %494 = and i32 %a.13.in, 128
  %495 = xor i32 %493, 27
  %496 = icmp eq i32 %494, 0
  %a.13.in.1 = select i1 %496, i32 %493, i32 %495
  %497 = shl i32 %a.13.in.1, 1
  %498 = and i32 %a.13.in.1, 128
  %499 = xor i32 %497, 27
  %500 = icmp eq i32 %498, 0
  %a.13.in.2 = select i1 %500, i32 %497, i32 %499
  %501 = shl i32 %a.13.in.2, 1
  %502 = and i32 %a.13.in.2, 128
  %503 = xor i32 %501, 27
  %504 = icmp eq i32 %502, 0
  %a.13.in.3 = select i1 %504, i32 %501, i32 %503
  %505 = shl i32 %a.13.in.3, 1
  %506 = and i32 %a.13.in.3, 128
  %507 = xor i32 %505, 27
  %508 = icmp eq i32 %506, 0
  %a.13.in.4 = select i1 %508, i32 %505, i32 %507
  %509 = shl i32 %a.13.in.4, 1
  %510 = and i32 %a.13.in.4, 128
  %511 = xor i32 %509, 27
  %512 = icmp eq i32 %510, 0
  %a.13.in.5 = select i1 %512, i32 %509, i32 %511
  %513 = shl i32 %a.13.in.5, 1
  %514 = lshr i8 %486, 1
  %515 = zext i8 %514 to i32
  %516 = zext i8 %486 to i32
  %517 = lshr i8 %486, 2
  %518 = lshr i8 %486, 3
  %519 = and i32 %515, 1
  %520 = and i32 %516, 1
  %521 = zext i8 %517 to i32
  %522 = zext i8 %518 to i32
  %523 = icmp eq i32 %519, 0
  %a.13 = trunc i32 %a.13.in to i8
  %524 = icmp eq i32 %520, 0
  %525 = and i32 %521, 1
  %526 = lshr i8 %486, 4
  %527 = lshr i8 %486, 5
  %528 = and i32 %522, 1
  %529 = select i1 %523, i8 0, i8 %a.13
  %530 = select i1 %524, i8 0, i8 %487
  %a.13.1 = trunc i32 %a.13.in.1 to i8
  %531 = icmp eq i32 %525, 0
  %532 = zext i8 %526 to i32
  %533 = zext i8 %527 to i32
  %534 = icmp eq i32 %528, 0
  %a.13.2 = trunc i32 %a.13.in.2 to i8
  %p.13..1 = xor i8 %529, %530
  %535 = select i1 %531, i8 0, i8 %a.13.1
  %536 = and i32 %532, 1
  %537 = lshr i8 %486, 6
  %538 = and i32 %a.13.in.5, 128
  %539 = and i32 %533, 1
  %540 = select i1 %534, i8 0, i8 %a.13.2
  %p.13..2 = xor i8 %535, %p.13..1
  %a.13.3 = trunc i32 %a.13.in.3 to i8
  %541 = icmp eq i32 %536, 0
  %542 = zext i8 %537 to i32
  %543 = icmp eq i32 %538, 0
  %544 = xor i32 %513, 27
  %545 = icmp eq i32 %539, 0
  %a.13.4 = trunc i32 %a.13.in.4 to i8
  %p.13..3 = xor i8 %540, %p.13..2
  %546 = select i1 %541, i8 0, i8 %a.13.3
  %547 = and i32 %542, 1
  %a.13.in.6 = select i1 %543, i32 %513, i32 %544
  %548 = select i1 %545, i8 0, i8 %a.13.4
  %p.13..4 = xor i8 %546, %p.13..3
  %a.13.5 = trunc i32 %a.13.in.5 to i8
  %549 = icmp eq i32 %547, 0
  %550 = icmp sgt i8 %486, -1
  %a.13.6 = trunc i32 %a.13.in.6 to i8
  %p.13..5 = xor i8 %548, %p.13..4
  %551 = select i1 %549, i8 0, i8 %a.13.5
  %552 = select i1 %550, i8 0, i8 %a.13.6
  %p.13..6 = xor i8 %551, %p.13..5
  %p.13..7 = xor i8 %552, %p.13..6
  %553 = and i64 %tmp77, 3
  %554 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType308, i64 0, i64 %553
  %555 = load <4 x i8>* %554, align 4
  %556 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %557 = extractelement <4 x i8> %555, i32 0
  %558 = extractelement <4 x i8> %556, i32 3
  %559 = zext i8 %558 to i32
  %560 = shl i32 %559, 1
  %561 = and i32 %559, 128
  %562 = xor i32 %560, 27
  %563 = icmp eq i32 %561, 0
  %a.15.in = select i1 %563, i32 %560, i32 %562
  %564 = shl i32 %a.15.in, 1
  %565 = and i32 %a.15.in, 128
  %566 = xor i32 %564, 27
  %567 = icmp eq i32 %565, 0
  %a.15.in.1 = select i1 %567, i32 %564, i32 %566
  %568 = shl i32 %a.15.in.1, 1
  %569 = and i32 %a.15.in.1, 128
  %570 = xor i32 %568, 27
  %571 = icmp eq i32 %569, 0
  %a.15.in.2 = select i1 %571, i32 %568, i32 %570
  %572 = shl i32 %a.15.in.2, 1
  %573 = and i32 %a.15.in.2, 128
  %574 = xor i32 %572, 27
  %575 = icmp eq i32 %573, 0
  %a.15.in.3 = select i1 %575, i32 %572, i32 %574
  %576 = shl i32 %a.15.in.3, 1
  %577 = and i32 %a.15.in.3, 128
  %578 = xor i32 %576, 27
  %579 = icmp eq i32 %577, 0
  %a.15.in.4 = select i1 %579, i32 %576, i32 %578
  %580 = shl i32 %a.15.in.4, 1
  %581 = and i32 %a.15.in.4, 128
  %582 = xor i32 %580, 27
  %583 = icmp eq i32 %581, 0
  %a.15.in.5 = select i1 %583, i32 %580, i32 %582
  %584 = shl i32 %a.15.in.5, 1
  %585 = lshr i8 %557, 1
  %586 = zext i8 %585 to i32
  %587 = zext i8 %557 to i32
  %588 = lshr i8 %557, 2
  %589 = lshr i8 %557, 3
  %590 = and i32 %586, 1
  %591 = and i32 %587, 1
  %592 = zext i8 %588 to i32
  %593 = zext i8 %589 to i32
  %594 = icmp eq i32 %590, 0
  %a.15 = trunc i32 %a.15.in to i8
  %595 = icmp eq i32 %591, 0
  %596 = and i32 %592, 1
  %597 = lshr i8 %557, 4
  %598 = lshr i8 %557, 5
  %599 = and i32 %593, 1
  %600 = select i1 %594, i8 0, i8 %a.15
  %601 = select i1 %595, i8 0, i8 %558
  %a.15.1 = trunc i32 %a.15.in.1 to i8
  %602 = icmp eq i32 %596, 0
  %603 = zext i8 %597 to i32
  %604 = zext i8 %598 to i32
  %605 = icmp eq i32 %599, 0
  %a.15.2 = trunc i32 %a.15.in.2 to i8
  %p.15..1 = xor i8 %600, %601
  %606 = select i1 %602, i8 0, i8 %a.15.1
  %607 = and i32 %603, 1
  %608 = lshr i8 %557, 6
  %609 = and i32 %a.15.in.5, 128
  %610 = and i32 %604, 1
  %611 = select i1 %605, i8 0, i8 %a.15.2
  %p.15..2 = xor i8 %606, %p.15..1
  %a.15.3 = trunc i32 %a.15.in.3 to i8
  %612 = icmp eq i32 %607, 0
  %613 = zext i8 %608 to i32
  %614 = icmp eq i32 %609, 0
  %615 = xor i32 %584, 27
  %616 = icmp eq i32 %610, 0
  %a.15.4 = trunc i32 %a.15.in.4 to i8
  %p.15..3 = xor i8 %611, %p.15..2
  %617 = select i1 %612, i8 0, i8 %a.15.3
  %618 = and i32 %613, 1
  %a.15.in.6 = select i1 %614, i32 %584, i32 %615
  %619 = select i1 %616, i8 0, i8 %a.15.4
  %p.15..4 = xor i8 %617, %p.15..3
  %a.15.5 = trunc i32 %a.15.in.5 to i8
  %620 = icmp eq i32 %618, 0
  %621 = icmp sgt i8 %557, -1
  %a.15.6 = trunc i32 %a.15.in.6 to i8
  %p.15..5 = xor i8 %619, %p.15..4
  %622 = select i1 %620, i8 0, i8 %a.15.5
  %623 = select i1 %621, i8 0, i8 %a.15.6
  %p.15..6 = xor i8 %622, %p.15..5
  %p.15..7 = xor i8 %623, %p.15..6
  %624 = xor i8 %p.9..7, %x.060
  store i8 %624, i8* %"&pSB[currWI].offset263", align 1
  %625 = xor i8 %p.11..7, %y.061
  store i8 %625, i8* %"&pSB[currWI].offset272", align 1
  %626 = xor i8 %p.13..7, %z.062
  store i8 %626, i8* %"&pSB[currWI].offset281", align 1
  %627 = xor i8 %p.15..7, %w.063
  store i8 %627, i8* %"&pSB[currWI].offset290", align 1
  %exitcond = icmp eq i64 %tmp, 3
  br i1 %exitcond, label %._crit_edge66, label %339

._crit_edge66:                                    ; preds = %339
  %"&(pSB[currWI].offset)266" = add nuw i64 %CurrSBIndex..3, 96
  %"&pSB[currWI].offset267" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)266"
  %loadedValue269 = load i8* %"&pSB[currWI].offset267", align 1
  %628 = insertelement <4 x i8> undef, i8 %loadedValue269, i32 0
  %"&(pSB[currWI].offset)275" = add nuw i64 %CurrSBIndex..3, 97
  %"&pSB[currWI].offset276" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)275"
  %loadedValue278 = load i8* %"&pSB[currWI].offset276", align 1
  %629 = insertelement <4 x i8> %628, i8 %loadedValue278, i32 1
  %"&(pSB[currWI].offset)284" = add nuw i64 %CurrSBIndex..3, 98
  %"&pSB[currWI].offset285" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)284"
  %loadedValue287 = load i8* %"&pSB[currWI].offset285", align 1
  %630 = insertelement <4 x i8> %629, i8 %loadedValue287, i32 2
  %"&(pSB[currWI].offset)293" = add nuw i64 %CurrSBIndex..3, 99
  %"&pSB[currWI].offset294" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)293"
  %loadedValue296 = load i8* %"&pSB[currWI].offset294", align 1
  %631 = insertelement <4 x i8> %630, i8 %loadedValue296, i32 3
  %"&(pSB[currWI].offset)165" = add nuw i64 %CurrSBIndex..3, 40
  %"&pSB[currWI].offset166" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)165"
  %CastToValueType167 = bitcast i8* %"&pSB[currWI].offset166" to <4 x i8> addrspace(3)**
  %loadedValue168 = load <4 x i8> addrspace(3)** %CastToValueType167, align 8
  store <4 x i8> %631, <4 x i8> addrspace(3)* %loadedValue168, align 4
  %check.WI.iter350 = icmp ult i64 %CurrWI..3, %iterCount
  br i1 %check.WI.iter350, label %thenBB347, label %SyncBB344

thenBB347:                                        ; preds = %._crit_edge66
  %"CurrWI++351" = add nuw i64 %CurrWI..3, 1
  %"loadedCurrSB+Stride353" = add nuw i64 %CurrSBIndex..3, 1712
  br label %SyncBB

SyncBB344:                                        ; preds = %._crit_edge66, %thenBB354, %thenBB
  %CurrSBIndex..1 = phi i64 [ %"loadedCurrSB+Stride360", %thenBB354 ], [ %"loadedCurrSB+Stride", %thenBB ], [ 0, %._crit_edge66 ]
  %currBarrier.0 = phi i32 [ %currBarrier.1, %thenBB354 ], [ %currBarrier.1, %thenBB ], [ 1, %._crit_edge66 ]
  %CurrWI..1 = phi i64 [ %"CurrWI++358", %thenBB354 ], [ %"CurrWI++", %thenBB ], [ 0, %._crit_edge66 ]
  %"&(pSB[currWI].offset)160" = add nuw i64 %CurrSBIndex..1, 40
  %"&pSB[currWI].offset161" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)160"
  %CastToValueType162 = bitcast i8* %"&pSB[currWI].offset161" to <4 x i8> addrspace(3)**
  %loadedValue163 = load <4 x i8> addrspace(3)** %CastToValueType162, align 8
  %632 = load <4 x i8> addrspace(3)* %loadedValue163, align 4
  %"&(pSB[currWI].offset)206" = add nuw i64 %CurrSBIndex..1, 64
  %"&pSB[currWI].offset207" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)206"
  %CastToValueType208 = bitcast i8* %"&pSB[currWI].offset207" to i32*
  %loadedValue209 = load i32* %CastToValueType208, align 4
  %633 = zext i32 %loadedValue209 to i64
  %634 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %633
  %635 = load <4 x i8> addrspace(1)* %634, align 4
  %636 = xor <4 x i8> %632, %635
  %"&(pSB[currWI].offset)298" = add nuw i64 %CurrSBIndex..1, 100
  %"&pSB[currWI].offset299" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)298"
  %CastToValueType300 = bitcast i8* %"&pSB[currWI].offset299" to <4 x i8>*
  store <4 x i8> %636, <4 x i8>* %CastToValueType300, align 4
  %"&(pSB[currWI].offset)118" = add nuw i64 %CurrSBIndex..1, 16
  %"&pSB[currWI].offset119" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)118"
  %CastToValueType120 = bitcast i8* %"&pSB[currWI].offset119" to <4 x i8> addrspace(3)**
  %loadedValue121 = load <4 x i8> addrspace(3)** %CastToValueType120, align 8
  store <4 x i8> %636, <4 x i8> addrspace(3)* %loadedValue121, align 4
  %"&(pSB[currWI].offset)197" = add nuw i64 %CurrSBIndex..1, 60
  %"&pSB[currWI].offset198" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)197"
  %CastToValueType199 = bitcast i8* %"&pSB[currWI].offset198" to i32*
  %loadedValue200 = load i32* %CastToValueType199, align 4
  %indvar.next80 = add i32 %loadedValue200, 1
  %"&(pSB[currWI].offset)302" = add nuw i64 %CurrSBIndex..1, 104
  %"&pSB[currWI].offset303" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)302"
  %CastToValueType304 = bitcast i8* %"&pSB[currWI].offset303" to i32*
  store i32 %indvar.next80, i32* %CastToValueType304, align 4
  br label %34

"Barrier BB89":                                   ; preds = %shiftRows.exit
  %"&pSB[currWI].offset101" = getelementptr inbounds i8* %pSpecialBuf, i64 %CurrSBIndex..2
  %CastToValueType102 = bitcast i8* %"&pSB[currWI].offset101" to i32*
  %loadedValue103 = load i32* %CastToValueType102, align 4
  %637 = add i32 %loadedValue103, %0
  %638 = zext i32 %637 to i64
  %639 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %638
  %640 = load <4 x i8> addrspace(1)* %639, align 4
  %"&(pSB[currWI].offset)237" = add nuw i64 %CurrSBIndex..2, 80
  %"&pSB[currWI].offset238" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)237"
  %CastToValueType239 = bitcast i8* %"&pSB[currWI].offset238" to <4 x i8>*
  %loadedValue240 = load <4 x i8>* %CastToValueType239, align 4
  %641 = xor <4 x i8> %loadedValue240, %640
  %"&(pSB[currWI].offset)109" = add nuw i64 %CurrSBIndex..2, 8
  %"&pSB[currWI].offset110" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)109"
  %CastToValueType111 = bitcast i8* %"&pSB[currWI].offset110" to i64*
  %loadedValue112 = load i64* %CastToValueType111, align 8
  %642 = getelementptr inbounds <4 x i8> addrspace(1)* %output, i64 %loadedValue112
  store <4 x i8> %641, <4 x i8> addrspace(1)* %642, align 4
  %check.WI.iter357 = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter357, label %thenBB354, label %SyncBB345

thenBB354:                                        ; preds = %"Barrier BB89"
  %"CurrWI++358" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride360" = add nuw i64 %CurrSBIndex..2, 1712
  %cond1 = icmp eq i32 %currBarrier.1, 12
  br i1 %cond1, label %SyncBB343, label %SyncBB344

SyncBB345:                                        ; preds = %"Barrier BB89"
  ret void
}

define i32 @shiftRowsInv(i32 %row.coerce, i32 %j, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind readnone {
; <label>:0
  %tmp1 = bitcast i32 %row.coerce to <4 x i8>
  %1 = icmp eq i32 %j, 0
  br i1 %1, label %._crit_edge, label %bb.nph

bb.nph:                                           ; preds = %0, %bb.nph
  %i.03 = phi i32 [ %3, %bb.nph ], [ 0, %0 ]
  %r.02 = phi <4 x i8> [ %2, %bb.nph ], [ %tmp1, %0 ]
  %2 = shufflevector <4 x i8> %r.02, <4 x i8> undef, <4 x i32> <i32 3, i32 0, i32 1, i32 2>
  %3 = add i32 %i.03, 1
  %exitcond = icmp eq i32 %3, %j
  br i1 %exitcond, label %._crit_edge, label %bb.nph

._crit_edge:                                      ; preds = %bb.nph, %0
  %r.0.lcssa = phi <4 x i8> [ %tmp1, %0 ], [ %2, %bb.nph ]
  %4 = bitcast <4 x i8> %r.0.lcssa to i32
  ret i32 %4
}

define void @__AESDecrypt_separated_args(<4 x i8> addrspace(1)* nocapture %output, <4 x i8> addrspace(1)* nocapture %input, <4 x i8> addrspace(1)* nocapture %roundKey, i8 addrspace(1)* nocapture %SBox, <4 x i8> addrspace(3)* nocapture %block0, <4 x i8> addrspace(3)* nocapture %block1, i32 %width, i32 %rounds, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind alwaysinline {
FirstBB:
  %0 = shl i32 %rounds, 2
  %tmp81 = add i32 %rounds, -1
  br label %SyncBB361

SyncBB361:                                        ; preds = %thenBB, %thenBB370, %FirstBB
  %CurrSBIndex..0 = phi i64 [ 0, %FirstBB ], [ %"loadedCurrSB+Stride376", %thenBB370 ], [ %"loadedCurrSB+Stride", %thenBB ]
  %currBarrier.2 = phi i32 [ 15, %FirstBB ], [ %currBarrier.1, %thenBB370 ], [ %currBarrier.1, %thenBB ]
  %CurrWI..0 = phi i64 [ 0, %FirstBB ], [ %"CurrWI++374", %thenBB370 ], [ %"CurrWI++", %thenBB ]
  %1 = load i64* %pWGId, align 8
  %2 = trunc i64 %1 to i32
  %3 = getelementptr i64* %pWGId, i64 1
  %4 = load i64* %3, align 8
  %5 = trunc i64 %4 to i32
  %6 = getelementptr %struct.PaddedDimId* %pLocalIds, i64 %CurrWI..0, i32 0, i64 1
  %7 = load i64* %6, align 8
  %8 = trunc i64 %7 to i32
  %"&(pSB[currWI].offset)" = add nuw i64 %CurrSBIndex..0, 128
  %"&pSB[currWI].offset" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)"
  %CastToValueType = bitcast i8* %"&pSB[currWI].offset" to i32*
  store i32 %8, i32* %CastToValueType, align 4
  %9 = mul i32 %5, %width
  %10 = shl i32 %2, 2
  %11 = add i32 %9, %10
  %12 = and i32 %11, -4
  %13 = add i32 %12, %8
  %"&(pSB[currWI].offset)354" = add nuw i64 %CurrSBIndex..0, 256
  %"&pSB[currWI].offset355" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)354"
  %14 = bitcast i8* %"&pSB[currWI].offset355" to <4 x i8>*
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %14, align 16
  %"&pSB[currWI].offset351.sum" = add i64 %CurrSBIndex..0, 260
  %15 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset351.sum"
  %16 = bitcast i8* %15 to <4 x i8>*
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %16, align 4
  %"&pSB[currWI].offset347.sum" = add i64 %CurrSBIndex..0, 264
  %17 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset347.sum"
  %18 = bitcast i8* %17 to <4 x i8>*
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %18, align 8
  %"&pSB[currWI].offset343.sum" = add i64 %CurrSBIndex..0, 268
  %19 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset343.sum"
  %20 = bitcast i8* %19 to <4 x i8>*
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %20, align 4
  %21 = zext i32 %13 to i64
  %"&(pSB[currWI].offset)102" = add nuw i64 %CurrSBIndex..0, 136
  %"&pSB[currWI].offset103" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)102"
  %CastToValueType104 = bitcast i8* %"&pSB[currWI].offset103" to i64*
  store i64 %21, i64* %CastToValueType104, align 8
  %22 = getelementptr inbounds <4 x i8> addrspace(1)* %input, i64 %21
  %23 = load <4 x i8> addrspace(1)* %22, align 4
  %24 = and i64 %7, 4294967295
  %"&(pSB[currWI].offset)111" = add nuw i64 %CurrSBIndex..0, 144
  %"&pSB[currWI].offset112" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)111"
  %CastToValueType113 = bitcast i8* %"&pSB[currWI].offset112" to i64*
  store i64 %24, i64* %CastToValueType113, align 8
  %25 = getelementptr inbounds <4 x i8> addrspace(3)* %block0, i64 %24
  %"&(pSB[currWI].offset)120" = add nuw i64 %CurrSBIndex..0, 152
  %"&pSB[currWI].offset121" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)120"
  %CastToValueType122 = bitcast i8* %"&pSB[currWI].offset121" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %25, <4 x i8> addrspace(3)** %CastToValueType122, align 8
  store <4 x i8> %23, <4 x i8> addrspace(3)* %25, align 4
  %26 = add i32 %8, %0
  %27 = zext i32 %26 to i64
  %28 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %27
  %29 = load <4 x i8> addrspace(1)* %28, align 4
  %30 = xor <4 x i8> %23, %29
  %"&(pSB[currWI].offset)144" = add nuw i64 %CurrSBIndex..0, 160
  %"&pSB[currWI].offset145" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)144"
  %CastToValueType146 = bitcast i8* %"&pSB[currWI].offset145" to <4 x i8>*
  store <4 x i8> %30, <4 x i8>* %CastToValueType146, align 4
  store <4 x i8> %30, <4 x i8> addrspace(3)* %25, align 4
  %31 = getelementptr inbounds <4 x i8> addrspace(3)* %block1, i64 %24
  %"&(pSB[currWI].offset)148" = add nuw i64 %CurrSBIndex..0, 168
  %"&pSB[currWI].offset149" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)148"
  %CastToValueType150 = bitcast i8* %"&pSB[currWI].offset149" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %31, <4 x i8> addrspace(3)** %CastToValueType150, align 8
  %32 = sub i32 0, %8
  %33 = and i32 %32, 3
  %34 = zext i32 %33 to i64
  %"&(pSB[currWI].offset)338" = add nuw i64 %CurrSBIndex..0, 256
  %"&pSB[currWI].offset339" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)338"
  %CastToValueType340 = bitcast i8* %"&pSB[currWI].offset339" to [4 x <4 x i8>]*
  %35 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType340, i64 0, i64 %34
  %"&(pSB[currWI].offset)157" = add nuw i64 %CurrSBIndex..0, 176
  %"&pSB[currWI].offset158" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)157"
  %CastToValueType159 = bitcast i8* %"&pSB[currWI].offset158" to <4 x i8>**
  store <4 x i8>* %35, <4 x i8>** %CastToValueType159, align 8
  %tmp75 = sub i64 1, %7
  %"&(pSB[currWI].offset)181" = add nuw i64 %CurrSBIndex..0, 184
  %"&pSB[currWI].offset182" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)181"
  %CastToValueType183 = bitcast i8* %"&pSB[currWI].offset182" to i64*
  store i64 %tmp75, i64* %CastToValueType183, align 8
  %tmp86 = add i32 %0, %8
  %tmp87 = add i32 %tmp86, -4
  %"&(pSB[currWI].offset)190" = add nuw i64 %CurrSBIndex..0, 192
  %"&pSB[currWI].offset191" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)190"
  %CastToValueType192 = bitcast i8* %"&pSB[currWI].offset191" to i32*
  store i32 %tmp87, i32* %CastToValueType192, align 4
  br label %36

; <label>:36                                      ; preds = %._crit_edge66, %SyncBB361
  %CurrSBIndex..2 = phi i64 [ %CurrSBIndex..0, %SyncBB361 ], [ %CurrSBIndex..1, %._crit_edge66 ]
  %currBarrier.1 = phi i32 [ %currBarrier.2, %SyncBB361 ], [ %currBarrier.0, %._crit_edge66 ]
  %CurrWI..2 = phi i64 [ %CurrWI..0, %SyncBB361 ], [ %CurrWI..1, %._crit_edge66 ]
  %37 = phi <4 x i8> [ %30, %SyncBB361 ], [ %638, %._crit_edge66 ]
  %indvar79 = phi i32 [ 0, %SyncBB361 ], [ %indvar.next80, %._crit_edge66 ]
  %"&(pSB[currWI].offset)199" = add nuw i64 %CurrSBIndex..2, 196
  %"&pSB[currWI].offset200" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)199"
  %CastToValueType201 = bitcast i8* %"&pSB[currWI].offset200" to i32*
  store i32 %indvar79, i32* %CastToValueType201, align 4
  %38 = bitcast <4 x i8> %37 to i32
  %tmp1.i = bitcast i32 %38 to <4 x i8>
  %"&(pSB[currWI].offset)218" = add nuw i64 %CurrSBIndex..2, 200
  %"&pSB[currWI].offset219" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)218"
  %CastToValueType220 = bitcast i8* %"&pSB[currWI].offset219" to <4 x i8>*
  store <4 x i8> %tmp1.i, <4 x i8>* %CastToValueType220, align 4
  %"&(pSB[currWI].offset)97" = add nuw i64 %CurrSBIndex..2, 128
  %"&pSB[currWI].offset98" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)97"
  %CastToValueType99 = bitcast i8* %"&pSB[currWI].offset98" to i32*
  %loadedValue100 = load i32* %CastToValueType99, align 4
  %39 = icmp eq i32 %loadedValue100, 0
  br i1 %39, label %shiftRowsInv.exit, label %bb.nph.i.preheader

bb.nph.i.preheader:                               ; preds = %36
  %"&(pSB[currWI].offset)222" = add nuw i64 %CurrSBIndex..2, 200
  %"&pSB[currWI].offset223" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)222"
  %CastToValueType224 = bitcast i8* %"&pSB[currWI].offset223" to <4 x i8>*
  %loadedValue225 = load <4 x i8>* %CastToValueType224, align 4
  %"&(pSB[currWI].offset)227" = add nuw i64 %CurrSBIndex..2, 204
  %"&pSB[currWI].offset228" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)227"
  %CastToValueType229 = bitcast i8* %"&pSB[currWI].offset228" to <4 x i8>*
  %"&(pSB[currWI].offset)236" = add nuw i64 %CurrSBIndex..2, 208
  %"&pSB[currWI].offset237" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)236"
  %CastToValueType238 = bitcast i8* %"&pSB[currWI].offset237" to i32*
  %"&(pSB[currWI].offset)93" = add nuw i64 %CurrSBIndex..2, 128
  %"&pSB[currWI].offset94" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)93"
  %CastToValueType95 = bitcast i8* %"&pSB[currWI].offset94" to i32*
  br label %bb.nph.i

bb.nph.i:                                         ; preds = %bb.nph.i, %bb.nph.i.preheader
  %i.03.i = phi i32 [ %41, %bb.nph.i ], [ 0, %bb.nph.i.preheader ]
  %r.02.i = phi <4 x i8> [ %40, %bb.nph.i ], [ %loadedValue225, %bb.nph.i.preheader ]
  %40 = shufflevector <4 x i8> %r.02.i, <4 x i8> undef, <4 x i32> <i32 3, i32 0, i32 1, i32 2>
  store <4 x i8> %40, <4 x i8>* %CastToValueType229, align 4
  %41 = add i32 %i.03.i, 1
  store i32 %41, i32* %CastToValueType238, align 4
  %loadedValue = load i32* %CastToValueType95, align 4
  %exitcond.i = icmp eq i32 %41, %loadedValue
  br i1 %exitcond.i, label %shiftRowsInv.exit.loopexit, label %bb.nph.i

shiftRowsInv.exit.loopexit:                       ; preds = %bb.nph.i
  %"&(pSB[currWI].offset)231" = add nuw i64 %CurrSBIndex..2, 204
  %"&pSB[currWI].offset232" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)231"
  %CastToValueType233 = bitcast i8* %"&pSB[currWI].offset232" to <4 x i8>*
  %loadedValue234 = load <4 x i8>* %CastToValueType233, align 4
  br label %shiftRowsInv.exit

shiftRowsInv.exit:                                ; preds = %shiftRowsInv.exit.loopexit, %36
  %r.0.lcssa.i = phi <4 x i8> [ %tmp1.i, %36 ], [ %loadedValue234, %shiftRowsInv.exit.loopexit ]
  %42 = bitcast <4 x i8> %r.0.lcssa.i to i32
  %tmp3 = bitcast i32 %42 to <4 x i8>
  %"&(pSB[currWI].offset)139" = add nuw i64 %CurrSBIndex..2, 152
  %"&pSB[currWI].offset140" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)139"
  %CastToValueType141 = bitcast i8* %"&pSB[currWI].offset140" to <4 x i8> addrspace(3)**
  %loadedValue142 = load <4 x i8> addrspace(3)** %CastToValueType141, align 8
  store <4 x i8> %tmp3, <4 x i8> addrspace(3)* %loadedValue142, align 4
  %43 = bitcast <4 x i8> %tmp3 to i32
  %tmp1.i89 = bitcast i32 %43 to <4 x i8>
  %44 = extractelement <4 x i8> %tmp1.i89, i32 0
  %45 = zext i8 %44 to i64
  %46 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %45
  %47 = load i8 addrspace(1)* %46, align 1
  %48 = insertelement <4 x i8> undef, i8 %47, i32 0
  %49 = extractelement <4 x i8> %tmp1.i89, i32 1
  %50 = zext i8 %49 to i64
  %51 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %50
  %52 = load i8 addrspace(1)* %51, align 1
  %53 = insertelement <4 x i8> %48, i8 %52, i32 1
  %54 = extractelement <4 x i8> %tmp1.i89, i32 2
  %55 = zext i8 %54 to i64
  %56 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %55
  %57 = load i8 addrspace(1)* %56, align 1
  %58 = insertelement <4 x i8> %53, i8 %57, i32 2
  %59 = extractelement <4 x i8> %tmp1.i89, i32 3
  %60 = zext i8 %59 to i64
  %61 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %60
  %62 = load i8 addrspace(1)* %61, align 1
  %63 = insertelement <4 x i8> %58, i8 %62, i32 3
  %64 = bitcast <4 x i8> %63 to i32
  %tmp1 = bitcast i32 %64 to <4 x i8>
  %"&(pSB[currWI].offset)240" = add nuw i64 %CurrSBIndex..2, 212
  %"&pSB[currWI].offset241" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)240"
  %CastToValueType242 = bitcast i8* %"&pSB[currWI].offset241" to <4 x i8>*
  store <4 x i8> %tmp1, <4 x i8>* %CastToValueType242, align 4
  %"&(pSB[currWI].offset)134" = add nuw i64 %CurrSBIndex..2, 152
  %"&pSB[currWI].offset135" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)134"
  %CastToValueType136 = bitcast i8* %"&pSB[currWI].offset135" to <4 x i8> addrspace(3)**
  %loadedValue137 = load <4 x i8> addrspace(3)** %CastToValueType136, align 8
  store <4 x i8> %tmp1, <4 x i8> addrspace(3)* %loadedValue137, align 4
  %"&(pSB[currWI].offset)208" = add nuw i64 %CurrSBIndex..2, 196
  %"&pSB[currWI].offset209" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)208"
  %CastToValueType210 = bitcast i8* %"&pSB[currWI].offset209" to i32*
  %loadedValue211 = load i32* %CastToValueType210, align 4
  %exitcond82 = icmp eq i32 %loadedValue211, %tmp81
  br i1 %exitcond82, label %"Barrier BB91", label %bb.nph65

bb.nph65:                                         ; preds = %shiftRowsInv.exit
  %"&(pSB[currWI].offset)203" = add nuw i64 %CurrSBIndex..2, 196
  %"&pSB[currWI].offset204" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)203"
  %CastToValueType205 = bitcast i8* %"&pSB[currWI].offset204" to i32*
  %loadedValue206 = load i32* %CastToValueType205, align 4
  %tmp83 = mul i32 %loadedValue206, -4
  %"&(pSB[currWI].offset)194" = add nuw i64 %CurrSBIndex..2, 192
  %"&pSB[currWI].offset195" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)194"
  %CastToValueType196 = bitcast i8* %"&pSB[currWI].offset195" to i32*
  %loadedValue197 = load i32* %CastToValueType196, align 4
  %tmp88 = add i32 %loadedValue197, %tmp83
  %"&(pSB[currWI].offset)249" = add nuw i64 %CurrSBIndex..2, 216
  %"&pSB[currWI].offset250" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)249"
  %CastToValueType251 = bitcast i8* %"&pSB[currWI].offset250" to i32*
  store i32 %tmp88, i32* %CastToValueType251, align 4
  %check.WI.iter = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter, label %thenBB, label %SyncBB

thenBB:                                           ; preds = %bb.nph65
  %"CurrWI++" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride" = add nuw i64 %CurrSBIndex..2, 1712
  %cond = icmp eq i32 %currBarrier.1, 4
  br i1 %cond, label %SyncBB359, label %SyncBB361

SyncBB:                                           ; preds = %bb.nph65, %thenBB363
  %CurrSBIndex..3 = phi i64 [ %"loadedCurrSB+Stride369", %thenBB363 ], [ 0, %bb.nph65 ]
  %CurrWI..3 = phi i64 [ %"CurrWI++367", %thenBB363 ], [ 0, %bb.nph65 ]
  %"&(pSB[currWI].offset)129" = add nuw i64 %CurrSBIndex..3, 152
  %"&pSB[currWI].offset130" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)129"
  %CastToValueType131 = bitcast i8* %"&pSB[currWI].offset130" to <4 x i8> addrspace(3)**
  %loadedValue132 = load <4 x i8> addrspace(3)** %CastToValueType131, align 8
  %65 = load <4 x i8> addrspace(3)* %loadedValue132, align 4
  %"&(pSB[currWI].offset)253" = add nuw i64 %CurrSBIndex..3, 216
  %"&pSB[currWI].offset254" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)253"
  %CastToValueType255 = bitcast i8* %"&pSB[currWI].offset254" to i32*
  %loadedValue256 = load i32* %CastToValueType255, align 4
  %66 = zext i32 %loadedValue256 to i64
  %67 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %66
  %68 = load <4 x i8> addrspace(1)* %67, align 4
  %69 = xor <4 x i8> %65, %68
  %"&(pSB[currWI].offset)152" = add nuw i64 %CurrSBIndex..3, 168
  %"&pSB[currWI].offset153" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)152"
  %CastToValueType154 = bitcast i8* %"&pSB[currWI].offset153" to <4 x i8> addrspace(3)**
  %loadedValue155 = load <4 x i8> addrspace(3)** %CastToValueType154, align 8
  store <4 x i8> %69, <4 x i8> addrspace(3)* %loadedValue155, align 4
  %check.WI.iter366 = icmp ult i64 %CurrWI..3, %iterCount
  br i1 %check.WI.iter366, label %thenBB363, label %SyncBB359

thenBB363:                                        ; preds = %SyncBB
  %"CurrWI++367" = add nuw i64 %CurrWI..3, 1
  %"loadedCurrSB+Stride369" = add nuw i64 %CurrSBIndex..3, 1712
  br label %SyncBB

SyncBB359:                                        ; preds = %SyncBB, %thenBB370, %thenBB
  %CurrSBIndex..1 = phi i64 [ %"loadedCurrSB+Stride376", %thenBB370 ], [ %"loadedCurrSB+Stride", %thenBB ], [ 0, %SyncBB ]
  %currBarrier.0 = phi i32 [ %currBarrier.1, %thenBB370 ], [ %currBarrier.1, %thenBB ], [ 4, %SyncBB ]
  %CurrWI..1 = phi i64 [ %"CurrWI++374", %thenBB370 ], [ %"CurrWI++", %thenBB ], [ 0, %SyncBB ]
  %"&(pSB[currWI].offset)176" = add nuw i64 %CurrSBIndex..1, 176
  %"&pSB[currWI].offset177" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)176"
  %CastToValueType178 = bitcast i8* %"&pSB[currWI].offset177" to <4 x i8>**
  %loadedValue179 = load <4 x i8>** %CastToValueType178, align 8
  %70 = load <4 x i8>* %loadedValue179, align 4
  %71 = load <4 x i8> addrspace(3)* %block1, align 4
  %72 = extractelement <4 x i8> %70, i32 0
  %73 = extractelement <4 x i8> %71, i32 0
  %74 = zext i8 %73 to i32
  %75 = shl i32 %74, 1
  %76 = and i32 %74, 128
  %77 = xor i32 %75, 27
  %78 = icmp eq i32 %76, 0
  %a.1.in = select i1 %78, i32 %75, i32 %77
  %79 = shl i32 %a.1.in, 1
  %80 = and i32 %a.1.in, 128
  %81 = xor i32 %79, 27
  %82 = icmp eq i32 %80, 0
  %a.1.in.1 = select i1 %82, i32 %79, i32 %81
  %83 = shl i32 %a.1.in.1, 1
  %84 = and i32 %a.1.in.1, 128
  %85 = xor i32 %83, 27
  %86 = icmp eq i32 %84, 0
  %a.1.in.2 = select i1 %86, i32 %83, i32 %85
  %87 = shl i32 %a.1.in.2, 1
  %88 = and i32 %a.1.in.2, 128
  %89 = xor i32 %87, 27
  %90 = icmp eq i32 %88, 0
  %a.1.in.3 = select i1 %90, i32 %87, i32 %89
  %91 = shl i32 %a.1.in.3, 1
  %92 = and i32 %a.1.in.3, 128
  %93 = xor i32 %91, 27
  %94 = icmp eq i32 %92, 0
  %a.1.in.4 = select i1 %94, i32 %91, i32 %93
  %95 = shl i32 %a.1.in.4, 1
  %96 = and i32 %a.1.in.4, 128
  %97 = xor i32 %95, 27
  %98 = icmp eq i32 %96, 0
  %a.1.in.5 = select i1 %98, i32 %95, i32 %97
  %99 = shl i32 %a.1.in.5, 1
  %100 = lshr i8 %72, 1
  %101 = zext i8 %100 to i32
  %102 = zext i8 %72 to i32
  %103 = lshr i8 %72, 2
  %104 = lshr i8 %72, 3
  %105 = and i32 %101, 1
  %106 = and i32 %102, 1
  %107 = zext i8 %103 to i32
  %108 = zext i8 %104 to i32
  %109 = icmp eq i32 %105, 0
  %a.1 = trunc i32 %a.1.in to i8
  %110 = icmp eq i32 %106, 0
  %111 = and i32 %107, 1
  %112 = lshr i8 %72, 4
  %113 = lshr i8 %72, 5
  %114 = and i32 %108, 1
  %115 = select i1 %109, i8 0, i8 %a.1
  %116 = select i1 %110, i8 0, i8 %73
  %a.1.1 = trunc i32 %a.1.in.1 to i8
  %117 = icmp eq i32 %111, 0
  %118 = zext i8 %112 to i32
  %119 = zext i8 %113 to i32
  %120 = icmp eq i32 %114, 0
  %a.1.2 = trunc i32 %a.1.in.2 to i8
  %p.1..1 = xor i8 %115, %116
  %121 = select i1 %117, i8 0, i8 %a.1.1
  %122 = and i32 %118, 1
  %123 = lshr i8 %72, 6
  %124 = and i32 %a.1.in.5, 128
  %125 = and i32 %119, 1
  %126 = select i1 %120, i8 0, i8 %a.1.2
  %p.1..2 = xor i8 %121, %p.1..1
  %a.1.3 = trunc i32 %a.1.in.3 to i8
  %127 = icmp eq i32 %122, 0
  %128 = zext i8 %123 to i32
  %129 = icmp eq i32 %124, 0
  %130 = xor i32 %99, 27
  %131 = icmp eq i32 %125, 0
  %a.1.4 = trunc i32 %a.1.in.4 to i8
  %p.1..3 = xor i8 %126, %p.1..2
  %132 = select i1 %127, i8 0, i8 %a.1.3
  %133 = and i32 %128, 1
  %a.1.in.6 = select i1 %129, i32 %99, i32 %130
  %134 = select i1 %131, i8 0, i8 %a.1.4
  %p.1..4 = xor i8 %132, %p.1..3
  %a.1.5 = trunc i32 %a.1.in.5 to i8
  %135 = icmp eq i32 %133, 0
  %136 = icmp sgt i8 %72, -1
  %a.1.6 = trunc i32 %a.1.in.6 to i8
  %p.1..5 = xor i8 %134, %p.1..4
  %137 = select i1 %135, i8 0, i8 %a.1.5
  %138 = select i1 %136, i8 0, i8 %a.1.6
  %p.1..6 = xor i8 %137, %p.1..5
  %p.1..7 = xor i8 %138, %p.1..6
  %"&(pSB[currWI].offset)258" = add nuw i64 %CurrSBIndex..1, 220
  %"&pSB[currWI].offset259" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)258"
  store i8 %p.1..7, i8* %"&pSB[currWI].offset259", align 1
  %"&(pSB[currWI].offset)171" = add nuw i64 %CurrSBIndex..1, 176
  %"&pSB[currWI].offset172" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)171"
  %CastToValueType173 = bitcast i8* %"&pSB[currWI].offset172" to <4 x i8>**
  %loadedValue174 = load <4 x i8>** %CastToValueType173, align 8
  %139 = load <4 x i8>* %loadedValue174, align 4
  %140 = load <4 x i8> addrspace(3)* %block1, align 4
  %141 = extractelement <4 x i8> %139, i32 0
  %142 = extractelement <4 x i8> %140, i32 1
  %143 = zext i8 %142 to i32
  %144 = shl i32 %143, 1
  %145 = and i32 %143, 128
  %146 = xor i32 %144, 27
  %147 = icmp eq i32 %145, 0
  %a.3.in = select i1 %147, i32 %144, i32 %146
  %148 = shl i32 %a.3.in, 1
  %149 = and i32 %a.3.in, 128
  %150 = xor i32 %148, 27
  %151 = icmp eq i32 %149, 0
  %a.3.in.1 = select i1 %151, i32 %148, i32 %150
  %152 = shl i32 %a.3.in.1, 1
  %153 = and i32 %a.3.in.1, 128
  %154 = xor i32 %152, 27
  %155 = icmp eq i32 %153, 0
  %a.3.in.2 = select i1 %155, i32 %152, i32 %154
  %156 = shl i32 %a.3.in.2, 1
  %157 = and i32 %a.3.in.2, 128
  %158 = xor i32 %156, 27
  %159 = icmp eq i32 %157, 0
  %a.3.in.3 = select i1 %159, i32 %156, i32 %158
  %160 = shl i32 %a.3.in.3, 1
  %161 = and i32 %a.3.in.3, 128
  %162 = xor i32 %160, 27
  %163 = icmp eq i32 %161, 0
  %a.3.in.4 = select i1 %163, i32 %160, i32 %162
  %164 = shl i32 %a.3.in.4, 1
  %165 = and i32 %a.3.in.4, 128
  %166 = xor i32 %164, 27
  %167 = icmp eq i32 %165, 0
  %a.3.in.5 = select i1 %167, i32 %164, i32 %166
  %168 = shl i32 %a.3.in.5, 1
  %169 = lshr i8 %141, 1
  %170 = zext i8 %169 to i32
  %171 = zext i8 %141 to i32
  %172 = lshr i8 %141, 2
  %173 = lshr i8 %141, 3
  %174 = and i32 %170, 1
  %175 = and i32 %171, 1
  %176 = zext i8 %172 to i32
  %177 = zext i8 %173 to i32
  %178 = icmp eq i32 %174, 0
  %a.3 = trunc i32 %a.3.in to i8
  %179 = icmp eq i32 %175, 0
  %180 = and i32 %176, 1
  %181 = lshr i8 %141, 4
  %182 = lshr i8 %141, 5
  %183 = and i32 %177, 1
  %184 = select i1 %178, i8 0, i8 %a.3
  %185 = select i1 %179, i8 0, i8 %142
  %a.3.1 = trunc i32 %a.3.in.1 to i8
  %186 = icmp eq i32 %180, 0
  %187 = zext i8 %181 to i32
  %188 = zext i8 %182 to i32
  %189 = icmp eq i32 %183, 0
  %a.3.2 = trunc i32 %a.3.in.2 to i8
  %p.3..1 = xor i8 %184, %185
  %190 = select i1 %186, i8 0, i8 %a.3.1
  %191 = and i32 %187, 1
  %192 = lshr i8 %141, 6
  %193 = and i32 %a.3.in.5, 128
  %194 = and i32 %188, 1
  %195 = select i1 %189, i8 0, i8 %a.3.2
  %p.3..2 = xor i8 %190, %p.3..1
  %a.3.3 = trunc i32 %a.3.in.3 to i8
  %196 = icmp eq i32 %191, 0
  %197 = zext i8 %192 to i32
  %198 = icmp eq i32 %193, 0
  %199 = xor i32 %168, 27
  %200 = icmp eq i32 %194, 0
  %a.3.4 = trunc i32 %a.3.in.4 to i8
  %p.3..3 = xor i8 %195, %p.3..2
  %201 = select i1 %196, i8 0, i8 %a.3.3
  %202 = and i32 %197, 1
  %a.3.in.6 = select i1 %198, i32 %168, i32 %199
  %203 = select i1 %200, i8 0, i8 %a.3.4
  %p.3..4 = xor i8 %201, %p.3..3
  %a.3.5 = trunc i32 %a.3.in.5 to i8
  %204 = icmp eq i32 %202, 0
  %205 = icmp sgt i8 %141, -1
  %a.3.6 = trunc i32 %a.3.in.6 to i8
  %p.3..5 = xor i8 %203, %p.3..4
  %206 = select i1 %204, i8 0, i8 %a.3.5
  %207 = select i1 %205, i8 0, i8 %a.3.6
  %p.3..6 = xor i8 %206, %p.3..5
  %p.3..7 = xor i8 %207, %p.3..6
  %"&(pSB[currWI].offset)262" = add nuw i64 %CurrSBIndex..1, 221
  %"&pSB[currWI].offset263" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)262"
  store i8 %p.3..7, i8* %"&pSB[currWI].offset263", align 1
  %"&(pSB[currWI].offset)166" = add nuw i64 %CurrSBIndex..1, 176
  %"&pSB[currWI].offset167" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)166"
  %CastToValueType168 = bitcast i8* %"&pSB[currWI].offset167" to <4 x i8>**
  %loadedValue169 = load <4 x i8>** %CastToValueType168, align 8
  %208 = load <4 x i8>* %loadedValue169, align 4
  %209 = load <4 x i8> addrspace(3)* %block1, align 4
  %210 = extractelement <4 x i8> %208, i32 0
  %211 = extractelement <4 x i8> %209, i32 2
  %212 = zext i8 %211 to i32
  %213 = shl i32 %212, 1
  %214 = and i32 %212, 128
  %215 = xor i32 %213, 27
  %216 = icmp eq i32 %214, 0
  %a.5.in = select i1 %216, i32 %213, i32 %215
  %217 = shl i32 %a.5.in, 1
  %218 = and i32 %a.5.in, 128
  %219 = xor i32 %217, 27
  %220 = icmp eq i32 %218, 0
  %a.5.in.1 = select i1 %220, i32 %217, i32 %219
  %221 = shl i32 %a.5.in.1, 1
  %222 = and i32 %a.5.in.1, 128
  %223 = xor i32 %221, 27
  %224 = icmp eq i32 %222, 0
  %a.5.in.2 = select i1 %224, i32 %221, i32 %223
  %225 = shl i32 %a.5.in.2, 1
  %226 = and i32 %a.5.in.2, 128
  %227 = xor i32 %225, 27
  %228 = icmp eq i32 %226, 0
  %a.5.in.3 = select i1 %228, i32 %225, i32 %227
  %229 = shl i32 %a.5.in.3, 1
  %230 = and i32 %a.5.in.3, 128
  %231 = xor i32 %229, 27
  %232 = icmp eq i32 %230, 0
  %a.5.in.4 = select i1 %232, i32 %229, i32 %231
  %233 = shl i32 %a.5.in.4, 1
  %234 = and i32 %a.5.in.4, 128
  %235 = xor i32 %233, 27
  %236 = icmp eq i32 %234, 0
  %a.5.in.5 = select i1 %236, i32 %233, i32 %235
  %237 = shl i32 %a.5.in.5, 1
  %238 = lshr i8 %210, 1
  %239 = zext i8 %238 to i32
  %240 = zext i8 %210 to i32
  %241 = lshr i8 %210, 2
  %242 = lshr i8 %210, 3
  %243 = and i32 %239, 1
  %244 = and i32 %240, 1
  %245 = zext i8 %241 to i32
  %246 = zext i8 %242 to i32
  %247 = icmp eq i32 %243, 0
  %a.5 = trunc i32 %a.5.in to i8
  %248 = icmp eq i32 %244, 0
  %249 = and i32 %245, 1
  %250 = lshr i8 %210, 4
  %251 = lshr i8 %210, 5
  %252 = and i32 %246, 1
  %253 = select i1 %247, i8 0, i8 %a.5
  %254 = select i1 %248, i8 0, i8 %211
  %a.5.1 = trunc i32 %a.5.in.1 to i8
  %255 = icmp eq i32 %249, 0
  %256 = zext i8 %250 to i32
  %257 = zext i8 %251 to i32
  %258 = icmp eq i32 %252, 0
  %a.5.2 = trunc i32 %a.5.in.2 to i8
  %p.5..1 = xor i8 %253, %254
  %259 = select i1 %255, i8 0, i8 %a.5.1
  %260 = and i32 %256, 1
  %261 = lshr i8 %210, 6
  %262 = and i32 %a.5.in.5, 128
  %263 = and i32 %257, 1
  %264 = select i1 %258, i8 0, i8 %a.5.2
  %p.5..2 = xor i8 %259, %p.5..1
  %a.5.3 = trunc i32 %a.5.in.3 to i8
  %265 = icmp eq i32 %260, 0
  %266 = zext i8 %261 to i32
  %267 = icmp eq i32 %262, 0
  %268 = xor i32 %237, 27
  %269 = icmp eq i32 %263, 0
  %a.5.4 = trunc i32 %a.5.in.4 to i8
  %p.5..3 = xor i8 %264, %p.5..2
  %270 = select i1 %265, i8 0, i8 %a.5.3
  %271 = and i32 %266, 1
  %a.5.in.6 = select i1 %267, i32 %237, i32 %268
  %272 = select i1 %269, i8 0, i8 %a.5.4
  %p.5..4 = xor i8 %270, %p.5..3
  %a.5.5 = trunc i32 %a.5.in.5 to i8
  %273 = icmp eq i32 %271, 0
  %274 = icmp sgt i8 %210, -1
  %a.5.6 = trunc i32 %a.5.in.6 to i8
  %p.5..5 = xor i8 %272, %p.5..4
  %275 = select i1 %273, i8 0, i8 %a.5.5
  %276 = select i1 %274, i8 0, i8 %a.5.6
  %p.5..6 = xor i8 %275, %p.5..5
  %p.5..7 = xor i8 %276, %p.5..6
  %"&(pSB[currWI].offset)266" = add nuw i64 %CurrSBIndex..1, 222
  %"&pSB[currWI].offset267" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)266"
  store i8 %p.5..7, i8* %"&pSB[currWI].offset267", align 1
  %"&(pSB[currWI].offset)161" = add nuw i64 %CurrSBIndex..1, 176
  %"&pSB[currWI].offset162" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)161"
  %CastToValueType163 = bitcast i8* %"&pSB[currWI].offset162" to <4 x i8>**
  %loadedValue164 = load <4 x i8>** %CastToValueType163, align 8
  %277 = load <4 x i8>* %loadedValue164, align 4
  %278 = load <4 x i8> addrspace(3)* %block1, align 4
  %279 = extractelement <4 x i8> %277, i32 0
  %280 = extractelement <4 x i8> %278, i32 3
  %281 = zext i8 %280 to i32
  %282 = shl i32 %281, 1
  %283 = and i32 %281, 128
  %284 = xor i32 %282, 27
  %285 = icmp eq i32 %283, 0
  %a.7.in = select i1 %285, i32 %282, i32 %284
  %286 = shl i32 %a.7.in, 1
  %287 = and i32 %a.7.in, 128
  %288 = xor i32 %286, 27
  %289 = icmp eq i32 %287, 0
  %a.7.in.1 = select i1 %289, i32 %286, i32 %288
  %290 = shl i32 %a.7.in.1, 1
  %291 = and i32 %a.7.in.1, 128
  %292 = xor i32 %290, 27
  %293 = icmp eq i32 %291, 0
  %a.7.in.2 = select i1 %293, i32 %290, i32 %292
  %294 = shl i32 %a.7.in.2, 1
  %295 = and i32 %a.7.in.2, 128
  %296 = xor i32 %294, 27
  %297 = icmp eq i32 %295, 0
  %a.7.in.3 = select i1 %297, i32 %294, i32 %296
  %298 = shl i32 %a.7.in.3, 1
  %299 = and i32 %a.7.in.3, 128
  %300 = xor i32 %298, 27
  %301 = icmp eq i32 %299, 0
  %a.7.in.4 = select i1 %301, i32 %298, i32 %300
  %302 = shl i32 %a.7.in.4, 1
  %303 = and i32 %a.7.in.4, 128
  %304 = xor i32 %302, 27
  %305 = icmp eq i32 %303, 0
  %a.7.in.5 = select i1 %305, i32 %302, i32 %304
  %306 = shl i32 %a.7.in.5, 1
  %307 = lshr i8 %279, 1
  %308 = zext i8 %307 to i32
  %309 = zext i8 %279 to i32
  %310 = lshr i8 %279, 2
  %311 = lshr i8 %279, 3
  %312 = and i32 %308, 1
  %313 = and i32 %309, 1
  %314 = zext i8 %310 to i32
  %315 = zext i8 %311 to i32
  %316 = icmp eq i32 %312, 0
  %a.7 = trunc i32 %a.7.in to i8
  %317 = icmp eq i32 %313, 0
  %318 = and i32 %314, 1
  %319 = lshr i8 %279, 4
  %320 = lshr i8 %279, 5
  %321 = and i32 %315, 1
  %322 = select i1 %316, i8 0, i8 %a.7
  %323 = select i1 %317, i8 0, i8 %280
  %a.7.1 = trunc i32 %a.7.in.1 to i8
  %324 = icmp eq i32 %318, 0
  %325 = zext i8 %319 to i32
  %326 = zext i8 %320 to i32
  %327 = icmp eq i32 %321, 0
  %a.7.2 = trunc i32 %a.7.in.2 to i8
  %p.7..1 = xor i8 %322, %323
  %328 = select i1 %324, i8 0, i8 %a.7.1
  %329 = and i32 %325, 1
  %330 = lshr i8 %279, 6
  %331 = and i32 %a.7.in.5, 128
  %332 = and i32 %326, 1
  %333 = select i1 %327, i8 0, i8 %a.7.2
  %p.7..2 = xor i8 %328, %p.7..1
  %a.7.3 = trunc i32 %a.7.in.3 to i8
  %334 = icmp eq i32 %329, 0
  %335 = zext i8 %330 to i32
  %336 = icmp eq i32 %331, 0
  %337 = xor i32 %306, 27
  %338 = icmp eq i32 %332, 0
  %a.7.4 = trunc i32 %a.7.in.4 to i8
  %p.7..3 = xor i8 %333, %p.7..2
  %339 = select i1 %334, i8 0, i8 %a.7.3
  %340 = and i32 %335, 1
  %a.7.in.6 = select i1 %336, i32 %306, i32 %337
  %341 = select i1 %338, i8 0, i8 %a.7.4
  %p.7..4 = xor i8 %339, %p.7..3
  %a.7.5 = trunc i32 %a.7.in.5 to i8
  %342 = icmp eq i32 %340, 0
  %343 = icmp sgt i8 %279, -1
  %a.7.6 = trunc i32 %a.7.in.6 to i8
  %p.7..5 = xor i8 %341, %p.7..4
  %344 = select i1 %342, i8 0, i8 %a.7.5
  %345 = select i1 %343, i8 0, i8 %a.7.6
  %p.7..6 = xor i8 %344, %p.7..5
  %p.7..7 = xor i8 %345, %p.7..6
  %"&(pSB[currWI].offset)270" = add nuw i64 %CurrSBIndex..1, 223
  %"&pSB[currWI].offset271" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)270"
  store i8 %p.7..7, i8* %"&pSB[currWI].offset271", align 1
  %"&(pSB[currWI].offset)274" = add nuw i64 %CurrSBIndex..1, 224
  %"&pSB[currWI].offset275" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)274"
  %CastToValueType276 = bitcast i8* %"&pSB[currWI].offset275" to i64*
  %"&(pSB[currWI].offset)185" = add nuw i64 %CurrSBIndex..1, 184
  %"&pSB[currWI].offset186" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)185"
  %CastToValueType187 = bitcast i8* %"&pSB[currWI].offset186" to i64*
  %"&(pSB[currWI].offset)334" = add nuw i64 %CurrSBIndex..1, 256
  %"&pSB[currWI].offset335" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)334"
  %CastToValueType336 = bitcast i8* %"&pSB[currWI].offset335" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)330" = add nuw i64 %CurrSBIndex..1, 256
  %"&pSB[currWI].offset331" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)330"
  %CastToValueType332 = bitcast i8* %"&pSB[currWI].offset331" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)326" = add nuw i64 %CurrSBIndex..1, 256
  %"&pSB[currWI].offset327" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)326"
  %CastToValueType328 = bitcast i8* %"&pSB[currWI].offset327" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)322" = add nuw i64 %CurrSBIndex..1, 256
  %"&pSB[currWI].offset323" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)322"
  %CastToValueType324 = bitcast i8* %"&pSB[currWI].offset323" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)278" = add nuw i64 %CurrSBIndex..1, 232
  %"&pSB[currWI].offset279" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)278"
  %"&(pSB[currWI].offset)287" = add nuw i64 %CurrSBIndex..1, 233
  %"&pSB[currWI].offset288" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)287"
  %"&(pSB[currWI].offset)296" = add nuw i64 %CurrSBIndex..1, 234
  %"&pSB[currWI].offset297" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)296"
  %"&(pSB[currWI].offset)305" = add nuw i64 %CurrSBIndex..1, 235
  %"&pSB[currWI].offset306" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)305"
  br label %346

; <label>:346                                     ; preds = %346, %SyncBB359
  %indvar = phi i64 [ 0, %SyncBB359 ], [ %tmp, %346 ]
  %w.063 = phi i8 [ %p.7..7, %SyncBB359 ], [ %634, %346 ]
  %z.062 = phi i8 [ %p.5..7, %SyncBB359 ], [ %633, %346 ]
  %y.061 = phi i8 [ %p.3..7, %SyncBB359 ], [ %632, %346 ]
  %x.060 = phi i8 [ %p.1..7, %SyncBB359 ], [ %631, %346 ]
  %tmp = add i64 %indvar, 1
  store i64 %tmp, i64* %CastToValueType276, align 8
  %scevgep = getelementptr <4 x i8> addrspace(3)* %block1, i64 %tmp
  %loadedValue188 = load i64* %CastToValueType187, align 8
  %tmp77 = add i64 %loadedValue188, %indvar
  %347 = and i64 %tmp77, 3
  %348 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType336, i64 0, i64 %347
  %349 = load <4 x i8>* %348, align 4
  %350 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %351 = extractelement <4 x i8> %349, i32 0
  %352 = extractelement <4 x i8> %350, i32 0
  %353 = zext i8 %352 to i32
  %354 = shl i32 %353, 1
  %355 = and i32 %353, 128
  %356 = xor i32 %354, 27
  %357 = icmp eq i32 %355, 0
  %a.9.in = select i1 %357, i32 %354, i32 %356
  %358 = shl i32 %a.9.in, 1
  %359 = and i32 %a.9.in, 128
  %360 = xor i32 %358, 27
  %361 = icmp eq i32 %359, 0
  %a.9.in.1 = select i1 %361, i32 %358, i32 %360
  %362 = shl i32 %a.9.in.1, 1
  %363 = and i32 %a.9.in.1, 128
  %364 = xor i32 %362, 27
  %365 = icmp eq i32 %363, 0
  %a.9.in.2 = select i1 %365, i32 %362, i32 %364
  %366 = shl i32 %a.9.in.2, 1
  %367 = and i32 %a.9.in.2, 128
  %368 = xor i32 %366, 27
  %369 = icmp eq i32 %367, 0
  %a.9.in.3 = select i1 %369, i32 %366, i32 %368
  %370 = shl i32 %a.9.in.3, 1
  %371 = and i32 %a.9.in.3, 128
  %372 = xor i32 %370, 27
  %373 = icmp eq i32 %371, 0
  %a.9.in.4 = select i1 %373, i32 %370, i32 %372
  %374 = shl i32 %a.9.in.4, 1
  %375 = and i32 %a.9.in.4, 128
  %376 = xor i32 %374, 27
  %377 = icmp eq i32 %375, 0
  %a.9.in.5 = select i1 %377, i32 %374, i32 %376
  %378 = shl i32 %a.9.in.5, 1
  %379 = lshr i8 %351, 1
  %380 = zext i8 %379 to i32
  %381 = zext i8 %351 to i32
  %382 = lshr i8 %351, 2
  %383 = lshr i8 %351, 3
  %384 = and i32 %380, 1
  %385 = and i32 %381, 1
  %386 = zext i8 %382 to i32
  %387 = zext i8 %383 to i32
  %388 = icmp eq i32 %384, 0
  %a.9 = trunc i32 %a.9.in to i8
  %389 = icmp eq i32 %385, 0
  %390 = and i32 %386, 1
  %391 = lshr i8 %351, 4
  %392 = lshr i8 %351, 5
  %393 = and i32 %387, 1
  %394 = select i1 %388, i8 0, i8 %a.9
  %395 = select i1 %389, i8 0, i8 %352
  %a.9.1 = trunc i32 %a.9.in.1 to i8
  %396 = icmp eq i32 %390, 0
  %397 = zext i8 %391 to i32
  %398 = zext i8 %392 to i32
  %399 = icmp eq i32 %393, 0
  %a.9.2 = trunc i32 %a.9.in.2 to i8
  %p.9..1 = xor i8 %394, %395
  %400 = select i1 %396, i8 0, i8 %a.9.1
  %401 = and i32 %397, 1
  %402 = lshr i8 %351, 6
  %403 = and i32 %a.9.in.5, 128
  %404 = and i32 %398, 1
  %405 = select i1 %399, i8 0, i8 %a.9.2
  %p.9..2 = xor i8 %400, %p.9..1
  %a.9.3 = trunc i32 %a.9.in.3 to i8
  %406 = icmp eq i32 %401, 0
  %407 = zext i8 %402 to i32
  %408 = icmp eq i32 %403, 0
  %409 = xor i32 %378, 27
  %410 = icmp eq i32 %404, 0
  %a.9.4 = trunc i32 %a.9.in.4 to i8
  %p.9..3 = xor i8 %405, %p.9..2
  %411 = select i1 %406, i8 0, i8 %a.9.3
  %412 = and i32 %407, 1
  %a.9.in.6 = select i1 %408, i32 %378, i32 %409
  %413 = select i1 %410, i8 0, i8 %a.9.4
  %p.9..4 = xor i8 %411, %p.9..3
  %a.9.5 = trunc i32 %a.9.in.5 to i8
  %414 = icmp eq i32 %412, 0
  %415 = icmp sgt i8 %351, -1
  %a.9.6 = trunc i32 %a.9.in.6 to i8
  %p.9..5 = xor i8 %413, %p.9..4
  %416 = select i1 %414, i8 0, i8 %a.9.5
  %417 = select i1 %415, i8 0, i8 %a.9.6
  %p.9..6 = xor i8 %416, %p.9..5
  %p.9..7 = xor i8 %417, %p.9..6
  %418 = and i64 %tmp77, 3
  %419 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType332, i64 0, i64 %418
  %420 = load <4 x i8>* %419, align 4
  %421 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %422 = extractelement <4 x i8> %420, i32 0
  %423 = extractelement <4 x i8> %421, i32 1
  %424 = zext i8 %423 to i32
  %425 = shl i32 %424, 1
  %426 = and i32 %424, 128
  %427 = xor i32 %425, 27
  %428 = icmp eq i32 %426, 0
  %a.11.in = select i1 %428, i32 %425, i32 %427
  %429 = shl i32 %a.11.in, 1
  %430 = and i32 %a.11.in, 128
  %431 = xor i32 %429, 27
  %432 = icmp eq i32 %430, 0
  %a.11.in.1 = select i1 %432, i32 %429, i32 %431
  %433 = shl i32 %a.11.in.1, 1
  %434 = and i32 %a.11.in.1, 128
  %435 = xor i32 %433, 27
  %436 = icmp eq i32 %434, 0
  %a.11.in.2 = select i1 %436, i32 %433, i32 %435
  %437 = shl i32 %a.11.in.2, 1
  %438 = and i32 %a.11.in.2, 128
  %439 = xor i32 %437, 27
  %440 = icmp eq i32 %438, 0
  %a.11.in.3 = select i1 %440, i32 %437, i32 %439
  %441 = shl i32 %a.11.in.3, 1
  %442 = and i32 %a.11.in.3, 128
  %443 = xor i32 %441, 27
  %444 = icmp eq i32 %442, 0
  %a.11.in.4 = select i1 %444, i32 %441, i32 %443
  %445 = shl i32 %a.11.in.4, 1
  %446 = and i32 %a.11.in.4, 128
  %447 = xor i32 %445, 27
  %448 = icmp eq i32 %446, 0
  %a.11.in.5 = select i1 %448, i32 %445, i32 %447
  %449 = shl i32 %a.11.in.5, 1
  %450 = lshr i8 %422, 1
  %451 = zext i8 %450 to i32
  %452 = zext i8 %422 to i32
  %453 = lshr i8 %422, 2
  %454 = lshr i8 %422, 3
  %455 = and i32 %451, 1
  %456 = and i32 %452, 1
  %457 = zext i8 %453 to i32
  %458 = zext i8 %454 to i32
  %459 = icmp eq i32 %455, 0
  %a.11 = trunc i32 %a.11.in to i8
  %460 = icmp eq i32 %456, 0
  %461 = and i32 %457, 1
  %462 = lshr i8 %422, 4
  %463 = lshr i8 %422, 5
  %464 = and i32 %458, 1
  %465 = select i1 %459, i8 0, i8 %a.11
  %466 = select i1 %460, i8 0, i8 %423
  %a.11.1 = trunc i32 %a.11.in.1 to i8
  %467 = icmp eq i32 %461, 0
  %468 = zext i8 %462 to i32
  %469 = zext i8 %463 to i32
  %470 = icmp eq i32 %464, 0
  %a.11.2 = trunc i32 %a.11.in.2 to i8
  %p.11..1 = xor i8 %465, %466
  %471 = select i1 %467, i8 0, i8 %a.11.1
  %472 = and i32 %468, 1
  %473 = lshr i8 %422, 6
  %474 = and i32 %a.11.in.5, 128
  %475 = and i32 %469, 1
  %476 = select i1 %470, i8 0, i8 %a.11.2
  %p.11..2 = xor i8 %471, %p.11..1
  %a.11.3 = trunc i32 %a.11.in.3 to i8
  %477 = icmp eq i32 %472, 0
  %478 = zext i8 %473 to i32
  %479 = icmp eq i32 %474, 0
  %480 = xor i32 %449, 27
  %481 = icmp eq i32 %475, 0
  %a.11.4 = trunc i32 %a.11.in.4 to i8
  %p.11..3 = xor i8 %476, %p.11..2
  %482 = select i1 %477, i8 0, i8 %a.11.3
  %483 = and i32 %478, 1
  %a.11.in.6 = select i1 %479, i32 %449, i32 %480
  %484 = select i1 %481, i8 0, i8 %a.11.4
  %p.11..4 = xor i8 %482, %p.11..3
  %a.11.5 = trunc i32 %a.11.in.5 to i8
  %485 = icmp eq i32 %483, 0
  %486 = icmp sgt i8 %422, -1
  %a.11.6 = trunc i32 %a.11.in.6 to i8
  %p.11..5 = xor i8 %484, %p.11..4
  %487 = select i1 %485, i8 0, i8 %a.11.5
  %488 = select i1 %486, i8 0, i8 %a.11.6
  %p.11..6 = xor i8 %487, %p.11..5
  %p.11..7 = xor i8 %488, %p.11..6
  %489 = and i64 %tmp77, 3
  %490 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType328, i64 0, i64 %489
  %491 = load <4 x i8>* %490, align 4
  %492 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %493 = extractelement <4 x i8> %491, i32 0
  %494 = extractelement <4 x i8> %492, i32 2
  %495 = zext i8 %494 to i32
  %496 = shl i32 %495, 1
  %497 = and i32 %495, 128
  %498 = xor i32 %496, 27
  %499 = icmp eq i32 %497, 0
  %a.13.in = select i1 %499, i32 %496, i32 %498
  %500 = shl i32 %a.13.in, 1
  %501 = and i32 %a.13.in, 128
  %502 = xor i32 %500, 27
  %503 = icmp eq i32 %501, 0
  %a.13.in.1 = select i1 %503, i32 %500, i32 %502
  %504 = shl i32 %a.13.in.1, 1
  %505 = and i32 %a.13.in.1, 128
  %506 = xor i32 %504, 27
  %507 = icmp eq i32 %505, 0
  %a.13.in.2 = select i1 %507, i32 %504, i32 %506
  %508 = shl i32 %a.13.in.2, 1
  %509 = and i32 %a.13.in.2, 128
  %510 = xor i32 %508, 27
  %511 = icmp eq i32 %509, 0
  %a.13.in.3 = select i1 %511, i32 %508, i32 %510
  %512 = shl i32 %a.13.in.3, 1
  %513 = and i32 %a.13.in.3, 128
  %514 = xor i32 %512, 27
  %515 = icmp eq i32 %513, 0
  %a.13.in.4 = select i1 %515, i32 %512, i32 %514
  %516 = shl i32 %a.13.in.4, 1
  %517 = and i32 %a.13.in.4, 128
  %518 = xor i32 %516, 27
  %519 = icmp eq i32 %517, 0
  %a.13.in.5 = select i1 %519, i32 %516, i32 %518
  %520 = shl i32 %a.13.in.5, 1
  %521 = lshr i8 %493, 1
  %522 = zext i8 %521 to i32
  %523 = zext i8 %493 to i32
  %524 = lshr i8 %493, 2
  %525 = lshr i8 %493, 3
  %526 = and i32 %522, 1
  %527 = and i32 %523, 1
  %528 = zext i8 %524 to i32
  %529 = zext i8 %525 to i32
  %530 = icmp eq i32 %526, 0
  %a.13 = trunc i32 %a.13.in to i8
  %531 = icmp eq i32 %527, 0
  %532 = and i32 %528, 1
  %533 = lshr i8 %493, 4
  %534 = lshr i8 %493, 5
  %535 = and i32 %529, 1
  %536 = select i1 %530, i8 0, i8 %a.13
  %537 = select i1 %531, i8 0, i8 %494
  %a.13.1 = trunc i32 %a.13.in.1 to i8
  %538 = icmp eq i32 %532, 0
  %539 = zext i8 %533 to i32
  %540 = zext i8 %534 to i32
  %541 = icmp eq i32 %535, 0
  %a.13.2 = trunc i32 %a.13.in.2 to i8
  %p.13..1 = xor i8 %536, %537
  %542 = select i1 %538, i8 0, i8 %a.13.1
  %543 = and i32 %539, 1
  %544 = lshr i8 %493, 6
  %545 = and i32 %a.13.in.5, 128
  %546 = and i32 %540, 1
  %547 = select i1 %541, i8 0, i8 %a.13.2
  %p.13..2 = xor i8 %542, %p.13..1
  %a.13.3 = trunc i32 %a.13.in.3 to i8
  %548 = icmp eq i32 %543, 0
  %549 = zext i8 %544 to i32
  %550 = icmp eq i32 %545, 0
  %551 = xor i32 %520, 27
  %552 = icmp eq i32 %546, 0
  %a.13.4 = trunc i32 %a.13.in.4 to i8
  %p.13..3 = xor i8 %547, %p.13..2
  %553 = select i1 %548, i8 0, i8 %a.13.3
  %554 = and i32 %549, 1
  %a.13.in.6 = select i1 %550, i32 %520, i32 %551
  %555 = select i1 %552, i8 0, i8 %a.13.4
  %p.13..4 = xor i8 %553, %p.13..3
  %a.13.5 = trunc i32 %a.13.in.5 to i8
  %556 = icmp eq i32 %554, 0
  %557 = icmp sgt i8 %493, -1
  %a.13.6 = trunc i32 %a.13.in.6 to i8
  %p.13..5 = xor i8 %555, %p.13..4
  %558 = select i1 %556, i8 0, i8 %a.13.5
  %559 = select i1 %557, i8 0, i8 %a.13.6
  %p.13..6 = xor i8 %558, %p.13..5
  %p.13..7 = xor i8 %559, %p.13..6
  %560 = and i64 %tmp77, 3
  %561 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType324, i64 0, i64 %560
  %562 = load <4 x i8>* %561, align 4
  %563 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %564 = extractelement <4 x i8> %562, i32 0
  %565 = extractelement <4 x i8> %563, i32 3
  %566 = zext i8 %565 to i32
  %567 = shl i32 %566, 1
  %568 = and i32 %566, 128
  %569 = xor i32 %567, 27
  %570 = icmp eq i32 %568, 0
  %a.15.in = select i1 %570, i32 %567, i32 %569
  %571 = shl i32 %a.15.in, 1
  %572 = and i32 %a.15.in, 128
  %573 = xor i32 %571, 27
  %574 = icmp eq i32 %572, 0
  %a.15.in.1 = select i1 %574, i32 %571, i32 %573
  %575 = shl i32 %a.15.in.1, 1
  %576 = and i32 %a.15.in.1, 128
  %577 = xor i32 %575, 27
  %578 = icmp eq i32 %576, 0
  %a.15.in.2 = select i1 %578, i32 %575, i32 %577
  %579 = shl i32 %a.15.in.2, 1
  %580 = and i32 %a.15.in.2, 128
  %581 = xor i32 %579, 27
  %582 = icmp eq i32 %580, 0
  %a.15.in.3 = select i1 %582, i32 %579, i32 %581
  %583 = shl i32 %a.15.in.3, 1
  %584 = and i32 %a.15.in.3, 128
  %585 = xor i32 %583, 27
  %586 = icmp eq i32 %584, 0
  %a.15.in.4 = select i1 %586, i32 %583, i32 %585
  %587 = shl i32 %a.15.in.4, 1
  %588 = and i32 %a.15.in.4, 128
  %589 = xor i32 %587, 27
  %590 = icmp eq i32 %588, 0
  %a.15.in.5 = select i1 %590, i32 %587, i32 %589
  %591 = shl i32 %a.15.in.5, 1
  %592 = lshr i8 %564, 1
  %593 = zext i8 %592 to i32
  %594 = zext i8 %564 to i32
  %595 = lshr i8 %564, 2
  %596 = lshr i8 %564, 3
  %597 = and i32 %593, 1
  %598 = and i32 %594, 1
  %599 = zext i8 %595 to i32
  %600 = zext i8 %596 to i32
  %601 = icmp eq i32 %597, 0
  %a.15 = trunc i32 %a.15.in to i8
  %602 = icmp eq i32 %598, 0
  %603 = and i32 %599, 1
  %604 = lshr i8 %564, 4
  %605 = lshr i8 %564, 5
  %606 = and i32 %600, 1
  %607 = select i1 %601, i8 0, i8 %a.15
  %608 = select i1 %602, i8 0, i8 %565
  %a.15.1 = trunc i32 %a.15.in.1 to i8
  %609 = icmp eq i32 %603, 0
  %610 = zext i8 %604 to i32
  %611 = zext i8 %605 to i32
  %612 = icmp eq i32 %606, 0
  %a.15.2 = trunc i32 %a.15.in.2 to i8
  %p.15..1 = xor i8 %607, %608
  %613 = select i1 %609, i8 0, i8 %a.15.1
  %614 = and i32 %610, 1
  %615 = lshr i8 %564, 6
  %616 = and i32 %a.15.in.5, 128
  %617 = and i32 %611, 1
  %618 = select i1 %612, i8 0, i8 %a.15.2
  %p.15..2 = xor i8 %613, %p.15..1
  %a.15.3 = trunc i32 %a.15.in.3 to i8
  %619 = icmp eq i32 %614, 0
  %620 = zext i8 %615 to i32
  %621 = icmp eq i32 %616, 0
  %622 = xor i32 %591, 27
  %623 = icmp eq i32 %617, 0
  %a.15.4 = trunc i32 %a.15.in.4 to i8
  %p.15..3 = xor i8 %618, %p.15..2
  %624 = select i1 %619, i8 0, i8 %a.15.3
  %625 = and i32 %620, 1
  %a.15.in.6 = select i1 %621, i32 %591, i32 %622
  %626 = select i1 %623, i8 0, i8 %a.15.4
  %p.15..4 = xor i8 %624, %p.15..3
  %a.15.5 = trunc i32 %a.15.in.5 to i8
  %627 = icmp eq i32 %625, 0
  %628 = icmp sgt i8 %564, -1
  %a.15.6 = trunc i32 %a.15.in.6 to i8
  %p.15..5 = xor i8 %626, %p.15..4
  %629 = select i1 %627, i8 0, i8 %a.15.5
  %630 = select i1 %628, i8 0, i8 %a.15.6
  %p.15..6 = xor i8 %629, %p.15..5
  %p.15..7 = xor i8 %630, %p.15..6
  %631 = xor i8 %p.9..7, %x.060
  store i8 %631, i8* %"&pSB[currWI].offset279", align 1
  %632 = xor i8 %p.11..7, %y.061
  store i8 %632, i8* %"&pSB[currWI].offset288", align 1
  %633 = xor i8 %p.13..7, %z.062
  store i8 %633, i8* %"&pSB[currWI].offset297", align 1
  %634 = xor i8 %p.15..7, %w.063
  store i8 %634, i8* %"&pSB[currWI].offset306", align 1
  %exitcond = icmp eq i64 %tmp, 3
  br i1 %exitcond, label %._crit_edge66, label %346

._crit_edge66:                                    ; preds = %346
  %"&(pSB[currWI].offset)282" = add nuw i64 %CurrSBIndex..1, 232
  %"&pSB[currWI].offset283" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)282"
  %loadedValue285 = load i8* %"&pSB[currWI].offset283", align 1
  %635 = insertelement <4 x i8> undef, i8 %loadedValue285, i32 0
  %"&(pSB[currWI].offset)291" = add nuw i64 %CurrSBIndex..1, 233
  %"&pSB[currWI].offset292" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)291"
  %loadedValue294 = load i8* %"&pSB[currWI].offset292", align 1
  %636 = insertelement <4 x i8> %635, i8 %loadedValue294, i32 1
  %"&(pSB[currWI].offset)300" = add nuw i64 %CurrSBIndex..1, 234
  %"&pSB[currWI].offset301" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)300"
  %loadedValue303 = load i8* %"&pSB[currWI].offset301", align 1
  %637 = insertelement <4 x i8> %636, i8 %loadedValue303, i32 2
  %"&(pSB[currWI].offset)309" = add nuw i64 %CurrSBIndex..1, 235
  %"&pSB[currWI].offset310" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)309"
  %loadedValue312 = load i8* %"&pSB[currWI].offset310", align 1
  %638 = insertelement <4 x i8> %637, i8 %loadedValue312, i32 3
  %"&(pSB[currWI].offset)314" = add nuw i64 %CurrSBIndex..1, 236
  %"&pSB[currWI].offset315" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)314"
  %CastToValueType316 = bitcast i8* %"&pSB[currWI].offset315" to <4 x i8>*
  store <4 x i8> %638, <4 x i8>* %CastToValueType316, align 4
  %"&(pSB[currWI].offset)124" = add nuw i64 %CurrSBIndex..1, 152
  %"&pSB[currWI].offset125" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)124"
  %CastToValueType126 = bitcast i8* %"&pSB[currWI].offset125" to <4 x i8> addrspace(3)**
  %loadedValue127 = load <4 x i8> addrspace(3)** %CastToValueType126, align 8
  store <4 x i8> %638, <4 x i8> addrspace(3)* %loadedValue127, align 4
  %"&(pSB[currWI].offset)213" = add nuw i64 %CurrSBIndex..1, 196
  %"&pSB[currWI].offset214" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)213"
  %CastToValueType215 = bitcast i8* %"&pSB[currWI].offset214" to i32*
  %loadedValue216 = load i32* %CastToValueType215, align 4
  %indvar.next80 = add i32 %loadedValue216, 1
  %"&(pSB[currWI].offset)318" = add nuw i64 %CurrSBIndex..1, 240
  %"&pSB[currWI].offset319" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)318"
  %CastToValueType320 = bitcast i8* %"&pSB[currWI].offset319" to i32*
  store i32 %indvar.next80, i32* %CastToValueType320, align 4
  br label %36

"Barrier BB91":                                   ; preds = %shiftRowsInv.exit
  %"&(pSB[currWI].offset)115" = add nuw i64 %CurrSBIndex..2, 144
  %"&pSB[currWI].offset116" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)115"
  %CastToValueType117 = bitcast i8* %"&pSB[currWI].offset116" to i64*
  %loadedValue118 = load i64* %CastToValueType117, align 8
  %639 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %loadedValue118
  %640 = load <4 x i8> addrspace(1)* %639, align 4
  %"&(pSB[currWI].offset)244" = add nuw i64 %CurrSBIndex..2, 212
  %"&pSB[currWI].offset245" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)244"
  %CastToValueType246 = bitcast i8* %"&pSB[currWI].offset245" to <4 x i8>*
  %loadedValue247 = load <4 x i8>* %CastToValueType246, align 4
  %641 = xor <4 x i8> %loadedValue247, %640
  %"&(pSB[currWI].offset)106" = add nuw i64 %CurrSBIndex..2, 136
  %"&pSB[currWI].offset107" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)106"
  %CastToValueType108 = bitcast i8* %"&pSB[currWI].offset107" to i64*
  %loadedValue109 = load i64* %CastToValueType108, align 8
  %642 = getelementptr inbounds <4 x i8> addrspace(1)* %output, i64 %loadedValue109
  store <4 x i8> %641, <4 x i8> addrspace(1)* %642, align 4
  %check.WI.iter373 = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter373, label %thenBB370, label %SyncBB360

thenBB370:                                        ; preds = %"Barrier BB91"
  %"CurrWI++374" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride376" = add nuw i64 %CurrSBIndex..2, 1712
  %cond1 = icmp eq i32 %currBarrier.1, 4
  br i1 %cond1, label %SyncBB359, label %SyncBB361

SyncBB360:                                        ; preds = %"Barrier BB91"
  ret void
}

define void @____Vectorized_.AESEncrypt_separated_args(<4 x i8> addrspace(1)* nocapture %output, <4 x i8> addrspace(1)* nocapture %input, <4 x i8> addrspace(1)* nocapture %roundKey, i8 addrspace(1)* nocapture %SBox, <4 x i8> addrspace(3)* nocapture %block0, <4 x i8> addrspace(3)* nocapture %block1, i32 %width, i32 %rounds, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind alwaysinline {
FirstBB:
  %tmp81 = icmp ugt i32 %rounds, 1
  %rounds.op = add i32 %rounds, -1
  %tmp82 = select i1 %tmp81, i32 %rounds.op, i32 0
  %0 = shl i32 %rounds, 2
  br label %SyncBB1715

SyncBB1715:                                       ; preds = %thenBB, %thenBB1726, %FirstBB
  %CurrSBIndex..0 = phi i64 [ 0, %FirstBB ], [ %"loadedCurrSB+Stride1732", %thenBB1726 ], [ %"loadedCurrSB+Stride", %thenBB ]
  %currBarrier.2 = phi i32 [ 14, %FirstBB ], [ %currBarrier.1, %thenBB1726 ], [ %currBarrier.1, %thenBB ]
  %CurrWI..0 = phi i64 [ 0, %FirstBB ], [ %"CurrWI++1730", %thenBB1726 ], [ %"CurrWI++", %thenBB ]
  %1 = load i64* %pWGId, align 8
  %2 = trunc i64 %1 to i32
  %3 = getelementptr i64* %pWGId, i64 1
  %4 = load i64* %3, align 8
  %5 = trunc i64 %4 to i32
  %6 = getelementptr %struct.PaddedDimId* %pLocalIds, i64 %CurrWI..0, i32 0, i64 1
  %7 = load i64* %6, align 8
  %8 = trunc i64 %7 to i32
  %"&(pSB[currWI].offset)" = add nuw i64 %CurrSBIndex..0, 272
  %"&pSB[currWI].offset" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)"
  %CastToValueType = bitcast i8* %"&pSB[currWI].offset" to i32*
  store i32 %8, i32* %CastToValueType, align 4
  %9 = mul i32 %5, %width
  %10 = shl i32 %2, 2
  %11 = add i32 %9, %10
  %12 = and i32 %11, -4
  %13 = add i32 %12, %8
  %"&(pSB[currWI].offset)1170" = add nuw i64 %CurrSBIndex..0, 640
  %"&pSB[currWI].offset1171" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1170"
  %14 = bitcast i8* %"&pSB[currWI].offset1171" to <4 x i8>*
  %"&(pSB[currWI].offset)1206" = add nuw i64 %CurrSBIndex..0, 656
  %"&pSB[currWI].offset1207" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1206"
  %15 = bitcast i8* %"&pSB[currWI].offset1207" to <4 x i8>*
  %"&(pSB[currWI].offset)1242" = add nuw i64 %CurrSBIndex..0, 672
  %"&pSB[currWI].offset1243" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1242"
  %16 = bitcast i8* %"&pSB[currWI].offset1243" to <4 x i8>*
  %"&(pSB[currWI].offset)1278" = add nuw i64 %CurrSBIndex..0, 688
  %"&pSB[currWI].offset1279" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1278"
  %17 = bitcast i8* %"&pSB[currWI].offset1279" to <4 x i8>*
  %"&(pSB[currWI].offset)1314" = add nuw i64 %CurrSBIndex..0, 704
  %"&pSB[currWI].offset1315" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1314"
  %18 = bitcast i8* %"&pSB[currWI].offset1315" to <4 x i8>*
  %"&(pSB[currWI].offset)1350" = add nuw i64 %CurrSBIndex..0, 720
  %"&pSB[currWI].offset1351" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1350"
  %19 = bitcast i8* %"&pSB[currWI].offset1351" to <4 x i8>*
  %"&(pSB[currWI].offset)1386" = add nuw i64 %CurrSBIndex..0, 736
  %"&pSB[currWI].offset1387" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1386"
  %20 = bitcast i8* %"&pSB[currWI].offset1387" to <4 x i8>*
  %"&(pSB[currWI].offset)1422" = add nuw i64 %CurrSBIndex..0, 752
  %"&pSB[currWI].offset1423" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1422"
  %21 = bitcast i8* %"&pSB[currWI].offset1423" to <4 x i8>*
  %"&(pSB[currWI].offset)1458" = add nuw i64 %CurrSBIndex..0, 768
  %"&pSB[currWI].offset1459" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1458"
  %22 = bitcast i8* %"&pSB[currWI].offset1459" to <4 x i8>*
  %"&(pSB[currWI].offset)1494" = add nuw i64 %CurrSBIndex..0, 784
  %"&pSB[currWI].offset1495" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1494"
  %23 = bitcast i8* %"&pSB[currWI].offset1495" to <4 x i8>*
  %"&(pSB[currWI].offset)1530" = add nuw i64 %CurrSBIndex..0, 800
  %"&pSB[currWI].offset1531" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1530"
  %24 = bitcast i8* %"&pSB[currWI].offset1531" to <4 x i8>*
  %"&(pSB[currWI].offset)1566" = add nuw i64 %CurrSBIndex..0, 816
  %"&pSB[currWI].offset1567" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1566"
  %25 = bitcast i8* %"&pSB[currWI].offset1567" to <4 x i8>*
  %"&(pSB[currWI].offset)1602" = add nuw i64 %CurrSBIndex..0, 832
  %"&pSB[currWI].offset1603" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1602"
  %26 = bitcast i8* %"&pSB[currWI].offset1603" to <4 x i8>*
  %"&(pSB[currWI].offset)1638" = add nuw i64 %CurrSBIndex..0, 848
  %"&pSB[currWI].offset1639" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1638"
  %27 = bitcast i8* %"&pSB[currWI].offset1639" to <4 x i8>*
  %"&(pSB[currWI].offset)1674" = add nuw i64 %CurrSBIndex..0, 864
  %"&pSB[currWI].offset1675" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1674"
  %28 = bitcast i8* %"&pSB[currWI].offset1675" to <4 x i8>*
  %"&(pSB[currWI].offset)1710" = add nuw i64 %CurrSBIndex..0, 880
  %"&pSB[currWI].offset1711" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1710"
  %29 = bitcast i8* %"&pSB[currWI].offset1711" to <4 x i8>*
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %14, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %15, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %16, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %17, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %18, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %19, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %20, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %21, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %22, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %23, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %24, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %25, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %26, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %27, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %28, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %29, align 16
  %"&pSB[currWI].offset1167.sum" = add i64 %CurrSBIndex..0, 644
  %30 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1167.sum"
  %31 = bitcast i8* %30 to <4 x i8>*
  %"&pSB[currWI].offset1203.sum" = add i64 %CurrSBIndex..0, 660
  %32 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1203.sum"
  %33 = bitcast i8* %32 to <4 x i8>*
  %"&pSB[currWI].offset1239.sum" = add i64 %CurrSBIndex..0, 676
  %34 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1239.sum"
  %35 = bitcast i8* %34 to <4 x i8>*
  %"&pSB[currWI].offset1275.sum" = add i64 %CurrSBIndex..0, 692
  %36 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1275.sum"
  %37 = bitcast i8* %36 to <4 x i8>*
  %"&pSB[currWI].offset1311.sum" = add i64 %CurrSBIndex..0, 708
  %38 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1311.sum"
  %39 = bitcast i8* %38 to <4 x i8>*
  %"&pSB[currWI].offset1347.sum" = add i64 %CurrSBIndex..0, 724
  %40 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1347.sum"
  %41 = bitcast i8* %40 to <4 x i8>*
  %"&pSB[currWI].offset1383.sum" = add i64 %CurrSBIndex..0, 740
  %42 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1383.sum"
  %43 = bitcast i8* %42 to <4 x i8>*
  %"&pSB[currWI].offset1419.sum" = add i64 %CurrSBIndex..0, 756
  %44 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1419.sum"
  %45 = bitcast i8* %44 to <4 x i8>*
  %"&pSB[currWI].offset1455.sum" = add i64 %CurrSBIndex..0, 772
  %46 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1455.sum"
  %47 = bitcast i8* %46 to <4 x i8>*
  %"&pSB[currWI].offset1491.sum" = add i64 %CurrSBIndex..0, 788
  %48 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1491.sum"
  %49 = bitcast i8* %48 to <4 x i8>*
  %"&pSB[currWI].offset1527.sum" = add i64 %CurrSBIndex..0, 804
  %50 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1527.sum"
  %51 = bitcast i8* %50 to <4 x i8>*
  %"&pSB[currWI].offset1563.sum" = add i64 %CurrSBIndex..0, 820
  %52 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1563.sum"
  %53 = bitcast i8* %52 to <4 x i8>*
  %"&pSB[currWI].offset1599.sum" = add i64 %CurrSBIndex..0, 836
  %54 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1599.sum"
  %55 = bitcast i8* %54 to <4 x i8>*
  %"&pSB[currWI].offset1635.sum" = add i64 %CurrSBIndex..0, 852
  %56 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1635.sum"
  %57 = bitcast i8* %56 to <4 x i8>*
  %"&pSB[currWI].offset1671.sum" = add i64 %CurrSBIndex..0, 868
  %58 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1671.sum"
  %59 = bitcast i8* %58 to <4 x i8>*
  %"&pSB[currWI].offset1707.sum" = add i64 %CurrSBIndex..0, 884
  %60 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1707.sum"
  %61 = bitcast i8* %60 to <4 x i8>*
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %31, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %33, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %35, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %37, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %39, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %41, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %43, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %45, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %47, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %57, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %59, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %61, align 4
  %"&pSB[currWI].offset1163.sum" = add i64 %CurrSBIndex..0, 648
  %62 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1163.sum"
  %63 = bitcast i8* %62 to <4 x i8>*
  %"&pSB[currWI].offset1199.sum" = add i64 %CurrSBIndex..0, 664
  %64 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1199.sum"
  %65 = bitcast i8* %64 to <4 x i8>*
  %"&pSB[currWI].offset1235.sum" = add i64 %CurrSBIndex..0, 680
  %66 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1235.sum"
  %67 = bitcast i8* %66 to <4 x i8>*
  %"&pSB[currWI].offset1271.sum" = add i64 %CurrSBIndex..0, 696
  %68 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1271.sum"
  %69 = bitcast i8* %68 to <4 x i8>*
  %"&pSB[currWI].offset1307.sum" = add i64 %CurrSBIndex..0, 712
  %70 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1307.sum"
  %71 = bitcast i8* %70 to <4 x i8>*
  %"&pSB[currWI].offset1343.sum" = add i64 %CurrSBIndex..0, 728
  %72 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1343.sum"
  %73 = bitcast i8* %72 to <4 x i8>*
  %"&pSB[currWI].offset1379.sum" = add i64 %CurrSBIndex..0, 744
  %74 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1379.sum"
  %75 = bitcast i8* %74 to <4 x i8>*
  %"&pSB[currWI].offset1415.sum" = add i64 %CurrSBIndex..0, 760
  %76 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1415.sum"
  %77 = bitcast i8* %76 to <4 x i8>*
  %"&pSB[currWI].offset1451.sum" = add i64 %CurrSBIndex..0, 776
  %78 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1451.sum"
  %79 = bitcast i8* %78 to <4 x i8>*
  %"&pSB[currWI].offset1487.sum" = add i64 %CurrSBIndex..0, 792
  %80 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1487.sum"
  %81 = bitcast i8* %80 to <4 x i8>*
  %"&pSB[currWI].offset1523.sum" = add i64 %CurrSBIndex..0, 808
  %82 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1523.sum"
  %83 = bitcast i8* %82 to <4 x i8>*
  %"&pSB[currWI].offset1559.sum" = add i64 %CurrSBIndex..0, 824
  %84 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1559.sum"
  %85 = bitcast i8* %84 to <4 x i8>*
  %"&pSB[currWI].offset1595.sum" = add i64 %CurrSBIndex..0, 840
  %86 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1595.sum"
  %87 = bitcast i8* %86 to <4 x i8>*
  %"&pSB[currWI].offset1631.sum" = add i64 %CurrSBIndex..0, 856
  %88 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1631.sum"
  %89 = bitcast i8* %88 to <4 x i8>*
  %"&pSB[currWI].offset1667.sum" = add i64 %CurrSBIndex..0, 872
  %90 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1667.sum"
  %91 = bitcast i8* %90 to <4 x i8>*
  %"&pSB[currWI].offset1703.sum" = add i64 %CurrSBIndex..0, 888
  %92 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1703.sum"
  %93 = bitcast i8* %92 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %63, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %65, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %67, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %69, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %71, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %73, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %75, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %77, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %79, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %81, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %83, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %85, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %87, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %89, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %91, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %93, align 8
  %"&pSB[currWI].offset1159.sum" = add i64 %CurrSBIndex..0, 652
  %94 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1159.sum"
  %95 = bitcast i8* %94 to <4 x i8>*
  %"&pSB[currWI].offset1195.sum" = add i64 %CurrSBIndex..0, 668
  %96 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1195.sum"
  %97 = bitcast i8* %96 to <4 x i8>*
  %"&pSB[currWI].offset1231.sum" = add i64 %CurrSBIndex..0, 684
  %98 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1231.sum"
  %99 = bitcast i8* %98 to <4 x i8>*
  %"&pSB[currWI].offset1267.sum" = add i64 %CurrSBIndex..0, 700
  %100 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1267.sum"
  %101 = bitcast i8* %100 to <4 x i8>*
  %"&pSB[currWI].offset1303.sum" = add i64 %CurrSBIndex..0, 716
  %102 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1303.sum"
  %103 = bitcast i8* %102 to <4 x i8>*
  %"&pSB[currWI].offset1339.sum" = add i64 %CurrSBIndex..0, 732
  %104 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1339.sum"
  %105 = bitcast i8* %104 to <4 x i8>*
  %"&pSB[currWI].offset1375.sum" = add i64 %CurrSBIndex..0, 748
  %106 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1375.sum"
  %107 = bitcast i8* %106 to <4 x i8>*
  %"&pSB[currWI].offset1411.sum" = add i64 %CurrSBIndex..0, 764
  %108 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1411.sum"
  %109 = bitcast i8* %108 to <4 x i8>*
  %"&pSB[currWI].offset1447.sum" = add i64 %CurrSBIndex..0, 780
  %110 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1447.sum"
  %111 = bitcast i8* %110 to <4 x i8>*
  %"&pSB[currWI].offset1483.sum" = add i64 %CurrSBIndex..0, 796
  %112 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1483.sum"
  %113 = bitcast i8* %112 to <4 x i8>*
  %"&pSB[currWI].offset1519.sum" = add i64 %CurrSBIndex..0, 812
  %114 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1519.sum"
  %115 = bitcast i8* %114 to <4 x i8>*
  %"&pSB[currWI].offset1555.sum" = add i64 %CurrSBIndex..0, 828
  %116 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1555.sum"
  %117 = bitcast i8* %116 to <4 x i8>*
  %"&pSB[currWI].offset1591.sum" = add i64 %CurrSBIndex..0, 844
  %118 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1591.sum"
  %119 = bitcast i8* %118 to <4 x i8>*
  %"&pSB[currWI].offset1627.sum" = add i64 %CurrSBIndex..0, 860
  %120 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1627.sum"
  %121 = bitcast i8* %120 to <4 x i8>*
  %"&pSB[currWI].offset1663.sum" = add i64 %CurrSBIndex..0, 876
  %122 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1663.sum"
  %123 = bitcast i8* %122 to <4 x i8>*
  %"&pSB[currWI].offset1699.sum" = add i64 %CurrSBIndex..0, 892
  %124 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1699.sum"
  %125 = bitcast i8* %124 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %95, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %97, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %99, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %101, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %103, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %105, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %107, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %109, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %111, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %113, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %115, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %117, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %119, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %121, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %123, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %125, align 4
  %126 = zext i32 %13 to i64
  %"&(pSB[currWI].offset)524" = add nuw i64 %CurrSBIndex..0, 280
  %"&pSB[currWI].offset525" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)524"
  %CastToValueType526 = bitcast i8* %"&pSB[currWI].offset525" to i64*
  store i64 %126, i64* %CastToValueType526, align 8
  %127 = getelementptr inbounds <4 x i8> addrspace(1)* %input, i64 %126
  %128 = load <4 x i8> addrspace(1)* %127, align 4
  %scalar = extractelement <4 x i8> %128, i32 0
  %scalar2 = extractelement <4 x i8> %128, i32 1
  %scalar3 = extractelement <4 x i8> %128, i32 2
  %scalar4 = extractelement <4 x i8> %128, i32 3
  %129 = and i64 %7, 4294967295
  %130 = getelementptr inbounds <4 x i8> addrspace(3)* %block0, i64 %129
  %"&(pSB[currWI].offset)533" = add nuw i64 %CurrSBIndex..0, 288
  %"&pSB[currWI].offset534" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)533"
  %CastToValueType535 = bitcast i8* %"&pSB[currWI].offset534" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %130, <4 x i8> addrspace(3)** %CastToValueType535, align 8
  store <4 x i8> %128, <4 x i8> addrspace(3)* %130, align 4
  %131 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %129
  %132 = load <4 x i8> addrspace(1)* %131, align 4
  %scalar5 = extractelement <4 x i8> %132, i32 0
  %scalar6 = extractelement <4 x i8> %132, i32 1
  %scalar7 = extractelement <4 x i8> %132, i32 2
  %scalar8 = extractelement <4 x i8> %132, i32 3
  %133 = xor i8 %scalar, %scalar5
  %"&(pSB[currWI].offset)547" = add nuw i64 %CurrSBIndex..0, 296
  %"&pSB[currWI].offset548" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)547"
  store i8 %133, i8* %"&pSB[currWI].offset548", align 1
  %134 = xor i8 %scalar2, %scalar6
  %"&(pSB[currWI].offset)551" = add nuw i64 %CurrSBIndex..0, 297
  %"&pSB[currWI].offset552" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)551"
  store i8 %134, i8* %"&pSB[currWI].offset552", align 1
  %135 = xor i8 %scalar3, %scalar7
  %"&(pSB[currWI].offset)555" = add nuw i64 %CurrSBIndex..0, 298
  %"&pSB[currWI].offset556" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)555"
  store i8 %135, i8* %"&pSB[currWI].offset556", align 1
  %136 = xor i8 %scalar4, %scalar8
  %"&(pSB[currWI].offset)559" = add nuw i64 %CurrSBIndex..0, 299
  %"&pSB[currWI].offset560" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)559"
  store i8 %136, i8* %"&pSB[currWI].offset560", align 1
  %temp.vect = insertelement <4 x i8> undef, i8 %133, i32 0
  %temp.vect105 = insertelement <4 x i8> %temp.vect, i8 %134, i32 1
  %temp.vect106 = insertelement <4 x i8> %temp.vect105, i8 %135, i32 2
  %temp.vect107 = insertelement <4 x i8> %temp.vect106, i8 %136, i32 3
  store <4 x i8> %temp.vect107, <4 x i8> addrspace(3)* %130, align 4
  %137 = sub i32 0, %8
  %138 = and i32 %137, 3
  %139 = zext i32 %138 to i64
  %"&(pSB[currWI].offset)1154" = add nuw i64 %CurrSBIndex..0, 640
  %"&pSB[currWI].offset1155" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1154"
  %CastToValueType1156 = bitcast i8* %"&pSB[currWI].offset1155" to [4 x <4 x i8>]*
  %140 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1156, i64 0, i64 %139
  %"&(pSB[currWI].offset)563" = add nuw i64 %CurrSBIndex..0, 304
  %"&pSB[currWI].offset564" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)563"
  %CastToValueType565 = bitcast i8* %"&pSB[currWI].offset564" to <4 x i8>**
  store <4 x i8>* %140, <4 x i8>** %CastToValueType565, align 8
  %"&(pSB[currWI].offset)1190" = add nuw i64 %CurrSBIndex..0, 656
  %"&pSB[currWI].offset1191" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1190"
  %CastToValueType1192 = bitcast i8* %"&pSB[currWI].offset1191" to [4 x <4 x i8>]*
  %141 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1192, i64 0, i64 %139
  %"&(pSB[currWI].offset)587" = add nuw i64 %CurrSBIndex..0, 312
  %"&pSB[currWI].offset588" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)587"
  %CastToValueType589 = bitcast i8* %"&pSB[currWI].offset588" to <4 x i8>**
  store <4 x i8>* %141, <4 x i8>** %CastToValueType589, align 8
  %"&(pSB[currWI].offset)1226" = add nuw i64 %CurrSBIndex..0, 672
  %"&pSB[currWI].offset1227" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1226"
  %CastToValueType1228 = bitcast i8* %"&pSB[currWI].offset1227" to [4 x <4 x i8>]*
  %142 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1228, i64 0, i64 %139
  %"&(pSB[currWI].offset)611" = add nuw i64 %CurrSBIndex..0, 320
  %"&pSB[currWI].offset612" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)611"
  %CastToValueType613 = bitcast i8* %"&pSB[currWI].offset612" to <4 x i8>**
  store <4 x i8>* %142, <4 x i8>** %CastToValueType613, align 8
  %"&(pSB[currWI].offset)1262" = add nuw i64 %CurrSBIndex..0, 688
  %"&pSB[currWI].offset1263" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1262"
  %CastToValueType1264 = bitcast i8* %"&pSB[currWI].offset1263" to [4 x <4 x i8>]*
  %143 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1264, i64 0, i64 %139
  %"&(pSB[currWI].offset)635" = add nuw i64 %CurrSBIndex..0, 328
  %"&pSB[currWI].offset636" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)635"
  %CastToValueType637 = bitcast i8* %"&pSB[currWI].offset636" to <4 x i8>**
  store <4 x i8>* %143, <4 x i8>** %CastToValueType637, align 8
  %"&(pSB[currWI].offset)1298" = add nuw i64 %CurrSBIndex..0, 704
  %"&pSB[currWI].offset1299" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1298"
  %CastToValueType1300 = bitcast i8* %"&pSB[currWI].offset1299" to [4 x <4 x i8>]*
  %144 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1300, i64 0, i64 %139
  %"&(pSB[currWI].offset)659" = add nuw i64 %CurrSBIndex..0, 336
  %"&pSB[currWI].offset660" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)659"
  %CastToValueType661 = bitcast i8* %"&pSB[currWI].offset660" to <4 x i8>**
  store <4 x i8>* %144, <4 x i8>** %CastToValueType661, align 8
  %"&(pSB[currWI].offset)1334" = add nuw i64 %CurrSBIndex..0, 720
  %"&pSB[currWI].offset1335" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1334"
  %CastToValueType1336 = bitcast i8* %"&pSB[currWI].offset1335" to [4 x <4 x i8>]*
  %145 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1336, i64 0, i64 %139
  %"&(pSB[currWI].offset)683" = add nuw i64 %CurrSBIndex..0, 344
  %"&pSB[currWI].offset684" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)683"
  %CastToValueType685 = bitcast i8* %"&pSB[currWI].offset684" to <4 x i8>**
  store <4 x i8>* %145, <4 x i8>** %CastToValueType685, align 8
  %"&(pSB[currWI].offset)1370" = add nuw i64 %CurrSBIndex..0, 736
  %"&pSB[currWI].offset1371" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1370"
  %CastToValueType1372 = bitcast i8* %"&pSB[currWI].offset1371" to [4 x <4 x i8>]*
  %146 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1372, i64 0, i64 %139
  %"&(pSB[currWI].offset)707" = add nuw i64 %CurrSBIndex..0, 352
  %"&pSB[currWI].offset708" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)707"
  %CastToValueType709 = bitcast i8* %"&pSB[currWI].offset708" to <4 x i8>**
  store <4 x i8>* %146, <4 x i8>** %CastToValueType709, align 8
  %"&(pSB[currWI].offset)1406" = add nuw i64 %CurrSBIndex..0, 752
  %"&pSB[currWI].offset1407" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1406"
  %CastToValueType1408 = bitcast i8* %"&pSB[currWI].offset1407" to [4 x <4 x i8>]*
  %147 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1408, i64 0, i64 %139
  %"&(pSB[currWI].offset)731" = add nuw i64 %CurrSBIndex..0, 360
  %"&pSB[currWI].offset732" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)731"
  %CastToValueType733 = bitcast i8* %"&pSB[currWI].offset732" to <4 x i8>**
  store <4 x i8>* %147, <4 x i8>** %CastToValueType733, align 8
  %"&(pSB[currWI].offset)1442" = add nuw i64 %CurrSBIndex..0, 768
  %"&pSB[currWI].offset1443" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1442"
  %CastToValueType1444 = bitcast i8* %"&pSB[currWI].offset1443" to [4 x <4 x i8>]*
  %148 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1444, i64 0, i64 %139
  %"&(pSB[currWI].offset)755" = add nuw i64 %CurrSBIndex..0, 368
  %"&pSB[currWI].offset756" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)755"
  %CastToValueType757 = bitcast i8* %"&pSB[currWI].offset756" to <4 x i8>**
  store <4 x i8>* %148, <4 x i8>** %CastToValueType757, align 8
  %"&(pSB[currWI].offset)1478" = add nuw i64 %CurrSBIndex..0, 784
  %"&pSB[currWI].offset1479" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1478"
  %CastToValueType1480 = bitcast i8* %"&pSB[currWI].offset1479" to [4 x <4 x i8>]*
  %149 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1480, i64 0, i64 %139
  %"&(pSB[currWI].offset)779" = add nuw i64 %CurrSBIndex..0, 376
  %"&pSB[currWI].offset780" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)779"
  %CastToValueType781 = bitcast i8* %"&pSB[currWI].offset780" to <4 x i8>**
  store <4 x i8>* %149, <4 x i8>** %CastToValueType781, align 8
  %"&(pSB[currWI].offset)1514" = add nuw i64 %CurrSBIndex..0, 800
  %"&pSB[currWI].offset1515" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1514"
  %CastToValueType1516 = bitcast i8* %"&pSB[currWI].offset1515" to [4 x <4 x i8>]*
  %150 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1516, i64 0, i64 %139
  %"&(pSB[currWI].offset)803" = add nuw i64 %CurrSBIndex..0, 384
  %"&pSB[currWI].offset804" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)803"
  %CastToValueType805 = bitcast i8* %"&pSB[currWI].offset804" to <4 x i8>**
  store <4 x i8>* %150, <4 x i8>** %CastToValueType805, align 8
  %"&(pSB[currWI].offset)1550" = add nuw i64 %CurrSBIndex..0, 816
  %"&pSB[currWI].offset1551" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1550"
  %CastToValueType1552 = bitcast i8* %"&pSB[currWI].offset1551" to [4 x <4 x i8>]*
  %151 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1552, i64 0, i64 %139
  %"&(pSB[currWI].offset)827" = add nuw i64 %CurrSBIndex..0, 392
  %"&pSB[currWI].offset828" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)827"
  %CastToValueType829 = bitcast i8* %"&pSB[currWI].offset828" to <4 x i8>**
  store <4 x i8>* %151, <4 x i8>** %CastToValueType829, align 8
  %"&(pSB[currWI].offset)1586" = add nuw i64 %CurrSBIndex..0, 832
  %"&pSB[currWI].offset1587" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1586"
  %CastToValueType1588 = bitcast i8* %"&pSB[currWI].offset1587" to [4 x <4 x i8>]*
  %152 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1588, i64 0, i64 %139
  %"&(pSB[currWI].offset)851" = add nuw i64 %CurrSBIndex..0, 400
  %"&pSB[currWI].offset852" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)851"
  %CastToValueType853 = bitcast i8* %"&pSB[currWI].offset852" to <4 x i8>**
  store <4 x i8>* %152, <4 x i8>** %CastToValueType853, align 8
  %"&(pSB[currWI].offset)1622" = add nuw i64 %CurrSBIndex..0, 848
  %"&pSB[currWI].offset1623" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1622"
  %CastToValueType1624 = bitcast i8* %"&pSB[currWI].offset1623" to [4 x <4 x i8>]*
  %153 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1624, i64 0, i64 %139
  %"&(pSB[currWI].offset)875" = add nuw i64 %CurrSBIndex..0, 408
  %"&pSB[currWI].offset876" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)875"
  %CastToValueType877 = bitcast i8* %"&pSB[currWI].offset876" to <4 x i8>**
  store <4 x i8>* %153, <4 x i8>** %CastToValueType877, align 8
  %"&(pSB[currWI].offset)1658" = add nuw i64 %CurrSBIndex..0, 864
  %"&pSB[currWI].offset1659" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1658"
  %CastToValueType1660 = bitcast i8* %"&pSB[currWI].offset1659" to [4 x <4 x i8>]*
  %154 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1660, i64 0, i64 %139
  %"&(pSB[currWI].offset)899" = add nuw i64 %CurrSBIndex..0, 416
  %"&pSB[currWI].offset900" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)899"
  %CastToValueType901 = bitcast i8* %"&pSB[currWI].offset900" to <4 x i8>**
  store <4 x i8>* %154, <4 x i8>** %CastToValueType901, align 8
  %"&(pSB[currWI].offset)1694" = add nuw i64 %CurrSBIndex..0, 880
  %"&pSB[currWI].offset1695" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1694"
  %CastToValueType1696 = bitcast i8* %"&pSB[currWI].offset1695" to [4 x <4 x i8>]*
  %155 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1696, i64 0, i64 %139
  %"&(pSB[currWI].offset)923" = add nuw i64 %CurrSBIndex..0, 424
  %"&pSB[currWI].offset924" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)923"
  %CastToValueType925 = bitcast i8* %"&pSB[currWI].offset924" to <4 x i8>**
  store <4 x i8>* %155, <4 x i8>** %CastToValueType925, align 8
  %156 = getelementptr inbounds <4 x i8> addrspace(3)* %block1, i64 %129
  %"&(pSB[currWI].offset)947" = add nuw i64 %CurrSBIndex..0, 432
  %"&pSB[currWI].offset948" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)947"
  %CastToValueType949 = bitcast i8* %"&pSB[currWI].offset948" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %156, <4 x i8> addrspace(3)** %CastToValueType949, align 8
  %tmp75 = sub i64 1, %7
  %"&(pSB[currWI].offset)961" = add nuw i64 %CurrSBIndex..0, 440
  %"&pSB[currWI].offset962" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)961"
  %CastToValueType963 = bitcast i8* %"&pSB[currWI].offset962" to i64*
  store i64 %tmp75, i64* %CastToValueType963, align 8
  %tmp86 = add i32 %8, 4
  %"&(pSB[currWI].offset)970" = add nuw i64 %CurrSBIndex..0, 448
  %"&pSB[currWI].offset971" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)970"
  %CastToValueType972 = bitcast i8* %"&pSB[currWI].offset971" to i32*
  store i32 %tmp86, i32* %CastToValueType972, align 4
  br label %157

; <label>:157                                     ; preds = %SyncBB1716, %SyncBB1715
  %CurrSBIndex..2 = phi i64 [ %CurrSBIndex..0, %SyncBB1715 ], [ %CurrSBIndex..1, %SyncBB1716 ]
  %currBarrier.1 = phi i32 [ %currBarrier.2, %SyncBB1715 ], [ %currBarrier.0, %SyncBB1716 ]
  %CurrWI..2 = phi i64 [ %CurrWI..0, %SyncBB1715 ], [ %CurrWI..1, %SyncBB1716 ]
  %158 = phi i8 [ %133, %SyncBB1715 ], [ %1045, %SyncBB1716 ]
  %159 = phi i8 [ %134, %SyncBB1715 ], [ %1046, %SyncBB1716 ]
  %160 = phi i8 [ %135, %SyncBB1715 ], [ %1047, %SyncBB1716 ]
  %161 = phi i8 [ %136, %SyncBB1715 ], [ %1048, %SyncBB1716 ]
  %indvar79 = phi i32 [ 0, %SyncBB1715 ], [ %indvar.next80, %SyncBB1716 ]
  %"&(pSB[currWI].offset)979" = add nuw i64 %CurrSBIndex..2, 452
  %"&pSB[currWI].offset980" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)979"
  %CastToValueType981 = bitcast i8* %"&pSB[currWI].offset980" to i32*
  store i32 %indvar79, i32* %CastToValueType981, align 4
  %temp.vect108 = insertelement <4 x i8> undef, i8 %158, i32 0
  %temp.vect109 = insertelement <4 x i8> %temp.vect108, i8 %159, i32 1
  %temp.vect110 = insertelement <4 x i8> %temp.vect109, i8 %160, i32 2
  %temp.vect111 = insertelement <4 x i8> %temp.vect110, i8 %161, i32 3
  %tmp84 = shl i32 %indvar79, 2
  %"&(pSB[currWI].offset)974" = add nuw i64 %CurrSBIndex..2, 448
  %"&pSB[currWI].offset975" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)974"
  %CastToValueType976 = bitcast i8* %"&pSB[currWI].offset975" to i32*
  %loadedValue977 = load i32* %CastToValueType976, align 4
  %tmp87 = add i32 %loadedValue977, %tmp84
  %"&(pSB[currWI].offset)993" = add nuw i64 %CurrSBIndex..2, 456
  %"&pSB[currWI].offset994" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)993"
  %CastToValueType995 = bitcast i8* %"&pSB[currWI].offset994" to i32*
  store i32 %tmp87, i32* %CastToValueType995, align 4
  %162 = bitcast <4 x i8> %temp.vect111 to i32
  %tmp1.i = bitcast i32 %162 to <4 x i8>
  %scalar9 = extractelement <4 x i8> %tmp1.i, i32 0
  %scalar10 = extractelement <4 x i8> %tmp1.i, i32 1
  %scalar11 = extractelement <4 x i8> %tmp1.i, i32 2
  %scalar12 = extractelement <4 x i8> %tmp1.i, i32 3
  %163 = zext i8 %scalar9 to i64
  %164 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %163
  %165 = load i8 addrspace(1)* %164, align 1
  %166 = zext i8 %scalar10 to i64
  %167 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %166
  %168 = load i8 addrspace(1)* %167, align 1
  %169 = zext i8 %scalar11 to i64
  %170 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %169
  %171 = load i8 addrspace(1)* %170, align 1
  %172 = zext i8 %scalar12 to i64
  %173 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %172
  %174 = load i8 addrspace(1)* %173, align 1
  %temp.vect112 = insertelement <4 x i8> undef, i8 %165, i32 0
  %temp.vect113 = insertelement <4 x i8> %temp.vect112, i8 %168, i32 1
  %temp.vect114 = insertelement <4 x i8> %temp.vect113, i8 %171, i32 2
  %temp.vect115 = insertelement <4 x i8> %temp.vect114, i8 %174, i32 3
  %175 = bitcast <4 x i8> %temp.vect115 to i32
  %tmp7 = bitcast i32 %175 to <4 x i8>
  %176 = bitcast <4 x i8> %tmp7 to i32
  %tmp1.i1 = bitcast i32 %176 to <4 x i8>
  %scalar17 = extractelement <4 x i8> %tmp1.i1, i32 0
  %"&(pSB[currWI].offset)1002" = add nuw i64 %CurrSBIndex..2, 460
  %"&pSB[currWI].offset1003" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1002"
  store i8 %scalar17, i8* %"&pSB[currWI].offset1003", align 1
  %scalar18 = extractelement <4 x i8> %tmp1.i1, i32 1
  %"&(pSB[currWI].offset)1006" = add nuw i64 %CurrSBIndex..2, 461
  %"&pSB[currWI].offset1007" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1006"
  store i8 %scalar18, i8* %"&pSB[currWI].offset1007", align 1
  %scalar19 = extractelement <4 x i8> %tmp1.i1, i32 2
  %"&(pSB[currWI].offset)1010" = add nuw i64 %CurrSBIndex..2, 462
  %"&pSB[currWI].offset1011" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1010"
  store i8 %scalar19, i8* %"&pSB[currWI].offset1011", align 1
  %scalar20 = extractelement <4 x i8> %tmp1.i1, i32 3
  %"&(pSB[currWI].offset)1014" = add nuw i64 %CurrSBIndex..2, 463
  %"&pSB[currWI].offset1015" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1014"
  store i8 %scalar20, i8* %"&pSB[currWI].offset1015", align 1
  %"&(pSB[currWI].offset)514" = add nuw i64 %CurrSBIndex..2, 272
  %"&pSB[currWI].offset515" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)514"
  %CastToValueType516 = bitcast i8* %"&pSB[currWI].offset515" to i32*
  %loadedValue517 = load i32* %CastToValueType516, align 4
  %177 = icmp eq i32 %loadedValue517, 0
  br i1 %177, label %shiftRows.exit, label %bb.nph.i.preheader

bb.nph.i.preheader:                               ; preds = %157
  %"&(pSB[currWI].offset)1030" = add nuw i64 %CurrSBIndex..2, 467
  %"&pSB[currWI].offset1031" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1030"
  %"&(pSB[currWI].offset)1026" = add nuw i64 %CurrSBIndex..2, 466
  %"&pSB[currWI].offset1027" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1026"
  %"&(pSB[currWI].offset)1022" = add nuw i64 %CurrSBIndex..2, 465
  %"&pSB[currWI].offset1023" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1022"
  %"&(pSB[currWI].offset)1018" = add nuw i64 %CurrSBIndex..2, 464
  %"&pSB[currWI].offset1019" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1018"
  %"&(pSB[currWI].offset)1034" = add nuw i64 %CurrSBIndex..2, 468
  %"&pSB[currWI].offset1035" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1034"
  %CastToValueType1036 = bitcast i8* %"&pSB[currWI].offset1035" to i32*
  %"&(pSB[currWI].offset)510" = add nuw i64 %CurrSBIndex..2, 272
  %"&pSB[currWI].offset511" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)510"
  %CastToValueType512 = bitcast i8* %"&pSB[currWI].offset511" to i32*
  br label %bb.nph.i

bb.nph.i:                                         ; preds = %bb.nph.i, %bb.nph.i.preheader
  %i.03.i = phi i32 [ %178, %bb.nph.i ], [ 0, %bb.nph.i.preheader ]
  %r.02.i13 = phi i8 [ %r.02.i14, %bb.nph.i ], [ %scalar17, %bb.nph.i.preheader ]
  %r.02.i14 = phi i8 [ %r.02.i15, %bb.nph.i ], [ %scalar18, %bb.nph.i.preheader ]
  %r.02.i15 = phi i8 [ %r.02.i16, %bb.nph.i ], [ %scalar19, %bb.nph.i.preheader ]
  %r.02.i16 = phi i8 [ %r.02.i13, %bb.nph.i ], [ %scalar20, %bb.nph.i.preheader ]
  store i8 %r.02.i16, i8* %"&pSB[currWI].offset1031", align 1
  store i8 %r.02.i15, i8* %"&pSB[currWI].offset1027", align 1
  store i8 %r.02.i14, i8* %"&pSB[currWI].offset1023", align 1
  store i8 %r.02.i13, i8* %"&pSB[currWI].offset1019", align 1
  %178 = add i32 %i.03.i, 1
  store i32 %178, i32* %CastToValueType1036, align 4
  %loadedValue = load i32* %CastToValueType512, align 4
  %exitcond.i = icmp eq i32 %178, %loadedValue
  br i1 %exitcond.i, label %shiftRows.exit, label %bb.nph.i

shiftRows.exit:                                   ; preds = %bb.nph.i, %157
  %r.0.lcssa.i21 = phi i8 [ %scalar17, %157 ], [ %r.02.i14, %bb.nph.i ]
  %r.0.lcssa.i22 = phi i8 [ %scalar18, %157 ], [ %r.02.i15, %bb.nph.i ]
  %r.0.lcssa.i23 = phi i8 [ %scalar19, %157 ], [ %r.02.i16, %bb.nph.i ]
  %r.0.lcssa.i24 = phi i8 [ %scalar20, %157 ], [ %r.02.i13, %bb.nph.i ]
  %temp.vect116 = insertelement <4 x i8> undef, i8 %r.0.lcssa.i21, i32 0
  %temp.vect117 = insertelement <4 x i8> %temp.vect116, i8 %r.0.lcssa.i22, i32 1
  %temp.vect118 = insertelement <4 x i8> %temp.vect117, i8 %r.0.lcssa.i23, i32 2
  %temp.vect119 = insertelement <4 x i8> %temp.vect118, i8 %r.0.lcssa.i24, i32 3
  %179 = bitcast <4 x i8> %temp.vect119 to i32
  %tmp5 = bitcast i32 %179 to <4 x i8>
  %"&(pSB[currWI].offset)1038" = add nuw i64 %CurrSBIndex..2, 472
  %"&pSB[currWI].offset1039" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1038"
  %CastToValueType1040 = bitcast i8* %"&pSB[currWI].offset1039" to <4 x i8>*
  store <4 x i8> %tmp5, <4 x i8>* %CastToValueType1040, align 4
  %"&(pSB[currWI].offset)542" = add nuw i64 %CurrSBIndex..2, 288
  %"&pSB[currWI].offset543" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)542"
  %CastToValueType544 = bitcast i8* %"&pSB[currWI].offset543" to <4 x i8> addrspace(3)**
  %loadedValue545 = load <4 x i8> addrspace(3)** %CastToValueType544, align 8
  store <4 x i8> %tmp5, <4 x i8> addrspace(3)* %loadedValue545, align 4
  %"&(pSB[currWI].offset)988" = add nuw i64 %CurrSBIndex..2, 452
  %"&pSB[currWI].offset989" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)988"
  %CastToValueType990 = bitcast i8* %"&pSB[currWI].offset989" to i32*
  %loadedValue991 = load i32* %CastToValueType990, align 4
  %exitcond83 = icmp eq i32 %loadedValue991, %tmp82
  br i1 %exitcond83, label %"Barrier BB508", label %bb.nph65

bb.nph65:                                         ; preds = %shiftRows.exit
  %check.WI.iter = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter, label %thenBB, label %SyncBB

thenBB:                                           ; preds = %bb.nph65
  %"CurrWI++" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride" = add nuw i64 %CurrSBIndex..2, 1712
  %cond = icmp eq i32 %currBarrier.1, 14
  br i1 %cond, label %SyncBB1715, label %SyncBB1716

SyncBB:                                           ; preds = %bb.nph65, %thenBB1719
  %CurrSBIndex..3 = phi i64 [ %"loadedCurrSB+Stride1725", %thenBB1719 ], [ 0, %bb.nph65 ]
  %CurrWI..3 = phi i64 [ %"CurrWI++1723", %thenBB1719 ], [ 0, %bb.nph65 ]
  %"&(pSB[currWI].offset)582" = add nuw i64 %CurrSBIndex..3, 304
  %"&pSB[currWI].offset583" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)582"
  %CastToValueType584 = bitcast i8* %"&pSB[currWI].offset583" to <4 x i8>**
  %loadedValue585 = load <4 x i8>** %CastToValueType584, align 8
  %180 = load <4 x i8>* %loadedValue585, align 4
  %"&(pSB[currWI].offset)606" = add nuw i64 %CurrSBIndex..3, 312
  %"&pSB[currWI].offset607" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)606"
  %CastToValueType608 = bitcast i8* %"&pSB[currWI].offset607" to <4 x i8>**
  %loadedValue609 = load <4 x i8>** %CastToValueType608, align 8
  %181 = load <4 x i8>* %loadedValue609, align 4
  %"&(pSB[currWI].offset)630" = add nuw i64 %CurrSBIndex..3, 320
  %"&pSB[currWI].offset631" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)630"
  %CastToValueType632 = bitcast i8* %"&pSB[currWI].offset631" to <4 x i8>**
  %loadedValue633 = load <4 x i8>** %CastToValueType632, align 8
  %182 = load <4 x i8>* %loadedValue633, align 4
  %"&(pSB[currWI].offset)654" = add nuw i64 %CurrSBIndex..3, 328
  %"&pSB[currWI].offset655" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)654"
  %CastToValueType656 = bitcast i8* %"&pSB[currWI].offset655" to <4 x i8>**
  %loadedValue657 = load <4 x i8>** %CastToValueType656, align 8
  %183 = load <4 x i8>* %loadedValue657, align 4
  %"&(pSB[currWI].offset)678" = add nuw i64 %CurrSBIndex..3, 336
  %"&pSB[currWI].offset679" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)678"
  %CastToValueType680 = bitcast i8* %"&pSB[currWI].offset679" to <4 x i8>**
  %loadedValue681 = load <4 x i8>** %CastToValueType680, align 8
  %184 = load <4 x i8>* %loadedValue681, align 4
  %"&(pSB[currWI].offset)702" = add nuw i64 %CurrSBIndex..3, 344
  %"&pSB[currWI].offset703" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)702"
  %CastToValueType704 = bitcast i8* %"&pSB[currWI].offset703" to <4 x i8>**
  %loadedValue705 = load <4 x i8>** %CastToValueType704, align 8
  %185 = load <4 x i8>* %loadedValue705, align 4
  %"&(pSB[currWI].offset)726" = add nuw i64 %CurrSBIndex..3, 352
  %"&pSB[currWI].offset727" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)726"
  %CastToValueType728 = bitcast i8* %"&pSB[currWI].offset727" to <4 x i8>**
  %loadedValue729 = load <4 x i8>** %CastToValueType728, align 8
  %186 = load <4 x i8>* %loadedValue729, align 4
  %"&(pSB[currWI].offset)750" = add nuw i64 %CurrSBIndex..3, 360
  %"&pSB[currWI].offset751" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)750"
  %CastToValueType752 = bitcast i8* %"&pSB[currWI].offset751" to <4 x i8>**
  %loadedValue753 = load <4 x i8>** %CastToValueType752, align 8
  %187 = load <4 x i8>* %loadedValue753, align 4
  %"&(pSB[currWI].offset)774" = add nuw i64 %CurrSBIndex..3, 368
  %"&pSB[currWI].offset775" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)774"
  %CastToValueType776 = bitcast i8* %"&pSB[currWI].offset775" to <4 x i8>**
  %loadedValue777 = load <4 x i8>** %CastToValueType776, align 8
  %188 = load <4 x i8>* %loadedValue777, align 4
  %"&(pSB[currWI].offset)798" = add nuw i64 %CurrSBIndex..3, 376
  %"&pSB[currWI].offset799" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)798"
  %CastToValueType800 = bitcast i8* %"&pSB[currWI].offset799" to <4 x i8>**
  %loadedValue801 = load <4 x i8>** %CastToValueType800, align 8
  %189 = load <4 x i8>* %loadedValue801, align 4
  %"&(pSB[currWI].offset)822" = add nuw i64 %CurrSBIndex..3, 384
  %"&pSB[currWI].offset823" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)822"
  %CastToValueType824 = bitcast i8* %"&pSB[currWI].offset823" to <4 x i8>**
  %loadedValue825 = load <4 x i8>** %CastToValueType824, align 8
  %190 = load <4 x i8>* %loadedValue825, align 4
  %"&(pSB[currWI].offset)846" = add nuw i64 %CurrSBIndex..3, 392
  %"&pSB[currWI].offset847" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)846"
  %CastToValueType848 = bitcast i8* %"&pSB[currWI].offset847" to <4 x i8>**
  %loadedValue849 = load <4 x i8>** %CastToValueType848, align 8
  %191 = load <4 x i8>* %loadedValue849, align 4
  %"&(pSB[currWI].offset)870" = add nuw i64 %CurrSBIndex..3, 400
  %"&pSB[currWI].offset871" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)870"
  %CastToValueType872 = bitcast i8* %"&pSB[currWI].offset871" to <4 x i8>**
  %loadedValue873 = load <4 x i8>** %CastToValueType872, align 8
  %192 = load <4 x i8>* %loadedValue873, align 4
  %"&(pSB[currWI].offset)894" = add nuw i64 %CurrSBIndex..3, 408
  %"&pSB[currWI].offset895" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)894"
  %CastToValueType896 = bitcast i8* %"&pSB[currWI].offset895" to <4 x i8>**
  %loadedValue897 = load <4 x i8>** %CastToValueType896, align 8
  %193 = load <4 x i8>* %loadedValue897, align 4
  %"&(pSB[currWI].offset)918" = add nuw i64 %CurrSBIndex..3, 416
  %"&pSB[currWI].offset919" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)918"
  %CastToValueType920 = bitcast i8* %"&pSB[currWI].offset919" to <4 x i8>**
  %loadedValue921 = load <4 x i8>** %CastToValueType920, align 8
  %194 = load <4 x i8>* %loadedValue921, align 4
  %"&(pSB[currWI].offset)942" = add nuw i64 %CurrSBIndex..3, 424
  %"&pSB[currWI].offset943" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)942"
  %CastToValueType944 = bitcast i8* %"&pSB[currWI].offset943" to <4 x i8>**
  %loadedValue945 = load <4 x i8>** %CastToValueType944, align 8
  %195 = load <4 x i8>* %loadedValue945, align 4
  %196 = extractelement <4 x i8> %180, i32 0
  %197 = extractelement <4 x i8> %181, i32 0
  %198 = extractelement <4 x i8> %182, i32 0
  %199 = extractelement <4 x i8> %183, i32 0
  %200 = extractelement <4 x i8> %184, i32 0
  %201 = extractelement <4 x i8> %185, i32 0
  %202 = extractelement <4 x i8> %186, i32 0
  %203 = extractelement <4 x i8> %187, i32 0
  %204 = extractelement <4 x i8> %188, i32 0
  %205 = extractelement <4 x i8> %189, i32 0
  %206 = extractelement <4 x i8> %190, i32 0
  %207 = extractelement <4 x i8> %191, i32 0
  %208 = extractelement <4 x i8> %192, i32 0
  %209 = extractelement <4 x i8> %193, i32 0
  %210 = extractelement <4 x i8> %194, i32 0
  %211 = extractelement <4 x i8> %195, i32 0
  %temp.vect132 = insertelement <16 x i8> undef, i8 %196, i32 0
  %temp.vect133 = insertelement <16 x i8> %temp.vect132, i8 %197, i32 1
  %temp.vect134 = insertelement <16 x i8> %temp.vect133, i8 %198, i32 2
  %temp.vect135 = insertelement <16 x i8> %temp.vect134, i8 %199, i32 3
  %temp.vect136 = insertelement <16 x i8> %temp.vect135, i8 %200, i32 4
  %temp.vect137 = insertelement <16 x i8> %temp.vect136, i8 %201, i32 5
  %temp.vect138 = insertelement <16 x i8> %temp.vect137, i8 %202, i32 6
  %temp.vect139 = insertelement <16 x i8> %temp.vect138, i8 %203, i32 7
  %temp.vect140 = insertelement <16 x i8> %temp.vect139, i8 %204, i32 8
  %temp.vect141 = insertelement <16 x i8> %temp.vect140, i8 %205, i32 9
  %temp.vect142 = insertelement <16 x i8> %temp.vect141, i8 %206, i32 10
  %temp.vect143 = insertelement <16 x i8> %temp.vect142, i8 %207, i32 11
  %temp.vect144 = insertelement <16 x i8> %temp.vect143, i8 %208, i32 12
  %temp.vect145 = insertelement <16 x i8> %temp.vect144, i8 %209, i32 13
  %temp.vect146 = insertelement <16 x i8> %temp.vect145, i8 %210, i32 14
  %temp.vect147 = insertelement <16 x i8> %temp.vect146, i8 %211, i32 15
  %212 = load <4 x i8> addrspace(3)* %block0, align 4
  %scalar29 = extractelement <4 x i8> %212, i32 0
  %temp148 = insertelement <16 x i8> undef, i8 %scalar29, i32 0
  %vector149 = shufflevector <16 x i8> %temp148, <16 x i8> undef, <16 x i32> zeroinitializer
  %213 = zext i8 %scalar29 to i32
  %214 = shl i32 %213, 1
  %215 = and i32 %213, 128
  %216 = xor i32 %214, 27
  %217 = icmp eq i32 %215, 0
  %a.1.in = select i1 %217, i32 %214, i32 %216
  %218 = shl i32 %a.1.in, 1
  %219 = and i32 %a.1.in, 128
  %220 = xor i32 %218, 27
  %221 = icmp eq i32 %219, 0
  %a.1.in.1 = select i1 %221, i32 %218, i32 %220
  %222 = shl i32 %a.1.in.1, 1
  %223 = and i32 %a.1.in.1, 128
  %224 = xor i32 %222, 27
  %225 = icmp eq i32 %223, 0
  %a.1.in.2 = select i1 %225, i32 %222, i32 %224
  %226 = shl i32 %a.1.in.2, 1
  %227 = and i32 %a.1.in.2, 128
  %228 = xor i32 %226, 27
  %229 = icmp eq i32 %227, 0
  %a.1.in.3 = select i1 %229, i32 %226, i32 %228
  %230 = shl i32 %a.1.in.3, 1
  %231 = and i32 %a.1.in.3, 128
  %232 = xor i32 %230, 27
  %233 = icmp eq i32 %231, 0
  %a.1.in.4 = select i1 %233, i32 %230, i32 %232
  %234 = shl i32 %a.1.in.4, 1
  %235 = and i32 %a.1.in.4, 128
  %236 = xor i32 %234, 27
  %237 = icmp eq i32 %235, 0
  %a.1.in.5 = select i1 %237, i32 %234, i32 %236
  %238 = shl i32 %a.1.in.5, 1
  %239 = lshr <16 x i8> %temp.vect147, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %240 = zext <16 x i8> %239 to <16 x i32>
  %241 = zext <16 x i8> %temp.vect147 to <16 x i32>
  %242 = lshr <16 x i8> %temp.vect147, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %243 = lshr <16 x i8> %temp.vect147, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %244 = and <16 x i32> %240, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %245 = and <16 x i32> %241, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %246 = zext <16 x i8> %242 to <16 x i32>
  %247 = zext <16 x i8> %243 to <16 x i32>
  %248 = icmp eq <16 x i32> %244, zeroinitializer
  %a.1 = trunc i32 %a.1.in to i8
  %temp = insertelement <16 x i8> undef, i8 %a.1, i32 0
  %vector = shufflevector <16 x i8> %temp, <16 x i8> undef, <16 x i32> zeroinitializer
  %249 = icmp eq <16 x i32> %245, zeroinitializer
  %250 = and <16 x i32> %246, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %251 = lshr <16 x i8> %temp.vect147, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %252 = lshr <16 x i8> %temp.vect147, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %253 = and <16 x i32> %247, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %254 = select <16 x i1> %248, <16 x i8> zeroinitializer, <16 x i8> %vector
  %255 = select <16 x i1> %249, <16 x i8> zeroinitializer, <16 x i8> %vector149
  %a.1.1 = trunc i32 %a.1.in.1 to i8
  %temp151 = insertelement <16 x i8> undef, i8 %a.1.1, i32 0
  %vector152 = shufflevector <16 x i8> %temp151, <16 x i8> undef, <16 x i32> zeroinitializer
  %256 = icmp eq <16 x i32> %250, zeroinitializer
  %257 = zext <16 x i8> %251 to <16 x i32>
  %258 = zext <16 x i8> %252 to <16 x i32>
  %259 = icmp eq <16 x i32> %253, zeroinitializer
  %a.1.2 = trunc i32 %a.1.in.2 to i8
  %temp153 = insertelement <16 x i8> undef, i8 %a.1.2, i32 0
  %vector154 = shufflevector <16 x i8> %temp153, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..1150 = xor <16 x i8> %254, %255
  %260 = select <16 x i1> %256, <16 x i8> zeroinitializer, <16 x i8> %vector152
  %261 = and <16 x i32> %257, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %262 = lshr <16 x i8> %temp.vect147, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %263 = and i32 %a.1.in.5, 128
  %264 = and <16 x i32> %258, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %265 = select <16 x i1> %259, <16 x i8> zeroinitializer, <16 x i8> %vector154
  %p.1..2155 = xor <16 x i8> %260, %p.1..1150
  %a.1.3 = trunc i32 %a.1.in.3 to i8
  %temp157 = insertelement <16 x i8> undef, i8 %a.1.3, i32 0
  %vector158 = shufflevector <16 x i8> %temp157, <16 x i8> undef, <16 x i32> zeroinitializer
  %266 = icmp eq <16 x i32> %261, zeroinitializer
  %267 = zext <16 x i8> %262 to <16 x i32>
  %268 = icmp eq i32 %263, 0
  %269 = xor i32 %238, 27
  %270 = icmp eq <16 x i32> %264, zeroinitializer
  %a.1.4 = trunc i32 %a.1.in.4 to i8
  %temp159 = insertelement <16 x i8> undef, i8 %a.1.4, i32 0
  %vector160 = shufflevector <16 x i8> %temp159, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..3156 = xor <16 x i8> %265, %p.1..2155
  %271 = select <16 x i1> %266, <16 x i8> zeroinitializer, <16 x i8> %vector158
  %272 = and <16 x i32> %267, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.1.in.6 = select i1 %268, i32 %238, i32 %269
  %273 = select <16 x i1> %270, <16 x i8> zeroinitializer, <16 x i8> %vector160
  %p.1..4161 = xor <16 x i8> %271, %p.1..3156
  %a.1.5 = trunc i32 %a.1.in.5 to i8
  %temp163 = insertelement <16 x i8> undef, i8 %a.1.5, i32 0
  %vector164 = shufflevector <16 x i8> %temp163, <16 x i8> undef, <16 x i32> zeroinitializer
  %274 = icmp eq <16 x i32> %272, zeroinitializer
  %275 = icmp sgt <16 x i8> %temp.vect147, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.1.6 = trunc i32 %a.1.in.6 to i8
  %temp165 = insertelement <16 x i8> undef, i8 %a.1.6, i32 0
  %vector166 = shufflevector <16 x i8> %temp165, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..5162 = xor <16 x i8> %273, %p.1..4161
  %276 = select <16 x i1> %274, <16 x i8> zeroinitializer, <16 x i8> %vector164
  %277 = select <16 x i1> %275, <16 x i8> zeroinitializer, <16 x i8> %vector166
  %p.1..6167 = xor <16 x i8> %276, %p.1..5162
  %p.1..7168 = xor <16 x i8> %277, %p.1..6167
  %"&(pSB[currWI].offset)1062" = add nuw i64 %CurrSBIndex..3, 480
  %"&pSB[currWI].offset1063" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1062"
  %CastToValueType1064 = bitcast i8* %"&pSB[currWI].offset1063" to <16 x i8>*
  store <16 x i8> %p.1..7168, <16 x i8>* %CastToValueType1064, align 16
  %"&(pSB[currWI].offset)577" = add nuw i64 %CurrSBIndex..3, 304
  %"&pSB[currWI].offset578" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)577"
  %CastToValueType579 = bitcast i8* %"&pSB[currWI].offset578" to <4 x i8>**
  %loadedValue580 = load <4 x i8>** %CastToValueType579, align 8
  %278 = load <4 x i8>* %loadedValue580, align 4
  %"&(pSB[currWI].offset)601" = add nuw i64 %CurrSBIndex..3, 312
  %"&pSB[currWI].offset602" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)601"
  %CastToValueType603 = bitcast i8* %"&pSB[currWI].offset602" to <4 x i8>**
  %loadedValue604 = load <4 x i8>** %CastToValueType603, align 8
  %279 = load <4 x i8>* %loadedValue604, align 4
  %"&(pSB[currWI].offset)625" = add nuw i64 %CurrSBIndex..3, 320
  %"&pSB[currWI].offset626" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)625"
  %CastToValueType627 = bitcast i8* %"&pSB[currWI].offset626" to <4 x i8>**
  %loadedValue628 = load <4 x i8>** %CastToValueType627, align 8
  %280 = load <4 x i8>* %loadedValue628, align 4
  %"&(pSB[currWI].offset)649" = add nuw i64 %CurrSBIndex..3, 328
  %"&pSB[currWI].offset650" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)649"
  %CastToValueType651 = bitcast i8* %"&pSB[currWI].offset650" to <4 x i8>**
  %loadedValue652 = load <4 x i8>** %CastToValueType651, align 8
  %281 = load <4 x i8>* %loadedValue652, align 4
  %"&(pSB[currWI].offset)673" = add nuw i64 %CurrSBIndex..3, 336
  %"&pSB[currWI].offset674" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)673"
  %CastToValueType675 = bitcast i8* %"&pSB[currWI].offset674" to <4 x i8>**
  %loadedValue676 = load <4 x i8>** %CastToValueType675, align 8
  %282 = load <4 x i8>* %loadedValue676, align 4
  %"&(pSB[currWI].offset)697" = add nuw i64 %CurrSBIndex..3, 344
  %"&pSB[currWI].offset698" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)697"
  %CastToValueType699 = bitcast i8* %"&pSB[currWI].offset698" to <4 x i8>**
  %loadedValue700 = load <4 x i8>** %CastToValueType699, align 8
  %283 = load <4 x i8>* %loadedValue700, align 4
  %"&(pSB[currWI].offset)721" = add nuw i64 %CurrSBIndex..3, 352
  %"&pSB[currWI].offset722" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)721"
  %CastToValueType723 = bitcast i8* %"&pSB[currWI].offset722" to <4 x i8>**
  %loadedValue724 = load <4 x i8>** %CastToValueType723, align 8
  %284 = load <4 x i8>* %loadedValue724, align 4
  %"&(pSB[currWI].offset)745" = add nuw i64 %CurrSBIndex..3, 360
  %"&pSB[currWI].offset746" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)745"
  %CastToValueType747 = bitcast i8* %"&pSB[currWI].offset746" to <4 x i8>**
  %loadedValue748 = load <4 x i8>** %CastToValueType747, align 8
  %285 = load <4 x i8>* %loadedValue748, align 4
  %"&(pSB[currWI].offset)769" = add nuw i64 %CurrSBIndex..3, 368
  %"&pSB[currWI].offset770" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)769"
  %CastToValueType771 = bitcast i8* %"&pSB[currWI].offset770" to <4 x i8>**
  %loadedValue772 = load <4 x i8>** %CastToValueType771, align 8
  %286 = load <4 x i8>* %loadedValue772, align 4
  %"&(pSB[currWI].offset)793" = add nuw i64 %CurrSBIndex..3, 376
  %"&pSB[currWI].offset794" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)793"
  %CastToValueType795 = bitcast i8* %"&pSB[currWI].offset794" to <4 x i8>**
  %loadedValue796 = load <4 x i8>** %CastToValueType795, align 8
  %287 = load <4 x i8>* %loadedValue796, align 4
  %"&(pSB[currWI].offset)817" = add nuw i64 %CurrSBIndex..3, 384
  %"&pSB[currWI].offset818" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)817"
  %CastToValueType819 = bitcast i8* %"&pSB[currWI].offset818" to <4 x i8>**
  %loadedValue820 = load <4 x i8>** %CastToValueType819, align 8
  %288 = load <4 x i8>* %loadedValue820, align 4
  %"&(pSB[currWI].offset)841" = add nuw i64 %CurrSBIndex..3, 392
  %"&pSB[currWI].offset842" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)841"
  %CastToValueType843 = bitcast i8* %"&pSB[currWI].offset842" to <4 x i8>**
  %loadedValue844 = load <4 x i8>** %CastToValueType843, align 8
  %289 = load <4 x i8>* %loadedValue844, align 4
  %"&(pSB[currWI].offset)865" = add nuw i64 %CurrSBIndex..3, 400
  %"&pSB[currWI].offset866" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)865"
  %CastToValueType867 = bitcast i8* %"&pSB[currWI].offset866" to <4 x i8>**
  %loadedValue868 = load <4 x i8>** %CastToValueType867, align 8
  %290 = load <4 x i8>* %loadedValue868, align 4
  %"&(pSB[currWI].offset)889" = add nuw i64 %CurrSBIndex..3, 408
  %"&pSB[currWI].offset890" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)889"
  %CastToValueType891 = bitcast i8* %"&pSB[currWI].offset890" to <4 x i8>**
  %loadedValue892 = load <4 x i8>** %CastToValueType891, align 8
  %291 = load <4 x i8>* %loadedValue892, align 4
  %"&(pSB[currWI].offset)913" = add nuw i64 %CurrSBIndex..3, 416
  %"&pSB[currWI].offset914" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)913"
  %CastToValueType915 = bitcast i8* %"&pSB[currWI].offset914" to <4 x i8>**
  %loadedValue916 = load <4 x i8>** %CastToValueType915, align 8
  %292 = load <4 x i8>* %loadedValue916, align 4
  %"&(pSB[currWI].offset)937" = add nuw i64 %CurrSBIndex..3, 424
  %"&pSB[currWI].offset938" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)937"
  %CastToValueType939 = bitcast i8* %"&pSB[currWI].offset938" to <4 x i8>**
  %loadedValue940 = load <4 x i8>** %CastToValueType939, align 8
  %293 = load <4 x i8>* %loadedValue940, align 4
  %294 = extractelement <4 x i8> %278, i32 0
  %295 = extractelement <4 x i8> %279, i32 0
  %296 = extractelement <4 x i8> %280, i32 0
  %297 = extractelement <4 x i8> %281, i32 0
  %298 = extractelement <4 x i8> %282, i32 0
  %299 = extractelement <4 x i8> %283, i32 0
  %300 = extractelement <4 x i8> %284, i32 0
  %301 = extractelement <4 x i8> %285, i32 0
  %302 = extractelement <4 x i8> %286, i32 0
  %303 = extractelement <4 x i8> %287, i32 0
  %304 = extractelement <4 x i8> %288, i32 0
  %305 = extractelement <4 x i8> %289, i32 0
  %306 = extractelement <4 x i8> %290, i32 0
  %307 = extractelement <4 x i8> %291, i32 0
  %308 = extractelement <4 x i8> %292, i32 0
  %309 = extractelement <4 x i8> %293, i32 0
  %temp.vect169 = insertelement <16 x i8> undef, i8 %294, i32 0
  %temp.vect170 = insertelement <16 x i8> %temp.vect169, i8 %295, i32 1
  %temp.vect171 = insertelement <16 x i8> %temp.vect170, i8 %296, i32 2
  %temp.vect172 = insertelement <16 x i8> %temp.vect171, i8 %297, i32 3
  %temp.vect173 = insertelement <16 x i8> %temp.vect172, i8 %298, i32 4
  %temp.vect174 = insertelement <16 x i8> %temp.vect173, i8 %299, i32 5
  %temp.vect175 = insertelement <16 x i8> %temp.vect174, i8 %300, i32 6
  %temp.vect176 = insertelement <16 x i8> %temp.vect175, i8 %301, i32 7
  %temp.vect177 = insertelement <16 x i8> %temp.vect176, i8 %302, i32 8
  %temp.vect178 = insertelement <16 x i8> %temp.vect177, i8 %303, i32 9
  %temp.vect179 = insertelement <16 x i8> %temp.vect178, i8 %304, i32 10
  %temp.vect180 = insertelement <16 x i8> %temp.vect179, i8 %305, i32 11
  %temp.vect181 = insertelement <16 x i8> %temp.vect180, i8 %306, i32 12
  %temp.vect182 = insertelement <16 x i8> %temp.vect181, i8 %307, i32 13
  %temp.vect183 = insertelement <16 x i8> %temp.vect182, i8 %308, i32 14
  %temp.vect184 = insertelement <16 x i8> %temp.vect183, i8 %309, i32 15
  %310 = load <4 x i8> addrspace(3)* %block0, align 4
  %scalar38 = extractelement <4 x i8> %310, i32 1
  %temp187 = insertelement <16 x i8> undef, i8 %scalar38, i32 0
  %vector188 = shufflevector <16 x i8> %temp187, <16 x i8> undef, <16 x i32> zeroinitializer
  %311 = zext i8 %scalar38 to i32
  %312 = shl i32 %311, 1
  %313 = and i32 %311, 128
  %314 = xor i32 %312, 27
  %315 = icmp eq i32 %313, 0
  %a.3.in = select i1 %315, i32 %312, i32 %314
  %316 = shl i32 %a.3.in, 1
  %317 = and i32 %a.3.in, 128
  %318 = xor i32 %316, 27
  %319 = icmp eq i32 %317, 0
  %a.3.in.1 = select i1 %319, i32 %316, i32 %318
  %320 = shl i32 %a.3.in.1, 1
  %321 = and i32 %a.3.in.1, 128
  %322 = xor i32 %320, 27
  %323 = icmp eq i32 %321, 0
  %a.3.in.2 = select i1 %323, i32 %320, i32 %322
  %324 = shl i32 %a.3.in.2, 1
  %325 = and i32 %a.3.in.2, 128
  %326 = xor i32 %324, 27
  %327 = icmp eq i32 %325, 0
  %a.3.in.3 = select i1 %327, i32 %324, i32 %326
  %328 = shl i32 %a.3.in.3, 1
  %329 = and i32 %a.3.in.3, 128
  %330 = xor i32 %328, 27
  %331 = icmp eq i32 %329, 0
  %a.3.in.4 = select i1 %331, i32 %328, i32 %330
  %332 = shl i32 %a.3.in.4, 1
  %333 = and i32 %a.3.in.4, 128
  %334 = xor i32 %332, 27
  %335 = icmp eq i32 %333, 0
  %a.3.in.5 = select i1 %335, i32 %332, i32 %334
  %336 = shl i32 %a.3.in.5, 1
  %337 = lshr <16 x i8> %temp.vect184, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %338 = zext <16 x i8> %337 to <16 x i32>
  %339 = zext <16 x i8> %temp.vect184 to <16 x i32>
  %340 = lshr <16 x i8> %temp.vect184, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %341 = lshr <16 x i8> %temp.vect184, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %342 = and <16 x i32> %338, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %343 = and <16 x i32> %339, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %344 = zext <16 x i8> %340 to <16 x i32>
  %345 = zext <16 x i8> %341 to <16 x i32>
  %346 = icmp eq <16 x i32> %342, zeroinitializer
  %a.3 = trunc i32 %a.3.in to i8
  %temp185 = insertelement <16 x i8> undef, i8 %a.3, i32 0
  %vector186 = shufflevector <16 x i8> %temp185, <16 x i8> undef, <16 x i32> zeroinitializer
  %347 = icmp eq <16 x i32> %343, zeroinitializer
  %348 = and <16 x i32> %344, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %349 = lshr <16 x i8> %temp.vect184, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %350 = lshr <16 x i8> %temp.vect184, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %351 = and <16 x i32> %345, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %352 = select <16 x i1> %346, <16 x i8> zeroinitializer, <16 x i8> %vector186
  %353 = select <16 x i1> %347, <16 x i8> zeroinitializer, <16 x i8> %vector188
  %a.3.1 = trunc i32 %a.3.in.1 to i8
  %temp190 = insertelement <16 x i8> undef, i8 %a.3.1, i32 0
  %vector191 = shufflevector <16 x i8> %temp190, <16 x i8> undef, <16 x i32> zeroinitializer
  %354 = icmp eq <16 x i32> %348, zeroinitializer
  %355 = zext <16 x i8> %349 to <16 x i32>
  %356 = zext <16 x i8> %350 to <16 x i32>
  %357 = icmp eq <16 x i32> %351, zeroinitializer
  %a.3.2 = trunc i32 %a.3.in.2 to i8
  %temp192 = insertelement <16 x i8> undef, i8 %a.3.2, i32 0
  %vector193 = shufflevector <16 x i8> %temp192, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..1189 = xor <16 x i8> %352, %353
  %358 = select <16 x i1> %354, <16 x i8> zeroinitializer, <16 x i8> %vector191
  %359 = and <16 x i32> %355, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %360 = lshr <16 x i8> %temp.vect184, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %361 = and i32 %a.3.in.5, 128
  %362 = and <16 x i32> %356, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %363 = select <16 x i1> %357, <16 x i8> zeroinitializer, <16 x i8> %vector193
  %p.3..2194 = xor <16 x i8> %358, %p.3..1189
  %a.3.3 = trunc i32 %a.3.in.3 to i8
  %temp196 = insertelement <16 x i8> undef, i8 %a.3.3, i32 0
  %vector197 = shufflevector <16 x i8> %temp196, <16 x i8> undef, <16 x i32> zeroinitializer
  %364 = icmp eq <16 x i32> %359, zeroinitializer
  %365 = zext <16 x i8> %360 to <16 x i32>
  %366 = icmp eq i32 %361, 0
  %367 = xor i32 %336, 27
  %368 = icmp eq <16 x i32> %362, zeroinitializer
  %a.3.4 = trunc i32 %a.3.in.4 to i8
  %temp198 = insertelement <16 x i8> undef, i8 %a.3.4, i32 0
  %vector199 = shufflevector <16 x i8> %temp198, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..3195 = xor <16 x i8> %363, %p.3..2194
  %369 = select <16 x i1> %364, <16 x i8> zeroinitializer, <16 x i8> %vector197
  %370 = and <16 x i32> %365, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.3.in.6 = select i1 %366, i32 %336, i32 %367
  %371 = select <16 x i1> %368, <16 x i8> zeroinitializer, <16 x i8> %vector199
  %p.3..4200 = xor <16 x i8> %369, %p.3..3195
  %a.3.5 = trunc i32 %a.3.in.5 to i8
  %temp202 = insertelement <16 x i8> undef, i8 %a.3.5, i32 0
  %vector203 = shufflevector <16 x i8> %temp202, <16 x i8> undef, <16 x i32> zeroinitializer
  %372 = icmp eq <16 x i32> %370, zeroinitializer
  %373 = icmp sgt <16 x i8> %temp.vect184, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.3.6 = trunc i32 %a.3.in.6 to i8
  %temp204 = insertelement <16 x i8> undef, i8 %a.3.6, i32 0
  %vector205 = shufflevector <16 x i8> %temp204, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..5201 = xor <16 x i8> %371, %p.3..4200
  %374 = select <16 x i1> %372, <16 x i8> zeroinitializer, <16 x i8> %vector203
  %375 = select <16 x i1> %373, <16 x i8> zeroinitializer, <16 x i8> %vector205
  %p.3..6206 = xor <16 x i8> %374, %p.3..5201
  %p.3..7207 = xor <16 x i8> %375, %p.3..6206
  %"&(pSB[currWI].offset)1066" = add nuw i64 %CurrSBIndex..3, 496
  %"&pSB[currWI].offset1067" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1066"
  %CastToValueType1068 = bitcast i8* %"&pSB[currWI].offset1067" to <16 x i8>*
  store <16 x i8> %p.3..7207, <16 x i8>* %CastToValueType1068, align 16
  %"&(pSB[currWI].offset)572" = add nuw i64 %CurrSBIndex..3, 304
  %"&pSB[currWI].offset573" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)572"
  %CastToValueType574 = bitcast i8* %"&pSB[currWI].offset573" to <4 x i8>**
  %loadedValue575 = load <4 x i8>** %CastToValueType574, align 8
  %376 = load <4 x i8>* %loadedValue575, align 4
  %"&(pSB[currWI].offset)596" = add nuw i64 %CurrSBIndex..3, 312
  %"&pSB[currWI].offset597" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)596"
  %CastToValueType598 = bitcast i8* %"&pSB[currWI].offset597" to <4 x i8>**
  %loadedValue599 = load <4 x i8>** %CastToValueType598, align 8
  %377 = load <4 x i8>* %loadedValue599, align 4
  %"&(pSB[currWI].offset)620" = add nuw i64 %CurrSBIndex..3, 320
  %"&pSB[currWI].offset621" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)620"
  %CastToValueType622 = bitcast i8* %"&pSB[currWI].offset621" to <4 x i8>**
  %loadedValue623 = load <4 x i8>** %CastToValueType622, align 8
  %378 = load <4 x i8>* %loadedValue623, align 4
  %"&(pSB[currWI].offset)644" = add nuw i64 %CurrSBIndex..3, 328
  %"&pSB[currWI].offset645" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)644"
  %CastToValueType646 = bitcast i8* %"&pSB[currWI].offset645" to <4 x i8>**
  %loadedValue647 = load <4 x i8>** %CastToValueType646, align 8
  %379 = load <4 x i8>* %loadedValue647, align 4
  %"&(pSB[currWI].offset)668" = add nuw i64 %CurrSBIndex..3, 336
  %"&pSB[currWI].offset669" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)668"
  %CastToValueType670 = bitcast i8* %"&pSB[currWI].offset669" to <4 x i8>**
  %loadedValue671 = load <4 x i8>** %CastToValueType670, align 8
  %380 = load <4 x i8>* %loadedValue671, align 4
  %"&(pSB[currWI].offset)692" = add nuw i64 %CurrSBIndex..3, 344
  %"&pSB[currWI].offset693" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)692"
  %CastToValueType694 = bitcast i8* %"&pSB[currWI].offset693" to <4 x i8>**
  %loadedValue695 = load <4 x i8>** %CastToValueType694, align 8
  %381 = load <4 x i8>* %loadedValue695, align 4
  %"&(pSB[currWI].offset)716" = add nuw i64 %CurrSBIndex..3, 352
  %"&pSB[currWI].offset717" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)716"
  %CastToValueType718 = bitcast i8* %"&pSB[currWI].offset717" to <4 x i8>**
  %loadedValue719 = load <4 x i8>** %CastToValueType718, align 8
  %382 = load <4 x i8>* %loadedValue719, align 4
  %"&(pSB[currWI].offset)740" = add nuw i64 %CurrSBIndex..3, 360
  %"&pSB[currWI].offset741" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)740"
  %CastToValueType742 = bitcast i8* %"&pSB[currWI].offset741" to <4 x i8>**
  %loadedValue743 = load <4 x i8>** %CastToValueType742, align 8
  %383 = load <4 x i8>* %loadedValue743, align 4
  %"&(pSB[currWI].offset)764" = add nuw i64 %CurrSBIndex..3, 368
  %"&pSB[currWI].offset765" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)764"
  %CastToValueType766 = bitcast i8* %"&pSB[currWI].offset765" to <4 x i8>**
  %loadedValue767 = load <4 x i8>** %CastToValueType766, align 8
  %384 = load <4 x i8>* %loadedValue767, align 4
  %"&(pSB[currWI].offset)788" = add nuw i64 %CurrSBIndex..3, 376
  %"&pSB[currWI].offset789" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)788"
  %CastToValueType790 = bitcast i8* %"&pSB[currWI].offset789" to <4 x i8>**
  %loadedValue791 = load <4 x i8>** %CastToValueType790, align 8
  %385 = load <4 x i8>* %loadedValue791, align 4
  %"&(pSB[currWI].offset)812" = add nuw i64 %CurrSBIndex..3, 384
  %"&pSB[currWI].offset813" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)812"
  %CastToValueType814 = bitcast i8* %"&pSB[currWI].offset813" to <4 x i8>**
  %loadedValue815 = load <4 x i8>** %CastToValueType814, align 8
  %386 = load <4 x i8>* %loadedValue815, align 4
  %"&(pSB[currWI].offset)836" = add nuw i64 %CurrSBIndex..3, 392
  %"&pSB[currWI].offset837" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)836"
  %CastToValueType838 = bitcast i8* %"&pSB[currWI].offset837" to <4 x i8>**
  %loadedValue839 = load <4 x i8>** %CastToValueType838, align 8
  %387 = load <4 x i8>* %loadedValue839, align 4
  %"&(pSB[currWI].offset)860" = add nuw i64 %CurrSBIndex..3, 400
  %"&pSB[currWI].offset861" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)860"
  %CastToValueType862 = bitcast i8* %"&pSB[currWI].offset861" to <4 x i8>**
  %loadedValue863 = load <4 x i8>** %CastToValueType862, align 8
  %388 = load <4 x i8>* %loadedValue863, align 4
  %"&(pSB[currWI].offset)884" = add nuw i64 %CurrSBIndex..3, 408
  %"&pSB[currWI].offset885" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)884"
  %CastToValueType886 = bitcast i8* %"&pSB[currWI].offset885" to <4 x i8>**
  %loadedValue887 = load <4 x i8>** %CastToValueType886, align 8
  %389 = load <4 x i8>* %loadedValue887, align 4
  %"&(pSB[currWI].offset)908" = add nuw i64 %CurrSBIndex..3, 416
  %"&pSB[currWI].offset909" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)908"
  %CastToValueType910 = bitcast i8* %"&pSB[currWI].offset909" to <4 x i8>**
  %loadedValue911 = load <4 x i8>** %CastToValueType910, align 8
  %390 = load <4 x i8>* %loadedValue911, align 4
  %"&(pSB[currWI].offset)932" = add nuw i64 %CurrSBIndex..3, 424
  %"&pSB[currWI].offset933" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)932"
  %CastToValueType934 = bitcast i8* %"&pSB[currWI].offset933" to <4 x i8>**
  %loadedValue935 = load <4 x i8>** %CastToValueType934, align 8
  %391 = load <4 x i8>* %loadedValue935, align 4
  %392 = extractelement <4 x i8> %376, i32 0
  %393 = extractelement <4 x i8> %377, i32 0
  %394 = extractelement <4 x i8> %378, i32 0
  %395 = extractelement <4 x i8> %379, i32 0
  %396 = extractelement <4 x i8> %380, i32 0
  %397 = extractelement <4 x i8> %381, i32 0
  %398 = extractelement <4 x i8> %382, i32 0
  %399 = extractelement <4 x i8> %383, i32 0
  %400 = extractelement <4 x i8> %384, i32 0
  %401 = extractelement <4 x i8> %385, i32 0
  %402 = extractelement <4 x i8> %386, i32 0
  %403 = extractelement <4 x i8> %387, i32 0
  %404 = extractelement <4 x i8> %388, i32 0
  %405 = extractelement <4 x i8> %389, i32 0
  %406 = extractelement <4 x i8> %390, i32 0
  %407 = extractelement <4 x i8> %391, i32 0
  %temp.vect208 = insertelement <16 x i8> undef, i8 %392, i32 0
  %temp.vect209 = insertelement <16 x i8> %temp.vect208, i8 %393, i32 1
  %temp.vect210 = insertelement <16 x i8> %temp.vect209, i8 %394, i32 2
  %temp.vect211 = insertelement <16 x i8> %temp.vect210, i8 %395, i32 3
  %temp.vect212 = insertelement <16 x i8> %temp.vect211, i8 %396, i32 4
  %temp.vect213 = insertelement <16 x i8> %temp.vect212, i8 %397, i32 5
  %temp.vect214 = insertelement <16 x i8> %temp.vect213, i8 %398, i32 6
  %temp.vect215 = insertelement <16 x i8> %temp.vect214, i8 %399, i32 7
  %temp.vect216 = insertelement <16 x i8> %temp.vect215, i8 %400, i32 8
  %temp.vect217 = insertelement <16 x i8> %temp.vect216, i8 %401, i32 9
  %temp.vect218 = insertelement <16 x i8> %temp.vect217, i8 %402, i32 10
  %temp.vect219 = insertelement <16 x i8> %temp.vect218, i8 %403, i32 11
  %temp.vect220 = insertelement <16 x i8> %temp.vect219, i8 %404, i32 12
  %temp.vect221 = insertelement <16 x i8> %temp.vect220, i8 %405, i32 13
  %temp.vect222 = insertelement <16 x i8> %temp.vect221, i8 %406, i32 14
  %temp.vect223 = insertelement <16 x i8> %temp.vect222, i8 %407, i32 15
  %408 = load <4 x i8> addrspace(3)* %block0, align 4
  %scalar47 = extractelement <4 x i8> %408, i32 2
  %temp226 = insertelement <16 x i8> undef, i8 %scalar47, i32 0
  %vector227 = shufflevector <16 x i8> %temp226, <16 x i8> undef, <16 x i32> zeroinitializer
  %409 = zext i8 %scalar47 to i32
  %410 = shl i32 %409, 1
  %411 = and i32 %409, 128
  %412 = xor i32 %410, 27
  %413 = icmp eq i32 %411, 0
  %a.5.in = select i1 %413, i32 %410, i32 %412
  %414 = shl i32 %a.5.in, 1
  %415 = and i32 %a.5.in, 128
  %416 = xor i32 %414, 27
  %417 = icmp eq i32 %415, 0
  %a.5.in.1 = select i1 %417, i32 %414, i32 %416
  %418 = shl i32 %a.5.in.1, 1
  %419 = and i32 %a.5.in.1, 128
  %420 = xor i32 %418, 27
  %421 = icmp eq i32 %419, 0
  %a.5.in.2 = select i1 %421, i32 %418, i32 %420
  %422 = shl i32 %a.5.in.2, 1
  %423 = and i32 %a.5.in.2, 128
  %424 = xor i32 %422, 27
  %425 = icmp eq i32 %423, 0
  %a.5.in.3 = select i1 %425, i32 %422, i32 %424
  %426 = shl i32 %a.5.in.3, 1
  %427 = and i32 %a.5.in.3, 128
  %428 = xor i32 %426, 27
  %429 = icmp eq i32 %427, 0
  %a.5.in.4 = select i1 %429, i32 %426, i32 %428
  %430 = shl i32 %a.5.in.4, 1
  %431 = and i32 %a.5.in.4, 128
  %432 = xor i32 %430, 27
  %433 = icmp eq i32 %431, 0
  %a.5.in.5 = select i1 %433, i32 %430, i32 %432
  %434 = shl i32 %a.5.in.5, 1
  %435 = lshr <16 x i8> %temp.vect223, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %436 = zext <16 x i8> %435 to <16 x i32>
  %437 = zext <16 x i8> %temp.vect223 to <16 x i32>
  %438 = lshr <16 x i8> %temp.vect223, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %439 = lshr <16 x i8> %temp.vect223, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %440 = and <16 x i32> %436, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %441 = and <16 x i32> %437, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %442 = zext <16 x i8> %438 to <16 x i32>
  %443 = zext <16 x i8> %439 to <16 x i32>
  %444 = icmp eq <16 x i32> %440, zeroinitializer
  %a.5 = trunc i32 %a.5.in to i8
  %temp224 = insertelement <16 x i8> undef, i8 %a.5, i32 0
  %vector225 = shufflevector <16 x i8> %temp224, <16 x i8> undef, <16 x i32> zeroinitializer
  %445 = icmp eq <16 x i32> %441, zeroinitializer
  %446 = and <16 x i32> %442, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %447 = lshr <16 x i8> %temp.vect223, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %448 = lshr <16 x i8> %temp.vect223, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %449 = and <16 x i32> %443, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %450 = select <16 x i1> %444, <16 x i8> zeroinitializer, <16 x i8> %vector225
  %451 = select <16 x i1> %445, <16 x i8> zeroinitializer, <16 x i8> %vector227
  %a.5.1 = trunc i32 %a.5.in.1 to i8
  %temp229 = insertelement <16 x i8> undef, i8 %a.5.1, i32 0
  %vector230 = shufflevector <16 x i8> %temp229, <16 x i8> undef, <16 x i32> zeroinitializer
  %452 = icmp eq <16 x i32> %446, zeroinitializer
  %453 = zext <16 x i8> %447 to <16 x i32>
  %454 = zext <16 x i8> %448 to <16 x i32>
  %455 = icmp eq <16 x i32> %449, zeroinitializer
  %a.5.2 = trunc i32 %a.5.in.2 to i8
  %temp231 = insertelement <16 x i8> undef, i8 %a.5.2, i32 0
  %vector232 = shufflevector <16 x i8> %temp231, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..1228 = xor <16 x i8> %450, %451
  %456 = select <16 x i1> %452, <16 x i8> zeroinitializer, <16 x i8> %vector230
  %457 = and <16 x i32> %453, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %458 = lshr <16 x i8> %temp.vect223, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %459 = and i32 %a.5.in.5, 128
  %460 = and <16 x i32> %454, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %461 = select <16 x i1> %455, <16 x i8> zeroinitializer, <16 x i8> %vector232
  %p.5..2233 = xor <16 x i8> %456, %p.5..1228
  %a.5.3 = trunc i32 %a.5.in.3 to i8
  %temp235 = insertelement <16 x i8> undef, i8 %a.5.3, i32 0
  %vector236 = shufflevector <16 x i8> %temp235, <16 x i8> undef, <16 x i32> zeroinitializer
  %462 = icmp eq <16 x i32> %457, zeroinitializer
  %463 = zext <16 x i8> %458 to <16 x i32>
  %464 = icmp eq i32 %459, 0
  %465 = xor i32 %434, 27
  %466 = icmp eq <16 x i32> %460, zeroinitializer
  %a.5.4 = trunc i32 %a.5.in.4 to i8
  %temp237 = insertelement <16 x i8> undef, i8 %a.5.4, i32 0
  %vector238 = shufflevector <16 x i8> %temp237, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..3234 = xor <16 x i8> %461, %p.5..2233
  %467 = select <16 x i1> %462, <16 x i8> zeroinitializer, <16 x i8> %vector236
  %468 = and <16 x i32> %463, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.5.in.6 = select i1 %464, i32 %434, i32 %465
  %469 = select <16 x i1> %466, <16 x i8> zeroinitializer, <16 x i8> %vector238
  %p.5..4239 = xor <16 x i8> %467, %p.5..3234
  %a.5.5 = trunc i32 %a.5.in.5 to i8
  %temp241 = insertelement <16 x i8> undef, i8 %a.5.5, i32 0
  %vector242 = shufflevector <16 x i8> %temp241, <16 x i8> undef, <16 x i32> zeroinitializer
  %470 = icmp eq <16 x i32> %468, zeroinitializer
  %471 = icmp sgt <16 x i8> %temp.vect223, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.5.6 = trunc i32 %a.5.in.6 to i8
  %temp243 = insertelement <16 x i8> undef, i8 %a.5.6, i32 0
  %vector244 = shufflevector <16 x i8> %temp243, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..5240 = xor <16 x i8> %469, %p.5..4239
  %472 = select <16 x i1> %470, <16 x i8> zeroinitializer, <16 x i8> %vector242
  %473 = select <16 x i1> %471, <16 x i8> zeroinitializer, <16 x i8> %vector244
  %p.5..6245 = xor <16 x i8> %472, %p.5..5240
  %p.5..7246 = xor <16 x i8> %473, %p.5..6245
  %"&(pSB[currWI].offset)1070" = add nuw i64 %CurrSBIndex..3, 512
  %"&pSB[currWI].offset1071" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1070"
  %CastToValueType1072 = bitcast i8* %"&pSB[currWI].offset1071" to <16 x i8>*
  store <16 x i8> %p.5..7246, <16 x i8>* %CastToValueType1072, align 16
  %"&(pSB[currWI].offset)567" = add nuw i64 %CurrSBIndex..3, 304
  %"&pSB[currWI].offset568" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)567"
  %CastToValueType569 = bitcast i8* %"&pSB[currWI].offset568" to <4 x i8>**
  %loadedValue570 = load <4 x i8>** %CastToValueType569, align 8
  %474 = load <4 x i8>* %loadedValue570, align 4
  %"&(pSB[currWI].offset)591" = add nuw i64 %CurrSBIndex..3, 312
  %"&pSB[currWI].offset592" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)591"
  %CastToValueType593 = bitcast i8* %"&pSB[currWI].offset592" to <4 x i8>**
  %loadedValue594 = load <4 x i8>** %CastToValueType593, align 8
  %475 = load <4 x i8>* %loadedValue594, align 4
  %"&(pSB[currWI].offset)615" = add nuw i64 %CurrSBIndex..3, 320
  %"&pSB[currWI].offset616" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)615"
  %CastToValueType617 = bitcast i8* %"&pSB[currWI].offset616" to <4 x i8>**
  %loadedValue618 = load <4 x i8>** %CastToValueType617, align 8
  %476 = load <4 x i8>* %loadedValue618, align 4
  %"&(pSB[currWI].offset)639" = add nuw i64 %CurrSBIndex..3, 328
  %"&pSB[currWI].offset640" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)639"
  %CastToValueType641 = bitcast i8* %"&pSB[currWI].offset640" to <4 x i8>**
  %loadedValue642 = load <4 x i8>** %CastToValueType641, align 8
  %477 = load <4 x i8>* %loadedValue642, align 4
  %"&(pSB[currWI].offset)663" = add nuw i64 %CurrSBIndex..3, 336
  %"&pSB[currWI].offset664" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)663"
  %CastToValueType665 = bitcast i8* %"&pSB[currWI].offset664" to <4 x i8>**
  %loadedValue666 = load <4 x i8>** %CastToValueType665, align 8
  %478 = load <4 x i8>* %loadedValue666, align 4
  %"&(pSB[currWI].offset)687" = add nuw i64 %CurrSBIndex..3, 344
  %"&pSB[currWI].offset688" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)687"
  %CastToValueType689 = bitcast i8* %"&pSB[currWI].offset688" to <4 x i8>**
  %loadedValue690 = load <4 x i8>** %CastToValueType689, align 8
  %479 = load <4 x i8>* %loadedValue690, align 4
  %"&(pSB[currWI].offset)711" = add nuw i64 %CurrSBIndex..3, 352
  %"&pSB[currWI].offset712" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)711"
  %CastToValueType713 = bitcast i8* %"&pSB[currWI].offset712" to <4 x i8>**
  %loadedValue714 = load <4 x i8>** %CastToValueType713, align 8
  %480 = load <4 x i8>* %loadedValue714, align 4
  %"&(pSB[currWI].offset)735" = add nuw i64 %CurrSBIndex..3, 360
  %"&pSB[currWI].offset736" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)735"
  %CastToValueType737 = bitcast i8* %"&pSB[currWI].offset736" to <4 x i8>**
  %loadedValue738 = load <4 x i8>** %CastToValueType737, align 8
  %481 = load <4 x i8>* %loadedValue738, align 4
  %"&(pSB[currWI].offset)759" = add nuw i64 %CurrSBIndex..3, 368
  %"&pSB[currWI].offset760" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)759"
  %CastToValueType761 = bitcast i8* %"&pSB[currWI].offset760" to <4 x i8>**
  %loadedValue762 = load <4 x i8>** %CastToValueType761, align 8
  %482 = load <4 x i8>* %loadedValue762, align 4
  %"&(pSB[currWI].offset)783" = add nuw i64 %CurrSBIndex..3, 376
  %"&pSB[currWI].offset784" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)783"
  %CastToValueType785 = bitcast i8* %"&pSB[currWI].offset784" to <4 x i8>**
  %loadedValue786 = load <4 x i8>** %CastToValueType785, align 8
  %483 = load <4 x i8>* %loadedValue786, align 4
  %"&(pSB[currWI].offset)807" = add nuw i64 %CurrSBIndex..3, 384
  %"&pSB[currWI].offset808" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)807"
  %CastToValueType809 = bitcast i8* %"&pSB[currWI].offset808" to <4 x i8>**
  %loadedValue810 = load <4 x i8>** %CastToValueType809, align 8
  %484 = load <4 x i8>* %loadedValue810, align 4
  %"&(pSB[currWI].offset)831" = add nuw i64 %CurrSBIndex..3, 392
  %"&pSB[currWI].offset832" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)831"
  %CastToValueType833 = bitcast i8* %"&pSB[currWI].offset832" to <4 x i8>**
  %loadedValue834 = load <4 x i8>** %CastToValueType833, align 8
  %485 = load <4 x i8>* %loadedValue834, align 4
  %"&(pSB[currWI].offset)855" = add nuw i64 %CurrSBIndex..3, 400
  %"&pSB[currWI].offset856" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)855"
  %CastToValueType857 = bitcast i8* %"&pSB[currWI].offset856" to <4 x i8>**
  %loadedValue858 = load <4 x i8>** %CastToValueType857, align 8
  %486 = load <4 x i8>* %loadedValue858, align 4
  %"&(pSB[currWI].offset)879" = add nuw i64 %CurrSBIndex..3, 408
  %"&pSB[currWI].offset880" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)879"
  %CastToValueType881 = bitcast i8* %"&pSB[currWI].offset880" to <4 x i8>**
  %loadedValue882 = load <4 x i8>** %CastToValueType881, align 8
  %487 = load <4 x i8>* %loadedValue882, align 4
  %"&(pSB[currWI].offset)903" = add nuw i64 %CurrSBIndex..3, 416
  %"&pSB[currWI].offset904" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)903"
  %CastToValueType905 = bitcast i8* %"&pSB[currWI].offset904" to <4 x i8>**
  %loadedValue906 = load <4 x i8>** %CastToValueType905, align 8
  %488 = load <4 x i8>* %loadedValue906, align 4
  %"&(pSB[currWI].offset)927" = add nuw i64 %CurrSBIndex..3, 424
  %"&pSB[currWI].offset928" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)927"
  %CastToValueType929 = bitcast i8* %"&pSB[currWI].offset928" to <4 x i8>**
  %loadedValue930 = load <4 x i8>** %CastToValueType929, align 8
  %489 = load <4 x i8>* %loadedValue930, align 4
  %490 = extractelement <4 x i8> %474, i32 0
  %491 = extractelement <4 x i8> %475, i32 0
  %492 = extractelement <4 x i8> %476, i32 0
  %493 = extractelement <4 x i8> %477, i32 0
  %494 = extractelement <4 x i8> %478, i32 0
  %495 = extractelement <4 x i8> %479, i32 0
  %496 = extractelement <4 x i8> %480, i32 0
  %497 = extractelement <4 x i8> %481, i32 0
  %498 = extractelement <4 x i8> %482, i32 0
  %499 = extractelement <4 x i8> %483, i32 0
  %500 = extractelement <4 x i8> %484, i32 0
  %501 = extractelement <4 x i8> %485, i32 0
  %502 = extractelement <4 x i8> %486, i32 0
  %503 = extractelement <4 x i8> %487, i32 0
  %504 = extractelement <4 x i8> %488, i32 0
  %505 = extractelement <4 x i8> %489, i32 0
  %temp.vect247 = insertelement <16 x i8> undef, i8 %490, i32 0
  %temp.vect248 = insertelement <16 x i8> %temp.vect247, i8 %491, i32 1
  %temp.vect249 = insertelement <16 x i8> %temp.vect248, i8 %492, i32 2
  %temp.vect250 = insertelement <16 x i8> %temp.vect249, i8 %493, i32 3
  %temp.vect251 = insertelement <16 x i8> %temp.vect250, i8 %494, i32 4
  %temp.vect252 = insertelement <16 x i8> %temp.vect251, i8 %495, i32 5
  %temp.vect253 = insertelement <16 x i8> %temp.vect252, i8 %496, i32 6
  %temp.vect254 = insertelement <16 x i8> %temp.vect253, i8 %497, i32 7
  %temp.vect255 = insertelement <16 x i8> %temp.vect254, i8 %498, i32 8
  %temp.vect256 = insertelement <16 x i8> %temp.vect255, i8 %499, i32 9
  %temp.vect257 = insertelement <16 x i8> %temp.vect256, i8 %500, i32 10
  %temp.vect258 = insertelement <16 x i8> %temp.vect257, i8 %501, i32 11
  %temp.vect259 = insertelement <16 x i8> %temp.vect258, i8 %502, i32 12
  %temp.vect260 = insertelement <16 x i8> %temp.vect259, i8 %503, i32 13
  %temp.vect261 = insertelement <16 x i8> %temp.vect260, i8 %504, i32 14
  %temp.vect262 = insertelement <16 x i8> %temp.vect261, i8 %505, i32 15
  %506 = load <4 x i8> addrspace(3)* %block0, align 4
  %scalar56 = extractelement <4 x i8> %506, i32 3
  %temp265 = insertelement <16 x i8> undef, i8 %scalar56, i32 0
  %vector266 = shufflevector <16 x i8> %temp265, <16 x i8> undef, <16 x i32> zeroinitializer
  %507 = zext i8 %scalar56 to i32
  %508 = shl i32 %507, 1
  %509 = and i32 %507, 128
  %510 = xor i32 %508, 27
  %511 = icmp eq i32 %509, 0
  %a.7.in = select i1 %511, i32 %508, i32 %510
  %512 = shl i32 %a.7.in, 1
  %513 = and i32 %a.7.in, 128
  %514 = xor i32 %512, 27
  %515 = icmp eq i32 %513, 0
  %a.7.in.1 = select i1 %515, i32 %512, i32 %514
  %516 = shl i32 %a.7.in.1, 1
  %517 = and i32 %a.7.in.1, 128
  %518 = xor i32 %516, 27
  %519 = icmp eq i32 %517, 0
  %a.7.in.2 = select i1 %519, i32 %516, i32 %518
  %520 = shl i32 %a.7.in.2, 1
  %521 = and i32 %a.7.in.2, 128
  %522 = xor i32 %520, 27
  %523 = icmp eq i32 %521, 0
  %a.7.in.3 = select i1 %523, i32 %520, i32 %522
  %524 = shl i32 %a.7.in.3, 1
  %525 = and i32 %a.7.in.3, 128
  %526 = xor i32 %524, 27
  %527 = icmp eq i32 %525, 0
  %a.7.in.4 = select i1 %527, i32 %524, i32 %526
  %528 = shl i32 %a.7.in.4, 1
  %529 = and i32 %a.7.in.4, 128
  %530 = xor i32 %528, 27
  %531 = icmp eq i32 %529, 0
  %a.7.in.5 = select i1 %531, i32 %528, i32 %530
  %532 = shl i32 %a.7.in.5, 1
  %533 = lshr <16 x i8> %temp.vect262, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %534 = zext <16 x i8> %533 to <16 x i32>
  %535 = zext <16 x i8> %temp.vect262 to <16 x i32>
  %536 = lshr <16 x i8> %temp.vect262, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %537 = lshr <16 x i8> %temp.vect262, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %538 = and <16 x i32> %534, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %539 = and <16 x i32> %535, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %540 = zext <16 x i8> %536 to <16 x i32>
  %541 = zext <16 x i8> %537 to <16 x i32>
  %542 = icmp eq <16 x i32> %538, zeroinitializer
  %a.7 = trunc i32 %a.7.in to i8
  %temp263 = insertelement <16 x i8> undef, i8 %a.7, i32 0
  %vector264 = shufflevector <16 x i8> %temp263, <16 x i8> undef, <16 x i32> zeroinitializer
  %543 = icmp eq <16 x i32> %539, zeroinitializer
  %544 = and <16 x i32> %540, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %545 = lshr <16 x i8> %temp.vect262, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %546 = lshr <16 x i8> %temp.vect262, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %547 = and <16 x i32> %541, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %548 = select <16 x i1> %542, <16 x i8> zeroinitializer, <16 x i8> %vector264
  %549 = select <16 x i1> %543, <16 x i8> zeroinitializer, <16 x i8> %vector266
  %a.7.1 = trunc i32 %a.7.in.1 to i8
  %temp268 = insertelement <16 x i8> undef, i8 %a.7.1, i32 0
  %vector269 = shufflevector <16 x i8> %temp268, <16 x i8> undef, <16 x i32> zeroinitializer
  %550 = icmp eq <16 x i32> %544, zeroinitializer
  %551 = zext <16 x i8> %545 to <16 x i32>
  %552 = zext <16 x i8> %546 to <16 x i32>
  %553 = icmp eq <16 x i32> %547, zeroinitializer
  %a.7.2 = trunc i32 %a.7.in.2 to i8
  %temp270 = insertelement <16 x i8> undef, i8 %a.7.2, i32 0
  %vector271 = shufflevector <16 x i8> %temp270, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..1267 = xor <16 x i8> %548, %549
  %554 = select <16 x i1> %550, <16 x i8> zeroinitializer, <16 x i8> %vector269
  %555 = and <16 x i32> %551, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %556 = lshr <16 x i8> %temp.vect262, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %557 = and i32 %a.7.in.5, 128
  %558 = and <16 x i32> %552, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %559 = select <16 x i1> %553, <16 x i8> zeroinitializer, <16 x i8> %vector271
  %p.7..2272 = xor <16 x i8> %554, %p.7..1267
  %a.7.3 = trunc i32 %a.7.in.3 to i8
  %temp274 = insertelement <16 x i8> undef, i8 %a.7.3, i32 0
  %vector275 = shufflevector <16 x i8> %temp274, <16 x i8> undef, <16 x i32> zeroinitializer
  %560 = icmp eq <16 x i32> %555, zeroinitializer
  %561 = zext <16 x i8> %556 to <16 x i32>
  %562 = icmp eq i32 %557, 0
  %563 = xor i32 %532, 27
  %564 = icmp eq <16 x i32> %558, zeroinitializer
  %a.7.4 = trunc i32 %a.7.in.4 to i8
  %temp276 = insertelement <16 x i8> undef, i8 %a.7.4, i32 0
  %vector277 = shufflevector <16 x i8> %temp276, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..3273 = xor <16 x i8> %559, %p.7..2272
  %565 = select <16 x i1> %560, <16 x i8> zeroinitializer, <16 x i8> %vector275
  %566 = and <16 x i32> %561, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.7.in.6 = select i1 %562, i32 %532, i32 %563
  %567 = select <16 x i1> %564, <16 x i8> zeroinitializer, <16 x i8> %vector277
  %p.7..4278 = xor <16 x i8> %565, %p.7..3273
  %a.7.5 = trunc i32 %a.7.in.5 to i8
  %temp280 = insertelement <16 x i8> undef, i8 %a.7.5, i32 0
  %vector281 = shufflevector <16 x i8> %temp280, <16 x i8> undef, <16 x i32> zeroinitializer
  %568 = icmp eq <16 x i32> %566, zeroinitializer
  %569 = icmp sgt <16 x i8> %temp.vect262, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.7.6 = trunc i32 %a.7.in.6 to i8
  %temp282 = insertelement <16 x i8> undef, i8 %a.7.6, i32 0
  %vector283 = shufflevector <16 x i8> %temp282, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..5279 = xor <16 x i8> %567, %p.7..4278
  %570 = select <16 x i1> %568, <16 x i8> zeroinitializer, <16 x i8> %vector281
  %571 = select <16 x i1> %569, <16 x i8> zeroinitializer, <16 x i8> %vector283
  %p.7..6284 = xor <16 x i8> %570, %p.7..5279
  %p.7..7285 = xor <16 x i8> %571, %p.7..6284
  %"&(pSB[currWI].offset)1074" = add nuw i64 %CurrSBIndex..3, 528
  %"&pSB[currWI].offset1075" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1074"
  %CastToValueType1076 = bitcast i8* %"&pSB[currWI].offset1075" to <16 x i8>*
  store <16 x i8> %p.7..7285, <16 x i8>* %CastToValueType1076, align 16
  %"&(pSB[currWI].offset)1078" = add nuw i64 %CurrSBIndex..3, 544
  %"&pSB[currWI].offset1079" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1078"
  %CastToValueType1080 = bitcast i8* %"&pSB[currWI].offset1079" to i64*
  %"&(pSB[currWI].offset)965" = add nuw i64 %CurrSBIndex..3, 440
  %"&pSB[currWI].offset966" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)965"
  %CastToValueType967 = bitcast i8* %"&pSB[currWI].offset966" to i64*
  %"&(pSB[currWI].offset)1150" = add nuw i64 %CurrSBIndex..3, 640
  %"&pSB[currWI].offset1151" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1150"
  %CastToValueType1152 = bitcast i8* %"&pSB[currWI].offset1151" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1186" = add nuw i64 %CurrSBIndex..3, 656
  %"&pSB[currWI].offset1187" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1186"
  %CastToValueType1188 = bitcast i8* %"&pSB[currWI].offset1187" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1222" = add nuw i64 %CurrSBIndex..3, 672
  %"&pSB[currWI].offset1223" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1222"
  %CastToValueType1224 = bitcast i8* %"&pSB[currWI].offset1223" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1258" = add nuw i64 %CurrSBIndex..3, 688
  %"&pSB[currWI].offset1259" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1258"
  %CastToValueType1260 = bitcast i8* %"&pSB[currWI].offset1259" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1294" = add nuw i64 %CurrSBIndex..3, 704
  %"&pSB[currWI].offset1295" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1294"
  %CastToValueType1296 = bitcast i8* %"&pSB[currWI].offset1295" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1330" = add nuw i64 %CurrSBIndex..3, 720
  %"&pSB[currWI].offset1331" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1330"
  %CastToValueType1332 = bitcast i8* %"&pSB[currWI].offset1331" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1366" = add nuw i64 %CurrSBIndex..3, 736
  %"&pSB[currWI].offset1367" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1366"
  %CastToValueType1368 = bitcast i8* %"&pSB[currWI].offset1367" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1402" = add nuw i64 %CurrSBIndex..3, 752
  %"&pSB[currWI].offset1403" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1402"
  %CastToValueType1404 = bitcast i8* %"&pSB[currWI].offset1403" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1438" = add nuw i64 %CurrSBIndex..3, 768
  %"&pSB[currWI].offset1439" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1438"
  %CastToValueType1440 = bitcast i8* %"&pSB[currWI].offset1439" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1474" = add nuw i64 %CurrSBIndex..3, 784
  %"&pSB[currWI].offset1475" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1474"
  %CastToValueType1476 = bitcast i8* %"&pSB[currWI].offset1475" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1510" = add nuw i64 %CurrSBIndex..3, 800
  %"&pSB[currWI].offset1511" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1510"
  %CastToValueType1512 = bitcast i8* %"&pSB[currWI].offset1511" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1546" = add nuw i64 %CurrSBIndex..3, 816
  %"&pSB[currWI].offset1547" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1546"
  %CastToValueType1548 = bitcast i8* %"&pSB[currWI].offset1547" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1582" = add nuw i64 %CurrSBIndex..3, 832
  %"&pSB[currWI].offset1583" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1582"
  %CastToValueType1584 = bitcast i8* %"&pSB[currWI].offset1583" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1618" = add nuw i64 %CurrSBIndex..3, 848
  %"&pSB[currWI].offset1619" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1618"
  %CastToValueType1620 = bitcast i8* %"&pSB[currWI].offset1619" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1654" = add nuw i64 %CurrSBIndex..3, 864
  %"&pSB[currWI].offset1655" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1654"
  %CastToValueType1656 = bitcast i8* %"&pSB[currWI].offset1655" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1690" = add nuw i64 %CurrSBIndex..3, 880
  %"&pSB[currWI].offset1691" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1690"
  %CastToValueType1692 = bitcast i8* %"&pSB[currWI].offset1691" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1146" = add nuw i64 %CurrSBIndex..3, 640
  %"&pSB[currWI].offset1147" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1146"
  %CastToValueType1148 = bitcast i8* %"&pSB[currWI].offset1147" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1182" = add nuw i64 %CurrSBIndex..3, 656
  %"&pSB[currWI].offset1183" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1182"
  %CastToValueType1184 = bitcast i8* %"&pSB[currWI].offset1183" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1218" = add nuw i64 %CurrSBIndex..3, 672
  %"&pSB[currWI].offset1219" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1218"
  %CastToValueType1220 = bitcast i8* %"&pSB[currWI].offset1219" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1254" = add nuw i64 %CurrSBIndex..3, 688
  %"&pSB[currWI].offset1255" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1254"
  %CastToValueType1256 = bitcast i8* %"&pSB[currWI].offset1255" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1290" = add nuw i64 %CurrSBIndex..3, 704
  %"&pSB[currWI].offset1291" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1290"
  %CastToValueType1292 = bitcast i8* %"&pSB[currWI].offset1291" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1326" = add nuw i64 %CurrSBIndex..3, 720
  %"&pSB[currWI].offset1327" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1326"
  %CastToValueType1328 = bitcast i8* %"&pSB[currWI].offset1327" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1362" = add nuw i64 %CurrSBIndex..3, 736
  %"&pSB[currWI].offset1363" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1362"
  %CastToValueType1364 = bitcast i8* %"&pSB[currWI].offset1363" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1398" = add nuw i64 %CurrSBIndex..3, 752
  %"&pSB[currWI].offset1399" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1398"
  %CastToValueType1400 = bitcast i8* %"&pSB[currWI].offset1399" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1434" = add nuw i64 %CurrSBIndex..3, 768
  %"&pSB[currWI].offset1435" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1434"
  %CastToValueType1436 = bitcast i8* %"&pSB[currWI].offset1435" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1470" = add nuw i64 %CurrSBIndex..3, 784
  %"&pSB[currWI].offset1471" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1470"
  %CastToValueType1472 = bitcast i8* %"&pSB[currWI].offset1471" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1506" = add nuw i64 %CurrSBIndex..3, 800
  %"&pSB[currWI].offset1507" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1506"
  %CastToValueType1508 = bitcast i8* %"&pSB[currWI].offset1507" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1542" = add nuw i64 %CurrSBIndex..3, 816
  %"&pSB[currWI].offset1543" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1542"
  %CastToValueType1544 = bitcast i8* %"&pSB[currWI].offset1543" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1578" = add nuw i64 %CurrSBIndex..3, 832
  %"&pSB[currWI].offset1579" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1578"
  %CastToValueType1580 = bitcast i8* %"&pSB[currWI].offset1579" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1614" = add nuw i64 %CurrSBIndex..3, 848
  %"&pSB[currWI].offset1615" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1614"
  %CastToValueType1616 = bitcast i8* %"&pSB[currWI].offset1615" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1650" = add nuw i64 %CurrSBIndex..3, 864
  %"&pSB[currWI].offset1651" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1650"
  %CastToValueType1652 = bitcast i8* %"&pSB[currWI].offset1651" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1686" = add nuw i64 %CurrSBIndex..3, 880
  %"&pSB[currWI].offset1687" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1686"
  %CastToValueType1688 = bitcast i8* %"&pSB[currWI].offset1687" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1142" = add nuw i64 %CurrSBIndex..3, 640
  %"&pSB[currWI].offset1143" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1142"
  %CastToValueType1144 = bitcast i8* %"&pSB[currWI].offset1143" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1178" = add nuw i64 %CurrSBIndex..3, 656
  %"&pSB[currWI].offset1179" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1178"
  %CastToValueType1180 = bitcast i8* %"&pSB[currWI].offset1179" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1214" = add nuw i64 %CurrSBIndex..3, 672
  %"&pSB[currWI].offset1215" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1214"
  %CastToValueType1216 = bitcast i8* %"&pSB[currWI].offset1215" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1250" = add nuw i64 %CurrSBIndex..3, 688
  %"&pSB[currWI].offset1251" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1250"
  %CastToValueType1252 = bitcast i8* %"&pSB[currWI].offset1251" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1286" = add nuw i64 %CurrSBIndex..3, 704
  %"&pSB[currWI].offset1287" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1286"
  %CastToValueType1288 = bitcast i8* %"&pSB[currWI].offset1287" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1322" = add nuw i64 %CurrSBIndex..3, 720
  %"&pSB[currWI].offset1323" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1322"
  %CastToValueType1324 = bitcast i8* %"&pSB[currWI].offset1323" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1358" = add nuw i64 %CurrSBIndex..3, 736
  %"&pSB[currWI].offset1359" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1358"
  %CastToValueType1360 = bitcast i8* %"&pSB[currWI].offset1359" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1394" = add nuw i64 %CurrSBIndex..3, 752
  %"&pSB[currWI].offset1395" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1394"
  %CastToValueType1396 = bitcast i8* %"&pSB[currWI].offset1395" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1430" = add nuw i64 %CurrSBIndex..3, 768
  %"&pSB[currWI].offset1431" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1430"
  %CastToValueType1432 = bitcast i8* %"&pSB[currWI].offset1431" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1466" = add nuw i64 %CurrSBIndex..3, 784
  %"&pSB[currWI].offset1467" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1466"
  %CastToValueType1468 = bitcast i8* %"&pSB[currWI].offset1467" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1502" = add nuw i64 %CurrSBIndex..3, 800
  %"&pSB[currWI].offset1503" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1502"
  %CastToValueType1504 = bitcast i8* %"&pSB[currWI].offset1503" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1538" = add nuw i64 %CurrSBIndex..3, 816
  %"&pSB[currWI].offset1539" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1538"
  %CastToValueType1540 = bitcast i8* %"&pSB[currWI].offset1539" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1574" = add nuw i64 %CurrSBIndex..3, 832
  %"&pSB[currWI].offset1575" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1574"
  %CastToValueType1576 = bitcast i8* %"&pSB[currWI].offset1575" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1610" = add nuw i64 %CurrSBIndex..3, 848
  %"&pSB[currWI].offset1611" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1610"
  %CastToValueType1612 = bitcast i8* %"&pSB[currWI].offset1611" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1646" = add nuw i64 %CurrSBIndex..3, 864
  %"&pSB[currWI].offset1647" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1646"
  %CastToValueType1648 = bitcast i8* %"&pSB[currWI].offset1647" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1682" = add nuw i64 %CurrSBIndex..3, 880
  %"&pSB[currWI].offset1683" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1682"
  %CastToValueType1684 = bitcast i8* %"&pSB[currWI].offset1683" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1138" = add nuw i64 %CurrSBIndex..3, 640
  %"&pSB[currWI].offset1139" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1138"
  %CastToValueType1140 = bitcast i8* %"&pSB[currWI].offset1139" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1174" = add nuw i64 %CurrSBIndex..3, 656
  %"&pSB[currWI].offset1175" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1174"
  %CastToValueType1176 = bitcast i8* %"&pSB[currWI].offset1175" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1210" = add nuw i64 %CurrSBIndex..3, 672
  %"&pSB[currWI].offset1211" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1210"
  %CastToValueType1212 = bitcast i8* %"&pSB[currWI].offset1211" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1246" = add nuw i64 %CurrSBIndex..3, 688
  %"&pSB[currWI].offset1247" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1246"
  %CastToValueType1248 = bitcast i8* %"&pSB[currWI].offset1247" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1282" = add nuw i64 %CurrSBIndex..3, 704
  %"&pSB[currWI].offset1283" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1282"
  %CastToValueType1284 = bitcast i8* %"&pSB[currWI].offset1283" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1318" = add nuw i64 %CurrSBIndex..3, 720
  %"&pSB[currWI].offset1319" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1318"
  %CastToValueType1320 = bitcast i8* %"&pSB[currWI].offset1319" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1354" = add nuw i64 %CurrSBIndex..3, 736
  %"&pSB[currWI].offset1355" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1354"
  %CastToValueType1356 = bitcast i8* %"&pSB[currWI].offset1355" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1390" = add nuw i64 %CurrSBIndex..3, 752
  %"&pSB[currWI].offset1391" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1390"
  %CastToValueType1392 = bitcast i8* %"&pSB[currWI].offset1391" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1426" = add nuw i64 %CurrSBIndex..3, 768
  %"&pSB[currWI].offset1427" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1426"
  %CastToValueType1428 = bitcast i8* %"&pSB[currWI].offset1427" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1462" = add nuw i64 %CurrSBIndex..3, 784
  %"&pSB[currWI].offset1463" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1462"
  %CastToValueType1464 = bitcast i8* %"&pSB[currWI].offset1463" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1498" = add nuw i64 %CurrSBIndex..3, 800
  %"&pSB[currWI].offset1499" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1498"
  %CastToValueType1500 = bitcast i8* %"&pSB[currWI].offset1499" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1534" = add nuw i64 %CurrSBIndex..3, 816
  %"&pSB[currWI].offset1535" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1534"
  %CastToValueType1536 = bitcast i8* %"&pSB[currWI].offset1535" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1570" = add nuw i64 %CurrSBIndex..3, 832
  %"&pSB[currWI].offset1571" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1570"
  %CastToValueType1572 = bitcast i8* %"&pSB[currWI].offset1571" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1606" = add nuw i64 %CurrSBIndex..3, 848
  %"&pSB[currWI].offset1607" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1606"
  %CastToValueType1608 = bitcast i8* %"&pSB[currWI].offset1607" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1642" = add nuw i64 %CurrSBIndex..3, 864
  %"&pSB[currWI].offset1643" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1642"
  %CastToValueType1644 = bitcast i8* %"&pSB[currWI].offset1643" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1678" = add nuw i64 %CurrSBIndex..3, 880
  %"&pSB[currWI].offset1679" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1678"
  %CastToValueType1680 = bitcast i8* %"&pSB[currWI].offset1679" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1082" = add nuw i64 %CurrSBIndex..3, 560
  %"&pSB[currWI].offset1083" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1082"
  %CastToValueType1084 = bitcast i8* %"&pSB[currWI].offset1083" to <16 x i8>*
  %"&(pSB[currWI].offset)1091" = add nuw i64 %CurrSBIndex..3, 576
  %"&pSB[currWI].offset1092" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1091"
  %CastToValueType1093 = bitcast i8* %"&pSB[currWI].offset1092" to <16 x i8>*
  %"&(pSB[currWI].offset)1100" = add nuw i64 %CurrSBIndex..3, 592
  %"&pSB[currWI].offset1101" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1100"
  %CastToValueType1102 = bitcast i8* %"&pSB[currWI].offset1101" to <16 x i8>*
  %"&(pSB[currWI].offset)1109" = add nuw i64 %CurrSBIndex..3, 608
  %"&pSB[currWI].offset1110" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1109"
  %CastToValueType1111 = bitcast i8* %"&pSB[currWI].offset1110" to <16 x i8>*
  br label %572

; <label>:572                                     ; preds = %572, %SyncBB
  %indvar = phi i64 [ 0, %SyncBB ], [ %tmp, %572 ]
  %vectorPHI = phi <16 x i8> [ %p.7..7285, %SyncBB ], [ %1036, %572 ]
  %vectorPHI286 = phi <16 x i8> [ %p.5..7246, %SyncBB ], [ %1035, %572 ]
  %vectorPHI287 = phi <16 x i8> [ %p.3..7207, %SyncBB ], [ %1034, %572 ]
  %vectorPHI288 = phi <16 x i8> [ %p.1..7168, %SyncBB ], [ %1033, %572 ]
  %tmp = add i64 %indvar, 1
  store i64 %tmp, i64* %CastToValueType1080, align 8
  %scevgep = getelementptr <4 x i8> addrspace(3)* %block0, i64 %tmp
  %loadedValue968 = load i64* %CastToValueType967, align 8
  %tmp77 = add i64 %loadedValue968, %indvar
  %573 = and i64 %tmp77, 3
  %574 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1152, i64 0, i64 %573
  %575 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1188, i64 0, i64 %573
  %576 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1224, i64 0, i64 %573
  %577 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1260, i64 0, i64 %573
  %578 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1296, i64 0, i64 %573
  %579 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1332, i64 0, i64 %573
  %580 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1368, i64 0, i64 %573
  %581 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1404, i64 0, i64 %573
  %582 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1440, i64 0, i64 %573
  %583 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1476, i64 0, i64 %573
  %584 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1512, i64 0, i64 %573
  %585 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1548, i64 0, i64 %573
  %586 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1584, i64 0, i64 %573
  %587 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1620, i64 0, i64 %573
  %588 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1656, i64 0, i64 %573
  %589 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1692, i64 0, i64 %573
  %590 = load <4 x i8>* %574, align 4
  %591 = load <4 x i8>* %575, align 4
  %592 = load <4 x i8>* %576, align 4
  %593 = load <4 x i8>* %577, align 4
  %594 = load <4 x i8>* %578, align 4
  %595 = load <4 x i8>* %579, align 4
  %596 = load <4 x i8>* %580, align 4
  %597 = load <4 x i8>* %581, align 4
  %598 = load <4 x i8>* %582, align 4
  %599 = load <4 x i8>* %583, align 4
  %600 = load <4 x i8>* %584, align 4
  %601 = load <4 x i8>* %585, align 4
  %602 = load <4 x i8>* %586, align 4
  %603 = load <4 x i8>* %587, align 4
  %604 = load <4 x i8>* %588, align 4
  %605 = load <4 x i8>* %589, align 4
  %606 = extractelement <4 x i8> %590, i32 0
  %607 = extractelement <4 x i8> %591, i32 0
  %608 = extractelement <4 x i8> %592, i32 0
  %609 = extractelement <4 x i8> %593, i32 0
  %610 = extractelement <4 x i8> %594, i32 0
  %611 = extractelement <4 x i8> %595, i32 0
  %612 = extractelement <4 x i8> %596, i32 0
  %613 = extractelement <4 x i8> %597, i32 0
  %614 = extractelement <4 x i8> %598, i32 0
  %615 = extractelement <4 x i8> %599, i32 0
  %616 = extractelement <4 x i8> %600, i32 0
  %617 = extractelement <4 x i8> %601, i32 0
  %618 = extractelement <4 x i8> %602, i32 0
  %619 = extractelement <4 x i8> %603, i32 0
  %620 = extractelement <4 x i8> %604, i32 0
  %621 = extractelement <4 x i8> %605, i32 0
  %temp.vect289 = insertelement <16 x i8> undef, i8 %606, i32 0
  %temp.vect290 = insertelement <16 x i8> %temp.vect289, i8 %607, i32 1
  %temp.vect291 = insertelement <16 x i8> %temp.vect290, i8 %608, i32 2
  %temp.vect292 = insertelement <16 x i8> %temp.vect291, i8 %609, i32 3
  %temp.vect293 = insertelement <16 x i8> %temp.vect292, i8 %610, i32 4
  %temp.vect294 = insertelement <16 x i8> %temp.vect293, i8 %611, i32 5
  %temp.vect295 = insertelement <16 x i8> %temp.vect294, i8 %612, i32 6
  %temp.vect296 = insertelement <16 x i8> %temp.vect295, i8 %613, i32 7
  %temp.vect297 = insertelement <16 x i8> %temp.vect296, i8 %614, i32 8
  %temp.vect298 = insertelement <16 x i8> %temp.vect297, i8 %615, i32 9
  %temp.vect299 = insertelement <16 x i8> %temp.vect298, i8 %616, i32 10
  %temp.vect300 = insertelement <16 x i8> %temp.vect299, i8 %617, i32 11
  %temp.vect301 = insertelement <16 x i8> %temp.vect300, i8 %618, i32 12
  %temp.vect302 = insertelement <16 x i8> %temp.vect301, i8 %619, i32 13
  %temp.vect303 = insertelement <16 x i8> %temp.vect302, i8 %620, i32 14
  %temp.vect304 = insertelement <16 x i8> %temp.vect303, i8 %621, i32 15
  %622 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar61 = extractelement <4 x i8> %622, i32 0
  %temp307 = insertelement <16 x i8> undef, i8 %scalar61, i32 0
  %vector308 = shufflevector <16 x i8> %temp307, <16 x i8> undef, <16 x i32> zeroinitializer
  %623 = zext i8 %scalar61 to i32
  %624 = shl i32 %623, 1
  %625 = and i32 %623, 128
  %626 = xor i32 %624, 27
  %627 = icmp eq i32 %625, 0
  %a.9.in = select i1 %627, i32 %624, i32 %626
  %628 = shl i32 %a.9.in, 1
  %629 = and i32 %a.9.in, 128
  %630 = xor i32 %628, 27
  %631 = icmp eq i32 %629, 0
  %a.9.in.1 = select i1 %631, i32 %628, i32 %630
  %632 = shl i32 %a.9.in.1, 1
  %633 = and i32 %a.9.in.1, 128
  %634 = xor i32 %632, 27
  %635 = icmp eq i32 %633, 0
  %a.9.in.2 = select i1 %635, i32 %632, i32 %634
  %636 = shl i32 %a.9.in.2, 1
  %637 = and i32 %a.9.in.2, 128
  %638 = xor i32 %636, 27
  %639 = icmp eq i32 %637, 0
  %a.9.in.3 = select i1 %639, i32 %636, i32 %638
  %640 = shl i32 %a.9.in.3, 1
  %641 = and i32 %a.9.in.3, 128
  %642 = xor i32 %640, 27
  %643 = icmp eq i32 %641, 0
  %a.9.in.4 = select i1 %643, i32 %640, i32 %642
  %644 = shl i32 %a.9.in.4, 1
  %645 = and i32 %a.9.in.4, 128
  %646 = xor i32 %644, 27
  %647 = icmp eq i32 %645, 0
  %a.9.in.5 = select i1 %647, i32 %644, i32 %646
  %648 = shl i32 %a.9.in.5, 1
  %649 = lshr <16 x i8> %temp.vect304, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %650 = zext <16 x i8> %649 to <16 x i32>
  %651 = zext <16 x i8> %temp.vect304 to <16 x i32>
  %652 = lshr <16 x i8> %temp.vect304, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %653 = lshr <16 x i8> %temp.vect304, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %654 = and <16 x i32> %650, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %655 = and <16 x i32> %651, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %656 = zext <16 x i8> %652 to <16 x i32>
  %657 = zext <16 x i8> %653 to <16 x i32>
  %658 = icmp eq <16 x i32> %654, zeroinitializer
  %a.9 = trunc i32 %a.9.in to i8
  %temp305 = insertelement <16 x i8> undef, i8 %a.9, i32 0
  %vector306 = shufflevector <16 x i8> %temp305, <16 x i8> undef, <16 x i32> zeroinitializer
  %659 = icmp eq <16 x i32> %655, zeroinitializer
  %660 = and <16 x i32> %656, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %661 = lshr <16 x i8> %temp.vect304, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %662 = lshr <16 x i8> %temp.vect304, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %663 = and <16 x i32> %657, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %664 = select <16 x i1> %658, <16 x i8> zeroinitializer, <16 x i8> %vector306
  %665 = select <16 x i1> %659, <16 x i8> zeroinitializer, <16 x i8> %vector308
  %a.9.1 = trunc i32 %a.9.in.1 to i8
  %temp310 = insertelement <16 x i8> undef, i8 %a.9.1, i32 0
  %vector311 = shufflevector <16 x i8> %temp310, <16 x i8> undef, <16 x i32> zeroinitializer
  %666 = icmp eq <16 x i32> %660, zeroinitializer
  %667 = zext <16 x i8> %661 to <16 x i32>
  %668 = zext <16 x i8> %662 to <16 x i32>
  %669 = icmp eq <16 x i32> %663, zeroinitializer
  %a.9.2 = trunc i32 %a.9.in.2 to i8
  %temp312 = insertelement <16 x i8> undef, i8 %a.9.2, i32 0
  %vector313 = shufflevector <16 x i8> %temp312, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..1309 = xor <16 x i8> %664, %665
  %670 = select <16 x i1> %666, <16 x i8> zeroinitializer, <16 x i8> %vector311
  %671 = and <16 x i32> %667, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %672 = lshr <16 x i8> %temp.vect304, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %673 = and i32 %a.9.in.5, 128
  %674 = and <16 x i32> %668, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %675 = select <16 x i1> %669, <16 x i8> zeroinitializer, <16 x i8> %vector313
  %p.9..2314 = xor <16 x i8> %670, %p.9..1309
  %a.9.3 = trunc i32 %a.9.in.3 to i8
  %temp316 = insertelement <16 x i8> undef, i8 %a.9.3, i32 0
  %vector317 = shufflevector <16 x i8> %temp316, <16 x i8> undef, <16 x i32> zeroinitializer
  %676 = icmp eq <16 x i32> %671, zeroinitializer
  %677 = zext <16 x i8> %672 to <16 x i32>
  %678 = icmp eq i32 %673, 0
  %679 = xor i32 %648, 27
  %680 = icmp eq <16 x i32> %674, zeroinitializer
  %a.9.4 = trunc i32 %a.9.in.4 to i8
  %temp318 = insertelement <16 x i8> undef, i8 %a.9.4, i32 0
  %vector319 = shufflevector <16 x i8> %temp318, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..3315 = xor <16 x i8> %675, %p.9..2314
  %681 = select <16 x i1> %676, <16 x i8> zeroinitializer, <16 x i8> %vector317
  %682 = and <16 x i32> %677, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.9.in.6 = select i1 %678, i32 %648, i32 %679
  %683 = select <16 x i1> %680, <16 x i8> zeroinitializer, <16 x i8> %vector319
  %p.9..4320 = xor <16 x i8> %681, %p.9..3315
  %a.9.5 = trunc i32 %a.9.in.5 to i8
  %temp322 = insertelement <16 x i8> undef, i8 %a.9.5, i32 0
  %vector323 = shufflevector <16 x i8> %temp322, <16 x i8> undef, <16 x i32> zeroinitializer
  %684 = icmp eq <16 x i32> %682, zeroinitializer
  %685 = icmp sgt <16 x i8> %temp.vect304, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.9.6 = trunc i32 %a.9.in.6 to i8
  %temp324 = insertelement <16 x i8> undef, i8 %a.9.6, i32 0
  %vector325 = shufflevector <16 x i8> %temp324, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..5321 = xor <16 x i8> %683, %p.9..4320
  %686 = select <16 x i1> %684, <16 x i8> zeroinitializer, <16 x i8> %vector323
  %687 = select <16 x i1> %685, <16 x i8> zeroinitializer, <16 x i8> %vector325
  %p.9..6326 = xor <16 x i8> %686, %p.9..5321
  %p.9..7327 = xor <16 x i8> %687, %p.9..6326
  %688 = and i64 %tmp77, 3
  %689 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1148, i64 0, i64 %688
  %690 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1184, i64 0, i64 %688
  %691 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1220, i64 0, i64 %688
  %692 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1256, i64 0, i64 %688
  %693 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1292, i64 0, i64 %688
  %694 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1328, i64 0, i64 %688
  %695 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1364, i64 0, i64 %688
  %696 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1400, i64 0, i64 %688
  %697 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1436, i64 0, i64 %688
  %698 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1472, i64 0, i64 %688
  %699 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1508, i64 0, i64 %688
  %700 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1544, i64 0, i64 %688
  %701 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1580, i64 0, i64 %688
  %702 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1616, i64 0, i64 %688
  %703 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1652, i64 0, i64 %688
  %704 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1688, i64 0, i64 %688
  %705 = load <4 x i8>* %689, align 4
  %706 = load <4 x i8>* %690, align 4
  %707 = load <4 x i8>* %691, align 4
  %708 = load <4 x i8>* %692, align 4
  %709 = load <4 x i8>* %693, align 4
  %710 = load <4 x i8>* %694, align 4
  %711 = load <4 x i8>* %695, align 4
  %712 = load <4 x i8>* %696, align 4
  %713 = load <4 x i8>* %697, align 4
  %714 = load <4 x i8>* %698, align 4
  %715 = load <4 x i8>* %699, align 4
  %716 = load <4 x i8>* %700, align 4
  %717 = load <4 x i8>* %701, align 4
  %718 = load <4 x i8>* %702, align 4
  %719 = load <4 x i8>* %703, align 4
  %720 = load <4 x i8>* %704, align 4
  %721 = extractelement <4 x i8> %705, i32 0
  %722 = extractelement <4 x i8> %706, i32 0
  %723 = extractelement <4 x i8> %707, i32 0
  %724 = extractelement <4 x i8> %708, i32 0
  %725 = extractelement <4 x i8> %709, i32 0
  %726 = extractelement <4 x i8> %710, i32 0
  %727 = extractelement <4 x i8> %711, i32 0
  %728 = extractelement <4 x i8> %712, i32 0
  %729 = extractelement <4 x i8> %713, i32 0
  %730 = extractelement <4 x i8> %714, i32 0
  %731 = extractelement <4 x i8> %715, i32 0
  %732 = extractelement <4 x i8> %716, i32 0
  %733 = extractelement <4 x i8> %717, i32 0
  %734 = extractelement <4 x i8> %718, i32 0
  %735 = extractelement <4 x i8> %719, i32 0
  %736 = extractelement <4 x i8> %720, i32 0
  %temp.vect328 = insertelement <16 x i8> undef, i8 %721, i32 0
  %temp.vect329 = insertelement <16 x i8> %temp.vect328, i8 %722, i32 1
  %temp.vect330 = insertelement <16 x i8> %temp.vect329, i8 %723, i32 2
  %temp.vect331 = insertelement <16 x i8> %temp.vect330, i8 %724, i32 3
  %temp.vect332 = insertelement <16 x i8> %temp.vect331, i8 %725, i32 4
  %temp.vect333 = insertelement <16 x i8> %temp.vect332, i8 %726, i32 5
  %temp.vect334 = insertelement <16 x i8> %temp.vect333, i8 %727, i32 6
  %temp.vect335 = insertelement <16 x i8> %temp.vect334, i8 %728, i32 7
  %temp.vect336 = insertelement <16 x i8> %temp.vect335, i8 %729, i32 8
  %temp.vect337 = insertelement <16 x i8> %temp.vect336, i8 %730, i32 9
  %temp.vect338 = insertelement <16 x i8> %temp.vect337, i8 %731, i32 10
  %temp.vect339 = insertelement <16 x i8> %temp.vect338, i8 %732, i32 11
  %temp.vect340 = insertelement <16 x i8> %temp.vect339, i8 %733, i32 12
  %temp.vect341 = insertelement <16 x i8> %temp.vect340, i8 %734, i32 13
  %temp.vect342 = insertelement <16 x i8> %temp.vect341, i8 %735, i32 14
  %temp.vect343 = insertelement <16 x i8> %temp.vect342, i8 %736, i32 15
  %737 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar70 = extractelement <4 x i8> %737, i32 1
  %temp346 = insertelement <16 x i8> undef, i8 %scalar70, i32 0
  %vector347 = shufflevector <16 x i8> %temp346, <16 x i8> undef, <16 x i32> zeroinitializer
  %738 = zext i8 %scalar70 to i32
  %739 = shl i32 %738, 1
  %740 = and i32 %738, 128
  %741 = xor i32 %739, 27
  %742 = icmp eq i32 %740, 0
  %a.11.in = select i1 %742, i32 %739, i32 %741
  %743 = shl i32 %a.11.in, 1
  %744 = and i32 %a.11.in, 128
  %745 = xor i32 %743, 27
  %746 = icmp eq i32 %744, 0
  %a.11.in.1 = select i1 %746, i32 %743, i32 %745
  %747 = shl i32 %a.11.in.1, 1
  %748 = and i32 %a.11.in.1, 128
  %749 = xor i32 %747, 27
  %750 = icmp eq i32 %748, 0
  %a.11.in.2 = select i1 %750, i32 %747, i32 %749
  %751 = shl i32 %a.11.in.2, 1
  %752 = and i32 %a.11.in.2, 128
  %753 = xor i32 %751, 27
  %754 = icmp eq i32 %752, 0
  %a.11.in.3 = select i1 %754, i32 %751, i32 %753
  %755 = shl i32 %a.11.in.3, 1
  %756 = and i32 %a.11.in.3, 128
  %757 = xor i32 %755, 27
  %758 = icmp eq i32 %756, 0
  %a.11.in.4 = select i1 %758, i32 %755, i32 %757
  %759 = shl i32 %a.11.in.4, 1
  %760 = and i32 %a.11.in.4, 128
  %761 = xor i32 %759, 27
  %762 = icmp eq i32 %760, 0
  %a.11.in.5 = select i1 %762, i32 %759, i32 %761
  %763 = shl i32 %a.11.in.5, 1
  %764 = lshr <16 x i8> %temp.vect343, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %765 = zext <16 x i8> %764 to <16 x i32>
  %766 = zext <16 x i8> %temp.vect343 to <16 x i32>
  %767 = lshr <16 x i8> %temp.vect343, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %768 = lshr <16 x i8> %temp.vect343, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %769 = and <16 x i32> %765, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %770 = and <16 x i32> %766, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %771 = zext <16 x i8> %767 to <16 x i32>
  %772 = zext <16 x i8> %768 to <16 x i32>
  %773 = icmp eq <16 x i32> %769, zeroinitializer
  %a.11 = trunc i32 %a.11.in to i8
  %temp344 = insertelement <16 x i8> undef, i8 %a.11, i32 0
  %vector345 = shufflevector <16 x i8> %temp344, <16 x i8> undef, <16 x i32> zeroinitializer
  %774 = icmp eq <16 x i32> %770, zeroinitializer
  %775 = and <16 x i32> %771, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %776 = lshr <16 x i8> %temp.vect343, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %777 = lshr <16 x i8> %temp.vect343, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %778 = and <16 x i32> %772, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %779 = select <16 x i1> %773, <16 x i8> zeroinitializer, <16 x i8> %vector345
  %780 = select <16 x i1> %774, <16 x i8> zeroinitializer, <16 x i8> %vector347
  %a.11.1 = trunc i32 %a.11.in.1 to i8
  %temp349 = insertelement <16 x i8> undef, i8 %a.11.1, i32 0
  %vector350 = shufflevector <16 x i8> %temp349, <16 x i8> undef, <16 x i32> zeroinitializer
  %781 = icmp eq <16 x i32> %775, zeroinitializer
  %782 = zext <16 x i8> %776 to <16 x i32>
  %783 = zext <16 x i8> %777 to <16 x i32>
  %784 = icmp eq <16 x i32> %778, zeroinitializer
  %a.11.2 = trunc i32 %a.11.in.2 to i8
  %temp351 = insertelement <16 x i8> undef, i8 %a.11.2, i32 0
  %vector352 = shufflevector <16 x i8> %temp351, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..1348 = xor <16 x i8> %779, %780
  %785 = select <16 x i1> %781, <16 x i8> zeroinitializer, <16 x i8> %vector350
  %786 = and <16 x i32> %782, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %787 = lshr <16 x i8> %temp.vect343, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %788 = and i32 %a.11.in.5, 128
  %789 = and <16 x i32> %783, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %790 = select <16 x i1> %784, <16 x i8> zeroinitializer, <16 x i8> %vector352
  %p.11..2353 = xor <16 x i8> %785, %p.11..1348
  %a.11.3 = trunc i32 %a.11.in.3 to i8
  %temp355 = insertelement <16 x i8> undef, i8 %a.11.3, i32 0
  %vector356 = shufflevector <16 x i8> %temp355, <16 x i8> undef, <16 x i32> zeroinitializer
  %791 = icmp eq <16 x i32> %786, zeroinitializer
  %792 = zext <16 x i8> %787 to <16 x i32>
  %793 = icmp eq i32 %788, 0
  %794 = xor i32 %763, 27
  %795 = icmp eq <16 x i32> %789, zeroinitializer
  %a.11.4 = trunc i32 %a.11.in.4 to i8
  %temp357 = insertelement <16 x i8> undef, i8 %a.11.4, i32 0
  %vector358 = shufflevector <16 x i8> %temp357, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..3354 = xor <16 x i8> %790, %p.11..2353
  %796 = select <16 x i1> %791, <16 x i8> zeroinitializer, <16 x i8> %vector356
  %797 = and <16 x i32> %792, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.11.in.6 = select i1 %793, i32 %763, i32 %794
  %798 = select <16 x i1> %795, <16 x i8> zeroinitializer, <16 x i8> %vector358
  %p.11..4359 = xor <16 x i8> %796, %p.11..3354
  %a.11.5 = trunc i32 %a.11.in.5 to i8
  %temp361 = insertelement <16 x i8> undef, i8 %a.11.5, i32 0
  %vector362 = shufflevector <16 x i8> %temp361, <16 x i8> undef, <16 x i32> zeroinitializer
  %799 = icmp eq <16 x i32> %797, zeroinitializer
  %800 = icmp sgt <16 x i8> %temp.vect343, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.11.6 = trunc i32 %a.11.in.6 to i8
  %temp363 = insertelement <16 x i8> undef, i8 %a.11.6, i32 0
  %vector364 = shufflevector <16 x i8> %temp363, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..5360 = xor <16 x i8> %798, %p.11..4359
  %801 = select <16 x i1> %799, <16 x i8> zeroinitializer, <16 x i8> %vector362
  %802 = select <16 x i1> %800, <16 x i8> zeroinitializer, <16 x i8> %vector364
  %p.11..6365 = xor <16 x i8> %801, %p.11..5360
  %p.11..7366 = xor <16 x i8> %802, %p.11..6365
  %803 = and i64 %tmp77, 3
  %804 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1144, i64 0, i64 %803
  %805 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1180, i64 0, i64 %803
  %806 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1216, i64 0, i64 %803
  %807 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1252, i64 0, i64 %803
  %808 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1288, i64 0, i64 %803
  %809 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1324, i64 0, i64 %803
  %810 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1360, i64 0, i64 %803
  %811 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1396, i64 0, i64 %803
  %812 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1432, i64 0, i64 %803
  %813 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1468, i64 0, i64 %803
  %814 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1504, i64 0, i64 %803
  %815 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1540, i64 0, i64 %803
  %816 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1576, i64 0, i64 %803
  %817 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1612, i64 0, i64 %803
  %818 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1648, i64 0, i64 %803
  %819 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1684, i64 0, i64 %803
  %820 = load <4 x i8>* %804, align 4
  %821 = load <4 x i8>* %805, align 4
  %822 = load <4 x i8>* %806, align 4
  %823 = load <4 x i8>* %807, align 4
  %824 = load <4 x i8>* %808, align 4
  %825 = load <4 x i8>* %809, align 4
  %826 = load <4 x i8>* %810, align 4
  %827 = load <4 x i8>* %811, align 4
  %828 = load <4 x i8>* %812, align 4
  %829 = load <4 x i8>* %813, align 4
  %830 = load <4 x i8>* %814, align 4
  %831 = load <4 x i8>* %815, align 4
  %832 = load <4 x i8>* %816, align 4
  %833 = load <4 x i8>* %817, align 4
  %834 = load <4 x i8>* %818, align 4
  %835 = load <4 x i8>* %819, align 4
  %836 = extractelement <4 x i8> %820, i32 0
  %837 = extractelement <4 x i8> %821, i32 0
  %838 = extractelement <4 x i8> %822, i32 0
  %839 = extractelement <4 x i8> %823, i32 0
  %840 = extractelement <4 x i8> %824, i32 0
  %841 = extractelement <4 x i8> %825, i32 0
  %842 = extractelement <4 x i8> %826, i32 0
  %843 = extractelement <4 x i8> %827, i32 0
  %844 = extractelement <4 x i8> %828, i32 0
  %845 = extractelement <4 x i8> %829, i32 0
  %846 = extractelement <4 x i8> %830, i32 0
  %847 = extractelement <4 x i8> %831, i32 0
  %848 = extractelement <4 x i8> %832, i32 0
  %849 = extractelement <4 x i8> %833, i32 0
  %850 = extractelement <4 x i8> %834, i32 0
  %851 = extractelement <4 x i8> %835, i32 0
  %temp.vect367 = insertelement <16 x i8> undef, i8 %836, i32 0
  %temp.vect368 = insertelement <16 x i8> %temp.vect367, i8 %837, i32 1
  %temp.vect369 = insertelement <16 x i8> %temp.vect368, i8 %838, i32 2
  %temp.vect370 = insertelement <16 x i8> %temp.vect369, i8 %839, i32 3
  %temp.vect371 = insertelement <16 x i8> %temp.vect370, i8 %840, i32 4
  %temp.vect372 = insertelement <16 x i8> %temp.vect371, i8 %841, i32 5
  %temp.vect373 = insertelement <16 x i8> %temp.vect372, i8 %842, i32 6
  %temp.vect374 = insertelement <16 x i8> %temp.vect373, i8 %843, i32 7
  %temp.vect375 = insertelement <16 x i8> %temp.vect374, i8 %844, i32 8
  %temp.vect376 = insertelement <16 x i8> %temp.vect375, i8 %845, i32 9
  %temp.vect377 = insertelement <16 x i8> %temp.vect376, i8 %846, i32 10
  %temp.vect378 = insertelement <16 x i8> %temp.vect377, i8 %847, i32 11
  %temp.vect379 = insertelement <16 x i8> %temp.vect378, i8 %848, i32 12
  %temp.vect380 = insertelement <16 x i8> %temp.vect379, i8 %849, i32 13
  %temp.vect381 = insertelement <16 x i8> %temp.vect380, i8 %850, i32 14
  %temp.vect382 = insertelement <16 x i8> %temp.vect381, i8 %851, i32 15
  %852 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar79 = extractelement <4 x i8> %852, i32 2
  %temp385 = insertelement <16 x i8> undef, i8 %scalar79, i32 0
  %vector386 = shufflevector <16 x i8> %temp385, <16 x i8> undef, <16 x i32> zeroinitializer
  %853 = zext i8 %scalar79 to i32
  %854 = shl i32 %853, 1
  %855 = and i32 %853, 128
  %856 = xor i32 %854, 27
  %857 = icmp eq i32 %855, 0
  %a.13.in = select i1 %857, i32 %854, i32 %856
  %858 = shl i32 %a.13.in, 1
  %859 = and i32 %a.13.in, 128
  %860 = xor i32 %858, 27
  %861 = icmp eq i32 %859, 0
  %a.13.in.1 = select i1 %861, i32 %858, i32 %860
  %862 = shl i32 %a.13.in.1, 1
  %863 = and i32 %a.13.in.1, 128
  %864 = xor i32 %862, 27
  %865 = icmp eq i32 %863, 0
  %a.13.in.2 = select i1 %865, i32 %862, i32 %864
  %866 = shl i32 %a.13.in.2, 1
  %867 = and i32 %a.13.in.2, 128
  %868 = xor i32 %866, 27
  %869 = icmp eq i32 %867, 0
  %a.13.in.3 = select i1 %869, i32 %866, i32 %868
  %870 = shl i32 %a.13.in.3, 1
  %871 = and i32 %a.13.in.3, 128
  %872 = xor i32 %870, 27
  %873 = icmp eq i32 %871, 0
  %a.13.in.4 = select i1 %873, i32 %870, i32 %872
  %874 = shl i32 %a.13.in.4, 1
  %875 = and i32 %a.13.in.4, 128
  %876 = xor i32 %874, 27
  %877 = icmp eq i32 %875, 0
  %a.13.in.5 = select i1 %877, i32 %874, i32 %876
  %878 = shl i32 %a.13.in.5, 1
  %879 = lshr <16 x i8> %temp.vect382, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %880 = zext <16 x i8> %879 to <16 x i32>
  %881 = zext <16 x i8> %temp.vect382 to <16 x i32>
  %882 = lshr <16 x i8> %temp.vect382, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %883 = lshr <16 x i8> %temp.vect382, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %884 = and <16 x i32> %880, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %885 = and <16 x i32> %881, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %886 = zext <16 x i8> %882 to <16 x i32>
  %887 = zext <16 x i8> %883 to <16 x i32>
  %888 = icmp eq <16 x i32> %884, zeroinitializer
  %a.13 = trunc i32 %a.13.in to i8
  %temp383 = insertelement <16 x i8> undef, i8 %a.13, i32 0
  %vector384 = shufflevector <16 x i8> %temp383, <16 x i8> undef, <16 x i32> zeroinitializer
  %889 = icmp eq <16 x i32> %885, zeroinitializer
  %890 = and <16 x i32> %886, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %891 = lshr <16 x i8> %temp.vect382, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %892 = lshr <16 x i8> %temp.vect382, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %893 = and <16 x i32> %887, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %894 = select <16 x i1> %888, <16 x i8> zeroinitializer, <16 x i8> %vector384
  %895 = select <16 x i1> %889, <16 x i8> zeroinitializer, <16 x i8> %vector386
  %a.13.1 = trunc i32 %a.13.in.1 to i8
  %temp388 = insertelement <16 x i8> undef, i8 %a.13.1, i32 0
  %vector389 = shufflevector <16 x i8> %temp388, <16 x i8> undef, <16 x i32> zeroinitializer
  %896 = icmp eq <16 x i32> %890, zeroinitializer
  %897 = zext <16 x i8> %891 to <16 x i32>
  %898 = zext <16 x i8> %892 to <16 x i32>
  %899 = icmp eq <16 x i32> %893, zeroinitializer
  %a.13.2 = trunc i32 %a.13.in.2 to i8
  %temp390 = insertelement <16 x i8> undef, i8 %a.13.2, i32 0
  %vector391 = shufflevector <16 x i8> %temp390, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..1387 = xor <16 x i8> %894, %895
  %900 = select <16 x i1> %896, <16 x i8> zeroinitializer, <16 x i8> %vector389
  %901 = and <16 x i32> %897, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %902 = lshr <16 x i8> %temp.vect382, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %903 = and i32 %a.13.in.5, 128
  %904 = and <16 x i32> %898, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %905 = select <16 x i1> %899, <16 x i8> zeroinitializer, <16 x i8> %vector391
  %p.13..2392 = xor <16 x i8> %900, %p.13..1387
  %a.13.3 = trunc i32 %a.13.in.3 to i8
  %temp394 = insertelement <16 x i8> undef, i8 %a.13.3, i32 0
  %vector395 = shufflevector <16 x i8> %temp394, <16 x i8> undef, <16 x i32> zeroinitializer
  %906 = icmp eq <16 x i32> %901, zeroinitializer
  %907 = zext <16 x i8> %902 to <16 x i32>
  %908 = icmp eq i32 %903, 0
  %909 = xor i32 %878, 27
  %910 = icmp eq <16 x i32> %904, zeroinitializer
  %a.13.4 = trunc i32 %a.13.in.4 to i8
  %temp396 = insertelement <16 x i8> undef, i8 %a.13.4, i32 0
  %vector397 = shufflevector <16 x i8> %temp396, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..3393 = xor <16 x i8> %905, %p.13..2392
  %911 = select <16 x i1> %906, <16 x i8> zeroinitializer, <16 x i8> %vector395
  %912 = and <16 x i32> %907, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.13.in.6 = select i1 %908, i32 %878, i32 %909
  %913 = select <16 x i1> %910, <16 x i8> zeroinitializer, <16 x i8> %vector397
  %p.13..4398 = xor <16 x i8> %911, %p.13..3393
  %a.13.5 = trunc i32 %a.13.in.5 to i8
  %temp400 = insertelement <16 x i8> undef, i8 %a.13.5, i32 0
  %vector401 = shufflevector <16 x i8> %temp400, <16 x i8> undef, <16 x i32> zeroinitializer
  %914 = icmp eq <16 x i32> %912, zeroinitializer
  %915 = icmp sgt <16 x i8> %temp.vect382, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.13.6 = trunc i32 %a.13.in.6 to i8
  %temp402 = insertelement <16 x i8> undef, i8 %a.13.6, i32 0
  %vector403 = shufflevector <16 x i8> %temp402, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..5399 = xor <16 x i8> %913, %p.13..4398
  %916 = select <16 x i1> %914, <16 x i8> zeroinitializer, <16 x i8> %vector401
  %917 = select <16 x i1> %915, <16 x i8> zeroinitializer, <16 x i8> %vector403
  %p.13..6404 = xor <16 x i8> %916, %p.13..5399
  %p.13..7405 = xor <16 x i8> %917, %p.13..6404
  %918 = and i64 %tmp77, 3
  %919 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1140, i64 0, i64 %918
  %920 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1176, i64 0, i64 %918
  %921 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1212, i64 0, i64 %918
  %922 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1248, i64 0, i64 %918
  %923 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1284, i64 0, i64 %918
  %924 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1320, i64 0, i64 %918
  %925 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1356, i64 0, i64 %918
  %926 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1392, i64 0, i64 %918
  %927 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1428, i64 0, i64 %918
  %928 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1464, i64 0, i64 %918
  %929 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1500, i64 0, i64 %918
  %930 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1536, i64 0, i64 %918
  %931 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1572, i64 0, i64 %918
  %932 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1608, i64 0, i64 %918
  %933 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1644, i64 0, i64 %918
  %934 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1680, i64 0, i64 %918
  %935 = load <4 x i8>* %919, align 4
  %936 = load <4 x i8>* %920, align 4
  %937 = load <4 x i8>* %921, align 4
  %938 = load <4 x i8>* %922, align 4
  %939 = load <4 x i8>* %923, align 4
  %940 = load <4 x i8>* %924, align 4
  %941 = load <4 x i8>* %925, align 4
  %942 = load <4 x i8>* %926, align 4
  %943 = load <4 x i8>* %927, align 4
  %944 = load <4 x i8>* %928, align 4
  %945 = load <4 x i8>* %929, align 4
  %946 = load <4 x i8>* %930, align 4
  %947 = load <4 x i8>* %931, align 4
  %948 = load <4 x i8>* %932, align 4
  %949 = load <4 x i8>* %933, align 4
  %950 = load <4 x i8>* %934, align 4
  %951 = extractelement <4 x i8> %935, i32 0
  %952 = extractelement <4 x i8> %936, i32 0
  %953 = extractelement <4 x i8> %937, i32 0
  %954 = extractelement <4 x i8> %938, i32 0
  %955 = extractelement <4 x i8> %939, i32 0
  %956 = extractelement <4 x i8> %940, i32 0
  %957 = extractelement <4 x i8> %941, i32 0
  %958 = extractelement <4 x i8> %942, i32 0
  %959 = extractelement <4 x i8> %943, i32 0
  %960 = extractelement <4 x i8> %944, i32 0
  %961 = extractelement <4 x i8> %945, i32 0
  %962 = extractelement <4 x i8> %946, i32 0
  %963 = extractelement <4 x i8> %947, i32 0
  %964 = extractelement <4 x i8> %948, i32 0
  %965 = extractelement <4 x i8> %949, i32 0
  %966 = extractelement <4 x i8> %950, i32 0
  %temp.vect406 = insertelement <16 x i8> undef, i8 %951, i32 0
  %temp.vect407 = insertelement <16 x i8> %temp.vect406, i8 %952, i32 1
  %temp.vect408 = insertelement <16 x i8> %temp.vect407, i8 %953, i32 2
  %temp.vect409 = insertelement <16 x i8> %temp.vect408, i8 %954, i32 3
  %temp.vect410 = insertelement <16 x i8> %temp.vect409, i8 %955, i32 4
  %temp.vect411 = insertelement <16 x i8> %temp.vect410, i8 %956, i32 5
  %temp.vect412 = insertelement <16 x i8> %temp.vect411, i8 %957, i32 6
  %temp.vect413 = insertelement <16 x i8> %temp.vect412, i8 %958, i32 7
  %temp.vect414 = insertelement <16 x i8> %temp.vect413, i8 %959, i32 8
  %temp.vect415 = insertelement <16 x i8> %temp.vect414, i8 %960, i32 9
  %temp.vect416 = insertelement <16 x i8> %temp.vect415, i8 %961, i32 10
  %temp.vect417 = insertelement <16 x i8> %temp.vect416, i8 %962, i32 11
  %temp.vect418 = insertelement <16 x i8> %temp.vect417, i8 %963, i32 12
  %temp.vect419 = insertelement <16 x i8> %temp.vect418, i8 %964, i32 13
  %temp.vect420 = insertelement <16 x i8> %temp.vect419, i8 %965, i32 14
  %temp.vect421 = insertelement <16 x i8> %temp.vect420, i8 %966, i32 15
  %967 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar88 = extractelement <4 x i8> %967, i32 3
  %temp424 = insertelement <16 x i8> undef, i8 %scalar88, i32 0
  %vector425 = shufflevector <16 x i8> %temp424, <16 x i8> undef, <16 x i32> zeroinitializer
  %968 = zext i8 %scalar88 to i32
  %969 = shl i32 %968, 1
  %970 = and i32 %968, 128
  %971 = xor i32 %969, 27
  %972 = icmp eq i32 %970, 0
  %a.15.in = select i1 %972, i32 %969, i32 %971
  %973 = shl i32 %a.15.in, 1
  %974 = and i32 %a.15.in, 128
  %975 = xor i32 %973, 27
  %976 = icmp eq i32 %974, 0
  %a.15.in.1 = select i1 %976, i32 %973, i32 %975
  %977 = shl i32 %a.15.in.1, 1
  %978 = and i32 %a.15.in.1, 128
  %979 = xor i32 %977, 27
  %980 = icmp eq i32 %978, 0
  %a.15.in.2 = select i1 %980, i32 %977, i32 %979
  %981 = shl i32 %a.15.in.2, 1
  %982 = and i32 %a.15.in.2, 128
  %983 = xor i32 %981, 27
  %984 = icmp eq i32 %982, 0
  %a.15.in.3 = select i1 %984, i32 %981, i32 %983
  %985 = shl i32 %a.15.in.3, 1
  %986 = and i32 %a.15.in.3, 128
  %987 = xor i32 %985, 27
  %988 = icmp eq i32 %986, 0
  %a.15.in.4 = select i1 %988, i32 %985, i32 %987
  %989 = shl i32 %a.15.in.4, 1
  %990 = and i32 %a.15.in.4, 128
  %991 = xor i32 %989, 27
  %992 = icmp eq i32 %990, 0
  %a.15.in.5 = select i1 %992, i32 %989, i32 %991
  %993 = shl i32 %a.15.in.5, 1
  %994 = lshr <16 x i8> %temp.vect421, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %995 = zext <16 x i8> %994 to <16 x i32>
  %996 = zext <16 x i8> %temp.vect421 to <16 x i32>
  %997 = lshr <16 x i8> %temp.vect421, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %998 = lshr <16 x i8> %temp.vect421, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %999 = and <16 x i32> %995, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1000 = and <16 x i32> %996, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1001 = zext <16 x i8> %997 to <16 x i32>
  %1002 = zext <16 x i8> %998 to <16 x i32>
  %1003 = icmp eq <16 x i32> %999, zeroinitializer
  %a.15 = trunc i32 %a.15.in to i8
  %temp422 = insertelement <16 x i8> undef, i8 %a.15, i32 0
  %vector423 = shufflevector <16 x i8> %temp422, <16 x i8> undef, <16 x i32> zeroinitializer
  %1004 = icmp eq <16 x i32> %1000, zeroinitializer
  %1005 = and <16 x i32> %1001, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1006 = lshr <16 x i8> %temp.vect421, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1007 = lshr <16 x i8> %temp.vect421, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1008 = and <16 x i32> %1002, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1009 = select <16 x i1> %1003, <16 x i8> zeroinitializer, <16 x i8> %vector423
  %1010 = select <16 x i1> %1004, <16 x i8> zeroinitializer, <16 x i8> %vector425
  %a.15.1 = trunc i32 %a.15.in.1 to i8
  %temp427 = insertelement <16 x i8> undef, i8 %a.15.1, i32 0
  %vector428 = shufflevector <16 x i8> %temp427, <16 x i8> undef, <16 x i32> zeroinitializer
  %1011 = icmp eq <16 x i32> %1005, zeroinitializer
  %1012 = zext <16 x i8> %1006 to <16 x i32>
  %1013 = zext <16 x i8> %1007 to <16 x i32>
  %1014 = icmp eq <16 x i32> %1008, zeroinitializer
  %a.15.2 = trunc i32 %a.15.in.2 to i8
  %temp429 = insertelement <16 x i8> undef, i8 %a.15.2, i32 0
  %vector430 = shufflevector <16 x i8> %temp429, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..1426 = xor <16 x i8> %1009, %1010
  %1015 = select <16 x i1> %1011, <16 x i8> zeroinitializer, <16 x i8> %vector428
  %1016 = and <16 x i32> %1012, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1017 = lshr <16 x i8> %temp.vect421, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1018 = and i32 %a.15.in.5, 128
  %1019 = and <16 x i32> %1013, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1020 = select <16 x i1> %1014, <16 x i8> zeroinitializer, <16 x i8> %vector430
  %p.15..2431 = xor <16 x i8> %1015, %p.15..1426
  %a.15.3 = trunc i32 %a.15.in.3 to i8
  %temp433 = insertelement <16 x i8> undef, i8 %a.15.3, i32 0
  %vector434 = shufflevector <16 x i8> %temp433, <16 x i8> undef, <16 x i32> zeroinitializer
  %1021 = icmp eq <16 x i32> %1016, zeroinitializer
  %1022 = zext <16 x i8> %1017 to <16 x i32>
  %1023 = icmp eq i32 %1018, 0
  %1024 = xor i32 %993, 27
  %1025 = icmp eq <16 x i32> %1019, zeroinitializer
  %a.15.4 = trunc i32 %a.15.in.4 to i8
  %temp435 = insertelement <16 x i8> undef, i8 %a.15.4, i32 0
  %vector436 = shufflevector <16 x i8> %temp435, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..3432 = xor <16 x i8> %1020, %p.15..2431
  %1026 = select <16 x i1> %1021, <16 x i8> zeroinitializer, <16 x i8> %vector434
  %1027 = and <16 x i32> %1022, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.15.in.6 = select i1 %1023, i32 %993, i32 %1024
  %1028 = select <16 x i1> %1025, <16 x i8> zeroinitializer, <16 x i8> %vector436
  %p.15..4437 = xor <16 x i8> %1026, %p.15..3432
  %a.15.5 = trunc i32 %a.15.in.5 to i8
  %temp439 = insertelement <16 x i8> undef, i8 %a.15.5, i32 0
  %vector440 = shufflevector <16 x i8> %temp439, <16 x i8> undef, <16 x i32> zeroinitializer
  %1029 = icmp eq <16 x i32> %1027, zeroinitializer
  %1030 = icmp sgt <16 x i8> %temp.vect421, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.15.6 = trunc i32 %a.15.in.6 to i8
  %temp441 = insertelement <16 x i8> undef, i8 %a.15.6, i32 0
  %vector442 = shufflevector <16 x i8> %temp441, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..5438 = xor <16 x i8> %1028, %p.15..4437
  %1031 = select <16 x i1> %1029, <16 x i8> zeroinitializer, <16 x i8> %vector440
  %1032 = select <16 x i1> %1030, <16 x i8> zeroinitializer, <16 x i8> %vector442
  %p.15..6443 = xor <16 x i8> %1031, %p.15..5438
  %p.15..7444 = xor <16 x i8> %1032, %p.15..6443
  %1033 = xor <16 x i8> %p.9..7327, %vectorPHI288
  store <16 x i8> %1033, <16 x i8>* %CastToValueType1084, align 16
  %1034 = xor <16 x i8> %p.11..7366, %vectorPHI287
  store <16 x i8> %1034, <16 x i8>* %CastToValueType1093, align 16
  %1035 = xor <16 x i8> %p.13..7405, %vectorPHI286
  store <16 x i8> %1035, <16 x i8>* %CastToValueType1102, align 16
  %1036 = xor <16 x i8> %p.15..7444, %vectorPHI
  store <16 x i8> %1036, <16 x i8>* %CastToValueType1111, align 16
  %exitcond = icmp eq i64 %tmp, 3
  br i1 %exitcond, label %._crit_edge66, label %572

._crit_edge66:                                    ; preds = %572
  %"&(pSB[currWI].offset)1113" = add nuw i64 %CurrSBIndex..3, 608
  %"&pSB[currWI].offset1114" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1113"
  %CastToValueType1115 = bitcast i8* %"&pSB[currWI].offset1114" to <16 x i8>*
  %loadedValue1116 = load <16 x i8>* %CastToValueType1115, align 16
  %extract507 = extractelement <16 x i8> %loadedValue1116, i32 15
  %"&(pSB[currWI].offset)1104" = add nuw i64 %CurrSBIndex..3, 592
  %"&pSB[currWI].offset1105" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1104"
  %CastToValueType1106 = bitcast i8* %"&pSB[currWI].offset1105" to <16 x i8>*
  %loadedValue1107 = load <16 x i8>* %CastToValueType1106, align 16
  %extract491 = extractelement <16 x i8> %loadedValue1107, i32 15
  %"&(pSB[currWI].offset)1095" = add nuw i64 %CurrSBIndex..3, 576
  %"&pSB[currWI].offset1096" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1095"
  %CastToValueType1097 = bitcast i8* %"&pSB[currWI].offset1096" to <16 x i8>*
  %loadedValue1098 = load <16 x i8>* %CastToValueType1097, align 16
  %extract475 = extractelement <16 x i8> %loadedValue1098, i32 15
  %"&(pSB[currWI].offset)1086" = add nuw i64 %CurrSBIndex..3, 560
  %"&pSB[currWI].offset1087" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1086"
  %CastToValueType1088 = bitcast i8* %"&pSB[currWI].offset1087" to <16 x i8>*
  %loadedValue1089 = load <16 x i8>* %CastToValueType1088, align 16
  %extract459 = extractelement <16 x i8> %loadedValue1089, i32 15
  %1037 = insertelement <4 x i8> undef, i8 %extract459, i32 0
  %1038 = insertelement <4 x i8> %1037, i8 %extract475, i32 1
  %1039 = insertelement <4 x i8> %1038, i8 %extract491, i32 2
  %1040 = insertelement <4 x i8> %1039, i8 %extract507, i32 3
  %"&(pSB[currWI].offset)951" = add nuw i64 %CurrSBIndex..3, 432
  %"&pSB[currWI].offset952" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)951"
  %CastToValueType953 = bitcast i8* %"&pSB[currWI].offset952" to <4 x i8> addrspace(3)**
  %loadedValue954 = load <4 x i8> addrspace(3)** %CastToValueType953, align 8
  store <4 x i8> %1040, <4 x i8> addrspace(3)* %loadedValue954, align 4
  %check.WI.iter1722 = icmp ult i64 %CurrWI..3, %iterCount
  br i1 %check.WI.iter1722, label %thenBB1719, label %SyncBB1716

thenBB1719:                                       ; preds = %._crit_edge66
  %"CurrWI++1723" = add nuw i64 %CurrWI..3, 1
  %"loadedCurrSB+Stride1725" = add nuw i64 %CurrSBIndex..3, 1712
  br label %SyncBB

SyncBB1716:                                       ; preds = %._crit_edge66, %thenBB1726, %thenBB
  %CurrSBIndex..1 = phi i64 [ %"loadedCurrSB+Stride1732", %thenBB1726 ], [ %"loadedCurrSB+Stride", %thenBB ], [ 0, %._crit_edge66 ]
  %currBarrier.0 = phi i32 [ %currBarrier.1, %thenBB1726 ], [ %currBarrier.1, %thenBB ], [ 5, %._crit_edge66 ]
  %CurrWI..1 = phi i64 [ %"CurrWI++1730", %thenBB1726 ], [ %"CurrWI++", %thenBB ], [ 0, %._crit_edge66 ]
  %"&(pSB[currWI].offset)956" = add nuw i64 %CurrSBIndex..1, 432
  %"&pSB[currWI].offset957" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)956"
  %CastToValueType958 = bitcast i8* %"&pSB[currWI].offset957" to <4 x i8> addrspace(3)**
  %loadedValue959 = load <4 x i8> addrspace(3)** %CastToValueType958, align 8
  %1041 = load <4 x i8> addrspace(3)* %loadedValue959, align 4
  %scalar89 = extractelement <4 x i8> %1041, i32 0
  %scalar90 = extractelement <4 x i8> %1041, i32 1
  %scalar91 = extractelement <4 x i8> %1041, i32 2
  %scalar92 = extractelement <4 x i8> %1041, i32 3
  %"&(pSB[currWI].offset)997" = add nuw i64 %CurrSBIndex..1, 456
  %"&pSB[currWI].offset998" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)997"
  %CastToValueType999 = bitcast i8* %"&pSB[currWI].offset998" to i32*
  %loadedValue1000 = load i32* %CastToValueType999, align 4
  %1042 = zext i32 %loadedValue1000 to i64
  %1043 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %1042
  %1044 = load <4 x i8> addrspace(1)* %1043, align 4
  %scalar93 = extractelement <4 x i8> %1044, i32 0
  %scalar94 = extractelement <4 x i8> %1044, i32 1
  %scalar95 = extractelement <4 x i8> %1044, i32 2
  %scalar96 = extractelement <4 x i8> %1044, i32 3
  %1045 = xor i8 %scalar89, %scalar93
  %"&(pSB[currWI].offset)1118" = add nuw i64 %CurrSBIndex..1, 624
  %"&pSB[currWI].offset1119" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1118"
  store i8 %1045, i8* %"&pSB[currWI].offset1119", align 1
  %1046 = xor i8 %scalar90, %scalar94
  %"&(pSB[currWI].offset)1122" = add nuw i64 %CurrSBIndex..1, 625
  %"&pSB[currWI].offset1123" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1122"
  store i8 %1046, i8* %"&pSB[currWI].offset1123", align 1
  %1047 = xor i8 %scalar91, %scalar95
  %"&(pSB[currWI].offset)1126" = add nuw i64 %CurrSBIndex..1, 626
  %"&pSB[currWI].offset1127" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1126"
  store i8 %1047, i8* %"&pSB[currWI].offset1127", align 1
  %1048 = xor i8 %scalar92, %scalar96
  %"&(pSB[currWI].offset)1130" = add nuw i64 %CurrSBIndex..1, 627
  %"&pSB[currWI].offset1131" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1130"
  store i8 %1048, i8* %"&pSB[currWI].offset1131", align 1
  %temp.vect124 = insertelement <4 x i8> undef, i8 %1045, i32 0
  %temp.vect125 = insertelement <4 x i8> %temp.vect124, i8 %1046, i32 1
  %temp.vect126 = insertelement <4 x i8> %temp.vect125, i8 %1047, i32 2
  %temp.vect127 = insertelement <4 x i8> %temp.vect126, i8 %1048, i32 3
  %"&(pSB[currWI].offset)537" = add nuw i64 %CurrSBIndex..1, 288
  %"&pSB[currWI].offset538" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)537"
  %CastToValueType539 = bitcast i8* %"&pSB[currWI].offset538" to <4 x i8> addrspace(3)**
  %loadedValue540 = load <4 x i8> addrspace(3)** %CastToValueType539, align 8
  store <4 x i8> %temp.vect127, <4 x i8> addrspace(3)* %loadedValue540, align 4
  %"&(pSB[currWI].offset)983" = add nuw i64 %CurrSBIndex..1, 452
  %"&pSB[currWI].offset984" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)983"
  %CastToValueType985 = bitcast i8* %"&pSB[currWI].offset984" to i32*
  %loadedValue986 = load i32* %CastToValueType985, align 4
  %indvar.next80 = add i32 %loadedValue986, 1
  %"&(pSB[currWI].offset)1134" = add nuw i64 %CurrSBIndex..1, 628
  %"&pSB[currWI].offset1135" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1134"
  %CastToValueType1136 = bitcast i8* %"&pSB[currWI].offset1135" to i32*
  store i32 %indvar.next80, i32* %CastToValueType1136, align 4
  br label %157

"Barrier BB508":                                  ; preds = %shiftRows.exit
  %"&(pSB[currWI].offset)1042" = add nuw i64 %CurrSBIndex..2, 472
  %"&pSB[currWI].offset1043" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1042"
  %CastToValueType1044 = bitcast i8* %"&pSB[currWI].offset1043" to <4 x i8>*
  %loadedValue1045 = load <4 x i8>* %CastToValueType1044, align 4
  %scalar100 = extractelement <4 x i8> %loadedValue1045, i32 3
  %"&(pSB[currWI].offset)1047" = add nuw i64 %CurrSBIndex..2, 472
  %"&pSB[currWI].offset1048" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1047"
  %CastToValueType1049 = bitcast i8* %"&pSB[currWI].offset1048" to <4 x i8>*
  %loadedValue1050 = load <4 x i8>* %CastToValueType1049, align 4
  %scalar99 = extractelement <4 x i8> %loadedValue1050, i32 2
  %"&(pSB[currWI].offset)1052" = add nuw i64 %CurrSBIndex..2, 472
  %"&pSB[currWI].offset1053" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1052"
  %CastToValueType1054 = bitcast i8* %"&pSB[currWI].offset1053" to <4 x i8>*
  %loadedValue1055 = load <4 x i8>* %CastToValueType1054, align 4
  %scalar98 = extractelement <4 x i8> %loadedValue1055, i32 1
  %"&(pSB[currWI].offset)1057" = add nuw i64 %CurrSBIndex..2, 472
  %"&pSB[currWI].offset1058" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1057"
  %CastToValueType1059 = bitcast i8* %"&pSB[currWI].offset1058" to <4 x i8>*
  %loadedValue1060 = load <4 x i8>* %CastToValueType1059, align 4
  %scalar97 = extractelement <4 x i8> %loadedValue1060, i32 0
  %"&(pSB[currWI].offset)519" = add nuw i64 %CurrSBIndex..2, 272
  %"&pSB[currWI].offset520" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)519"
  %CastToValueType521 = bitcast i8* %"&pSB[currWI].offset520" to i32*
  %loadedValue522 = load i32* %CastToValueType521, align 4
  %1049 = add i32 %loadedValue522, %0
  %1050 = zext i32 %1049 to i64
  %1051 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %1050
  %1052 = load <4 x i8> addrspace(1)* %1051, align 4
  %scalar101 = extractelement <4 x i8> %1052, i32 0
  %scalar102 = extractelement <4 x i8> %1052, i32 1
  %scalar103 = extractelement <4 x i8> %1052, i32 2
  %scalar104 = extractelement <4 x i8> %1052, i32 3
  %1053 = xor i8 %scalar97, %scalar101
  %1054 = xor i8 %scalar98, %scalar102
  %1055 = xor i8 %scalar99, %scalar103
  %1056 = xor i8 %scalar100, %scalar104
  %temp.vect128 = insertelement <4 x i8> undef, i8 %1053, i32 0
  %temp.vect129 = insertelement <4 x i8> %temp.vect128, i8 %1054, i32 1
  %temp.vect130 = insertelement <4 x i8> %temp.vect129, i8 %1055, i32 2
  %temp.vect131 = insertelement <4 x i8> %temp.vect130, i8 %1056, i32 3
  %"&(pSB[currWI].offset)528" = add nuw i64 %CurrSBIndex..2, 280
  %"&pSB[currWI].offset529" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)528"
  %CastToValueType530 = bitcast i8* %"&pSB[currWI].offset529" to i64*
  %loadedValue531 = load i64* %CastToValueType530, align 8
  %1057 = getelementptr inbounds <4 x i8> addrspace(1)* %output, i64 %loadedValue531
  store <4 x i8> %temp.vect131, <4 x i8> addrspace(1)* %1057, align 4
  %check.WI.iter1729 = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter1729, label %thenBB1726, label %SyncBB1717

thenBB1726:                                       ; preds = %"Barrier BB508"
  %"CurrWI++1730" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride1732" = add nuw i64 %CurrSBIndex..2, 1712
  %cond1 = icmp eq i32 %currBarrier.1, 14
  br i1 %cond1, label %SyncBB1715, label %SyncBB1716

SyncBB1717:                                       ; preds = %"Barrier BB508"
  ret void
}

define void @____Vectorized_.AESDecrypt_separated_args(<4 x i8> addrspace(1)* nocapture %output, <4 x i8> addrspace(1)* nocapture %input, <4 x i8> addrspace(1)* nocapture %roundKey, i8 addrspace(1)* nocapture %SBox, <4 x i8> addrspace(3)* nocapture %block0, <4 x i8> addrspace(3)* nocapture %block1, i32 %width, i32 %rounds, i8 addrspace(3)* %pLocalMem, %struct.WorkDim* %pWorkDim, i64* %pWGId, %struct.PaddedDimId* %pBaseGlbId, %struct.PaddedDimId* %pLocalIds, i64* %contextpointer, i64 %iterCount, i8* %pSpecialBuf, i64* %pCurrWI) nounwind alwaysinline {
FirstBB:
  %0 = shl i32 %rounds, 2
  %tmp81 = add i32 %rounds, -1
  br label %SyncBB

SyncBB:                                           ; preds = %thenBB, %thenBB2221, %FirstBB
  %CurrSBIndex..0 = phi i64 [ 0, %FirstBB ], [ %"loadedCurrSB+Stride2227", %thenBB2221 ], [ %"loadedCurrSB+Stride", %thenBB ]
  %currBarrier.2 = phi i32 [ 13, %FirstBB ], [ %currBarrier.1, %thenBB2221 ], [ %currBarrier.1, %thenBB ]
  %CurrWI..0 = phi i64 [ 0, %FirstBB ], [ %"CurrWI++2225", %thenBB2221 ], [ %"CurrWI++", %thenBB ]
  %1 = load i64* %pWGId, align 8
  %2 = trunc i64 %1 to i32
  %3 = getelementptr i64* %pWGId, i64 1
  %4 = load i64* %3, align 8
  %5 = trunc i64 %4 to i32
  %6 = getelementptr %struct.PaddedDimId* %pLocalIds, i64 %CurrWI..0, i32 0, i64 1
  %7 = load i64* %6, align 8
  %8 = trunc i64 %7 to i32
  %"&(pSB[currWI].offset)" = add nuw i64 %CurrSBIndex..0, 896
  %"&pSB[currWI].offset" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)"
  %CastToValueType = bitcast i8* %"&pSB[currWI].offset" to i32*
  store i32 %8, i32* %CastToValueType, align 4
  %9 = mul i32 %5, %width
  %10 = shl i32 %2, 2
  %11 = add i32 %9, %10
  %12 = and i32 %11, -4
  %13 = add i32 %12, %8
  %"&(pSB[currWI].offset)1665" = add nuw i64 %CurrSBIndex..0, 1456
  %"&pSB[currWI].offset1666" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1665"
  %14 = bitcast i8* %"&pSB[currWI].offset1666" to <4 x i8>*
  %"&(pSB[currWI].offset)1701" = add nuw i64 %CurrSBIndex..0, 1472
  %"&pSB[currWI].offset1702" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1701"
  %15 = bitcast i8* %"&pSB[currWI].offset1702" to <4 x i8>*
  %"&(pSB[currWI].offset)1737" = add nuw i64 %CurrSBIndex..0, 1488
  %"&pSB[currWI].offset1738" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1737"
  %16 = bitcast i8* %"&pSB[currWI].offset1738" to <4 x i8>*
  %"&(pSB[currWI].offset)1773" = add nuw i64 %CurrSBIndex..0, 1504
  %"&pSB[currWI].offset1774" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1773"
  %17 = bitcast i8* %"&pSB[currWI].offset1774" to <4 x i8>*
  %"&(pSB[currWI].offset)1809" = add nuw i64 %CurrSBIndex..0, 1520
  %"&pSB[currWI].offset1810" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1809"
  %18 = bitcast i8* %"&pSB[currWI].offset1810" to <4 x i8>*
  %"&(pSB[currWI].offset)1845" = add nuw i64 %CurrSBIndex..0, 1536
  %"&pSB[currWI].offset1846" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1845"
  %19 = bitcast i8* %"&pSB[currWI].offset1846" to <4 x i8>*
  %"&(pSB[currWI].offset)1881" = add nuw i64 %CurrSBIndex..0, 1552
  %"&pSB[currWI].offset1882" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1881"
  %20 = bitcast i8* %"&pSB[currWI].offset1882" to <4 x i8>*
  %"&(pSB[currWI].offset)1917" = add nuw i64 %CurrSBIndex..0, 1568
  %"&pSB[currWI].offset1918" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1917"
  %21 = bitcast i8* %"&pSB[currWI].offset1918" to <4 x i8>*
  %"&(pSB[currWI].offset)1953" = add nuw i64 %CurrSBIndex..0, 1584
  %"&pSB[currWI].offset1954" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1953"
  %22 = bitcast i8* %"&pSB[currWI].offset1954" to <4 x i8>*
  %"&(pSB[currWI].offset)1989" = add nuw i64 %CurrSBIndex..0, 1600
  %"&pSB[currWI].offset1990" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1989"
  %23 = bitcast i8* %"&pSB[currWI].offset1990" to <4 x i8>*
  %"&(pSB[currWI].offset)2025" = add nuw i64 %CurrSBIndex..0, 1616
  %"&pSB[currWI].offset2026" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2025"
  %24 = bitcast i8* %"&pSB[currWI].offset2026" to <4 x i8>*
  %"&(pSB[currWI].offset)2061" = add nuw i64 %CurrSBIndex..0, 1632
  %"&pSB[currWI].offset2062" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2061"
  %25 = bitcast i8* %"&pSB[currWI].offset2062" to <4 x i8>*
  %"&(pSB[currWI].offset)2097" = add nuw i64 %CurrSBIndex..0, 1648
  %"&pSB[currWI].offset2098" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2097"
  %26 = bitcast i8* %"&pSB[currWI].offset2098" to <4 x i8>*
  %"&(pSB[currWI].offset)2133" = add nuw i64 %CurrSBIndex..0, 1664
  %"&pSB[currWI].offset2134" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2133"
  %27 = bitcast i8* %"&pSB[currWI].offset2134" to <4 x i8>*
  %"&(pSB[currWI].offset)2169" = add nuw i64 %CurrSBIndex..0, 1680
  %"&pSB[currWI].offset2170" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2169"
  %28 = bitcast i8* %"&pSB[currWI].offset2170" to <4 x i8>*
  %"&(pSB[currWI].offset)2205" = add nuw i64 %CurrSBIndex..0, 1696
  %"&pSB[currWI].offset2206" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2205"
  %29 = bitcast i8* %"&pSB[currWI].offset2206" to <4 x i8>*
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %14, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %15, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %16, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %17, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %18, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %19, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %20, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %21, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %22, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %23, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %24, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %25, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %26, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %27, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %28, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %29, align 16
  %"&pSB[currWI].offset1662.sum" = add i64 %CurrSBIndex..0, 1460
  %30 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1662.sum"
  %31 = bitcast i8* %30 to <4 x i8>*
  %"&pSB[currWI].offset1698.sum" = add i64 %CurrSBIndex..0, 1476
  %32 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1698.sum"
  %33 = bitcast i8* %32 to <4 x i8>*
  %"&pSB[currWI].offset1734.sum" = add i64 %CurrSBIndex..0, 1492
  %34 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1734.sum"
  %35 = bitcast i8* %34 to <4 x i8>*
  %"&pSB[currWI].offset1770.sum" = add i64 %CurrSBIndex..0, 1508
  %36 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1770.sum"
  %37 = bitcast i8* %36 to <4 x i8>*
  %"&pSB[currWI].offset1806.sum" = add i64 %CurrSBIndex..0, 1524
  %38 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1806.sum"
  %39 = bitcast i8* %38 to <4 x i8>*
  %"&pSB[currWI].offset1842.sum" = add i64 %CurrSBIndex..0, 1540
  %40 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1842.sum"
  %41 = bitcast i8* %40 to <4 x i8>*
  %"&pSB[currWI].offset1878.sum" = add i64 %CurrSBIndex..0, 1556
  %42 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1878.sum"
  %43 = bitcast i8* %42 to <4 x i8>*
  %"&pSB[currWI].offset1914.sum" = add i64 %CurrSBIndex..0, 1572
  %44 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1914.sum"
  %45 = bitcast i8* %44 to <4 x i8>*
  %"&pSB[currWI].offset1950.sum" = add i64 %CurrSBIndex..0, 1588
  %46 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1950.sum"
  %47 = bitcast i8* %46 to <4 x i8>*
  %"&pSB[currWI].offset1986.sum" = add i64 %CurrSBIndex..0, 1604
  %48 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1986.sum"
  %49 = bitcast i8* %48 to <4 x i8>*
  %"&pSB[currWI].offset2022.sum" = add i64 %CurrSBIndex..0, 1620
  %50 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2022.sum"
  %51 = bitcast i8* %50 to <4 x i8>*
  %"&pSB[currWI].offset2058.sum" = add i64 %CurrSBIndex..0, 1636
  %52 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2058.sum"
  %53 = bitcast i8* %52 to <4 x i8>*
  %"&pSB[currWI].offset2094.sum" = add i64 %CurrSBIndex..0, 1652
  %54 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2094.sum"
  %55 = bitcast i8* %54 to <4 x i8>*
  %"&pSB[currWI].offset2130.sum" = add i64 %CurrSBIndex..0, 1668
  %56 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2130.sum"
  %57 = bitcast i8* %56 to <4 x i8>*
  %"&pSB[currWI].offset2166.sum" = add i64 %CurrSBIndex..0, 1684
  %58 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2166.sum"
  %59 = bitcast i8* %58 to <4 x i8>*
  %"&pSB[currWI].offset2202.sum" = add i64 %CurrSBIndex..0, 1700
  %60 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2202.sum"
  %61 = bitcast i8* %60 to <4 x i8>*
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %31, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %33, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %35, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %37, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %39, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %41, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %43, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %45, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %47, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %57, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %59, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %61, align 4
  %"&pSB[currWI].offset1658.sum" = add i64 %CurrSBIndex..0, 1464
  %62 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1658.sum"
  %63 = bitcast i8* %62 to <4 x i8>*
  %"&pSB[currWI].offset1694.sum" = add i64 %CurrSBIndex..0, 1480
  %64 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1694.sum"
  %65 = bitcast i8* %64 to <4 x i8>*
  %"&pSB[currWI].offset1730.sum" = add i64 %CurrSBIndex..0, 1496
  %66 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1730.sum"
  %67 = bitcast i8* %66 to <4 x i8>*
  %"&pSB[currWI].offset1766.sum" = add i64 %CurrSBIndex..0, 1512
  %68 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1766.sum"
  %69 = bitcast i8* %68 to <4 x i8>*
  %"&pSB[currWI].offset1802.sum" = add i64 %CurrSBIndex..0, 1528
  %70 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1802.sum"
  %71 = bitcast i8* %70 to <4 x i8>*
  %"&pSB[currWI].offset1838.sum" = add i64 %CurrSBIndex..0, 1544
  %72 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1838.sum"
  %73 = bitcast i8* %72 to <4 x i8>*
  %"&pSB[currWI].offset1874.sum" = add i64 %CurrSBIndex..0, 1560
  %74 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1874.sum"
  %75 = bitcast i8* %74 to <4 x i8>*
  %"&pSB[currWI].offset1910.sum" = add i64 %CurrSBIndex..0, 1576
  %76 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1910.sum"
  %77 = bitcast i8* %76 to <4 x i8>*
  %"&pSB[currWI].offset1946.sum" = add i64 %CurrSBIndex..0, 1592
  %78 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1946.sum"
  %79 = bitcast i8* %78 to <4 x i8>*
  %"&pSB[currWI].offset1982.sum" = add i64 %CurrSBIndex..0, 1608
  %80 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1982.sum"
  %81 = bitcast i8* %80 to <4 x i8>*
  %"&pSB[currWI].offset2018.sum" = add i64 %CurrSBIndex..0, 1624
  %82 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2018.sum"
  %83 = bitcast i8* %82 to <4 x i8>*
  %"&pSB[currWI].offset2054.sum" = add i64 %CurrSBIndex..0, 1640
  %84 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2054.sum"
  %85 = bitcast i8* %84 to <4 x i8>*
  %"&pSB[currWI].offset2090.sum" = add i64 %CurrSBIndex..0, 1656
  %86 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2090.sum"
  %87 = bitcast i8* %86 to <4 x i8>*
  %"&pSB[currWI].offset2126.sum" = add i64 %CurrSBIndex..0, 1672
  %88 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2126.sum"
  %89 = bitcast i8* %88 to <4 x i8>*
  %"&pSB[currWI].offset2162.sum" = add i64 %CurrSBIndex..0, 1688
  %90 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2162.sum"
  %91 = bitcast i8* %90 to <4 x i8>*
  %"&pSB[currWI].offset2198.sum" = add i64 %CurrSBIndex..0, 1704
  %92 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2198.sum"
  %93 = bitcast i8* %92 to <4 x i8>*
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %63, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %65, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %67, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %69, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %71, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %73, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %75, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %77, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %79, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %81, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %83, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %85, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %87, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %89, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %91, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %93, align 8
  %"&pSB[currWI].offset1654.sum" = add i64 %CurrSBIndex..0, 1468
  %94 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1654.sum"
  %95 = bitcast i8* %94 to <4 x i8>*
  %"&pSB[currWI].offset1690.sum" = add i64 %CurrSBIndex..0, 1484
  %96 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1690.sum"
  %97 = bitcast i8* %96 to <4 x i8>*
  %"&pSB[currWI].offset1726.sum" = add i64 %CurrSBIndex..0, 1500
  %98 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1726.sum"
  %99 = bitcast i8* %98 to <4 x i8>*
  %"&pSB[currWI].offset1762.sum" = add i64 %CurrSBIndex..0, 1516
  %100 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1762.sum"
  %101 = bitcast i8* %100 to <4 x i8>*
  %"&pSB[currWI].offset1798.sum" = add i64 %CurrSBIndex..0, 1532
  %102 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1798.sum"
  %103 = bitcast i8* %102 to <4 x i8>*
  %"&pSB[currWI].offset1834.sum" = add i64 %CurrSBIndex..0, 1548
  %104 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1834.sum"
  %105 = bitcast i8* %104 to <4 x i8>*
  %"&pSB[currWI].offset1870.sum" = add i64 %CurrSBIndex..0, 1564
  %106 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1870.sum"
  %107 = bitcast i8* %106 to <4 x i8>*
  %"&pSB[currWI].offset1906.sum" = add i64 %CurrSBIndex..0, 1580
  %108 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1906.sum"
  %109 = bitcast i8* %108 to <4 x i8>*
  %"&pSB[currWI].offset1942.sum" = add i64 %CurrSBIndex..0, 1596
  %110 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1942.sum"
  %111 = bitcast i8* %110 to <4 x i8>*
  %"&pSB[currWI].offset1978.sum" = add i64 %CurrSBIndex..0, 1612
  %112 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset1978.sum"
  %113 = bitcast i8* %112 to <4 x i8>*
  %"&pSB[currWI].offset2014.sum" = add i64 %CurrSBIndex..0, 1628
  %114 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2014.sum"
  %115 = bitcast i8* %114 to <4 x i8>*
  %"&pSB[currWI].offset2050.sum" = add i64 %CurrSBIndex..0, 1644
  %116 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2050.sum"
  %117 = bitcast i8* %116 to <4 x i8>*
  %"&pSB[currWI].offset2086.sum" = add i64 %CurrSBIndex..0, 1660
  %118 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2086.sum"
  %119 = bitcast i8* %118 to <4 x i8>*
  %"&pSB[currWI].offset2122.sum" = add i64 %CurrSBIndex..0, 1676
  %120 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2122.sum"
  %121 = bitcast i8* %120 to <4 x i8>*
  %"&pSB[currWI].offset2158.sum" = add i64 %CurrSBIndex..0, 1692
  %122 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2158.sum"
  %123 = bitcast i8* %122 to <4 x i8>*
  %"&pSB[currWI].offset2194.sum" = add i64 %CurrSBIndex..0, 1708
  %124 = getelementptr inbounds i8* %pSpecialBuf, i64 %"&pSB[currWI].offset2194.sum"
  %125 = bitcast i8* %124 to <4 x i8>*
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %95, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %97, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %99, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %101, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %103, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %105, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %107, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %109, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %111, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %113, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %115, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %117, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %119, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %121, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %123, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %125, align 4
  %126 = zext i32 %13 to i64
  %"&(pSB[currWI].offset)996" = add nuw i64 %CurrSBIndex..0, 904
  %"&pSB[currWI].offset997" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)996"
  %CastToValueType998 = bitcast i8* %"&pSB[currWI].offset997" to i64*
  store i64 %126, i64* %CastToValueType998, align 8
  %127 = getelementptr inbounds <4 x i8> addrspace(1)* %input, i64 %126
  %128 = load <4 x i8> addrspace(1)* %127, align 4
  %scalar = extractelement <4 x i8> %128, i32 0
  %scalar2 = extractelement <4 x i8> %128, i32 1
  %scalar3 = extractelement <4 x i8> %128, i32 2
  %scalar4 = extractelement <4 x i8> %128, i32 3
  %129 = and i64 %7, 4294967295
  %"&(pSB[currWI].offset)1005" = add nuw i64 %CurrSBIndex..0, 912
  %"&pSB[currWI].offset1006" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1005"
  %CastToValueType1007 = bitcast i8* %"&pSB[currWI].offset1006" to i64*
  store i64 %129, i64* %CastToValueType1007, align 8
  %130 = getelementptr inbounds <4 x i8> addrspace(3)* %block0, i64 %129
  %"&(pSB[currWI].offset)1014" = add nuw i64 %CurrSBIndex..0, 920
  %"&pSB[currWI].offset1015" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1014"
  %CastToValueType1016 = bitcast i8* %"&pSB[currWI].offset1015" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %130, <4 x i8> addrspace(3)** %CastToValueType1016, align 8
  store <4 x i8> %128, <4 x i8> addrspace(3)* %130, align 4
  %131 = add i32 %8, %0
  %132 = zext i32 %131 to i64
  %133 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %132
  %134 = load <4 x i8> addrspace(1)* %133, align 4
  %scalar5 = extractelement <4 x i8> %134, i32 0
  %scalar6 = extractelement <4 x i8> %134, i32 1
  %scalar7 = extractelement <4 x i8> %134, i32 2
  %scalar8 = extractelement <4 x i8> %134, i32 3
  %135 = xor i8 %scalar, %scalar5
  %temp = insertelement <16 x i8> undef, i8 %135, i32 0
  %vector = shufflevector <16 x i8> %temp, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1038" = add nuw i64 %CurrSBIndex..0, 928
  %"&pSB[currWI].offset1039" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1038"
  %CastToValueType1040 = bitcast i8* %"&pSB[currWI].offset1039" to <16 x i8>*
  store <16 x i8> %vector, <16 x i8>* %CastToValueType1040, align 16
  %136 = xor i8 %scalar2, %scalar6
  %temp133 = insertelement <16 x i8> undef, i8 %136, i32 0
  %vector134 = shufflevector <16 x i8> %temp133, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1042" = add nuw i64 %CurrSBIndex..0, 944
  %"&pSB[currWI].offset1043" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1042"
  %CastToValueType1044 = bitcast i8* %"&pSB[currWI].offset1043" to <16 x i8>*
  store <16 x i8> %vector134, <16 x i8>* %CastToValueType1044, align 16
  %137 = xor i8 %scalar3, %scalar7
  %temp136 = insertelement <16 x i8> undef, i8 %137, i32 0
  %vector137 = shufflevector <16 x i8> %temp136, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1046" = add nuw i64 %CurrSBIndex..0, 960
  %"&pSB[currWI].offset1047" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1046"
  %CastToValueType1048 = bitcast i8* %"&pSB[currWI].offset1047" to <16 x i8>*
  store <16 x i8> %vector137, <16 x i8>* %CastToValueType1048, align 16
  %138 = xor i8 %scalar4, %scalar8
  %temp139 = insertelement <16 x i8> undef, i8 %138, i32 0
  %vector140 = shufflevector <16 x i8> %temp139, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1050" = add nuw i64 %CurrSBIndex..0, 976
  %"&pSB[currWI].offset1051" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1050"
  %CastToValueType1052 = bitcast i8* %"&pSB[currWI].offset1051" to <16 x i8>*
  store <16 x i8> %vector140, <16 x i8>* %CastToValueType1052, align 16
  %temp.vect = insertelement <4 x i8> undef, i8 %135, i32 0
  %temp.vect105 = insertelement <4 x i8> %temp.vect, i8 %136, i32 1
  %temp.vect106 = insertelement <4 x i8> %temp.vect105, i8 %137, i32 2
  %temp.vect107 = insertelement <4 x i8> %temp.vect106, i8 %138, i32 3
  store <4 x i8> %temp.vect107, <4 x i8> addrspace(3)* %130, align 4
  %139 = getelementptr inbounds <4 x i8> addrspace(3)* %block1, i64 %129
  %"&(pSB[currWI].offset)1054" = add nuw i64 %CurrSBIndex..0, 992
  %"&pSB[currWI].offset1055" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1054"
  %CastToValueType1056 = bitcast i8* %"&pSB[currWI].offset1055" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %139, <4 x i8> addrspace(3)** %CastToValueType1056, align 8
  %140 = sub i32 0, %8
  %141 = and i32 %140, 3
  %142 = zext i32 %141 to i64
  %"&(pSB[currWI].offset)1649" = add nuw i64 %CurrSBIndex..0, 1456
  %"&pSB[currWI].offset1650" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1649"
  %CastToValueType1651 = bitcast i8* %"&pSB[currWI].offset1650" to [4 x <4 x i8>]*
  %143 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1651, i64 0, i64 %142
  %"&(pSB[currWI].offset)1063" = add nuw i64 %CurrSBIndex..0, 1000
  %"&pSB[currWI].offset1064" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1063"
  %CastToValueType1065 = bitcast i8* %"&pSB[currWI].offset1064" to <4 x i8>**
  store <4 x i8>* %143, <4 x i8>** %CastToValueType1065, align 8
  %"&(pSB[currWI].offset)1685" = add nuw i64 %CurrSBIndex..0, 1472
  %"&pSB[currWI].offset1686" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1685"
  %CastToValueType1687 = bitcast i8* %"&pSB[currWI].offset1686" to [4 x <4 x i8>]*
  %144 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1687, i64 0, i64 %142
  %"&(pSB[currWI].offset)1087" = add nuw i64 %CurrSBIndex..0, 1008
  %"&pSB[currWI].offset1088" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1087"
  %CastToValueType1089 = bitcast i8* %"&pSB[currWI].offset1088" to <4 x i8>**
  store <4 x i8>* %144, <4 x i8>** %CastToValueType1089, align 8
  %"&(pSB[currWI].offset)1721" = add nuw i64 %CurrSBIndex..0, 1488
  %"&pSB[currWI].offset1722" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1721"
  %CastToValueType1723 = bitcast i8* %"&pSB[currWI].offset1722" to [4 x <4 x i8>]*
  %145 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1723, i64 0, i64 %142
  %"&(pSB[currWI].offset)1111" = add nuw i64 %CurrSBIndex..0, 1016
  %"&pSB[currWI].offset1112" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1111"
  %CastToValueType1113 = bitcast i8* %"&pSB[currWI].offset1112" to <4 x i8>**
  store <4 x i8>* %145, <4 x i8>** %CastToValueType1113, align 8
  %"&(pSB[currWI].offset)1757" = add nuw i64 %CurrSBIndex..0, 1504
  %"&pSB[currWI].offset1758" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1757"
  %CastToValueType1759 = bitcast i8* %"&pSB[currWI].offset1758" to [4 x <4 x i8>]*
  %146 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1759, i64 0, i64 %142
  %"&(pSB[currWI].offset)1135" = add nuw i64 %CurrSBIndex..0, 1024
  %"&pSB[currWI].offset1136" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1135"
  %CastToValueType1137 = bitcast i8* %"&pSB[currWI].offset1136" to <4 x i8>**
  store <4 x i8>* %146, <4 x i8>** %CastToValueType1137, align 8
  %"&(pSB[currWI].offset)1793" = add nuw i64 %CurrSBIndex..0, 1520
  %"&pSB[currWI].offset1794" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1793"
  %CastToValueType1795 = bitcast i8* %"&pSB[currWI].offset1794" to [4 x <4 x i8>]*
  %147 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1795, i64 0, i64 %142
  %"&(pSB[currWI].offset)1159" = add nuw i64 %CurrSBIndex..0, 1032
  %"&pSB[currWI].offset1160" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1159"
  %CastToValueType1161 = bitcast i8* %"&pSB[currWI].offset1160" to <4 x i8>**
  store <4 x i8>* %147, <4 x i8>** %CastToValueType1161, align 8
  %"&(pSB[currWI].offset)1829" = add nuw i64 %CurrSBIndex..0, 1536
  %"&pSB[currWI].offset1830" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1829"
  %CastToValueType1831 = bitcast i8* %"&pSB[currWI].offset1830" to [4 x <4 x i8>]*
  %148 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1831, i64 0, i64 %142
  %"&(pSB[currWI].offset)1183" = add nuw i64 %CurrSBIndex..0, 1040
  %"&pSB[currWI].offset1184" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1183"
  %CastToValueType1185 = bitcast i8* %"&pSB[currWI].offset1184" to <4 x i8>**
  store <4 x i8>* %148, <4 x i8>** %CastToValueType1185, align 8
  %"&(pSB[currWI].offset)1865" = add nuw i64 %CurrSBIndex..0, 1552
  %"&pSB[currWI].offset1866" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1865"
  %CastToValueType1867 = bitcast i8* %"&pSB[currWI].offset1866" to [4 x <4 x i8>]*
  %149 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1867, i64 0, i64 %142
  %"&(pSB[currWI].offset)1207" = add nuw i64 %CurrSBIndex..0, 1048
  %"&pSB[currWI].offset1208" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1207"
  %CastToValueType1209 = bitcast i8* %"&pSB[currWI].offset1208" to <4 x i8>**
  store <4 x i8>* %149, <4 x i8>** %CastToValueType1209, align 8
  %"&(pSB[currWI].offset)1901" = add nuw i64 %CurrSBIndex..0, 1568
  %"&pSB[currWI].offset1902" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1901"
  %CastToValueType1903 = bitcast i8* %"&pSB[currWI].offset1902" to [4 x <4 x i8>]*
  %150 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1903, i64 0, i64 %142
  %"&(pSB[currWI].offset)1231" = add nuw i64 %CurrSBIndex..0, 1056
  %"&pSB[currWI].offset1232" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1231"
  %CastToValueType1233 = bitcast i8* %"&pSB[currWI].offset1232" to <4 x i8>**
  store <4 x i8>* %150, <4 x i8>** %CastToValueType1233, align 8
  %"&(pSB[currWI].offset)1937" = add nuw i64 %CurrSBIndex..0, 1584
  %"&pSB[currWI].offset1938" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1937"
  %CastToValueType1939 = bitcast i8* %"&pSB[currWI].offset1938" to [4 x <4 x i8>]*
  %151 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1939, i64 0, i64 %142
  %"&(pSB[currWI].offset)1255" = add nuw i64 %CurrSBIndex..0, 1064
  %"&pSB[currWI].offset1256" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1255"
  %CastToValueType1257 = bitcast i8* %"&pSB[currWI].offset1256" to <4 x i8>**
  store <4 x i8>* %151, <4 x i8>** %CastToValueType1257, align 8
  %"&(pSB[currWI].offset)1973" = add nuw i64 %CurrSBIndex..0, 1600
  %"&pSB[currWI].offset1974" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1973"
  %CastToValueType1975 = bitcast i8* %"&pSB[currWI].offset1974" to [4 x <4 x i8>]*
  %152 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1975, i64 0, i64 %142
  %"&(pSB[currWI].offset)1279" = add nuw i64 %CurrSBIndex..0, 1072
  %"&pSB[currWI].offset1280" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1279"
  %CastToValueType1281 = bitcast i8* %"&pSB[currWI].offset1280" to <4 x i8>**
  store <4 x i8>* %152, <4 x i8>** %CastToValueType1281, align 8
  %"&(pSB[currWI].offset)2009" = add nuw i64 %CurrSBIndex..0, 1616
  %"&pSB[currWI].offset2010" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2009"
  %CastToValueType2011 = bitcast i8* %"&pSB[currWI].offset2010" to [4 x <4 x i8>]*
  %153 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2011, i64 0, i64 %142
  %"&(pSB[currWI].offset)1303" = add nuw i64 %CurrSBIndex..0, 1080
  %"&pSB[currWI].offset1304" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1303"
  %CastToValueType1305 = bitcast i8* %"&pSB[currWI].offset1304" to <4 x i8>**
  store <4 x i8>* %153, <4 x i8>** %CastToValueType1305, align 8
  %"&(pSB[currWI].offset)2045" = add nuw i64 %CurrSBIndex..0, 1632
  %"&pSB[currWI].offset2046" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2045"
  %CastToValueType2047 = bitcast i8* %"&pSB[currWI].offset2046" to [4 x <4 x i8>]*
  %154 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2047, i64 0, i64 %142
  %"&(pSB[currWI].offset)1327" = add nuw i64 %CurrSBIndex..0, 1088
  %"&pSB[currWI].offset1328" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1327"
  %CastToValueType1329 = bitcast i8* %"&pSB[currWI].offset1328" to <4 x i8>**
  store <4 x i8>* %154, <4 x i8>** %CastToValueType1329, align 8
  %"&(pSB[currWI].offset)2081" = add nuw i64 %CurrSBIndex..0, 1648
  %"&pSB[currWI].offset2082" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2081"
  %CastToValueType2083 = bitcast i8* %"&pSB[currWI].offset2082" to [4 x <4 x i8>]*
  %155 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2083, i64 0, i64 %142
  %"&(pSB[currWI].offset)1351" = add nuw i64 %CurrSBIndex..0, 1096
  %"&pSB[currWI].offset1352" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1351"
  %CastToValueType1353 = bitcast i8* %"&pSB[currWI].offset1352" to <4 x i8>**
  store <4 x i8>* %155, <4 x i8>** %CastToValueType1353, align 8
  %"&(pSB[currWI].offset)2117" = add nuw i64 %CurrSBIndex..0, 1664
  %"&pSB[currWI].offset2118" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2117"
  %CastToValueType2119 = bitcast i8* %"&pSB[currWI].offset2118" to [4 x <4 x i8>]*
  %156 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2119, i64 0, i64 %142
  %"&(pSB[currWI].offset)1375" = add nuw i64 %CurrSBIndex..0, 1104
  %"&pSB[currWI].offset1376" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1375"
  %CastToValueType1377 = bitcast i8* %"&pSB[currWI].offset1376" to <4 x i8>**
  store <4 x i8>* %156, <4 x i8>** %CastToValueType1377, align 8
  %"&(pSB[currWI].offset)2153" = add nuw i64 %CurrSBIndex..0, 1680
  %"&pSB[currWI].offset2154" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2153"
  %CastToValueType2155 = bitcast i8* %"&pSB[currWI].offset2154" to [4 x <4 x i8>]*
  %157 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2155, i64 0, i64 %142
  %"&(pSB[currWI].offset)1399" = add nuw i64 %CurrSBIndex..0, 1112
  %"&pSB[currWI].offset1400" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1399"
  %CastToValueType1401 = bitcast i8* %"&pSB[currWI].offset1400" to <4 x i8>**
  store <4 x i8>* %157, <4 x i8>** %CastToValueType1401, align 8
  %"&(pSB[currWI].offset)2189" = add nuw i64 %CurrSBIndex..0, 1696
  %"&pSB[currWI].offset2190" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2189"
  %CastToValueType2191 = bitcast i8* %"&pSB[currWI].offset2190" to [4 x <4 x i8>]*
  %158 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2191, i64 0, i64 %142
  %"&(pSB[currWI].offset)1423" = add nuw i64 %CurrSBIndex..0, 1120
  %"&pSB[currWI].offset1424" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1423"
  %CastToValueType1425 = bitcast i8* %"&pSB[currWI].offset1424" to <4 x i8>**
  store <4 x i8>* %158, <4 x i8>** %CastToValueType1425, align 8
  %tmp75 = sub i64 1, %7
  %"&(pSB[currWI].offset)1447" = add nuw i64 %CurrSBIndex..0, 1128
  %"&pSB[currWI].offset1448" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1447"
  %CastToValueType1449 = bitcast i8* %"&pSB[currWI].offset1448" to i64*
  store i64 %tmp75, i64* %CastToValueType1449, align 8
  %tmp86 = add i32 %0, %8
  %tmp87 = add i32 %tmp86, -4
  %"&(pSB[currWI].offset)1456" = add nuw i64 %CurrSBIndex..0, 1136
  %"&pSB[currWI].offset1457" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1456"
  %CastToValueType1458 = bitcast i8* %"&pSB[currWI].offset1457" to i32*
  store i32 %tmp87, i32* %CastToValueType1458, align 4
  br label %159

; <label>:159                                     ; preds = %._crit_edge66, %SyncBB
  %CurrSBIndex..2 = phi i64 [ %CurrSBIndex..0, %SyncBB ], [ %CurrSBIndex..1, %._crit_edge66 ]
  %currBarrier.1 = phi i32 [ %currBarrier.2, %SyncBB ], [ %currBarrier.0, %._crit_edge66 ]
  %CurrWI..2 = phi i64 [ %CurrWI..0, %SyncBB ], [ %CurrWI..1, %._crit_edge66 ]
  %vectorPHI = phi <16 x i8> [ %vector, %SyncBB ], [ %loadedValue1580, %._crit_edge66 ]
  %vectorPHI132 = phi <16 x i8> [ %vector134, %SyncBB ], [ %loadedValue1594, %._crit_edge66 ]
  %vectorPHI135 = phi <16 x i8> [ %vector137, %SyncBB ], [ %loadedValue1608, %._crit_edge66 ]
  %vectorPHI138 = phi <16 x i8> [ %vector140, %SyncBB ], [ %loadedValue1622, %._crit_edge66 ]
  %indvar79 = phi i32 [ 0, %SyncBB ], [ %indvar.next80, %._crit_edge66 ]
  %"&(pSB[currWI].offset)1465" = add nuw i64 %CurrSBIndex..2, 1140
  %"&pSB[currWI].offset1466" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1465"
  %CastToValueType1467 = bitcast i8* %"&pSB[currWI].offset1466" to i32*
  store i32 %indvar79, i32* %CastToValueType1467, align 4
  %extract188 = extractelement <16 x i8> %vectorPHI138, i32 0
  %extract189 = extractelement <16 x i8> %vectorPHI138, i32 1
  %extract190 = extractelement <16 x i8> %vectorPHI138, i32 2
  %extract191 = extractelement <16 x i8> %vectorPHI138, i32 3
  %extract192 = extractelement <16 x i8> %vectorPHI138, i32 4
  %extract193 = extractelement <16 x i8> %vectorPHI138, i32 5
  %extract194 = extractelement <16 x i8> %vectorPHI138, i32 6
  %extract195 = extractelement <16 x i8> %vectorPHI138, i32 7
  %extract196 = extractelement <16 x i8> %vectorPHI138, i32 8
  %extract197 = extractelement <16 x i8> %vectorPHI138, i32 9
  %extract198 = extractelement <16 x i8> %vectorPHI138, i32 10
  %extract199 = extractelement <16 x i8> %vectorPHI138, i32 11
  %extract200 = extractelement <16 x i8> %vectorPHI138, i32 12
  %extract201 = extractelement <16 x i8> %vectorPHI138, i32 13
  %extract202 = extractelement <16 x i8> %vectorPHI138, i32 14
  %extract203 = extractelement <16 x i8> %vectorPHI138, i32 15
  %extract172 = extractelement <16 x i8> %vectorPHI135, i32 0
  %extract173 = extractelement <16 x i8> %vectorPHI135, i32 1
  %extract174 = extractelement <16 x i8> %vectorPHI135, i32 2
  %extract175 = extractelement <16 x i8> %vectorPHI135, i32 3
  %extract176 = extractelement <16 x i8> %vectorPHI135, i32 4
  %extract177 = extractelement <16 x i8> %vectorPHI135, i32 5
  %extract178 = extractelement <16 x i8> %vectorPHI135, i32 6
  %extract179 = extractelement <16 x i8> %vectorPHI135, i32 7
  %extract180 = extractelement <16 x i8> %vectorPHI135, i32 8
  %extract181 = extractelement <16 x i8> %vectorPHI135, i32 9
  %extract182 = extractelement <16 x i8> %vectorPHI135, i32 10
  %extract183 = extractelement <16 x i8> %vectorPHI135, i32 11
  %extract184 = extractelement <16 x i8> %vectorPHI135, i32 12
  %extract185 = extractelement <16 x i8> %vectorPHI135, i32 13
  %extract186 = extractelement <16 x i8> %vectorPHI135, i32 14
  %extract187 = extractelement <16 x i8> %vectorPHI135, i32 15
  %extract156 = extractelement <16 x i8> %vectorPHI132, i32 0
  %extract157 = extractelement <16 x i8> %vectorPHI132, i32 1
  %extract158 = extractelement <16 x i8> %vectorPHI132, i32 2
  %extract159 = extractelement <16 x i8> %vectorPHI132, i32 3
  %extract160 = extractelement <16 x i8> %vectorPHI132, i32 4
  %extract161 = extractelement <16 x i8> %vectorPHI132, i32 5
  %extract162 = extractelement <16 x i8> %vectorPHI132, i32 6
  %extract163 = extractelement <16 x i8> %vectorPHI132, i32 7
  %extract164 = extractelement <16 x i8> %vectorPHI132, i32 8
  %extract165 = extractelement <16 x i8> %vectorPHI132, i32 9
  %extract166 = extractelement <16 x i8> %vectorPHI132, i32 10
  %extract167 = extractelement <16 x i8> %vectorPHI132, i32 11
  %extract168 = extractelement <16 x i8> %vectorPHI132, i32 12
  %extract169 = extractelement <16 x i8> %vectorPHI132, i32 13
  %extract170 = extractelement <16 x i8> %vectorPHI132, i32 14
  %extract171 = extractelement <16 x i8> %vectorPHI132, i32 15
  %extract = extractelement <16 x i8> %vectorPHI, i32 0
  %extract141 = extractelement <16 x i8> %vectorPHI, i32 1
  %extract142 = extractelement <16 x i8> %vectorPHI, i32 2
  %extract143 = extractelement <16 x i8> %vectorPHI, i32 3
  %extract144 = extractelement <16 x i8> %vectorPHI, i32 4
  %extract145 = extractelement <16 x i8> %vectorPHI, i32 5
  %extract146 = extractelement <16 x i8> %vectorPHI, i32 6
  %extract147 = extractelement <16 x i8> %vectorPHI, i32 7
  %extract148 = extractelement <16 x i8> %vectorPHI, i32 8
  %extract149 = extractelement <16 x i8> %vectorPHI, i32 9
  %extract150 = extractelement <16 x i8> %vectorPHI, i32 10
  %extract151 = extractelement <16 x i8> %vectorPHI, i32 11
  %extract152 = extractelement <16 x i8> %vectorPHI, i32 12
  %extract153 = extractelement <16 x i8> %vectorPHI, i32 13
  %extract154 = extractelement <16 x i8> %vectorPHI, i32 14
  %extract155 = extractelement <16 x i8> %vectorPHI, i32 15
  %160 = insertelement <4 x i8> undef, i8 %extract, i32 0
  %161 = insertelement <4 x i8> undef, i8 %extract141, i32 0
  %162 = insertelement <4 x i8> undef, i8 %extract142, i32 0
  %163 = insertelement <4 x i8> undef, i8 %extract143, i32 0
  %164 = insertelement <4 x i8> undef, i8 %extract144, i32 0
  %165 = insertelement <4 x i8> undef, i8 %extract145, i32 0
  %166 = insertelement <4 x i8> undef, i8 %extract146, i32 0
  %167 = insertelement <4 x i8> undef, i8 %extract147, i32 0
  %168 = insertelement <4 x i8> undef, i8 %extract148, i32 0
  %169 = insertelement <4 x i8> undef, i8 %extract149, i32 0
  %170 = insertelement <4 x i8> undef, i8 %extract150, i32 0
  %171 = insertelement <4 x i8> undef, i8 %extract151, i32 0
  %172 = insertelement <4 x i8> undef, i8 %extract152, i32 0
  %173 = insertelement <4 x i8> undef, i8 %extract153, i32 0
  %174 = insertelement <4 x i8> undef, i8 %extract154, i32 0
  %175 = insertelement <4 x i8> undef, i8 %extract155, i32 0
  %176 = insertelement <4 x i8> %160, i8 %extract156, i32 1
  %177 = insertelement <4 x i8> %161, i8 %extract157, i32 1
  %178 = insertelement <4 x i8> %162, i8 %extract158, i32 1
  %179 = insertelement <4 x i8> %163, i8 %extract159, i32 1
  %180 = insertelement <4 x i8> %164, i8 %extract160, i32 1
  %181 = insertelement <4 x i8> %165, i8 %extract161, i32 1
  %182 = insertelement <4 x i8> %166, i8 %extract162, i32 1
  %183 = insertelement <4 x i8> %167, i8 %extract163, i32 1
  %184 = insertelement <4 x i8> %168, i8 %extract164, i32 1
  %185 = insertelement <4 x i8> %169, i8 %extract165, i32 1
  %186 = insertelement <4 x i8> %170, i8 %extract166, i32 1
  %187 = insertelement <4 x i8> %171, i8 %extract167, i32 1
  %188 = insertelement <4 x i8> %172, i8 %extract168, i32 1
  %189 = insertelement <4 x i8> %173, i8 %extract169, i32 1
  %190 = insertelement <4 x i8> %174, i8 %extract170, i32 1
  %191 = insertelement <4 x i8> %175, i8 %extract171, i32 1
  %192 = insertelement <4 x i8> %176, i8 %extract172, i32 2
  %193 = insertelement <4 x i8> %177, i8 %extract173, i32 2
  %194 = insertelement <4 x i8> %178, i8 %extract174, i32 2
  %195 = insertelement <4 x i8> %179, i8 %extract175, i32 2
  %196 = insertelement <4 x i8> %180, i8 %extract176, i32 2
  %197 = insertelement <4 x i8> %181, i8 %extract177, i32 2
  %198 = insertelement <4 x i8> %182, i8 %extract178, i32 2
  %199 = insertelement <4 x i8> %183, i8 %extract179, i32 2
  %200 = insertelement <4 x i8> %184, i8 %extract180, i32 2
  %201 = insertelement <4 x i8> %185, i8 %extract181, i32 2
  %202 = insertelement <4 x i8> %186, i8 %extract182, i32 2
  %203 = insertelement <4 x i8> %187, i8 %extract183, i32 2
  %204 = insertelement <4 x i8> %188, i8 %extract184, i32 2
  %205 = insertelement <4 x i8> %189, i8 %extract185, i32 2
  %206 = insertelement <4 x i8> %190, i8 %extract186, i32 2
  %207 = insertelement <4 x i8> %191, i8 %extract187, i32 2
  %208 = insertelement <4 x i8> %192, i8 %extract188, i32 3
  %209 = insertelement <4 x i8> %193, i8 %extract189, i32 3
  %210 = insertelement <4 x i8> %194, i8 %extract190, i32 3
  %211 = insertelement <4 x i8> %195, i8 %extract191, i32 3
  %212 = insertelement <4 x i8> %196, i8 %extract192, i32 3
  %213 = insertelement <4 x i8> %197, i8 %extract193, i32 3
  %214 = insertelement <4 x i8> %198, i8 %extract194, i32 3
  %215 = insertelement <4 x i8> %199, i8 %extract195, i32 3
  %216 = insertelement <4 x i8> %200, i8 %extract196, i32 3
  %217 = insertelement <4 x i8> %201, i8 %extract197, i32 3
  %218 = insertelement <4 x i8> %202, i8 %extract198, i32 3
  %219 = insertelement <4 x i8> %203, i8 %extract199, i32 3
  %220 = insertelement <4 x i8> %204, i8 %extract200, i32 3
  %221 = insertelement <4 x i8> %205, i8 %extract201, i32 3
  %222 = insertelement <4 x i8> %206, i8 %extract202, i32 3
  %223 = insertelement <4 x i8> %207, i8 %extract203, i32 3
  %224 = bitcast <4 x i8> %208 to i32
  %225 = bitcast <4 x i8> %209 to i32
  %226 = bitcast <4 x i8> %210 to i32
  %227 = bitcast <4 x i8> %211 to i32
  %228 = bitcast <4 x i8> %212 to i32
  %229 = bitcast <4 x i8> %213 to i32
  %230 = bitcast <4 x i8> %214 to i32
  %231 = bitcast <4 x i8> %215 to i32
  %232 = bitcast <4 x i8> %216 to i32
  %233 = bitcast <4 x i8> %217 to i32
  %234 = bitcast <4 x i8> %218 to i32
  %235 = bitcast <4 x i8> %219 to i32
  %236 = bitcast <4 x i8> %220 to i32
  %237 = bitcast <4 x i8> %221 to i32
  %238 = bitcast <4 x i8> %222 to i32
  %239 = bitcast <4 x i8> %223 to i32
  %240 = bitcast i32 %224 to <4 x i8>
  %241 = bitcast i32 %225 to <4 x i8>
  %242 = bitcast i32 %226 to <4 x i8>
  %243 = bitcast i32 %227 to <4 x i8>
  %244 = bitcast i32 %228 to <4 x i8>
  %245 = bitcast i32 %229 to <4 x i8>
  %246 = bitcast i32 %230 to <4 x i8>
  %247 = bitcast i32 %231 to <4 x i8>
  %248 = bitcast i32 %232 to <4 x i8>
  %249 = bitcast i32 %233 to <4 x i8>
  %250 = bitcast i32 %234 to <4 x i8>
  %251 = bitcast i32 %235 to <4 x i8>
  %252 = bitcast i32 %236 to <4 x i8>
  %253 = bitcast i32 %237 to <4 x i8>
  %254 = bitcast i32 %238 to <4 x i8>
  %255 = bitcast i32 %239 to <4 x i8>
  %256 = extractelement <4 x i8> %240, i32 0
  %257 = extractelement <4 x i8> %241, i32 0
  %258 = extractelement <4 x i8> %242, i32 0
  %259 = extractelement <4 x i8> %243, i32 0
  %260 = extractelement <4 x i8> %244, i32 0
  %261 = extractelement <4 x i8> %245, i32 0
  %262 = extractelement <4 x i8> %246, i32 0
  %263 = extractelement <4 x i8> %247, i32 0
  %264 = extractelement <4 x i8> %248, i32 0
  %265 = extractelement <4 x i8> %249, i32 0
  %266 = extractelement <4 x i8> %250, i32 0
  %267 = extractelement <4 x i8> %251, i32 0
  %268 = extractelement <4 x i8> %252, i32 0
  %269 = extractelement <4 x i8> %253, i32 0
  %270 = extractelement <4 x i8> %254, i32 0
  %271 = extractelement <4 x i8> %255, i32 0
  %temp.vect205 = insertelement <16 x i8> undef, i8 %256, i32 0
  %temp.vect206 = insertelement <16 x i8> %temp.vect205, i8 %257, i32 1
  %temp.vect207 = insertelement <16 x i8> %temp.vect206, i8 %258, i32 2
  %temp.vect208 = insertelement <16 x i8> %temp.vect207, i8 %259, i32 3
  %temp.vect209 = insertelement <16 x i8> %temp.vect208, i8 %260, i32 4
  %temp.vect210 = insertelement <16 x i8> %temp.vect209, i8 %261, i32 5
  %temp.vect211 = insertelement <16 x i8> %temp.vect210, i8 %262, i32 6
  %temp.vect212 = insertelement <16 x i8> %temp.vect211, i8 %263, i32 7
  %temp.vect213 = insertelement <16 x i8> %temp.vect212, i8 %264, i32 8
  %temp.vect214 = insertelement <16 x i8> %temp.vect213, i8 %265, i32 9
  %temp.vect215 = insertelement <16 x i8> %temp.vect214, i8 %266, i32 10
  %temp.vect216 = insertelement <16 x i8> %temp.vect215, i8 %267, i32 11
  %temp.vect217 = insertelement <16 x i8> %temp.vect216, i8 %268, i32 12
  %temp.vect218 = insertelement <16 x i8> %temp.vect217, i8 %269, i32 13
  %temp.vect219 = insertelement <16 x i8> %temp.vect218, i8 %270, i32 14
  %temp.vect220 = insertelement <16 x i8> %temp.vect219, i8 %271, i32 15
  %"&(pSB[currWI].offset)1484" = add nuw i64 %CurrSBIndex..2, 1152
  %"&pSB[currWI].offset1485" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1484"
  %CastToValueType1486 = bitcast i8* %"&pSB[currWI].offset1485" to <16 x i8>*
  store <16 x i8> %temp.vect220, <16 x i8>* %CastToValueType1486, align 16
  %272 = extractelement <4 x i8> %240, i32 1
  %273 = extractelement <4 x i8> %241, i32 1
  %274 = extractelement <4 x i8> %242, i32 1
  %275 = extractelement <4 x i8> %243, i32 1
  %276 = extractelement <4 x i8> %244, i32 1
  %277 = extractelement <4 x i8> %245, i32 1
  %278 = extractelement <4 x i8> %246, i32 1
  %279 = extractelement <4 x i8> %247, i32 1
  %280 = extractelement <4 x i8> %248, i32 1
  %281 = extractelement <4 x i8> %249, i32 1
  %282 = extractelement <4 x i8> %250, i32 1
  %283 = extractelement <4 x i8> %251, i32 1
  %284 = extractelement <4 x i8> %252, i32 1
  %285 = extractelement <4 x i8> %253, i32 1
  %286 = extractelement <4 x i8> %254, i32 1
  %287 = extractelement <4 x i8> %255, i32 1
  %temp.vect222 = insertelement <16 x i8> undef, i8 %272, i32 0
  %temp.vect223 = insertelement <16 x i8> %temp.vect222, i8 %273, i32 1
  %temp.vect224 = insertelement <16 x i8> %temp.vect223, i8 %274, i32 2
  %temp.vect225 = insertelement <16 x i8> %temp.vect224, i8 %275, i32 3
  %temp.vect226 = insertelement <16 x i8> %temp.vect225, i8 %276, i32 4
  %temp.vect227 = insertelement <16 x i8> %temp.vect226, i8 %277, i32 5
  %temp.vect228 = insertelement <16 x i8> %temp.vect227, i8 %278, i32 6
  %temp.vect229 = insertelement <16 x i8> %temp.vect228, i8 %279, i32 7
  %temp.vect230 = insertelement <16 x i8> %temp.vect229, i8 %280, i32 8
  %temp.vect231 = insertelement <16 x i8> %temp.vect230, i8 %281, i32 9
  %temp.vect232 = insertelement <16 x i8> %temp.vect231, i8 %282, i32 10
  %temp.vect233 = insertelement <16 x i8> %temp.vect232, i8 %283, i32 11
  %temp.vect234 = insertelement <16 x i8> %temp.vect233, i8 %284, i32 12
  %temp.vect235 = insertelement <16 x i8> %temp.vect234, i8 %285, i32 13
  %temp.vect236 = insertelement <16 x i8> %temp.vect235, i8 %286, i32 14
  %temp.vect237 = insertelement <16 x i8> %temp.vect236, i8 %287, i32 15
  %"&(pSB[currWI].offset)1488" = add nuw i64 %CurrSBIndex..2, 1168
  %"&pSB[currWI].offset1489" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1488"
  %CastToValueType1490 = bitcast i8* %"&pSB[currWI].offset1489" to <16 x i8>*
  store <16 x i8> %temp.vect237, <16 x i8>* %CastToValueType1490, align 16
  %288 = extractelement <4 x i8> %240, i32 2
  %289 = extractelement <4 x i8> %241, i32 2
  %290 = extractelement <4 x i8> %242, i32 2
  %291 = extractelement <4 x i8> %243, i32 2
  %292 = extractelement <4 x i8> %244, i32 2
  %293 = extractelement <4 x i8> %245, i32 2
  %294 = extractelement <4 x i8> %246, i32 2
  %295 = extractelement <4 x i8> %247, i32 2
  %296 = extractelement <4 x i8> %248, i32 2
  %297 = extractelement <4 x i8> %249, i32 2
  %298 = extractelement <4 x i8> %250, i32 2
  %299 = extractelement <4 x i8> %251, i32 2
  %300 = extractelement <4 x i8> %252, i32 2
  %301 = extractelement <4 x i8> %253, i32 2
  %302 = extractelement <4 x i8> %254, i32 2
  %303 = extractelement <4 x i8> %255, i32 2
  %temp.vect239 = insertelement <16 x i8> undef, i8 %288, i32 0
  %temp.vect240 = insertelement <16 x i8> %temp.vect239, i8 %289, i32 1
  %temp.vect241 = insertelement <16 x i8> %temp.vect240, i8 %290, i32 2
  %temp.vect242 = insertelement <16 x i8> %temp.vect241, i8 %291, i32 3
  %temp.vect243 = insertelement <16 x i8> %temp.vect242, i8 %292, i32 4
  %temp.vect244 = insertelement <16 x i8> %temp.vect243, i8 %293, i32 5
  %temp.vect245 = insertelement <16 x i8> %temp.vect244, i8 %294, i32 6
  %temp.vect246 = insertelement <16 x i8> %temp.vect245, i8 %295, i32 7
  %temp.vect247 = insertelement <16 x i8> %temp.vect246, i8 %296, i32 8
  %temp.vect248 = insertelement <16 x i8> %temp.vect247, i8 %297, i32 9
  %temp.vect249 = insertelement <16 x i8> %temp.vect248, i8 %298, i32 10
  %temp.vect250 = insertelement <16 x i8> %temp.vect249, i8 %299, i32 11
  %temp.vect251 = insertelement <16 x i8> %temp.vect250, i8 %300, i32 12
  %temp.vect252 = insertelement <16 x i8> %temp.vect251, i8 %301, i32 13
  %temp.vect253 = insertelement <16 x i8> %temp.vect252, i8 %302, i32 14
  %temp.vect254 = insertelement <16 x i8> %temp.vect253, i8 %303, i32 15
  %"&(pSB[currWI].offset)1492" = add nuw i64 %CurrSBIndex..2, 1184
  %"&pSB[currWI].offset1493" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1492"
  %CastToValueType1494 = bitcast i8* %"&pSB[currWI].offset1493" to <16 x i8>*
  store <16 x i8> %temp.vect254, <16 x i8>* %CastToValueType1494, align 16
  %304 = extractelement <4 x i8> %240, i32 3
  %305 = extractelement <4 x i8> %241, i32 3
  %306 = extractelement <4 x i8> %242, i32 3
  %307 = extractelement <4 x i8> %243, i32 3
  %308 = extractelement <4 x i8> %244, i32 3
  %309 = extractelement <4 x i8> %245, i32 3
  %310 = extractelement <4 x i8> %246, i32 3
  %311 = extractelement <4 x i8> %247, i32 3
  %312 = extractelement <4 x i8> %248, i32 3
  %313 = extractelement <4 x i8> %249, i32 3
  %314 = extractelement <4 x i8> %250, i32 3
  %315 = extractelement <4 x i8> %251, i32 3
  %316 = extractelement <4 x i8> %252, i32 3
  %317 = extractelement <4 x i8> %253, i32 3
  %318 = extractelement <4 x i8> %254, i32 3
  %319 = extractelement <4 x i8> %255, i32 3
  %temp.vect256 = insertelement <16 x i8> undef, i8 %304, i32 0
  %temp.vect257 = insertelement <16 x i8> %temp.vect256, i8 %305, i32 1
  %temp.vect258 = insertelement <16 x i8> %temp.vect257, i8 %306, i32 2
  %temp.vect259 = insertelement <16 x i8> %temp.vect258, i8 %307, i32 3
  %temp.vect260 = insertelement <16 x i8> %temp.vect259, i8 %308, i32 4
  %temp.vect261 = insertelement <16 x i8> %temp.vect260, i8 %309, i32 5
  %temp.vect262 = insertelement <16 x i8> %temp.vect261, i8 %310, i32 6
  %temp.vect263 = insertelement <16 x i8> %temp.vect262, i8 %311, i32 7
  %temp.vect264 = insertelement <16 x i8> %temp.vect263, i8 %312, i32 8
  %temp.vect265 = insertelement <16 x i8> %temp.vect264, i8 %313, i32 9
  %temp.vect266 = insertelement <16 x i8> %temp.vect265, i8 %314, i32 10
  %temp.vect267 = insertelement <16 x i8> %temp.vect266, i8 %315, i32 11
  %temp.vect268 = insertelement <16 x i8> %temp.vect267, i8 %316, i32 12
  %temp.vect269 = insertelement <16 x i8> %temp.vect268, i8 %317, i32 13
  %temp.vect270 = insertelement <16 x i8> %temp.vect269, i8 %318, i32 14
  %temp.vect271 = insertelement <16 x i8> %temp.vect270, i8 %319, i32 15
  %"&(pSB[currWI].offset)1496" = add nuw i64 %CurrSBIndex..2, 1200
  %"&pSB[currWI].offset1497" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1496"
  %CastToValueType1498 = bitcast i8* %"&pSB[currWI].offset1497" to <16 x i8>*
  store <16 x i8> %temp.vect271, <16 x i8>* %CastToValueType1498, align 16
  %"&(pSB[currWI].offset)991" = add nuw i64 %CurrSBIndex..2, 896
  %"&pSB[currWI].offset992" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)991"
  %CastToValueType993 = bitcast i8* %"&pSB[currWI].offset992" to i32*
  %loadedValue994 = load i32* %CastToValueType993, align 4
  %320 = icmp eq i32 %loadedValue994, 0
  br i1 %320, label %shiftRowsInv.exit, label %bb.nph.i.preheader

bb.nph.i.preheader:                               ; preds = %159
  %"&(pSB[currWI].offset)1512" = add nuw i64 %CurrSBIndex..2, 1264
  %"&pSB[currWI].offset1513" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1512"
  %CastToValueType1514 = bitcast i8* %"&pSB[currWI].offset1513" to <16 x i8>*
  %"&(pSB[currWI].offset)1508" = add nuw i64 %CurrSBIndex..2, 1248
  %"&pSB[currWI].offset1509" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1508"
  %CastToValueType1510 = bitcast i8* %"&pSB[currWI].offset1509" to <16 x i8>*
  %"&(pSB[currWI].offset)1504" = add nuw i64 %CurrSBIndex..2, 1232
  %"&pSB[currWI].offset1505" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1504"
  %CastToValueType1506 = bitcast i8* %"&pSB[currWI].offset1505" to <16 x i8>*
  %"&(pSB[currWI].offset)1500" = add nuw i64 %CurrSBIndex..2, 1216
  %"&pSB[currWI].offset1501" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1500"
  %CastToValueType1502 = bitcast i8* %"&pSB[currWI].offset1501" to <16 x i8>*
  %"&(pSB[currWI].offset)1516" = add nuw i64 %CurrSBIndex..2, 1280
  %"&pSB[currWI].offset1517" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1516"
  %CastToValueType1518 = bitcast i8* %"&pSB[currWI].offset1517" to i32*
  %"&(pSB[currWI].offset)987" = add nuw i64 %CurrSBIndex..2, 896
  %"&pSB[currWI].offset988" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)987"
  %CastToValueType989 = bitcast i8* %"&pSB[currWI].offset988" to i32*
  br label %bb.nph.i

bb.nph.i:                                         ; preds = %bb.nph.i, %bb.nph.i.preheader
  %i.03.i = phi i32 [ %321, %bb.nph.i ], [ 0, %bb.nph.i.preheader ]
  %vectorPHI204 = phi <16 x i8> [ %vectorPHI255, %bb.nph.i ], [ %temp.vect220, %bb.nph.i.preheader ]
  %vectorPHI221 = phi <16 x i8> [ %vectorPHI204, %bb.nph.i ], [ %temp.vect237, %bb.nph.i.preheader ]
  %vectorPHI238 = phi <16 x i8> [ %vectorPHI221, %bb.nph.i ], [ %temp.vect254, %bb.nph.i.preheader ]
  %vectorPHI255 = phi <16 x i8> [ %vectorPHI238, %bb.nph.i ], [ %temp.vect271, %bb.nph.i.preheader ]
  store <16 x i8> %vectorPHI255, <16 x i8>* %CastToValueType1514, align 16
  store <16 x i8> %vectorPHI238, <16 x i8>* %CastToValueType1510, align 16
  store <16 x i8> %vectorPHI221, <16 x i8>* %CastToValueType1506, align 16
  store <16 x i8> %vectorPHI204, <16 x i8>* %CastToValueType1502, align 16
  %321 = add i32 %i.03.i, 1
  store i32 %321, i32* %CastToValueType1518, align 4
  %loadedValue = load i32* %CastToValueType989, align 4
  %exitcond.i = icmp eq i32 %321, %loadedValue
  br i1 %exitcond.i, label %shiftRowsInv.exit, label %bb.nph.i

shiftRowsInv.exit:                                ; preds = %bb.nph.i, %159
  %vectorPHI272 = phi <16 x i8> [ %temp.vect220, %159 ], [ %vectorPHI255, %bb.nph.i ]
  %vectorPHI273 = phi <16 x i8> [ %temp.vect237, %159 ], [ %vectorPHI204, %bb.nph.i ]
  %vectorPHI274 = phi <16 x i8> [ %temp.vect254, %159 ], [ %vectorPHI221, %bb.nph.i ]
  %vectorPHI275 = phi <16 x i8> [ %temp.vect271, %159 ], [ %vectorPHI238, %bb.nph.i ]
  %extract339 = extractelement <16 x i8> %vectorPHI275, i32 15
  %extract323 = extractelement <16 x i8> %vectorPHI274, i32 15
  %extract307 = extractelement <16 x i8> %vectorPHI273, i32 15
  %extract291 = extractelement <16 x i8> %vectorPHI272, i32 15
  %322 = insertelement <4 x i8> undef, i8 %extract291, i32 0
  %323 = insertelement <4 x i8> %322, i8 %extract307, i32 1
  %324 = insertelement <4 x i8> %323, i8 %extract323, i32 2
  %325 = insertelement <4 x i8> %324, i8 %extract339, i32 3
  %326 = bitcast <4 x i8> %325 to i32
  %327 = bitcast i32 %326 to <4 x i8>
  %"&(pSB[currWI].offset)1028" = add nuw i64 %CurrSBIndex..2, 920
  %"&pSB[currWI].offset1029" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1028"
  %CastToValueType1030 = bitcast i8* %"&pSB[currWI].offset1029" to <4 x i8> addrspace(3)**
  %loadedValue1031 = load <4 x i8> addrspace(3)** %CastToValueType1030, align 8
  store <4 x i8> %327, <4 x i8> addrspace(3)* %loadedValue1031, align 4
  %328 = bitcast <4 x i8> %327 to i32
  %329 = bitcast i32 %328 to <4 x i8>
  %330 = extractelement <4 x i8> %329, i32 0
  %331 = extractelement <4 x i8> %329, i32 1
  %332 = extractelement <4 x i8> %329, i32 2
  %333 = extractelement <4 x i8> %329, i32 3
  %334 = zext i8 %330 to i64
  %335 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %334
  %336 = load i8 addrspace(1)* %335, align 1
  %337 = zext i8 %331 to i64
  %338 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %337
  %339 = load i8 addrspace(1)* %338, align 1
  %340 = zext i8 %332 to i64
  %341 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %340
  %342 = load i8 addrspace(1)* %341, align 1
  %343 = zext i8 %333 to i64
  %344 = getelementptr inbounds i8 addrspace(1)* %SBox, i64 %343
  %345 = load i8 addrspace(1)* %344, align 1
  %346 = insertelement <4 x i8> undef, i8 %336, i32 0
  %347 = insertelement <4 x i8> %346, i8 %339, i32 1
  %348 = insertelement <4 x i8> %347, i8 %342, i32 2
  %349 = insertelement <4 x i8> %348, i8 %345, i32 3
  %350 = bitcast <4 x i8> %349 to i32
  %351 = bitcast i32 %350 to <4 x i8>
  %"&(pSB[currWI].offset)1520" = add nuw i64 %CurrSBIndex..2, 1284
  %"&pSB[currWI].offset1521" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1520"
  %CastToValueType1522 = bitcast i8* %"&pSB[currWI].offset1521" to <4 x i8>*
  store <4 x i8> %351, <4 x i8>* %CastToValueType1522, align 4
  %"&(pSB[currWI].offset)1023" = add nuw i64 %CurrSBIndex..2, 920
  %"&pSB[currWI].offset1024" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1023"
  %CastToValueType1025 = bitcast i8* %"&pSB[currWI].offset1024" to <4 x i8> addrspace(3)**
  %loadedValue1026 = load <4 x i8> addrspace(3)** %CastToValueType1025, align 8
  store <4 x i8> %351, <4 x i8> addrspace(3)* %loadedValue1026, align 4
  %"&(pSB[currWI].offset)1479" = add nuw i64 %CurrSBIndex..2, 1140
  %"&pSB[currWI].offset1480" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1479"
  %CastToValueType1481 = bitcast i8* %"&pSB[currWI].offset1480" to i32*
  %loadedValue1482 = load i32* %CastToValueType1481, align 4
  %exitcond82 = icmp eq i32 %loadedValue1482, %tmp81
  br i1 %exitcond82, label %"Barrier BB985", label %bb.nph65

bb.nph65:                                         ; preds = %shiftRowsInv.exit
  %"&(pSB[currWI].offset)1474" = add nuw i64 %CurrSBIndex..2, 1140
  %"&pSB[currWI].offset1475" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1474"
  %CastToValueType1476 = bitcast i8* %"&pSB[currWI].offset1475" to i32*
  %loadedValue1477 = load i32* %CastToValueType1476, align 4
  %tmp83 = mul i32 %loadedValue1477, -4
  %"&(pSB[currWI].offset)1460" = add nuw i64 %CurrSBIndex..2, 1136
  %"&pSB[currWI].offset1461" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1460"
  %CastToValueType1462 = bitcast i8* %"&pSB[currWI].offset1461" to i32*
  %loadedValue1463 = load i32* %CastToValueType1462, align 4
  %tmp88 = add i32 %loadedValue1463, %tmp83
  %"&(pSB[currWI].offset)1544" = add nuw i64 %CurrSBIndex..2, 1288
  %"&pSB[currWI].offset1545" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1544"
  %CastToValueType1546 = bitcast i8* %"&pSB[currWI].offset1545" to i32*
  store i32 %tmp88, i32* %CastToValueType1546, align 4
  %check.WI.iter = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter, label %thenBB, label %SyncBB2210

thenBB:                                           ; preds = %bb.nph65
  %"CurrWI++" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride" = add nuw i64 %CurrSBIndex..2, 1712
  %cond = icmp eq i32 %currBarrier.1, 8
  br i1 %cond, label %SyncBB2211, label %SyncBB

SyncBB2210:                                       ; preds = %bb.nph65, %thenBB2214
  %CurrSBIndex..3 = phi i64 [ %"loadedCurrSB+Stride2220", %thenBB2214 ], [ 0, %bb.nph65 ]
  %CurrWI..3 = phi i64 [ %"CurrWI++2218", %thenBB2214 ], [ 0, %bb.nph65 ]
  %"&(pSB[currWI].offset)1033" = add nuw i64 %CurrSBIndex..3, 920
  %"&pSB[currWI].offset1034" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1033"
  %CastToValueType1035 = bitcast i8* %"&pSB[currWI].offset1034" to <4 x i8> addrspace(3)**
  %loadedValue1036 = load <4 x i8> addrspace(3)** %CastToValueType1035, align 8
  %352 = load <4 x i8> addrspace(3)* %loadedValue1036, align 4
  %scalar25 = extractelement <4 x i8> %352, i32 0
  %scalar26 = extractelement <4 x i8> %352, i32 1
  %scalar27 = extractelement <4 x i8> %352, i32 2
  %scalar28 = extractelement <4 x i8> %352, i32 3
  %"&(pSB[currWI].offset)1548" = add nuw i64 %CurrSBIndex..3, 1288
  %"&pSB[currWI].offset1549" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1548"
  %CastToValueType1550 = bitcast i8* %"&pSB[currWI].offset1549" to i32*
  %loadedValue1551 = load i32* %CastToValueType1550, align 4
  %353 = zext i32 %loadedValue1551 to i64
  %354 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %353
  %355 = load <4 x i8> addrspace(1)* %354, align 4
  %scalar29 = extractelement <4 x i8> %355, i32 0
  %scalar30 = extractelement <4 x i8> %355, i32 1
  %scalar31 = extractelement <4 x i8> %355, i32 2
  %scalar32 = extractelement <4 x i8> %355, i32 3
  %356 = xor i8 %scalar25, %scalar29
  %357 = xor i8 %scalar26, %scalar30
  %358 = xor i8 %scalar27, %scalar31
  %359 = xor i8 %scalar28, %scalar32
  %temp.vect120 = insertelement <4 x i8> undef, i8 %356, i32 0
  %temp.vect121 = insertelement <4 x i8> %temp.vect120, i8 %357, i32 1
  %temp.vect122 = insertelement <4 x i8> %temp.vect121, i8 %358, i32 2
  %temp.vect123 = insertelement <4 x i8> %temp.vect122, i8 %359, i32 3
  %"&(pSB[currWI].offset)1058" = add nuw i64 %CurrSBIndex..3, 992
  %"&pSB[currWI].offset1059" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1058"
  %CastToValueType1060 = bitcast i8* %"&pSB[currWI].offset1059" to <4 x i8> addrspace(3)**
  %loadedValue1061 = load <4 x i8> addrspace(3)** %CastToValueType1060, align 8
  store <4 x i8> %temp.vect123, <4 x i8> addrspace(3)* %loadedValue1061, align 4
  %check.WI.iter2217 = icmp ult i64 %CurrWI..3, %iterCount
  br i1 %check.WI.iter2217, label %thenBB2214, label %SyncBB2211

thenBB2214:                                       ; preds = %SyncBB2210
  %"CurrWI++2218" = add nuw i64 %CurrWI..3, 1
  %"loadedCurrSB+Stride2220" = add nuw i64 %CurrSBIndex..3, 1712
  br label %SyncBB2210

SyncBB2211:                                       ; preds = %SyncBB2210, %thenBB2221, %thenBB
  %CurrSBIndex..1 = phi i64 [ %"loadedCurrSB+Stride2227", %thenBB2221 ], [ %"loadedCurrSB+Stride", %thenBB ], [ 0, %SyncBB2210 ]
  %currBarrier.0 = phi i32 [ %currBarrier.1, %thenBB2221 ], [ %currBarrier.1, %thenBB ], [ 8, %SyncBB2210 ]
  %CurrWI..1 = phi i64 [ %"CurrWI++2225", %thenBB2221 ], [ %"CurrWI++", %thenBB ], [ 0, %SyncBB2210 ]
  %"&(pSB[currWI].offset)1082" = add nuw i64 %CurrSBIndex..1, 1000
  %"&pSB[currWI].offset1083" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1082"
  %CastToValueType1084 = bitcast i8* %"&pSB[currWI].offset1083" to <4 x i8>**
  %loadedValue1085 = load <4 x i8>** %CastToValueType1084, align 8
  %360 = load <4 x i8>* %loadedValue1085, align 4
  %"&(pSB[currWI].offset)1106" = add nuw i64 %CurrSBIndex..1, 1008
  %"&pSB[currWI].offset1107" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1106"
  %CastToValueType1108 = bitcast i8* %"&pSB[currWI].offset1107" to <4 x i8>**
  %loadedValue1109 = load <4 x i8>** %CastToValueType1108, align 8
  %361 = load <4 x i8>* %loadedValue1109, align 4
  %"&(pSB[currWI].offset)1130" = add nuw i64 %CurrSBIndex..1, 1016
  %"&pSB[currWI].offset1131" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1130"
  %CastToValueType1132 = bitcast i8* %"&pSB[currWI].offset1131" to <4 x i8>**
  %loadedValue1133 = load <4 x i8>** %CastToValueType1132, align 8
  %362 = load <4 x i8>* %loadedValue1133, align 4
  %"&(pSB[currWI].offset)1154" = add nuw i64 %CurrSBIndex..1, 1024
  %"&pSB[currWI].offset1155" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1154"
  %CastToValueType1156 = bitcast i8* %"&pSB[currWI].offset1155" to <4 x i8>**
  %loadedValue1157 = load <4 x i8>** %CastToValueType1156, align 8
  %363 = load <4 x i8>* %loadedValue1157, align 4
  %"&(pSB[currWI].offset)1178" = add nuw i64 %CurrSBIndex..1, 1032
  %"&pSB[currWI].offset1179" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1178"
  %CastToValueType1180 = bitcast i8* %"&pSB[currWI].offset1179" to <4 x i8>**
  %loadedValue1181 = load <4 x i8>** %CastToValueType1180, align 8
  %364 = load <4 x i8>* %loadedValue1181, align 4
  %"&(pSB[currWI].offset)1202" = add nuw i64 %CurrSBIndex..1, 1040
  %"&pSB[currWI].offset1203" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1202"
  %CastToValueType1204 = bitcast i8* %"&pSB[currWI].offset1203" to <4 x i8>**
  %loadedValue1205 = load <4 x i8>** %CastToValueType1204, align 8
  %365 = load <4 x i8>* %loadedValue1205, align 4
  %"&(pSB[currWI].offset)1226" = add nuw i64 %CurrSBIndex..1, 1048
  %"&pSB[currWI].offset1227" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1226"
  %CastToValueType1228 = bitcast i8* %"&pSB[currWI].offset1227" to <4 x i8>**
  %loadedValue1229 = load <4 x i8>** %CastToValueType1228, align 8
  %366 = load <4 x i8>* %loadedValue1229, align 4
  %"&(pSB[currWI].offset)1250" = add nuw i64 %CurrSBIndex..1, 1056
  %"&pSB[currWI].offset1251" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1250"
  %CastToValueType1252 = bitcast i8* %"&pSB[currWI].offset1251" to <4 x i8>**
  %loadedValue1253 = load <4 x i8>** %CastToValueType1252, align 8
  %367 = load <4 x i8>* %loadedValue1253, align 4
  %"&(pSB[currWI].offset)1274" = add nuw i64 %CurrSBIndex..1, 1064
  %"&pSB[currWI].offset1275" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1274"
  %CastToValueType1276 = bitcast i8* %"&pSB[currWI].offset1275" to <4 x i8>**
  %loadedValue1277 = load <4 x i8>** %CastToValueType1276, align 8
  %368 = load <4 x i8>* %loadedValue1277, align 4
  %"&(pSB[currWI].offset)1298" = add nuw i64 %CurrSBIndex..1, 1072
  %"&pSB[currWI].offset1299" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1298"
  %CastToValueType1300 = bitcast i8* %"&pSB[currWI].offset1299" to <4 x i8>**
  %loadedValue1301 = load <4 x i8>** %CastToValueType1300, align 8
  %369 = load <4 x i8>* %loadedValue1301, align 4
  %"&(pSB[currWI].offset)1322" = add nuw i64 %CurrSBIndex..1, 1080
  %"&pSB[currWI].offset1323" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1322"
  %CastToValueType1324 = bitcast i8* %"&pSB[currWI].offset1323" to <4 x i8>**
  %loadedValue1325 = load <4 x i8>** %CastToValueType1324, align 8
  %370 = load <4 x i8>* %loadedValue1325, align 4
  %"&(pSB[currWI].offset)1346" = add nuw i64 %CurrSBIndex..1, 1088
  %"&pSB[currWI].offset1347" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1346"
  %CastToValueType1348 = bitcast i8* %"&pSB[currWI].offset1347" to <4 x i8>**
  %loadedValue1349 = load <4 x i8>** %CastToValueType1348, align 8
  %371 = load <4 x i8>* %loadedValue1349, align 4
  %"&(pSB[currWI].offset)1370" = add nuw i64 %CurrSBIndex..1, 1096
  %"&pSB[currWI].offset1371" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1370"
  %CastToValueType1372 = bitcast i8* %"&pSB[currWI].offset1371" to <4 x i8>**
  %loadedValue1373 = load <4 x i8>** %CastToValueType1372, align 8
  %372 = load <4 x i8>* %loadedValue1373, align 4
  %"&(pSB[currWI].offset)1394" = add nuw i64 %CurrSBIndex..1, 1104
  %"&pSB[currWI].offset1395" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1394"
  %CastToValueType1396 = bitcast i8* %"&pSB[currWI].offset1395" to <4 x i8>**
  %loadedValue1397 = load <4 x i8>** %CastToValueType1396, align 8
  %373 = load <4 x i8>* %loadedValue1397, align 4
  %"&(pSB[currWI].offset)1418" = add nuw i64 %CurrSBIndex..1, 1112
  %"&pSB[currWI].offset1419" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1418"
  %CastToValueType1420 = bitcast i8* %"&pSB[currWI].offset1419" to <4 x i8>**
  %loadedValue1421 = load <4 x i8>** %CastToValueType1420, align 8
  %374 = load <4 x i8>* %loadedValue1421, align 4
  %"&(pSB[currWI].offset)1442" = add nuw i64 %CurrSBIndex..1, 1120
  %"&pSB[currWI].offset1443" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1442"
  %CastToValueType1444 = bitcast i8* %"&pSB[currWI].offset1443" to <4 x i8>**
  %loadedValue1445 = load <4 x i8>** %CastToValueType1444, align 8
  %375 = load <4 x i8>* %loadedValue1445, align 4
  %376 = extractelement <4 x i8> %360, i32 0
  %377 = extractelement <4 x i8> %361, i32 0
  %378 = extractelement <4 x i8> %362, i32 0
  %379 = extractelement <4 x i8> %363, i32 0
  %380 = extractelement <4 x i8> %364, i32 0
  %381 = extractelement <4 x i8> %365, i32 0
  %382 = extractelement <4 x i8> %366, i32 0
  %383 = extractelement <4 x i8> %367, i32 0
  %384 = extractelement <4 x i8> %368, i32 0
  %385 = extractelement <4 x i8> %369, i32 0
  %386 = extractelement <4 x i8> %370, i32 0
  %387 = extractelement <4 x i8> %371, i32 0
  %388 = extractelement <4 x i8> %372, i32 0
  %389 = extractelement <4 x i8> %373, i32 0
  %390 = extractelement <4 x i8> %374, i32 0
  %391 = extractelement <4 x i8> %375, i32 0
  %temp.vect468 = insertelement <16 x i8> undef, i8 %376, i32 0
  %temp.vect469 = insertelement <16 x i8> %temp.vect468, i8 %377, i32 1
  %temp.vect470 = insertelement <16 x i8> %temp.vect469, i8 %378, i32 2
  %temp.vect471 = insertelement <16 x i8> %temp.vect470, i8 %379, i32 3
  %temp.vect472 = insertelement <16 x i8> %temp.vect471, i8 %380, i32 4
  %temp.vect473 = insertelement <16 x i8> %temp.vect472, i8 %381, i32 5
  %temp.vect474 = insertelement <16 x i8> %temp.vect473, i8 %382, i32 6
  %temp.vect475 = insertelement <16 x i8> %temp.vect474, i8 %383, i32 7
  %temp.vect476 = insertelement <16 x i8> %temp.vect475, i8 %384, i32 8
  %temp.vect477 = insertelement <16 x i8> %temp.vect476, i8 %385, i32 9
  %temp.vect478 = insertelement <16 x i8> %temp.vect477, i8 %386, i32 10
  %temp.vect479 = insertelement <16 x i8> %temp.vect478, i8 %387, i32 11
  %temp.vect480 = insertelement <16 x i8> %temp.vect479, i8 %388, i32 12
  %temp.vect481 = insertelement <16 x i8> %temp.vect480, i8 %389, i32 13
  %temp.vect482 = insertelement <16 x i8> %temp.vect481, i8 %390, i32 14
  %temp.vect483 = insertelement <16 x i8> %temp.vect482, i8 %391, i32 15
  %392 = load <4 x i8> addrspace(3)* %block1, align 4
  %scalar37 = extractelement <4 x i8> %392, i32 0
  %temp486 = insertelement <16 x i8> undef, i8 %scalar37, i32 0
  %vector487 = shufflevector <16 x i8> %temp486, <16 x i8> undef, <16 x i32> zeroinitializer
  %393 = zext i8 %scalar37 to i32
  %394 = shl i32 %393, 1
  %395 = and i32 %393, 128
  %396 = xor i32 %394, 27
  %397 = icmp eq i32 %395, 0
  %a.1.in = select i1 %397, i32 %394, i32 %396
  %398 = shl i32 %a.1.in, 1
  %399 = and i32 %a.1.in, 128
  %400 = xor i32 %398, 27
  %401 = icmp eq i32 %399, 0
  %a.1.in.1 = select i1 %401, i32 %398, i32 %400
  %402 = shl i32 %a.1.in.1, 1
  %403 = and i32 %a.1.in.1, 128
  %404 = xor i32 %402, 27
  %405 = icmp eq i32 %403, 0
  %a.1.in.2 = select i1 %405, i32 %402, i32 %404
  %406 = shl i32 %a.1.in.2, 1
  %407 = and i32 %a.1.in.2, 128
  %408 = xor i32 %406, 27
  %409 = icmp eq i32 %407, 0
  %a.1.in.3 = select i1 %409, i32 %406, i32 %408
  %410 = shl i32 %a.1.in.3, 1
  %411 = and i32 %a.1.in.3, 128
  %412 = xor i32 %410, 27
  %413 = icmp eq i32 %411, 0
  %a.1.in.4 = select i1 %413, i32 %410, i32 %412
  %414 = shl i32 %a.1.in.4, 1
  %415 = and i32 %a.1.in.4, 128
  %416 = xor i32 %414, 27
  %417 = icmp eq i32 %415, 0
  %a.1.in.5 = select i1 %417, i32 %414, i32 %416
  %418 = shl i32 %a.1.in.5, 1
  %419 = lshr <16 x i8> %temp.vect483, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %420 = zext <16 x i8> %419 to <16 x i32>
  %421 = zext <16 x i8> %temp.vect483 to <16 x i32>
  %422 = lshr <16 x i8> %temp.vect483, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %423 = lshr <16 x i8> %temp.vect483, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %424 = and <16 x i32> %420, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %425 = and <16 x i32> %421, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %426 = zext <16 x i8> %422 to <16 x i32>
  %427 = zext <16 x i8> %423 to <16 x i32>
  %428 = icmp eq <16 x i32> %424, zeroinitializer
  %a.1 = trunc i32 %a.1.in to i8
  %temp484 = insertelement <16 x i8> undef, i8 %a.1, i32 0
  %vector485 = shufflevector <16 x i8> %temp484, <16 x i8> undef, <16 x i32> zeroinitializer
  %429 = icmp eq <16 x i32> %425, zeroinitializer
  %430 = and <16 x i32> %426, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %431 = lshr <16 x i8> %temp.vect483, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %432 = lshr <16 x i8> %temp.vect483, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %433 = and <16 x i32> %427, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %434 = select <16 x i1> %428, <16 x i8> zeroinitializer, <16 x i8> %vector485
  %435 = select <16 x i1> %429, <16 x i8> zeroinitializer, <16 x i8> %vector487
  %a.1.1 = trunc i32 %a.1.in.1 to i8
  %temp489 = insertelement <16 x i8> undef, i8 %a.1.1, i32 0
  %vector490 = shufflevector <16 x i8> %temp489, <16 x i8> undef, <16 x i32> zeroinitializer
  %436 = icmp eq <16 x i32> %430, zeroinitializer
  %437 = zext <16 x i8> %431 to <16 x i32>
  %438 = zext <16 x i8> %432 to <16 x i32>
  %439 = icmp eq <16 x i32> %433, zeroinitializer
  %a.1.2 = trunc i32 %a.1.in.2 to i8
  %temp491 = insertelement <16 x i8> undef, i8 %a.1.2, i32 0
  %vector492 = shufflevector <16 x i8> %temp491, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..1488 = xor <16 x i8> %434, %435
  %440 = select <16 x i1> %436, <16 x i8> zeroinitializer, <16 x i8> %vector490
  %441 = and <16 x i32> %437, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %442 = lshr <16 x i8> %temp.vect483, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %443 = and i32 %a.1.in.5, 128
  %444 = and <16 x i32> %438, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %445 = select <16 x i1> %439, <16 x i8> zeroinitializer, <16 x i8> %vector492
  %p.1..2493 = xor <16 x i8> %440, %p.1..1488
  %a.1.3 = trunc i32 %a.1.in.3 to i8
  %temp495 = insertelement <16 x i8> undef, i8 %a.1.3, i32 0
  %vector496 = shufflevector <16 x i8> %temp495, <16 x i8> undef, <16 x i32> zeroinitializer
  %446 = icmp eq <16 x i32> %441, zeroinitializer
  %447 = zext <16 x i8> %442 to <16 x i32>
  %448 = icmp eq i32 %443, 0
  %449 = xor i32 %418, 27
  %450 = icmp eq <16 x i32> %444, zeroinitializer
  %a.1.4 = trunc i32 %a.1.in.4 to i8
  %temp497 = insertelement <16 x i8> undef, i8 %a.1.4, i32 0
  %vector498 = shufflevector <16 x i8> %temp497, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..3494 = xor <16 x i8> %445, %p.1..2493
  %451 = select <16 x i1> %446, <16 x i8> zeroinitializer, <16 x i8> %vector496
  %452 = and <16 x i32> %447, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.1.in.6 = select i1 %448, i32 %418, i32 %449
  %453 = select <16 x i1> %450, <16 x i8> zeroinitializer, <16 x i8> %vector498
  %p.1..4499 = xor <16 x i8> %451, %p.1..3494
  %a.1.5 = trunc i32 %a.1.in.5 to i8
  %temp501 = insertelement <16 x i8> undef, i8 %a.1.5, i32 0
  %vector502 = shufflevector <16 x i8> %temp501, <16 x i8> undef, <16 x i32> zeroinitializer
  %454 = icmp eq <16 x i32> %452, zeroinitializer
  %455 = icmp sgt <16 x i8> %temp.vect483, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.1.6 = trunc i32 %a.1.in.6 to i8
  %temp503 = insertelement <16 x i8> undef, i8 %a.1.6, i32 0
  %vector504 = shufflevector <16 x i8> %temp503, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..5500 = xor <16 x i8> %453, %p.1..4499
  %456 = select <16 x i1> %454, <16 x i8> zeroinitializer, <16 x i8> %vector502
  %457 = select <16 x i1> %455, <16 x i8> zeroinitializer, <16 x i8> %vector504
  %p.1..6505 = xor <16 x i8> %456, %p.1..5500
  %p.1..7506 = xor <16 x i8> %457, %p.1..6505
  %"&(pSB[currWI].offset)1553" = add nuw i64 %CurrSBIndex..1, 1296
  %"&pSB[currWI].offset1554" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1553"
  %CastToValueType1555 = bitcast i8* %"&pSB[currWI].offset1554" to <16 x i8>*
  store <16 x i8> %p.1..7506, <16 x i8>* %CastToValueType1555, align 16
  %"&(pSB[currWI].offset)1077" = add nuw i64 %CurrSBIndex..1, 1000
  %"&pSB[currWI].offset1078" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1077"
  %CastToValueType1079 = bitcast i8* %"&pSB[currWI].offset1078" to <4 x i8>**
  %loadedValue1080 = load <4 x i8>** %CastToValueType1079, align 8
  %458 = load <4 x i8>* %loadedValue1080, align 4
  %"&(pSB[currWI].offset)1101" = add nuw i64 %CurrSBIndex..1, 1008
  %"&pSB[currWI].offset1102" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1101"
  %CastToValueType1103 = bitcast i8* %"&pSB[currWI].offset1102" to <4 x i8>**
  %loadedValue1104 = load <4 x i8>** %CastToValueType1103, align 8
  %459 = load <4 x i8>* %loadedValue1104, align 4
  %"&(pSB[currWI].offset)1125" = add nuw i64 %CurrSBIndex..1, 1016
  %"&pSB[currWI].offset1126" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1125"
  %CastToValueType1127 = bitcast i8* %"&pSB[currWI].offset1126" to <4 x i8>**
  %loadedValue1128 = load <4 x i8>** %CastToValueType1127, align 8
  %460 = load <4 x i8>* %loadedValue1128, align 4
  %"&(pSB[currWI].offset)1149" = add nuw i64 %CurrSBIndex..1, 1024
  %"&pSB[currWI].offset1150" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1149"
  %CastToValueType1151 = bitcast i8* %"&pSB[currWI].offset1150" to <4 x i8>**
  %loadedValue1152 = load <4 x i8>** %CastToValueType1151, align 8
  %461 = load <4 x i8>* %loadedValue1152, align 4
  %"&(pSB[currWI].offset)1173" = add nuw i64 %CurrSBIndex..1, 1032
  %"&pSB[currWI].offset1174" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1173"
  %CastToValueType1175 = bitcast i8* %"&pSB[currWI].offset1174" to <4 x i8>**
  %loadedValue1176 = load <4 x i8>** %CastToValueType1175, align 8
  %462 = load <4 x i8>* %loadedValue1176, align 4
  %"&(pSB[currWI].offset)1197" = add nuw i64 %CurrSBIndex..1, 1040
  %"&pSB[currWI].offset1198" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1197"
  %CastToValueType1199 = bitcast i8* %"&pSB[currWI].offset1198" to <4 x i8>**
  %loadedValue1200 = load <4 x i8>** %CastToValueType1199, align 8
  %463 = load <4 x i8>* %loadedValue1200, align 4
  %"&(pSB[currWI].offset)1221" = add nuw i64 %CurrSBIndex..1, 1048
  %"&pSB[currWI].offset1222" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1221"
  %CastToValueType1223 = bitcast i8* %"&pSB[currWI].offset1222" to <4 x i8>**
  %loadedValue1224 = load <4 x i8>** %CastToValueType1223, align 8
  %464 = load <4 x i8>* %loadedValue1224, align 4
  %"&(pSB[currWI].offset)1245" = add nuw i64 %CurrSBIndex..1, 1056
  %"&pSB[currWI].offset1246" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1245"
  %CastToValueType1247 = bitcast i8* %"&pSB[currWI].offset1246" to <4 x i8>**
  %loadedValue1248 = load <4 x i8>** %CastToValueType1247, align 8
  %465 = load <4 x i8>* %loadedValue1248, align 4
  %"&(pSB[currWI].offset)1269" = add nuw i64 %CurrSBIndex..1, 1064
  %"&pSB[currWI].offset1270" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1269"
  %CastToValueType1271 = bitcast i8* %"&pSB[currWI].offset1270" to <4 x i8>**
  %loadedValue1272 = load <4 x i8>** %CastToValueType1271, align 8
  %466 = load <4 x i8>* %loadedValue1272, align 4
  %"&(pSB[currWI].offset)1293" = add nuw i64 %CurrSBIndex..1, 1072
  %"&pSB[currWI].offset1294" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1293"
  %CastToValueType1295 = bitcast i8* %"&pSB[currWI].offset1294" to <4 x i8>**
  %loadedValue1296 = load <4 x i8>** %CastToValueType1295, align 8
  %467 = load <4 x i8>* %loadedValue1296, align 4
  %"&(pSB[currWI].offset)1317" = add nuw i64 %CurrSBIndex..1, 1080
  %"&pSB[currWI].offset1318" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1317"
  %CastToValueType1319 = bitcast i8* %"&pSB[currWI].offset1318" to <4 x i8>**
  %loadedValue1320 = load <4 x i8>** %CastToValueType1319, align 8
  %468 = load <4 x i8>* %loadedValue1320, align 4
  %"&(pSB[currWI].offset)1341" = add nuw i64 %CurrSBIndex..1, 1088
  %"&pSB[currWI].offset1342" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1341"
  %CastToValueType1343 = bitcast i8* %"&pSB[currWI].offset1342" to <4 x i8>**
  %loadedValue1344 = load <4 x i8>** %CastToValueType1343, align 8
  %469 = load <4 x i8>* %loadedValue1344, align 4
  %"&(pSB[currWI].offset)1365" = add nuw i64 %CurrSBIndex..1, 1096
  %"&pSB[currWI].offset1366" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1365"
  %CastToValueType1367 = bitcast i8* %"&pSB[currWI].offset1366" to <4 x i8>**
  %loadedValue1368 = load <4 x i8>** %CastToValueType1367, align 8
  %470 = load <4 x i8>* %loadedValue1368, align 4
  %"&(pSB[currWI].offset)1389" = add nuw i64 %CurrSBIndex..1, 1104
  %"&pSB[currWI].offset1390" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1389"
  %CastToValueType1391 = bitcast i8* %"&pSB[currWI].offset1390" to <4 x i8>**
  %loadedValue1392 = load <4 x i8>** %CastToValueType1391, align 8
  %471 = load <4 x i8>* %loadedValue1392, align 4
  %"&(pSB[currWI].offset)1413" = add nuw i64 %CurrSBIndex..1, 1112
  %"&pSB[currWI].offset1414" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1413"
  %CastToValueType1415 = bitcast i8* %"&pSB[currWI].offset1414" to <4 x i8>**
  %loadedValue1416 = load <4 x i8>** %CastToValueType1415, align 8
  %472 = load <4 x i8>* %loadedValue1416, align 4
  %"&(pSB[currWI].offset)1437" = add nuw i64 %CurrSBIndex..1, 1120
  %"&pSB[currWI].offset1438" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1437"
  %CastToValueType1439 = bitcast i8* %"&pSB[currWI].offset1438" to <4 x i8>**
  %loadedValue1440 = load <4 x i8>** %CastToValueType1439, align 8
  %473 = load <4 x i8>* %loadedValue1440, align 4
  %474 = extractelement <4 x i8> %458, i32 0
  %475 = extractelement <4 x i8> %459, i32 0
  %476 = extractelement <4 x i8> %460, i32 0
  %477 = extractelement <4 x i8> %461, i32 0
  %478 = extractelement <4 x i8> %462, i32 0
  %479 = extractelement <4 x i8> %463, i32 0
  %480 = extractelement <4 x i8> %464, i32 0
  %481 = extractelement <4 x i8> %465, i32 0
  %482 = extractelement <4 x i8> %466, i32 0
  %483 = extractelement <4 x i8> %467, i32 0
  %484 = extractelement <4 x i8> %468, i32 0
  %485 = extractelement <4 x i8> %469, i32 0
  %486 = extractelement <4 x i8> %470, i32 0
  %487 = extractelement <4 x i8> %471, i32 0
  %488 = extractelement <4 x i8> %472, i32 0
  %489 = extractelement <4 x i8> %473, i32 0
  %temp.vect507 = insertelement <16 x i8> undef, i8 %474, i32 0
  %temp.vect508 = insertelement <16 x i8> %temp.vect507, i8 %475, i32 1
  %temp.vect509 = insertelement <16 x i8> %temp.vect508, i8 %476, i32 2
  %temp.vect510 = insertelement <16 x i8> %temp.vect509, i8 %477, i32 3
  %temp.vect511 = insertelement <16 x i8> %temp.vect510, i8 %478, i32 4
  %temp.vect512 = insertelement <16 x i8> %temp.vect511, i8 %479, i32 5
  %temp.vect513 = insertelement <16 x i8> %temp.vect512, i8 %480, i32 6
  %temp.vect514 = insertelement <16 x i8> %temp.vect513, i8 %481, i32 7
  %temp.vect515 = insertelement <16 x i8> %temp.vect514, i8 %482, i32 8
  %temp.vect516 = insertelement <16 x i8> %temp.vect515, i8 %483, i32 9
  %temp.vect517 = insertelement <16 x i8> %temp.vect516, i8 %484, i32 10
  %temp.vect518 = insertelement <16 x i8> %temp.vect517, i8 %485, i32 11
  %temp.vect519 = insertelement <16 x i8> %temp.vect518, i8 %486, i32 12
  %temp.vect520 = insertelement <16 x i8> %temp.vect519, i8 %487, i32 13
  %temp.vect521 = insertelement <16 x i8> %temp.vect520, i8 %488, i32 14
  %temp.vect522 = insertelement <16 x i8> %temp.vect521, i8 %489, i32 15
  %490 = load <4 x i8> addrspace(3)* %block1, align 4
  %scalar46 = extractelement <4 x i8> %490, i32 1
  %temp525 = insertelement <16 x i8> undef, i8 %scalar46, i32 0
  %vector526 = shufflevector <16 x i8> %temp525, <16 x i8> undef, <16 x i32> zeroinitializer
  %491 = zext i8 %scalar46 to i32
  %492 = shl i32 %491, 1
  %493 = and i32 %491, 128
  %494 = xor i32 %492, 27
  %495 = icmp eq i32 %493, 0
  %a.3.in = select i1 %495, i32 %492, i32 %494
  %496 = shl i32 %a.3.in, 1
  %497 = and i32 %a.3.in, 128
  %498 = xor i32 %496, 27
  %499 = icmp eq i32 %497, 0
  %a.3.in.1 = select i1 %499, i32 %496, i32 %498
  %500 = shl i32 %a.3.in.1, 1
  %501 = and i32 %a.3.in.1, 128
  %502 = xor i32 %500, 27
  %503 = icmp eq i32 %501, 0
  %a.3.in.2 = select i1 %503, i32 %500, i32 %502
  %504 = shl i32 %a.3.in.2, 1
  %505 = and i32 %a.3.in.2, 128
  %506 = xor i32 %504, 27
  %507 = icmp eq i32 %505, 0
  %a.3.in.3 = select i1 %507, i32 %504, i32 %506
  %508 = shl i32 %a.3.in.3, 1
  %509 = and i32 %a.3.in.3, 128
  %510 = xor i32 %508, 27
  %511 = icmp eq i32 %509, 0
  %a.3.in.4 = select i1 %511, i32 %508, i32 %510
  %512 = shl i32 %a.3.in.4, 1
  %513 = and i32 %a.3.in.4, 128
  %514 = xor i32 %512, 27
  %515 = icmp eq i32 %513, 0
  %a.3.in.5 = select i1 %515, i32 %512, i32 %514
  %516 = shl i32 %a.3.in.5, 1
  %517 = lshr <16 x i8> %temp.vect522, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %518 = zext <16 x i8> %517 to <16 x i32>
  %519 = zext <16 x i8> %temp.vect522 to <16 x i32>
  %520 = lshr <16 x i8> %temp.vect522, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %521 = lshr <16 x i8> %temp.vect522, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %522 = and <16 x i32> %518, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %523 = and <16 x i32> %519, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %524 = zext <16 x i8> %520 to <16 x i32>
  %525 = zext <16 x i8> %521 to <16 x i32>
  %526 = icmp eq <16 x i32> %522, zeroinitializer
  %a.3 = trunc i32 %a.3.in to i8
  %temp523 = insertelement <16 x i8> undef, i8 %a.3, i32 0
  %vector524 = shufflevector <16 x i8> %temp523, <16 x i8> undef, <16 x i32> zeroinitializer
  %527 = icmp eq <16 x i32> %523, zeroinitializer
  %528 = and <16 x i32> %524, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %529 = lshr <16 x i8> %temp.vect522, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %530 = lshr <16 x i8> %temp.vect522, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %531 = and <16 x i32> %525, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %532 = select <16 x i1> %526, <16 x i8> zeroinitializer, <16 x i8> %vector524
  %533 = select <16 x i1> %527, <16 x i8> zeroinitializer, <16 x i8> %vector526
  %a.3.1 = trunc i32 %a.3.in.1 to i8
  %temp528 = insertelement <16 x i8> undef, i8 %a.3.1, i32 0
  %vector529 = shufflevector <16 x i8> %temp528, <16 x i8> undef, <16 x i32> zeroinitializer
  %534 = icmp eq <16 x i32> %528, zeroinitializer
  %535 = zext <16 x i8> %529 to <16 x i32>
  %536 = zext <16 x i8> %530 to <16 x i32>
  %537 = icmp eq <16 x i32> %531, zeroinitializer
  %a.3.2 = trunc i32 %a.3.in.2 to i8
  %temp530 = insertelement <16 x i8> undef, i8 %a.3.2, i32 0
  %vector531 = shufflevector <16 x i8> %temp530, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..1527 = xor <16 x i8> %532, %533
  %538 = select <16 x i1> %534, <16 x i8> zeroinitializer, <16 x i8> %vector529
  %539 = and <16 x i32> %535, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %540 = lshr <16 x i8> %temp.vect522, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %541 = and i32 %a.3.in.5, 128
  %542 = and <16 x i32> %536, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %543 = select <16 x i1> %537, <16 x i8> zeroinitializer, <16 x i8> %vector531
  %p.3..2532 = xor <16 x i8> %538, %p.3..1527
  %a.3.3 = trunc i32 %a.3.in.3 to i8
  %temp534 = insertelement <16 x i8> undef, i8 %a.3.3, i32 0
  %vector535 = shufflevector <16 x i8> %temp534, <16 x i8> undef, <16 x i32> zeroinitializer
  %544 = icmp eq <16 x i32> %539, zeroinitializer
  %545 = zext <16 x i8> %540 to <16 x i32>
  %546 = icmp eq i32 %541, 0
  %547 = xor i32 %516, 27
  %548 = icmp eq <16 x i32> %542, zeroinitializer
  %a.3.4 = trunc i32 %a.3.in.4 to i8
  %temp536 = insertelement <16 x i8> undef, i8 %a.3.4, i32 0
  %vector537 = shufflevector <16 x i8> %temp536, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..3533 = xor <16 x i8> %543, %p.3..2532
  %549 = select <16 x i1> %544, <16 x i8> zeroinitializer, <16 x i8> %vector535
  %550 = and <16 x i32> %545, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.3.in.6 = select i1 %546, i32 %516, i32 %547
  %551 = select <16 x i1> %548, <16 x i8> zeroinitializer, <16 x i8> %vector537
  %p.3..4538 = xor <16 x i8> %549, %p.3..3533
  %a.3.5 = trunc i32 %a.3.in.5 to i8
  %temp540 = insertelement <16 x i8> undef, i8 %a.3.5, i32 0
  %vector541 = shufflevector <16 x i8> %temp540, <16 x i8> undef, <16 x i32> zeroinitializer
  %552 = icmp eq <16 x i32> %550, zeroinitializer
  %553 = icmp sgt <16 x i8> %temp.vect522, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.3.6 = trunc i32 %a.3.in.6 to i8
  %temp542 = insertelement <16 x i8> undef, i8 %a.3.6, i32 0
  %vector543 = shufflevector <16 x i8> %temp542, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..5539 = xor <16 x i8> %551, %p.3..4538
  %554 = select <16 x i1> %552, <16 x i8> zeroinitializer, <16 x i8> %vector541
  %555 = select <16 x i1> %553, <16 x i8> zeroinitializer, <16 x i8> %vector543
  %p.3..6544 = xor <16 x i8> %554, %p.3..5539
  %p.3..7545 = xor <16 x i8> %555, %p.3..6544
  %"&(pSB[currWI].offset)1557" = add nuw i64 %CurrSBIndex..1, 1312
  %"&pSB[currWI].offset1558" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1557"
  %CastToValueType1559 = bitcast i8* %"&pSB[currWI].offset1558" to <16 x i8>*
  store <16 x i8> %p.3..7545, <16 x i8>* %CastToValueType1559, align 16
  %"&(pSB[currWI].offset)1072" = add nuw i64 %CurrSBIndex..1, 1000
  %"&pSB[currWI].offset1073" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1072"
  %CastToValueType1074 = bitcast i8* %"&pSB[currWI].offset1073" to <4 x i8>**
  %loadedValue1075 = load <4 x i8>** %CastToValueType1074, align 8
  %556 = load <4 x i8>* %loadedValue1075, align 4
  %"&(pSB[currWI].offset)1096" = add nuw i64 %CurrSBIndex..1, 1008
  %"&pSB[currWI].offset1097" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1096"
  %CastToValueType1098 = bitcast i8* %"&pSB[currWI].offset1097" to <4 x i8>**
  %loadedValue1099 = load <4 x i8>** %CastToValueType1098, align 8
  %557 = load <4 x i8>* %loadedValue1099, align 4
  %"&(pSB[currWI].offset)1120" = add nuw i64 %CurrSBIndex..1, 1016
  %"&pSB[currWI].offset1121" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1120"
  %CastToValueType1122 = bitcast i8* %"&pSB[currWI].offset1121" to <4 x i8>**
  %loadedValue1123 = load <4 x i8>** %CastToValueType1122, align 8
  %558 = load <4 x i8>* %loadedValue1123, align 4
  %"&(pSB[currWI].offset)1144" = add nuw i64 %CurrSBIndex..1, 1024
  %"&pSB[currWI].offset1145" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1144"
  %CastToValueType1146 = bitcast i8* %"&pSB[currWI].offset1145" to <4 x i8>**
  %loadedValue1147 = load <4 x i8>** %CastToValueType1146, align 8
  %559 = load <4 x i8>* %loadedValue1147, align 4
  %"&(pSB[currWI].offset)1168" = add nuw i64 %CurrSBIndex..1, 1032
  %"&pSB[currWI].offset1169" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1168"
  %CastToValueType1170 = bitcast i8* %"&pSB[currWI].offset1169" to <4 x i8>**
  %loadedValue1171 = load <4 x i8>** %CastToValueType1170, align 8
  %560 = load <4 x i8>* %loadedValue1171, align 4
  %"&(pSB[currWI].offset)1192" = add nuw i64 %CurrSBIndex..1, 1040
  %"&pSB[currWI].offset1193" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1192"
  %CastToValueType1194 = bitcast i8* %"&pSB[currWI].offset1193" to <4 x i8>**
  %loadedValue1195 = load <4 x i8>** %CastToValueType1194, align 8
  %561 = load <4 x i8>* %loadedValue1195, align 4
  %"&(pSB[currWI].offset)1216" = add nuw i64 %CurrSBIndex..1, 1048
  %"&pSB[currWI].offset1217" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1216"
  %CastToValueType1218 = bitcast i8* %"&pSB[currWI].offset1217" to <4 x i8>**
  %loadedValue1219 = load <4 x i8>** %CastToValueType1218, align 8
  %562 = load <4 x i8>* %loadedValue1219, align 4
  %"&(pSB[currWI].offset)1240" = add nuw i64 %CurrSBIndex..1, 1056
  %"&pSB[currWI].offset1241" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1240"
  %CastToValueType1242 = bitcast i8* %"&pSB[currWI].offset1241" to <4 x i8>**
  %loadedValue1243 = load <4 x i8>** %CastToValueType1242, align 8
  %563 = load <4 x i8>* %loadedValue1243, align 4
  %"&(pSB[currWI].offset)1264" = add nuw i64 %CurrSBIndex..1, 1064
  %"&pSB[currWI].offset1265" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1264"
  %CastToValueType1266 = bitcast i8* %"&pSB[currWI].offset1265" to <4 x i8>**
  %loadedValue1267 = load <4 x i8>** %CastToValueType1266, align 8
  %564 = load <4 x i8>* %loadedValue1267, align 4
  %"&(pSB[currWI].offset)1288" = add nuw i64 %CurrSBIndex..1, 1072
  %"&pSB[currWI].offset1289" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1288"
  %CastToValueType1290 = bitcast i8* %"&pSB[currWI].offset1289" to <4 x i8>**
  %loadedValue1291 = load <4 x i8>** %CastToValueType1290, align 8
  %565 = load <4 x i8>* %loadedValue1291, align 4
  %"&(pSB[currWI].offset)1312" = add nuw i64 %CurrSBIndex..1, 1080
  %"&pSB[currWI].offset1313" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1312"
  %CastToValueType1314 = bitcast i8* %"&pSB[currWI].offset1313" to <4 x i8>**
  %loadedValue1315 = load <4 x i8>** %CastToValueType1314, align 8
  %566 = load <4 x i8>* %loadedValue1315, align 4
  %"&(pSB[currWI].offset)1336" = add nuw i64 %CurrSBIndex..1, 1088
  %"&pSB[currWI].offset1337" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1336"
  %CastToValueType1338 = bitcast i8* %"&pSB[currWI].offset1337" to <4 x i8>**
  %loadedValue1339 = load <4 x i8>** %CastToValueType1338, align 8
  %567 = load <4 x i8>* %loadedValue1339, align 4
  %"&(pSB[currWI].offset)1360" = add nuw i64 %CurrSBIndex..1, 1096
  %"&pSB[currWI].offset1361" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1360"
  %CastToValueType1362 = bitcast i8* %"&pSB[currWI].offset1361" to <4 x i8>**
  %loadedValue1363 = load <4 x i8>** %CastToValueType1362, align 8
  %568 = load <4 x i8>* %loadedValue1363, align 4
  %"&(pSB[currWI].offset)1384" = add nuw i64 %CurrSBIndex..1, 1104
  %"&pSB[currWI].offset1385" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1384"
  %CastToValueType1386 = bitcast i8* %"&pSB[currWI].offset1385" to <4 x i8>**
  %loadedValue1387 = load <4 x i8>** %CastToValueType1386, align 8
  %569 = load <4 x i8>* %loadedValue1387, align 4
  %"&(pSB[currWI].offset)1408" = add nuw i64 %CurrSBIndex..1, 1112
  %"&pSB[currWI].offset1409" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1408"
  %CastToValueType1410 = bitcast i8* %"&pSB[currWI].offset1409" to <4 x i8>**
  %loadedValue1411 = load <4 x i8>** %CastToValueType1410, align 8
  %570 = load <4 x i8>* %loadedValue1411, align 4
  %"&(pSB[currWI].offset)1432" = add nuw i64 %CurrSBIndex..1, 1120
  %"&pSB[currWI].offset1433" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1432"
  %CastToValueType1434 = bitcast i8* %"&pSB[currWI].offset1433" to <4 x i8>**
  %loadedValue1435 = load <4 x i8>** %CastToValueType1434, align 8
  %571 = load <4 x i8>* %loadedValue1435, align 4
  %572 = extractelement <4 x i8> %556, i32 0
  %573 = extractelement <4 x i8> %557, i32 0
  %574 = extractelement <4 x i8> %558, i32 0
  %575 = extractelement <4 x i8> %559, i32 0
  %576 = extractelement <4 x i8> %560, i32 0
  %577 = extractelement <4 x i8> %561, i32 0
  %578 = extractelement <4 x i8> %562, i32 0
  %579 = extractelement <4 x i8> %563, i32 0
  %580 = extractelement <4 x i8> %564, i32 0
  %581 = extractelement <4 x i8> %565, i32 0
  %582 = extractelement <4 x i8> %566, i32 0
  %583 = extractelement <4 x i8> %567, i32 0
  %584 = extractelement <4 x i8> %568, i32 0
  %585 = extractelement <4 x i8> %569, i32 0
  %586 = extractelement <4 x i8> %570, i32 0
  %587 = extractelement <4 x i8> %571, i32 0
  %temp.vect546 = insertelement <16 x i8> undef, i8 %572, i32 0
  %temp.vect547 = insertelement <16 x i8> %temp.vect546, i8 %573, i32 1
  %temp.vect548 = insertelement <16 x i8> %temp.vect547, i8 %574, i32 2
  %temp.vect549 = insertelement <16 x i8> %temp.vect548, i8 %575, i32 3
  %temp.vect550 = insertelement <16 x i8> %temp.vect549, i8 %576, i32 4
  %temp.vect551 = insertelement <16 x i8> %temp.vect550, i8 %577, i32 5
  %temp.vect552 = insertelement <16 x i8> %temp.vect551, i8 %578, i32 6
  %temp.vect553 = insertelement <16 x i8> %temp.vect552, i8 %579, i32 7
  %temp.vect554 = insertelement <16 x i8> %temp.vect553, i8 %580, i32 8
  %temp.vect555 = insertelement <16 x i8> %temp.vect554, i8 %581, i32 9
  %temp.vect556 = insertelement <16 x i8> %temp.vect555, i8 %582, i32 10
  %temp.vect557 = insertelement <16 x i8> %temp.vect556, i8 %583, i32 11
  %temp.vect558 = insertelement <16 x i8> %temp.vect557, i8 %584, i32 12
  %temp.vect559 = insertelement <16 x i8> %temp.vect558, i8 %585, i32 13
  %temp.vect560 = insertelement <16 x i8> %temp.vect559, i8 %586, i32 14
  %temp.vect561 = insertelement <16 x i8> %temp.vect560, i8 %587, i32 15
  %588 = load <4 x i8> addrspace(3)* %block1, align 4
  %scalar55 = extractelement <4 x i8> %588, i32 2
  %temp564 = insertelement <16 x i8> undef, i8 %scalar55, i32 0
  %vector565 = shufflevector <16 x i8> %temp564, <16 x i8> undef, <16 x i32> zeroinitializer
  %589 = zext i8 %scalar55 to i32
  %590 = shl i32 %589, 1
  %591 = and i32 %589, 128
  %592 = xor i32 %590, 27
  %593 = icmp eq i32 %591, 0
  %a.5.in = select i1 %593, i32 %590, i32 %592
  %594 = shl i32 %a.5.in, 1
  %595 = and i32 %a.5.in, 128
  %596 = xor i32 %594, 27
  %597 = icmp eq i32 %595, 0
  %a.5.in.1 = select i1 %597, i32 %594, i32 %596
  %598 = shl i32 %a.5.in.1, 1
  %599 = and i32 %a.5.in.1, 128
  %600 = xor i32 %598, 27
  %601 = icmp eq i32 %599, 0
  %a.5.in.2 = select i1 %601, i32 %598, i32 %600
  %602 = shl i32 %a.5.in.2, 1
  %603 = and i32 %a.5.in.2, 128
  %604 = xor i32 %602, 27
  %605 = icmp eq i32 %603, 0
  %a.5.in.3 = select i1 %605, i32 %602, i32 %604
  %606 = shl i32 %a.5.in.3, 1
  %607 = and i32 %a.5.in.3, 128
  %608 = xor i32 %606, 27
  %609 = icmp eq i32 %607, 0
  %a.5.in.4 = select i1 %609, i32 %606, i32 %608
  %610 = shl i32 %a.5.in.4, 1
  %611 = and i32 %a.5.in.4, 128
  %612 = xor i32 %610, 27
  %613 = icmp eq i32 %611, 0
  %a.5.in.5 = select i1 %613, i32 %610, i32 %612
  %614 = shl i32 %a.5.in.5, 1
  %615 = lshr <16 x i8> %temp.vect561, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %616 = zext <16 x i8> %615 to <16 x i32>
  %617 = zext <16 x i8> %temp.vect561 to <16 x i32>
  %618 = lshr <16 x i8> %temp.vect561, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %619 = lshr <16 x i8> %temp.vect561, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %620 = and <16 x i32> %616, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %621 = and <16 x i32> %617, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %622 = zext <16 x i8> %618 to <16 x i32>
  %623 = zext <16 x i8> %619 to <16 x i32>
  %624 = icmp eq <16 x i32> %620, zeroinitializer
  %a.5 = trunc i32 %a.5.in to i8
  %temp562 = insertelement <16 x i8> undef, i8 %a.5, i32 0
  %vector563 = shufflevector <16 x i8> %temp562, <16 x i8> undef, <16 x i32> zeroinitializer
  %625 = icmp eq <16 x i32> %621, zeroinitializer
  %626 = and <16 x i32> %622, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %627 = lshr <16 x i8> %temp.vect561, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %628 = lshr <16 x i8> %temp.vect561, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %629 = and <16 x i32> %623, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %630 = select <16 x i1> %624, <16 x i8> zeroinitializer, <16 x i8> %vector563
  %631 = select <16 x i1> %625, <16 x i8> zeroinitializer, <16 x i8> %vector565
  %a.5.1 = trunc i32 %a.5.in.1 to i8
  %temp567 = insertelement <16 x i8> undef, i8 %a.5.1, i32 0
  %vector568 = shufflevector <16 x i8> %temp567, <16 x i8> undef, <16 x i32> zeroinitializer
  %632 = icmp eq <16 x i32> %626, zeroinitializer
  %633 = zext <16 x i8> %627 to <16 x i32>
  %634 = zext <16 x i8> %628 to <16 x i32>
  %635 = icmp eq <16 x i32> %629, zeroinitializer
  %a.5.2 = trunc i32 %a.5.in.2 to i8
  %temp569 = insertelement <16 x i8> undef, i8 %a.5.2, i32 0
  %vector570 = shufflevector <16 x i8> %temp569, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..1566 = xor <16 x i8> %630, %631
  %636 = select <16 x i1> %632, <16 x i8> zeroinitializer, <16 x i8> %vector568
  %637 = and <16 x i32> %633, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %638 = lshr <16 x i8> %temp.vect561, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %639 = and i32 %a.5.in.5, 128
  %640 = and <16 x i32> %634, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %641 = select <16 x i1> %635, <16 x i8> zeroinitializer, <16 x i8> %vector570
  %p.5..2571 = xor <16 x i8> %636, %p.5..1566
  %a.5.3 = trunc i32 %a.5.in.3 to i8
  %temp573 = insertelement <16 x i8> undef, i8 %a.5.3, i32 0
  %vector574 = shufflevector <16 x i8> %temp573, <16 x i8> undef, <16 x i32> zeroinitializer
  %642 = icmp eq <16 x i32> %637, zeroinitializer
  %643 = zext <16 x i8> %638 to <16 x i32>
  %644 = icmp eq i32 %639, 0
  %645 = xor i32 %614, 27
  %646 = icmp eq <16 x i32> %640, zeroinitializer
  %a.5.4 = trunc i32 %a.5.in.4 to i8
  %temp575 = insertelement <16 x i8> undef, i8 %a.5.4, i32 0
  %vector576 = shufflevector <16 x i8> %temp575, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..3572 = xor <16 x i8> %641, %p.5..2571
  %647 = select <16 x i1> %642, <16 x i8> zeroinitializer, <16 x i8> %vector574
  %648 = and <16 x i32> %643, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.5.in.6 = select i1 %644, i32 %614, i32 %645
  %649 = select <16 x i1> %646, <16 x i8> zeroinitializer, <16 x i8> %vector576
  %p.5..4577 = xor <16 x i8> %647, %p.5..3572
  %a.5.5 = trunc i32 %a.5.in.5 to i8
  %temp579 = insertelement <16 x i8> undef, i8 %a.5.5, i32 0
  %vector580 = shufflevector <16 x i8> %temp579, <16 x i8> undef, <16 x i32> zeroinitializer
  %650 = icmp eq <16 x i32> %648, zeroinitializer
  %651 = icmp sgt <16 x i8> %temp.vect561, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.5.6 = trunc i32 %a.5.in.6 to i8
  %temp581 = insertelement <16 x i8> undef, i8 %a.5.6, i32 0
  %vector582 = shufflevector <16 x i8> %temp581, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..5578 = xor <16 x i8> %649, %p.5..4577
  %652 = select <16 x i1> %650, <16 x i8> zeroinitializer, <16 x i8> %vector580
  %653 = select <16 x i1> %651, <16 x i8> zeroinitializer, <16 x i8> %vector582
  %p.5..6583 = xor <16 x i8> %652, %p.5..5578
  %p.5..7584 = xor <16 x i8> %653, %p.5..6583
  %"&(pSB[currWI].offset)1561" = add nuw i64 %CurrSBIndex..1, 1328
  %"&pSB[currWI].offset1562" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1561"
  %CastToValueType1563 = bitcast i8* %"&pSB[currWI].offset1562" to <16 x i8>*
  store <16 x i8> %p.5..7584, <16 x i8>* %CastToValueType1563, align 16
  %"&(pSB[currWI].offset)1067" = add nuw i64 %CurrSBIndex..1, 1000
  %"&pSB[currWI].offset1068" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1067"
  %CastToValueType1069 = bitcast i8* %"&pSB[currWI].offset1068" to <4 x i8>**
  %loadedValue1070 = load <4 x i8>** %CastToValueType1069, align 8
  %654 = load <4 x i8>* %loadedValue1070, align 4
  %"&(pSB[currWI].offset)1091" = add nuw i64 %CurrSBIndex..1, 1008
  %"&pSB[currWI].offset1092" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1091"
  %CastToValueType1093 = bitcast i8* %"&pSB[currWI].offset1092" to <4 x i8>**
  %loadedValue1094 = load <4 x i8>** %CastToValueType1093, align 8
  %655 = load <4 x i8>* %loadedValue1094, align 4
  %"&(pSB[currWI].offset)1115" = add nuw i64 %CurrSBIndex..1, 1016
  %"&pSB[currWI].offset1116" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1115"
  %CastToValueType1117 = bitcast i8* %"&pSB[currWI].offset1116" to <4 x i8>**
  %loadedValue1118 = load <4 x i8>** %CastToValueType1117, align 8
  %656 = load <4 x i8>* %loadedValue1118, align 4
  %"&(pSB[currWI].offset)1139" = add nuw i64 %CurrSBIndex..1, 1024
  %"&pSB[currWI].offset1140" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1139"
  %CastToValueType1141 = bitcast i8* %"&pSB[currWI].offset1140" to <4 x i8>**
  %loadedValue1142 = load <4 x i8>** %CastToValueType1141, align 8
  %657 = load <4 x i8>* %loadedValue1142, align 4
  %"&(pSB[currWI].offset)1163" = add nuw i64 %CurrSBIndex..1, 1032
  %"&pSB[currWI].offset1164" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1163"
  %CastToValueType1165 = bitcast i8* %"&pSB[currWI].offset1164" to <4 x i8>**
  %loadedValue1166 = load <4 x i8>** %CastToValueType1165, align 8
  %658 = load <4 x i8>* %loadedValue1166, align 4
  %"&(pSB[currWI].offset)1187" = add nuw i64 %CurrSBIndex..1, 1040
  %"&pSB[currWI].offset1188" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1187"
  %CastToValueType1189 = bitcast i8* %"&pSB[currWI].offset1188" to <4 x i8>**
  %loadedValue1190 = load <4 x i8>** %CastToValueType1189, align 8
  %659 = load <4 x i8>* %loadedValue1190, align 4
  %"&(pSB[currWI].offset)1211" = add nuw i64 %CurrSBIndex..1, 1048
  %"&pSB[currWI].offset1212" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1211"
  %CastToValueType1213 = bitcast i8* %"&pSB[currWI].offset1212" to <4 x i8>**
  %loadedValue1214 = load <4 x i8>** %CastToValueType1213, align 8
  %660 = load <4 x i8>* %loadedValue1214, align 4
  %"&(pSB[currWI].offset)1235" = add nuw i64 %CurrSBIndex..1, 1056
  %"&pSB[currWI].offset1236" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1235"
  %CastToValueType1237 = bitcast i8* %"&pSB[currWI].offset1236" to <4 x i8>**
  %loadedValue1238 = load <4 x i8>** %CastToValueType1237, align 8
  %661 = load <4 x i8>* %loadedValue1238, align 4
  %"&(pSB[currWI].offset)1259" = add nuw i64 %CurrSBIndex..1, 1064
  %"&pSB[currWI].offset1260" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1259"
  %CastToValueType1261 = bitcast i8* %"&pSB[currWI].offset1260" to <4 x i8>**
  %loadedValue1262 = load <4 x i8>** %CastToValueType1261, align 8
  %662 = load <4 x i8>* %loadedValue1262, align 4
  %"&(pSB[currWI].offset)1283" = add nuw i64 %CurrSBIndex..1, 1072
  %"&pSB[currWI].offset1284" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1283"
  %CastToValueType1285 = bitcast i8* %"&pSB[currWI].offset1284" to <4 x i8>**
  %loadedValue1286 = load <4 x i8>** %CastToValueType1285, align 8
  %663 = load <4 x i8>* %loadedValue1286, align 4
  %"&(pSB[currWI].offset)1307" = add nuw i64 %CurrSBIndex..1, 1080
  %"&pSB[currWI].offset1308" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1307"
  %CastToValueType1309 = bitcast i8* %"&pSB[currWI].offset1308" to <4 x i8>**
  %loadedValue1310 = load <4 x i8>** %CastToValueType1309, align 8
  %664 = load <4 x i8>* %loadedValue1310, align 4
  %"&(pSB[currWI].offset)1331" = add nuw i64 %CurrSBIndex..1, 1088
  %"&pSB[currWI].offset1332" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1331"
  %CastToValueType1333 = bitcast i8* %"&pSB[currWI].offset1332" to <4 x i8>**
  %loadedValue1334 = load <4 x i8>** %CastToValueType1333, align 8
  %665 = load <4 x i8>* %loadedValue1334, align 4
  %"&(pSB[currWI].offset)1355" = add nuw i64 %CurrSBIndex..1, 1096
  %"&pSB[currWI].offset1356" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1355"
  %CastToValueType1357 = bitcast i8* %"&pSB[currWI].offset1356" to <4 x i8>**
  %loadedValue1358 = load <4 x i8>** %CastToValueType1357, align 8
  %666 = load <4 x i8>* %loadedValue1358, align 4
  %"&(pSB[currWI].offset)1379" = add nuw i64 %CurrSBIndex..1, 1104
  %"&pSB[currWI].offset1380" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1379"
  %CastToValueType1381 = bitcast i8* %"&pSB[currWI].offset1380" to <4 x i8>**
  %loadedValue1382 = load <4 x i8>** %CastToValueType1381, align 8
  %667 = load <4 x i8>* %loadedValue1382, align 4
  %"&(pSB[currWI].offset)1403" = add nuw i64 %CurrSBIndex..1, 1112
  %"&pSB[currWI].offset1404" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1403"
  %CastToValueType1405 = bitcast i8* %"&pSB[currWI].offset1404" to <4 x i8>**
  %loadedValue1406 = load <4 x i8>** %CastToValueType1405, align 8
  %668 = load <4 x i8>* %loadedValue1406, align 4
  %"&(pSB[currWI].offset)1427" = add nuw i64 %CurrSBIndex..1, 1120
  %"&pSB[currWI].offset1428" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1427"
  %CastToValueType1429 = bitcast i8* %"&pSB[currWI].offset1428" to <4 x i8>**
  %loadedValue1430 = load <4 x i8>** %CastToValueType1429, align 8
  %669 = load <4 x i8>* %loadedValue1430, align 4
  %670 = extractelement <4 x i8> %654, i32 0
  %671 = extractelement <4 x i8> %655, i32 0
  %672 = extractelement <4 x i8> %656, i32 0
  %673 = extractelement <4 x i8> %657, i32 0
  %674 = extractelement <4 x i8> %658, i32 0
  %675 = extractelement <4 x i8> %659, i32 0
  %676 = extractelement <4 x i8> %660, i32 0
  %677 = extractelement <4 x i8> %661, i32 0
  %678 = extractelement <4 x i8> %662, i32 0
  %679 = extractelement <4 x i8> %663, i32 0
  %680 = extractelement <4 x i8> %664, i32 0
  %681 = extractelement <4 x i8> %665, i32 0
  %682 = extractelement <4 x i8> %666, i32 0
  %683 = extractelement <4 x i8> %667, i32 0
  %684 = extractelement <4 x i8> %668, i32 0
  %685 = extractelement <4 x i8> %669, i32 0
  %temp.vect585 = insertelement <16 x i8> undef, i8 %670, i32 0
  %temp.vect586 = insertelement <16 x i8> %temp.vect585, i8 %671, i32 1
  %temp.vect587 = insertelement <16 x i8> %temp.vect586, i8 %672, i32 2
  %temp.vect588 = insertelement <16 x i8> %temp.vect587, i8 %673, i32 3
  %temp.vect589 = insertelement <16 x i8> %temp.vect588, i8 %674, i32 4
  %temp.vect590 = insertelement <16 x i8> %temp.vect589, i8 %675, i32 5
  %temp.vect591 = insertelement <16 x i8> %temp.vect590, i8 %676, i32 6
  %temp.vect592 = insertelement <16 x i8> %temp.vect591, i8 %677, i32 7
  %temp.vect593 = insertelement <16 x i8> %temp.vect592, i8 %678, i32 8
  %temp.vect594 = insertelement <16 x i8> %temp.vect593, i8 %679, i32 9
  %temp.vect595 = insertelement <16 x i8> %temp.vect594, i8 %680, i32 10
  %temp.vect596 = insertelement <16 x i8> %temp.vect595, i8 %681, i32 11
  %temp.vect597 = insertelement <16 x i8> %temp.vect596, i8 %682, i32 12
  %temp.vect598 = insertelement <16 x i8> %temp.vect597, i8 %683, i32 13
  %temp.vect599 = insertelement <16 x i8> %temp.vect598, i8 %684, i32 14
  %temp.vect600 = insertelement <16 x i8> %temp.vect599, i8 %685, i32 15
  %686 = load <4 x i8> addrspace(3)* %block1, align 4
  %scalar64 = extractelement <4 x i8> %686, i32 3
  %temp603 = insertelement <16 x i8> undef, i8 %scalar64, i32 0
  %vector604 = shufflevector <16 x i8> %temp603, <16 x i8> undef, <16 x i32> zeroinitializer
  %687 = zext i8 %scalar64 to i32
  %688 = shl i32 %687, 1
  %689 = and i32 %687, 128
  %690 = xor i32 %688, 27
  %691 = icmp eq i32 %689, 0
  %a.7.in = select i1 %691, i32 %688, i32 %690
  %692 = shl i32 %a.7.in, 1
  %693 = and i32 %a.7.in, 128
  %694 = xor i32 %692, 27
  %695 = icmp eq i32 %693, 0
  %a.7.in.1 = select i1 %695, i32 %692, i32 %694
  %696 = shl i32 %a.7.in.1, 1
  %697 = and i32 %a.7.in.1, 128
  %698 = xor i32 %696, 27
  %699 = icmp eq i32 %697, 0
  %a.7.in.2 = select i1 %699, i32 %696, i32 %698
  %700 = shl i32 %a.7.in.2, 1
  %701 = and i32 %a.7.in.2, 128
  %702 = xor i32 %700, 27
  %703 = icmp eq i32 %701, 0
  %a.7.in.3 = select i1 %703, i32 %700, i32 %702
  %704 = shl i32 %a.7.in.3, 1
  %705 = and i32 %a.7.in.3, 128
  %706 = xor i32 %704, 27
  %707 = icmp eq i32 %705, 0
  %a.7.in.4 = select i1 %707, i32 %704, i32 %706
  %708 = shl i32 %a.7.in.4, 1
  %709 = and i32 %a.7.in.4, 128
  %710 = xor i32 %708, 27
  %711 = icmp eq i32 %709, 0
  %a.7.in.5 = select i1 %711, i32 %708, i32 %710
  %712 = shl i32 %a.7.in.5, 1
  %713 = lshr <16 x i8> %temp.vect600, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %714 = zext <16 x i8> %713 to <16 x i32>
  %715 = zext <16 x i8> %temp.vect600 to <16 x i32>
  %716 = lshr <16 x i8> %temp.vect600, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %717 = lshr <16 x i8> %temp.vect600, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %718 = and <16 x i32> %714, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %719 = and <16 x i32> %715, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %720 = zext <16 x i8> %716 to <16 x i32>
  %721 = zext <16 x i8> %717 to <16 x i32>
  %722 = icmp eq <16 x i32> %718, zeroinitializer
  %a.7 = trunc i32 %a.7.in to i8
  %temp601 = insertelement <16 x i8> undef, i8 %a.7, i32 0
  %vector602 = shufflevector <16 x i8> %temp601, <16 x i8> undef, <16 x i32> zeroinitializer
  %723 = icmp eq <16 x i32> %719, zeroinitializer
  %724 = and <16 x i32> %720, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %725 = lshr <16 x i8> %temp.vect600, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %726 = lshr <16 x i8> %temp.vect600, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %727 = and <16 x i32> %721, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %728 = select <16 x i1> %722, <16 x i8> zeroinitializer, <16 x i8> %vector602
  %729 = select <16 x i1> %723, <16 x i8> zeroinitializer, <16 x i8> %vector604
  %a.7.1 = trunc i32 %a.7.in.1 to i8
  %temp606 = insertelement <16 x i8> undef, i8 %a.7.1, i32 0
  %vector607 = shufflevector <16 x i8> %temp606, <16 x i8> undef, <16 x i32> zeroinitializer
  %730 = icmp eq <16 x i32> %724, zeroinitializer
  %731 = zext <16 x i8> %725 to <16 x i32>
  %732 = zext <16 x i8> %726 to <16 x i32>
  %733 = icmp eq <16 x i32> %727, zeroinitializer
  %a.7.2 = trunc i32 %a.7.in.2 to i8
  %temp608 = insertelement <16 x i8> undef, i8 %a.7.2, i32 0
  %vector609 = shufflevector <16 x i8> %temp608, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..1605 = xor <16 x i8> %728, %729
  %734 = select <16 x i1> %730, <16 x i8> zeroinitializer, <16 x i8> %vector607
  %735 = and <16 x i32> %731, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %736 = lshr <16 x i8> %temp.vect600, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %737 = and i32 %a.7.in.5, 128
  %738 = and <16 x i32> %732, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %739 = select <16 x i1> %733, <16 x i8> zeroinitializer, <16 x i8> %vector609
  %p.7..2610 = xor <16 x i8> %734, %p.7..1605
  %a.7.3 = trunc i32 %a.7.in.3 to i8
  %temp612 = insertelement <16 x i8> undef, i8 %a.7.3, i32 0
  %vector613 = shufflevector <16 x i8> %temp612, <16 x i8> undef, <16 x i32> zeroinitializer
  %740 = icmp eq <16 x i32> %735, zeroinitializer
  %741 = zext <16 x i8> %736 to <16 x i32>
  %742 = icmp eq i32 %737, 0
  %743 = xor i32 %712, 27
  %744 = icmp eq <16 x i32> %738, zeroinitializer
  %a.7.4 = trunc i32 %a.7.in.4 to i8
  %temp614 = insertelement <16 x i8> undef, i8 %a.7.4, i32 0
  %vector615 = shufflevector <16 x i8> %temp614, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..3611 = xor <16 x i8> %739, %p.7..2610
  %745 = select <16 x i1> %740, <16 x i8> zeroinitializer, <16 x i8> %vector613
  %746 = and <16 x i32> %741, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.7.in.6 = select i1 %742, i32 %712, i32 %743
  %747 = select <16 x i1> %744, <16 x i8> zeroinitializer, <16 x i8> %vector615
  %p.7..4616 = xor <16 x i8> %745, %p.7..3611
  %a.7.5 = trunc i32 %a.7.in.5 to i8
  %temp618 = insertelement <16 x i8> undef, i8 %a.7.5, i32 0
  %vector619 = shufflevector <16 x i8> %temp618, <16 x i8> undef, <16 x i32> zeroinitializer
  %748 = icmp eq <16 x i32> %746, zeroinitializer
  %749 = icmp sgt <16 x i8> %temp.vect600, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.7.6 = trunc i32 %a.7.in.6 to i8
  %temp620 = insertelement <16 x i8> undef, i8 %a.7.6, i32 0
  %vector621 = shufflevector <16 x i8> %temp620, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..5617 = xor <16 x i8> %747, %p.7..4616
  %750 = select <16 x i1> %748, <16 x i8> zeroinitializer, <16 x i8> %vector619
  %751 = select <16 x i1> %749, <16 x i8> zeroinitializer, <16 x i8> %vector621
  %p.7..6622 = xor <16 x i8> %750, %p.7..5617
  %p.7..7623 = xor <16 x i8> %751, %p.7..6622
  %"&(pSB[currWI].offset)1565" = add nuw i64 %CurrSBIndex..1, 1344
  %"&pSB[currWI].offset1566" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1565"
  %CastToValueType1567 = bitcast i8* %"&pSB[currWI].offset1566" to <16 x i8>*
  store <16 x i8> %p.7..7623, <16 x i8>* %CastToValueType1567, align 16
  %"&(pSB[currWI].offset)1569" = add nuw i64 %CurrSBIndex..1, 1360
  %"&pSB[currWI].offset1570" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1569"
  %CastToValueType1571 = bitcast i8* %"&pSB[currWI].offset1570" to i64*
  %"&(pSB[currWI].offset)1451" = add nuw i64 %CurrSBIndex..1, 1128
  %"&pSB[currWI].offset1452" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1451"
  %CastToValueType1453 = bitcast i8* %"&pSB[currWI].offset1452" to i64*
  %"&(pSB[currWI].offset)1645" = add nuw i64 %CurrSBIndex..1, 1456
  %"&pSB[currWI].offset1646" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1645"
  %CastToValueType1647 = bitcast i8* %"&pSB[currWI].offset1646" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1681" = add nuw i64 %CurrSBIndex..1, 1472
  %"&pSB[currWI].offset1682" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1681"
  %CastToValueType1683 = bitcast i8* %"&pSB[currWI].offset1682" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1717" = add nuw i64 %CurrSBIndex..1, 1488
  %"&pSB[currWI].offset1718" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1717"
  %CastToValueType1719 = bitcast i8* %"&pSB[currWI].offset1718" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1753" = add nuw i64 %CurrSBIndex..1, 1504
  %"&pSB[currWI].offset1754" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1753"
  %CastToValueType1755 = bitcast i8* %"&pSB[currWI].offset1754" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1789" = add nuw i64 %CurrSBIndex..1, 1520
  %"&pSB[currWI].offset1790" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1789"
  %CastToValueType1791 = bitcast i8* %"&pSB[currWI].offset1790" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1825" = add nuw i64 %CurrSBIndex..1, 1536
  %"&pSB[currWI].offset1826" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1825"
  %CastToValueType1827 = bitcast i8* %"&pSB[currWI].offset1826" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1861" = add nuw i64 %CurrSBIndex..1, 1552
  %"&pSB[currWI].offset1862" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1861"
  %CastToValueType1863 = bitcast i8* %"&pSB[currWI].offset1862" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1897" = add nuw i64 %CurrSBIndex..1, 1568
  %"&pSB[currWI].offset1898" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1897"
  %CastToValueType1899 = bitcast i8* %"&pSB[currWI].offset1898" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1933" = add nuw i64 %CurrSBIndex..1, 1584
  %"&pSB[currWI].offset1934" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1933"
  %CastToValueType1935 = bitcast i8* %"&pSB[currWI].offset1934" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1969" = add nuw i64 %CurrSBIndex..1, 1600
  %"&pSB[currWI].offset1970" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1969"
  %CastToValueType1971 = bitcast i8* %"&pSB[currWI].offset1970" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2005" = add nuw i64 %CurrSBIndex..1, 1616
  %"&pSB[currWI].offset2006" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2005"
  %CastToValueType2007 = bitcast i8* %"&pSB[currWI].offset2006" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2041" = add nuw i64 %CurrSBIndex..1, 1632
  %"&pSB[currWI].offset2042" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2041"
  %CastToValueType2043 = bitcast i8* %"&pSB[currWI].offset2042" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2077" = add nuw i64 %CurrSBIndex..1, 1648
  %"&pSB[currWI].offset2078" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2077"
  %CastToValueType2079 = bitcast i8* %"&pSB[currWI].offset2078" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2113" = add nuw i64 %CurrSBIndex..1, 1664
  %"&pSB[currWI].offset2114" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2113"
  %CastToValueType2115 = bitcast i8* %"&pSB[currWI].offset2114" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2149" = add nuw i64 %CurrSBIndex..1, 1680
  %"&pSB[currWI].offset2150" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2149"
  %CastToValueType2151 = bitcast i8* %"&pSB[currWI].offset2150" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2185" = add nuw i64 %CurrSBIndex..1, 1696
  %"&pSB[currWI].offset2186" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2185"
  %CastToValueType2187 = bitcast i8* %"&pSB[currWI].offset2186" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1641" = add nuw i64 %CurrSBIndex..1, 1456
  %"&pSB[currWI].offset1642" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1641"
  %CastToValueType1643 = bitcast i8* %"&pSB[currWI].offset1642" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1677" = add nuw i64 %CurrSBIndex..1, 1472
  %"&pSB[currWI].offset1678" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1677"
  %CastToValueType1679 = bitcast i8* %"&pSB[currWI].offset1678" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1713" = add nuw i64 %CurrSBIndex..1, 1488
  %"&pSB[currWI].offset1714" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1713"
  %CastToValueType1715 = bitcast i8* %"&pSB[currWI].offset1714" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1749" = add nuw i64 %CurrSBIndex..1, 1504
  %"&pSB[currWI].offset1750" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1749"
  %CastToValueType1751 = bitcast i8* %"&pSB[currWI].offset1750" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1785" = add nuw i64 %CurrSBIndex..1, 1520
  %"&pSB[currWI].offset1786" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1785"
  %CastToValueType1787 = bitcast i8* %"&pSB[currWI].offset1786" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1821" = add nuw i64 %CurrSBIndex..1, 1536
  %"&pSB[currWI].offset1822" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1821"
  %CastToValueType1823 = bitcast i8* %"&pSB[currWI].offset1822" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1857" = add nuw i64 %CurrSBIndex..1, 1552
  %"&pSB[currWI].offset1858" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1857"
  %CastToValueType1859 = bitcast i8* %"&pSB[currWI].offset1858" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1893" = add nuw i64 %CurrSBIndex..1, 1568
  %"&pSB[currWI].offset1894" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1893"
  %CastToValueType1895 = bitcast i8* %"&pSB[currWI].offset1894" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1929" = add nuw i64 %CurrSBIndex..1, 1584
  %"&pSB[currWI].offset1930" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1929"
  %CastToValueType1931 = bitcast i8* %"&pSB[currWI].offset1930" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1965" = add nuw i64 %CurrSBIndex..1, 1600
  %"&pSB[currWI].offset1966" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1965"
  %CastToValueType1967 = bitcast i8* %"&pSB[currWI].offset1966" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2001" = add nuw i64 %CurrSBIndex..1, 1616
  %"&pSB[currWI].offset2002" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2001"
  %CastToValueType2003 = bitcast i8* %"&pSB[currWI].offset2002" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2037" = add nuw i64 %CurrSBIndex..1, 1632
  %"&pSB[currWI].offset2038" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2037"
  %CastToValueType2039 = bitcast i8* %"&pSB[currWI].offset2038" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2073" = add nuw i64 %CurrSBIndex..1, 1648
  %"&pSB[currWI].offset2074" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2073"
  %CastToValueType2075 = bitcast i8* %"&pSB[currWI].offset2074" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2109" = add nuw i64 %CurrSBIndex..1, 1664
  %"&pSB[currWI].offset2110" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2109"
  %CastToValueType2111 = bitcast i8* %"&pSB[currWI].offset2110" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2145" = add nuw i64 %CurrSBIndex..1, 1680
  %"&pSB[currWI].offset2146" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2145"
  %CastToValueType2147 = bitcast i8* %"&pSB[currWI].offset2146" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2181" = add nuw i64 %CurrSBIndex..1, 1696
  %"&pSB[currWI].offset2182" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2181"
  %CastToValueType2183 = bitcast i8* %"&pSB[currWI].offset2182" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1637" = add nuw i64 %CurrSBIndex..1, 1456
  %"&pSB[currWI].offset1638" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1637"
  %CastToValueType1639 = bitcast i8* %"&pSB[currWI].offset1638" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1673" = add nuw i64 %CurrSBIndex..1, 1472
  %"&pSB[currWI].offset1674" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1673"
  %CastToValueType1675 = bitcast i8* %"&pSB[currWI].offset1674" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1709" = add nuw i64 %CurrSBIndex..1, 1488
  %"&pSB[currWI].offset1710" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1709"
  %CastToValueType1711 = bitcast i8* %"&pSB[currWI].offset1710" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1745" = add nuw i64 %CurrSBIndex..1, 1504
  %"&pSB[currWI].offset1746" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1745"
  %CastToValueType1747 = bitcast i8* %"&pSB[currWI].offset1746" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1781" = add nuw i64 %CurrSBIndex..1, 1520
  %"&pSB[currWI].offset1782" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1781"
  %CastToValueType1783 = bitcast i8* %"&pSB[currWI].offset1782" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1817" = add nuw i64 %CurrSBIndex..1, 1536
  %"&pSB[currWI].offset1818" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1817"
  %CastToValueType1819 = bitcast i8* %"&pSB[currWI].offset1818" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1853" = add nuw i64 %CurrSBIndex..1, 1552
  %"&pSB[currWI].offset1854" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1853"
  %CastToValueType1855 = bitcast i8* %"&pSB[currWI].offset1854" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1889" = add nuw i64 %CurrSBIndex..1, 1568
  %"&pSB[currWI].offset1890" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1889"
  %CastToValueType1891 = bitcast i8* %"&pSB[currWI].offset1890" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1925" = add nuw i64 %CurrSBIndex..1, 1584
  %"&pSB[currWI].offset1926" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1925"
  %CastToValueType1927 = bitcast i8* %"&pSB[currWI].offset1926" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1961" = add nuw i64 %CurrSBIndex..1, 1600
  %"&pSB[currWI].offset1962" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1961"
  %CastToValueType1963 = bitcast i8* %"&pSB[currWI].offset1962" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1997" = add nuw i64 %CurrSBIndex..1, 1616
  %"&pSB[currWI].offset1998" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1997"
  %CastToValueType1999 = bitcast i8* %"&pSB[currWI].offset1998" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2033" = add nuw i64 %CurrSBIndex..1, 1632
  %"&pSB[currWI].offset2034" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2033"
  %CastToValueType2035 = bitcast i8* %"&pSB[currWI].offset2034" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2069" = add nuw i64 %CurrSBIndex..1, 1648
  %"&pSB[currWI].offset2070" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2069"
  %CastToValueType2071 = bitcast i8* %"&pSB[currWI].offset2070" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2105" = add nuw i64 %CurrSBIndex..1, 1664
  %"&pSB[currWI].offset2106" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2105"
  %CastToValueType2107 = bitcast i8* %"&pSB[currWI].offset2106" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2141" = add nuw i64 %CurrSBIndex..1, 1680
  %"&pSB[currWI].offset2142" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2141"
  %CastToValueType2143 = bitcast i8* %"&pSB[currWI].offset2142" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2177" = add nuw i64 %CurrSBIndex..1, 1696
  %"&pSB[currWI].offset2178" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2177"
  %CastToValueType2179 = bitcast i8* %"&pSB[currWI].offset2178" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1633" = add nuw i64 %CurrSBIndex..1, 1456
  %"&pSB[currWI].offset1634" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1633"
  %CastToValueType1635 = bitcast i8* %"&pSB[currWI].offset1634" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1669" = add nuw i64 %CurrSBIndex..1, 1472
  %"&pSB[currWI].offset1670" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1669"
  %CastToValueType1671 = bitcast i8* %"&pSB[currWI].offset1670" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1705" = add nuw i64 %CurrSBIndex..1, 1488
  %"&pSB[currWI].offset1706" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1705"
  %CastToValueType1707 = bitcast i8* %"&pSB[currWI].offset1706" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1741" = add nuw i64 %CurrSBIndex..1, 1504
  %"&pSB[currWI].offset1742" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1741"
  %CastToValueType1743 = bitcast i8* %"&pSB[currWI].offset1742" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1777" = add nuw i64 %CurrSBIndex..1, 1520
  %"&pSB[currWI].offset1778" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1777"
  %CastToValueType1779 = bitcast i8* %"&pSB[currWI].offset1778" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1813" = add nuw i64 %CurrSBIndex..1, 1536
  %"&pSB[currWI].offset1814" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1813"
  %CastToValueType1815 = bitcast i8* %"&pSB[currWI].offset1814" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1849" = add nuw i64 %CurrSBIndex..1, 1552
  %"&pSB[currWI].offset1850" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1849"
  %CastToValueType1851 = bitcast i8* %"&pSB[currWI].offset1850" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1885" = add nuw i64 %CurrSBIndex..1, 1568
  %"&pSB[currWI].offset1886" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1885"
  %CastToValueType1887 = bitcast i8* %"&pSB[currWI].offset1886" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1921" = add nuw i64 %CurrSBIndex..1, 1584
  %"&pSB[currWI].offset1922" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1921"
  %CastToValueType1923 = bitcast i8* %"&pSB[currWI].offset1922" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1957" = add nuw i64 %CurrSBIndex..1, 1600
  %"&pSB[currWI].offset1958" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1957"
  %CastToValueType1959 = bitcast i8* %"&pSB[currWI].offset1958" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1993" = add nuw i64 %CurrSBIndex..1, 1616
  %"&pSB[currWI].offset1994" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1993"
  %CastToValueType1995 = bitcast i8* %"&pSB[currWI].offset1994" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2029" = add nuw i64 %CurrSBIndex..1, 1632
  %"&pSB[currWI].offset2030" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2029"
  %CastToValueType2031 = bitcast i8* %"&pSB[currWI].offset2030" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2065" = add nuw i64 %CurrSBIndex..1, 1648
  %"&pSB[currWI].offset2066" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2065"
  %CastToValueType2067 = bitcast i8* %"&pSB[currWI].offset2066" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2101" = add nuw i64 %CurrSBIndex..1, 1664
  %"&pSB[currWI].offset2102" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2101"
  %CastToValueType2103 = bitcast i8* %"&pSB[currWI].offset2102" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2137" = add nuw i64 %CurrSBIndex..1, 1680
  %"&pSB[currWI].offset2138" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2137"
  %CastToValueType2139 = bitcast i8* %"&pSB[currWI].offset2138" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2173" = add nuw i64 %CurrSBIndex..1, 1696
  %"&pSB[currWI].offset2174" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)2173"
  %CastToValueType2175 = bitcast i8* %"&pSB[currWI].offset2174" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1573" = add nuw i64 %CurrSBIndex..1, 1376
  %"&pSB[currWI].offset1574" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1573"
  %CastToValueType1575 = bitcast i8* %"&pSB[currWI].offset1574" to <16 x i8>*
  %"&(pSB[currWI].offset)1587" = add nuw i64 %CurrSBIndex..1, 1392
  %"&pSB[currWI].offset1588" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1587"
  %CastToValueType1589 = bitcast i8* %"&pSB[currWI].offset1588" to <16 x i8>*
  %"&(pSB[currWI].offset)1601" = add nuw i64 %CurrSBIndex..1, 1408
  %"&pSB[currWI].offset1602" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1601"
  %CastToValueType1603 = bitcast i8* %"&pSB[currWI].offset1602" to <16 x i8>*
  %"&(pSB[currWI].offset)1615" = add nuw i64 %CurrSBIndex..1, 1424
  %"&pSB[currWI].offset1616" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1615"
  %CastToValueType1617 = bitcast i8* %"&pSB[currWI].offset1616" to <16 x i8>*
  br label %752

; <label>:752                                     ; preds = %752, %SyncBB2211
  %indvar = phi i64 [ 0, %SyncBB2211 ], [ %tmp, %752 ]
  %vectorPHI624 = phi <16 x i8> [ %p.7..7623, %SyncBB2211 ], [ %1216, %752 ]
  %vectorPHI625 = phi <16 x i8> [ %p.5..7584, %SyncBB2211 ], [ %1215, %752 ]
  %vectorPHI626 = phi <16 x i8> [ %p.3..7545, %SyncBB2211 ], [ %1214, %752 ]
  %vectorPHI627 = phi <16 x i8> [ %p.1..7506, %SyncBB2211 ], [ %1213, %752 ]
  %tmp = add i64 %indvar, 1
  store i64 %tmp, i64* %CastToValueType1571, align 8
  %scevgep = getelementptr <4 x i8> addrspace(3)* %block1, i64 %tmp
  %loadedValue1454 = load i64* %CastToValueType1453, align 8
  %tmp77 = add i64 %loadedValue1454, %indvar
  %753 = and i64 %tmp77, 3
  %754 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1647, i64 0, i64 %753
  %755 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1683, i64 0, i64 %753
  %756 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1719, i64 0, i64 %753
  %757 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1755, i64 0, i64 %753
  %758 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1791, i64 0, i64 %753
  %759 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1827, i64 0, i64 %753
  %760 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1863, i64 0, i64 %753
  %761 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1899, i64 0, i64 %753
  %762 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1935, i64 0, i64 %753
  %763 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1971, i64 0, i64 %753
  %764 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2007, i64 0, i64 %753
  %765 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2043, i64 0, i64 %753
  %766 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2079, i64 0, i64 %753
  %767 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2115, i64 0, i64 %753
  %768 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2151, i64 0, i64 %753
  %769 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2187, i64 0, i64 %753
  %770 = load <4 x i8>* %754, align 4
  %771 = load <4 x i8>* %755, align 4
  %772 = load <4 x i8>* %756, align 4
  %773 = load <4 x i8>* %757, align 4
  %774 = load <4 x i8>* %758, align 4
  %775 = load <4 x i8>* %759, align 4
  %776 = load <4 x i8>* %760, align 4
  %777 = load <4 x i8>* %761, align 4
  %778 = load <4 x i8>* %762, align 4
  %779 = load <4 x i8>* %763, align 4
  %780 = load <4 x i8>* %764, align 4
  %781 = load <4 x i8>* %765, align 4
  %782 = load <4 x i8>* %766, align 4
  %783 = load <4 x i8>* %767, align 4
  %784 = load <4 x i8>* %768, align 4
  %785 = load <4 x i8>* %769, align 4
  %786 = extractelement <4 x i8> %770, i32 0
  %787 = extractelement <4 x i8> %771, i32 0
  %788 = extractelement <4 x i8> %772, i32 0
  %789 = extractelement <4 x i8> %773, i32 0
  %790 = extractelement <4 x i8> %774, i32 0
  %791 = extractelement <4 x i8> %775, i32 0
  %792 = extractelement <4 x i8> %776, i32 0
  %793 = extractelement <4 x i8> %777, i32 0
  %794 = extractelement <4 x i8> %778, i32 0
  %795 = extractelement <4 x i8> %779, i32 0
  %796 = extractelement <4 x i8> %780, i32 0
  %797 = extractelement <4 x i8> %781, i32 0
  %798 = extractelement <4 x i8> %782, i32 0
  %799 = extractelement <4 x i8> %783, i32 0
  %800 = extractelement <4 x i8> %784, i32 0
  %801 = extractelement <4 x i8> %785, i32 0
  %temp.vect628 = insertelement <16 x i8> undef, i8 %786, i32 0
  %temp.vect629 = insertelement <16 x i8> %temp.vect628, i8 %787, i32 1
  %temp.vect630 = insertelement <16 x i8> %temp.vect629, i8 %788, i32 2
  %temp.vect631 = insertelement <16 x i8> %temp.vect630, i8 %789, i32 3
  %temp.vect632 = insertelement <16 x i8> %temp.vect631, i8 %790, i32 4
  %temp.vect633 = insertelement <16 x i8> %temp.vect632, i8 %791, i32 5
  %temp.vect634 = insertelement <16 x i8> %temp.vect633, i8 %792, i32 6
  %temp.vect635 = insertelement <16 x i8> %temp.vect634, i8 %793, i32 7
  %temp.vect636 = insertelement <16 x i8> %temp.vect635, i8 %794, i32 8
  %temp.vect637 = insertelement <16 x i8> %temp.vect636, i8 %795, i32 9
  %temp.vect638 = insertelement <16 x i8> %temp.vect637, i8 %796, i32 10
  %temp.vect639 = insertelement <16 x i8> %temp.vect638, i8 %797, i32 11
  %temp.vect640 = insertelement <16 x i8> %temp.vect639, i8 %798, i32 12
  %temp.vect641 = insertelement <16 x i8> %temp.vect640, i8 %799, i32 13
  %temp.vect642 = insertelement <16 x i8> %temp.vect641, i8 %800, i32 14
  %temp.vect643 = insertelement <16 x i8> %temp.vect642, i8 %801, i32 15
  %802 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar69 = extractelement <4 x i8> %802, i32 0
  %temp646 = insertelement <16 x i8> undef, i8 %scalar69, i32 0
  %vector647 = shufflevector <16 x i8> %temp646, <16 x i8> undef, <16 x i32> zeroinitializer
  %803 = zext i8 %scalar69 to i32
  %804 = shl i32 %803, 1
  %805 = and i32 %803, 128
  %806 = xor i32 %804, 27
  %807 = icmp eq i32 %805, 0
  %a.9.in = select i1 %807, i32 %804, i32 %806
  %808 = shl i32 %a.9.in, 1
  %809 = and i32 %a.9.in, 128
  %810 = xor i32 %808, 27
  %811 = icmp eq i32 %809, 0
  %a.9.in.1 = select i1 %811, i32 %808, i32 %810
  %812 = shl i32 %a.9.in.1, 1
  %813 = and i32 %a.9.in.1, 128
  %814 = xor i32 %812, 27
  %815 = icmp eq i32 %813, 0
  %a.9.in.2 = select i1 %815, i32 %812, i32 %814
  %816 = shl i32 %a.9.in.2, 1
  %817 = and i32 %a.9.in.2, 128
  %818 = xor i32 %816, 27
  %819 = icmp eq i32 %817, 0
  %a.9.in.3 = select i1 %819, i32 %816, i32 %818
  %820 = shl i32 %a.9.in.3, 1
  %821 = and i32 %a.9.in.3, 128
  %822 = xor i32 %820, 27
  %823 = icmp eq i32 %821, 0
  %a.9.in.4 = select i1 %823, i32 %820, i32 %822
  %824 = shl i32 %a.9.in.4, 1
  %825 = and i32 %a.9.in.4, 128
  %826 = xor i32 %824, 27
  %827 = icmp eq i32 %825, 0
  %a.9.in.5 = select i1 %827, i32 %824, i32 %826
  %828 = shl i32 %a.9.in.5, 1
  %829 = lshr <16 x i8> %temp.vect643, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %830 = zext <16 x i8> %829 to <16 x i32>
  %831 = zext <16 x i8> %temp.vect643 to <16 x i32>
  %832 = lshr <16 x i8> %temp.vect643, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %833 = lshr <16 x i8> %temp.vect643, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %834 = and <16 x i32> %830, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %835 = and <16 x i32> %831, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %836 = zext <16 x i8> %832 to <16 x i32>
  %837 = zext <16 x i8> %833 to <16 x i32>
  %838 = icmp eq <16 x i32> %834, zeroinitializer
  %a.9 = trunc i32 %a.9.in to i8
  %temp644 = insertelement <16 x i8> undef, i8 %a.9, i32 0
  %vector645 = shufflevector <16 x i8> %temp644, <16 x i8> undef, <16 x i32> zeroinitializer
  %839 = icmp eq <16 x i32> %835, zeroinitializer
  %840 = and <16 x i32> %836, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %841 = lshr <16 x i8> %temp.vect643, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %842 = lshr <16 x i8> %temp.vect643, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %843 = and <16 x i32> %837, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %844 = select <16 x i1> %838, <16 x i8> zeroinitializer, <16 x i8> %vector645
  %845 = select <16 x i1> %839, <16 x i8> zeroinitializer, <16 x i8> %vector647
  %a.9.1 = trunc i32 %a.9.in.1 to i8
  %temp649 = insertelement <16 x i8> undef, i8 %a.9.1, i32 0
  %vector650 = shufflevector <16 x i8> %temp649, <16 x i8> undef, <16 x i32> zeroinitializer
  %846 = icmp eq <16 x i32> %840, zeroinitializer
  %847 = zext <16 x i8> %841 to <16 x i32>
  %848 = zext <16 x i8> %842 to <16 x i32>
  %849 = icmp eq <16 x i32> %843, zeroinitializer
  %a.9.2 = trunc i32 %a.9.in.2 to i8
  %temp651 = insertelement <16 x i8> undef, i8 %a.9.2, i32 0
  %vector652 = shufflevector <16 x i8> %temp651, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..1648 = xor <16 x i8> %844, %845
  %850 = select <16 x i1> %846, <16 x i8> zeroinitializer, <16 x i8> %vector650
  %851 = and <16 x i32> %847, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %852 = lshr <16 x i8> %temp.vect643, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %853 = and i32 %a.9.in.5, 128
  %854 = and <16 x i32> %848, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %855 = select <16 x i1> %849, <16 x i8> zeroinitializer, <16 x i8> %vector652
  %p.9..2653 = xor <16 x i8> %850, %p.9..1648
  %a.9.3 = trunc i32 %a.9.in.3 to i8
  %temp655 = insertelement <16 x i8> undef, i8 %a.9.3, i32 0
  %vector656 = shufflevector <16 x i8> %temp655, <16 x i8> undef, <16 x i32> zeroinitializer
  %856 = icmp eq <16 x i32> %851, zeroinitializer
  %857 = zext <16 x i8> %852 to <16 x i32>
  %858 = icmp eq i32 %853, 0
  %859 = xor i32 %828, 27
  %860 = icmp eq <16 x i32> %854, zeroinitializer
  %a.9.4 = trunc i32 %a.9.in.4 to i8
  %temp657 = insertelement <16 x i8> undef, i8 %a.9.4, i32 0
  %vector658 = shufflevector <16 x i8> %temp657, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..3654 = xor <16 x i8> %855, %p.9..2653
  %861 = select <16 x i1> %856, <16 x i8> zeroinitializer, <16 x i8> %vector656
  %862 = and <16 x i32> %857, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.9.in.6 = select i1 %858, i32 %828, i32 %859
  %863 = select <16 x i1> %860, <16 x i8> zeroinitializer, <16 x i8> %vector658
  %p.9..4659 = xor <16 x i8> %861, %p.9..3654
  %a.9.5 = trunc i32 %a.9.in.5 to i8
  %temp661 = insertelement <16 x i8> undef, i8 %a.9.5, i32 0
  %vector662 = shufflevector <16 x i8> %temp661, <16 x i8> undef, <16 x i32> zeroinitializer
  %864 = icmp eq <16 x i32> %862, zeroinitializer
  %865 = icmp sgt <16 x i8> %temp.vect643, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.9.6 = trunc i32 %a.9.in.6 to i8
  %temp663 = insertelement <16 x i8> undef, i8 %a.9.6, i32 0
  %vector664 = shufflevector <16 x i8> %temp663, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..5660 = xor <16 x i8> %863, %p.9..4659
  %866 = select <16 x i1> %864, <16 x i8> zeroinitializer, <16 x i8> %vector662
  %867 = select <16 x i1> %865, <16 x i8> zeroinitializer, <16 x i8> %vector664
  %p.9..6665 = xor <16 x i8> %866, %p.9..5660
  %p.9..7666 = xor <16 x i8> %867, %p.9..6665
  %868 = and i64 %tmp77, 3
  %869 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1643, i64 0, i64 %868
  %870 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1679, i64 0, i64 %868
  %871 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1715, i64 0, i64 %868
  %872 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1751, i64 0, i64 %868
  %873 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1787, i64 0, i64 %868
  %874 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1823, i64 0, i64 %868
  %875 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1859, i64 0, i64 %868
  %876 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1895, i64 0, i64 %868
  %877 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1931, i64 0, i64 %868
  %878 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1967, i64 0, i64 %868
  %879 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2003, i64 0, i64 %868
  %880 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2039, i64 0, i64 %868
  %881 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2075, i64 0, i64 %868
  %882 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2111, i64 0, i64 %868
  %883 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2147, i64 0, i64 %868
  %884 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2183, i64 0, i64 %868
  %885 = load <4 x i8>* %869, align 4
  %886 = load <4 x i8>* %870, align 4
  %887 = load <4 x i8>* %871, align 4
  %888 = load <4 x i8>* %872, align 4
  %889 = load <4 x i8>* %873, align 4
  %890 = load <4 x i8>* %874, align 4
  %891 = load <4 x i8>* %875, align 4
  %892 = load <4 x i8>* %876, align 4
  %893 = load <4 x i8>* %877, align 4
  %894 = load <4 x i8>* %878, align 4
  %895 = load <4 x i8>* %879, align 4
  %896 = load <4 x i8>* %880, align 4
  %897 = load <4 x i8>* %881, align 4
  %898 = load <4 x i8>* %882, align 4
  %899 = load <4 x i8>* %883, align 4
  %900 = load <4 x i8>* %884, align 4
  %901 = extractelement <4 x i8> %885, i32 0
  %902 = extractelement <4 x i8> %886, i32 0
  %903 = extractelement <4 x i8> %887, i32 0
  %904 = extractelement <4 x i8> %888, i32 0
  %905 = extractelement <4 x i8> %889, i32 0
  %906 = extractelement <4 x i8> %890, i32 0
  %907 = extractelement <4 x i8> %891, i32 0
  %908 = extractelement <4 x i8> %892, i32 0
  %909 = extractelement <4 x i8> %893, i32 0
  %910 = extractelement <4 x i8> %894, i32 0
  %911 = extractelement <4 x i8> %895, i32 0
  %912 = extractelement <4 x i8> %896, i32 0
  %913 = extractelement <4 x i8> %897, i32 0
  %914 = extractelement <4 x i8> %898, i32 0
  %915 = extractelement <4 x i8> %899, i32 0
  %916 = extractelement <4 x i8> %900, i32 0
  %temp.vect667 = insertelement <16 x i8> undef, i8 %901, i32 0
  %temp.vect668 = insertelement <16 x i8> %temp.vect667, i8 %902, i32 1
  %temp.vect669 = insertelement <16 x i8> %temp.vect668, i8 %903, i32 2
  %temp.vect670 = insertelement <16 x i8> %temp.vect669, i8 %904, i32 3
  %temp.vect671 = insertelement <16 x i8> %temp.vect670, i8 %905, i32 4
  %temp.vect672 = insertelement <16 x i8> %temp.vect671, i8 %906, i32 5
  %temp.vect673 = insertelement <16 x i8> %temp.vect672, i8 %907, i32 6
  %temp.vect674 = insertelement <16 x i8> %temp.vect673, i8 %908, i32 7
  %temp.vect675 = insertelement <16 x i8> %temp.vect674, i8 %909, i32 8
  %temp.vect676 = insertelement <16 x i8> %temp.vect675, i8 %910, i32 9
  %temp.vect677 = insertelement <16 x i8> %temp.vect676, i8 %911, i32 10
  %temp.vect678 = insertelement <16 x i8> %temp.vect677, i8 %912, i32 11
  %temp.vect679 = insertelement <16 x i8> %temp.vect678, i8 %913, i32 12
  %temp.vect680 = insertelement <16 x i8> %temp.vect679, i8 %914, i32 13
  %temp.vect681 = insertelement <16 x i8> %temp.vect680, i8 %915, i32 14
  %temp.vect682 = insertelement <16 x i8> %temp.vect681, i8 %916, i32 15
  %917 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar78 = extractelement <4 x i8> %917, i32 1
  %temp685 = insertelement <16 x i8> undef, i8 %scalar78, i32 0
  %vector686 = shufflevector <16 x i8> %temp685, <16 x i8> undef, <16 x i32> zeroinitializer
  %918 = zext i8 %scalar78 to i32
  %919 = shl i32 %918, 1
  %920 = and i32 %918, 128
  %921 = xor i32 %919, 27
  %922 = icmp eq i32 %920, 0
  %a.11.in = select i1 %922, i32 %919, i32 %921
  %923 = shl i32 %a.11.in, 1
  %924 = and i32 %a.11.in, 128
  %925 = xor i32 %923, 27
  %926 = icmp eq i32 %924, 0
  %a.11.in.1 = select i1 %926, i32 %923, i32 %925
  %927 = shl i32 %a.11.in.1, 1
  %928 = and i32 %a.11.in.1, 128
  %929 = xor i32 %927, 27
  %930 = icmp eq i32 %928, 0
  %a.11.in.2 = select i1 %930, i32 %927, i32 %929
  %931 = shl i32 %a.11.in.2, 1
  %932 = and i32 %a.11.in.2, 128
  %933 = xor i32 %931, 27
  %934 = icmp eq i32 %932, 0
  %a.11.in.3 = select i1 %934, i32 %931, i32 %933
  %935 = shl i32 %a.11.in.3, 1
  %936 = and i32 %a.11.in.3, 128
  %937 = xor i32 %935, 27
  %938 = icmp eq i32 %936, 0
  %a.11.in.4 = select i1 %938, i32 %935, i32 %937
  %939 = shl i32 %a.11.in.4, 1
  %940 = and i32 %a.11.in.4, 128
  %941 = xor i32 %939, 27
  %942 = icmp eq i32 %940, 0
  %a.11.in.5 = select i1 %942, i32 %939, i32 %941
  %943 = shl i32 %a.11.in.5, 1
  %944 = lshr <16 x i8> %temp.vect682, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %945 = zext <16 x i8> %944 to <16 x i32>
  %946 = zext <16 x i8> %temp.vect682 to <16 x i32>
  %947 = lshr <16 x i8> %temp.vect682, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %948 = lshr <16 x i8> %temp.vect682, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %949 = and <16 x i32> %945, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %950 = and <16 x i32> %946, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %951 = zext <16 x i8> %947 to <16 x i32>
  %952 = zext <16 x i8> %948 to <16 x i32>
  %953 = icmp eq <16 x i32> %949, zeroinitializer
  %a.11 = trunc i32 %a.11.in to i8
  %temp683 = insertelement <16 x i8> undef, i8 %a.11, i32 0
  %vector684 = shufflevector <16 x i8> %temp683, <16 x i8> undef, <16 x i32> zeroinitializer
  %954 = icmp eq <16 x i32> %950, zeroinitializer
  %955 = and <16 x i32> %951, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %956 = lshr <16 x i8> %temp.vect682, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %957 = lshr <16 x i8> %temp.vect682, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %958 = and <16 x i32> %952, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %959 = select <16 x i1> %953, <16 x i8> zeroinitializer, <16 x i8> %vector684
  %960 = select <16 x i1> %954, <16 x i8> zeroinitializer, <16 x i8> %vector686
  %a.11.1 = trunc i32 %a.11.in.1 to i8
  %temp688 = insertelement <16 x i8> undef, i8 %a.11.1, i32 0
  %vector689 = shufflevector <16 x i8> %temp688, <16 x i8> undef, <16 x i32> zeroinitializer
  %961 = icmp eq <16 x i32> %955, zeroinitializer
  %962 = zext <16 x i8> %956 to <16 x i32>
  %963 = zext <16 x i8> %957 to <16 x i32>
  %964 = icmp eq <16 x i32> %958, zeroinitializer
  %a.11.2 = trunc i32 %a.11.in.2 to i8
  %temp690 = insertelement <16 x i8> undef, i8 %a.11.2, i32 0
  %vector691 = shufflevector <16 x i8> %temp690, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..1687 = xor <16 x i8> %959, %960
  %965 = select <16 x i1> %961, <16 x i8> zeroinitializer, <16 x i8> %vector689
  %966 = and <16 x i32> %962, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %967 = lshr <16 x i8> %temp.vect682, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %968 = and i32 %a.11.in.5, 128
  %969 = and <16 x i32> %963, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %970 = select <16 x i1> %964, <16 x i8> zeroinitializer, <16 x i8> %vector691
  %p.11..2692 = xor <16 x i8> %965, %p.11..1687
  %a.11.3 = trunc i32 %a.11.in.3 to i8
  %temp694 = insertelement <16 x i8> undef, i8 %a.11.3, i32 0
  %vector695 = shufflevector <16 x i8> %temp694, <16 x i8> undef, <16 x i32> zeroinitializer
  %971 = icmp eq <16 x i32> %966, zeroinitializer
  %972 = zext <16 x i8> %967 to <16 x i32>
  %973 = icmp eq i32 %968, 0
  %974 = xor i32 %943, 27
  %975 = icmp eq <16 x i32> %969, zeroinitializer
  %a.11.4 = trunc i32 %a.11.in.4 to i8
  %temp696 = insertelement <16 x i8> undef, i8 %a.11.4, i32 0
  %vector697 = shufflevector <16 x i8> %temp696, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..3693 = xor <16 x i8> %970, %p.11..2692
  %976 = select <16 x i1> %971, <16 x i8> zeroinitializer, <16 x i8> %vector695
  %977 = and <16 x i32> %972, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.11.in.6 = select i1 %973, i32 %943, i32 %974
  %978 = select <16 x i1> %975, <16 x i8> zeroinitializer, <16 x i8> %vector697
  %p.11..4698 = xor <16 x i8> %976, %p.11..3693
  %a.11.5 = trunc i32 %a.11.in.5 to i8
  %temp700 = insertelement <16 x i8> undef, i8 %a.11.5, i32 0
  %vector701 = shufflevector <16 x i8> %temp700, <16 x i8> undef, <16 x i32> zeroinitializer
  %979 = icmp eq <16 x i32> %977, zeroinitializer
  %980 = icmp sgt <16 x i8> %temp.vect682, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.11.6 = trunc i32 %a.11.in.6 to i8
  %temp702 = insertelement <16 x i8> undef, i8 %a.11.6, i32 0
  %vector703 = shufflevector <16 x i8> %temp702, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..5699 = xor <16 x i8> %978, %p.11..4698
  %981 = select <16 x i1> %979, <16 x i8> zeroinitializer, <16 x i8> %vector701
  %982 = select <16 x i1> %980, <16 x i8> zeroinitializer, <16 x i8> %vector703
  %p.11..6704 = xor <16 x i8> %981, %p.11..5699
  %p.11..7705 = xor <16 x i8> %982, %p.11..6704
  %983 = and i64 %tmp77, 3
  %984 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1639, i64 0, i64 %983
  %985 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1675, i64 0, i64 %983
  %986 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1711, i64 0, i64 %983
  %987 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1747, i64 0, i64 %983
  %988 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1783, i64 0, i64 %983
  %989 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1819, i64 0, i64 %983
  %990 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1855, i64 0, i64 %983
  %991 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1891, i64 0, i64 %983
  %992 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1927, i64 0, i64 %983
  %993 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1963, i64 0, i64 %983
  %994 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1999, i64 0, i64 %983
  %995 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2035, i64 0, i64 %983
  %996 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2071, i64 0, i64 %983
  %997 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2107, i64 0, i64 %983
  %998 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2143, i64 0, i64 %983
  %999 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2179, i64 0, i64 %983
  %1000 = load <4 x i8>* %984, align 4
  %1001 = load <4 x i8>* %985, align 4
  %1002 = load <4 x i8>* %986, align 4
  %1003 = load <4 x i8>* %987, align 4
  %1004 = load <4 x i8>* %988, align 4
  %1005 = load <4 x i8>* %989, align 4
  %1006 = load <4 x i8>* %990, align 4
  %1007 = load <4 x i8>* %991, align 4
  %1008 = load <4 x i8>* %992, align 4
  %1009 = load <4 x i8>* %993, align 4
  %1010 = load <4 x i8>* %994, align 4
  %1011 = load <4 x i8>* %995, align 4
  %1012 = load <4 x i8>* %996, align 4
  %1013 = load <4 x i8>* %997, align 4
  %1014 = load <4 x i8>* %998, align 4
  %1015 = load <4 x i8>* %999, align 4
  %1016 = extractelement <4 x i8> %1000, i32 0
  %1017 = extractelement <4 x i8> %1001, i32 0
  %1018 = extractelement <4 x i8> %1002, i32 0
  %1019 = extractelement <4 x i8> %1003, i32 0
  %1020 = extractelement <4 x i8> %1004, i32 0
  %1021 = extractelement <4 x i8> %1005, i32 0
  %1022 = extractelement <4 x i8> %1006, i32 0
  %1023 = extractelement <4 x i8> %1007, i32 0
  %1024 = extractelement <4 x i8> %1008, i32 0
  %1025 = extractelement <4 x i8> %1009, i32 0
  %1026 = extractelement <4 x i8> %1010, i32 0
  %1027 = extractelement <4 x i8> %1011, i32 0
  %1028 = extractelement <4 x i8> %1012, i32 0
  %1029 = extractelement <4 x i8> %1013, i32 0
  %1030 = extractelement <4 x i8> %1014, i32 0
  %1031 = extractelement <4 x i8> %1015, i32 0
  %temp.vect706 = insertelement <16 x i8> undef, i8 %1016, i32 0
  %temp.vect707 = insertelement <16 x i8> %temp.vect706, i8 %1017, i32 1
  %temp.vect708 = insertelement <16 x i8> %temp.vect707, i8 %1018, i32 2
  %temp.vect709 = insertelement <16 x i8> %temp.vect708, i8 %1019, i32 3
  %temp.vect710 = insertelement <16 x i8> %temp.vect709, i8 %1020, i32 4
  %temp.vect711 = insertelement <16 x i8> %temp.vect710, i8 %1021, i32 5
  %temp.vect712 = insertelement <16 x i8> %temp.vect711, i8 %1022, i32 6
  %temp.vect713 = insertelement <16 x i8> %temp.vect712, i8 %1023, i32 7
  %temp.vect714 = insertelement <16 x i8> %temp.vect713, i8 %1024, i32 8
  %temp.vect715 = insertelement <16 x i8> %temp.vect714, i8 %1025, i32 9
  %temp.vect716 = insertelement <16 x i8> %temp.vect715, i8 %1026, i32 10
  %temp.vect717 = insertelement <16 x i8> %temp.vect716, i8 %1027, i32 11
  %temp.vect718 = insertelement <16 x i8> %temp.vect717, i8 %1028, i32 12
  %temp.vect719 = insertelement <16 x i8> %temp.vect718, i8 %1029, i32 13
  %temp.vect720 = insertelement <16 x i8> %temp.vect719, i8 %1030, i32 14
  %temp.vect721 = insertelement <16 x i8> %temp.vect720, i8 %1031, i32 15
  %1032 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar87 = extractelement <4 x i8> %1032, i32 2
  %temp724 = insertelement <16 x i8> undef, i8 %scalar87, i32 0
  %vector725 = shufflevector <16 x i8> %temp724, <16 x i8> undef, <16 x i32> zeroinitializer
  %1033 = zext i8 %scalar87 to i32
  %1034 = shl i32 %1033, 1
  %1035 = and i32 %1033, 128
  %1036 = xor i32 %1034, 27
  %1037 = icmp eq i32 %1035, 0
  %a.13.in = select i1 %1037, i32 %1034, i32 %1036
  %1038 = shl i32 %a.13.in, 1
  %1039 = and i32 %a.13.in, 128
  %1040 = xor i32 %1038, 27
  %1041 = icmp eq i32 %1039, 0
  %a.13.in.1 = select i1 %1041, i32 %1038, i32 %1040
  %1042 = shl i32 %a.13.in.1, 1
  %1043 = and i32 %a.13.in.1, 128
  %1044 = xor i32 %1042, 27
  %1045 = icmp eq i32 %1043, 0
  %a.13.in.2 = select i1 %1045, i32 %1042, i32 %1044
  %1046 = shl i32 %a.13.in.2, 1
  %1047 = and i32 %a.13.in.2, 128
  %1048 = xor i32 %1046, 27
  %1049 = icmp eq i32 %1047, 0
  %a.13.in.3 = select i1 %1049, i32 %1046, i32 %1048
  %1050 = shl i32 %a.13.in.3, 1
  %1051 = and i32 %a.13.in.3, 128
  %1052 = xor i32 %1050, 27
  %1053 = icmp eq i32 %1051, 0
  %a.13.in.4 = select i1 %1053, i32 %1050, i32 %1052
  %1054 = shl i32 %a.13.in.4, 1
  %1055 = and i32 %a.13.in.4, 128
  %1056 = xor i32 %1054, 27
  %1057 = icmp eq i32 %1055, 0
  %a.13.in.5 = select i1 %1057, i32 %1054, i32 %1056
  %1058 = shl i32 %a.13.in.5, 1
  %1059 = lshr <16 x i8> %temp.vect721, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %1060 = zext <16 x i8> %1059 to <16 x i32>
  %1061 = zext <16 x i8> %temp.vect721 to <16 x i32>
  %1062 = lshr <16 x i8> %temp.vect721, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %1063 = lshr <16 x i8> %temp.vect721, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %1064 = and <16 x i32> %1060, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1065 = and <16 x i32> %1061, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1066 = zext <16 x i8> %1062 to <16 x i32>
  %1067 = zext <16 x i8> %1063 to <16 x i32>
  %1068 = icmp eq <16 x i32> %1064, zeroinitializer
  %a.13 = trunc i32 %a.13.in to i8
  %temp722 = insertelement <16 x i8> undef, i8 %a.13, i32 0
  %vector723 = shufflevector <16 x i8> %temp722, <16 x i8> undef, <16 x i32> zeroinitializer
  %1069 = icmp eq <16 x i32> %1065, zeroinitializer
  %1070 = and <16 x i32> %1066, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1071 = lshr <16 x i8> %temp.vect721, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1072 = lshr <16 x i8> %temp.vect721, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1073 = and <16 x i32> %1067, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1074 = select <16 x i1> %1068, <16 x i8> zeroinitializer, <16 x i8> %vector723
  %1075 = select <16 x i1> %1069, <16 x i8> zeroinitializer, <16 x i8> %vector725
  %a.13.1 = trunc i32 %a.13.in.1 to i8
  %temp727 = insertelement <16 x i8> undef, i8 %a.13.1, i32 0
  %vector728 = shufflevector <16 x i8> %temp727, <16 x i8> undef, <16 x i32> zeroinitializer
  %1076 = icmp eq <16 x i32> %1070, zeroinitializer
  %1077 = zext <16 x i8> %1071 to <16 x i32>
  %1078 = zext <16 x i8> %1072 to <16 x i32>
  %1079 = icmp eq <16 x i32> %1073, zeroinitializer
  %a.13.2 = trunc i32 %a.13.in.2 to i8
  %temp729 = insertelement <16 x i8> undef, i8 %a.13.2, i32 0
  %vector730 = shufflevector <16 x i8> %temp729, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..1726 = xor <16 x i8> %1074, %1075
  %1080 = select <16 x i1> %1076, <16 x i8> zeroinitializer, <16 x i8> %vector728
  %1081 = and <16 x i32> %1077, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1082 = lshr <16 x i8> %temp.vect721, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1083 = and i32 %a.13.in.5, 128
  %1084 = and <16 x i32> %1078, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1085 = select <16 x i1> %1079, <16 x i8> zeroinitializer, <16 x i8> %vector730
  %p.13..2731 = xor <16 x i8> %1080, %p.13..1726
  %a.13.3 = trunc i32 %a.13.in.3 to i8
  %temp733 = insertelement <16 x i8> undef, i8 %a.13.3, i32 0
  %vector734 = shufflevector <16 x i8> %temp733, <16 x i8> undef, <16 x i32> zeroinitializer
  %1086 = icmp eq <16 x i32> %1081, zeroinitializer
  %1087 = zext <16 x i8> %1082 to <16 x i32>
  %1088 = icmp eq i32 %1083, 0
  %1089 = xor i32 %1058, 27
  %1090 = icmp eq <16 x i32> %1084, zeroinitializer
  %a.13.4 = trunc i32 %a.13.in.4 to i8
  %temp735 = insertelement <16 x i8> undef, i8 %a.13.4, i32 0
  %vector736 = shufflevector <16 x i8> %temp735, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..3732 = xor <16 x i8> %1085, %p.13..2731
  %1091 = select <16 x i1> %1086, <16 x i8> zeroinitializer, <16 x i8> %vector734
  %1092 = and <16 x i32> %1087, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.13.in.6 = select i1 %1088, i32 %1058, i32 %1089
  %1093 = select <16 x i1> %1090, <16 x i8> zeroinitializer, <16 x i8> %vector736
  %p.13..4737 = xor <16 x i8> %1091, %p.13..3732
  %a.13.5 = trunc i32 %a.13.in.5 to i8
  %temp739 = insertelement <16 x i8> undef, i8 %a.13.5, i32 0
  %vector740 = shufflevector <16 x i8> %temp739, <16 x i8> undef, <16 x i32> zeroinitializer
  %1094 = icmp eq <16 x i32> %1092, zeroinitializer
  %1095 = icmp sgt <16 x i8> %temp.vect721, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.13.6 = trunc i32 %a.13.in.6 to i8
  %temp741 = insertelement <16 x i8> undef, i8 %a.13.6, i32 0
  %vector742 = shufflevector <16 x i8> %temp741, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..5738 = xor <16 x i8> %1093, %p.13..4737
  %1096 = select <16 x i1> %1094, <16 x i8> zeroinitializer, <16 x i8> %vector740
  %1097 = select <16 x i1> %1095, <16 x i8> zeroinitializer, <16 x i8> %vector742
  %p.13..6743 = xor <16 x i8> %1096, %p.13..5738
  %p.13..7744 = xor <16 x i8> %1097, %p.13..6743
  %1098 = and i64 %tmp77, 3
  %1099 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1635, i64 0, i64 %1098
  %1100 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1671, i64 0, i64 %1098
  %1101 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1707, i64 0, i64 %1098
  %1102 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1743, i64 0, i64 %1098
  %1103 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1779, i64 0, i64 %1098
  %1104 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1815, i64 0, i64 %1098
  %1105 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1851, i64 0, i64 %1098
  %1106 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1887, i64 0, i64 %1098
  %1107 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1923, i64 0, i64 %1098
  %1108 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1959, i64 0, i64 %1098
  %1109 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1995, i64 0, i64 %1098
  %1110 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2031, i64 0, i64 %1098
  %1111 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2067, i64 0, i64 %1098
  %1112 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2103, i64 0, i64 %1098
  %1113 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2139, i64 0, i64 %1098
  %1114 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2175, i64 0, i64 %1098
  %1115 = load <4 x i8>* %1099, align 4
  %1116 = load <4 x i8>* %1100, align 4
  %1117 = load <4 x i8>* %1101, align 4
  %1118 = load <4 x i8>* %1102, align 4
  %1119 = load <4 x i8>* %1103, align 4
  %1120 = load <4 x i8>* %1104, align 4
  %1121 = load <4 x i8>* %1105, align 4
  %1122 = load <4 x i8>* %1106, align 4
  %1123 = load <4 x i8>* %1107, align 4
  %1124 = load <4 x i8>* %1108, align 4
  %1125 = load <4 x i8>* %1109, align 4
  %1126 = load <4 x i8>* %1110, align 4
  %1127 = load <4 x i8>* %1111, align 4
  %1128 = load <4 x i8>* %1112, align 4
  %1129 = load <4 x i8>* %1113, align 4
  %1130 = load <4 x i8>* %1114, align 4
  %1131 = extractelement <4 x i8> %1115, i32 0
  %1132 = extractelement <4 x i8> %1116, i32 0
  %1133 = extractelement <4 x i8> %1117, i32 0
  %1134 = extractelement <4 x i8> %1118, i32 0
  %1135 = extractelement <4 x i8> %1119, i32 0
  %1136 = extractelement <4 x i8> %1120, i32 0
  %1137 = extractelement <4 x i8> %1121, i32 0
  %1138 = extractelement <4 x i8> %1122, i32 0
  %1139 = extractelement <4 x i8> %1123, i32 0
  %1140 = extractelement <4 x i8> %1124, i32 0
  %1141 = extractelement <4 x i8> %1125, i32 0
  %1142 = extractelement <4 x i8> %1126, i32 0
  %1143 = extractelement <4 x i8> %1127, i32 0
  %1144 = extractelement <4 x i8> %1128, i32 0
  %1145 = extractelement <4 x i8> %1129, i32 0
  %1146 = extractelement <4 x i8> %1130, i32 0
  %temp.vect745 = insertelement <16 x i8> undef, i8 %1131, i32 0
  %temp.vect746 = insertelement <16 x i8> %temp.vect745, i8 %1132, i32 1
  %temp.vect747 = insertelement <16 x i8> %temp.vect746, i8 %1133, i32 2
  %temp.vect748 = insertelement <16 x i8> %temp.vect747, i8 %1134, i32 3
  %temp.vect749 = insertelement <16 x i8> %temp.vect748, i8 %1135, i32 4
  %temp.vect750 = insertelement <16 x i8> %temp.vect749, i8 %1136, i32 5
  %temp.vect751 = insertelement <16 x i8> %temp.vect750, i8 %1137, i32 6
  %temp.vect752 = insertelement <16 x i8> %temp.vect751, i8 %1138, i32 7
  %temp.vect753 = insertelement <16 x i8> %temp.vect752, i8 %1139, i32 8
  %temp.vect754 = insertelement <16 x i8> %temp.vect753, i8 %1140, i32 9
  %temp.vect755 = insertelement <16 x i8> %temp.vect754, i8 %1141, i32 10
  %temp.vect756 = insertelement <16 x i8> %temp.vect755, i8 %1142, i32 11
  %temp.vect757 = insertelement <16 x i8> %temp.vect756, i8 %1143, i32 12
  %temp.vect758 = insertelement <16 x i8> %temp.vect757, i8 %1144, i32 13
  %temp.vect759 = insertelement <16 x i8> %temp.vect758, i8 %1145, i32 14
  %temp.vect760 = insertelement <16 x i8> %temp.vect759, i8 %1146, i32 15
  %1147 = load <4 x i8> addrspace(3)* %scevgep, align 4
  %scalar96 = extractelement <4 x i8> %1147, i32 3
  %temp763 = insertelement <16 x i8> undef, i8 %scalar96, i32 0
  %vector764 = shufflevector <16 x i8> %temp763, <16 x i8> undef, <16 x i32> zeroinitializer
  %1148 = zext i8 %scalar96 to i32
  %1149 = shl i32 %1148, 1
  %1150 = and i32 %1148, 128
  %1151 = xor i32 %1149, 27
  %1152 = icmp eq i32 %1150, 0
  %a.15.in = select i1 %1152, i32 %1149, i32 %1151
  %1153 = shl i32 %a.15.in, 1
  %1154 = and i32 %a.15.in, 128
  %1155 = xor i32 %1153, 27
  %1156 = icmp eq i32 %1154, 0
  %a.15.in.1 = select i1 %1156, i32 %1153, i32 %1155
  %1157 = shl i32 %a.15.in.1, 1
  %1158 = and i32 %a.15.in.1, 128
  %1159 = xor i32 %1157, 27
  %1160 = icmp eq i32 %1158, 0
  %a.15.in.2 = select i1 %1160, i32 %1157, i32 %1159
  %1161 = shl i32 %a.15.in.2, 1
  %1162 = and i32 %a.15.in.2, 128
  %1163 = xor i32 %1161, 27
  %1164 = icmp eq i32 %1162, 0
  %a.15.in.3 = select i1 %1164, i32 %1161, i32 %1163
  %1165 = shl i32 %a.15.in.3, 1
  %1166 = and i32 %a.15.in.3, 128
  %1167 = xor i32 %1165, 27
  %1168 = icmp eq i32 %1166, 0
  %a.15.in.4 = select i1 %1168, i32 %1165, i32 %1167
  %1169 = shl i32 %a.15.in.4, 1
  %1170 = and i32 %a.15.in.4, 128
  %1171 = xor i32 %1169, 27
  %1172 = icmp eq i32 %1170, 0
  %a.15.in.5 = select i1 %1172, i32 %1169, i32 %1171
  %1173 = shl i32 %a.15.in.5, 1
  %1174 = lshr <16 x i8> %temp.vect760, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %1175 = zext <16 x i8> %1174 to <16 x i32>
  %1176 = zext <16 x i8> %temp.vect760 to <16 x i32>
  %1177 = lshr <16 x i8> %temp.vect760, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %1178 = lshr <16 x i8> %temp.vect760, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %1179 = and <16 x i32> %1175, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1180 = and <16 x i32> %1176, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1181 = zext <16 x i8> %1177 to <16 x i32>
  %1182 = zext <16 x i8> %1178 to <16 x i32>
  %1183 = icmp eq <16 x i32> %1179, zeroinitializer
  %a.15 = trunc i32 %a.15.in to i8
  %temp761 = insertelement <16 x i8> undef, i8 %a.15, i32 0
  %vector762 = shufflevector <16 x i8> %temp761, <16 x i8> undef, <16 x i32> zeroinitializer
  %1184 = icmp eq <16 x i32> %1180, zeroinitializer
  %1185 = and <16 x i32> %1181, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1186 = lshr <16 x i8> %temp.vect760, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1187 = lshr <16 x i8> %temp.vect760, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1188 = and <16 x i32> %1182, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1189 = select <16 x i1> %1183, <16 x i8> zeroinitializer, <16 x i8> %vector762
  %1190 = select <16 x i1> %1184, <16 x i8> zeroinitializer, <16 x i8> %vector764
  %a.15.1 = trunc i32 %a.15.in.1 to i8
  %temp766 = insertelement <16 x i8> undef, i8 %a.15.1, i32 0
  %vector767 = shufflevector <16 x i8> %temp766, <16 x i8> undef, <16 x i32> zeroinitializer
  %1191 = icmp eq <16 x i32> %1185, zeroinitializer
  %1192 = zext <16 x i8> %1186 to <16 x i32>
  %1193 = zext <16 x i8> %1187 to <16 x i32>
  %1194 = icmp eq <16 x i32> %1188, zeroinitializer
  %a.15.2 = trunc i32 %a.15.in.2 to i8
  %temp768 = insertelement <16 x i8> undef, i8 %a.15.2, i32 0
  %vector769 = shufflevector <16 x i8> %temp768, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..1765 = xor <16 x i8> %1189, %1190
  %1195 = select <16 x i1> %1191, <16 x i8> zeroinitializer, <16 x i8> %vector767
  %1196 = and <16 x i32> %1192, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1197 = lshr <16 x i8> %temp.vect760, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1198 = and i32 %a.15.in.5, 128
  %1199 = and <16 x i32> %1193, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1200 = select <16 x i1> %1194, <16 x i8> zeroinitializer, <16 x i8> %vector769
  %p.15..2770 = xor <16 x i8> %1195, %p.15..1765
  %a.15.3 = trunc i32 %a.15.in.3 to i8
  %temp772 = insertelement <16 x i8> undef, i8 %a.15.3, i32 0
  %vector773 = shufflevector <16 x i8> %temp772, <16 x i8> undef, <16 x i32> zeroinitializer
  %1201 = icmp eq <16 x i32> %1196, zeroinitializer
  %1202 = zext <16 x i8> %1197 to <16 x i32>
  %1203 = icmp eq i32 %1198, 0
  %1204 = xor i32 %1173, 27
  %1205 = icmp eq <16 x i32> %1199, zeroinitializer
  %a.15.4 = trunc i32 %a.15.in.4 to i8
  %temp774 = insertelement <16 x i8> undef, i8 %a.15.4, i32 0
  %vector775 = shufflevector <16 x i8> %temp774, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..3771 = xor <16 x i8> %1200, %p.15..2770
  %1206 = select <16 x i1> %1201, <16 x i8> zeroinitializer, <16 x i8> %vector773
  %1207 = and <16 x i32> %1202, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.15.in.6 = select i1 %1203, i32 %1173, i32 %1204
  %1208 = select <16 x i1> %1205, <16 x i8> zeroinitializer, <16 x i8> %vector775
  %p.15..4776 = xor <16 x i8> %1206, %p.15..3771
  %a.15.5 = trunc i32 %a.15.in.5 to i8
  %temp778 = insertelement <16 x i8> undef, i8 %a.15.5, i32 0
  %vector779 = shufflevector <16 x i8> %temp778, <16 x i8> undef, <16 x i32> zeroinitializer
  %1209 = icmp eq <16 x i32> %1207, zeroinitializer
  %1210 = icmp sgt <16 x i8> %temp.vect760, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.15.6 = trunc i32 %a.15.in.6 to i8
  %temp780 = insertelement <16 x i8> undef, i8 %a.15.6, i32 0
  %vector781 = shufflevector <16 x i8> %temp780, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..5777 = xor <16 x i8> %1208, %p.15..4776
  %1211 = select <16 x i1> %1209, <16 x i8> zeroinitializer, <16 x i8> %vector779
  %1212 = select <16 x i1> %1210, <16 x i8> zeroinitializer, <16 x i8> %vector781
  %p.15..6782 = xor <16 x i8> %1211, %p.15..5777
  %p.15..7783 = xor <16 x i8> %1212, %p.15..6782
  %1213 = xor <16 x i8> %p.9..7666, %vectorPHI627
  store <16 x i8> %1213, <16 x i8>* %CastToValueType1575, align 16
  %1214 = xor <16 x i8> %p.11..7705, %vectorPHI626
  store <16 x i8> %1214, <16 x i8>* %CastToValueType1589, align 16
  %1215 = xor <16 x i8> %p.13..7744, %vectorPHI625
  store <16 x i8> %1215, <16 x i8>* %CastToValueType1603, align 16
  %1216 = xor <16 x i8> %p.15..7783, %vectorPHI624
  store <16 x i8> %1216, <16 x i8>* %CastToValueType1617, align 16
  %exitcond = icmp eq i64 %tmp, 3
  br i1 %exitcond, label %._crit_edge66, label %752

._crit_edge66:                                    ; preds = %752
  %"&(pSB[currWI].offset)1624" = add nuw i64 %CurrSBIndex..1, 1424
  %"&pSB[currWI].offset1625" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1624"
  %CastToValueType1626 = bitcast i8* %"&pSB[currWI].offset1625" to <16 x i8>*
  %loadedValue1627 = load <16 x i8>* %CastToValueType1626, align 16
  %extract847 = extractelement <16 x i8> %loadedValue1627, i32 15
  %"&(pSB[currWI].offset)1610" = add nuw i64 %CurrSBIndex..1, 1408
  %"&pSB[currWI].offset1611" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1610"
  %CastToValueType1612 = bitcast i8* %"&pSB[currWI].offset1611" to <16 x i8>*
  %loadedValue1613 = load <16 x i8>* %CastToValueType1612, align 16
  %extract831 = extractelement <16 x i8> %loadedValue1613, i32 15
  %"&(pSB[currWI].offset)1596" = add nuw i64 %CurrSBIndex..1, 1392
  %"&pSB[currWI].offset1597" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1596"
  %CastToValueType1598 = bitcast i8* %"&pSB[currWI].offset1597" to <16 x i8>*
  %loadedValue1599 = load <16 x i8>* %CastToValueType1598, align 16
  %extract815 = extractelement <16 x i8> %loadedValue1599, i32 15
  %"&(pSB[currWI].offset)1582" = add nuw i64 %CurrSBIndex..1, 1376
  %"&pSB[currWI].offset1583" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1582"
  %CastToValueType1584 = bitcast i8* %"&pSB[currWI].offset1583" to <16 x i8>*
  %loadedValue1585 = load <16 x i8>* %CastToValueType1584, align 16
  %extract799 = extractelement <16 x i8> %loadedValue1585, i32 15
  %1217 = insertelement <4 x i8> undef, i8 %extract799, i32 0
  %1218 = insertelement <4 x i8> %1217, i8 %extract815, i32 1
  %1219 = insertelement <4 x i8> %1218, i8 %extract831, i32 2
  %1220 = insertelement <4 x i8> %1219, i8 %extract847, i32 3
  %"&(pSB[currWI].offset)1018" = add nuw i64 %CurrSBIndex..1, 920
  %"&pSB[currWI].offset1019" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1018"
  %CastToValueType1020 = bitcast i8* %"&pSB[currWI].offset1019" to <4 x i8> addrspace(3)**
  %loadedValue1021 = load <4 x i8> addrspace(3)** %CastToValueType1020, align 8
  store <4 x i8> %1220, <4 x i8> addrspace(3)* %loadedValue1021, align 4
  %"&(pSB[currWI].offset)1469" = add nuw i64 %CurrSBIndex..1, 1140
  %"&pSB[currWI].offset1470" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1469"
  %CastToValueType1471 = bitcast i8* %"&pSB[currWI].offset1470" to i32*
  %loadedValue1472 = load i32* %CastToValueType1471, align 4
  %indvar.next80 = add i32 %loadedValue1472, 1
  %"&(pSB[currWI].offset)1629" = add nuw i64 %CurrSBIndex..1, 1440
  %"&pSB[currWI].offset1630" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1629"
  %CastToValueType1631 = bitcast i8* %"&pSB[currWI].offset1630" to i32*
  store i32 %indvar.next80, i32* %CastToValueType1631, align 4
  %"&(pSB[currWI].offset)1577" = add nuw i64 %CurrSBIndex..1, 1376
  %"&pSB[currWI].offset1578" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1577"
  %CastToValueType1579 = bitcast i8* %"&pSB[currWI].offset1578" to <16 x i8>*
  %loadedValue1580 = load <16 x i8>* %CastToValueType1579, align 16
  %"&(pSB[currWI].offset)1591" = add nuw i64 %CurrSBIndex..1, 1392
  %"&pSB[currWI].offset1592" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1591"
  %CastToValueType1593 = bitcast i8* %"&pSB[currWI].offset1592" to <16 x i8>*
  %loadedValue1594 = load <16 x i8>* %CastToValueType1593, align 16
  %"&(pSB[currWI].offset)1605" = add nuw i64 %CurrSBIndex..1, 1408
  %"&pSB[currWI].offset1606" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1605"
  %CastToValueType1607 = bitcast i8* %"&pSB[currWI].offset1606" to <16 x i8>*
  %loadedValue1608 = load <16 x i8>* %CastToValueType1607, align 16
  %"&(pSB[currWI].offset)1619" = add nuw i64 %CurrSBIndex..1, 1424
  %"&pSB[currWI].offset1620" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1619"
  %CastToValueType1621 = bitcast i8* %"&pSB[currWI].offset1620" to <16 x i8>*
  %loadedValue1622 = load <16 x i8>* %CastToValueType1621, align 16
  br label %159

"Barrier BB985":                                  ; preds = %shiftRowsInv.exit
  %"&(pSB[currWI].offset)1524" = add nuw i64 %CurrSBIndex..2, 1284
  %"&pSB[currWI].offset1525" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1524"
  %CastToValueType1526 = bitcast i8* %"&pSB[currWI].offset1525" to <4 x i8>*
  %loadedValue1527 = load <4 x i8>* %CastToValueType1526, align 4
  %1221 = extractelement <4 x i8> %loadedValue1527, i32 3
  %"&(pSB[currWI].offset)1529" = add nuw i64 %CurrSBIndex..2, 1284
  %"&pSB[currWI].offset1530" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1529"
  %CastToValueType1531 = bitcast i8* %"&pSB[currWI].offset1530" to <4 x i8>*
  %loadedValue1532 = load <4 x i8>* %CastToValueType1531, align 4
  %1222 = extractelement <4 x i8> %loadedValue1532, i32 2
  %"&(pSB[currWI].offset)1534" = add nuw i64 %CurrSBIndex..2, 1284
  %"&pSB[currWI].offset1535" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1534"
  %CastToValueType1536 = bitcast i8* %"&pSB[currWI].offset1535" to <4 x i8>*
  %loadedValue1537 = load <4 x i8>* %CastToValueType1536, align 4
  %1223 = extractelement <4 x i8> %loadedValue1537, i32 1
  %"&(pSB[currWI].offset)1539" = add nuw i64 %CurrSBIndex..2, 1284
  %"&pSB[currWI].offset1540" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1539"
  %CastToValueType1541 = bitcast i8* %"&pSB[currWI].offset1540" to <4 x i8>*
  %loadedValue1542 = load <4 x i8>* %CastToValueType1541, align 4
  %1224 = extractelement <4 x i8> %loadedValue1542, i32 0
  %"&(pSB[currWI].offset)1009" = add nuw i64 %CurrSBIndex..2, 912
  %"&pSB[currWI].offset1010" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1009"
  %CastToValueType1011 = bitcast i8* %"&pSB[currWI].offset1010" to i64*
  %loadedValue1012 = load i64* %CastToValueType1011, align 8
  %1225 = getelementptr inbounds <4 x i8> addrspace(1)* %roundKey, i64 %loadedValue1012
  %1226 = load <4 x i8> addrspace(1)* %1225, align 4
  %scalar101 = extractelement <4 x i8> %1226, i32 0
  %scalar102 = extractelement <4 x i8> %1226, i32 1
  %scalar103 = extractelement <4 x i8> %1226, i32 2
  %scalar104 = extractelement <4 x i8> %1226, i32 3
  %extract935 = xor i8 %1224, %scalar101
  %extract951 = xor i8 %1223, %scalar102
  %extract967 = xor i8 %1222, %scalar103
  %extract983 = xor i8 %1221, %scalar104
  %1227 = insertelement <4 x i8> undef, i8 %extract935, i32 0
  %1228 = insertelement <4 x i8> %1227, i8 %extract951, i32 1
  %1229 = insertelement <4 x i8> %1228, i8 %extract967, i32 2
  %1230 = insertelement <4 x i8> %1229, i8 %extract983, i32 3
  %"&(pSB[currWI].offset)1000" = add nuw i64 %CurrSBIndex..2, 904
  %"&pSB[currWI].offset1001" = getelementptr inbounds i8* %pSpecialBuf, i64 %"&(pSB[currWI].offset)1000"
  %CastToValueType1002 = bitcast i8* %"&pSB[currWI].offset1001" to i64*
  %loadedValue1003 = load i64* %CastToValueType1002, align 8
  %1231 = getelementptr inbounds <4 x i8> addrspace(1)* %output, i64 %loadedValue1003
  store <4 x i8> %1230, <4 x i8> addrspace(1)* %1231, align 4
  %check.WI.iter2224 = icmp ult i64 %CurrWI..2, %iterCount
  br i1 %check.WI.iter2224, label %thenBB2221, label %SyncBB2212

thenBB2221:                                       ; preds = %"Barrier BB985"
  %"CurrWI++2225" = add nuw i64 %CurrWI..2, 1
  %"loadedCurrSB+Stride2227" = add nuw i64 %CurrSBIndex..2, 1712
  %cond1 = icmp eq i32 %currBarrier.1, 8
  br i1 %cond1, label %SyncBB2211, label %SyncBB

SyncBB2212:                                       ; preds = %"Barrier BB985"
  ret void
}

define void @AESEncrypt(i8* %pBuffer) {
entry:
  %0 = bitcast i8* %pBuffer to <4 x i8> addrspace(1)**
  %1 = load <4 x i8> addrspace(1)** %0, align 8
  %2 = getelementptr i8* %pBuffer, i64 8
  %3 = bitcast i8* %2 to <4 x i8> addrspace(1)**
  %4 = load <4 x i8> addrspace(1)** %3, align 8
  %5 = getelementptr i8* %pBuffer, i64 16
  %6 = bitcast i8* %5 to <4 x i8> addrspace(1)**
  %7 = load <4 x i8> addrspace(1)** %6, align 8
  %8 = getelementptr i8* %pBuffer, i64 24
  %9 = bitcast i8* %8 to i8 addrspace(1)**
  %10 = load i8 addrspace(1)** %9, align 8
  %11 = getelementptr i8* %pBuffer, i64 32
  %12 = bitcast i8* %11 to <4 x i8> addrspace(3)**
  %13 = load <4 x i8> addrspace(3)** %12, align 8
  %14 = getelementptr i8* %pBuffer, i64 40
  %15 = bitcast i8* %14 to <4 x i8> addrspace(3)**
  %16 = load <4 x i8> addrspace(3)** %15, align 8
  %17 = getelementptr i8* %pBuffer, i64 48
  %18 = bitcast i8* %17 to i32*
  %19 = load i32* %18, align 4
  %20 = getelementptr i8* %pBuffer, i64 52
  %21 = bitcast i8* %20 to i32*
  %22 = load i32* %21, align 4
  %23 = getelementptr i8* %pBuffer, i64 72
  %24 = bitcast i8* %23 to i64**
  %25 = load i64** %24, align 8
  %26 = getelementptr i8* %pBuffer, i64 88
  %27 = bitcast i8* %26 to %struct.PaddedDimId**
  %28 = load %struct.PaddedDimId** %27, align 8
  %29 = getelementptr i8* %pBuffer, i64 104
  %30 = bitcast i8* %29 to i64*
  %31 = load i64* %30, align 8
  %32 = getelementptr i8* %pBuffer, i64 112
  %33 = bitcast i8* %32 to i8**
  %34 = load i8** %33, align 8
  %tmp81.i = icmp ugt i32 %22, 1
  %rounds.op.i = add i32 %22, -1
  %tmp82.i = select i1 %tmp81.i, i32 %rounds.op.i, i32 0
  %35 = shl i32 %22, 2
  br label %SyncBB343.i

SyncBB343.i:                                      ; preds = %thenBB354.i, %thenBB.i, %entry
  %CurrSBIndex..0.i = phi i64 [ 0, %entry ], [ %"loadedCurrSB+Stride360.i", %thenBB354.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ]
  %currBarrier.2.i = phi i32 [ 12, %entry ], [ %currBarrier.1.i, %thenBB354.i ], [ %currBarrier.1.i, %thenBB.i ]
  %CurrWI..0.i = phi i64 [ 0, %entry ], [ %"CurrWI++358.i", %thenBB354.i ], [ %"CurrWI++.i", %thenBB.i ]
  %36 = load i64* %25, align 8
  %37 = trunc i64 %36 to i32
  %38 = getelementptr i64* %25, i64 1
  %39 = load i64* %38, align 8
  %40 = trunc i64 %39 to i32
  %41 = getelementptr %struct.PaddedDimId* %28, i64 %CurrWI..0.i, i32 0, i64 1
  %42 = load i64* %41, align 8
  %43 = trunc i64 %42 to i32
  %"&pSB[currWI].offset.i" = getelementptr inbounds i8* %34, i64 %CurrSBIndex..0.i
  %CastToValueType.i = bitcast i8* %"&pSB[currWI].offset.i" to i32*
  store i32 %43, i32* %CastToValueType.i, align 4
  %44 = mul i32 %40, %19
  %45 = shl i32 %37, 2
  %46 = add i32 %44, %45
  %47 = and i32 %46, -4
  %48 = add i32 %47, %43
  %"&(pSB[currWI].offset)338.i" = add nuw i64 %CurrSBIndex..0.i, 112
  %"&pSB[currWI].offset339.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)338.i"
  %49 = bitcast i8* %"&pSB[currWI].offset339.i" to <4 x i8>*
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 16
  %"&pSB[currWI].offset335.sum.i" = add i64 %CurrSBIndex..0.i, 116
  %50 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset335.sum.i"
  %51 = bitcast i8* %50 to <4 x i8>*
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 4
  %"&pSB[currWI].offset331.sum.i" = add i64 %CurrSBIndex..0.i, 120
  %52 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset331.sum.i"
  %53 = bitcast i8* %52 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 8
  %"&pSB[currWI].offset327.sum.i" = add i64 %CurrSBIndex..0.i, 124
  %54 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset327.sum.i"
  %55 = bitcast i8* %54 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 4
  %56 = zext i32 %48 to i64
  %"&(pSB[currWI].offset)105.i" = add nuw i64 %CurrSBIndex..0.i, 8
  %"&pSB[currWI].offset106.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)105.i"
  %CastToValueType107.i = bitcast i8* %"&pSB[currWI].offset106.i" to i64*
  store i64 %56, i64* %CastToValueType107.i, align 8
  %57 = getelementptr inbounds <4 x i8> addrspace(1)* %4, i64 %56
  %58 = load <4 x i8> addrspace(1)* %57, align 4
  %59 = and i64 %42, 4294967295
  %60 = getelementptr inbounds <4 x i8> addrspace(3)* %13, i64 %59
  %"&(pSB[currWI].offset)114.i" = add nuw i64 %CurrSBIndex..0.i, 16
  %"&pSB[currWI].offset115.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)114.i"
  %CastToValueType116.i = bitcast i8* %"&pSB[currWI].offset115.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %60, <4 x i8> addrspace(3)** %CastToValueType116.i, align 8
  store <4 x i8> %58, <4 x i8> addrspace(3)* %60, align 4
  %61 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %59
  %62 = load <4 x i8> addrspace(1)* %61, align 4
  %63 = xor <4 x i8> %58, %62
  %"&(pSB[currWI].offset)128.i" = add nuw i64 %CurrSBIndex..0.i, 24
  %"&pSB[currWI].offset129.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)128.i"
  %CastToValueType130.i = bitcast i8* %"&pSB[currWI].offset129.i" to <4 x i8>*
  store <4 x i8> %63, <4 x i8>* %CastToValueType130.i, align 4
  store <4 x i8> %63, <4 x i8> addrspace(3)* %60, align 4
  %64 = sub i32 0, %43
  %65 = and i32 %64, 3
  %66 = zext i32 %65 to i64
  %"&(pSB[currWI].offset)322.i" = add nuw i64 %CurrSBIndex..0.i, 112
  %"&pSB[currWI].offset323.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)322.i"
  %CastToValueType324.i = bitcast i8* %"&pSB[currWI].offset323.i" to [4 x <4 x i8>]*
  %67 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType324.i, i64 0, i64 %66
  %"&(pSB[currWI].offset)132.i" = add nuw i64 %CurrSBIndex..0.i, 32
  %"&pSB[currWI].offset133.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)132.i"
  %CastToValueType134.i = bitcast i8* %"&pSB[currWI].offset133.i" to <4 x i8>**
  store <4 x i8>* %67, <4 x i8>** %CastToValueType134.i, align 8
  %68 = getelementptr inbounds <4 x i8> addrspace(3)* %16, i64 %59
  %"&(pSB[currWI].offset)156.i" = add nuw i64 %CurrSBIndex..0.i, 40
  %"&pSB[currWI].offset157.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)156.i"
  %CastToValueType158.i = bitcast i8* %"&pSB[currWI].offset157.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %68, <4 x i8> addrspace(3)** %CastToValueType158.i, align 8
  %tmp75.i = sub i64 1, %42
  %"&(pSB[currWI].offset)170.i" = add nuw i64 %CurrSBIndex..0.i, 48
  %"&pSB[currWI].offset171.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)170.i"
  %CastToValueType172.i = bitcast i8* %"&pSB[currWI].offset171.i" to i64*
  store i64 %tmp75.i, i64* %CastToValueType172.i, align 8
  %tmp86.i = add i32 %43, 4
  %"&(pSB[currWI].offset)179.i" = add nuw i64 %CurrSBIndex..0.i, 56
  %"&pSB[currWI].offset180.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)179.i"
  %CastToValueType181.i = bitcast i8* %"&pSB[currWI].offset180.i" to i32*
  store i32 %tmp86.i, i32* %CastToValueType181.i, align 4
  br label %69

; <label>:69                                      ; preds = %SyncBB344.i, %SyncBB343.i
  %CurrSBIndex..2.i = phi i64 [ %CurrSBIndex..0.i, %SyncBB343.i ], [ %CurrSBIndex..1.i, %SyncBB344.i ]
  %currBarrier.1.i = phi i32 [ %currBarrier.2.i, %SyncBB343.i ], [ %currBarrier.0.i, %SyncBB344.i ]
  %CurrWI..2.i = phi i64 [ %CurrWI..0.i, %SyncBB343.i ], [ %CurrWI..1.i, %SyncBB344.i ]
  %70 = phi <4 x i8> [ %63, %SyncBB343.i ], [ %671, %SyncBB344.i ]
  %indvar79.i = phi i32 [ 0, %SyncBB343.i ], [ %indvar.next80.i, %SyncBB344.i ]
  %"&(pSB[currWI].offset)188.i" = add nuw i64 %CurrSBIndex..2.i, 60
  %"&pSB[currWI].offset189.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)188.i"
  %CastToValueType190.i = bitcast i8* %"&pSB[currWI].offset189.i" to i32*
  store i32 %indvar79.i, i32* %CastToValueType190.i, align 4
  %tmp84.i = shl i32 %indvar79.i, 2
  %"&(pSB[currWI].offset)183.i" = add nuw i64 %CurrSBIndex..2.i, 56
  %"&pSB[currWI].offset184.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)183.i"
  %CastToValueType185.i = bitcast i8* %"&pSB[currWI].offset184.i" to i32*
  %loadedValue186.i = load i32* %CastToValueType185.i, align 4
  %tmp87.i = add i32 %loadedValue186.i, %tmp84.i
  %"&(pSB[currWI].offset)202.i" = add nuw i64 %CurrSBIndex..2.i, 64
  %"&pSB[currWI].offset203.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)202.i"
  %CastToValueType204.i = bitcast i8* %"&pSB[currWI].offset203.i" to i32*
  store i32 %tmp87.i, i32* %CastToValueType204.i, align 4
  %71 = bitcast <4 x i8> %70 to i32
  %tmp1.i.i = bitcast i32 %71 to <4 x i8>
  %72 = extractelement <4 x i8> %tmp1.i.i, i32 0
  %73 = zext i8 %72 to i64
  %74 = getelementptr inbounds i8 addrspace(1)* %10, i64 %73
  %75 = load i8 addrspace(1)* %74, align 1
  %76 = insertelement <4 x i8> undef, i8 %75, i32 0
  %77 = extractelement <4 x i8> %tmp1.i.i, i32 1
  %78 = zext i8 %77 to i64
  %79 = getelementptr inbounds i8 addrspace(1)* %10, i64 %78
  %80 = load i8 addrspace(1)* %79, align 1
  %81 = insertelement <4 x i8> %76, i8 %80, i32 1
  %82 = extractelement <4 x i8> %tmp1.i.i, i32 2
  %83 = zext i8 %82 to i64
  %84 = getelementptr inbounds i8 addrspace(1)* %10, i64 %83
  %85 = load i8 addrspace(1)* %84, align 1
  %86 = insertelement <4 x i8> %81, i8 %85, i32 2
  %87 = extractelement <4 x i8> %tmp1.i.i, i32 3
  %88 = zext i8 %87 to i64
  %89 = getelementptr inbounds i8 addrspace(1)* %10, i64 %88
  %90 = load i8 addrspace(1)* %89, align 1
  %91 = insertelement <4 x i8> %86, i8 %90, i32 3
  %92 = bitcast <4 x i8> %91 to i32
  %tmp7.i = bitcast i32 %92 to <4 x i8>
  %93 = bitcast <4 x i8> %tmp7.i to i32
  %tmp1.i88.i = bitcast i32 %93 to <4 x i8>
  %"&(pSB[currWI].offset)211.i" = add nuw i64 %CurrSBIndex..2.i, 68
  %"&pSB[currWI].offset212.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)211.i"
  %CastToValueType213.i = bitcast i8* %"&pSB[currWI].offset212.i" to <4 x i8>*
  store <4 x i8> %tmp1.i88.i, <4 x i8>* %CastToValueType213.i, align 4
  %"&pSB[currWI].offset96.i" = getelementptr inbounds i8* %34, i64 %CurrSBIndex..2.i
  %CastToValueType97.i = bitcast i8* %"&pSB[currWI].offset96.i" to i32*
  %loadedValue98.i = load i32* %CastToValueType97.i, align 4
  %94 = icmp eq i32 %loadedValue98.i, 0
  br i1 %94, label %shiftRows.exit.i, label %bb.nph.i.preheader.i

bb.nph.i.preheader.i:                             ; preds = %69
  %"&(pSB[currWI].offset)215.i" = add nuw i64 %CurrSBIndex..2.i, 68
  %"&pSB[currWI].offset216.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)215.i"
  %CastToValueType217.i = bitcast i8* %"&pSB[currWI].offset216.i" to <4 x i8>*
  %loadedValue218.i = load <4 x i8>* %CastToValueType217.i, align 4
  %"&(pSB[currWI].offset)220.i" = add nuw i64 %CurrSBIndex..2.i, 72
  %"&pSB[currWI].offset221.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)220.i"
  %CastToValueType222.i = bitcast i8* %"&pSB[currWI].offset221.i" to <4 x i8>*
  %"&(pSB[currWI].offset)229.i" = add nuw i64 %CurrSBIndex..2.i, 76
  %"&pSB[currWI].offset230.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)229.i"
  %CastToValueType231.i = bitcast i8* %"&pSB[currWI].offset230.i" to i32*
  %"&pSB[currWI].offset92.i" = getelementptr inbounds i8* %34, i64 %CurrSBIndex..2.i
  %CastToValueType93.i = bitcast i8* %"&pSB[currWI].offset92.i" to i32*
  br label %bb.nph.i.i

bb.nph.i.i:                                       ; preds = %bb.nph.i.i, %bb.nph.i.preheader.i
  %i.03.i.i = phi i32 [ %96, %bb.nph.i.i ], [ 0, %bb.nph.i.preheader.i ]
  %r.02.i.i = phi <4 x i8> [ %95, %bb.nph.i.i ], [ %loadedValue218.i, %bb.nph.i.preheader.i ]
  %95 = shufflevector <4 x i8> %r.02.i.i, <4 x i8> undef, <4 x i32> <i32 1, i32 2, i32 3, i32 0>
  store <4 x i8> %95, <4 x i8>* %CastToValueType222.i, align 4
  %96 = add i32 %i.03.i.i, 1
  store i32 %96, i32* %CastToValueType231.i, align 4
  %loadedValue.i = load i32* %CastToValueType93.i, align 4
  %exitcond.i.i = icmp eq i32 %96, %loadedValue.i
  br i1 %exitcond.i.i, label %shiftRows.exit.loopexit.i, label %bb.nph.i.i

shiftRows.exit.loopexit.i:                        ; preds = %bb.nph.i.i
  %"&(pSB[currWI].offset)224.i" = add nuw i64 %CurrSBIndex..2.i, 72
  %"&pSB[currWI].offset225.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)224.i"
  %CastToValueType226.i = bitcast i8* %"&pSB[currWI].offset225.i" to <4 x i8>*
  %loadedValue227.i = load <4 x i8>* %CastToValueType226.i, align 4
  br label %shiftRows.exit.i

shiftRows.exit.i:                                 ; preds = %shiftRows.exit.loopexit.i, %69
  %r.0.lcssa.i.i = phi <4 x i8> [ %tmp1.i88.i, %69 ], [ %loadedValue227.i, %shiftRows.exit.loopexit.i ]
  %97 = bitcast <4 x i8> %r.0.lcssa.i.i to i32
  %tmp5.i = bitcast i32 %97 to <4 x i8>
  %"&(pSB[currWI].offset)233.i" = add nuw i64 %CurrSBIndex..2.i, 80
  %"&pSB[currWI].offset234.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)233.i"
  %CastToValueType235.i = bitcast i8* %"&pSB[currWI].offset234.i" to <4 x i8>*
  store <4 x i8> %tmp5.i, <4 x i8>* %CastToValueType235.i, align 4
  %"&(pSB[currWI].offset)123.i" = add nuw i64 %CurrSBIndex..2.i, 16
  %"&pSB[currWI].offset124.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)123.i"
  %CastToValueType125.i = bitcast i8* %"&pSB[currWI].offset124.i" to <4 x i8> addrspace(3)**
  %loadedValue126.i = load <4 x i8> addrspace(3)** %CastToValueType125.i, align 8
  store <4 x i8> %tmp5.i, <4 x i8> addrspace(3)* %loadedValue126.i, align 4
  %"&(pSB[currWI].offset)192.i" = add nuw i64 %CurrSBIndex..2.i, 60
  %"&pSB[currWI].offset193.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)192.i"
  %CastToValueType194.i = bitcast i8* %"&pSB[currWI].offset193.i" to i32*
  %loadedValue195.i = load i32* %CastToValueType194.i, align 4
  %exitcond83.i = icmp eq i32 %loadedValue195.i, %tmp82.i
  br i1 %exitcond83.i, label %"Barrier BB89.i", label %bb.nph65.i

bb.nph65.i:                                       ; preds = %shiftRows.exit.i
  %check.WI.iter.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter.i, label %thenBB.i, label %SyncBB.i

thenBB.i:                                         ; preds = %bb.nph65.i
  %"CurrWI++.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond.i = icmp eq i32 %currBarrier.1.i, 12
  br i1 %cond.i, label %SyncBB343.i, label %SyncBB344.i

SyncBB.i:                                         ; preds = %thenBB347.i, %bb.nph65.i
  %CurrSBIndex..3.i = phi i64 [ %"loadedCurrSB+Stride353.i", %thenBB347.i ], [ 0, %bb.nph65.i ]
  %CurrWI..3.i = phi i64 [ %"CurrWI++351.i", %thenBB347.i ], [ 0, %bb.nph65.i ]
  %"&(pSB[currWI].offset)151.i" = add nuw i64 %CurrSBIndex..3.i, 32
  %"&pSB[currWI].offset152.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)151.i"
  %CastToValueType153.i = bitcast i8* %"&pSB[currWI].offset152.i" to <4 x i8>**
  %loadedValue154.i = load <4 x i8>** %CastToValueType153.i, align 8
  %98 = load <4 x i8>* %loadedValue154.i, align 4
  %99 = load <4 x i8> addrspace(3)* %13, align 4
  %100 = extractelement <4 x i8> %98, i32 0
  %101 = extractelement <4 x i8> %99, i32 0
  %102 = zext i8 %101 to i32
  %103 = shl i32 %102, 1
  %104 = and i32 %102, 128
  %105 = xor i32 %103, 27
  %106 = icmp eq i32 %104, 0
  %a.1.in.i = select i1 %106, i32 %103, i32 %105
  %107 = shl i32 %a.1.in.i, 1
  %108 = and i32 %a.1.in.i, 128
  %109 = xor i32 %107, 27
  %110 = icmp eq i32 %108, 0
  %a.1.in.1.i = select i1 %110, i32 %107, i32 %109
  %111 = shl i32 %a.1.in.1.i, 1
  %112 = and i32 %a.1.in.1.i, 128
  %113 = xor i32 %111, 27
  %114 = icmp eq i32 %112, 0
  %a.1.in.2.i = select i1 %114, i32 %111, i32 %113
  %115 = shl i32 %a.1.in.2.i, 1
  %116 = and i32 %a.1.in.2.i, 128
  %117 = xor i32 %115, 27
  %118 = icmp eq i32 %116, 0
  %a.1.in.3.i = select i1 %118, i32 %115, i32 %117
  %119 = shl i32 %a.1.in.3.i, 1
  %120 = and i32 %a.1.in.3.i, 128
  %121 = xor i32 %119, 27
  %122 = icmp eq i32 %120, 0
  %a.1.in.4.i = select i1 %122, i32 %119, i32 %121
  %123 = shl i32 %a.1.in.4.i, 1
  %124 = and i32 %a.1.in.4.i, 128
  %125 = xor i32 %123, 27
  %126 = icmp eq i32 %124, 0
  %a.1.in.5.i = select i1 %126, i32 %123, i32 %125
  %127 = shl i32 %a.1.in.5.i, 1
  %128 = lshr i8 %100, 1
  %129 = zext i8 %128 to i32
  %130 = zext i8 %100 to i32
  %131 = lshr i8 %100, 2
  %132 = lshr i8 %100, 3
  %133 = and i32 %129, 1
  %134 = and i32 %130, 1
  %135 = zext i8 %131 to i32
  %136 = zext i8 %132 to i32
  %137 = icmp eq i32 %133, 0
  %a.1.i = trunc i32 %a.1.in.i to i8
  %138 = icmp eq i32 %134, 0
  %139 = and i32 %135, 1
  %140 = lshr i8 %100, 4
  %141 = lshr i8 %100, 5
  %142 = and i32 %136, 1
  %143 = select i1 %137, i8 0, i8 %a.1.i
  %144 = select i1 %138, i8 0, i8 %101
  %a.1.1.i = trunc i32 %a.1.in.1.i to i8
  %145 = icmp eq i32 %139, 0
  %146 = zext i8 %140 to i32
  %147 = zext i8 %141 to i32
  %148 = icmp eq i32 %142, 0
  %a.1.2.i = trunc i32 %a.1.in.2.i to i8
  %p.1..1.i = xor i8 %143, %144
  %149 = select i1 %145, i8 0, i8 %a.1.1.i
  %150 = and i32 %146, 1
  %151 = lshr i8 %100, 6
  %152 = and i32 %a.1.in.5.i, 128
  %153 = and i32 %147, 1
  %154 = select i1 %148, i8 0, i8 %a.1.2.i
  %p.1..2.i = xor i8 %149, %p.1..1.i
  %a.1.3.i = trunc i32 %a.1.in.3.i to i8
  %155 = icmp eq i32 %150, 0
  %156 = zext i8 %151 to i32
  %157 = icmp eq i32 %152, 0
  %158 = xor i32 %127, 27
  %159 = icmp eq i32 %153, 0
  %a.1.4.i = trunc i32 %a.1.in.4.i to i8
  %p.1..3.i = xor i8 %154, %p.1..2.i
  %160 = select i1 %155, i8 0, i8 %a.1.3.i
  %161 = and i32 %156, 1
  %a.1.in.6.i = select i1 %157, i32 %127, i32 %158
  %162 = select i1 %159, i8 0, i8 %a.1.4.i
  %p.1..4.i = xor i8 %160, %p.1..3.i
  %a.1.5.i = trunc i32 %a.1.in.5.i to i8
  %163 = icmp eq i32 %161, 0
  %164 = icmp sgt i8 %100, -1
  %a.1.6.i = trunc i32 %a.1.in.6.i to i8
  %p.1..5.i = xor i8 %162, %p.1..4.i
  %165 = select i1 %163, i8 0, i8 %a.1.5.i
  %166 = select i1 %164, i8 0, i8 %a.1.6.i
  %p.1..6.i = xor i8 %165, %p.1..5.i
  %p.1..7.i = xor i8 %166, %p.1..6.i
  %"&(pSB[currWI].offset)242.i" = add nuw i64 %CurrSBIndex..3.i, 84
  %"&pSB[currWI].offset243.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)242.i"
  store i8 %p.1..7.i, i8* %"&pSB[currWI].offset243.i", align 1
  %"&(pSB[currWI].offset)146.i" = add nuw i64 %CurrSBIndex..3.i, 32
  %"&pSB[currWI].offset147.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)146.i"
  %CastToValueType148.i = bitcast i8* %"&pSB[currWI].offset147.i" to <4 x i8>**
  %loadedValue149.i = load <4 x i8>** %CastToValueType148.i, align 8
  %167 = load <4 x i8>* %loadedValue149.i, align 4
  %168 = load <4 x i8> addrspace(3)* %13, align 4
  %169 = extractelement <4 x i8> %167, i32 0
  %170 = extractelement <4 x i8> %168, i32 1
  %171 = zext i8 %170 to i32
  %172 = shl i32 %171, 1
  %173 = and i32 %171, 128
  %174 = xor i32 %172, 27
  %175 = icmp eq i32 %173, 0
  %a.3.in.i = select i1 %175, i32 %172, i32 %174
  %176 = shl i32 %a.3.in.i, 1
  %177 = and i32 %a.3.in.i, 128
  %178 = xor i32 %176, 27
  %179 = icmp eq i32 %177, 0
  %a.3.in.1.i = select i1 %179, i32 %176, i32 %178
  %180 = shl i32 %a.3.in.1.i, 1
  %181 = and i32 %a.3.in.1.i, 128
  %182 = xor i32 %180, 27
  %183 = icmp eq i32 %181, 0
  %a.3.in.2.i = select i1 %183, i32 %180, i32 %182
  %184 = shl i32 %a.3.in.2.i, 1
  %185 = and i32 %a.3.in.2.i, 128
  %186 = xor i32 %184, 27
  %187 = icmp eq i32 %185, 0
  %a.3.in.3.i = select i1 %187, i32 %184, i32 %186
  %188 = shl i32 %a.3.in.3.i, 1
  %189 = and i32 %a.3.in.3.i, 128
  %190 = xor i32 %188, 27
  %191 = icmp eq i32 %189, 0
  %a.3.in.4.i = select i1 %191, i32 %188, i32 %190
  %192 = shl i32 %a.3.in.4.i, 1
  %193 = and i32 %a.3.in.4.i, 128
  %194 = xor i32 %192, 27
  %195 = icmp eq i32 %193, 0
  %a.3.in.5.i = select i1 %195, i32 %192, i32 %194
  %196 = shl i32 %a.3.in.5.i, 1
  %197 = lshr i8 %169, 1
  %198 = zext i8 %197 to i32
  %199 = zext i8 %169 to i32
  %200 = lshr i8 %169, 2
  %201 = lshr i8 %169, 3
  %202 = and i32 %198, 1
  %203 = and i32 %199, 1
  %204 = zext i8 %200 to i32
  %205 = zext i8 %201 to i32
  %206 = icmp eq i32 %202, 0
  %a.3.i = trunc i32 %a.3.in.i to i8
  %207 = icmp eq i32 %203, 0
  %208 = and i32 %204, 1
  %209 = lshr i8 %169, 4
  %210 = lshr i8 %169, 5
  %211 = and i32 %205, 1
  %212 = select i1 %206, i8 0, i8 %a.3.i
  %213 = select i1 %207, i8 0, i8 %170
  %a.3.1.i = trunc i32 %a.3.in.1.i to i8
  %214 = icmp eq i32 %208, 0
  %215 = zext i8 %209 to i32
  %216 = zext i8 %210 to i32
  %217 = icmp eq i32 %211, 0
  %a.3.2.i = trunc i32 %a.3.in.2.i to i8
  %p.3..1.i = xor i8 %212, %213
  %218 = select i1 %214, i8 0, i8 %a.3.1.i
  %219 = and i32 %215, 1
  %220 = lshr i8 %169, 6
  %221 = and i32 %a.3.in.5.i, 128
  %222 = and i32 %216, 1
  %223 = select i1 %217, i8 0, i8 %a.3.2.i
  %p.3..2.i = xor i8 %218, %p.3..1.i
  %a.3.3.i = trunc i32 %a.3.in.3.i to i8
  %224 = icmp eq i32 %219, 0
  %225 = zext i8 %220 to i32
  %226 = icmp eq i32 %221, 0
  %227 = xor i32 %196, 27
  %228 = icmp eq i32 %222, 0
  %a.3.4.i = trunc i32 %a.3.in.4.i to i8
  %p.3..3.i = xor i8 %223, %p.3..2.i
  %229 = select i1 %224, i8 0, i8 %a.3.3.i
  %230 = and i32 %225, 1
  %a.3.in.6.i = select i1 %226, i32 %196, i32 %227
  %231 = select i1 %228, i8 0, i8 %a.3.4.i
  %p.3..4.i = xor i8 %229, %p.3..3.i
  %a.3.5.i = trunc i32 %a.3.in.5.i to i8
  %232 = icmp eq i32 %230, 0
  %233 = icmp sgt i8 %169, -1
  %a.3.6.i = trunc i32 %a.3.in.6.i to i8
  %p.3..5.i = xor i8 %231, %p.3..4.i
  %234 = select i1 %232, i8 0, i8 %a.3.5.i
  %235 = select i1 %233, i8 0, i8 %a.3.6.i
  %p.3..6.i = xor i8 %234, %p.3..5.i
  %p.3..7.i = xor i8 %235, %p.3..6.i
  %"&(pSB[currWI].offset)246.i" = add nuw i64 %CurrSBIndex..3.i, 85
  %"&pSB[currWI].offset247.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)246.i"
  store i8 %p.3..7.i, i8* %"&pSB[currWI].offset247.i", align 1
  %"&(pSB[currWI].offset)141.i" = add nuw i64 %CurrSBIndex..3.i, 32
  %"&pSB[currWI].offset142.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)141.i"
  %CastToValueType143.i = bitcast i8* %"&pSB[currWI].offset142.i" to <4 x i8>**
  %loadedValue144.i = load <4 x i8>** %CastToValueType143.i, align 8
  %236 = load <4 x i8>* %loadedValue144.i, align 4
  %237 = load <4 x i8> addrspace(3)* %13, align 4
  %238 = extractelement <4 x i8> %236, i32 0
  %239 = extractelement <4 x i8> %237, i32 2
  %240 = zext i8 %239 to i32
  %241 = shl i32 %240, 1
  %242 = and i32 %240, 128
  %243 = xor i32 %241, 27
  %244 = icmp eq i32 %242, 0
  %a.5.in.i = select i1 %244, i32 %241, i32 %243
  %245 = shl i32 %a.5.in.i, 1
  %246 = and i32 %a.5.in.i, 128
  %247 = xor i32 %245, 27
  %248 = icmp eq i32 %246, 0
  %a.5.in.1.i = select i1 %248, i32 %245, i32 %247
  %249 = shl i32 %a.5.in.1.i, 1
  %250 = and i32 %a.5.in.1.i, 128
  %251 = xor i32 %249, 27
  %252 = icmp eq i32 %250, 0
  %a.5.in.2.i = select i1 %252, i32 %249, i32 %251
  %253 = shl i32 %a.5.in.2.i, 1
  %254 = and i32 %a.5.in.2.i, 128
  %255 = xor i32 %253, 27
  %256 = icmp eq i32 %254, 0
  %a.5.in.3.i = select i1 %256, i32 %253, i32 %255
  %257 = shl i32 %a.5.in.3.i, 1
  %258 = and i32 %a.5.in.3.i, 128
  %259 = xor i32 %257, 27
  %260 = icmp eq i32 %258, 0
  %a.5.in.4.i = select i1 %260, i32 %257, i32 %259
  %261 = shl i32 %a.5.in.4.i, 1
  %262 = and i32 %a.5.in.4.i, 128
  %263 = xor i32 %261, 27
  %264 = icmp eq i32 %262, 0
  %a.5.in.5.i = select i1 %264, i32 %261, i32 %263
  %265 = shl i32 %a.5.in.5.i, 1
  %266 = lshr i8 %238, 1
  %267 = zext i8 %266 to i32
  %268 = zext i8 %238 to i32
  %269 = lshr i8 %238, 2
  %270 = lshr i8 %238, 3
  %271 = and i32 %267, 1
  %272 = and i32 %268, 1
  %273 = zext i8 %269 to i32
  %274 = zext i8 %270 to i32
  %275 = icmp eq i32 %271, 0
  %a.5.i = trunc i32 %a.5.in.i to i8
  %276 = icmp eq i32 %272, 0
  %277 = and i32 %273, 1
  %278 = lshr i8 %238, 4
  %279 = lshr i8 %238, 5
  %280 = and i32 %274, 1
  %281 = select i1 %275, i8 0, i8 %a.5.i
  %282 = select i1 %276, i8 0, i8 %239
  %a.5.1.i = trunc i32 %a.5.in.1.i to i8
  %283 = icmp eq i32 %277, 0
  %284 = zext i8 %278 to i32
  %285 = zext i8 %279 to i32
  %286 = icmp eq i32 %280, 0
  %a.5.2.i = trunc i32 %a.5.in.2.i to i8
  %p.5..1.i = xor i8 %281, %282
  %287 = select i1 %283, i8 0, i8 %a.5.1.i
  %288 = and i32 %284, 1
  %289 = lshr i8 %238, 6
  %290 = and i32 %a.5.in.5.i, 128
  %291 = and i32 %285, 1
  %292 = select i1 %286, i8 0, i8 %a.5.2.i
  %p.5..2.i = xor i8 %287, %p.5..1.i
  %a.5.3.i = trunc i32 %a.5.in.3.i to i8
  %293 = icmp eq i32 %288, 0
  %294 = zext i8 %289 to i32
  %295 = icmp eq i32 %290, 0
  %296 = xor i32 %265, 27
  %297 = icmp eq i32 %291, 0
  %a.5.4.i = trunc i32 %a.5.in.4.i to i8
  %p.5..3.i = xor i8 %292, %p.5..2.i
  %298 = select i1 %293, i8 0, i8 %a.5.3.i
  %299 = and i32 %294, 1
  %a.5.in.6.i = select i1 %295, i32 %265, i32 %296
  %300 = select i1 %297, i8 0, i8 %a.5.4.i
  %p.5..4.i = xor i8 %298, %p.5..3.i
  %a.5.5.i = trunc i32 %a.5.in.5.i to i8
  %301 = icmp eq i32 %299, 0
  %302 = icmp sgt i8 %238, -1
  %a.5.6.i = trunc i32 %a.5.in.6.i to i8
  %p.5..5.i = xor i8 %300, %p.5..4.i
  %303 = select i1 %301, i8 0, i8 %a.5.5.i
  %304 = select i1 %302, i8 0, i8 %a.5.6.i
  %p.5..6.i = xor i8 %303, %p.5..5.i
  %p.5..7.i = xor i8 %304, %p.5..6.i
  %"&(pSB[currWI].offset)250.i" = add nuw i64 %CurrSBIndex..3.i, 86
  %"&pSB[currWI].offset251.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)250.i"
  store i8 %p.5..7.i, i8* %"&pSB[currWI].offset251.i", align 1
  %"&(pSB[currWI].offset)136.i" = add nuw i64 %CurrSBIndex..3.i, 32
  %"&pSB[currWI].offset137.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)136.i"
  %CastToValueType138.i = bitcast i8* %"&pSB[currWI].offset137.i" to <4 x i8>**
  %loadedValue139.i = load <4 x i8>** %CastToValueType138.i, align 8
  %305 = load <4 x i8>* %loadedValue139.i, align 4
  %306 = load <4 x i8> addrspace(3)* %13, align 4
  %307 = extractelement <4 x i8> %305, i32 0
  %308 = extractelement <4 x i8> %306, i32 3
  %309 = zext i8 %308 to i32
  %310 = shl i32 %309, 1
  %311 = and i32 %309, 128
  %312 = xor i32 %310, 27
  %313 = icmp eq i32 %311, 0
  %a.7.in.i = select i1 %313, i32 %310, i32 %312
  %314 = shl i32 %a.7.in.i, 1
  %315 = and i32 %a.7.in.i, 128
  %316 = xor i32 %314, 27
  %317 = icmp eq i32 %315, 0
  %a.7.in.1.i = select i1 %317, i32 %314, i32 %316
  %318 = shl i32 %a.7.in.1.i, 1
  %319 = and i32 %a.7.in.1.i, 128
  %320 = xor i32 %318, 27
  %321 = icmp eq i32 %319, 0
  %a.7.in.2.i = select i1 %321, i32 %318, i32 %320
  %322 = shl i32 %a.7.in.2.i, 1
  %323 = and i32 %a.7.in.2.i, 128
  %324 = xor i32 %322, 27
  %325 = icmp eq i32 %323, 0
  %a.7.in.3.i = select i1 %325, i32 %322, i32 %324
  %326 = shl i32 %a.7.in.3.i, 1
  %327 = and i32 %a.7.in.3.i, 128
  %328 = xor i32 %326, 27
  %329 = icmp eq i32 %327, 0
  %a.7.in.4.i = select i1 %329, i32 %326, i32 %328
  %330 = shl i32 %a.7.in.4.i, 1
  %331 = and i32 %a.7.in.4.i, 128
  %332 = xor i32 %330, 27
  %333 = icmp eq i32 %331, 0
  %a.7.in.5.i = select i1 %333, i32 %330, i32 %332
  %334 = shl i32 %a.7.in.5.i, 1
  %335 = lshr i8 %307, 1
  %336 = zext i8 %335 to i32
  %337 = zext i8 %307 to i32
  %338 = lshr i8 %307, 2
  %339 = lshr i8 %307, 3
  %340 = and i32 %336, 1
  %341 = and i32 %337, 1
  %342 = zext i8 %338 to i32
  %343 = zext i8 %339 to i32
  %344 = icmp eq i32 %340, 0
  %a.7.i = trunc i32 %a.7.in.i to i8
  %345 = icmp eq i32 %341, 0
  %346 = and i32 %342, 1
  %347 = lshr i8 %307, 4
  %348 = lshr i8 %307, 5
  %349 = and i32 %343, 1
  %350 = select i1 %344, i8 0, i8 %a.7.i
  %351 = select i1 %345, i8 0, i8 %308
  %a.7.1.i = trunc i32 %a.7.in.1.i to i8
  %352 = icmp eq i32 %346, 0
  %353 = zext i8 %347 to i32
  %354 = zext i8 %348 to i32
  %355 = icmp eq i32 %349, 0
  %a.7.2.i = trunc i32 %a.7.in.2.i to i8
  %p.7..1.i = xor i8 %350, %351
  %356 = select i1 %352, i8 0, i8 %a.7.1.i
  %357 = and i32 %353, 1
  %358 = lshr i8 %307, 6
  %359 = and i32 %a.7.in.5.i, 128
  %360 = and i32 %354, 1
  %361 = select i1 %355, i8 0, i8 %a.7.2.i
  %p.7..2.i = xor i8 %356, %p.7..1.i
  %a.7.3.i = trunc i32 %a.7.in.3.i to i8
  %362 = icmp eq i32 %357, 0
  %363 = zext i8 %358 to i32
  %364 = icmp eq i32 %359, 0
  %365 = xor i32 %334, 27
  %366 = icmp eq i32 %360, 0
  %a.7.4.i = trunc i32 %a.7.in.4.i to i8
  %p.7..3.i = xor i8 %361, %p.7..2.i
  %367 = select i1 %362, i8 0, i8 %a.7.3.i
  %368 = and i32 %363, 1
  %a.7.in.6.i = select i1 %364, i32 %334, i32 %365
  %369 = select i1 %366, i8 0, i8 %a.7.4.i
  %p.7..4.i = xor i8 %367, %p.7..3.i
  %a.7.5.i = trunc i32 %a.7.in.5.i to i8
  %370 = icmp eq i32 %368, 0
  %371 = icmp sgt i8 %307, -1
  %a.7.6.i = trunc i32 %a.7.in.6.i to i8
  %p.7..5.i = xor i8 %369, %p.7..4.i
  %372 = select i1 %370, i8 0, i8 %a.7.5.i
  %373 = select i1 %371, i8 0, i8 %a.7.6.i
  %p.7..6.i = xor i8 %372, %p.7..5.i
  %p.7..7.i = xor i8 %373, %p.7..6.i
  %"&(pSB[currWI].offset)254.i" = add nuw i64 %CurrSBIndex..3.i, 87
  %"&pSB[currWI].offset255.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)254.i"
  store i8 %p.7..7.i, i8* %"&pSB[currWI].offset255.i", align 1
  %"&(pSB[currWI].offset)258.i" = add nuw i64 %CurrSBIndex..3.i, 88
  %"&pSB[currWI].offset259.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)258.i"
  %CastToValueType260.i = bitcast i8* %"&pSB[currWI].offset259.i" to i64*
  %"&(pSB[currWI].offset)174.i" = add nuw i64 %CurrSBIndex..3.i, 48
  %"&pSB[currWI].offset175.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)174.i"
  %CastToValueType176.i = bitcast i8* %"&pSB[currWI].offset175.i" to i64*
  %"&(pSB[currWI].offset)318.i" = add nuw i64 %CurrSBIndex..3.i, 112
  %"&pSB[currWI].offset319.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)318.i"
  %CastToValueType320.i = bitcast i8* %"&pSB[currWI].offset319.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)314.i" = add nuw i64 %CurrSBIndex..3.i, 112
  %"&pSB[currWI].offset315.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)314.i"
  %CastToValueType316.i = bitcast i8* %"&pSB[currWI].offset315.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)310.i" = add nuw i64 %CurrSBIndex..3.i, 112
  %"&pSB[currWI].offset311.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)310.i"
  %CastToValueType312.i = bitcast i8* %"&pSB[currWI].offset311.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)306.i" = add nuw i64 %CurrSBIndex..3.i, 112
  %"&pSB[currWI].offset307.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)306.i"
  %CastToValueType308.i = bitcast i8* %"&pSB[currWI].offset307.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)262.i" = add nuw i64 %CurrSBIndex..3.i, 96
  %"&pSB[currWI].offset263.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)262.i"
  %"&(pSB[currWI].offset)271.i" = add nuw i64 %CurrSBIndex..3.i, 97
  %"&pSB[currWI].offset272.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)271.i"
  %"&(pSB[currWI].offset)280.i" = add nuw i64 %CurrSBIndex..3.i, 98
  %"&pSB[currWI].offset281.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)280.i"
  %"&(pSB[currWI].offset)289.i" = add nuw i64 %CurrSBIndex..3.i, 99
  %"&pSB[currWI].offset290.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)289.i"
  br label %374

; <label>:374                                     ; preds = %374, %SyncBB.i
  %indvar.i = phi i64 [ 0, %SyncBB.i ], [ %tmp.i, %374 ]
  %w.063.i = phi i8 [ %p.7..7.i, %SyncBB.i ], [ %662, %374 ]
  %z.062.i = phi i8 [ %p.5..7.i, %SyncBB.i ], [ %661, %374 ]
  %y.061.i = phi i8 [ %p.3..7.i, %SyncBB.i ], [ %660, %374 ]
  %x.060.i = phi i8 [ %p.1..7.i, %SyncBB.i ], [ %659, %374 ]
  %tmp.i = add i64 %indvar.i, 1
  store i64 %tmp.i, i64* %CastToValueType260.i, align 8
  %scevgep.i = getelementptr <4 x i8> addrspace(3)* %13, i64 %tmp.i
  %loadedValue177.i = load i64* %CastToValueType176.i, align 8
  %tmp77.i = add i64 %loadedValue177.i, %indvar.i
  %375 = and i64 %tmp77.i, 3
  %376 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType320.i, i64 0, i64 %375
  %377 = load <4 x i8>* %376, align 4
  %378 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %379 = extractelement <4 x i8> %377, i32 0
  %380 = extractelement <4 x i8> %378, i32 0
  %381 = zext i8 %380 to i32
  %382 = shl i32 %381, 1
  %383 = and i32 %381, 128
  %384 = xor i32 %382, 27
  %385 = icmp eq i32 %383, 0
  %a.9.in.i = select i1 %385, i32 %382, i32 %384
  %386 = shl i32 %a.9.in.i, 1
  %387 = and i32 %a.9.in.i, 128
  %388 = xor i32 %386, 27
  %389 = icmp eq i32 %387, 0
  %a.9.in.1.i = select i1 %389, i32 %386, i32 %388
  %390 = shl i32 %a.9.in.1.i, 1
  %391 = and i32 %a.9.in.1.i, 128
  %392 = xor i32 %390, 27
  %393 = icmp eq i32 %391, 0
  %a.9.in.2.i = select i1 %393, i32 %390, i32 %392
  %394 = shl i32 %a.9.in.2.i, 1
  %395 = and i32 %a.9.in.2.i, 128
  %396 = xor i32 %394, 27
  %397 = icmp eq i32 %395, 0
  %a.9.in.3.i = select i1 %397, i32 %394, i32 %396
  %398 = shl i32 %a.9.in.3.i, 1
  %399 = and i32 %a.9.in.3.i, 128
  %400 = xor i32 %398, 27
  %401 = icmp eq i32 %399, 0
  %a.9.in.4.i = select i1 %401, i32 %398, i32 %400
  %402 = shl i32 %a.9.in.4.i, 1
  %403 = and i32 %a.9.in.4.i, 128
  %404 = xor i32 %402, 27
  %405 = icmp eq i32 %403, 0
  %a.9.in.5.i = select i1 %405, i32 %402, i32 %404
  %406 = shl i32 %a.9.in.5.i, 1
  %407 = lshr i8 %379, 1
  %408 = zext i8 %407 to i32
  %409 = zext i8 %379 to i32
  %410 = lshr i8 %379, 2
  %411 = lshr i8 %379, 3
  %412 = and i32 %408, 1
  %413 = and i32 %409, 1
  %414 = zext i8 %410 to i32
  %415 = zext i8 %411 to i32
  %416 = icmp eq i32 %412, 0
  %a.9.i = trunc i32 %a.9.in.i to i8
  %417 = icmp eq i32 %413, 0
  %418 = and i32 %414, 1
  %419 = lshr i8 %379, 4
  %420 = lshr i8 %379, 5
  %421 = and i32 %415, 1
  %422 = select i1 %416, i8 0, i8 %a.9.i
  %423 = select i1 %417, i8 0, i8 %380
  %a.9.1.i = trunc i32 %a.9.in.1.i to i8
  %424 = icmp eq i32 %418, 0
  %425 = zext i8 %419 to i32
  %426 = zext i8 %420 to i32
  %427 = icmp eq i32 %421, 0
  %a.9.2.i = trunc i32 %a.9.in.2.i to i8
  %p.9..1.i = xor i8 %422, %423
  %428 = select i1 %424, i8 0, i8 %a.9.1.i
  %429 = and i32 %425, 1
  %430 = lshr i8 %379, 6
  %431 = and i32 %a.9.in.5.i, 128
  %432 = and i32 %426, 1
  %433 = select i1 %427, i8 0, i8 %a.9.2.i
  %p.9..2.i = xor i8 %428, %p.9..1.i
  %a.9.3.i = trunc i32 %a.9.in.3.i to i8
  %434 = icmp eq i32 %429, 0
  %435 = zext i8 %430 to i32
  %436 = icmp eq i32 %431, 0
  %437 = xor i32 %406, 27
  %438 = icmp eq i32 %432, 0
  %a.9.4.i = trunc i32 %a.9.in.4.i to i8
  %p.9..3.i = xor i8 %433, %p.9..2.i
  %439 = select i1 %434, i8 0, i8 %a.9.3.i
  %440 = and i32 %435, 1
  %a.9.in.6.i = select i1 %436, i32 %406, i32 %437
  %441 = select i1 %438, i8 0, i8 %a.9.4.i
  %p.9..4.i = xor i8 %439, %p.9..3.i
  %a.9.5.i = trunc i32 %a.9.in.5.i to i8
  %442 = icmp eq i32 %440, 0
  %443 = icmp sgt i8 %379, -1
  %a.9.6.i = trunc i32 %a.9.in.6.i to i8
  %p.9..5.i = xor i8 %441, %p.9..4.i
  %444 = select i1 %442, i8 0, i8 %a.9.5.i
  %445 = select i1 %443, i8 0, i8 %a.9.6.i
  %p.9..6.i = xor i8 %444, %p.9..5.i
  %p.9..7.i = xor i8 %445, %p.9..6.i
  %446 = and i64 %tmp77.i, 3
  %447 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType316.i, i64 0, i64 %446
  %448 = load <4 x i8>* %447, align 4
  %449 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %450 = extractelement <4 x i8> %448, i32 0
  %451 = extractelement <4 x i8> %449, i32 1
  %452 = zext i8 %451 to i32
  %453 = shl i32 %452, 1
  %454 = and i32 %452, 128
  %455 = xor i32 %453, 27
  %456 = icmp eq i32 %454, 0
  %a.11.in.i = select i1 %456, i32 %453, i32 %455
  %457 = shl i32 %a.11.in.i, 1
  %458 = and i32 %a.11.in.i, 128
  %459 = xor i32 %457, 27
  %460 = icmp eq i32 %458, 0
  %a.11.in.1.i = select i1 %460, i32 %457, i32 %459
  %461 = shl i32 %a.11.in.1.i, 1
  %462 = and i32 %a.11.in.1.i, 128
  %463 = xor i32 %461, 27
  %464 = icmp eq i32 %462, 0
  %a.11.in.2.i = select i1 %464, i32 %461, i32 %463
  %465 = shl i32 %a.11.in.2.i, 1
  %466 = and i32 %a.11.in.2.i, 128
  %467 = xor i32 %465, 27
  %468 = icmp eq i32 %466, 0
  %a.11.in.3.i = select i1 %468, i32 %465, i32 %467
  %469 = shl i32 %a.11.in.3.i, 1
  %470 = and i32 %a.11.in.3.i, 128
  %471 = xor i32 %469, 27
  %472 = icmp eq i32 %470, 0
  %a.11.in.4.i = select i1 %472, i32 %469, i32 %471
  %473 = shl i32 %a.11.in.4.i, 1
  %474 = and i32 %a.11.in.4.i, 128
  %475 = xor i32 %473, 27
  %476 = icmp eq i32 %474, 0
  %a.11.in.5.i = select i1 %476, i32 %473, i32 %475
  %477 = shl i32 %a.11.in.5.i, 1
  %478 = lshr i8 %450, 1
  %479 = zext i8 %478 to i32
  %480 = zext i8 %450 to i32
  %481 = lshr i8 %450, 2
  %482 = lshr i8 %450, 3
  %483 = and i32 %479, 1
  %484 = and i32 %480, 1
  %485 = zext i8 %481 to i32
  %486 = zext i8 %482 to i32
  %487 = icmp eq i32 %483, 0
  %a.11.i = trunc i32 %a.11.in.i to i8
  %488 = icmp eq i32 %484, 0
  %489 = and i32 %485, 1
  %490 = lshr i8 %450, 4
  %491 = lshr i8 %450, 5
  %492 = and i32 %486, 1
  %493 = select i1 %487, i8 0, i8 %a.11.i
  %494 = select i1 %488, i8 0, i8 %451
  %a.11.1.i = trunc i32 %a.11.in.1.i to i8
  %495 = icmp eq i32 %489, 0
  %496 = zext i8 %490 to i32
  %497 = zext i8 %491 to i32
  %498 = icmp eq i32 %492, 0
  %a.11.2.i = trunc i32 %a.11.in.2.i to i8
  %p.11..1.i = xor i8 %493, %494
  %499 = select i1 %495, i8 0, i8 %a.11.1.i
  %500 = and i32 %496, 1
  %501 = lshr i8 %450, 6
  %502 = and i32 %a.11.in.5.i, 128
  %503 = and i32 %497, 1
  %504 = select i1 %498, i8 0, i8 %a.11.2.i
  %p.11..2.i = xor i8 %499, %p.11..1.i
  %a.11.3.i = trunc i32 %a.11.in.3.i to i8
  %505 = icmp eq i32 %500, 0
  %506 = zext i8 %501 to i32
  %507 = icmp eq i32 %502, 0
  %508 = xor i32 %477, 27
  %509 = icmp eq i32 %503, 0
  %a.11.4.i = trunc i32 %a.11.in.4.i to i8
  %p.11..3.i = xor i8 %504, %p.11..2.i
  %510 = select i1 %505, i8 0, i8 %a.11.3.i
  %511 = and i32 %506, 1
  %a.11.in.6.i = select i1 %507, i32 %477, i32 %508
  %512 = select i1 %509, i8 0, i8 %a.11.4.i
  %p.11..4.i = xor i8 %510, %p.11..3.i
  %a.11.5.i = trunc i32 %a.11.in.5.i to i8
  %513 = icmp eq i32 %511, 0
  %514 = icmp sgt i8 %450, -1
  %a.11.6.i = trunc i32 %a.11.in.6.i to i8
  %p.11..5.i = xor i8 %512, %p.11..4.i
  %515 = select i1 %513, i8 0, i8 %a.11.5.i
  %516 = select i1 %514, i8 0, i8 %a.11.6.i
  %p.11..6.i = xor i8 %515, %p.11..5.i
  %p.11..7.i = xor i8 %516, %p.11..6.i
  %517 = and i64 %tmp77.i, 3
  %518 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType312.i, i64 0, i64 %517
  %519 = load <4 x i8>* %518, align 4
  %520 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %521 = extractelement <4 x i8> %519, i32 0
  %522 = extractelement <4 x i8> %520, i32 2
  %523 = zext i8 %522 to i32
  %524 = shl i32 %523, 1
  %525 = and i32 %523, 128
  %526 = xor i32 %524, 27
  %527 = icmp eq i32 %525, 0
  %a.13.in.i = select i1 %527, i32 %524, i32 %526
  %528 = shl i32 %a.13.in.i, 1
  %529 = and i32 %a.13.in.i, 128
  %530 = xor i32 %528, 27
  %531 = icmp eq i32 %529, 0
  %a.13.in.1.i = select i1 %531, i32 %528, i32 %530
  %532 = shl i32 %a.13.in.1.i, 1
  %533 = and i32 %a.13.in.1.i, 128
  %534 = xor i32 %532, 27
  %535 = icmp eq i32 %533, 0
  %a.13.in.2.i = select i1 %535, i32 %532, i32 %534
  %536 = shl i32 %a.13.in.2.i, 1
  %537 = and i32 %a.13.in.2.i, 128
  %538 = xor i32 %536, 27
  %539 = icmp eq i32 %537, 0
  %a.13.in.3.i = select i1 %539, i32 %536, i32 %538
  %540 = shl i32 %a.13.in.3.i, 1
  %541 = and i32 %a.13.in.3.i, 128
  %542 = xor i32 %540, 27
  %543 = icmp eq i32 %541, 0
  %a.13.in.4.i = select i1 %543, i32 %540, i32 %542
  %544 = shl i32 %a.13.in.4.i, 1
  %545 = and i32 %a.13.in.4.i, 128
  %546 = xor i32 %544, 27
  %547 = icmp eq i32 %545, 0
  %a.13.in.5.i = select i1 %547, i32 %544, i32 %546
  %548 = shl i32 %a.13.in.5.i, 1
  %549 = lshr i8 %521, 1
  %550 = zext i8 %549 to i32
  %551 = zext i8 %521 to i32
  %552 = lshr i8 %521, 2
  %553 = lshr i8 %521, 3
  %554 = and i32 %550, 1
  %555 = and i32 %551, 1
  %556 = zext i8 %552 to i32
  %557 = zext i8 %553 to i32
  %558 = icmp eq i32 %554, 0
  %a.13.i = trunc i32 %a.13.in.i to i8
  %559 = icmp eq i32 %555, 0
  %560 = and i32 %556, 1
  %561 = lshr i8 %521, 4
  %562 = lshr i8 %521, 5
  %563 = and i32 %557, 1
  %564 = select i1 %558, i8 0, i8 %a.13.i
  %565 = select i1 %559, i8 0, i8 %522
  %a.13.1.i = trunc i32 %a.13.in.1.i to i8
  %566 = icmp eq i32 %560, 0
  %567 = zext i8 %561 to i32
  %568 = zext i8 %562 to i32
  %569 = icmp eq i32 %563, 0
  %a.13.2.i = trunc i32 %a.13.in.2.i to i8
  %p.13..1.i = xor i8 %564, %565
  %570 = select i1 %566, i8 0, i8 %a.13.1.i
  %571 = and i32 %567, 1
  %572 = lshr i8 %521, 6
  %573 = and i32 %a.13.in.5.i, 128
  %574 = and i32 %568, 1
  %575 = select i1 %569, i8 0, i8 %a.13.2.i
  %p.13..2.i = xor i8 %570, %p.13..1.i
  %a.13.3.i = trunc i32 %a.13.in.3.i to i8
  %576 = icmp eq i32 %571, 0
  %577 = zext i8 %572 to i32
  %578 = icmp eq i32 %573, 0
  %579 = xor i32 %548, 27
  %580 = icmp eq i32 %574, 0
  %a.13.4.i = trunc i32 %a.13.in.4.i to i8
  %p.13..3.i = xor i8 %575, %p.13..2.i
  %581 = select i1 %576, i8 0, i8 %a.13.3.i
  %582 = and i32 %577, 1
  %a.13.in.6.i = select i1 %578, i32 %548, i32 %579
  %583 = select i1 %580, i8 0, i8 %a.13.4.i
  %p.13..4.i = xor i8 %581, %p.13..3.i
  %a.13.5.i = trunc i32 %a.13.in.5.i to i8
  %584 = icmp eq i32 %582, 0
  %585 = icmp sgt i8 %521, -1
  %a.13.6.i = trunc i32 %a.13.in.6.i to i8
  %p.13..5.i = xor i8 %583, %p.13..4.i
  %586 = select i1 %584, i8 0, i8 %a.13.5.i
  %587 = select i1 %585, i8 0, i8 %a.13.6.i
  %p.13..6.i = xor i8 %586, %p.13..5.i
  %p.13..7.i = xor i8 %587, %p.13..6.i
  %588 = and i64 %tmp77.i, 3
  %589 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType308.i, i64 0, i64 %588
  %590 = load <4 x i8>* %589, align 4
  %591 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %592 = extractelement <4 x i8> %590, i32 0
  %593 = extractelement <4 x i8> %591, i32 3
  %594 = zext i8 %593 to i32
  %595 = shl i32 %594, 1
  %596 = and i32 %594, 128
  %597 = xor i32 %595, 27
  %598 = icmp eq i32 %596, 0
  %a.15.in.i = select i1 %598, i32 %595, i32 %597
  %599 = shl i32 %a.15.in.i, 1
  %600 = and i32 %a.15.in.i, 128
  %601 = xor i32 %599, 27
  %602 = icmp eq i32 %600, 0
  %a.15.in.1.i = select i1 %602, i32 %599, i32 %601
  %603 = shl i32 %a.15.in.1.i, 1
  %604 = and i32 %a.15.in.1.i, 128
  %605 = xor i32 %603, 27
  %606 = icmp eq i32 %604, 0
  %a.15.in.2.i = select i1 %606, i32 %603, i32 %605
  %607 = shl i32 %a.15.in.2.i, 1
  %608 = and i32 %a.15.in.2.i, 128
  %609 = xor i32 %607, 27
  %610 = icmp eq i32 %608, 0
  %a.15.in.3.i = select i1 %610, i32 %607, i32 %609
  %611 = shl i32 %a.15.in.3.i, 1
  %612 = and i32 %a.15.in.3.i, 128
  %613 = xor i32 %611, 27
  %614 = icmp eq i32 %612, 0
  %a.15.in.4.i = select i1 %614, i32 %611, i32 %613
  %615 = shl i32 %a.15.in.4.i, 1
  %616 = and i32 %a.15.in.4.i, 128
  %617 = xor i32 %615, 27
  %618 = icmp eq i32 %616, 0
  %a.15.in.5.i = select i1 %618, i32 %615, i32 %617
  %619 = shl i32 %a.15.in.5.i, 1
  %620 = lshr i8 %592, 1
  %621 = zext i8 %620 to i32
  %622 = zext i8 %592 to i32
  %623 = lshr i8 %592, 2
  %624 = lshr i8 %592, 3
  %625 = and i32 %621, 1
  %626 = and i32 %622, 1
  %627 = zext i8 %623 to i32
  %628 = zext i8 %624 to i32
  %629 = icmp eq i32 %625, 0
  %a.15.i = trunc i32 %a.15.in.i to i8
  %630 = icmp eq i32 %626, 0
  %631 = and i32 %627, 1
  %632 = lshr i8 %592, 4
  %633 = lshr i8 %592, 5
  %634 = and i32 %628, 1
  %635 = select i1 %629, i8 0, i8 %a.15.i
  %636 = select i1 %630, i8 0, i8 %593
  %a.15.1.i = trunc i32 %a.15.in.1.i to i8
  %637 = icmp eq i32 %631, 0
  %638 = zext i8 %632 to i32
  %639 = zext i8 %633 to i32
  %640 = icmp eq i32 %634, 0
  %a.15.2.i = trunc i32 %a.15.in.2.i to i8
  %p.15..1.i = xor i8 %635, %636
  %641 = select i1 %637, i8 0, i8 %a.15.1.i
  %642 = and i32 %638, 1
  %643 = lshr i8 %592, 6
  %644 = and i32 %a.15.in.5.i, 128
  %645 = and i32 %639, 1
  %646 = select i1 %640, i8 0, i8 %a.15.2.i
  %p.15..2.i = xor i8 %641, %p.15..1.i
  %a.15.3.i = trunc i32 %a.15.in.3.i to i8
  %647 = icmp eq i32 %642, 0
  %648 = zext i8 %643 to i32
  %649 = icmp eq i32 %644, 0
  %650 = xor i32 %619, 27
  %651 = icmp eq i32 %645, 0
  %a.15.4.i = trunc i32 %a.15.in.4.i to i8
  %p.15..3.i = xor i8 %646, %p.15..2.i
  %652 = select i1 %647, i8 0, i8 %a.15.3.i
  %653 = and i32 %648, 1
  %a.15.in.6.i = select i1 %649, i32 %619, i32 %650
  %654 = select i1 %651, i8 0, i8 %a.15.4.i
  %p.15..4.i = xor i8 %652, %p.15..3.i
  %a.15.5.i = trunc i32 %a.15.in.5.i to i8
  %655 = icmp eq i32 %653, 0
  %656 = icmp sgt i8 %592, -1
  %a.15.6.i = trunc i32 %a.15.in.6.i to i8
  %p.15..5.i = xor i8 %654, %p.15..4.i
  %657 = select i1 %655, i8 0, i8 %a.15.5.i
  %658 = select i1 %656, i8 0, i8 %a.15.6.i
  %p.15..6.i = xor i8 %657, %p.15..5.i
  %p.15..7.i = xor i8 %658, %p.15..6.i
  %659 = xor i8 %p.9..7.i, %x.060.i
  store i8 %659, i8* %"&pSB[currWI].offset263.i", align 1
  %660 = xor i8 %p.11..7.i, %y.061.i
  store i8 %660, i8* %"&pSB[currWI].offset272.i", align 1
  %661 = xor i8 %p.13..7.i, %z.062.i
  store i8 %661, i8* %"&pSB[currWI].offset281.i", align 1
  %662 = xor i8 %p.15..7.i, %w.063.i
  store i8 %662, i8* %"&pSB[currWI].offset290.i", align 1
  %exitcond.i = icmp eq i64 %tmp.i, 3
  br i1 %exitcond.i, label %._crit_edge66.i, label %374

._crit_edge66.i:                                  ; preds = %374
  %"&(pSB[currWI].offset)266.i" = add nuw i64 %CurrSBIndex..3.i, 96
  %"&pSB[currWI].offset267.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)266.i"
  %loadedValue269.i = load i8* %"&pSB[currWI].offset267.i", align 1
  %663 = insertelement <4 x i8> undef, i8 %loadedValue269.i, i32 0
  %"&(pSB[currWI].offset)275.i" = add nuw i64 %CurrSBIndex..3.i, 97
  %"&pSB[currWI].offset276.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)275.i"
  %loadedValue278.i = load i8* %"&pSB[currWI].offset276.i", align 1
  %664 = insertelement <4 x i8> %663, i8 %loadedValue278.i, i32 1
  %"&(pSB[currWI].offset)284.i" = add nuw i64 %CurrSBIndex..3.i, 98
  %"&pSB[currWI].offset285.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)284.i"
  %loadedValue287.i = load i8* %"&pSB[currWI].offset285.i", align 1
  %665 = insertelement <4 x i8> %664, i8 %loadedValue287.i, i32 2
  %"&(pSB[currWI].offset)293.i" = add nuw i64 %CurrSBIndex..3.i, 99
  %"&pSB[currWI].offset294.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)293.i"
  %loadedValue296.i = load i8* %"&pSB[currWI].offset294.i", align 1
  %666 = insertelement <4 x i8> %665, i8 %loadedValue296.i, i32 3
  %"&(pSB[currWI].offset)165.i" = add nuw i64 %CurrSBIndex..3.i, 40
  %"&pSB[currWI].offset166.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)165.i"
  %CastToValueType167.i = bitcast i8* %"&pSB[currWI].offset166.i" to <4 x i8> addrspace(3)**
  %loadedValue168.i = load <4 x i8> addrspace(3)** %CastToValueType167.i, align 8
  store <4 x i8> %666, <4 x i8> addrspace(3)* %loadedValue168.i, align 4
  %check.WI.iter350.i = icmp ult i64 %CurrWI..3.i, %31
  br i1 %check.WI.iter350.i, label %thenBB347.i, label %SyncBB344.i

thenBB347.i:                                      ; preds = %._crit_edge66.i
  %"CurrWI++351.i" = add nuw i64 %CurrWI..3.i, 1
  %"loadedCurrSB+Stride353.i" = add nuw i64 %CurrSBIndex..3.i, 1712
  br label %SyncBB.i

SyncBB344.i:                                      ; preds = %thenBB354.i, %._crit_edge66.i, %thenBB.i
  %CurrSBIndex..1.i = phi i64 [ %"loadedCurrSB+Stride360.i", %thenBB354.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ], [ 0, %._crit_edge66.i ]
  %currBarrier.0.i = phi i32 [ %currBarrier.1.i, %thenBB354.i ], [ %currBarrier.1.i, %thenBB.i ], [ 1, %._crit_edge66.i ]
  %CurrWI..1.i = phi i64 [ %"CurrWI++358.i", %thenBB354.i ], [ %"CurrWI++.i", %thenBB.i ], [ 0, %._crit_edge66.i ]
  %"&(pSB[currWI].offset)160.i" = add nuw i64 %CurrSBIndex..1.i, 40
  %"&pSB[currWI].offset161.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)160.i"
  %CastToValueType162.i = bitcast i8* %"&pSB[currWI].offset161.i" to <4 x i8> addrspace(3)**
  %loadedValue163.i = load <4 x i8> addrspace(3)** %CastToValueType162.i, align 8
  %667 = load <4 x i8> addrspace(3)* %loadedValue163.i, align 4
  %"&(pSB[currWI].offset)206.i" = add nuw i64 %CurrSBIndex..1.i, 64
  %"&pSB[currWI].offset207.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)206.i"
  %CastToValueType208.i = bitcast i8* %"&pSB[currWI].offset207.i" to i32*
  %loadedValue209.i = load i32* %CastToValueType208.i, align 4
  %668 = zext i32 %loadedValue209.i to i64
  %669 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %668
  %670 = load <4 x i8> addrspace(1)* %669, align 4
  %671 = xor <4 x i8> %667, %670
  %"&(pSB[currWI].offset)298.i" = add nuw i64 %CurrSBIndex..1.i, 100
  %"&pSB[currWI].offset299.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)298.i"
  %CastToValueType300.i = bitcast i8* %"&pSB[currWI].offset299.i" to <4 x i8>*
  store <4 x i8> %671, <4 x i8>* %CastToValueType300.i, align 4
  %"&(pSB[currWI].offset)118.i" = add nuw i64 %CurrSBIndex..1.i, 16
  %"&pSB[currWI].offset119.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)118.i"
  %CastToValueType120.i = bitcast i8* %"&pSB[currWI].offset119.i" to <4 x i8> addrspace(3)**
  %loadedValue121.i = load <4 x i8> addrspace(3)** %CastToValueType120.i, align 8
  store <4 x i8> %671, <4 x i8> addrspace(3)* %loadedValue121.i, align 4
  %"&(pSB[currWI].offset)197.i" = add nuw i64 %CurrSBIndex..1.i, 60
  %"&pSB[currWI].offset198.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)197.i"
  %CastToValueType199.i = bitcast i8* %"&pSB[currWI].offset198.i" to i32*
  %loadedValue200.i = load i32* %CastToValueType199.i, align 4
  %indvar.next80.i = add i32 %loadedValue200.i, 1
  %"&(pSB[currWI].offset)302.i" = add nuw i64 %CurrSBIndex..1.i, 104
  %"&pSB[currWI].offset303.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)302.i"
  %CastToValueType304.i = bitcast i8* %"&pSB[currWI].offset303.i" to i32*
  store i32 %indvar.next80.i, i32* %CastToValueType304.i, align 4
  br label %69

"Barrier BB89.i":                                 ; preds = %shiftRows.exit.i
  %"&pSB[currWI].offset101.i" = getelementptr inbounds i8* %34, i64 %CurrSBIndex..2.i
  %CastToValueType102.i = bitcast i8* %"&pSB[currWI].offset101.i" to i32*
  %loadedValue103.i = load i32* %CastToValueType102.i, align 4
  %672 = add i32 %loadedValue103.i, %35
  %673 = zext i32 %672 to i64
  %674 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %673
  %675 = load <4 x i8> addrspace(1)* %674, align 4
  %"&(pSB[currWI].offset)237.i" = add nuw i64 %CurrSBIndex..2.i, 80
  %"&pSB[currWI].offset238.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)237.i"
  %CastToValueType239.i = bitcast i8* %"&pSB[currWI].offset238.i" to <4 x i8>*
  %loadedValue240.i = load <4 x i8>* %CastToValueType239.i, align 4
  %676 = xor <4 x i8> %loadedValue240.i, %675
  %"&(pSB[currWI].offset)109.i" = add nuw i64 %CurrSBIndex..2.i, 8
  %"&pSB[currWI].offset110.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)109.i"
  %CastToValueType111.i = bitcast i8* %"&pSB[currWI].offset110.i" to i64*
  %loadedValue112.i = load i64* %CastToValueType111.i, align 8
  %677 = getelementptr inbounds <4 x i8> addrspace(1)* %1, i64 %loadedValue112.i
  store <4 x i8> %676, <4 x i8> addrspace(1)* %677, align 4
  %check.WI.iter357.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter357.i, label %thenBB354.i, label %__AESEncrypt_separated_args.exit

thenBB354.i:                                      ; preds = %"Barrier BB89.i"
  %"CurrWI++358.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride360.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond1.i = icmp eq i32 %currBarrier.1.i, 12
  br i1 %cond1.i, label %SyncBB343.i, label %SyncBB344.i

__AESEncrypt_separated_args.exit:                 ; preds = %"Barrier BB89.i"
  ret void
}

define void @AESDecrypt(i8* %pBuffer) {
entry:
  %0 = bitcast i8* %pBuffer to <4 x i8> addrspace(1)**
  %1 = load <4 x i8> addrspace(1)** %0, align 8
  %2 = getelementptr i8* %pBuffer, i64 8
  %3 = bitcast i8* %2 to <4 x i8> addrspace(1)**
  %4 = load <4 x i8> addrspace(1)** %3, align 8
  %5 = getelementptr i8* %pBuffer, i64 16
  %6 = bitcast i8* %5 to <4 x i8> addrspace(1)**
  %7 = load <4 x i8> addrspace(1)** %6, align 8
  %8 = getelementptr i8* %pBuffer, i64 24
  %9 = bitcast i8* %8 to i8 addrspace(1)**
  %10 = load i8 addrspace(1)** %9, align 8
  %11 = getelementptr i8* %pBuffer, i64 32
  %12 = bitcast i8* %11 to <4 x i8> addrspace(3)**
  %13 = load <4 x i8> addrspace(3)** %12, align 8
  %14 = getelementptr i8* %pBuffer, i64 40
  %15 = bitcast i8* %14 to <4 x i8> addrspace(3)**
  %16 = load <4 x i8> addrspace(3)** %15, align 8
  %17 = getelementptr i8* %pBuffer, i64 48
  %18 = bitcast i8* %17 to i32*
  %19 = load i32* %18, align 4
  %20 = getelementptr i8* %pBuffer, i64 52
  %21 = bitcast i8* %20 to i32*
  %22 = load i32* %21, align 4
  %23 = getelementptr i8* %pBuffer, i64 72
  %24 = bitcast i8* %23 to i64**
  %25 = load i64** %24, align 8
  %26 = getelementptr i8* %pBuffer, i64 88
  %27 = bitcast i8* %26 to %struct.PaddedDimId**
  %28 = load %struct.PaddedDimId** %27, align 8
  %29 = getelementptr i8* %pBuffer, i64 104
  %30 = bitcast i8* %29 to i64*
  %31 = load i64* %30, align 8
  %32 = getelementptr i8* %pBuffer, i64 112
  %33 = bitcast i8* %32 to i8**
  %34 = load i8** %33, align 8
  %35 = shl i32 %22, 2
  %tmp81.i = add i32 %22, -1
  br label %SyncBB361.i

SyncBB361.i:                                      ; preds = %thenBB370.i, %thenBB.i, %entry
  %CurrSBIndex..0.i = phi i64 [ 0, %entry ], [ %"loadedCurrSB+Stride376.i", %thenBB370.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ]
  %currBarrier.2.i = phi i32 [ 15, %entry ], [ %currBarrier.1.i, %thenBB370.i ], [ %currBarrier.1.i, %thenBB.i ]
  %CurrWI..0.i = phi i64 [ 0, %entry ], [ %"CurrWI++374.i", %thenBB370.i ], [ %"CurrWI++.i", %thenBB.i ]
  %36 = load i64* %25, align 8
  %37 = trunc i64 %36 to i32
  %38 = getelementptr i64* %25, i64 1
  %39 = load i64* %38, align 8
  %40 = trunc i64 %39 to i32
  %41 = getelementptr %struct.PaddedDimId* %28, i64 %CurrWI..0.i, i32 0, i64 1
  %42 = load i64* %41, align 8
  %43 = trunc i64 %42 to i32
  %"&(pSB[currWI].offset).i" = add nuw i64 %CurrSBIndex..0.i, 128
  %"&pSB[currWI].offset.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset).i"
  %CastToValueType.i = bitcast i8* %"&pSB[currWI].offset.i" to i32*
  store i32 %43, i32* %CastToValueType.i, align 4
  %44 = mul i32 %40, %19
  %45 = shl i32 %37, 2
  %46 = add i32 %44, %45
  %47 = and i32 %46, -4
  %48 = add i32 %47, %43
  %"&(pSB[currWI].offset)354.i" = add nuw i64 %CurrSBIndex..0.i, 256
  %"&pSB[currWI].offset355.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)354.i"
  %49 = bitcast i8* %"&pSB[currWI].offset355.i" to <4 x i8>*
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 16
  %"&pSB[currWI].offset351.sum.i" = add i64 %CurrSBIndex..0.i, 260
  %50 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset351.sum.i"
  %51 = bitcast i8* %50 to <4 x i8>*
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 4
  %"&pSB[currWI].offset347.sum.i" = add i64 %CurrSBIndex..0.i, 264
  %52 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset347.sum.i"
  %53 = bitcast i8* %52 to <4 x i8>*
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 8
  %"&pSB[currWI].offset343.sum.i" = add i64 %CurrSBIndex..0.i, 268
  %54 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset343.sum.i"
  %55 = bitcast i8* %54 to <4 x i8>*
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 4
  %56 = zext i32 %48 to i64
  %"&(pSB[currWI].offset)102.i" = add nuw i64 %CurrSBIndex..0.i, 136
  %"&pSB[currWI].offset103.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)102.i"
  %CastToValueType104.i = bitcast i8* %"&pSB[currWI].offset103.i" to i64*
  store i64 %56, i64* %CastToValueType104.i, align 8
  %57 = getelementptr inbounds <4 x i8> addrspace(1)* %4, i64 %56
  %58 = load <4 x i8> addrspace(1)* %57, align 4
  %59 = and i64 %42, 4294967295
  %"&(pSB[currWI].offset)111.i" = add nuw i64 %CurrSBIndex..0.i, 144
  %"&pSB[currWI].offset112.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)111.i"
  %CastToValueType113.i = bitcast i8* %"&pSB[currWI].offset112.i" to i64*
  store i64 %59, i64* %CastToValueType113.i, align 8
  %60 = getelementptr inbounds <4 x i8> addrspace(3)* %13, i64 %59
  %"&(pSB[currWI].offset)120.i" = add nuw i64 %CurrSBIndex..0.i, 152
  %"&pSB[currWI].offset121.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)120.i"
  %CastToValueType122.i = bitcast i8* %"&pSB[currWI].offset121.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %60, <4 x i8> addrspace(3)** %CastToValueType122.i, align 8
  store <4 x i8> %58, <4 x i8> addrspace(3)* %60, align 4
  %61 = add i32 %43, %35
  %62 = zext i32 %61 to i64
  %63 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %62
  %64 = load <4 x i8> addrspace(1)* %63, align 4
  %65 = xor <4 x i8> %58, %64
  %"&(pSB[currWI].offset)144.i" = add nuw i64 %CurrSBIndex..0.i, 160
  %"&pSB[currWI].offset145.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)144.i"
  %CastToValueType146.i = bitcast i8* %"&pSB[currWI].offset145.i" to <4 x i8>*
  store <4 x i8> %65, <4 x i8>* %CastToValueType146.i, align 4
  store <4 x i8> %65, <4 x i8> addrspace(3)* %60, align 4
  %66 = getelementptr inbounds <4 x i8> addrspace(3)* %16, i64 %59
  %"&(pSB[currWI].offset)148.i" = add nuw i64 %CurrSBIndex..0.i, 168
  %"&pSB[currWI].offset149.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)148.i"
  %CastToValueType150.i = bitcast i8* %"&pSB[currWI].offset149.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %66, <4 x i8> addrspace(3)** %CastToValueType150.i, align 8
  %67 = sub i32 0, %43
  %68 = and i32 %67, 3
  %69 = zext i32 %68 to i64
  %"&(pSB[currWI].offset)338.i" = add nuw i64 %CurrSBIndex..0.i, 256
  %"&pSB[currWI].offset339.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)338.i"
  %CastToValueType340.i = bitcast i8* %"&pSB[currWI].offset339.i" to [4 x <4 x i8>]*
  %70 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType340.i, i64 0, i64 %69
  %"&(pSB[currWI].offset)157.i" = add nuw i64 %CurrSBIndex..0.i, 176
  %"&pSB[currWI].offset158.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)157.i"
  %CastToValueType159.i = bitcast i8* %"&pSB[currWI].offset158.i" to <4 x i8>**
  store <4 x i8>* %70, <4 x i8>** %CastToValueType159.i, align 8
  %tmp75.i = sub i64 1, %42
  %"&(pSB[currWI].offset)181.i" = add nuw i64 %CurrSBIndex..0.i, 184
  %"&pSB[currWI].offset182.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)181.i"
  %CastToValueType183.i = bitcast i8* %"&pSB[currWI].offset182.i" to i64*
  store i64 %tmp75.i, i64* %CastToValueType183.i, align 8
  %tmp86.i = add i32 %35, %43
  %tmp87.i = add i32 %tmp86.i, -4
  %"&(pSB[currWI].offset)190.i" = add nuw i64 %CurrSBIndex..0.i, 192
  %"&pSB[currWI].offset191.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)190.i"
  %CastToValueType192.i = bitcast i8* %"&pSB[currWI].offset191.i" to i32*
  store i32 %tmp87.i, i32* %CastToValueType192.i, align 4
  br label %71

; <label>:71                                      ; preds = %._crit_edge66.i, %SyncBB361.i
  %CurrSBIndex..2.i = phi i64 [ %CurrSBIndex..0.i, %SyncBB361.i ], [ %CurrSBIndex..1.i, %._crit_edge66.i ]
  %currBarrier.1.i = phi i32 [ %currBarrier.2.i, %SyncBB361.i ], [ %currBarrier.0.i, %._crit_edge66.i ]
  %CurrWI..2.i = phi i64 [ %CurrWI..0.i, %SyncBB361.i ], [ %CurrWI..1.i, %._crit_edge66.i ]
  %72 = phi <4 x i8> [ %65, %SyncBB361.i ], [ %673, %._crit_edge66.i ]
  %indvar79.i = phi i32 [ 0, %SyncBB361.i ], [ %indvar.next80.i, %._crit_edge66.i ]
  %"&(pSB[currWI].offset)199.i" = add nuw i64 %CurrSBIndex..2.i, 196
  %"&pSB[currWI].offset200.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)199.i"
  %CastToValueType201.i = bitcast i8* %"&pSB[currWI].offset200.i" to i32*
  store i32 %indvar79.i, i32* %CastToValueType201.i, align 4
  %73 = bitcast <4 x i8> %72 to i32
  %tmp1.i.i = bitcast i32 %73 to <4 x i8>
  %"&(pSB[currWI].offset)218.i" = add nuw i64 %CurrSBIndex..2.i, 200
  %"&pSB[currWI].offset219.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)218.i"
  %CastToValueType220.i = bitcast i8* %"&pSB[currWI].offset219.i" to <4 x i8>*
  store <4 x i8> %tmp1.i.i, <4 x i8>* %CastToValueType220.i, align 4
  %"&(pSB[currWI].offset)97.i" = add nuw i64 %CurrSBIndex..2.i, 128
  %"&pSB[currWI].offset98.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)97.i"
  %CastToValueType99.i = bitcast i8* %"&pSB[currWI].offset98.i" to i32*
  %loadedValue100.i = load i32* %CastToValueType99.i, align 4
  %74 = icmp eq i32 %loadedValue100.i, 0
  br i1 %74, label %shiftRowsInv.exit.i, label %bb.nph.i.preheader.i

bb.nph.i.preheader.i:                             ; preds = %71
  %"&(pSB[currWI].offset)222.i" = add nuw i64 %CurrSBIndex..2.i, 200
  %"&pSB[currWI].offset223.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)222.i"
  %CastToValueType224.i = bitcast i8* %"&pSB[currWI].offset223.i" to <4 x i8>*
  %loadedValue225.i = load <4 x i8>* %CastToValueType224.i, align 4
  %"&(pSB[currWI].offset)227.i" = add nuw i64 %CurrSBIndex..2.i, 204
  %"&pSB[currWI].offset228.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)227.i"
  %CastToValueType229.i = bitcast i8* %"&pSB[currWI].offset228.i" to <4 x i8>*
  %"&(pSB[currWI].offset)236.i" = add nuw i64 %CurrSBIndex..2.i, 208
  %"&pSB[currWI].offset237.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)236.i"
  %CastToValueType238.i = bitcast i8* %"&pSB[currWI].offset237.i" to i32*
  %"&(pSB[currWI].offset)93.i" = add nuw i64 %CurrSBIndex..2.i, 128
  %"&pSB[currWI].offset94.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)93.i"
  %CastToValueType95.i = bitcast i8* %"&pSB[currWI].offset94.i" to i32*
  br label %bb.nph.i.i

bb.nph.i.i:                                       ; preds = %bb.nph.i.i, %bb.nph.i.preheader.i
  %i.03.i.i = phi i32 [ %76, %bb.nph.i.i ], [ 0, %bb.nph.i.preheader.i ]
  %r.02.i.i = phi <4 x i8> [ %75, %bb.nph.i.i ], [ %loadedValue225.i, %bb.nph.i.preheader.i ]
  %75 = shufflevector <4 x i8> %r.02.i.i, <4 x i8> undef, <4 x i32> <i32 3, i32 0, i32 1, i32 2>
  store <4 x i8> %75, <4 x i8>* %CastToValueType229.i, align 4
  %76 = add i32 %i.03.i.i, 1
  store i32 %76, i32* %CastToValueType238.i, align 4
  %loadedValue.i = load i32* %CastToValueType95.i, align 4
  %exitcond.i.i = icmp eq i32 %76, %loadedValue.i
  br i1 %exitcond.i.i, label %shiftRowsInv.exit.loopexit.i, label %bb.nph.i.i

shiftRowsInv.exit.loopexit.i:                     ; preds = %bb.nph.i.i
  %"&(pSB[currWI].offset)231.i" = add nuw i64 %CurrSBIndex..2.i, 204
  %"&pSB[currWI].offset232.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)231.i"
  %CastToValueType233.i = bitcast i8* %"&pSB[currWI].offset232.i" to <4 x i8>*
  %loadedValue234.i = load <4 x i8>* %CastToValueType233.i, align 4
  br label %shiftRowsInv.exit.i

shiftRowsInv.exit.i:                              ; preds = %shiftRowsInv.exit.loopexit.i, %71
  %r.0.lcssa.i.i = phi <4 x i8> [ %tmp1.i.i, %71 ], [ %loadedValue234.i, %shiftRowsInv.exit.loopexit.i ]
  %77 = bitcast <4 x i8> %r.0.lcssa.i.i to i32
  %tmp3.i = bitcast i32 %77 to <4 x i8>
  %"&(pSB[currWI].offset)139.i" = add nuw i64 %CurrSBIndex..2.i, 152
  %"&pSB[currWI].offset140.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)139.i"
  %CastToValueType141.i = bitcast i8* %"&pSB[currWI].offset140.i" to <4 x i8> addrspace(3)**
  %loadedValue142.i = load <4 x i8> addrspace(3)** %CastToValueType141.i, align 8
  store <4 x i8> %tmp3.i, <4 x i8> addrspace(3)* %loadedValue142.i, align 4
  %78 = bitcast <4 x i8> %tmp3.i to i32
  %tmp1.i89.i = bitcast i32 %78 to <4 x i8>
  %79 = extractelement <4 x i8> %tmp1.i89.i, i32 0
  %80 = zext i8 %79 to i64
  %81 = getelementptr inbounds i8 addrspace(1)* %10, i64 %80
  %82 = load i8 addrspace(1)* %81, align 1
  %83 = insertelement <4 x i8> undef, i8 %82, i32 0
  %84 = extractelement <4 x i8> %tmp1.i89.i, i32 1
  %85 = zext i8 %84 to i64
  %86 = getelementptr inbounds i8 addrspace(1)* %10, i64 %85
  %87 = load i8 addrspace(1)* %86, align 1
  %88 = insertelement <4 x i8> %83, i8 %87, i32 1
  %89 = extractelement <4 x i8> %tmp1.i89.i, i32 2
  %90 = zext i8 %89 to i64
  %91 = getelementptr inbounds i8 addrspace(1)* %10, i64 %90
  %92 = load i8 addrspace(1)* %91, align 1
  %93 = insertelement <4 x i8> %88, i8 %92, i32 2
  %94 = extractelement <4 x i8> %tmp1.i89.i, i32 3
  %95 = zext i8 %94 to i64
  %96 = getelementptr inbounds i8 addrspace(1)* %10, i64 %95
  %97 = load i8 addrspace(1)* %96, align 1
  %98 = insertelement <4 x i8> %93, i8 %97, i32 3
  %99 = bitcast <4 x i8> %98 to i32
  %tmp1.i = bitcast i32 %99 to <4 x i8>
  %"&(pSB[currWI].offset)240.i" = add nuw i64 %CurrSBIndex..2.i, 212
  %"&pSB[currWI].offset241.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)240.i"
  %CastToValueType242.i = bitcast i8* %"&pSB[currWI].offset241.i" to <4 x i8>*
  store <4 x i8> %tmp1.i, <4 x i8>* %CastToValueType242.i, align 4
  %"&(pSB[currWI].offset)134.i" = add nuw i64 %CurrSBIndex..2.i, 152
  %"&pSB[currWI].offset135.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)134.i"
  %CastToValueType136.i = bitcast i8* %"&pSB[currWI].offset135.i" to <4 x i8> addrspace(3)**
  %loadedValue137.i = load <4 x i8> addrspace(3)** %CastToValueType136.i, align 8
  store <4 x i8> %tmp1.i, <4 x i8> addrspace(3)* %loadedValue137.i, align 4
  %"&(pSB[currWI].offset)208.i" = add nuw i64 %CurrSBIndex..2.i, 196
  %"&pSB[currWI].offset209.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)208.i"
  %CastToValueType210.i = bitcast i8* %"&pSB[currWI].offset209.i" to i32*
  %loadedValue211.i = load i32* %CastToValueType210.i, align 4
  %exitcond82.i = icmp eq i32 %loadedValue211.i, %tmp81.i
  br i1 %exitcond82.i, label %"Barrier BB91.i", label %bb.nph65.i

bb.nph65.i:                                       ; preds = %shiftRowsInv.exit.i
  %"&(pSB[currWI].offset)203.i" = add nuw i64 %CurrSBIndex..2.i, 196
  %"&pSB[currWI].offset204.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)203.i"
  %CastToValueType205.i = bitcast i8* %"&pSB[currWI].offset204.i" to i32*
  %loadedValue206.i = load i32* %CastToValueType205.i, align 4
  %tmp83.i = mul i32 %loadedValue206.i, -4
  %"&(pSB[currWI].offset)194.i" = add nuw i64 %CurrSBIndex..2.i, 192
  %"&pSB[currWI].offset195.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)194.i"
  %CastToValueType196.i = bitcast i8* %"&pSB[currWI].offset195.i" to i32*
  %loadedValue197.i = load i32* %CastToValueType196.i, align 4
  %tmp88.i = add i32 %loadedValue197.i, %tmp83.i
  %"&(pSB[currWI].offset)249.i" = add nuw i64 %CurrSBIndex..2.i, 216
  %"&pSB[currWI].offset250.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)249.i"
  %CastToValueType251.i = bitcast i8* %"&pSB[currWI].offset250.i" to i32*
  store i32 %tmp88.i, i32* %CastToValueType251.i, align 4
  %check.WI.iter.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter.i, label %thenBB.i, label %SyncBB.i

thenBB.i:                                         ; preds = %bb.nph65.i
  %"CurrWI++.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond.i = icmp eq i32 %currBarrier.1.i, 4
  br i1 %cond.i, label %SyncBB359.i, label %SyncBB361.i

SyncBB.i:                                         ; preds = %thenBB363.i, %bb.nph65.i
  %CurrSBIndex..3.i = phi i64 [ %"loadedCurrSB+Stride369.i", %thenBB363.i ], [ 0, %bb.nph65.i ]
  %CurrWI..3.i = phi i64 [ %"CurrWI++367.i", %thenBB363.i ], [ 0, %bb.nph65.i ]
  %"&(pSB[currWI].offset)129.i" = add nuw i64 %CurrSBIndex..3.i, 152
  %"&pSB[currWI].offset130.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)129.i"
  %CastToValueType131.i = bitcast i8* %"&pSB[currWI].offset130.i" to <4 x i8> addrspace(3)**
  %loadedValue132.i = load <4 x i8> addrspace(3)** %CastToValueType131.i, align 8
  %100 = load <4 x i8> addrspace(3)* %loadedValue132.i, align 4
  %"&(pSB[currWI].offset)253.i" = add nuw i64 %CurrSBIndex..3.i, 216
  %"&pSB[currWI].offset254.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)253.i"
  %CastToValueType255.i = bitcast i8* %"&pSB[currWI].offset254.i" to i32*
  %loadedValue256.i = load i32* %CastToValueType255.i, align 4
  %101 = zext i32 %loadedValue256.i to i64
  %102 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %101
  %103 = load <4 x i8> addrspace(1)* %102, align 4
  %104 = xor <4 x i8> %100, %103
  %"&(pSB[currWI].offset)152.i" = add nuw i64 %CurrSBIndex..3.i, 168
  %"&pSB[currWI].offset153.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)152.i"
  %CastToValueType154.i = bitcast i8* %"&pSB[currWI].offset153.i" to <4 x i8> addrspace(3)**
  %loadedValue155.i = load <4 x i8> addrspace(3)** %CastToValueType154.i, align 8
  store <4 x i8> %104, <4 x i8> addrspace(3)* %loadedValue155.i, align 4
  %check.WI.iter366.i = icmp ult i64 %CurrWI..3.i, %31
  br i1 %check.WI.iter366.i, label %thenBB363.i, label %SyncBB359.i

thenBB363.i:                                      ; preds = %SyncBB.i
  %"CurrWI++367.i" = add nuw i64 %CurrWI..3.i, 1
  %"loadedCurrSB+Stride369.i" = add nuw i64 %CurrSBIndex..3.i, 1712
  br label %SyncBB.i

SyncBB359.i:                                      ; preds = %thenBB370.i, %SyncBB.i, %thenBB.i
  %CurrSBIndex..1.i = phi i64 [ %"loadedCurrSB+Stride376.i", %thenBB370.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ], [ 0, %SyncBB.i ]
  %currBarrier.0.i = phi i32 [ %currBarrier.1.i, %thenBB370.i ], [ %currBarrier.1.i, %thenBB.i ], [ 4, %SyncBB.i ]
  %CurrWI..1.i = phi i64 [ %"CurrWI++374.i", %thenBB370.i ], [ %"CurrWI++.i", %thenBB.i ], [ 0, %SyncBB.i ]
  %"&(pSB[currWI].offset)176.i" = add nuw i64 %CurrSBIndex..1.i, 176
  %"&pSB[currWI].offset177.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)176.i"
  %CastToValueType178.i = bitcast i8* %"&pSB[currWI].offset177.i" to <4 x i8>**
  %loadedValue179.i = load <4 x i8>** %CastToValueType178.i, align 8
  %105 = load <4 x i8>* %loadedValue179.i, align 4
  %106 = load <4 x i8> addrspace(3)* %16, align 4
  %107 = extractelement <4 x i8> %105, i32 0
  %108 = extractelement <4 x i8> %106, i32 0
  %109 = zext i8 %108 to i32
  %110 = shl i32 %109, 1
  %111 = and i32 %109, 128
  %112 = xor i32 %110, 27
  %113 = icmp eq i32 %111, 0
  %a.1.in.i = select i1 %113, i32 %110, i32 %112
  %114 = shl i32 %a.1.in.i, 1
  %115 = and i32 %a.1.in.i, 128
  %116 = xor i32 %114, 27
  %117 = icmp eq i32 %115, 0
  %a.1.in.1.i = select i1 %117, i32 %114, i32 %116
  %118 = shl i32 %a.1.in.1.i, 1
  %119 = and i32 %a.1.in.1.i, 128
  %120 = xor i32 %118, 27
  %121 = icmp eq i32 %119, 0
  %a.1.in.2.i = select i1 %121, i32 %118, i32 %120
  %122 = shl i32 %a.1.in.2.i, 1
  %123 = and i32 %a.1.in.2.i, 128
  %124 = xor i32 %122, 27
  %125 = icmp eq i32 %123, 0
  %a.1.in.3.i = select i1 %125, i32 %122, i32 %124
  %126 = shl i32 %a.1.in.3.i, 1
  %127 = and i32 %a.1.in.3.i, 128
  %128 = xor i32 %126, 27
  %129 = icmp eq i32 %127, 0
  %a.1.in.4.i = select i1 %129, i32 %126, i32 %128
  %130 = shl i32 %a.1.in.4.i, 1
  %131 = and i32 %a.1.in.4.i, 128
  %132 = xor i32 %130, 27
  %133 = icmp eq i32 %131, 0
  %a.1.in.5.i = select i1 %133, i32 %130, i32 %132
  %134 = shl i32 %a.1.in.5.i, 1
  %135 = lshr i8 %107, 1
  %136 = zext i8 %135 to i32
  %137 = zext i8 %107 to i32
  %138 = lshr i8 %107, 2
  %139 = lshr i8 %107, 3
  %140 = and i32 %136, 1
  %141 = and i32 %137, 1
  %142 = zext i8 %138 to i32
  %143 = zext i8 %139 to i32
  %144 = icmp eq i32 %140, 0
  %a.1.i = trunc i32 %a.1.in.i to i8
  %145 = icmp eq i32 %141, 0
  %146 = and i32 %142, 1
  %147 = lshr i8 %107, 4
  %148 = lshr i8 %107, 5
  %149 = and i32 %143, 1
  %150 = select i1 %144, i8 0, i8 %a.1.i
  %151 = select i1 %145, i8 0, i8 %108
  %a.1.1.i = trunc i32 %a.1.in.1.i to i8
  %152 = icmp eq i32 %146, 0
  %153 = zext i8 %147 to i32
  %154 = zext i8 %148 to i32
  %155 = icmp eq i32 %149, 0
  %a.1.2.i = trunc i32 %a.1.in.2.i to i8
  %p.1..1.i = xor i8 %150, %151
  %156 = select i1 %152, i8 0, i8 %a.1.1.i
  %157 = and i32 %153, 1
  %158 = lshr i8 %107, 6
  %159 = and i32 %a.1.in.5.i, 128
  %160 = and i32 %154, 1
  %161 = select i1 %155, i8 0, i8 %a.1.2.i
  %p.1..2.i = xor i8 %156, %p.1..1.i
  %a.1.3.i = trunc i32 %a.1.in.3.i to i8
  %162 = icmp eq i32 %157, 0
  %163 = zext i8 %158 to i32
  %164 = icmp eq i32 %159, 0
  %165 = xor i32 %134, 27
  %166 = icmp eq i32 %160, 0
  %a.1.4.i = trunc i32 %a.1.in.4.i to i8
  %p.1..3.i = xor i8 %161, %p.1..2.i
  %167 = select i1 %162, i8 0, i8 %a.1.3.i
  %168 = and i32 %163, 1
  %a.1.in.6.i = select i1 %164, i32 %134, i32 %165
  %169 = select i1 %166, i8 0, i8 %a.1.4.i
  %p.1..4.i = xor i8 %167, %p.1..3.i
  %a.1.5.i = trunc i32 %a.1.in.5.i to i8
  %170 = icmp eq i32 %168, 0
  %171 = icmp sgt i8 %107, -1
  %a.1.6.i = trunc i32 %a.1.in.6.i to i8
  %p.1..5.i = xor i8 %169, %p.1..4.i
  %172 = select i1 %170, i8 0, i8 %a.1.5.i
  %173 = select i1 %171, i8 0, i8 %a.1.6.i
  %p.1..6.i = xor i8 %172, %p.1..5.i
  %p.1..7.i = xor i8 %173, %p.1..6.i
  %"&(pSB[currWI].offset)258.i" = add nuw i64 %CurrSBIndex..1.i, 220
  %"&pSB[currWI].offset259.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)258.i"
  store i8 %p.1..7.i, i8* %"&pSB[currWI].offset259.i", align 1
  %"&(pSB[currWI].offset)171.i" = add nuw i64 %CurrSBIndex..1.i, 176
  %"&pSB[currWI].offset172.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)171.i"
  %CastToValueType173.i = bitcast i8* %"&pSB[currWI].offset172.i" to <4 x i8>**
  %loadedValue174.i = load <4 x i8>** %CastToValueType173.i, align 8
  %174 = load <4 x i8>* %loadedValue174.i, align 4
  %175 = load <4 x i8> addrspace(3)* %16, align 4
  %176 = extractelement <4 x i8> %174, i32 0
  %177 = extractelement <4 x i8> %175, i32 1
  %178 = zext i8 %177 to i32
  %179 = shl i32 %178, 1
  %180 = and i32 %178, 128
  %181 = xor i32 %179, 27
  %182 = icmp eq i32 %180, 0
  %a.3.in.i = select i1 %182, i32 %179, i32 %181
  %183 = shl i32 %a.3.in.i, 1
  %184 = and i32 %a.3.in.i, 128
  %185 = xor i32 %183, 27
  %186 = icmp eq i32 %184, 0
  %a.3.in.1.i = select i1 %186, i32 %183, i32 %185
  %187 = shl i32 %a.3.in.1.i, 1
  %188 = and i32 %a.3.in.1.i, 128
  %189 = xor i32 %187, 27
  %190 = icmp eq i32 %188, 0
  %a.3.in.2.i = select i1 %190, i32 %187, i32 %189
  %191 = shl i32 %a.3.in.2.i, 1
  %192 = and i32 %a.3.in.2.i, 128
  %193 = xor i32 %191, 27
  %194 = icmp eq i32 %192, 0
  %a.3.in.3.i = select i1 %194, i32 %191, i32 %193
  %195 = shl i32 %a.3.in.3.i, 1
  %196 = and i32 %a.3.in.3.i, 128
  %197 = xor i32 %195, 27
  %198 = icmp eq i32 %196, 0
  %a.3.in.4.i = select i1 %198, i32 %195, i32 %197
  %199 = shl i32 %a.3.in.4.i, 1
  %200 = and i32 %a.3.in.4.i, 128
  %201 = xor i32 %199, 27
  %202 = icmp eq i32 %200, 0
  %a.3.in.5.i = select i1 %202, i32 %199, i32 %201
  %203 = shl i32 %a.3.in.5.i, 1
  %204 = lshr i8 %176, 1
  %205 = zext i8 %204 to i32
  %206 = zext i8 %176 to i32
  %207 = lshr i8 %176, 2
  %208 = lshr i8 %176, 3
  %209 = and i32 %205, 1
  %210 = and i32 %206, 1
  %211 = zext i8 %207 to i32
  %212 = zext i8 %208 to i32
  %213 = icmp eq i32 %209, 0
  %a.3.i = trunc i32 %a.3.in.i to i8
  %214 = icmp eq i32 %210, 0
  %215 = and i32 %211, 1
  %216 = lshr i8 %176, 4
  %217 = lshr i8 %176, 5
  %218 = and i32 %212, 1
  %219 = select i1 %213, i8 0, i8 %a.3.i
  %220 = select i1 %214, i8 0, i8 %177
  %a.3.1.i = trunc i32 %a.3.in.1.i to i8
  %221 = icmp eq i32 %215, 0
  %222 = zext i8 %216 to i32
  %223 = zext i8 %217 to i32
  %224 = icmp eq i32 %218, 0
  %a.3.2.i = trunc i32 %a.3.in.2.i to i8
  %p.3..1.i = xor i8 %219, %220
  %225 = select i1 %221, i8 0, i8 %a.3.1.i
  %226 = and i32 %222, 1
  %227 = lshr i8 %176, 6
  %228 = and i32 %a.3.in.5.i, 128
  %229 = and i32 %223, 1
  %230 = select i1 %224, i8 0, i8 %a.3.2.i
  %p.3..2.i = xor i8 %225, %p.3..1.i
  %a.3.3.i = trunc i32 %a.3.in.3.i to i8
  %231 = icmp eq i32 %226, 0
  %232 = zext i8 %227 to i32
  %233 = icmp eq i32 %228, 0
  %234 = xor i32 %203, 27
  %235 = icmp eq i32 %229, 0
  %a.3.4.i = trunc i32 %a.3.in.4.i to i8
  %p.3..3.i = xor i8 %230, %p.3..2.i
  %236 = select i1 %231, i8 0, i8 %a.3.3.i
  %237 = and i32 %232, 1
  %a.3.in.6.i = select i1 %233, i32 %203, i32 %234
  %238 = select i1 %235, i8 0, i8 %a.3.4.i
  %p.3..4.i = xor i8 %236, %p.3..3.i
  %a.3.5.i = trunc i32 %a.3.in.5.i to i8
  %239 = icmp eq i32 %237, 0
  %240 = icmp sgt i8 %176, -1
  %a.3.6.i = trunc i32 %a.3.in.6.i to i8
  %p.3..5.i = xor i8 %238, %p.3..4.i
  %241 = select i1 %239, i8 0, i8 %a.3.5.i
  %242 = select i1 %240, i8 0, i8 %a.3.6.i
  %p.3..6.i = xor i8 %241, %p.3..5.i
  %p.3..7.i = xor i8 %242, %p.3..6.i
  %"&(pSB[currWI].offset)262.i" = add nuw i64 %CurrSBIndex..1.i, 221
  %"&pSB[currWI].offset263.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)262.i"
  store i8 %p.3..7.i, i8* %"&pSB[currWI].offset263.i", align 1
  %"&(pSB[currWI].offset)166.i" = add nuw i64 %CurrSBIndex..1.i, 176
  %"&pSB[currWI].offset167.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)166.i"
  %CastToValueType168.i = bitcast i8* %"&pSB[currWI].offset167.i" to <4 x i8>**
  %loadedValue169.i = load <4 x i8>** %CastToValueType168.i, align 8
  %243 = load <4 x i8>* %loadedValue169.i, align 4
  %244 = load <4 x i8> addrspace(3)* %16, align 4
  %245 = extractelement <4 x i8> %243, i32 0
  %246 = extractelement <4 x i8> %244, i32 2
  %247 = zext i8 %246 to i32
  %248 = shl i32 %247, 1
  %249 = and i32 %247, 128
  %250 = xor i32 %248, 27
  %251 = icmp eq i32 %249, 0
  %a.5.in.i = select i1 %251, i32 %248, i32 %250
  %252 = shl i32 %a.5.in.i, 1
  %253 = and i32 %a.5.in.i, 128
  %254 = xor i32 %252, 27
  %255 = icmp eq i32 %253, 0
  %a.5.in.1.i = select i1 %255, i32 %252, i32 %254
  %256 = shl i32 %a.5.in.1.i, 1
  %257 = and i32 %a.5.in.1.i, 128
  %258 = xor i32 %256, 27
  %259 = icmp eq i32 %257, 0
  %a.5.in.2.i = select i1 %259, i32 %256, i32 %258
  %260 = shl i32 %a.5.in.2.i, 1
  %261 = and i32 %a.5.in.2.i, 128
  %262 = xor i32 %260, 27
  %263 = icmp eq i32 %261, 0
  %a.5.in.3.i = select i1 %263, i32 %260, i32 %262
  %264 = shl i32 %a.5.in.3.i, 1
  %265 = and i32 %a.5.in.3.i, 128
  %266 = xor i32 %264, 27
  %267 = icmp eq i32 %265, 0
  %a.5.in.4.i = select i1 %267, i32 %264, i32 %266
  %268 = shl i32 %a.5.in.4.i, 1
  %269 = and i32 %a.5.in.4.i, 128
  %270 = xor i32 %268, 27
  %271 = icmp eq i32 %269, 0
  %a.5.in.5.i = select i1 %271, i32 %268, i32 %270
  %272 = shl i32 %a.5.in.5.i, 1
  %273 = lshr i8 %245, 1
  %274 = zext i8 %273 to i32
  %275 = zext i8 %245 to i32
  %276 = lshr i8 %245, 2
  %277 = lshr i8 %245, 3
  %278 = and i32 %274, 1
  %279 = and i32 %275, 1
  %280 = zext i8 %276 to i32
  %281 = zext i8 %277 to i32
  %282 = icmp eq i32 %278, 0
  %a.5.i = trunc i32 %a.5.in.i to i8
  %283 = icmp eq i32 %279, 0
  %284 = and i32 %280, 1
  %285 = lshr i8 %245, 4
  %286 = lshr i8 %245, 5
  %287 = and i32 %281, 1
  %288 = select i1 %282, i8 0, i8 %a.5.i
  %289 = select i1 %283, i8 0, i8 %246
  %a.5.1.i = trunc i32 %a.5.in.1.i to i8
  %290 = icmp eq i32 %284, 0
  %291 = zext i8 %285 to i32
  %292 = zext i8 %286 to i32
  %293 = icmp eq i32 %287, 0
  %a.5.2.i = trunc i32 %a.5.in.2.i to i8
  %p.5..1.i = xor i8 %288, %289
  %294 = select i1 %290, i8 0, i8 %a.5.1.i
  %295 = and i32 %291, 1
  %296 = lshr i8 %245, 6
  %297 = and i32 %a.5.in.5.i, 128
  %298 = and i32 %292, 1
  %299 = select i1 %293, i8 0, i8 %a.5.2.i
  %p.5..2.i = xor i8 %294, %p.5..1.i
  %a.5.3.i = trunc i32 %a.5.in.3.i to i8
  %300 = icmp eq i32 %295, 0
  %301 = zext i8 %296 to i32
  %302 = icmp eq i32 %297, 0
  %303 = xor i32 %272, 27
  %304 = icmp eq i32 %298, 0
  %a.5.4.i = trunc i32 %a.5.in.4.i to i8
  %p.5..3.i = xor i8 %299, %p.5..2.i
  %305 = select i1 %300, i8 0, i8 %a.5.3.i
  %306 = and i32 %301, 1
  %a.5.in.6.i = select i1 %302, i32 %272, i32 %303
  %307 = select i1 %304, i8 0, i8 %a.5.4.i
  %p.5..4.i = xor i8 %305, %p.5..3.i
  %a.5.5.i = trunc i32 %a.5.in.5.i to i8
  %308 = icmp eq i32 %306, 0
  %309 = icmp sgt i8 %245, -1
  %a.5.6.i = trunc i32 %a.5.in.6.i to i8
  %p.5..5.i = xor i8 %307, %p.5..4.i
  %310 = select i1 %308, i8 0, i8 %a.5.5.i
  %311 = select i1 %309, i8 0, i8 %a.5.6.i
  %p.5..6.i = xor i8 %310, %p.5..5.i
  %p.5..7.i = xor i8 %311, %p.5..6.i
  %"&(pSB[currWI].offset)266.i" = add nuw i64 %CurrSBIndex..1.i, 222
  %"&pSB[currWI].offset267.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)266.i"
  store i8 %p.5..7.i, i8* %"&pSB[currWI].offset267.i", align 1
  %"&(pSB[currWI].offset)161.i" = add nuw i64 %CurrSBIndex..1.i, 176
  %"&pSB[currWI].offset162.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)161.i"
  %CastToValueType163.i = bitcast i8* %"&pSB[currWI].offset162.i" to <4 x i8>**
  %loadedValue164.i = load <4 x i8>** %CastToValueType163.i, align 8
  %312 = load <4 x i8>* %loadedValue164.i, align 4
  %313 = load <4 x i8> addrspace(3)* %16, align 4
  %314 = extractelement <4 x i8> %312, i32 0
  %315 = extractelement <4 x i8> %313, i32 3
  %316 = zext i8 %315 to i32
  %317 = shl i32 %316, 1
  %318 = and i32 %316, 128
  %319 = xor i32 %317, 27
  %320 = icmp eq i32 %318, 0
  %a.7.in.i = select i1 %320, i32 %317, i32 %319
  %321 = shl i32 %a.7.in.i, 1
  %322 = and i32 %a.7.in.i, 128
  %323 = xor i32 %321, 27
  %324 = icmp eq i32 %322, 0
  %a.7.in.1.i = select i1 %324, i32 %321, i32 %323
  %325 = shl i32 %a.7.in.1.i, 1
  %326 = and i32 %a.7.in.1.i, 128
  %327 = xor i32 %325, 27
  %328 = icmp eq i32 %326, 0
  %a.7.in.2.i = select i1 %328, i32 %325, i32 %327
  %329 = shl i32 %a.7.in.2.i, 1
  %330 = and i32 %a.7.in.2.i, 128
  %331 = xor i32 %329, 27
  %332 = icmp eq i32 %330, 0
  %a.7.in.3.i = select i1 %332, i32 %329, i32 %331
  %333 = shl i32 %a.7.in.3.i, 1
  %334 = and i32 %a.7.in.3.i, 128
  %335 = xor i32 %333, 27
  %336 = icmp eq i32 %334, 0
  %a.7.in.4.i = select i1 %336, i32 %333, i32 %335
  %337 = shl i32 %a.7.in.4.i, 1
  %338 = and i32 %a.7.in.4.i, 128
  %339 = xor i32 %337, 27
  %340 = icmp eq i32 %338, 0
  %a.7.in.5.i = select i1 %340, i32 %337, i32 %339
  %341 = shl i32 %a.7.in.5.i, 1
  %342 = lshr i8 %314, 1
  %343 = zext i8 %342 to i32
  %344 = zext i8 %314 to i32
  %345 = lshr i8 %314, 2
  %346 = lshr i8 %314, 3
  %347 = and i32 %343, 1
  %348 = and i32 %344, 1
  %349 = zext i8 %345 to i32
  %350 = zext i8 %346 to i32
  %351 = icmp eq i32 %347, 0
  %a.7.i = trunc i32 %a.7.in.i to i8
  %352 = icmp eq i32 %348, 0
  %353 = and i32 %349, 1
  %354 = lshr i8 %314, 4
  %355 = lshr i8 %314, 5
  %356 = and i32 %350, 1
  %357 = select i1 %351, i8 0, i8 %a.7.i
  %358 = select i1 %352, i8 0, i8 %315
  %a.7.1.i = trunc i32 %a.7.in.1.i to i8
  %359 = icmp eq i32 %353, 0
  %360 = zext i8 %354 to i32
  %361 = zext i8 %355 to i32
  %362 = icmp eq i32 %356, 0
  %a.7.2.i = trunc i32 %a.7.in.2.i to i8
  %p.7..1.i = xor i8 %357, %358
  %363 = select i1 %359, i8 0, i8 %a.7.1.i
  %364 = and i32 %360, 1
  %365 = lshr i8 %314, 6
  %366 = and i32 %a.7.in.5.i, 128
  %367 = and i32 %361, 1
  %368 = select i1 %362, i8 0, i8 %a.7.2.i
  %p.7..2.i = xor i8 %363, %p.7..1.i
  %a.7.3.i = trunc i32 %a.7.in.3.i to i8
  %369 = icmp eq i32 %364, 0
  %370 = zext i8 %365 to i32
  %371 = icmp eq i32 %366, 0
  %372 = xor i32 %341, 27
  %373 = icmp eq i32 %367, 0
  %a.7.4.i = trunc i32 %a.7.in.4.i to i8
  %p.7..3.i = xor i8 %368, %p.7..2.i
  %374 = select i1 %369, i8 0, i8 %a.7.3.i
  %375 = and i32 %370, 1
  %a.7.in.6.i = select i1 %371, i32 %341, i32 %372
  %376 = select i1 %373, i8 0, i8 %a.7.4.i
  %p.7..4.i = xor i8 %374, %p.7..3.i
  %a.7.5.i = trunc i32 %a.7.in.5.i to i8
  %377 = icmp eq i32 %375, 0
  %378 = icmp sgt i8 %314, -1
  %a.7.6.i = trunc i32 %a.7.in.6.i to i8
  %p.7..5.i = xor i8 %376, %p.7..4.i
  %379 = select i1 %377, i8 0, i8 %a.7.5.i
  %380 = select i1 %378, i8 0, i8 %a.7.6.i
  %p.7..6.i = xor i8 %379, %p.7..5.i
  %p.7..7.i = xor i8 %380, %p.7..6.i
  %"&(pSB[currWI].offset)270.i" = add nuw i64 %CurrSBIndex..1.i, 223
  %"&pSB[currWI].offset271.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)270.i"
  store i8 %p.7..7.i, i8* %"&pSB[currWI].offset271.i", align 1
  %"&(pSB[currWI].offset)274.i" = add nuw i64 %CurrSBIndex..1.i, 224
  %"&pSB[currWI].offset275.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)274.i"
  %CastToValueType276.i = bitcast i8* %"&pSB[currWI].offset275.i" to i64*
  %"&(pSB[currWI].offset)185.i" = add nuw i64 %CurrSBIndex..1.i, 184
  %"&pSB[currWI].offset186.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)185.i"
  %CastToValueType187.i = bitcast i8* %"&pSB[currWI].offset186.i" to i64*
  %"&(pSB[currWI].offset)334.i" = add nuw i64 %CurrSBIndex..1.i, 256
  %"&pSB[currWI].offset335.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)334.i"
  %CastToValueType336.i = bitcast i8* %"&pSB[currWI].offset335.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)330.i" = add nuw i64 %CurrSBIndex..1.i, 256
  %"&pSB[currWI].offset331.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)330.i"
  %CastToValueType332.i = bitcast i8* %"&pSB[currWI].offset331.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)326.i" = add nuw i64 %CurrSBIndex..1.i, 256
  %"&pSB[currWI].offset327.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)326.i"
  %CastToValueType328.i = bitcast i8* %"&pSB[currWI].offset327.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)322.i" = add nuw i64 %CurrSBIndex..1.i, 256
  %"&pSB[currWI].offset323.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)322.i"
  %CastToValueType324.i = bitcast i8* %"&pSB[currWI].offset323.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)278.i" = add nuw i64 %CurrSBIndex..1.i, 232
  %"&pSB[currWI].offset279.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)278.i"
  %"&(pSB[currWI].offset)287.i" = add nuw i64 %CurrSBIndex..1.i, 233
  %"&pSB[currWI].offset288.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)287.i"
  %"&(pSB[currWI].offset)296.i" = add nuw i64 %CurrSBIndex..1.i, 234
  %"&pSB[currWI].offset297.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)296.i"
  %"&(pSB[currWI].offset)305.i" = add nuw i64 %CurrSBIndex..1.i, 235
  %"&pSB[currWI].offset306.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)305.i"
  br label %381

; <label>:381                                     ; preds = %381, %SyncBB359.i
  %indvar.i = phi i64 [ 0, %SyncBB359.i ], [ %tmp.i, %381 ]
  %w.063.i = phi i8 [ %p.7..7.i, %SyncBB359.i ], [ %669, %381 ]
  %z.062.i = phi i8 [ %p.5..7.i, %SyncBB359.i ], [ %668, %381 ]
  %y.061.i = phi i8 [ %p.3..7.i, %SyncBB359.i ], [ %667, %381 ]
  %x.060.i = phi i8 [ %p.1..7.i, %SyncBB359.i ], [ %666, %381 ]
  %tmp.i = add i64 %indvar.i, 1
  store i64 %tmp.i, i64* %CastToValueType276.i, align 8
  %scevgep.i = getelementptr <4 x i8> addrspace(3)* %16, i64 %tmp.i
  %loadedValue188.i = load i64* %CastToValueType187.i, align 8
  %tmp77.i = add i64 %loadedValue188.i, %indvar.i
  %382 = and i64 %tmp77.i, 3
  %383 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType336.i, i64 0, i64 %382
  %384 = load <4 x i8>* %383, align 4
  %385 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %386 = extractelement <4 x i8> %384, i32 0
  %387 = extractelement <4 x i8> %385, i32 0
  %388 = zext i8 %387 to i32
  %389 = shl i32 %388, 1
  %390 = and i32 %388, 128
  %391 = xor i32 %389, 27
  %392 = icmp eq i32 %390, 0
  %a.9.in.i = select i1 %392, i32 %389, i32 %391
  %393 = shl i32 %a.9.in.i, 1
  %394 = and i32 %a.9.in.i, 128
  %395 = xor i32 %393, 27
  %396 = icmp eq i32 %394, 0
  %a.9.in.1.i = select i1 %396, i32 %393, i32 %395
  %397 = shl i32 %a.9.in.1.i, 1
  %398 = and i32 %a.9.in.1.i, 128
  %399 = xor i32 %397, 27
  %400 = icmp eq i32 %398, 0
  %a.9.in.2.i = select i1 %400, i32 %397, i32 %399
  %401 = shl i32 %a.9.in.2.i, 1
  %402 = and i32 %a.9.in.2.i, 128
  %403 = xor i32 %401, 27
  %404 = icmp eq i32 %402, 0
  %a.9.in.3.i = select i1 %404, i32 %401, i32 %403
  %405 = shl i32 %a.9.in.3.i, 1
  %406 = and i32 %a.9.in.3.i, 128
  %407 = xor i32 %405, 27
  %408 = icmp eq i32 %406, 0
  %a.9.in.4.i = select i1 %408, i32 %405, i32 %407
  %409 = shl i32 %a.9.in.4.i, 1
  %410 = and i32 %a.9.in.4.i, 128
  %411 = xor i32 %409, 27
  %412 = icmp eq i32 %410, 0
  %a.9.in.5.i = select i1 %412, i32 %409, i32 %411
  %413 = shl i32 %a.9.in.5.i, 1
  %414 = lshr i8 %386, 1
  %415 = zext i8 %414 to i32
  %416 = zext i8 %386 to i32
  %417 = lshr i8 %386, 2
  %418 = lshr i8 %386, 3
  %419 = and i32 %415, 1
  %420 = and i32 %416, 1
  %421 = zext i8 %417 to i32
  %422 = zext i8 %418 to i32
  %423 = icmp eq i32 %419, 0
  %a.9.i = trunc i32 %a.9.in.i to i8
  %424 = icmp eq i32 %420, 0
  %425 = and i32 %421, 1
  %426 = lshr i8 %386, 4
  %427 = lshr i8 %386, 5
  %428 = and i32 %422, 1
  %429 = select i1 %423, i8 0, i8 %a.9.i
  %430 = select i1 %424, i8 0, i8 %387
  %a.9.1.i = trunc i32 %a.9.in.1.i to i8
  %431 = icmp eq i32 %425, 0
  %432 = zext i8 %426 to i32
  %433 = zext i8 %427 to i32
  %434 = icmp eq i32 %428, 0
  %a.9.2.i = trunc i32 %a.9.in.2.i to i8
  %p.9..1.i = xor i8 %429, %430
  %435 = select i1 %431, i8 0, i8 %a.9.1.i
  %436 = and i32 %432, 1
  %437 = lshr i8 %386, 6
  %438 = and i32 %a.9.in.5.i, 128
  %439 = and i32 %433, 1
  %440 = select i1 %434, i8 0, i8 %a.9.2.i
  %p.9..2.i = xor i8 %435, %p.9..1.i
  %a.9.3.i = trunc i32 %a.9.in.3.i to i8
  %441 = icmp eq i32 %436, 0
  %442 = zext i8 %437 to i32
  %443 = icmp eq i32 %438, 0
  %444 = xor i32 %413, 27
  %445 = icmp eq i32 %439, 0
  %a.9.4.i = trunc i32 %a.9.in.4.i to i8
  %p.9..3.i = xor i8 %440, %p.9..2.i
  %446 = select i1 %441, i8 0, i8 %a.9.3.i
  %447 = and i32 %442, 1
  %a.9.in.6.i = select i1 %443, i32 %413, i32 %444
  %448 = select i1 %445, i8 0, i8 %a.9.4.i
  %p.9..4.i = xor i8 %446, %p.9..3.i
  %a.9.5.i = trunc i32 %a.9.in.5.i to i8
  %449 = icmp eq i32 %447, 0
  %450 = icmp sgt i8 %386, -1
  %a.9.6.i = trunc i32 %a.9.in.6.i to i8
  %p.9..5.i = xor i8 %448, %p.9..4.i
  %451 = select i1 %449, i8 0, i8 %a.9.5.i
  %452 = select i1 %450, i8 0, i8 %a.9.6.i
  %p.9..6.i = xor i8 %451, %p.9..5.i
  %p.9..7.i = xor i8 %452, %p.9..6.i
  %453 = and i64 %tmp77.i, 3
  %454 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType332.i, i64 0, i64 %453
  %455 = load <4 x i8>* %454, align 4
  %456 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %457 = extractelement <4 x i8> %455, i32 0
  %458 = extractelement <4 x i8> %456, i32 1
  %459 = zext i8 %458 to i32
  %460 = shl i32 %459, 1
  %461 = and i32 %459, 128
  %462 = xor i32 %460, 27
  %463 = icmp eq i32 %461, 0
  %a.11.in.i = select i1 %463, i32 %460, i32 %462
  %464 = shl i32 %a.11.in.i, 1
  %465 = and i32 %a.11.in.i, 128
  %466 = xor i32 %464, 27
  %467 = icmp eq i32 %465, 0
  %a.11.in.1.i = select i1 %467, i32 %464, i32 %466
  %468 = shl i32 %a.11.in.1.i, 1
  %469 = and i32 %a.11.in.1.i, 128
  %470 = xor i32 %468, 27
  %471 = icmp eq i32 %469, 0
  %a.11.in.2.i = select i1 %471, i32 %468, i32 %470
  %472 = shl i32 %a.11.in.2.i, 1
  %473 = and i32 %a.11.in.2.i, 128
  %474 = xor i32 %472, 27
  %475 = icmp eq i32 %473, 0
  %a.11.in.3.i = select i1 %475, i32 %472, i32 %474
  %476 = shl i32 %a.11.in.3.i, 1
  %477 = and i32 %a.11.in.3.i, 128
  %478 = xor i32 %476, 27
  %479 = icmp eq i32 %477, 0
  %a.11.in.4.i = select i1 %479, i32 %476, i32 %478
  %480 = shl i32 %a.11.in.4.i, 1
  %481 = and i32 %a.11.in.4.i, 128
  %482 = xor i32 %480, 27
  %483 = icmp eq i32 %481, 0
  %a.11.in.5.i = select i1 %483, i32 %480, i32 %482
  %484 = shl i32 %a.11.in.5.i, 1
  %485 = lshr i8 %457, 1
  %486 = zext i8 %485 to i32
  %487 = zext i8 %457 to i32
  %488 = lshr i8 %457, 2
  %489 = lshr i8 %457, 3
  %490 = and i32 %486, 1
  %491 = and i32 %487, 1
  %492 = zext i8 %488 to i32
  %493 = zext i8 %489 to i32
  %494 = icmp eq i32 %490, 0
  %a.11.i = trunc i32 %a.11.in.i to i8
  %495 = icmp eq i32 %491, 0
  %496 = and i32 %492, 1
  %497 = lshr i8 %457, 4
  %498 = lshr i8 %457, 5
  %499 = and i32 %493, 1
  %500 = select i1 %494, i8 0, i8 %a.11.i
  %501 = select i1 %495, i8 0, i8 %458
  %a.11.1.i = trunc i32 %a.11.in.1.i to i8
  %502 = icmp eq i32 %496, 0
  %503 = zext i8 %497 to i32
  %504 = zext i8 %498 to i32
  %505 = icmp eq i32 %499, 0
  %a.11.2.i = trunc i32 %a.11.in.2.i to i8
  %p.11..1.i = xor i8 %500, %501
  %506 = select i1 %502, i8 0, i8 %a.11.1.i
  %507 = and i32 %503, 1
  %508 = lshr i8 %457, 6
  %509 = and i32 %a.11.in.5.i, 128
  %510 = and i32 %504, 1
  %511 = select i1 %505, i8 0, i8 %a.11.2.i
  %p.11..2.i = xor i8 %506, %p.11..1.i
  %a.11.3.i = trunc i32 %a.11.in.3.i to i8
  %512 = icmp eq i32 %507, 0
  %513 = zext i8 %508 to i32
  %514 = icmp eq i32 %509, 0
  %515 = xor i32 %484, 27
  %516 = icmp eq i32 %510, 0
  %a.11.4.i = trunc i32 %a.11.in.4.i to i8
  %p.11..3.i = xor i8 %511, %p.11..2.i
  %517 = select i1 %512, i8 0, i8 %a.11.3.i
  %518 = and i32 %513, 1
  %a.11.in.6.i = select i1 %514, i32 %484, i32 %515
  %519 = select i1 %516, i8 0, i8 %a.11.4.i
  %p.11..4.i = xor i8 %517, %p.11..3.i
  %a.11.5.i = trunc i32 %a.11.in.5.i to i8
  %520 = icmp eq i32 %518, 0
  %521 = icmp sgt i8 %457, -1
  %a.11.6.i = trunc i32 %a.11.in.6.i to i8
  %p.11..5.i = xor i8 %519, %p.11..4.i
  %522 = select i1 %520, i8 0, i8 %a.11.5.i
  %523 = select i1 %521, i8 0, i8 %a.11.6.i
  %p.11..6.i = xor i8 %522, %p.11..5.i
  %p.11..7.i = xor i8 %523, %p.11..6.i
  %524 = and i64 %tmp77.i, 3
  %525 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType328.i, i64 0, i64 %524
  %526 = load <4 x i8>* %525, align 4
  %527 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %528 = extractelement <4 x i8> %526, i32 0
  %529 = extractelement <4 x i8> %527, i32 2
  %530 = zext i8 %529 to i32
  %531 = shl i32 %530, 1
  %532 = and i32 %530, 128
  %533 = xor i32 %531, 27
  %534 = icmp eq i32 %532, 0
  %a.13.in.i = select i1 %534, i32 %531, i32 %533
  %535 = shl i32 %a.13.in.i, 1
  %536 = and i32 %a.13.in.i, 128
  %537 = xor i32 %535, 27
  %538 = icmp eq i32 %536, 0
  %a.13.in.1.i = select i1 %538, i32 %535, i32 %537
  %539 = shl i32 %a.13.in.1.i, 1
  %540 = and i32 %a.13.in.1.i, 128
  %541 = xor i32 %539, 27
  %542 = icmp eq i32 %540, 0
  %a.13.in.2.i = select i1 %542, i32 %539, i32 %541
  %543 = shl i32 %a.13.in.2.i, 1
  %544 = and i32 %a.13.in.2.i, 128
  %545 = xor i32 %543, 27
  %546 = icmp eq i32 %544, 0
  %a.13.in.3.i = select i1 %546, i32 %543, i32 %545
  %547 = shl i32 %a.13.in.3.i, 1
  %548 = and i32 %a.13.in.3.i, 128
  %549 = xor i32 %547, 27
  %550 = icmp eq i32 %548, 0
  %a.13.in.4.i = select i1 %550, i32 %547, i32 %549
  %551 = shl i32 %a.13.in.4.i, 1
  %552 = and i32 %a.13.in.4.i, 128
  %553 = xor i32 %551, 27
  %554 = icmp eq i32 %552, 0
  %a.13.in.5.i = select i1 %554, i32 %551, i32 %553
  %555 = shl i32 %a.13.in.5.i, 1
  %556 = lshr i8 %528, 1
  %557 = zext i8 %556 to i32
  %558 = zext i8 %528 to i32
  %559 = lshr i8 %528, 2
  %560 = lshr i8 %528, 3
  %561 = and i32 %557, 1
  %562 = and i32 %558, 1
  %563 = zext i8 %559 to i32
  %564 = zext i8 %560 to i32
  %565 = icmp eq i32 %561, 0
  %a.13.i = trunc i32 %a.13.in.i to i8
  %566 = icmp eq i32 %562, 0
  %567 = and i32 %563, 1
  %568 = lshr i8 %528, 4
  %569 = lshr i8 %528, 5
  %570 = and i32 %564, 1
  %571 = select i1 %565, i8 0, i8 %a.13.i
  %572 = select i1 %566, i8 0, i8 %529
  %a.13.1.i = trunc i32 %a.13.in.1.i to i8
  %573 = icmp eq i32 %567, 0
  %574 = zext i8 %568 to i32
  %575 = zext i8 %569 to i32
  %576 = icmp eq i32 %570, 0
  %a.13.2.i = trunc i32 %a.13.in.2.i to i8
  %p.13..1.i = xor i8 %571, %572
  %577 = select i1 %573, i8 0, i8 %a.13.1.i
  %578 = and i32 %574, 1
  %579 = lshr i8 %528, 6
  %580 = and i32 %a.13.in.5.i, 128
  %581 = and i32 %575, 1
  %582 = select i1 %576, i8 0, i8 %a.13.2.i
  %p.13..2.i = xor i8 %577, %p.13..1.i
  %a.13.3.i = trunc i32 %a.13.in.3.i to i8
  %583 = icmp eq i32 %578, 0
  %584 = zext i8 %579 to i32
  %585 = icmp eq i32 %580, 0
  %586 = xor i32 %555, 27
  %587 = icmp eq i32 %581, 0
  %a.13.4.i = trunc i32 %a.13.in.4.i to i8
  %p.13..3.i = xor i8 %582, %p.13..2.i
  %588 = select i1 %583, i8 0, i8 %a.13.3.i
  %589 = and i32 %584, 1
  %a.13.in.6.i = select i1 %585, i32 %555, i32 %586
  %590 = select i1 %587, i8 0, i8 %a.13.4.i
  %p.13..4.i = xor i8 %588, %p.13..3.i
  %a.13.5.i = trunc i32 %a.13.in.5.i to i8
  %591 = icmp eq i32 %589, 0
  %592 = icmp sgt i8 %528, -1
  %a.13.6.i = trunc i32 %a.13.in.6.i to i8
  %p.13..5.i = xor i8 %590, %p.13..4.i
  %593 = select i1 %591, i8 0, i8 %a.13.5.i
  %594 = select i1 %592, i8 0, i8 %a.13.6.i
  %p.13..6.i = xor i8 %593, %p.13..5.i
  %p.13..7.i = xor i8 %594, %p.13..6.i
  %595 = and i64 %tmp77.i, 3
  %596 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType324.i, i64 0, i64 %595
  %597 = load <4 x i8>* %596, align 4
  %598 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %599 = extractelement <4 x i8> %597, i32 0
  %600 = extractelement <4 x i8> %598, i32 3
  %601 = zext i8 %600 to i32
  %602 = shl i32 %601, 1
  %603 = and i32 %601, 128
  %604 = xor i32 %602, 27
  %605 = icmp eq i32 %603, 0
  %a.15.in.i = select i1 %605, i32 %602, i32 %604
  %606 = shl i32 %a.15.in.i, 1
  %607 = and i32 %a.15.in.i, 128
  %608 = xor i32 %606, 27
  %609 = icmp eq i32 %607, 0
  %a.15.in.1.i = select i1 %609, i32 %606, i32 %608
  %610 = shl i32 %a.15.in.1.i, 1
  %611 = and i32 %a.15.in.1.i, 128
  %612 = xor i32 %610, 27
  %613 = icmp eq i32 %611, 0
  %a.15.in.2.i = select i1 %613, i32 %610, i32 %612
  %614 = shl i32 %a.15.in.2.i, 1
  %615 = and i32 %a.15.in.2.i, 128
  %616 = xor i32 %614, 27
  %617 = icmp eq i32 %615, 0
  %a.15.in.3.i = select i1 %617, i32 %614, i32 %616
  %618 = shl i32 %a.15.in.3.i, 1
  %619 = and i32 %a.15.in.3.i, 128
  %620 = xor i32 %618, 27
  %621 = icmp eq i32 %619, 0
  %a.15.in.4.i = select i1 %621, i32 %618, i32 %620
  %622 = shl i32 %a.15.in.4.i, 1
  %623 = and i32 %a.15.in.4.i, 128
  %624 = xor i32 %622, 27
  %625 = icmp eq i32 %623, 0
  %a.15.in.5.i = select i1 %625, i32 %622, i32 %624
  %626 = shl i32 %a.15.in.5.i, 1
  %627 = lshr i8 %599, 1
  %628 = zext i8 %627 to i32
  %629 = zext i8 %599 to i32
  %630 = lshr i8 %599, 2
  %631 = lshr i8 %599, 3
  %632 = and i32 %628, 1
  %633 = and i32 %629, 1
  %634 = zext i8 %630 to i32
  %635 = zext i8 %631 to i32
  %636 = icmp eq i32 %632, 0
  %a.15.i = trunc i32 %a.15.in.i to i8
  %637 = icmp eq i32 %633, 0
  %638 = and i32 %634, 1
  %639 = lshr i8 %599, 4
  %640 = lshr i8 %599, 5
  %641 = and i32 %635, 1
  %642 = select i1 %636, i8 0, i8 %a.15.i
  %643 = select i1 %637, i8 0, i8 %600
  %a.15.1.i = trunc i32 %a.15.in.1.i to i8
  %644 = icmp eq i32 %638, 0
  %645 = zext i8 %639 to i32
  %646 = zext i8 %640 to i32
  %647 = icmp eq i32 %641, 0
  %a.15.2.i = trunc i32 %a.15.in.2.i to i8
  %p.15..1.i = xor i8 %642, %643
  %648 = select i1 %644, i8 0, i8 %a.15.1.i
  %649 = and i32 %645, 1
  %650 = lshr i8 %599, 6
  %651 = and i32 %a.15.in.5.i, 128
  %652 = and i32 %646, 1
  %653 = select i1 %647, i8 0, i8 %a.15.2.i
  %p.15..2.i = xor i8 %648, %p.15..1.i
  %a.15.3.i = trunc i32 %a.15.in.3.i to i8
  %654 = icmp eq i32 %649, 0
  %655 = zext i8 %650 to i32
  %656 = icmp eq i32 %651, 0
  %657 = xor i32 %626, 27
  %658 = icmp eq i32 %652, 0
  %a.15.4.i = trunc i32 %a.15.in.4.i to i8
  %p.15..3.i = xor i8 %653, %p.15..2.i
  %659 = select i1 %654, i8 0, i8 %a.15.3.i
  %660 = and i32 %655, 1
  %a.15.in.6.i = select i1 %656, i32 %626, i32 %657
  %661 = select i1 %658, i8 0, i8 %a.15.4.i
  %p.15..4.i = xor i8 %659, %p.15..3.i
  %a.15.5.i = trunc i32 %a.15.in.5.i to i8
  %662 = icmp eq i32 %660, 0
  %663 = icmp sgt i8 %599, -1
  %a.15.6.i = trunc i32 %a.15.in.6.i to i8
  %p.15..5.i = xor i8 %661, %p.15..4.i
  %664 = select i1 %662, i8 0, i8 %a.15.5.i
  %665 = select i1 %663, i8 0, i8 %a.15.6.i
  %p.15..6.i = xor i8 %664, %p.15..5.i
  %p.15..7.i = xor i8 %665, %p.15..6.i
  %666 = xor i8 %p.9..7.i, %x.060.i
  store i8 %666, i8* %"&pSB[currWI].offset279.i", align 1
  %667 = xor i8 %p.11..7.i, %y.061.i
  store i8 %667, i8* %"&pSB[currWI].offset288.i", align 1
  %668 = xor i8 %p.13..7.i, %z.062.i
  store i8 %668, i8* %"&pSB[currWI].offset297.i", align 1
  %669 = xor i8 %p.15..7.i, %w.063.i
  store i8 %669, i8* %"&pSB[currWI].offset306.i", align 1
  %exitcond.i = icmp eq i64 %tmp.i, 3
  br i1 %exitcond.i, label %._crit_edge66.i, label %381

._crit_edge66.i:                                  ; preds = %381
  %"&(pSB[currWI].offset)282.i" = add nuw i64 %CurrSBIndex..1.i, 232
  %"&pSB[currWI].offset283.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)282.i"
  %loadedValue285.i = load i8* %"&pSB[currWI].offset283.i", align 1
  %670 = insertelement <4 x i8> undef, i8 %loadedValue285.i, i32 0
  %"&(pSB[currWI].offset)291.i" = add nuw i64 %CurrSBIndex..1.i, 233
  %"&pSB[currWI].offset292.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)291.i"
  %loadedValue294.i = load i8* %"&pSB[currWI].offset292.i", align 1
  %671 = insertelement <4 x i8> %670, i8 %loadedValue294.i, i32 1
  %"&(pSB[currWI].offset)300.i" = add nuw i64 %CurrSBIndex..1.i, 234
  %"&pSB[currWI].offset301.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)300.i"
  %loadedValue303.i = load i8* %"&pSB[currWI].offset301.i", align 1
  %672 = insertelement <4 x i8> %671, i8 %loadedValue303.i, i32 2
  %"&(pSB[currWI].offset)309.i" = add nuw i64 %CurrSBIndex..1.i, 235
  %"&pSB[currWI].offset310.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)309.i"
  %loadedValue312.i = load i8* %"&pSB[currWI].offset310.i", align 1
  %673 = insertelement <4 x i8> %672, i8 %loadedValue312.i, i32 3
  %"&(pSB[currWI].offset)314.i" = add nuw i64 %CurrSBIndex..1.i, 236
  %"&pSB[currWI].offset315.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)314.i"
  %CastToValueType316.i = bitcast i8* %"&pSB[currWI].offset315.i" to <4 x i8>*
  store <4 x i8> %673, <4 x i8>* %CastToValueType316.i, align 4
  %"&(pSB[currWI].offset)124.i" = add nuw i64 %CurrSBIndex..1.i, 152
  %"&pSB[currWI].offset125.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)124.i"
  %CastToValueType126.i = bitcast i8* %"&pSB[currWI].offset125.i" to <4 x i8> addrspace(3)**
  %loadedValue127.i = load <4 x i8> addrspace(3)** %CastToValueType126.i, align 8
  store <4 x i8> %673, <4 x i8> addrspace(3)* %loadedValue127.i, align 4
  %"&(pSB[currWI].offset)213.i" = add nuw i64 %CurrSBIndex..1.i, 196
  %"&pSB[currWI].offset214.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)213.i"
  %CastToValueType215.i = bitcast i8* %"&pSB[currWI].offset214.i" to i32*
  %loadedValue216.i = load i32* %CastToValueType215.i, align 4
  %indvar.next80.i = add i32 %loadedValue216.i, 1
  %"&(pSB[currWI].offset)318.i" = add nuw i64 %CurrSBIndex..1.i, 240
  %"&pSB[currWI].offset319.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)318.i"
  %CastToValueType320.i = bitcast i8* %"&pSB[currWI].offset319.i" to i32*
  store i32 %indvar.next80.i, i32* %CastToValueType320.i, align 4
  br label %71

"Barrier BB91.i":                                 ; preds = %shiftRowsInv.exit.i
  %"&(pSB[currWI].offset)115.i" = add nuw i64 %CurrSBIndex..2.i, 144
  %"&pSB[currWI].offset116.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)115.i"
  %CastToValueType117.i = bitcast i8* %"&pSB[currWI].offset116.i" to i64*
  %loadedValue118.i = load i64* %CastToValueType117.i, align 8
  %674 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %loadedValue118.i
  %675 = load <4 x i8> addrspace(1)* %674, align 4
  %"&(pSB[currWI].offset)244.i" = add nuw i64 %CurrSBIndex..2.i, 212
  %"&pSB[currWI].offset245.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)244.i"
  %CastToValueType246.i = bitcast i8* %"&pSB[currWI].offset245.i" to <4 x i8>*
  %loadedValue247.i = load <4 x i8>* %CastToValueType246.i, align 4
  %676 = xor <4 x i8> %loadedValue247.i, %675
  %"&(pSB[currWI].offset)106.i" = add nuw i64 %CurrSBIndex..2.i, 136
  %"&pSB[currWI].offset107.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)106.i"
  %CastToValueType108.i = bitcast i8* %"&pSB[currWI].offset107.i" to i64*
  %loadedValue109.i = load i64* %CastToValueType108.i, align 8
  %677 = getelementptr inbounds <4 x i8> addrspace(1)* %1, i64 %loadedValue109.i
  store <4 x i8> %676, <4 x i8> addrspace(1)* %677, align 4
  %check.WI.iter373.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter373.i, label %thenBB370.i, label %__AESDecrypt_separated_args.exit

thenBB370.i:                                      ; preds = %"Barrier BB91.i"
  %"CurrWI++374.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride376.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond1.i = icmp eq i32 %currBarrier.1.i, 4
  br i1 %cond1.i, label %SyncBB359.i, label %SyncBB361.i

__AESDecrypt_separated_args.exit:                 ; preds = %"Barrier BB91.i"
  ret void
}

define void @__Vectorized_.AESDecrypt(i8* %pBuffer) {
entry:
  %0 = bitcast i8* %pBuffer to <4 x i8> addrspace(1)**
  %1 = load <4 x i8> addrspace(1)** %0, align 8
  %2 = getelementptr i8* %pBuffer, i64 8
  %3 = bitcast i8* %2 to <4 x i8> addrspace(1)**
  %4 = load <4 x i8> addrspace(1)** %3, align 8
  %5 = getelementptr i8* %pBuffer, i64 16
  %6 = bitcast i8* %5 to <4 x i8> addrspace(1)**
  %7 = load <4 x i8> addrspace(1)** %6, align 8
  %8 = getelementptr i8* %pBuffer, i64 24
  %9 = bitcast i8* %8 to i8 addrspace(1)**
  %10 = load i8 addrspace(1)** %9, align 8
  %11 = getelementptr i8* %pBuffer, i64 32
  %12 = bitcast i8* %11 to <4 x i8> addrspace(3)**
  %13 = load <4 x i8> addrspace(3)** %12, align 8
  %14 = getelementptr i8* %pBuffer, i64 40
  %15 = bitcast i8* %14 to <4 x i8> addrspace(3)**
  %16 = load <4 x i8> addrspace(3)** %15, align 8
  %17 = getelementptr i8* %pBuffer, i64 48
  %18 = bitcast i8* %17 to i32*
  %19 = load i32* %18, align 4
  %20 = getelementptr i8* %pBuffer, i64 52
  %21 = bitcast i8* %20 to i32*
  %22 = load i32* %21, align 4
  %23 = getelementptr i8* %pBuffer, i64 72
  %24 = bitcast i8* %23 to i64**
  %25 = load i64** %24, align 8
  %26 = getelementptr i8* %pBuffer, i64 88
  %27 = bitcast i8* %26 to %struct.PaddedDimId**
  %28 = load %struct.PaddedDimId** %27, align 8
  %29 = getelementptr i8* %pBuffer, i64 104
  %30 = bitcast i8* %29 to i64*
  %31 = load i64* %30, align 8
  %32 = getelementptr i8* %pBuffer, i64 112
  %33 = bitcast i8* %32 to i8**
  %34 = load i8** %33, align 8
  %35 = shl i32 %22, 2
  %tmp81.i = add i32 %22, -1
  br label %SyncBB.i

SyncBB.i:                                         ; preds = %thenBB2221.i, %thenBB.i, %entry
  %CurrSBIndex..0.i = phi i64 [ 0, %entry ], [ %"loadedCurrSB+Stride2227.i", %thenBB2221.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ]
  %currBarrier.2.i = phi i32 [ 13, %entry ], [ %currBarrier.1.i, %thenBB2221.i ], [ %currBarrier.1.i, %thenBB.i ]
  %CurrWI..0.i = phi i64 [ 0, %entry ], [ %"CurrWI++2225.i", %thenBB2221.i ], [ %"CurrWI++.i", %thenBB.i ]
  %36 = load i64* %25, align 8
  %37 = trunc i64 %36 to i32
  %38 = getelementptr i64* %25, i64 1
  %39 = load i64* %38, align 8
  %40 = trunc i64 %39 to i32
  %41 = getelementptr %struct.PaddedDimId* %28, i64 %CurrWI..0.i, i32 0, i64 1
  %42 = load i64* %41, align 8
  %43 = trunc i64 %42 to i32
  %"&(pSB[currWI].offset).i" = add nuw i64 %CurrSBIndex..0.i, 896
  %"&pSB[currWI].offset.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset).i"
  %CastToValueType.i = bitcast i8* %"&pSB[currWI].offset.i" to i32*
  store i32 %43, i32* %CastToValueType.i, align 4
  %44 = mul i32 %40, %19
  %45 = shl i32 %37, 2
  %46 = add i32 %44, %45
  %47 = and i32 %46, -4
  %48 = add i32 %47, %43
  %"&(pSB[currWI].offset)1665.i" = add nuw i64 %CurrSBIndex..0.i, 1456
  %"&pSB[currWI].offset1666.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1665.i"
  %49 = bitcast i8* %"&pSB[currWI].offset1666.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1701.i" = add nuw i64 %CurrSBIndex..0.i, 1472
  %"&pSB[currWI].offset1702.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1701.i"
  %50 = bitcast i8* %"&pSB[currWI].offset1702.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1737.i" = add nuw i64 %CurrSBIndex..0.i, 1488
  %"&pSB[currWI].offset1738.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1737.i"
  %51 = bitcast i8* %"&pSB[currWI].offset1738.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1773.i" = add nuw i64 %CurrSBIndex..0.i, 1504
  %"&pSB[currWI].offset1774.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1773.i"
  %52 = bitcast i8* %"&pSB[currWI].offset1774.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1809.i" = add nuw i64 %CurrSBIndex..0.i, 1520
  %"&pSB[currWI].offset1810.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1809.i"
  %53 = bitcast i8* %"&pSB[currWI].offset1810.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1845.i" = add nuw i64 %CurrSBIndex..0.i, 1536
  %"&pSB[currWI].offset1846.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1845.i"
  %54 = bitcast i8* %"&pSB[currWI].offset1846.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1881.i" = add nuw i64 %CurrSBIndex..0.i, 1552
  %"&pSB[currWI].offset1882.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1881.i"
  %55 = bitcast i8* %"&pSB[currWI].offset1882.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1917.i" = add nuw i64 %CurrSBIndex..0.i, 1568
  %"&pSB[currWI].offset1918.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1917.i"
  %56 = bitcast i8* %"&pSB[currWI].offset1918.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1953.i" = add nuw i64 %CurrSBIndex..0.i, 1584
  %"&pSB[currWI].offset1954.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1953.i"
  %57 = bitcast i8* %"&pSB[currWI].offset1954.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1989.i" = add nuw i64 %CurrSBIndex..0.i, 1600
  %"&pSB[currWI].offset1990.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1989.i"
  %58 = bitcast i8* %"&pSB[currWI].offset1990.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2025.i" = add nuw i64 %CurrSBIndex..0.i, 1616
  %"&pSB[currWI].offset2026.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2025.i"
  %59 = bitcast i8* %"&pSB[currWI].offset2026.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2061.i" = add nuw i64 %CurrSBIndex..0.i, 1632
  %"&pSB[currWI].offset2062.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2061.i"
  %60 = bitcast i8* %"&pSB[currWI].offset2062.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2097.i" = add nuw i64 %CurrSBIndex..0.i, 1648
  %"&pSB[currWI].offset2098.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2097.i"
  %61 = bitcast i8* %"&pSB[currWI].offset2098.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2133.i" = add nuw i64 %CurrSBIndex..0.i, 1664
  %"&pSB[currWI].offset2134.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2133.i"
  %62 = bitcast i8* %"&pSB[currWI].offset2134.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2169.i" = add nuw i64 %CurrSBIndex..0.i, 1680
  %"&pSB[currWI].offset2170.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2169.i"
  %63 = bitcast i8* %"&pSB[currWI].offset2170.i" to <4 x i8>*
  %"&(pSB[currWI].offset)2205.i" = add nuw i64 %CurrSBIndex..0.i, 1696
  %"&pSB[currWI].offset2206.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2205.i"
  %64 = bitcast i8* %"&pSB[currWI].offset2206.i" to <4 x i8>*
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %50, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %52, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %54, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %56, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %57, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %58, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %59, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %60, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %61, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %62, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %63, align 16
  store <4 x i8> <i8 14, i8 0, i8 0, i8 0>, <4 x i8>* %64, align 16
  %"&pSB[currWI].offset1662.sum.i" = add i64 %CurrSBIndex..0.i, 1460
  %65 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1662.sum.i"
  %66 = bitcast i8* %65 to <4 x i8>*
  %"&pSB[currWI].offset1698.sum.i" = add i64 %CurrSBIndex..0.i, 1476
  %67 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1698.sum.i"
  %68 = bitcast i8* %67 to <4 x i8>*
  %"&pSB[currWI].offset1734.sum.i" = add i64 %CurrSBIndex..0.i, 1492
  %69 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1734.sum.i"
  %70 = bitcast i8* %69 to <4 x i8>*
  %"&pSB[currWI].offset1770.sum.i" = add i64 %CurrSBIndex..0.i, 1508
  %71 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1770.sum.i"
  %72 = bitcast i8* %71 to <4 x i8>*
  %"&pSB[currWI].offset1806.sum.i" = add i64 %CurrSBIndex..0.i, 1524
  %73 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1806.sum.i"
  %74 = bitcast i8* %73 to <4 x i8>*
  %"&pSB[currWI].offset1842.sum.i" = add i64 %CurrSBIndex..0.i, 1540
  %75 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1842.sum.i"
  %76 = bitcast i8* %75 to <4 x i8>*
  %"&pSB[currWI].offset1878.sum.i" = add i64 %CurrSBIndex..0.i, 1556
  %77 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1878.sum.i"
  %78 = bitcast i8* %77 to <4 x i8>*
  %"&pSB[currWI].offset1914.sum.i" = add i64 %CurrSBIndex..0.i, 1572
  %79 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1914.sum.i"
  %80 = bitcast i8* %79 to <4 x i8>*
  %"&pSB[currWI].offset1950.sum.i" = add i64 %CurrSBIndex..0.i, 1588
  %81 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1950.sum.i"
  %82 = bitcast i8* %81 to <4 x i8>*
  %"&pSB[currWI].offset1986.sum.i" = add i64 %CurrSBIndex..0.i, 1604
  %83 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1986.sum.i"
  %84 = bitcast i8* %83 to <4 x i8>*
  %"&pSB[currWI].offset2022.sum.i" = add i64 %CurrSBIndex..0.i, 1620
  %85 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2022.sum.i"
  %86 = bitcast i8* %85 to <4 x i8>*
  %"&pSB[currWI].offset2058.sum.i" = add i64 %CurrSBIndex..0.i, 1636
  %87 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2058.sum.i"
  %88 = bitcast i8* %87 to <4 x i8>*
  %"&pSB[currWI].offset2094.sum.i" = add i64 %CurrSBIndex..0.i, 1652
  %89 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2094.sum.i"
  %90 = bitcast i8* %89 to <4 x i8>*
  %"&pSB[currWI].offset2130.sum.i" = add i64 %CurrSBIndex..0.i, 1668
  %91 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2130.sum.i"
  %92 = bitcast i8* %91 to <4 x i8>*
  %"&pSB[currWI].offset2166.sum.i" = add i64 %CurrSBIndex..0.i, 1684
  %93 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2166.sum.i"
  %94 = bitcast i8* %93 to <4 x i8>*
  %"&pSB[currWI].offset2202.sum.i" = add i64 %CurrSBIndex..0.i, 1700
  %95 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2202.sum.i"
  %96 = bitcast i8* %95 to <4 x i8>*
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %66, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %68, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %70, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %72, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %74, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %76, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %78, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %80, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %82, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %84, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %86, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %88, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %90, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %92, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %94, align 4
  store <4 x i8> <i8 11, i8 0, i8 0, i8 0>, <4 x i8>* %96, align 4
  %"&pSB[currWI].offset1658.sum.i" = add i64 %CurrSBIndex..0.i, 1464
  %97 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1658.sum.i"
  %98 = bitcast i8* %97 to <4 x i8>*
  %"&pSB[currWI].offset1694.sum.i" = add i64 %CurrSBIndex..0.i, 1480
  %99 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1694.sum.i"
  %100 = bitcast i8* %99 to <4 x i8>*
  %"&pSB[currWI].offset1730.sum.i" = add i64 %CurrSBIndex..0.i, 1496
  %101 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1730.sum.i"
  %102 = bitcast i8* %101 to <4 x i8>*
  %"&pSB[currWI].offset1766.sum.i" = add i64 %CurrSBIndex..0.i, 1512
  %103 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1766.sum.i"
  %104 = bitcast i8* %103 to <4 x i8>*
  %"&pSB[currWI].offset1802.sum.i" = add i64 %CurrSBIndex..0.i, 1528
  %105 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1802.sum.i"
  %106 = bitcast i8* %105 to <4 x i8>*
  %"&pSB[currWI].offset1838.sum.i" = add i64 %CurrSBIndex..0.i, 1544
  %107 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1838.sum.i"
  %108 = bitcast i8* %107 to <4 x i8>*
  %"&pSB[currWI].offset1874.sum.i" = add i64 %CurrSBIndex..0.i, 1560
  %109 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1874.sum.i"
  %110 = bitcast i8* %109 to <4 x i8>*
  %"&pSB[currWI].offset1910.sum.i" = add i64 %CurrSBIndex..0.i, 1576
  %111 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1910.sum.i"
  %112 = bitcast i8* %111 to <4 x i8>*
  %"&pSB[currWI].offset1946.sum.i" = add i64 %CurrSBIndex..0.i, 1592
  %113 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1946.sum.i"
  %114 = bitcast i8* %113 to <4 x i8>*
  %"&pSB[currWI].offset1982.sum.i" = add i64 %CurrSBIndex..0.i, 1608
  %115 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1982.sum.i"
  %116 = bitcast i8* %115 to <4 x i8>*
  %"&pSB[currWI].offset2018.sum.i" = add i64 %CurrSBIndex..0.i, 1624
  %117 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2018.sum.i"
  %118 = bitcast i8* %117 to <4 x i8>*
  %"&pSB[currWI].offset2054.sum.i" = add i64 %CurrSBIndex..0.i, 1640
  %119 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2054.sum.i"
  %120 = bitcast i8* %119 to <4 x i8>*
  %"&pSB[currWI].offset2090.sum.i" = add i64 %CurrSBIndex..0.i, 1656
  %121 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2090.sum.i"
  %122 = bitcast i8* %121 to <4 x i8>*
  %"&pSB[currWI].offset2126.sum.i" = add i64 %CurrSBIndex..0.i, 1672
  %123 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2126.sum.i"
  %124 = bitcast i8* %123 to <4 x i8>*
  %"&pSB[currWI].offset2162.sum.i" = add i64 %CurrSBIndex..0.i, 1688
  %125 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2162.sum.i"
  %126 = bitcast i8* %125 to <4 x i8>*
  %"&pSB[currWI].offset2198.sum.i" = add i64 %CurrSBIndex..0.i, 1704
  %127 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2198.sum.i"
  %128 = bitcast i8* %127 to <4 x i8>*
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %98, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %100, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %102, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %104, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %106, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %108, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %110, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %112, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %114, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %116, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %118, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %120, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %122, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %124, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %126, align 8
  store <4 x i8> <i8 13, i8 0, i8 0, i8 0>, <4 x i8>* %128, align 8
  %"&pSB[currWI].offset1654.sum.i" = add i64 %CurrSBIndex..0.i, 1468
  %129 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1654.sum.i"
  %130 = bitcast i8* %129 to <4 x i8>*
  %"&pSB[currWI].offset1690.sum.i" = add i64 %CurrSBIndex..0.i, 1484
  %131 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1690.sum.i"
  %132 = bitcast i8* %131 to <4 x i8>*
  %"&pSB[currWI].offset1726.sum.i" = add i64 %CurrSBIndex..0.i, 1500
  %133 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1726.sum.i"
  %134 = bitcast i8* %133 to <4 x i8>*
  %"&pSB[currWI].offset1762.sum.i" = add i64 %CurrSBIndex..0.i, 1516
  %135 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1762.sum.i"
  %136 = bitcast i8* %135 to <4 x i8>*
  %"&pSB[currWI].offset1798.sum.i" = add i64 %CurrSBIndex..0.i, 1532
  %137 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1798.sum.i"
  %138 = bitcast i8* %137 to <4 x i8>*
  %"&pSB[currWI].offset1834.sum.i" = add i64 %CurrSBIndex..0.i, 1548
  %139 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1834.sum.i"
  %140 = bitcast i8* %139 to <4 x i8>*
  %"&pSB[currWI].offset1870.sum.i" = add i64 %CurrSBIndex..0.i, 1564
  %141 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1870.sum.i"
  %142 = bitcast i8* %141 to <4 x i8>*
  %"&pSB[currWI].offset1906.sum.i" = add i64 %CurrSBIndex..0.i, 1580
  %143 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1906.sum.i"
  %144 = bitcast i8* %143 to <4 x i8>*
  %"&pSB[currWI].offset1942.sum.i" = add i64 %CurrSBIndex..0.i, 1596
  %145 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1942.sum.i"
  %146 = bitcast i8* %145 to <4 x i8>*
  %"&pSB[currWI].offset1978.sum.i" = add i64 %CurrSBIndex..0.i, 1612
  %147 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1978.sum.i"
  %148 = bitcast i8* %147 to <4 x i8>*
  %"&pSB[currWI].offset2014.sum.i" = add i64 %CurrSBIndex..0.i, 1628
  %149 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2014.sum.i"
  %150 = bitcast i8* %149 to <4 x i8>*
  %"&pSB[currWI].offset2050.sum.i" = add i64 %CurrSBIndex..0.i, 1644
  %151 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2050.sum.i"
  %152 = bitcast i8* %151 to <4 x i8>*
  %"&pSB[currWI].offset2086.sum.i" = add i64 %CurrSBIndex..0.i, 1660
  %153 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2086.sum.i"
  %154 = bitcast i8* %153 to <4 x i8>*
  %"&pSB[currWI].offset2122.sum.i" = add i64 %CurrSBIndex..0.i, 1676
  %155 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2122.sum.i"
  %156 = bitcast i8* %155 to <4 x i8>*
  %"&pSB[currWI].offset2158.sum.i" = add i64 %CurrSBIndex..0.i, 1692
  %157 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2158.sum.i"
  %158 = bitcast i8* %157 to <4 x i8>*
  %"&pSB[currWI].offset2194.sum.i" = add i64 %CurrSBIndex..0.i, 1708
  %159 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset2194.sum.i"
  %160 = bitcast i8* %159 to <4 x i8>*
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %130, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %132, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %134, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %136, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %138, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %140, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %142, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %144, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %146, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %148, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %150, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %152, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %154, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %156, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %158, align 4
  store <4 x i8> <i8 9, i8 0, i8 0, i8 0>, <4 x i8>* %160, align 4
  %161 = zext i32 %48 to i64
  %"&(pSB[currWI].offset)996.i" = add nuw i64 %CurrSBIndex..0.i, 904
  %"&pSB[currWI].offset997.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)996.i"
  %CastToValueType998.i = bitcast i8* %"&pSB[currWI].offset997.i" to i64*
  store i64 %161, i64* %CastToValueType998.i, align 8
  %162 = getelementptr inbounds <4 x i8> addrspace(1)* %4, i64 %161
  %163 = load <4 x i8> addrspace(1)* %162, align 4
  %scalar.i = extractelement <4 x i8> %163, i32 0
  %scalar2.i = extractelement <4 x i8> %163, i32 1
  %scalar3.i = extractelement <4 x i8> %163, i32 2
  %scalar4.i = extractelement <4 x i8> %163, i32 3
  %164 = and i64 %42, 4294967295
  %"&(pSB[currWI].offset)1005.i" = add nuw i64 %CurrSBIndex..0.i, 912
  %"&pSB[currWI].offset1006.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1005.i"
  %CastToValueType1007.i = bitcast i8* %"&pSB[currWI].offset1006.i" to i64*
  store i64 %164, i64* %CastToValueType1007.i, align 8
  %165 = getelementptr inbounds <4 x i8> addrspace(3)* %13, i64 %164
  %"&(pSB[currWI].offset)1014.i" = add nuw i64 %CurrSBIndex..0.i, 920
  %"&pSB[currWI].offset1015.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1014.i"
  %CastToValueType1016.i = bitcast i8* %"&pSB[currWI].offset1015.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %165, <4 x i8> addrspace(3)** %CastToValueType1016.i, align 8
  store <4 x i8> %163, <4 x i8> addrspace(3)* %165, align 4
  %166 = add i32 %43, %35
  %167 = zext i32 %166 to i64
  %168 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %167
  %169 = load <4 x i8> addrspace(1)* %168, align 4
  %scalar5.i = extractelement <4 x i8> %169, i32 0
  %scalar6.i = extractelement <4 x i8> %169, i32 1
  %scalar7.i = extractelement <4 x i8> %169, i32 2
  %scalar8.i = extractelement <4 x i8> %169, i32 3
  %170 = xor i8 %scalar.i, %scalar5.i
  %temp.i = insertelement <16 x i8> undef, i8 %170, i32 0
  %vector.i = shufflevector <16 x i8> %temp.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1038.i" = add nuw i64 %CurrSBIndex..0.i, 928
  %"&pSB[currWI].offset1039.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1038.i"
  %CastToValueType1040.i = bitcast i8* %"&pSB[currWI].offset1039.i" to <16 x i8>*
  store <16 x i8> %vector.i, <16 x i8>* %CastToValueType1040.i, align 16
  %171 = xor i8 %scalar2.i, %scalar6.i
  %temp133.i = insertelement <16 x i8> undef, i8 %171, i32 0
  %vector134.i = shufflevector <16 x i8> %temp133.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1042.i" = add nuw i64 %CurrSBIndex..0.i, 944
  %"&pSB[currWI].offset1043.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1042.i"
  %CastToValueType1044.i = bitcast i8* %"&pSB[currWI].offset1043.i" to <16 x i8>*
  store <16 x i8> %vector134.i, <16 x i8>* %CastToValueType1044.i, align 16
  %172 = xor i8 %scalar3.i, %scalar7.i
  %temp136.i = insertelement <16 x i8> undef, i8 %172, i32 0
  %vector137.i = shufflevector <16 x i8> %temp136.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1046.i" = add nuw i64 %CurrSBIndex..0.i, 960
  %"&pSB[currWI].offset1047.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1046.i"
  %CastToValueType1048.i = bitcast i8* %"&pSB[currWI].offset1047.i" to <16 x i8>*
  store <16 x i8> %vector137.i, <16 x i8>* %CastToValueType1048.i, align 16
  %173 = xor i8 %scalar4.i, %scalar8.i
  %temp139.i = insertelement <16 x i8> undef, i8 %173, i32 0
  %vector140.i = shufflevector <16 x i8> %temp139.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %"&(pSB[currWI].offset)1050.i" = add nuw i64 %CurrSBIndex..0.i, 976
  %"&pSB[currWI].offset1051.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1050.i"
  %CastToValueType1052.i = bitcast i8* %"&pSB[currWI].offset1051.i" to <16 x i8>*
  store <16 x i8> %vector140.i, <16 x i8>* %CastToValueType1052.i, align 16
  %temp.vect.i = insertelement <4 x i8> undef, i8 %170, i32 0
  %temp.vect105.i = insertelement <4 x i8> %temp.vect.i, i8 %171, i32 1
  %temp.vect106.i = insertelement <4 x i8> %temp.vect105.i, i8 %172, i32 2
  %temp.vect107.i = insertelement <4 x i8> %temp.vect106.i, i8 %173, i32 3
  store <4 x i8> %temp.vect107.i, <4 x i8> addrspace(3)* %165, align 4
  %174 = getelementptr inbounds <4 x i8> addrspace(3)* %16, i64 %164
  %"&(pSB[currWI].offset)1054.i" = add nuw i64 %CurrSBIndex..0.i, 992
  %"&pSB[currWI].offset1055.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1054.i"
  %CastToValueType1056.i = bitcast i8* %"&pSB[currWI].offset1055.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %174, <4 x i8> addrspace(3)** %CastToValueType1056.i, align 8
  %175 = sub i32 0, %43
  %176 = and i32 %175, 3
  %177 = zext i32 %176 to i64
  %"&(pSB[currWI].offset)1649.i" = add nuw i64 %CurrSBIndex..0.i, 1456
  %"&pSB[currWI].offset1650.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1649.i"
  %CastToValueType1651.i = bitcast i8* %"&pSB[currWI].offset1650.i" to [4 x <4 x i8>]*
  %178 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1651.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1063.i" = add nuw i64 %CurrSBIndex..0.i, 1000
  %"&pSB[currWI].offset1064.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1063.i"
  %CastToValueType1065.i = bitcast i8* %"&pSB[currWI].offset1064.i" to <4 x i8>**
  store <4 x i8>* %178, <4 x i8>** %CastToValueType1065.i, align 8
  %"&(pSB[currWI].offset)1685.i" = add nuw i64 %CurrSBIndex..0.i, 1472
  %"&pSB[currWI].offset1686.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1685.i"
  %CastToValueType1687.i = bitcast i8* %"&pSB[currWI].offset1686.i" to [4 x <4 x i8>]*
  %179 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1687.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1087.i" = add nuw i64 %CurrSBIndex..0.i, 1008
  %"&pSB[currWI].offset1088.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1087.i"
  %CastToValueType1089.i = bitcast i8* %"&pSB[currWI].offset1088.i" to <4 x i8>**
  store <4 x i8>* %179, <4 x i8>** %CastToValueType1089.i, align 8
  %"&(pSB[currWI].offset)1721.i" = add nuw i64 %CurrSBIndex..0.i, 1488
  %"&pSB[currWI].offset1722.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1721.i"
  %CastToValueType1723.i = bitcast i8* %"&pSB[currWI].offset1722.i" to [4 x <4 x i8>]*
  %180 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1723.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1111.i" = add nuw i64 %CurrSBIndex..0.i, 1016
  %"&pSB[currWI].offset1112.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1111.i"
  %CastToValueType1113.i = bitcast i8* %"&pSB[currWI].offset1112.i" to <4 x i8>**
  store <4 x i8>* %180, <4 x i8>** %CastToValueType1113.i, align 8
  %"&(pSB[currWI].offset)1757.i" = add nuw i64 %CurrSBIndex..0.i, 1504
  %"&pSB[currWI].offset1758.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1757.i"
  %CastToValueType1759.i = bitcast i8* %"&pSB[currWI].offset1758.i" to [4 x <4 x i8>]*
  %181 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1759.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1135.i" = add nuw i64 %CurrSBIndex..0.i, 1024
  %"&pSB[currWI].offset1136.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1135.i"
  %CastToValueType1137.i = bitcast i8* %"&pSB[currWI].offset1136.i" to <4 x i8>**
  store <4 x i8>* %181, <4 x i8>** %CastToValueType1137.i, align 8
  %"&(pSB[currWI].offset)1793.i" = add nuw i64 %CurrSBIndex..0.i, 1520
  %"&pSB[currWI].offset1794.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1793.i"
  %CastToValueType1795.i = bitcast i8* %"&pSB[currWI].offset1794.i" to [4 x <4 x i8>]*
  %182 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1795.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1159.i" = add nuw i64 %CurrSBIndex..0.i, 1032
  %"&pSB[currWI].offset1160.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1159.i"
  %CastToValueType1161.i = bitcast i8* %"&pSB[currWI].offset1160.i" to <4 x i8>**
  store <4 x i8>* %182, <4 x i8>** %CastToValueType1161.i, align 8
  %"&(pSB[currWI].offset)1829.i" = add nuw i64 %CurrSBIndex..0.i, 1536
  %"&pSB[currWI].offset1830.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1829.i"
  %CastToValueType1831.i = bitcast i8* %"&pSB[currWI].offset1830.i" to [4 x <4 x i8>]*
  %183 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1831.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1183.i" = add nuw i64 %CurrSBIndex..0.i, 1040
  %"&pSB[currWI].offset1184.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1183.i"
  %CastToValueType1185.i = bitcast i8* %"&pSB[currWI].offset1184.i" to <4 x i8>**
  store <4 x i8>* %183, <4 x i8>** %CastToValueType1185.i, align 8
  %"&(pSB[currWI].offset)1865.i" = add nuw i64 %CurrSBIndex..0.i, 1552
  %"&pSB[currWI].offset1866.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1865.i"
  %CastToValueType1867.i = bitcast i8* %"&pSB[currWI].offset1866.i" to [4 x <4 x i8>]*
  %184 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1867.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1207.i" = add nuw i64 %CurrSBIndex..0.i, 1048
  %"&pSB[currWI].offset1208.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1207.i"
  %CastToValueType1209.i = bitcast i8* %"&pSB[currWI].offset1208.i" to <4 x i8>**
  store <4 x i8>* %184, <4 x i8>** %CastToValueType1209.i, align 8
  %"&(pSB[currWI].offset)1901.i" = add nuw i64 %CurrSBIndex..0.i, 1568
  %"&pSB[currWI].offset1902.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1901.i"
  %CastToValueType1903.i = bitcast i8* %"&pSB[currWI].offset1902.i" to [4 x <4 x i8>]*
  %185 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1903.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1231.i" = add nuw i64 %CurrSBIndex..0.i, 1056
  %"&pSB[currWI].offset1232.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1231.i"
  %CastToValueType1233.i = bitcast i8* %"&pSB[currWI].offset1232.i" to <4 x i8>**
  store <4 x i8>* %185, <4 x i8>** %CastToValueType1233.i, align 8
  %"&(pSB[currWI].offset)1937.i" = add nuw i64 %CurrSBIndex..0.i, 1584
  %"&pSB[currWI].offset1938.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1937.i"
  %CastToValueType1939.i = bitcast i8* %"&pSB[currWI].offset1938.i" to [4 x <4 x i8>]*
  %186 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1939.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1255.i" = add nuw i64 %CurrSBIndex..0.i, 1064
  %"&pSB[currWI].offset1256.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1255.i"
  %CastToValueType1257.i = bitcast i8* %"&pSB[currWI].offset1256.i" to <4 x i8>**
  store <4 x i8>* %186, <4 x i8>** %CastToValueType1257.i, align 8
  %"&(pSB[currWI].offset)1973.i" = add nuw i64 %CurrSBIndex..0.i, 1600
  %"&pSB[currWI].offset1974.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1973.i"
  %CastToValueType1975.i = bitcast i8* %"&pSB[currWI].offset1974.i" to [4 x <4 x i8>]*
  %187 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1975.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1279.i" = add nuw i64 %CurrSBIndex..0.i, 1072
  %"&pSB[currWI].offset1280.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1279.i"
  %CastToValueType1281.i = bitcast i8* %"&pSB[currWI].offset1280.i" to <4 x i8>**
  store <4 x i8>* %187, <4 x i8>** %CastToValueType1281.i, align 8
  %"&(pSB[currWI].offset)2009.i" = add nuw i64 %CurrSBIndex..0.i, 1616
  %"&pSB[currWI].offset2010.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2009.i"
  %CastToValueType2011.i = bitcast i8* %"&pSB[currWI].offset2010.i" to [4 x <4 x i8>]*
  %188 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2011.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1303.i" = add nuw i64 %CurrSBIndex..0.i, 1080
  %"&pSB[currWI].offset1304.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1303.i"
  %CastToValueType1305.i = bitcast i8* %"&pSB[currWI].offset1304.i" to <4 x i8>**
  store <4 x i8>* %188, <4 x i8>** %CastToValueType1305.i, align 8
  %"&(pSB[currWI].offset)2045.i" = add nuw i64 %CurrSBIndex..0.i, 1632
  %"&pSB[currWI].offset2046.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2045.i"
  %CastToValueType2047.i = bitcast i8* %"&pSB[currWI].offset2046.i" to [4 x <4 x i8>]*
  %189 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2047.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1327.i" = add nuw i64 %CurrSBIndex..0.i, 1088
  %"&pSB[currWI].offset1328.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1327.i"
  %CastToValueType1329.i = bitcast i8* %"&pSB[currWI].offset1328.i" to <4 x i8>**
  store <4 x i8>* %189, <4 x i8>** %CastToValueType1329.i, align 8
  %"&(pSB[currWI].offset)2081.i" = add nuw i64 %CurrSBIndex..0.i, 1648
  %"&pSB[currWI].offset2082.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2081.i"
  %CastToValueType2083.i = bitcast i8* %"&pSB[currWI].offset2082.i" to [4 x <4 x i8>]*
  %190 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2083.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1351.i" = add nuw i64 %CurrSBIndex..0.i, 1096
  %"&pSB[currWI].offset1352.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1351.i"
  %CastToValueType1353.i = bitcast i8* %"&pSB[currWI].offset1352.i" to <4 x i8>**
  store <4 x i8>* %190, <4 x i8>** %CastToValueType1353.i, align 8
  %"&(pSB[currWI].offset)2117.i" = add nuw i64 %CurrSBIndex..0.i, 1664
  %"&pSB[currWI].offset2118.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2117.i"
  %CastToValueType2119.i = bitcast i8* %"&pSB[currWI].offset2118.i" to [4 x <4 x i8>]*
  %191 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2119.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1375.i" = add nuw i64 %CurrSBIndex..0.i, 1104
  %"&pSB[currWI].offset1376.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1375.i"
  %CastToValueType1377.i = bitcast i8* %"&pSB[currWI].offset1376.i" to <4 x i8>**
  store <4 x i8>* %191, <4 x i8>** %CastToValueType1377.i, align 8
  %"&(pSB[currWI].offset)2153.i" = add nuw i64 %CurrSBIndex..0.i, 1680
  %"&pSB[currWI].offset2154.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2153.i"
  %CastToValueType2155.i = bitcast i8* %"&pSB[currWI].offset2154.i" to [4 x <4 x i8>]*
  %192 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2155.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1399.i" = add nuw i64 %CurrSBIndex..0.i, 1112
  %"&pSB[currWI].offset1400.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1399.i"
  %CastToValueType1401.i = bitcast i8* %"&pSB[currWI].offset1400.i" to <4 x i8>**
  store <4 x i8>* %192, <4 x i8>** %CastToValueType1401.i, align 8
  %"&(pSB[currWI].offset)2189.i" = add nuw i64 %CurrSBIndex..0.i, 1696
  %"&pSB[currWI].offset2190.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2189.i"
  %CastToValueType2191.i = bitcast i8* %"&pSB[currWI].offset2190.i" to [4 x <4 x i8>]*
  %193 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2191.i, i64 0, i64 %177
  %"&(pSB[currWI].offset)1423.i" = add nuw i64 %CurrSBIndex..0.i, 1120
  %"&pSB[currWI].offset1424.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1423.i"
  %CastToValueType1425.i = bitcast i8* %"&pSB[currWI].offset1424.i" to <4 x i8>**
  store <4 x i8>* %193, <4 x i8>** %CastToValueType1425.i, align 8
  %tmp75.i = sub i64 1, %42
  %"&(pSB[currWI].offset)1447.i" = add nuw i64 %CurrSBIndex..0.i, 1128
  %"&pSB[currWI].offset1448.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1447.i"
  %CastToValueType1449.i = bitcast i8* %"&pSB[currWI].offset1448.i" to i64*
  store i64 %tmp75.i, i64* %CastToValueType1449.i, align 8
  %tmp86.i = add i32 %35, %43
  %tmp87.i = add i32 %tmp86.i, -4
  %"&(pSB[currWI].offset)1456.i" = add nuw i64 %CurrSBIndex..0.i, 1136
  %"&pSB[currWI].offset1457.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1456.i"
  %CastToValueType1458.i = bitcast i8* %"&pSB[currWI].offset1457.i" to i32*
  store i32 %tmp87.i, i32* %CastToValueType1458.i, align 4
  br label %194

; <label>:194                                     ; preds = %._crit_edge66.i, %SyncBB.i
  %CurrSBIndex..2.i = phi i64 [ %CurrSBIndex..0.i, %SyncBB.i ], [ %CurrSBIndex..1.i, %._crit_edge66.i ]
  %currBarrier.1.i = phi i32 [ %currBarrier.2.i, %SyncBB.i ], [ %currBarrier.0.i, %._crit_edge66.i ]
  %CurrWI..2.i = phi i64 [ %CurrWI..0.i, %SyncBB.i ], [ %CurrWI..1.i, %._crit_edge66.i ]
  %vectorPHI.i = phi <16 x i8> [ %vector.i, %SyncBB.i ], [ %loadedValue1580.i, %._crit_edge66.i ]
  %vectorPHI132.i = phi <16 x i8> [ %vector134.i, %SyncBB.i ], [ %loadedValue1594.i, %._crit_edge66.i ]
  %vectorPHI135.i = phi <16 x i8> [ %vector137.i, %SyncBB.i ], [ %loadedValue1608.i, %._crit_edge66.i ]
  %vectorPHI138.i = phi <16 x i8> [ %vector140.i, %SyncBB.i ], [ %loadedValue1622.i, %._crit_edge66.i ]
  %indvar79.i = phi i32 [ 0, %SyncBB.i ], [ %indvar.next80.i, %._crit_edge66.i ]
  %"&(pSB[currWI].offset)1465.i" = add nuw i64 %CurrSBIndex..2.i, 1140
  %"&pSB[currWI].offset1466.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1465.i"
  %CastToValueType1467.i = bitcast i8* %"&pSB[currWI].offset1466.i" to i32*
  store i32 %indvar79.i, i32* %CastToValueType1467.i, align 4
  %extract188.i = extractelement <16 x i8> %vectorPHI138.i, i32 0
  %extract189.i = extractelement <16 x i8> %vectorPHI138.i, i32 1
  %extract190.i = extractelement <16 x i8> %vectorPHI138.i, i32 2
  %extract191.i = extractelement <16 x i8> %vectorPHI138.i, i32 3
  %extract192.i = extractelement <16 x i8> %vectorPHI138.i, i32 4
  %extract193.i = extractelement <16 x i8> %vectorPHI138.i, i32 5
  %extract194.i = extractelement <16 x i8> %vectorPHI138.i, i32 6
  %extract195.i = extractelement <16 x i8> %vectorPHI138.i, i32 7
  %extract196.i = extractelement <16 x i8> %vectorPHI138.i, i32 8
  %extract197.i = extractelement <16 x i8> %vectorPHI138.i, i32 9
  %extract198.i = extractelement <16 x i8> %vectorPHI138.i, i32 10
  %extract199.i = extractelement <16 x i8> %vectorPHI138.i, i32 11
  %extract200.i = extractelement <16 x i8> %vectorPHI138.i, i32 12
  %extract201.i = extractelement <16 x i8> %vectorPHI138.i, i32 13
  %extract202.i = extractelement <16 x i8> %vectorPHI138.i, i32 14
  %extract203.i = extractelement <16 x i8> %vectorPHI138.i, i32 15
  %extract172.i = extractelement <16 x i8> %vectorPHI135.i, i32 0
  %extract173.i = extractelement <16 x i8> %vectorPHI135.i, i32 1
  %extract174.i = extractelement <16 x i8> %vectorPHI135.i, i32 2
  %extract175.i = extractelement <16 x i8> %vectorPHI135.i, i32 3
  %extract176.i = extractelement <16 x i8> %vectorPHI135.i, i32 4
  %extract177.i = extractelement <16 x i8> %vectorPHI135.i, i32 5
  %extract178.i = extractelement <16 x i8> %vectorPHI135.i, i32 6
  %extract179.i = extractelement <16 x i8> %vectorPHI135.i, i32 7
  %extract180.i = extractelement <16 x i8> %vectorPHI135.i, i32 8
  %extract181.i = extractelement <16 x i8> %vectorPHI135.i, i32 9
  %extract182.i = extractelement <16 x i8> %vectorPHI135.i, i32 10
  %extract183.i = extractelement <16 x i8> %vectorPHI135.i, i32 11
  %extract184.i = extractelement <16 x i8> %vectorPHI135.i, i32 12
  %extract185.i = extractelement <16 x i8> %vectorPHI135.i, i32 13
  %extract186.i = extractelement <16 x i8> %vectorPHI135.i, i32 14
  %extract187.i = extractelement <16 x i8> %vectorPHI135.i, i32 15
  %extract156.i = extractelement <16 x i8> %vectorPHI132.i, i32 0
  %extract157.i = extractelement <16 x i8> %vectorPHI132.i, i32 1
  %extract158.i = extractelement <16 x i8> %vectorPHI132.i, i32 2
  %extract159.i = extractelement <16 x i8> %vectorPHI132.i, i32 3
  %extract160.i = extractelement <16 x i8> %vectorPHI132.i, i32 4
  %extract161.i = extractelement <16 x i8> %vectorPHI132.i, i32 5
  %extract162.i = extractelement <16 x i8> %vectorPHI132.i, i32 6
  %extract163.i = extractelement <16 x i8> %vectorPHI132.i, i32 7
  %extract164.i = extractelement <16 x i8> %vectorPHI132.i, i32 8
  %extract165.i = extractelement <16 x i8> %vectorPHI132.i, i32 9
  %extract166.i = extractelement <16 x i8> %vectorPHI132.i, i32 10
  %extract167.i = extractelement <16 x i8> %vectorPHI132.i, i32 11
  %extract168.i = extractelement <16 x i8> %vectorPHI132.i, i32 12
  %extract169.i = extractelement <16 x i8> %vectorPHI132.i, i32 13
  %extract170.i = extractelement <16 x i8> %vectorPHI132.i, i32 14
  %extract171.i = extractelement <16 x i8> %vectorPHI132.i, i32 15
  %extract.i = extractelement <16 x i8> %vectorPHI.i, i32 0
  %extract141.i = extractelement <16 x i8> %vectorPHI.i, i32 1
  %extract142.i = extractelement <16 x i8> %vectorPHI.i, i32 2
  %extract143.i = extractelement <16 x i8> %vectorPHI.i, i32 3
  %extract144.i = extractelement <16 x i8> %vectorPHI.i, i32 4
  %extract145.i = extractelement <16 x i8> %vectorPHI.i, i32 5
  %extract146.i = extractelement <16 x i8> %vectorPHI.i, i32 6
  %extract147.i = extractelement <16 x i8> %vectorPHI.i, i32 7
  %extract148.i = extractelement <16 x i8> %vectorPHI.i, i32 8
  %extract149.i = extractelement <16 x i8> %vectorPHI.i, i32 9
  %extract150.i = extractelement <16 x i8> %vectorPHI.i, i32 10
  %extract151.i = extractelement <16 x i8> %vectorPHI.i, i32 11
  %extract152.i = extractelement <16 x i8> %vectorPHI.i, i32 12
  %extract153.i = extractelement <16 x i8> %vectorPHI.i, i32 13
  %extract154.i = extractelement <16 x i8> %vectorPHI.i, i32 14
  %extract155.i = extractelement <16 x i8> %vectorPHI.i, i32 15
  %195 = insertelement <4 x i8> undef, i8 %extract.i, i32 0
  %196 = insertelement <4 x i8> undef, i8 %extract141.i, i32 0
  %197 = insertelement <4 x i8> undef, i8 %extract142.i, i32 0
  %198 = insertelement <4 x i8> undef, i8 %extract143.i, i32 0
  %199 = insertelement <4 x i8> undef, i8 %extract144.i, i32 0
  %200 = insertelement <4 x i8> undef, i8 %extract145.i, i32 0
  %201 = insertelement <4 x i8> undef, i8 %extract146.i, i32 0
  %202 = insertelement <4 x i8> undef, i8 %extract147.i, i32 0
  %203 = insertelement <4 x i8> undef, i8 %extract148.i, i32 0
  %204 = insertelement <4 x i8> undef, i8 %extract149.i, i32 0
  %205 = insertelement <4 x i8> undef, i8 %extract150.i, i32 0
  %206 = insertelement <4 x i8> undef, i8 %extract151.i, i32 0
  %207 = insertelement <4 x i8> undef, i8 %extract152.i, i32 0
  %208 = insertelement <4 x i8> undef, i8 %extract153.i, i32 0
  %209 = insertelement <4 x i8> undef, i8 %extract154.i, i32 0
  %210 = insertelement <4 x i8> undef, i8 %extract155.i, i32 0
  %211 = insertelement <4 x i8> %195, i8 %extract156.i, i32 1
  %212 = insertelement <4 x i8> %196, i8 %extract157.i, i32 1
  %213 = insertelement <4 x i8> %197, i8 %extract158.i, i32 1
  %214 = insertelement <4 x i8> %198, i8 %extract159.i, i32 1
  %215 = insertelement <4 x i8> %199, i8 %extract160.i, i32 1
  %216 = insertelement <4 x i8> %200, i8 %extract161.i, i32 1
  %217 = insertelement <4 x i8> %201, i8 %extract162.i, i32 1
  %218 = insertelement <4 x i8> %202, i8 %extract163.i, i32 1
  %219 = insertelement <4 x i8> %203, i8 %extract164.i, i32 1
  %220 = insertelement <4 x i8> %204, i8 %extract165.i, i32 1
  %221 = insertelement <4 x i8> %205, i8 %extract166.i, i32 1
  %222 = insertelement <4 x i8> %206, i8 %extract167.i, i32 1
  %223 = insertelement <4 x i8> %207, i8 %extract168.i, i32 1
  %224 = insertelement <4 x i8> %208, i8 %extract169.i, i32 1
  %225 = insertelement <4 x i8> %209, i8 %extract170.i, i32 1
  %226 = insertelement <4 x i8> %210, i8 %extract171.i, i32 1
  %227 = insertelement <4 x i8> %211, i8 %extract172.i, i32 2
  %228 = insertelement <4 x i8> %212, i8 %extract173.i, i32 2
  %229 = insertelement <4 x i8> %213, i8 %extract174.i, i32 2
  %230 = insertelement <4 x i8> %214, i8 %extract175.i, i32 2
  %231 = insertelement <4 x i8> %215, i8 %extract176.i, i32 2
  %232 = insertelement <4 x i8> %216, i8 %extract177.i, i32 2
  %233 = insertelement <4 x i8> %217, i8 %extract178.i, i32 2
  %234 = insertelement <4 x i8> %218, i8 %extract179.i, i32 2
  %235 = insertelement <4 x i8> %219, i8 %extract180.i, i32 2
  %236 = insertelement <4 x i8> %220, i8 %extract181.i, i32 2
  %237 = insertelement <4 x i8> %221, i8 %extract182.i, i32 2
  %238 = insertelement <4 x i8> %222, i8 %extract183.i, i32 2
  %239 = insertelement <4 x i8> %223, i8 %extract184.i, i32 2
  %240 = insertelement <4 x i8> %224, i8 %extract185.i, i32 2
  %241 = insertelement <4 x i8> %225, i8 %extract186.i, i32 2
  %242 = insertelement <4 x i8> %226, i8 %extract187.i, i32 2
  %243 = insertelement <4 x i8> %227, i8 %extract188.i, i32 3
  %244 = insertelement <4 x i8> %228, i8 %extract189.i, i32 3
  %245 = insertelement <4 x i8> %229, i8 %extract190.i, i32 3
  %246 = insertelement <4 x i8> %230, i8 %extract191.i, i32 3
  %247 = insertelement <4 x i8> %231, i8 %extract192.i, i32 3
  %248 = insertelement <4 x i8> %232, i8 %extract193.i, i32 3
  %249 = insertelement <4 x i8> %233, i8 %extract194.i, i32 3
  %250 = insertelement <4 x i8> %234, i8 %extract195.i, i32 3
  %251 = insertelement <4 x i8> %235, i8 %extract196.i, i32 3
  %252 = insertelement <4 x i8> %236, i8 %extract197.i, i32 3
  %253 = insertelement <4 x i8> %237, i8 %extract198.i, i32 3
  %254 = insertelement <4 x i8> %238, i8 %extract199.i, i32 3
  %255 = insertelement <4 x i8> %239, i8 %extract200.i, i32 3
  %256 = insertelement <4 x i8> %240, i8 %extract201.i, i32 3
  %257 = insertelement <4 x i8> %241, i8 %extract202.i, i32 3
  %258 = insertelement <4 x i8> %242, i8 %extract203.i, i32 3
  %259 = bitcast <4 x i8> %243 to i32
  %260 = bitcast <4 x i8> %244 to i32
  %261 = bitcast <4 x i8> %245 to i32
  %262 = bitcast <4 x i8> %246 to i32
  %263 = bitcast <4 x i8> %247 to i32
  %264 = bitcast <4 x i8> %248 to i32
  %265 = bitcast <4 x i8> %249 to i32
  %266 = bitcast <4 x i8> %250 to i32
  %267 = bitcast <4 x i8> %251 to i32
  %268 = bitcast <4 x i8> %252 to i32
  %269 = bitcast <4 x i8> %253 to i32
  %270 = bitcast <4 x i8> %254 to i32
  %271 = bitcast <4 x i8> %255 to i32
  %272 = bitcast <4 x i8> %256 to i32
  %273 = bitcast <4 x i8> %257 to i32
  %274 = bitcast <4 x i8> %258 to i32
  %275 = bitcast i32 %259 to <4 x i8>
  %276 = bitcast i32 %260 to <4 x i8>
  %277 = bitcast i32 %261 to <4 x i8>
  %278 = bitcast i32 %262 to <4 x i8>
  %279 = bitcast i32 %263 to <4 x i8>
  %280 = bitcast i32 %264 to <4 x i8>
  %281 = bitcast i32 %265 to <4 x i8>
  %282 = bitcast i32 %266 to <4 x i8>
  %283 = bitcast i32 %267 to <4 x i8>
  %284 = bitcast i32 %268 to <4 x i8>
  %285 = bitcast i32 %269 to <4 x i8>
  %286 = bitcast i32 %270 to <4 x i8>
  %287 = bitcast i32 %271 to <4 x i8>
  %288 = bitcast i32 %272 to <4 x i8>
  %289 = bitcast i32 %273 to <4 x i8>
  %290 = bitcast i32 %274 to <4 x i8>
  %291 = extractelement <4 x i8> %275, i32 0
  %292 = extractelement <4 x i8> %276, i32 0
  %293 = extractelement <4 x i8> %277, i32 0
  %294 = extractelement <4 x i8> %278, i32 0
  %295 = extractelement <4 x i8> %279, i32 0
  %296 = extractelement <4 x i8> %280, i32 0
  %297 = extractelement <4 x i8> %281, i32 0
  %298 = extractelement <4 x i8> %282, i32 0
  %299 = extractelement <4 x i8> %283, i32 0
  %300 = extractelement <4 x i8> %284, i32 0
  %301 = extractelement <4 x i8> %285, i32 0
  %302 = extractelement <4 x i8> %286, i32 0
  %303 = extractelement <4 x i8> %287, i32 0
  %304 = extractelement <4 x i8> %288, i32 0
  %305 = extractelement <4 x i8> %289, i32 0
  %306 = extractelement <4 x i8> %290, i32 0
  %temp.vect205.i = insertelement <16 x i8> undef, i8 %291, i32 0
  %temp.vect206.i = insertelement <16 x i8> %temp.vect205.i, i8 %292, i32 1
  %temp.vect207.i = insertelement <16 x i8> %temp.vect206.i, i8 %293, i32 2
  %temp.vect208.i = insertelement <16 x i8> %temp.vect207.i, i8 %294, i32 3
  %temp.vect209.i = insertelement <16 x i8> %temp.vect208.i, i8 %295, i32 4
  %temp.vect210.i = insertelement <16 x i8> %temp.vect209.i, i8 %296, i32 5
  %temp.vect211.i = insertelement <16 x i8> %temp.vect210.i, i8 %297, i32 6
  %temp.vect212.i = insertelement <16 x i8> %temp.vect211.i, i8 %298, i32 7
  %temp.vect213.i = insertelement <16 x i8> %temp.vect212.i, i8 %299, i32 8
  %temp.vect214.i = insertelement <16 x i8> %temp.vect213.i, i8 %300, i32 9
  %temp.vect215.i = insertelement <16 x i8> %temp.vect214.i, i8 %301, i32 10
  %temp.vect216.i = insertelement <16 x i8> %temp.vect215.i, i8 %302, i32 11
  %temp.vect217.i = insertelement <16 x i8> %temp.vect216.i, i8 %303, i32 12
  %temp.vect218.i = insertelement <16 x i8> %temp.vect217.i, i8 %304, i32 13
  %temp.vect219.i = insertelement <16 x i8> %temp.vect218.i, i8 %305, i32 14
  %temp.vect220.i = insertelement <16 x i8> %temp.vect219.i, i8 %306, i32 15
  %"&(pSB[currWI].offset)1484.i" = add nuw i64 %CurrSBIndex..2.i, 1152
  %"&pSB[currWI].offset1485.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1484.i"
  %CastToValueType1486.i = bitcast i8* %"&pSB[currWI].offset1485.i" to <16 x i8>*
  store <16 x i8> %temp.vect220.i, <16 x i8>* %CastToValueType1486.i, align 16
  %307 = extractelement <4 x i8> %275, i32 1
  %308 = extractelement <4 x i8> %276, i32 1
  %309 = extractelement <4 x i8> %277, i32 1
  %310 = extractelement <4 x i8> %278, i32 1
  %311 = extractelement <4 x i8> %279, i32 1
  %312 = extractelement <4 x i8> %280, i32 1
  %313 = extractelement <4 x i8> %281, i32 1
  %314 = extractelement <4 x i8> %282, i32 1
  %315 = extractelement <4 x i8> %283, i32 1
  %316 = extractelement <4 x i8> %284, i32 1
  %317 = extractelement <4 x i8> %285, i32 1
  %318 = extractelement <4 x i8> %286, i32 1
  %319 = extractelement <4 x i8> %287, i32 1
  %320 = extractelement <4 x i8> %288, i32 1
  %321 = extractelement <4 x i8> %289, i32 1
  %322 = extractelement <4 x i8> %290, i32 1
  %temp.vect222.i = insertelement <16 x i8> undef, i8 %307, i32 0
  %temp.vect223.i = insertelement <16 x i8> %temp.vect222.i, i8 %308, i32 1
  %temp.vect224.i = insertelement <16 x i8> %temp.vect223.i, i8 %309, i32 2
  %temp.vect225.i = insertelement <16 x i8> %temp.vect224.i, i8 %310, i32 3
  %temp.vect226.i = insertelement <16 x i8> %temp.vect225.i, i8 %311, i32 4
  %temp.vect227.i = insertelement <16 x i8> %temp.vect226.i, i8 %312, i32 5
  %temp.vect228.i = insertelement <16 x i8> %temp.vect227.i, i8 %313, i32 6
  %temp.vect229.i = insertelement <16 x i8> %temp.vect228.i, i8 %314, i32 7
  %temp.vect230.i = insertelement <16 x i8> %temp.vect229.i, i8 %315, i32 8
  %temp.vect231.i = insertelement <16 x i8> %temp.vect230.i, i8 %316, i32 9
  %temp.vect232.i = insertelement <16 x i8> %temp.vect231.i, i8 %317, i32 10
  %temp.vect233.i = insertelement <16 x i8> %temp.vect232.i, i8 %318, i32 11
  %temp.vect234.i = insertelement <16 x i8> %temp.vect233.i, i8 %319, i32 12
  %temp.vect235.i = insertelement <16 x i8> %temp.vect234.i, i8 %320, i32 13
  %temp.vect236.i = insertelement <16 x i8> %temp.vect235.i, i8 %321, i32 14
  %temp.vect237.i = insertelement <16 x i8> %temp.vect236.i, i8 %322, i32 15
  %"&(pSB[currWI].offset)1488.i" = add nuw i64 %CurrSBIndex..2.i, 1168
  %"&pSB[currWI].offset1489.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1488.i"
  %CastToValueType1490.i = bitcast i8* %"&pSB[currWI].offset1489.i" to <16 x i8>*
  store <16 x i8> %temp.vect237.i, <16 x i8>* %CastToValueType1490.i, align 16
  %323 = extractelement <4 x i8> %275, i32 2
  %324 = extractelement <4 x i8> %276, i32 2
  %325 = extractelement <4 x i8> %277, i32 2
  %326 = extractelement <4 x i8> %278, i32 2
  %327 = extractelement <4 x i8> %279, i32 2
  %328 = extractelement <4 x i8> %280, i32 2
  %329 = extractelement <4 x i8> %281, i32 2
  %330 = extractelement <4 x i8> %282, i32 2
  %331 = extractelement <4 x i8> %283, i32 2
  %332 = extractelement <4 x i8> %284, i32 2
  %333 = extractelement <4 x i8> %285, i32 2
  %334 = extractelement <4 x i8> %286, i32 2
  %335 = extractelement <4 x i8> %287, i32 2
  %336 = extractelement <4 x i8> %288, i32 2
  %337 = extractelement <4 x i8> %289, i32 2
  %338 = extractelement <4 x i8> %290, i32 2
  %temp.vect239.i = insertelement <16 x i8> undef, i8 %323, i32 0
  %temp.vect240.i = insertelement <16 x i8> %temp.vect239.i, i8 %324, i32 1
  %temp.vect241.i = insertelement <16 x i8> %temp.vect240.i, i8 %325, i32 2
  %temp.vect242.i = insertelement <16 x i8> %temp.vect241.i, i8 %326, i32 3
  %temp.vect243.i = insertelement <16 x i8> %temp.vect242.i, i8 %327, i32 4
  %temp.vect244.i = insertelement <16 x i8> %temp.vect243.i, i8 %328, i32 5
  %temp.vect245.i = insertelement <16 x i8> %temp.vect244.i, i8 %329, i32 6
  %temp.vect246.i = insertelement <16 x i8> %temp.vect245.i, i8 %330, i32 7
  %temp.vect247.i = insertelement <16 x i8> %temp.vect246.i, i8 %331, i32 8
  %temp.vect248.i = insertelement <16 x i8> %temp.vect247.i, i8 %332, i32 9
  %temp.vect249.i = insertelement <16 x i8> %temp.vect248.i, i8 %333, i32 10
  %temp.vect250.i = insertelement <16 x i8> %temp.vect249.i, i8 %334, i32 11
  %temp.vect251.i = insertelement <16 x i8> %temp.vect250.i, i8 %335, i32 12
  %temp.vect252.i = insertelement <16 x i8> %temp.vect251.i, i8 %336, i32 13
  %temp.vect253.i = insertelement <16 x i8> %temp.vect252.i, i8 %337, i32 14
  %temp.vect254.i = insertelement <16 x i8> %temp.vect253.i, i8 %338, i32 15
  %"&(pSB[currWI].offset)1492.i" = add nuw i64 %CurrSBIndex..2.i, 1184
  %"&pSB[currWI].offset1493.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1492.i"
  %CastToValueType1494.i = bitcast i8* %"&pSB[currWI].offset1493.i" to <16 x i8>*
  store <16 x i8> %temp.vect254.i, <16 x i8>* %CastToValueType1494.i, align 16
  %339 = extractelement <4 x i8> %275, i32 3
  %340 = extractelement <4 x i8> %276, i32 3
  %341 = extractelement <4 x i8> %277, i32 3
  %342 = extractelement <4 x i8> %278, i32 3
  %343 = extractelement <4 x i8> %279, i32 3
  %344 = extractelement <4 x i8> %280, i32 3
  %345 = extractelement <4 x i8> %281, i32 3
  %346 = extractelement <4 x i8> %282, i32 3
  %347 = extractelement <4 x i8> %283, i32 3
  %348 = extractelement <4 x i8> %284, i32 3
  %349 = extractelement <4 x i8> %285, i32 3
  %350 = extractelement <4 x i8> %286, i32 3
  %351 = extractelement <4 x i8> %287, i32 3
  %352 = extractelement <4 x i8> %288, i32 3
  %353 = extractelement <4 x i8> %289, i32 3
  %354 = extractelement <4 x i8> %290, i32 3
  %temp.vect256.i = insertelement <16 x i8> undef, i8 %339, i32 0
  %temp.vect257.i = insertelement <16 x i8> %temp.vect256.i, i8 %340, i32 1
  %temp.vect258.i = insertelement <16 x i8> %temp.vect257.i, i8 %341, i32 2
  %temp.vect259.i = insertelement <16 x i8> %temp.vect258.i, i8 %342, i32 3
  %temp.vect260.i = insertelement <16 x i8> %temp.vect259.i, i8 %343, i32 4
  %temp.vect261.i = insertelement <16 x i8> %temp.vect260.i, i8 %344, i32 5
  %temp.vect262.i = insertelement <16 x i8> %temp.vect261.i, i8 %345, i32 6
  %temp.vect263.i = insertelement <16 x i8> %temp.vect262.i, i8 %346, i32 7
  %temp.vect264.i = insertelement <16 x i8> %temp.vect263.i, i8 %347, i32 8
  %temp.vect265.i = insertelement <16 x i8> %temp.vect264.i, i8 %348, i32 9
  %temp.vect266.i = insertelement <16 x i8> %temp.vect265.i, i8 %349, i32 10
  %temp.vect267.i = insertelement <16 x i8> %temp.vect266.i, i8 %350, i32 11
  %temp.vect268.i = insertelement <16 x i8> %temp.vect267.i, i8 %351, i32 12
  %temp.vect269.i = insertelement <16 x i8> %temp.vect268.i, i8 %352, i32 13
  %temp.vect270.i = insertelement <16 x i8> %temp.vect269.i, i8 %353, i32 14
  %temp.vect271.i = insertelement <16 x i8> %temp.vect270.i, i8 %354, i32 15
  %"&(pSB[currWI].offset)1496.i" = add nuw i64 %CurrSBIndex..2.i, 1200
  %"&pSB[currWI].offset1497.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1496.i"
  %CastToValueType1498.i = bitcast i8* %"&pSB[currWI].offset1497.i" to <16 x i8>*
  store <16 x i8> %temp.vect271.i, <16 x i8>* %CastToValueType1498.i, align 16
  %"&(pSB[currWI].offset)991.i" = add nuw i64 %CurrSBIndex..2.i, 896
  %"&pSB[currWI].offset992.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)991.i"
  %CastToValueType993.i = bitcast i8* %"&pSB[currWI].offset992.i" to i32*
  %loadedValue994.i = load i32* %CastToValueType993.i, align 4
  %355 = icmp eq i32 %loadedValue994.i, 0
  br i1 %355, label %shiftRowsInv.exit.i, label %bb.nph.i.preheader.i

bb.nph.i.preheader.i:                             ; preds = %194
  %"&(pSB[currWI].offset)1512.i" = add nuw i64 %CurrSBIndex..2.i, 1264
  %"&pSB[currWI].offset1513.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1512.i"
  %CastToValueType1514.i = bitcast i8* %"&pSB[currWI].offset1513.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1508.i" = add nuw i64 %CurrSBIndex..2.i, 1248
  %"&pSB[currWI].offset1509.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1508.i"
  %CastToValueType1510.i = bitcast i8* %"&pSB[currWI].offset1509.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1504.i" = add nuw i64 %CurrSBIndex..2.i, 1232
  %"&pSB[currWI].offset1505.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1504.i"
  %CastToValueType1506.i = bitcast i8* %"&pSB[currWI].offset1505.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1500.i" = add nuw i64 %CurrSBIndex..2.i, 1216
  %"&pSB[currWI].offset1501.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1500.i"
  %CastToValueType1502.i = bitcast i8* %"&pSB[currWI].offset1501.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1516.i" = add nuw i64 %CurrSBIndex..2.i, 1280
  %"&pSB[currWI].offset1517.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1516.i"
  %CastToValueType1518.i = bitcast i8* %"&pSB[currWI].offset1517.i" to i32*
  %"&(pSB[currWI].offset)987.i" = add nuw i64 %CurrSBIndex..2.i, 896
  %"&pSB[currWI].offset988.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)987.i"
  %CastToValueType989.i = bitcast i8* %"&pSB[currWI].offset988.i" to i32*
  br label %bb.nph.i.i

bb.nph.i.i:                                       ; preds = %bb.nph.i.i, %bb.nph.i.preheader.i
  %i.03.i.i = phi i32 [ %356, %bb.nph.i.i ], [ 0, %bb.nph.i.preheader.i ]
  %vectorPHI204.i = phi <16 x i8> [ %vectorPHI255.i, %bb.nph.i.i ], [ %temp.vect220.i, %bb.nph.i.preheader.i ]
  %vectorPHI221.i = phi <16 x i8> [ %vectorPHI204.i, %bb.nph.i.i ], [ %temp.vect237.i, %bb.nph.i.preheader.i ]
  %vectorPHI238.i = phi <16 x i8> [ %vectorPHI221.i, %bb.nph.i.i ], [ %temp.vect254.i, %bb.nph.i.preheader.i ]
  %vectorPHI255.i = phi <16 x i8> [ %vectorPHI238.i, %bb.nph.i.i ], [ %temp.vect271.i, %bb.nph.i.preheader.i ]
  store <16 x i8> %vectorPHI255.i, <16 x i8>* %CastToValueType1514.i, align 16
  store <16 x i8> %vectorPHI238.i, <16 x i8>* %CastToValueType1510.i, align 16
  store <16 x i8> %vectorPHI221.i, <16 x i8>* %CastToValueType1506.i, align 16
  store <16 x i8> %vectorPHI204.i, <16 x i8>* %CastToValueType1502.i, align 16
  %356 = add i32 %i.03.i.i, 1
  store i32 %356, i32* %CastToValueType1518.i, align 4
  %loadedValue.i = load i32* %CastToValueType989.i, align 4
  %exitcond.i.i = icmp eq i32 %356, %loadedValue.i
  br i1 %exitcond.i.i, label %shiftRowsInv.exit.i, label %bb.nph.i.i

shiftRowsInv.exit.i:                              ; preds = %bb.nph.i.i, %194
  %vectorPHI272.i = phi <16 x i8> [ %temp.vect220.i, %194 ], [ %vectorPHI255.i, %bb.nph.i.i ]
  %vectorPHI273.i = phi <16 x i8> [ %temp.vect237.i, %194 ], [ %vectorPHI204.i, %bb.nph.i.i ]
  %vectorPHI274.i = phi <16 x i8> [ %temp.vect254.i, %194 ], [ %vectorPHI221.i, %bb.nph.i.i ]
  %vectorPHI275.i = phi <16 x i8> [ %temp.vect271.i, %194 ], [ %vectorPHI238.i, %bb.nph.i.i ]
  %extract339.i = extractelement <16 x i8> %vectorPHI275.i, i32 15
  %extract323.i = extractelement <16 x i8> %vectorPHI274.i, i32 15
  %extract307.i = extractelement <16 x i8> %vectorPHI273.i, i32 15
  %extract291.i = extractelement <16 x i8> %vectorPHI272.i, i32 15
  %357 = insertelement <4 x i8> undef, i8 %extract291.i, i32 0
  %358 = insertelement <4 x i8> %357, i8 %extract307.i, i32 1
  %359 = insertelement <4 x i8> %358, i8 %extract323.i, i32 2
  %360 = insertelement <4 x i8> %359, i8 %extract339.i, i32 3
  %361 = bitcast <4 x i8> %360 to i32
  %362 = bitcast i32 %361 to <4 x i8>
  %"&(pSB[currWI].offset)1028.i" = add nuw i64 %CurrSBIndex..2.i, 920
  %"&pSB[currWI].offset1029.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1028.i"
  %CastToValueType1030.i = bitcast i8* %"&pSB[currWI].offset1029.i" to <4 x i8> addrspace(3)**
  %loadedValue1031.i = load <4 x i8> addrspace(3)** %CastToValueType1030.i, align 8
  store <4 x i8> %362, <4 x i8> addrspace(3)* %loadedValue1031.i, align 4
  %363 = bitcast <4 x i8> %362 to i32
  %364 = bitcast i32 %363 to <4 x i8>
  %365 = extractelement <4 x i8> %364, i32 0
  %366 = extractelement <4 x i8> %364, i32 1
  %367 = extractelement <4 x i8> %364, i32 2
  %368 = extractelement <4 x i8> %364, i32 3
  %369 = zext i8 %365 to i64
  %370 = getelementptr inbounds i8 addrspace(1)* %10, i64 %369
  %371 = load i8 addrspace(1)* %370, align 1
  %372 = zext i8 %366 to i64
  %373 = getelementptr inbounds i8 addrspace(1)* %10, i64 %372
  %374 = load i8 addrspace(1)* %373, align 1
  %375 = zext i8 %367 to i64
  %376 = getelementptr inbounds i8 addrspace(1)* %10, i64 %375
  %377 = load i8 addrspace(1)* %376, align 1
  %378 = zext i8 %368 to i64
  %379 = getelementptr inbounds i8 addrspace(1)* %10, i64 %378
  %380 = load i8 addrspace(1)* %379, align 1
  %381 = insertelement <4 x i8> undef, i8 %371, i32 0
  %382 = insertelement <4 x i8> %381, i8 %374, i32 1
  %383 = insertelement <4 x i8> %382, i8 %377, i32 2
  %384 = insertelement <4 x i8> %383, i8 %380, i32 3
  %385 = bitcast <4 x i8> %384 to i32
  %386 = bitcast i32 %385 to <4 x i8>
  %"&(pSB[currWI].offset)1520.i" = add nuw i64 %CurrSBIndex..2.i, 1284
  %"&pSB[currWI].offset1521.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1520.i"
  %CastToValueType1522.i = bitcast i8* %"&pSB[currWI].offset1521.i" to <4 x i8>*
  store <4 x i8> %386, <4 x i8>* %CastToValueType1522.i, align 4
  %"&(pSB[currWI].offset)1023.i" = add nuw i64 %CurrSBIndex..2.i, 920
  %"&pSB[currWI].offset1024.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1023.i"
  %CastToValueType1025.i = bitcast i8* %"&pSB[currWI].offset1024.i" to <4 x i8> addrspace(3)**
  %loadedValue1026.i = load <4 x i8> addrspace(3)** %CastToValueType1025.i, align 8
  store <4 x i8> %386, <4 x i8> addrspace(3)* %loadedValue1026.i, align 4
  %"&(pSB[currWI].offset)1479.i" = add nuw i64 %CurrSBIndex..2.i, 1140
  %"&pSB[currWI].offset1480.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1479.i"
  %CastToValueType1481.i = bitcast i8* %"&pSB[currWI].offset1480.i" to i32*
  %loadedValue1482.i = load i32* %CastToValueType1481.i, align 4
  %exitcond82.i = icmp eq i32 %loadedValue1482.i, %tmp81.i
  br i1 %exitcond82.i, label %"Barrier BB985.i", label %bb.nph65.i

bb.nph65.i:                                       ; preds = %shiftRowsInv.exit.i
  %"&(pSB[currWI].offset)1474.i" = add nuw i64 %CurrSBIndex..2.i, 1140
  %"&pSB[currWI].offset1475.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1474.i"
  %CastToValueType1476.i = bitcast i8* %"&pSB[currWI].offset1475.i" to i32*
  %loadedValue1477.i = load i32* %CastToValueType1476.i, align 4
  %tmp83.i = mul i32 %loadedValue1477.i, -4
  %"&(pSB[currWI].offset)1460.i" = add nuw i64 %CurrSBIndex..2.i, 1136
  %"&pSB[currWI].offset1461.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1460.i"
  %CastToValueType1462.i = bitcast i8* %"&pSB[currWI].offset1461.i" to i32*
  %loadedValue1463.i = load i32* %CastToValueType1462.i, align 4
  %tmp88.i = add i32 %loadedValue1463.i, %tmp83.i
  %"&(pSB[currWI].offset)1544.i" = add nuw i64 %CurrSBIndex..2.i, 1288
  %"&pSB[currWI].offset1545.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1544.i"
  %CastToValueType1546.i = bitcast i8* %"&pSB[currWI].offset1545.i" to i32*
  store i32 %tmp88.i, i32* %CastToValueType1546.i, align 4
  %check.WI.iter.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter.i, label %thenBB.i, label %SyncBB2210.i

thenBB.i:                                         ; preds = %bb.nph65.i
  %"CurrWI++.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond.i = icmp eq i32 %currBarrier.1.i, 8
  br i1 %cond.i, label %SyncBB2211.i, label %SyncBB.i

SyncBB2210.i:                                     ; preds = %thenBB2214.i, %bb.nph65.i
  %CurrSBIndex..3.i = phi i64 [ %"loadedCurrSB+Stride2220.i", %thenBB2214.i ], [ 0, %bb.nph65.i ]
  %CurrWI..3.i = phi i64 [ %"CurrWI++2218.i", %thenBB2214.i ], [ 0, %bb.nph65.i ]
  %"&(pSB[currWI].offset)1033.i" = add nuw i64 %CurrSBIndex..3.i, 920
  %"&pSB[currWI].offset1034.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1033.i"
  %CastToValueType1035.i = bitcast i8* %"&pSB[currWI].offset1034.i" to <4 x i8> addrspace(3)**
  %loadedValue1036.i = load <4 x i8> addrspace(3)** %CastToValueType1035.i, align 8
  %387 = load <4 x i8> addrspace(3)* %loadedValue1036.i, align 4
  %scalar25.i = extractelement <4 x i8> %387, i32 0
  %scalar26.i = extractelement <4 x i8> %387, i32 1
  %scalar27.i = extractelement <4 x i8> %387, i32 2
  %scalar28.i = extractelement <4 x i8> %387, i32 3
  %"&(pSB[currWI].offset)1548.i" = add nuw i64 %CurrSBIndex..3.i, 1288
  %"&pSB[currWI].offset1549.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1548.i"
  %CastToValueType1550.i = bitcast i8* %"&pSB[currWI].offset1549.i" to i32*
  %loadedValue1551.i = load i32* %CastToValueType1550.i, align 4
  %388 = zext i32 %loadedValue1551.i to i64
  %389 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %388
  %390 = load <4 x i8> addrspace(1)* %389, align 4
  %scalar29.i = extractelement <4 x i8> %390, i32 0
  %scalar30.i = extractelement <4 x i8> %390, i32 1
  %scalar31.i = extractelement <4 x i8> %390, i32 2
  %scalar32.i = extractelement <4 x i8> %390, i32 3
  %391 = xor i8 %scalar25.i, %scalar29.i
  %392 = xor i8 %scalar26.i, %scalar30.i
  %393 = xor i8 %scalar27.i, %scalar31.i
  %394 = xor i8 %scalar28.i, %scalar32.i
  %temp.vect120.i = insertelement <4 x i8> undef, i8 %391, i32 0
  %temp.vect121.i = insertelement <4 x i8> %temp.vect120.i, i8 %392, i32 1
  %temp.vect122.i = insertelement <4 x i8> %temp.vect121.i, i8 %393, i32 2
  %temp.vect123.i = insertelement <4 x i8> %temp.vect122.i, i8 %394, i32 3
  %"&(pSB[currWI].offset)1058.i" = add nuw i64 %CurrSBIndex..3.i, 992
  %"&pSB[currWI].offset1059.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1058.i"
  %CastToValueType1060.i = bitcast i8* %"&pSB[currWI].offset1059.i" to <4 x i8> addrspace(3)**
  %loadedValue1061.i = load <4 x i8> addrspace(3)** %CastToValueType1060.i, align 8
  store <4 x i8> %temp.vect123.i, <4 x i8> addrspace(3)* %loadedValue1061.i, align 4
  %check.WI.iter2217.i = icmp ult i64 %CurrWI..3.i, %31
  br i1 %check.WI.iter2217.i, label %thenBB2214.i, label %SyncBB2211.i

thenBB2214.i:                                     ; preds = %SyncBB2210.i
  %"CurrWI++2218.i" = add nuw i64 %CurrWI..3.i, 1
  %"loadedCurrSB+Stride2220.i" = add nuw i64 %CurrSBIndex..3.i, 1712
  br label %SyncBB2210.i

SyncBB2211.i:                                     ; preds = %thenBB2221.i, %SyncBB2210.i, %thenBB.i
  %CurrSBIndex..1.i = phi i64 [ %"loadedCurrSB+Stride2227.i", %thenBB2221.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ], [ 0, %SyncBB2210.i ]
  %currBarrier.0.i = phi i32 [ %currBarrier.1.i, %thenBB2221.i ], [ %currBarrier.1.i, %thenBB.i ], [ 8, %SyncBB2210.i ]
  %CurrWI..1.i = phi i64 [ %"CurrWI++2225.i", %thenBB2221.i ], [ %"CurrWI++.i", %thenBB.i ], [ 0, %SyncBB2210.i ]
  %"&(pSB[currWI].offset)1082.i" = add nuw i64 %CurrSBIndex..1.i, 1000
  %"&pSB[currWI].offset1083.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1082.i"
  %CastToValueType1084.i = bitcast i8* %"&pSB[currWI].offset1083.i" to <4 x i8>**
  %loadedValue1085.i = load <4 x i8>** %CastToValueType1084.i, align 8
  %395 = load <4 x i8>* %loadedValue1085.i, align 4
  %"&(pSB[currWI].offset)1106.i" = add nuw i64 %CurrSBIndex..1.i, 1008
  %"&pSB[currWI].offset1107.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1106.i"
  %CastToValueType1108.i = bitcast i8* %"&pSB[currWI].offset1107.i" to <4 x i8>**
  %loadedValue1109.i = load <4 x i8>** %CastToValueType1108.i, align 8
  %396 = load <4 x i8>* %loadedValue1109.i, align 4
  %"&(pSB[currWI].offset)1130.i" = add nuw i64 %CurrSBIndex..1.i, 1016
  %"&pSB[currWI].offset1131.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1130.i"
  %CastToValueType1132.i = bitcast i8* %"&pSB[currWI].offset1131.i" to <4 x i8>**
  %loadedValue1133.i = load <4 x i8>** %CastToValueType1132.i, align 8
  %397 = load <4 x i8>* %loadedValue1133.i, align 4
  %"&(pSB[currWI].offset)1154.i" = add nuw i64 %CurrSBIndex..1.i, 1024
  %"&pSB[currWI].offset1155.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1154.i"
  %CastToValueType1156.i = bitcast i8* %"&pSB[currWI].offset1155.i" to <4 x i8>**
  %loadedValue1157.i = load <4 x i8>** %CastToValueType1156.i, align 8
  %398 = load <4 x i8>* %loadedValue1157.i, align 4
  %"&(pSB[currWI].offset)1178.i" = add nuw i64 %CurrSBIndex..1.i, 1032
  %"&pSB[currWI].offset1179.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1178.i"
  %CastToValueType1180.i = bitcast i8* %"&pSB[currWI].offset1179.i" to <4 x i8>**
  %loadedValue1181.i = load <4 x i8>** %CastToValueType1180.i, align 8
  %399 = load <4 x i8>* %loadedValue1181.i, align 4
  %"&(pSB[currWI].offset)1202.i" = add nuw i64 %CurrSBIndex..1.i, 1040
  %"&pSB[currWI].offset1203.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1202.i"
  %CastToValueType1204.i = bitcast i8* %"&pSB[currWI].offset1203.i" to <4 x i8>**
  %loadedValue1205.i = load <4 x i8>** %CastToValueType1204.i, align 8
  %400 = load <4 x i8>* %loadedValue1205.i, align 4
  %"&(pSB[currWI].offset)1226.i" = add nuw i64 %CurrSBIndex..1.i, 1048
  %"&pSB[currWI].offset1227.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1226.i"
  %CastToValueType1228.i = bitcast i8* %"&pSB[currWI].offset1227.i" to <4 x i8>**
  %loadedValue1229.i = load <4 x i8>** %CastToValueType1228.i, align 8
  %401 = load <4 x i8>* %loadedValue1229.i, align 4
  %"&(pSB[currWI].offset)1250.i" = add nuw i64 %CurrSBIndex..1.i, 1056
  %"&pSB[currWI].offset1251.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1250.i"
  %CastToValueType1252.i = bitcast i8* %"&pSB[currWI].offset1251.i" to <4 x i8>**
  %loadedValue1253.i = load <4 x i8>** %CastToValueType1252.i, align 8
  %402 = load <4 x i8>* %loadedValue1253.i, align 4
  %"&(pSB[currWI].offset)1274.i" = add nuw i64 %CurrSBIndex..1.i, 1064
  %"&pSB[currWI].offset1275.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1274.i"
  %CastToValueType1276.i = bitcast i8* %"&pSB[currWI].offset1275.i" to <4 x i8>**
  %loadedValue1277.i = load <4 x i8>** %CastToValueType1276.i, align 8
  %403 = load <4 x i8>* %loadedValue1277.i, align 4
  %"&(pSB[currWI].offset)1298.i" = add nuw i64 %CurrSBIndex..1.i, 1072
  %"&pSB[currWI].offset1299.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1298.i"
  %CastToValueType1300.i = bitcast i8* %"&pSB[currWI].offset1299.i" to <4 x i8>**
  %loadedValue1301.i = load <4 x i8>** %CastToValueType1300.i, align 8
  %404 = load <4 x i8>* %loadedValue1301.i, align 4
  %"&(pSB[currWI].offset)1322.i" = add nuw i64 %CurrSBIndex..1.i, 1080
  %"&pSB[currWI].offset1323.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1322.i"
  %CastToValueType1324.i = bitcast i8* %"&pSB[currWI].offset1323.i" to <4 x i8>**
  %loadedValue1325.i = load <4 x i8>** %CastToValueType1324.i, align 8
  %405 = load <4 x i8>* %loadedValue1325.i, align 4
  %"&(pSB[currWI].offset)1346.i" = add nuw i64 %CurrSBIndex..1.i, 1088
  %"&pSB[currWI].offset1347.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1346.i"
  %CastToValueType1348.i = bitcast i8* %"&pSB[currWI].offset1347.i" to <4 x i8>**
  %loadedValue1349.i = load <4 x i8>** %CastToValueType1348.i, align 8
  %406 = load <4 x i8>* %loadedValue1349.i, align 4
  %"&(pSB[currWI].offset)1370.i" = add nuw i64 %CurrSBIndex..1.i, 1096
  %"&pSB[currWI].offset1371.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1370.i"
  %CastToValueType1372.i = bitcast i8* %"&pSB[currWI].offset1371.i" to <4 x i8>**
  %loadedValue1373.i = load <4 x i8>** %CastToValueType1372.i, align 8
  %407 = load <4 x i8>* %loadedValue1373.i, align 4
  %"&(pSB[currWI].offset)1394.i" = add nuw i64 %CurrSBIndex..1.i, 1104
  %"&pSB[currWI].offset1395.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1394.i"
  %CastToValueType1396.i = bitcast i8* %"&pSB[currWI].offset1395.i" to <4 x i8>**
  %loadedValue1397.i = load <4 x i8>** %CastToValueType1396.i, align 8
  %408 = load <4 x i8>* %loadedValue1397.i, align 4
  %"&(pSB[currWI].offset)1418.i" = add nuw i64 %CurrSBIndex..1.i, 1112
  %"&pSB[currWI].offset1419.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1418.i"
  %CastToValueType1420.i = bitcast i8* %"&pSB[currWI].offset1419.i" to <4 x i8>**
  %loadedValue1421.i = load <4 x i8>** %CastToValueType1420.i, align 8
  %409 = load <4 x i8>* %loadedValue1421.i, align 4
  %"&(pSB[currWI].offset)1442.i" = add nuw i64 %CurrSBIndex..1.i, 1120
  %"&pSB[currWI].offset1443.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1442.i"
  %CastToValueType1444.i = bitcast i8* %"&pSB[currWI].offset1443.i" to <4 x i8>**
  %loadedValue1445.i = load <4 x i8>** %CastToValueType1444.i, align 8
  %410 = load <4 x i8>* %loadedValue1445.i, align 4
  %411 = extractelement <4 x i8> %395, i32 0
  %412 = extractelement <4 x i8> %396, i32 0
  %413 = extractelement <4 x i8> %397, i32 0
  %414 = extractelement <4 x i8> %398, i32 0
  %415 = extractelement <4 x i8> %399, i32 0
  %416 = extractelement <4 x i8> %400, i32 0
  %417 = extractelement <4 x i8> %401, i32 0
  %418 = extractelement <4 x i8> %402, i32 0
  %419 = extractelement <4 x i8> %403, i32 0
  %420 = extractelement <4 x i8> %404, i32 0
  %421 = extractelement <4 x i8> %405, i32 0
  %422 = extractelement <4 x i8> %406, i32 0
  %423 = extractelement <4 x i8> %407, i32 0
  %424 = extractelement <4 x i8> %408, i32 0
  %425 = extractelement <4 x i8> %409, i32 0
  %426 = extractelement <4 x i8> %410, i32 0
  %temp.vect468.i = insertelement <16 x i8> undef, i8 %411, i32 0
  %temp.vect469.i = insertelement <16 x i8> %temp.vect468.i, i8 %412, i32 1
  %temp.vect470.i = insertelement <16 x i8> %temp.vect469.i, i8 %413, i32 2
  %temp.vect471.i = insertelement <16 x i8> %temp.vect470.i, i8 %414, i32 3
  %temp.vect472.i = insertelement <16 x i8> %temp.vect471.i, i8 %415, i32 4
  %temp.vect473.i = insertelement <16 x i8> %temp.vect472.i, i8 %416, i32 5
  %temp.vect474.i = insertelement <16 x i8> %temp.vect473.i, i8 %417, i32 6
  %temp.vect475.i = insertelement <16 x i8> %temp.vect474.i, i8 %418, i32 7
  %temp.vect476.i = insertelement <16 x i8> %temp.vect475.i, i8 %419, i32 8
  %temp.vect477.i = insertelement <16 x i8> %temp.vect476.i, i8 %420, i32 9
  %temp.vect478.i = insertelement <16 x i8> %temp.vect477.i, i8 %421, i32 10
  %temp.vect479.i = insertelement <16 x i8> %temp.vect478.i, i8 %422, i32 11
  %temp.vect480.i = insertelement <16 x i8> %temp.vect479.i, i8 %423, i32 12
  %temp.vect481.i = insertelement <16 x i8> %temp.vect480.i, i8 %424, i32 13
  %temp.vect482.i = insertelement <16 x i8> %temp.vect481.i, i8 %425, i32 14
  %temp.vect483.i = insertelement <16 x i8> %temp.vect482.i, i8 %426, i32 15
  %427 = load <4 x i8> addrspace(3)* %16, align 4
  %scalar37.i = extractelement <4 x i8> %427, i32 0
  %temp486.i = insertelement <16 x i8> undef, i8 %scalar37.i, i32 0
  %vector487.i = shufflevector <16 x i8> %temp486.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %428 = zext i8 %scalar37.i to i32
  %429 = shl i32 %428, 1
  %430 = and i32 %428, 128
  %431 = xor i32 %429, 27
  %432 = icmp eq i32 %430, 0
  %a.1.in.i = select i1 %432, i32 %429, i32 %431
  %433 = shl i32 %a.1.in.i, 1
  %434 = and i32 %a.1.in.i, 128
  %435 = xor i32 %433, 27
  %436 = icmp eq i32 %434, 0
  %a.1.in.1.i = select i1 %436, i32 %433, i32 %435
  %437 = shl i32 %a.1.in.1.i, 1
  %438 = and i32 %a.1.in.1.i, 128
  %439 = xor i32 %437, 27
  %440 = icmp eq i32 %438, 0
  %a.1.in.2.i = select i1 %440, i32 %437, i32 %439
  %441 = shl i32 %a.1.in.2.i, 1
  %442 = and i32 %a.1.in.2.i, 128
  %443 = xor i32 %441, 27
  %444 = icmp eq i32 %442, 0
  %a.1.in.3.i = select i1 %444, i32 %441, i32 %443
  %445 = shl i32 %a.1.in.3.i, 1
  %446 = and i32 %a.1.in.3.i, 128
  %447 = xor i32 %445, 27
  %448 = icmp eq i32 %446, 0
  %a.1.in.4.i = select i1 %448, i32 %445, i32 %447
  %449 = shl i32 %a.1.in.4.i, 1
  %450 = and i32 %a.1.in.4.i, 128
  %451 = xor i32 %449, 27
  %452 = icmp eq i32 %450, 0
  %a.1.in.5.i = select i1 %452, i32 %449, i32 %451
  %453 = shl i32 %a.1.in.5.i, 1
  %454 = lshr <16 x i8> %temp.vect483.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %455 = zext <16 x i8> %454 to <16 x i32>
  %456 = zext <16 x i8> %temp.vect483.i to <16 x i32>
  %457 = lshr <16 x i8> %temp.vect483.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %458 = lshr <16 x i8> %temp.vect483.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %459 = and <16 x i32> %455, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %460 = and <16 x i32> %456, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %461 = zext <16 x i8> %457 to <16 x i32>
  %462 = zext <16 x i8> %458 to <16 x i32>
  %463 = icmp eq <16 x i32> %459, zeroinitializer
  %a.1.i = trunc i32 %a.1.in.i to i8
  %temp484.i = insertelement <16 x i8> undef, i8 %a.1.i, i32 0
  %vector485.i = shufflevector <16 x i8> %temp484.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %464 = icmp eq <16 x i32> %460, zeroinitializer
  %465 = and <16 x i32> %461, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %466 = lshr <16 x i8> %temp.vect483.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %467 = lshr <16 x i8> %temp.vect483.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %468 = and <16 x i32> %462, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %469 = select <16 x i1> %463, <16 x i8> zeroinitializer, <16 x i8> %vector485.i
  %470 = select <16 x i1> %464, <16 x i8> zeroinitializer, <16 x i8> %vector487.i
  %a.1.1.i = trunc i32 %a.1.in.1.i to i8
  %temp489.i = insertelement <16 x i8> undef, i8 %a.1.1.i, i32 0
  %vector490.i = shufflevector <16 x i8> %temp489.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %471 = icmp eq <16 x i32> %465, zeroinitializer
  %472 = zext <16 x i8> %466 to <16 x i32>
  %473 = zext <16 x i8> %467 to <16 x i32>
  %474 = icmp eq <16 x i32> %468, zeroinitializer
  %a.1.2.i = trunc i32 %a.1.in.2.i to i8
  %temp491.i = insertelement <16 x i8> undef, i8 %a.1.2.i, i32 0
  %vector492.i = shufflevector <16 x i8> %temp491.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..1488.i = xor <16 x i8> %469, %470
  %475 = select <16 x i1> %471, <16 x i8> zeroinitializer, <16 x i8> %vector490.i
  %476 = and <16 x i32> %472, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %477 = lshr <16 x i8> %temp.vect483.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %478 = and i32 %a.1.in.5.i, 128
  %479 = and <16 x i32> %473, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %480 = select <16 x i1> %474, <16 x i8> zeroinitializer, <16 x i8> %vector492.i
  %p.1..2493.i = xor <16 x i8> %475, %p.1..1488.i
  %a.1.3.i = trunc i32 %a.1.in.3.i to i8
  %temp495.i = insertelement <16 x i8> undef, i8 %a.1.3.i, i32 0
  %vector496.i = shufflevector <16 x i8> %temp495.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %481 = icmp eq <16 x i32> %476, zeroinitializer
  %482 = zext <16 x i8> %477 to <16 x i32>
  %483 = icmp eq i32 %478, 0
  %484 = xor i32 %453, 27
  %485 = icmp eq <16 x i32> %479, zeroinitializer
  %a.1.4.i = trunc i32 %a.1.in.4.i to i8
  %temp497.i = insertelement <16 x i8> undef, i8 %a.1.4.i, i32 0
  %vector498.i = shufflevector <16 x i8> %temp497.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..3494.i = xor <16 x i8> %480, %p.1..2493.i
  %486 = select <16 x i1> %481, <16 x i8> zeroinitializer, <16 x i8> %vector496.i
  %487 = and <16 x i32> %482, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.1.in.6.i = select i1 %483, i32 %453, i32 %484
  %488 = select <16 x i1> %485, <16 x i8> zeroinitializer, <16 x i8> %vector498.i
  %p.1..4499.i = xor <16 x i8> %486, %p.1..3494.i
  %a.1.5.i = trunc i32 %a.1.in.5.i to i8
  %temp501.i = insertelement <16 x i8> undef, i8 %a.1.5.i, i32 0
  %vector502.i = shufflevector <16 x i8> %temp501.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %489 = icmp eq <16 x i32> %487, zeroinitializer
  %490 = icmp sgt <16 x i8> %temp.vect483.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.1.6.i = trunc i32 %a.1.in.6.i to i8
  %temp503.i = insertelement <16 x i8> undef, i8 %a.1.6.i, i32 0
  %vector504.i = shufflevector <16 x i8> %temp503.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..5500.i = xor <16 x i8> %488, %p.1..4499.i
  %491 = select <16 x i1> %489, <16 x i8> zeroinitializer, <16 x i8> %vector502.i
  %492 = select <16 x i1> %490, <16 x i8> zeroinitializer, <16 x i8> %vector504.i
  %p.1..6505.i = xor <16 x i8> %491, %p.1..5500.i
  %p.1..7506.i = xor <16 x i8> %492, %p.1..6505.i
  %"&(pSB[currWI].offset)1553.i" = add nuw i64 %CurrSBIndex..1.i, 1296
  %"&pSB[currWI].offset1554.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1553.i"
  %CastToValueType1555.i = bitcast i8* %"&pSB[currWI].offset1554.i" to <16 x i8>*
  store <16 x i8> %p.1..7506.i, <16 x i8>* %CastToValueType1555.i, align 16
  %"&(pSB[currWI].offset)1077.i" = add nuw i64 %CurrSBIndex..1.i, 1000
  %"&pSB[currWI].offset1078.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1077.i"
  %CastToValueType1079.i = bitcast i8* %"&pSB[currWI].offset1078.i" to <4 x i8>**
  %loadedValue1080.i = load <4 x i8>** %CastToValueType1079.i, align 8
  %493 = load <4 x i8>* %loadedValue1080.i, align 4
  %"&(pSB[currWI].offset)1101.i" = add nuw i64 %CurrSBIndex..1.i, 1008
  %"&pSB[currWI].offset1102.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1101.i"
  %CastToValueType1103.i = bitcast i8* %"&pSB[currWI].offset1102.i" to <4 x i8>**
  %loadedValue1104.i = load <4 x i8>** %CastToValueType1103.i, align 8
  %494 = load <4 x i8>* %loadedValue1104.i, align 4
  %"&(pSB[currWI].offset)1125.i" = add nuw i64 %CurrSBIndex..1.i, 1016
  %"&pSB[currWI].offset1126.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1125.i"
  %CastToValueType1127.i = bitcast i8* %"&pSB[currWI].offset1126.i" to <4 x i8>**
  %loadedValue1128.i = load <4 x i8>** %CastToValueType1127.i, align 8
  %495 = load <4 x i8>* %loadedValue1128.i, align 4
  %"&(pSB[currWI].offset)1149.i" = add nuw i64 %CurrSBIndex..1.i, 1024
  %"&pSB[currWI].offset1150.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1149.i"
  %CastToValueType1151.i = bitcast i8* %"&pSB[currWI].offset1150.i" to <4 x i8>**
  %loadedValue1152.i = load <4 x i8>** %CastToValueType1151.i, align 8
  %496 = load <4 x i8>* %loadedValue1152.i, align 4
  %"&(pSB[currWI].offset)1173.i" = add nuw i64 %CurrSBIndex..1.i, 1032
  %"&pSB[currWI].offset1174.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1173.i"
  %CastToValueType1175.i = bitcast i8* %"&pSB[currWI].offset1174.i" to <4 x i8>**
  %loadedValue1176.i = load <4 x i8>** %CastToValueType1175.i, align 8
  %497 = load <4 x i8>* %loadedValue1176.i, align 4
  %"&(pSB[currWI].offset)1197.i" = add nuw i64 %CurrSBIndex..1.i, 1040
  %"&pSB[currWI].offset1198.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1197.i"
  %CastToValueType1199.i = bitcast i8* %"&pSB[currWI].offset1198.i" to <4 x i8>**
  %loadedValue1200.i = load <4 x i8>** %CastToValueType1199.i, align 8
  %498 = load <4 x i8>* %loadedValue1200.i, align 4
  %"&(pSB[currWI].offset)1221.i" = add nuw i64 %CurrSBIndex..1.i, 1048
  %"&pSB[currWI].offset1222.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1221.i"
  %CastToValueType1223.i = bitcast i8* %"&pSB[currWI].offset1222.i" to <4 x i8>**
  %loadedValue1224.i = load <4 x i8>** %CastToValueType1223.i, align 8
  %499 = load <4 x i8>* %loadedValue1224.i, align 4
  %"&(pSB[currWI].offset)1245.i" = add nuw i64 %CurrSBIndex..1.i, 1056
  %"&pSB[currWI].offset1246.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1245.i"
  %CastToValueType1247.i = bitcast i8* %"&pSB[currWI].offset1246.i" to <4 x i8>**
  %loadedValue1248.i = load <4 x i8>** %CastToValueType1247.i, align 8
  %500 = load <4 x i8>* %loadedValue1248.i, align 4
  %"&(pSB[currWI].offset)1269.i" = add nuw i64 %CurrSBIndex..1.i, 1064
  %"&pSB[currWI].offset1270.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1269.i"
  %CastToValueType1271.i = bitcast i8* %"&pSB[currWI].offset1270.i" to <4 x i8>**
  %loadedValue1272.i = load <4 x i8>** %CastToValueType1271.i, align 8
  %501 = load <4 x i8>* %loadedValue1272.i, align 4
  %"&(pSB[currWI].offset)1293.i" = add nuw i64 %CurrSBIndex..1.i, 1072
  %"&pSB[currWI].offset1294.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1293.i"
  %CastToValueType1295.i = bitcast i8* %"&pSB[currWI].offset1294.i" to <4 x i8>**
  %loadedValue1296.i = load <4 x i8>** %CastToValueType1295.i, align 8
  %502 = load <4 x i8>* %loadedValue1296.i, align 4
  %"&(pSB[currWI].offset)1317.i" = add nuw i64 %CurrSBIndex..1.i, 1080
  %"&pSB[currWI].offset1318.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1317.i"
  %CastToValueType1319.i = bitcast i8* %"&pSB[currWI].offset1318.i" to <4 x i8>**
  %loadedValue1320.i = load <4 x i8>** %CastToValueType1319.i, align 8
  %503 = load <4 x i8>* %loadedValue1320.i, align 4
  %"&(pSB[currWI].offset)1341.i" = add nuw i64 %CurrSBIndex..1.i, 1088
  %"&pSB[currWI].offset1342.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1341.i"
  %CastToValueType1343.i = bitcast i8* %"&pSB[currWI].offset1342.i" to <4 x i8>**
  %loadedValue1344.i = load <4 x i8>** %CastToValueType1343.i, align 8
  %504 = load <4 x i8>* %loadedValue1344.i, align 4
  %"&(pSB[currWI].offset)1365.i" = add nuw i64 %CurrSBIndex..1.i, 1096
  %"&pSB[currWI].offset1366.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1365.i"
  %CastToValueType1367.i = bitcast i8* %"&pSB[currWI].offset1366.i" to <4 x i8>**
  %loadedValue1368.i = load <4 x i8>** %CastToValueType1367.i, align 8
  %505 = load <4 x i8>* %loadedValue1368.i, align 4
  %"&(pSB[currWI].offset)1389.i" = add nuw i64 %CurrSBIndex..1.i, 1104
  %"&pSB[currWI].offset1390.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1389.i"
  %CastToValueType1391.i = bitcast i8* %"&pSB[currWI].offset1390.i" to <4 x i8>**
  %loadedValue1392.i = load <4 x i8>** %CastToValueType1391.i, align 8
  %506 = load <4 x i8>* %loadedValue1392.i, align 4
  %"&(pSB[currWI].offset)1413.i" = add nuw i64 %CurrSBIndex..1.i, 1112
  %"&pSB[currWI].offset1414.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1413.i"
  %CastToValueType1415.i = bitcast i8* %"&pSB[currWI].offset1414.i" to <4 x i8>**
  %loadedValue1416.i = load <4 x i8>** %CastToValueType1415.i, align 8
  %507 = load <4 x i8>* %loadedValue1416.i, align 4
  %"&(pSB[currWI].offset)1437.i" = add nuw i64 %CurrSBIndex..1.i, 1120
  %"&pSB[currWI].offset1438.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1437.i"
  %CastToValueType1439.i = bitcast i8* %"&pSB[currWI].offset1438.i" to <4 x i8>**
  %loadedValue1440.i = load <4 x i8>** %CastToValueType1439.i, align 8
  %508 = load <4 x i8>* %loadedValue1440.i, align 4
  %509 = extractelement <4 x i8> %493, i32 0
  %510 = extractelement <4 x i8> %494, i32 0
  %511 = extractelement <4 x i8> %495, i32 0
  %512 = extractelement <4 x i8> %496, i32 0
  %513 = extractelement <4 x i8> %497, i32 0
  %514 = extractelement <4 x i8> %498, i32 0
  %515 = extractelement <4 x i8> %499, i32 0
  %516 = extractelement <4 x i8> %500, i32 0
  %517 = extractelement <4 x i8> %501, i32 0
  %518 = extractelement <4 x i8> %502, i32 0
  %519 = extractelement <4 x i8> %503, i32 0
  %520 = extractelement <4 x i8> %504, i32 0
  %521 = extractelement <4 x i8> %505, i32 0
  %522 = extractelement <4 x i8> %506, i32 0
  %523 = extractelement <4 x i8> %507, i32 0
  %524 = extractelement <4 x i8> %508, i32 0
  %temp.vect507.i = insertelement <16 x i8> undef, i8 %509, i32 0
  %temp.vect508.i = insertelement <16 x i8> %temp.vect507.i, i8 %510, i32 1
  %temp.vect509.i = insertelement <16 x i8> %temp.vect508.i, i8 %511, i32 2
  %temp.vect510.i = insertelement <16 x i8> %temp.vect509.i, i8 %512, i32 3
  %temp.vect511.i = insertelement <16 x i8> %temp.vect510.i, i8 %513, i32 4
  %temp.vect512.i = insertelement <16 x i8> %temp.vect511.i, i8 %514, i32 5
  %temp.vect513.i = insertelement <16 x i8> %temp.vect512.i, i8 %515, i32 6
  %temp.vect514.i = insertelement <16 x i8> %temp.vect513.i, i8 %516, i32 7
  %temp.vect515.i = insertelement <16 x i8> %temp.vect514.i, i8 %517, i32 8
  %temp.vect516.i = insertelement <16 x i8> %temp.vect515.i, i8 %518, i32 9
  %temp.vect517.i = insertelement <16 x i8> %temp.vect516.i, i8 %519, i32 10
  %temp.vect518.i = insertelement <16 x i8> %temp.vect517.i, i8 %520, i32 11
  %temp.vect519.i = insertelement <16 x i8> %temp.vect518.i, i8 %521, i32 12
  %temp.vect520.i = insertelement <16 x i8> %temp.vect519.i, i8 %522, i32 13
  %temp.vect521.i = insertelement <16 x i8> %temp.vect520.i, i8 %523, i32 14
  %temp.vect522.i = insertelement <16 x i8> %temp.vect521.i, i8 %524, i32 15
  %525 = load <4 x i8> addrspace(3)* %16, align 4
  %scalar46.i = extractelement <4 x i8> %525, i32 1
  %temp525.i = insertelement <16 x i8> undef, i8 %scalar46.i, i32 0
  %vector526.i = shufflevector <16 x i8> %temp525.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %526 = zext i8 %scalar46.i to i32
  %527 = shl i32 %526, 1
  %528 = and i32 %526, 128
  %529 = xor i32 %527, 27
  %530 = icmp eq i32 %528, 0
  %a.3.in.i = select i1 %530, i32 %527, i32 %529
  %531 = shl i32 %a.3.in.i, 1
  %532 = and i32 %a.3.in.i, 128
  %533 = xor i32 %531, 27
  %534 = icmp eq i32 %532, 0
  %a.3.in.1.i = select i1 %534, i32 %531, i32 %533
  %535 = shl i32 %a.3.in.1.i, 1
  %536 = and i32 %a.3.in.1.i, 128
  %537 = xor i32 %535, 27
  %538 = icmp eq i32 %536, 0
  %a.3.in.2.i = select i1 %538, i32 %535, i32 %537
  %539 = shl i32 %a.3.in.2.i, 1
  %540 = and i32 %a.3.in.2.i, 128
  %541 = xor i32 %539, 27
  %542 = icmp eq i32 %540, 0
  %a.3.in.3.i = select i1 %542, i32 %539, i32 %541
  %543 = shl i32 %a.3.in.3.i, 1
  %544 = and i32 %a.3.in.3.i, 128
  %545 = xor i32 %543, 27
  %546 = icmp eq i32 %544, 0
  %a.3.in.4.i = select i1 %546, i32 %543, i32 %545
  %547 = shl i32 %a.3.in.4.i, 1
  %548 = and i32 %a.3.in.4.i, 128
  %549 = xor i32 %547, 27
  %550 = icmp eq i32 %548, 0
  %a.3.in.5.i = select i1 %550, i32 %547, i32 %549
  %551 = shl i32 %a.3.in.5.i, 1
  %552 = lshr <16 x i8> %temp.vect522.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %553 = zext <16 x i8> %552 to <16 x i32>
  %554 = zext <16 x i8> %temp.vect522.i to <16 x i32>
  %555 = lshr <16 x i8> %temp.vect522.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %556 = lshr <16 x i8> %temp.vect522.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %557 = and <16 x i32> %553, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %558 = and <16 x i32> %554, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %559 = zext <16 x i8> %555 to <16 x i32>
  %560 = zext <16 x i8> %556 to <16 x i32>
  %561 = icmp eq <16 x i32> %557, zeroinitializer
  %a.3.i = trunc i32 %a.3.in.i to i8
  %temp523.i = insertelement <16 x i8> undef, i8 %a.3.i, i32 0
  %vector524.i = shufflevector <16 x i8> %temp523.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %562 = icmp eq <16 x i32> %558, zeroinitializer
  %563 = and <16 x i32> %559, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %564 = lshr <16 x i8> %temp.vect522.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %565 = lshr <16 x i8> %temp.vect522.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %566 = and <16 x i32> %560, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %567 = select <16 x i1> %561, <16 x i8> zeroinitializer, <16 x i8> %vector524.i
  %568 = select <16 x i1> %562, <16 x i8> zeroinitializer, <16 x i8> %vector526.i
  %a.3.1.i = trunc i32 %a.3.in.1.i to i8
  %temp528.i = insertelement <16 x i8> undef, i8 %a.3.1.i, i32 0
  %vector529.i = shufflevector <16 x i8> %temp528.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %569 = icmp eq <16 x i32> %563, zeroinitializer
  %570 = zext <16 x i8> %564 to <16 x i32>
  %571 = zext <16 x i8> %565 to <16 x i32>
  %572 = icmp eq <16 x i32> %566, zeroinitializer
  %a.3.2.i = trunc i32 %a.3.in.2.i to i8
  %temp530.i = insertelement <16 x i8> undef, i8 %a.3.2.i, i32 0
  %vector531.i = shufflevector <16 x i8> %temp530.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..1527.i = xor <16 x i8> %567, %568
  %573 = select <16 x i1> %569, <16 x i8> zeroinitializer, <16 x i8> %vector529.i
  %574 = and <16 x i32> %570, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %575 = lshr <16 x i8> %temp.vect522.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %576 = and i32 %a.3.in.5.i, 128
  %577 = and <16 x i32> %571, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %578 = select <16 x i1> %572, <16 x i8> zeroinitializer, <16 x i8> %vector531.i
  %p.3..2532.i = xor <16 x i8> %573, %p.3..1527.i
  %a.3.3.i = trunc i32 %a.3.in.3.i to i8
  %temp534.i = insertelement <16 x i8> undef, i8 %a.3.3.i, i32 0
  %vector535.i = shufflevector <16 x i8> %temp534.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %579 = icmp eq <16 x i32> %574, zeroinitializer
  %580 = zext <16 x i8> %575 to <16 x i32>
  %581 = icmp eq i32 %576, 0
  %582 = xor i32 %551, 27
  %583 = icmp eq <16 x i32> %577, zeroinitializer
  %a.3.4.i = trunc i32 %a.3.in.4.i to i8
  %temp536.i = insertelement <16 x i8> undef, i8 %a.3.4.i, i32 0
  %vector537.i = shufflevector <16 x i8> %temp536.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..3533.i = xor <16 x i8> %578, %p.3..2532.i
  %584 = select <16 x i1> %579, <16 x i8> zeroinitializer, <16 x i8> %vector535.i
  %585 = and <16 x i32> %580, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.3.in.6.i = select i1 %581, i32 %551, i32 %582
  %586 = select <16 x i1> %583, <16 x i8> zeroinitializer, <16 x i8> %vector537.i
  %p.3..4538.i = xor <16 x i8> %584, %p.3..3533.i
  %a.3.5.i = trunc i32 %a.3.in.5.i to i8
  %temp540.i = insertelement <16 x i8> undef, i8 %a.3.5.i, i32 0
  %vector541.i = shufflevector <16 x i8> %temp540.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %587 = icmp eq <16 x i32> %585, zeroinitializer
  %588 = icmp sgt <16 x i8> %temp.vect522.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.3.6.i = trunc i32 %a.3.in.6.i to i8
  %temp542.i = insertelement <16 x i8> undef, i8 %a.3.6.i, i32 0
  %vector543.i = shufflevector <16 x i8> %temp542.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..5539.i = xor <16 x i8> %586, %p.3..4538.i
  %589 = select <16 x i1> %587, <16 x i8> zeroinitializer, <16 x i8> %vector541.i
  %590 = select <16 x i1> %588, <16 x i8> zeroinitializer, <16 x i8> %vector543.i
  %p.3..6544.i = xor <16 x i8> %589, %p.3..5539.i
  %p.3..7545.i = xor <16 x i8> %590, %p.3..6544.i
  %"&(pSB[currWI].offset)1557.i" = add nuw i64 %CurrSBIndex..1.i, 1312
  %"&pSB[currWI].offset1558.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1557.i"
  %CastToValueType1559.i = bitcast i8* %"&pSB[currWI].offset1558.i" to <16 x i8>*
  store <16 x i8> %p.3..7545.i, <16 x i8>* %CastToValueType1559.i, align 16
  %"&(pSB[currWI].offset)1072.i" = add nuw i64 %CurrSBIndex..1.i, 1000
  %"&pSB[currWI].offset1073.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1072.i"
  %CastToValueType1074.i = bitcast i8* %"&pSB[currWI].offset1073.i" to <4 x i8>**
  %loadedValue1075.i = load <4 x i8>** %CastToValueType1074.i, align 8
  %591 = load <4 x i8>* %loadedValue1075.i, align 4
  %"&(pSB[currWI].offset)1096.i" = add nuw i64 %CurrSBIndex..1.i, 1008
  %"&pSB[currWI].offset1097.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1096.i"
  %CastToValueType1098.i = bitcast i8* %"&pSB[currWI].offset1097.i" to <4 x i8>**
  %loadedValue1099.i = load <4 x i8>** %CastToValueType1098.i, align 8
  %592 = load <4 x i8>* %loadedValue1099.i, align 4
  %"&(pSB[currWI].offset)1120.i" = add nuw i64 %CurrSBIndex..1.i, 1016
  %"&pSB[currWI].offset1121.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1120.i"
  %CastToValueType1122.i = bitcast i8* %"&pSB[currWI].offset1121.i" to <4 x i8>**
  %loadedValue1123.i = load <4 x i8>** %CastToValueType1122.i, align 8
  %593 = load <4 x i8>* %loadedValue1123.i, align 4
  %"&(pSB[currWI].offset)1144.i" = add nuw i64 %CurrSBIndex..1.i, 1024
  %"&pSB[currWI].offset1145.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1144.i"
  %CastToValueType1146.i = bitcast i8* %"&pSB[currWI].offset1145.i" to <4 x i8>**
  %loadedValue1147.i = load <4 x i8>** %CastToValueType1146.i, align 8
  %594 = load <4 x i8>* %loadedValue1147.i, align 4
  %"&(pSB[currWI].offset)1168.i" = add nuw i64 %CurrSBIndex..1.i, 1032
  %"&pSB[currWI].offset1169.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1168.i"
  %CastToValueType1170.i = bitcast i8* %"&pSB[currWI].offset1169.i" to <4 x i8>**
  %loadedValue1171.i = load <4 x i8>** %CastToValueType1170.i, align 8
  %595 = load <4 x i8>* %loadedValue1171.i, align 4
  %"&(pSB[currWI].offset)1192.i" = add nuw i64 %CurrSBIndex..1.i, 1040
  %"&pSB[currWI].offset1193.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1192.i"
  %CastToValueType1194.i = bitcast i8* %"&pSB[currWI].offset1193.i" to <4 x i8>**
  %loadedValue1195.i = load <4 x i8>** %CastToValueType1194.i, align 8
  %596 = load <4 x i8>* %loadedValue1195.i, align 4
  %"&(pSB[currWI].offset)1216.i" = add nuw i64 %CurrSBIndex..1.i, 1048
  %"&pSB[currWI].offset1217.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1216.i"
  %CastToValueType1218.i = bitcast i8* %"&pSB[currWI].offset1217.i" to <4 x i8>**
  %loadedValue1219.i = load <4 x i8>** %CastToValueType1218.i, align 8
  %597 = load <4 x i8>* %loadedValue1219.i, align 4
  %"&(pSB[currWI].offset)1240.i" = add nuw i64 %CurrSBIndex..1.i, 1056
  %"&pSB[currWI].offset1241.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1240.i"
  %CastToValueType1242.i = bitcast i8* %"&pSB[currWI].offset1241.i" to <4 x i8>**
  %loadedValue1243.i = load <4 x i8>** %CastToValueType1242.i, align 8
  %598 = load <4 x i8>* %loadedValue1243.i, align 4
  %"&(pSB[currWI].offset)1264.i" = add nuw i64 %CurrSBIndex..1.i, 1064
  %"&pSB[currWI].offset1265.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1264.i"
  %CastToValueType1266.i = bitcast i8* %"&pSB[currWI].offset1265.i" to <4 x i8>**
  %loadedValue1267.i = load <4 x i8>** %CastToValueType1266.i, align 8
  %599 = load <4 x i8>* %loadedValue1267.i, align 4
  %"&(pSB[currWI].offset)1288.i" = add nuw i64 %CurrSBIndex..1.i, 1072
  %"&pSB[currWI].offset1289.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1288.i"
  %CastToValueType1290.i = bitcast i8* %"&pSB[currWI].offset1289.i" to <4 x i8>**
  %loadedValue1291.i = load <4 x i8>** %CastToValueType1290.i, align 8
  %600 = load <4 x i8>* %loadedValue1291.i, align 4
  %"&(pSB[currWI].offset)1312.i" = add nuw i64 %CurrSBIndex..1.i, 1080
  %"&pSB[currWI].offset1313.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1312.i"
  %CastToValueType1314.i = bitcast i8* %"&pSB[currWI].offset1313.i" to <4 x i8>**
  %loadedValue1315.i = load <4 x i8>** %CastToValueType1314.i, align 8
  %601 = load <4 x i8>* %loadedValue1315.i, align 4
  %"&(pSB[currWI].offset)1336.i" = add nuw i64 %CurrSBIndex..1.i, 1088
  %"&pSB[currWI].offset1337.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1336.i"
  %CastToValueType1338.i = bitcast i8* %"&pSB[currWI].offset1337.i" to <4 x i8>**
  %loadedValue1339.i = load <4 x i8>** %CastToValueType1338.i, align 8
  %602 = load <4 x i8>* %loadedValue1339.i, align 4
  %"&(pSB[currWI].offset)1360.i" = add nuw i64 %CurrSBIndex..1.i, 1096
  %"&pSB[currWI].offset1361.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1360.i"
  %CastToValueType1362.i = bitcast i8* %"&pSB[currWI].offset1361.i" to <4 x i8>**
  %loadedValue1363.i = load <4 x i8>** %CastToValueType1362.i, align 8
  %603 = load <4 x i8>* %loadedValue1363.i, align 4
  %"&(pSB[currWI].offset)1384.i" = add nuw i64 %CurrSBIndex..1.i, 1104
  %"&pSB[currWI].offset1385.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1384.i"
  %CastToValueType1386.i = bitcast i8* %"&pSB[currWI].offset1385.i" to <4 x i8>**
  %loadedValue1387.i = load <4 x i8>** %CastToValueType1386.i, align 8
  %604 = load <4 x i8>* %loadedValue1387.i, align 4
  %"&(pSB[currWI].offset)1408.i" = add nuw i64 %CurrSBIndex..1.i, 1112
  %"&pSB[currWI].offset1409.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1408.i"
  %CastToValueType1410.i = bitcast i8* %"&pSB[currWI].offset1409.i" to <4 x i8>**
  %loadedValue1411.i = load <4 x i8>** %CastToValueType1410.i, align 8
  %605 = load <4 x i8>* %loadedValue1411.i, align 4
  %"&(pSB[currWI].offset)1432.i" = add nuw i64 %CurrSBIndex..1.i, 1120
  %"&pSB[currWI].offset1433.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1432.i"
  %CastToValueType1434.i = bitcast i8* %"&pSB[currWI].offset1433.i" to <4 x i8>**
  %loadedValue1435.i = load <4 x i8>** %CastToValueType1434.i, align 8
  %606 = load <4 x i8>* %loadedValue1435.i, align 4
  %607 = extractelement <4 x i8> %591, i32 0
  %608 = extractelement <4 x i8> %592, i32 0
  %609 = extractelement <4 x i8> %593, i32 0
  %610 = extractelement <4 x i8> %594, i32 0
  %611 = extractelement <4 x i8> %595, i32 0
  %612 = extractelement <4 x i8> %596, i32 0
  %613 = extractelement <4 x i8> %597, i32 0
  %614 = extractelement <4 x i8> %598, i32 0
  %615 = extractelement <4 x i8> %599, i32 0
  %616 = extractelement <4 x i8> %600, i32 0
  %617 = extractelement <4 x i8> %601, i32 0
  %618 = extractelement <4 x i8> %602, i32 0
  %619 = extractelement <4 x i8> %603, i32 0
  %620 = extractelement <4 x i8> %604, i32 0
  %621 = extractelement <4 x i8> %605, i32 0
  %622 = extractelement <4 x i8> %606, i32 0
  %temp.vect546.i = insertelement <16 x i8> undef, i8 %607, i32 0
  %temp.vect547.i = insertelement <16 x i8> %temp.vect546.i, i8 %608, i32 1
  %temp.vect548.i = insertelement <16 x i8> %temp.vect547.i, i8 %609, i32 2
  %temp.vect549.i = insertelement <16 x i8> %temp.vect548.i, i8 %610, i32 3
  %temp.vect550.i = insertelement <16 x i8> %temp.vect549.i, i8 %611, i32 4
  %temp.vect551.i = insertelement <16 x i8> %temp.vect550.i, i8 %612, i32 5
  %temp.vect552.i = insertelement <16 x i8> %temp.vect551.i, i8 %613, i32 6
  %temp.vect553.i = insertelement <16 x i8> %temp.vect552.i, i8 %614, i32 7
  %temp.vect554.i = insertelement <16 x i8> %temp.vect553.i, i8 %615, i32 8
  %temp.vect555.i = insertelement <16 x i8> %temp.vect554.i, i8 %616, i32 9
  %temp.vect556.i = insertelement <16 x i8> %temp.vect555.i, i8 %617, i32 10
  %temp.vect557.i = insertelement <16 x i8> %temp.vect556.i, i8 %618, i32 11
  %temp.vect558.i = insertelement <16 x i8> %temp.vect557.i, i8 %619, i32 12
  %temp.vect559.i = insertelement <16 x i8> %temp.vect558.i, i8 %620, i32 13
  %temp.vect560.i = insertelement <16 x i8> %temp.vect559.i, i8 %621, i32 14
  %temp.vect561.i = insertelement <16 x i8> %temp.vect560.i, i8 %622, i32 15
  %623 = load <4 x i8> addrspace(3)* %16, align 4
  %scalar55.i = extractelement <4 x i8> %623, i32 2
  %temp564.i = insertelement <16 x i8> undef, i8 %scalar55.i, i32 0
  %vector565.i = shufflevector <16 x i8> %temp564.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %624 = zext i8 %scalar55.i to i32
  %625 = shl i32 %624, 1
  %626 = and i32 %624, 128
  %627 = xor i32 %625, 27
  %628 = icmp eq i32 %626, 0
  %a.5.in.i = select i1 %628, i32 %625, i32 %627
  %629 = shl i32 %a.5.in.i, 1
  %630 = and i32 %a.5.in.i, 128
  %631 = xor i32 %629, 27
  %632 = icmp eq i32 %630, 0
  %a.5.in.1.i = select i1 %632, i32 %629, i32 %631
  %633 = shl i32 %a.5.in.1.i, 1
  %634 = and i32 %a.5.in.1.i, 128
  %635 = xor i32 %633, 27
  %636 = icmp eq i32 %634, 0
  %a.5.in.2.i = select i1 %636, i32 %633, i32 %635
  %637 = shl i32 %a.5.in.2.i, 1
  %638 = and i32 %a.5.in.2.i, 128
  %639 = xor i32 %637, 27
  %640 = icmp eq i32 %638, 0
  %a.5.in.3.i = select i1 %640, i32 %637, i32 %639
  %641 = shl i32 %a.5.in.3.i, 1
  %642 = and i32 %a.5.in.3.i, 128
  %643 = xor i32 %641, 27
  %644 = icmp eq i32 %642, 0
  %a.5.in.4.i = select i1 %644, i32 %641, i32 %643
  %645 = shl i32 %a.5.in.4.i, 1
  %646 = and i32 %a.5.in.4.i, 128
  %647 = xor i32 %645, 27
  %648 = icmp eq i32 %646, 0
  %a.5.in.5.i = select i1 %648, i32 %645, i32 %647
  %649 = shl i32 %a.5.in.5.i, 1
  %650 = lshr <16 x i8> %temp.vect561.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %651 = zext <16 x i8> %650 to <16 x i32>
  %652 = zext <16 x i8> %temp.vect561.i to <16 x i32>
  %653 = lshr <16 x i8> %temp.vect561.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %654 = lshr <16 x i8> %temp.vect561.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %655 = and <16 x i32> %651, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %656 = and <16 x i32> %652, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %657 = zext <16 x i8> %653 to <16 x i32>
  %658 = zext <16 x i8> %654 to <16 x i32>
  %659 = icmp eq <16 x i32> %655, zeroinitializer
  %a.5.i = trunc i32 %a.5.in.i to i8
  %temp562.i = insertelement <16 x i8> undef, i8 %a.5.i, i32 0
  %vector563.i = shufflevector <16 x i8> %temp562.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %660 = icmp eq <16 x i32> %656, zeroinitializer
  %661 = and <16 x i32> %657, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %662 = lshr <16 x i8> %temp.vect561.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %663 = lshr <16 x i8> %temp.vect561.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %664 = and <16 x i32> %658, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %665 = select <16 x i1> %659, <16 x i8> zeroinitializer, <16 x i8> %vector563.i
  %666 = select <16 x i1> %660, <16 x i8> zeroinitializer, <16 x i8> %vector565.i
  %a.5.1.i = trunc i32 %a.5.in.1.i to i8
  %temp567.i = insertelement <16 x i8> undef, i8 %a.5.1.i, i32 0
  %vector568.i = shufflevector <16 x i8> %temp567.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %667 = icmp eq <16 x i32> %661, zeroinitializer
  %668 = zext <16 x i8> %662 to <16 x i32>
  %669 = zext <16 x i8> %663 to <16 x i32>
  %670 = icmp eq <16 x i32> %664, zeroinitializer
  %a.5.2.i = trunc i32 %a.5.in.2.i to i8
  %temp569.i = insertelement <16 x i8> undef, i8 %a.5.2.i, i32 0
  %vector570.i = shufflevector <16 x i8> %temp569.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..1566.i = xor <16 x i8> %665, %666
  %671 = select <16 x i1> %667, <16 x i8> zeroinitializer, <16 x i8> %vector568.i
  %672 = and <16 x i32> %668, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %673 = lshr <16 x i8> %temp.vect561.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %674 = and i32 %a.5.in.5.i, 128
  %675 = and <16 x i32> %669, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %676 = select <16 x i1> %670, <16 x i8> zeroinitializer, <16 x i8> %vector570.i
  %p.5..2571.i = xor <16 x i8> %671, %p.5..1566.i
  %a.5.3.i = trunc i32 %a.5.in.3.i to i8
  %temp573.i = insertelement <16 x i8> undef, i8 %a.5.3.i, i32 0
  %vector574.i = shufflevector <16 x i8> %temp573.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %677 = icmp eq <16 x i32> %672, zeroinitializer
  %678 = zext <16 x i8> %673 to <16 x i32>
  %679 = icmp eq i32 %674, 0
  %680 = xor i32 %649, 27
  %681 = icmp eq <16 x i32> %675, zeroinitializer
  %a.5.4.i = trunc i32 %a.5.in.4.i to i8
  %temp575.i = insertelement <16 x i8> undef, i8 %a.5.4.i, i32 0
  %vector576.i = shufflevector <16 x i8> %temp575.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..3572.i = xor <16 x i8> %676, %p.5..2571.i
  %682 = select <16 x i1> %677, <16 x i8> zeroinitializer, <16 x i8> %vector574.i
  %683 = and <16 x i32> %678, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.5.in.6.i = select i1 %679, i32 %649, i32 %680
  %684 = select <16 x i1> %681, <16 x i8> zeroinitializer, <16 x i8> %vector576.i
  %p.5..4577.i = xor <16 x i8> %682, %p.5..3572.i
  %a.5.5.i = trunc i32 %a.5.in.5.i to i8
  %temp579.i = insertelement <16 x i8> undef, i8 %a.5.5.i, i32 0
  %vector580.i = shufflevector <16 x i8> %temp579.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %685 = icmp eq <16 x i32> %683, zeroinitializer
  %686 = icmp sgt <16 x i8> %temp.vect561.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.5.6.i = trunc i32 %a.5.in.6.i to i8
  %temp581.i = insertelement <16 x i8> undef, i8 %a.5.6.i, i32 0
  %vector582.i = shufflevector <16 x i8> %temp581.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..5578.i = xor <16 x i8> %684, %p.5..4577.i
  %687 = select <16 x i1> %685, <16 x i8> zeroinitializer, <16 x i8> %vector580.i
  %688 = select <16 x i1> %686, <16 x i8> zeroinitializer, <16 x i8> %vector582.i
  %p.5..6583.i = xor <16 x i8> %687, %p.5..5578.i
  %p.5..7584.i = xor <16 x i8> %688, %p.5..6583.i
  %"&(pSB[currWI].offset)1561.i" = add nuw i64 %CurrSBIndex..1.i, 1328
  %"&pSB[currWI].offset1562.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1561.i"
  %CastToValueType1563.i = bitcast i8* %"&pSB[currWI].offset1562.i" to <16 x i8>*
  store <16 x i8> %p.5..7584.i, <16 x i8>* %CastToValueType1563.i, align 16
  %"&(pSB[currWI].offset)1067.i" = add nuw i64 %CurrSBIndex..1.i, 1000
  %"&pSB[currWI].offset1068.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1067.i"
  %CastToValueType1069.i = bitcast i8* %"&pSB[currWI].offset1068.i" to <4 x i8>**
  %loadedValue1070.i = load <4 x i8>** %CastToValueType1069.i, align 8
  %689 = load <4 x i8>* %loadedValue1070.i, align 4
  %"&(pSB[currWI].offset)1091.i" = add nuw i64 %CurrSBIndex..1.i, 1008
  %"&pSB[currWI].offset1092.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1091.i"
  %CastToValueType1093.i = bitcast i8* %"&pSB[currWI].offset1092.i" to <4 x i8>**
  %loadedValue1094.i = load <4 x i8>** %CastToValueType1093.i, align 8
  %690 = load <4 x i8>* %loadedValue1094.i, align 4
  %"&(pSB[currWI].offset)1115.i" = add nuw i64 %CurrSBIndex..1.i, 1016
  %"&pSB[currWI].offset1116.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1115.i"
  %CastToValueType1117.i = bitcast i8* %"&pSB[currWI].offset1116.i" to <4 x i8>**
  %loadedValue1118.i = load <4 x i8>** %CastToValueType1117.i, align 8
  %691 = load <4 x i8>* %loadedValue1118.i, align 4
  %"&(pSB[currWI].offset)1139.i" = add nuw i64 %CurrSBIndex..1.i, 1024
  %"&pSB[currWI].offset1140.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1139.i"
  %CastToValueType1141.i = bitcast i8* %"&pSB[currWI].offset1140.i" to <4 x i8>**
  %loadedValue1142.i = load <4 x i8>** %CastToValueType1141.i, align 8
  %692 = load <4 x i8>* %loadedValue1142.i, align 4
  %"&(pSB[currWI].offset)1163.i" = add nuw i64 %CurrSBIndex..1.i, 1032
  %"&pSB[currWI].offset1164.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1163.i"
  %CastToValueType1165.i = bitcast i8* %"&pSB[currWI].offset1164.i" to <4 x i8>**
  %loadedValue1166.i = load <4 x i8>** %CastToValueType1165.i, align 8
  %693 = load <4 x i8>* %loadedValue1166.i, align 4
  %"&(pSB[currWI].offset)1187.i" = add nuw i64 %CurrSBIndex..1.i, 1040
  %"&pSB[currWI].offset1188.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1187.i"
  %CastToValueType1189.i = bitcast i8* %"&pSB[currWI].offset1188.i" to <4 x i8>**
  %loadedValue1190.i = load <4 x i8>** %CastToValueType1189.i, align 8
  %694 = load <4 x i8>* %loadedValue1190.i, align 4
  %"&(pSB[currWI].offset)1211.i" = add nuw i64 %CurrSBIndex..1.i, 1048
  %"&pSB[currWI].offset1212.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1211.i"
  %CastToValueType1213.i = bitcast i8* %"&pSB[currWI].offset1212.i" to <4 x i8>**
  %loadedValue1214.i = load <4 x i8>** %CastToValueType1213.i, align 8
  %695 = load <4 x i8>* %loadedValue1214.i, align 4
  %"&(pSB[currWI].offset)1235.i" = add nuw i64 %CurrSBIndex..1.i, 1056
  %"&pSB[currWI].offset1236.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1235.i"
  %CastToValueType1237.i = bitcast i8* %"&pSB[currWI].offset1236.i" to <4 x i8>**
  %loadedValue1238.i = load <4 x i8>** %CastToValueType1237.i, align 8
  %696 = load <4 x i8>* %loadedValue1238.i, align 4
  %"&(pSB[currWI].offset)1259.i" = add nuw i64 %CurrSBIndex..1.i, 1064
  %"&pSB[currWI].offset1260.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1259.i"
  %CastToValueType1261.i = bitcast i8* %"&pSB[currWI].offset1260.i" to <4 x i8>**
  %loadedValue1262.i = load <4 x i8>** %CastToValueType1261.i, align 8
  %697 = load <4 x i8>* %loadedValue1262.i, align 4
  %"&(pSB[currWI].offset)1283.i" = add nuw i64 %CurrSBIndex..1.i, 1072
  %"&pSB[currWI].offset1284.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1283.i"
  %CastToValueType1285.i = bitcast i8* %"&pSB[currWI].offset1284.i" to <4 x i8>**
  %loadedValue1286.i = load <4 x i8>** %CastToValueType1285.i, align 8
  %698 = load <4 x i8>* %loadedValue1286.i, align 4
  %"&(pSB[currWI].offset)1307.i" = add nuw i64 %CurrSBIndex..1.i, 1080
  %"&pSB[currWI].offset1308.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1307.i"
  %CastToValueType1309.i = bitcast i8* %"&pSB[currWI].offset1308.i" to <4 x i8>**
  %loadedValue1310.i = load <4 x i8>** %CastToValueType1309.i, align 8
  %699 = load <4 x i8>* %loadedValue1310.i, align 4
  %"&(pSB[currWI].offset)1331.i" = add nuw i64 %CurrSBIndex..1.i, 1088
  %"&pSB[currWI].offset1332.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1331.i"
  %CastToValueType1333.i = bitcast i8* %"&pSB[currWI].offset1332.i" to <4 x i8>**
  %loadedValue1334.i = load <4 x i8>** %CastToValueType1333.i, align 8
  %700 = load <4 x i8>* %loadedValue1334.i, align 4
  %"&(pSB[currWI].offset)1355.i" = add nuw i64 %CurrSBIndex..1.i, 1096
  %"&pSB[currWI].offset1356.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1355.i"
  %CastToValueType1357.i = bitcast i8* %"&pSB[currWI].offset1356.i" to <4 x i8>**
  %loadedValue1358.i = load <4 x i8>** %CastToValueType1357.i, align 8
  %701 = load <4 x i8>* %loadedValue1358.i, align 4
  %"&(pSB[currWI].offset)1379.i" = add nuw i64 %CurrSBIndex..1.i, 1104
  %"&pSB[currWI].offset1380.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1379.i"
  %CastToValueType1381.i = bitcast i8* %"&pSB[currWI].offset1380.i" to <4 x i8>**
  %loadedValue1382.i = load <4 x i8>** %CastToValueType1381.i, align 8
  %702 = load <4 x i8>* %loadedValue1382.i, align 4
  %"&(pSB[currWI].offset)1403.i" = add nuw i64 %CurrSBIndex..1.i, 1112
  %"&pSB[currWI].offset1404.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1403.i"
  %CastToValueType1405.i = bitcast i8* %"&pSB[currWI].offset1404.i" to <4 x i8>**
  %loadedValue1406.i = load <4 x i8>** %CastToValueType1405.i, align 8
  %703 = load <4 x i8>* %loadedValue1406.i, align 4
  %"&(pSB[currWI].offset)1427.i" = add nuw i64 %CurrSBIndex..1.i, 1120
  %"&pSB[currWI].offset1428.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1427.i"
  %CastToValueType1429.i = bitcast i8* %"&pSB[currWI].offset1428.i" to <4 x i8>**
  %loadedValue1430.i = load <4 x i8>** %CastToValueType1429.i, align 8
  %704 = load <4 x i8>* %loadedValue1430.i, align 4
  %705 = extractelement <4 x i8> %689, i32 0
  %706 = extractelement <4 x i8> %690, i32 0
  %707 = extractelement <4 x i8> %691, i32 0
  %708 = extractelement <4 x i8> %692, i32 0
  %709 = extractelement <4 x i8> %693, i32 0
  %710 = extractelement <4 x i8> %694, i32 0
  %711 = extractelement <4 x i8> %695, i32 0
  %712 = extractelement <4 x i8> %696, i32 0
  %713 = extractelement <4 x i8> %697, i32 0
  %714 = extractelement <4 x i8> %698, i32 0
  %715 = extractelement <4 x i8> %699, i32 0
  %716 = extractelement <4 x i8> %700, i32 0
  %717 = extractelement <4 x i8> %701, i32 0
  %718 = extractelement <4 x i8> %702, i32 0
  %719 = extractelement <4 x i8> %703, i32 0
  %720 = extractelement <4 x i8> %704, i32 0
  %temp.vect585.i = insertelement <16 x i8> undef, i8 %705, i32 0
  %temp.vect586.i = insertelement <16 x i8> %temp.vect585.i, i8 %706, i32 1
  %temp.vect587.i = insertelement <16 x i8> %temp.vect586.i, i8 %707, i32 2
  %temp.vect588.i = insertelement <16 x i8> %temp.vect587.i, i8 %708, i32 3
  %temp.vect589.i = insertelement <16 x i8> %temp.vect588.i, i8 %709, i32 4
  %temp.vect590.i = insertelement <16 x i8> %temp.vect589.i, i8 %710, i32 5
  %temp.vect591.i = insertelement <16 x i8> %temp.vect590.i, i8 %711, i32 6
  %temp.vect592.i = insertelement <16 x i8> %temp.vect591.i, i8 %712, i32 7
  %temp.vect593.i = insertelement <16 x i8> %temp.vect592.i, i8 %713, i32 8
  %temp.vect594.i = insertelement <16 x i8> %temp.vect593.i, i8 %714, i32 9
  %temp.vect595.i = insertelement <16 x i8> %temp.vect594.i, i8 %715, i32 10
  %temp.vect596.i = insertelement <16 x i8> %temp.vect595.i, i8 %716, i32 11
  %temp.vect597.i = insertelement <16 x i8> %temp.vect596.i, i8 %717, i32 12
  %temp.vect598.i = insertelement <16 x i8> %temp.vect597.i, i8 %718, i32 13
  %temp.vect599.i = insertelement <16 x i8> %temp.vect598.i, i8 %719, i32 14
  %temp.vect600.i = insertelement <16 x i8> %temp.vect599.i, i8 %720, i32 15
  %721 = load <4 x i8> addrspace(3)* %16, align 4
  %scalar64.i = extractelement <4 x i8> %721, i32 3
  %temp603.i = insertelement <16 x i8> undef, i8 %scalar64.i, i32 0
  %vector604.i = shufflevector <16 x i8> %temp603.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %722 = zext i8 %scalar64.i to i32
  %723 = shl i32 %722, 1
  %724 = and i32 %722, 128
  %725 = xor i32 %723, 27
  %726 = icmp eq i32 %724, 0
  %a.7.in.i = select i1 %726, i32 %723, i32 %725
  %727 = shl i32 %a.7.in.i, 1
  %728 = and i32 %a.7.in.i, 128
  %729 = xor i32 %727, 27
  %730 = icmp eq i32 %728, 0
  %a.7.in.1.i = select i1 %730, i32 %727, i32 %729
  %731 = shl i32 %a.7.in.1.i, 1
  %732 = and i32 %a.7.in.1.i, 128
  %733 = xor i32 %731, 27
  %734 = icmp eq i32 %732, 0
  %a.7.in.2.i = select i1 %734, i32 %731, i32 %733
  %735 = shl i32 %a.7.in.2.i, 1
  %736 = and i32 %a.7.in.2.i, 128
  %737 = xor i32 %735, 27
  %738 = icmp eq i32 %736, 0
  %a.7.in.3.i = select i1 %738, i32 %735, i32 %737
  %739 = shl i32 %a.7.in.3.i, 1
  %740 = and i32 %a.7.in.3.i, 128
  %741 = xor i32 %739, 27
  %742 = icmp eq i32 %740, 0
  %a.7.in.4.i = select i1 %742, i32 %739, i32 %741
  %743 = shl i32 %a.7.in.4.i, 1
  %744 = and i32 %a.7.in.4.i, 128
  %745 = xor i32 %743, 27
  %746 = icmp eq i32 %744, 0
  %a.7.in.5.i = select i1 %746, i32 %743, i32 %745
  %747 = shl i32 %a.7.in.5.i, 1
  %748 = lshr <16 x i8> %temp.vect600.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %749 = zext <16 x i8> %748 to <16 x i32>
  %750 = zext <16 x i8> %temp.vect600.i to <16 x i32>
  %751 = lshr <16 x i8> %temp.vect600.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %752 = lshr <16 x i8> %temp.vect600.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %753 = and <16 x i32> %749, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %754 = and <16 x i32> %750, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %755 = zext <16 x i8> %751 to <16 x i32>
  %756 = zext <16 x i8> %752 to <16 x i32>
  %757 = icmp eq <16 x i32> %753, zeroinitializer
  %a.7.i = trunc i32 %a.7.in.i to i8
  %temp601.i = insertelement <16 x i8> undef, i8 %a.7.i, i32 0
  %vector602.i = shufflevector <16 x i8> %temp601.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %758 = icmp eq <16 x i32> %754, zeroinitializer
  %759 = and <16 x i32> %755, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %760 = lshr <16 x i8> %temp.vect600.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %761 = lshr <16 x i8> %temp.vect600.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %762 = and <16 x i32> %756, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %763 = select <16 x i1> %757, <16 x i8> zeroinitializer, <16 x i8> %vector602.i
  %764 = select <16 x i1> %758, <16 x i8> zeroinitializer, <16 x i8> %vector604.i
  %a.7.1.i = trunc i32 %a.7.in.1.i to i8
  %temp606.i = insertelement <16 x i8> undef, i8 %a.7.1.i, i32 0
  %vector607.i = shufflevector <16 x i8> %temp606.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %765 = icmp eq <16 x i32> %759, zeroinitializer
  %766 = zext <16 x i8> %760 to <16 x i32>
  %767 = zext <16 x i8> %761 to <16 x i32>
  %768 = icmp eq <16 x i32> %762, zeroinitializer
  %a.7.2.i = trunc i32 %a.7.in.2.i to i8
  %temp608.i = insertelement <16 x i8> undef, i8 %a.7.2.i, i32 0
  %vector609.i = shufflevector <16 x i8> %temp608.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..1605.i = xor <16 x i8> %763, %764
  %769 = select <16 x i1> %765, <16 x i8> zeroinitializer, <16 x i8> %vector607.i
  %770 = and <16 x i32> %766, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %771 = lshr <16 x i8> %temp.vect600.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %772 = and i32 %a.7.in.5.i, 128
  %773 = and <16 x i32> %767, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %774 = select <16 x i1> %768, <16 x i8> zeroinitializer, <16 x i8> %vector609.i
  %p.7..2610.i = xor <16 x i8> %769, %p.7..1605.i
  %a.7.3.i = trunc i32 %a.7.in.3.i to i8
  %temp612.i = insertelement <16 x i8> undef, i8 %a.7.3.i, i32 0
  %vector613.i = shufflevector <16 x i8> %temp612.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %775 = icmp eq <16 x i32> %770, zeroinitializer
  %776 = zext <16 x i8> %771 to <16 x i32>
  %777 = icmp eq i32 %772, 0
  %778 = xor i32 %747, 27
  %779 = icmp eq <16 x i32> %773, zeroinitializer
  %a.7.4.i = trunc i32 %a.7.in.4.i to i8
  %temp614.i = insertelement <16 x i8> undef, i8 %a.7.4.i, i32 0
  %vector615.i = shufflevector <16 x i8> %temp614.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..3611.i = xor <16 x i8> %774, %p.7..2610.i
  %780 = select <16 x i1> %775, <16 x i8> zeroinitializer, <16 x i8> %vector613.i
  %781 = and <16 x i32> %776, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.7.in.6.i = select i1 %777, i32 %747, i32 %778
  %782 = select <16 x i1> %779, <16 x i8> zeroinitializer, <16 x i8> %vector615.i
  %p.7..4616.i = xor <16 x i8> %780, %p.7..3611.i
  %a.7.5.i = trunc i32 %a.7.in.5.i to i8
  %temp618.i = insertelement <16 x i8> undef, i8 %a.7.5.i, i32 0
  %vector619.i = shufflevector <16 x i8> %temp618.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %783 = icmp eq <16 x i32> %781, zeroinitializer
  %784 = icmp sgt <16 x i8> %temp.vect600.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.7.6.i = trunc i32 %a.7.in.6.i to i8
  %temp620.i = insertelement <16 x i8> undef, i8 %a.7.6.i, i32 0
  %vector621.i = shufflevector <16 x i8> %temp620.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..5617.i = xor <16 x i8> %782, %p.7..4616.i
  %785 = select <16 x i1> %783, <16 x i8> zeroinitializer, <16 x i8> %vector619.i
  %786 = select <16 x i1> %784, <16 x i8> zeroinitializer, <16 x i8> %vector621.i
  %p.7..6622.i = xor <16 x i8> %785, %p.7..5617.i
  %p.7..7623.i = xor <16 x i8> %786, %p.7..6622.i
  %"&(pSB[currWI].offset)1565.i" = add nuw i64 %CurrSBIndex..1.i, 1344
  %"&pSB[currWI].offset1566.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1565.i"
  %CastToValueType1567.i = bitcast i8* %"&pSB[currWI].offset1566.i" to <16 x i8>*
  store <16 x i8> %p.7..7623.i, <16 x i8>* %CastToValueType1567.i, align 16
  %"&(pSB[currWI].offset)1569.i" = add nuw i64 %CurrSBIndex..1.i, 1360
  %"&pSB[currWI].offset1570.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1569.i"
  %CastToValueType1571.i = bitcast i8* %"&pSB[currWI].offset1570.i" to i64*
  %"&(pSB[currWI].offset)1451.i" = add nuw i64 %CurrSBIndex..1.i, 1128
  %"&pSB[currWI].offset1452.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1451.i"
  %CastToValueType1453.i = bitcast i8* %"&pSB[currWI].offset1452.i" to i64*
  %"&(pSB[currWI].offset)1645.i" = add nuw i64 %CurrSBIndex..1.i, 1456
  %"&pSB[currWI].offset1646.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1645.i"
  %CastToValueType1647.i = bitcast i8* %"&pSB[currWI].offset1646.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1681.i" = add nuw i64 %CurrSBIndex..1.i, 1472
  %"&pSB[currWI].offset1682.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1681.i"
  %CastToValueType1683.i = bitcast i8* %"&pSB[currWI].offset1682.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1717.i" = add nuw i64 %CurrSBIndex..1.i, 1488
  %"&pSB[currWI].offset1718.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1717.i"
  %CastToValueType1719.i = bitcast i8* %"&pSB[currWI].offset1718.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1753.i" = add nuw i64 %CurrSBIndex..1.i, 1504
  %"&pSB[currWI].offset1754.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1753.i"
  %CastToValueType1755.i = bitcast i8* %"&pSB[currWI].offset1754.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1789.i" = add nuw i64 %CurrSBIndex..1.i, 1520
  %"&pSB[currWI].offset1790.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1789.i"
  %CastToValueType1791.i = bitcast i8* %"&pSB[currWI].offset1790.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1825.i" = add nuw i64 %CurrSBIndex..1.i, 1536
  %"&pSB[currWI].offset1826.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1825.i"
  %CastToValueType1827.i = bitcast i8* %"&pSB[currWI].offset1826.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1861.i" = add nuw i64 %CurrSBIndex..1.i, 1552
  %"&pSB[currWI].offset1862.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1861.i"
  %CastToValueType1863.i = bitcast i8* %"&pSB[currWI].offset1862.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1897.i" = add nuw i64 %CurrSBIndex..1.i, 1568
  %"&pSB[currWI].offset1898.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1897.i"
  %CastToValueType1899.i = bitcast i8* %"&pSB[currWI].offset1898.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1933.i" = add nuw i64 %CurrSBIndex..1.i, 1584
  %"&pSB[currWI].offset1934.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1933.i"
  %CastToValueType1935.i = bitcast i8* %"&pSB[currWI].offset1934.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1969.i" = add nuw i64 %CurrSBIndex..1.i, 1600
  %"&pSB[currWI].offset1970.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1969.i"
  %CastToValueType1971.i = bitcast i8* %"&pSB[currWI].offset1970.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2005.i" = add nuw i64 %CurrSBIndex..1.i, 1616
  %"&pSB[currWI].offset2006.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2005.i"
  %CastToValueType2007.i = bitcast i8* %"&pSB[currWI].offset2006.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2041.i" = add nuw i64 %CurrSBIndex..1.i, 1632
  %"&pSB[currWI].offset2042.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2041.i"
  %CastToValueType2043.i = bitcast i8* %"&pSB[currWI].offset2042.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2077.i" = add nuw i64 %CurrSBIndex..1.i, 1648
  %"&pSB[currWI].offset2078.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2077.i"
  %CastToValueType2079.i = bitcast i8* %"&pSB[currWI].offset2078.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2113.i" = add nuw i64 %CurrSBIndex..1.i, 1664
  %"&pSB[currWI].offset2114.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2113.i"
  %CastToValueType2115.i = bitcast i8* %"&pSB[currWI].offset2114.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2149.i" = add nuw i64 %CurrSBIndex..1.i, 1680
  %"&pSB[currWI].offset2150.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2149.i"
  %CastToValueType2151.i = bitcast i8* %"&pSB[currWI].offset2150.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2185.i" = add nuw i64 %CurrSBIndex..1.i, 1696
  %"&pSB[currWI].offset2186.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2185.i"
  %CastToValueType2187.i = bitcast i8* %"&pSB[currWI].offset2186.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1641.i" = add nuw i64 %CurrSBIndex..1.i, 1456
  %"&pSB[currWI].offset1642.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1641.i"
  %CastToValueType1643.i = bitcast i8* %"&pSB[currWI].offset1642.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1677.i" = add nuw i64 %CurrSBIndex..1.i, 1472
  %"&pSB[currWI].offset1678.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1677.i"
  %CastToValueType1679.i = bitcast i8* %"&pSB[currWI].offset1678.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1713.i" = add nuw i64 %CurrSBIndex..1.i, 1488
  %"&pSB[currWI].offset1714.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1713.i"
  %CastToValueType1715.i = bitcast i8* %"&pSB[currWI].offset1714.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1749.i" = add nuw i64 %CurrSBIndex..1.i, 1504
  %"&pSB[currWI].offset1750.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1749.i"
  %CastToValueType1751.i = bitcast i8* %"&pSB[currWI].offset1750.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1785.i" = add nuw i64 %CurrSBIndex..1.i, 1520
  %"&pSB[currWI].offset1786.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1785.i"
  %CastToValueType1787.i = bitcast i8* %"&pSB[currWI].offset1786.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1821.i" = add nuw i64 %CurrSBIndex..1.i, 1536
  %"&pSB[currWI].offset1822.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1821.i"
  %CastToValueType1823.i = bitcast i8* %"&pSB[currWI].offset1822.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1857.i" = add nuw i64 %CurrSBIndex..1.i, 1552
  %"&pSB[currWI].offset1858.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1857.i"
  %CastToValueType1859.i = bitcast i8* %"&pSB[currWI].offset1858.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1893.i" = add nuw i64 %CurrSBIndex..1.i, 1568
  %"&pSB[currWI].offset1894.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1893.i"
  %CastToValueType1895.i = bitcast i8* %"&pSB[currWI].offset1894.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1929.i" = add nuw i64 %CurrSBIndex..1.i, 1584
  %"&pSB[currWI].offset1930.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1929.i"
  %CastToValueType1931.i = bitcast i8* %"&pSB[currWI].offset1930.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1965.i" = add nuw i64 %CurrSBIndex..1.i, 1600
  %"&pSB[currWI].offset1966.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1965.i"
  %CastToValueType1967.i = bitcast i8* %"&pSB[currWI].offset1966.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2001.i" = add nuw i64 %CurrSBIndex..1.i, 1616
  %"&pSB[currWI].offset2002.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2001.i"
  %CastToValueType2003.i = bitcast i8* %"&pSB[currWI].offset2002.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2037.i" = add nuw i64 %CurrSBIndex..1.i, 1632
  %"&pSB[currWI].offset2038.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2037.i"
  %CastToValueType2039.i = bitcast i8* %"&pSB[currWI].offset2038.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2073.i" = add nuw i64 %CurrSBIndex..1.i, 1648
  %"&pSB[currWI].offset2074.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2073.i"
  %CastToValueType2075.i = bitcast i8* %"&pSB[currWI].offset2074.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2109.i" = add nuw i64 %CurrSBIndex..1.i, 1664
  %"&pSB[currWI].offset2110.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2109.i"
  %CastToValueType2111.i = bitcast i8* %"&pSB[currWI].offset2110.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2145.i" = add nuw i64 %CurrSBIndex..1.i, 1680
  %"&pSB[currWI].offset2146.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2145.i"
  %CastToValueType2147.i = bitcast i8* %"&pSB[currWI].offset2146.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2181.i" = add nuw i64 %CurrSBIndex..1.i, 1696
  %"&pSB[currWI].offset2182.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2181.i"
  %CastToValueType2183.i = bitcast i8* %"&pSB[currWI].offset2182.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1637.i" = add nuw i64 %CurrSBIndex..1.i, 1456
  %"&pSB[currWI].offset1638.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1637.i"
  %CastToValueType1639.i = bitcast i8* %"&pSB[currWI].offset1638.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1673.i" = add nuw i64 %CurrSBIndex..1.i, 1472
  %"&pSB[currWI].offset1674.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1673.i"
  %CastToValueType1675.i = bitcast i8* %"&pSB[currWI].offset1674.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1709.i" = add nuw i64 %CurrSBIndex..1.i, 1488
  %"&pSB[currWI].offset1710.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1709.i"
  %CastToValueType1711.i = bitcast i8* %"&pSB[currWI].offset1710.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1745.i" = add nuw i64 %CurrSBIndex..1.i, 1504
  %"&pSB[currWI].offset1746.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1745.i"
  %CastToValueType1747.i = bitcast i8* %"&pSB[currWI].offset1746.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1781.i" = add nuw i64 %CurrSBIndex..1.i, 1520
  %"&pSB[currWI].offset1782.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1781.i"
  %CastToValueType1783.i = bitcast i8* %"&pSB[currWI].offset1782.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1817.i" = add nuw i64 %CurrSBIndex..1.i, 1536
  %"&pSB[currWI].offset1818.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1817.i"
  %CastToValueType1819.i = bitcast i8* %"&pSB[currWI].offset1818.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1853.i" = add nuw i64 %CurrSBIndex..1.i, 1552
  %"&pSB[currWI].offset1854.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1853.i"
  %CastToValueType1855.i = bitcast i8* %"&pSB[currWI].offset1854.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1889.i" = add nuw i64 %CurrSBIndex..1.i, 1568
  %"&pSB[currWI].offset1890.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1889.i"
  %CastToValueType1891.i = bitcast i8* %"&pSB[currWI].offset1890.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1925.i" = add nuw i64 %CurrSBIndex..1.i, 1584
  %"&pSB[currWI].offset1926.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1925.i"
  %CastToValueType1927.i = bitcast i8* %"&pSB[currWI].offset1926.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1961.i" = add nuw i64 %CurrSBIndex..1.i, 1600
  %"&pSB[currWI].offset1962.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1961.i"
  %CastToValueType1963.i = bitcast i8* %"&pSB[currWI].offset1962.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1997.i" = add nuw i64 %CurrSBIndex..1.i, 1616
  %"&pSB[currWI].offset1998.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1997.i"
  %CastToValueType1999.i = bitcast i8* %"&pSB[currWI].offset1998.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2033.i" = add nuw i64 %CurrSBIndex..1.i, 1632
  %"&pSB[currWI].offset2034.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2033.i"
  %CastToValueType2035.i = bitcast i8* %"&pSB[currWI].offset2034.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2069.i" = add nuw i64 %CurrSBIndex..1.i, 1648
  %"&pSB[currWI].offset2070.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2069.i"
  %CastToValueType2071.i = bitcast i8* %"&pSB[currWI].offset2070.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2105.i" = add nuw i64 %CurrSBIndex..1.i, 1664
  %"&pSB[currWI].offset2106.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2105.i"
  %CastToValueType2107.i = bitcast i8* %"&pSB[currWI].offset2106.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2141.i" = add nuw i64 %CurrSBIndex..1.i, 1680
  %"&pSB[currWI].offset2142.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2141.i"
  %CastToValueType2143.i = bitcast i8* %"&pSB[currWI].offset2142.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2177.i" = add nuw i64 %CurrSBIndex..1.i, 1696
  %"&pSB[currWI].offset2178.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2177.i"
  %CastToValueType2179.i = bitcast i8* %"&pSB[currWI].offset2178.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1633.i" = add nuw i64 %CurrSBIndex..1.i, 1456
  %"&pSB[currWI].offset1634.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1633.i"
  %CastToValueType1635.i = bitcast i8* %"&pSB[currWI].offset1634.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1669.i" = add nuw i64 %CurrSBIndex..1.i, 1472
  %"&pSB[currWI].offset1670.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1669.i"
  %CastToValueType1671.i = bitcast i8* %"&pSB[currWI].offset1670.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1705.i" = add nuw i64 %CurrSBIndex..1.i, 1488
  %"&pSB[currWI].offset1706.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1705.i"
  %CastToValueType1707.i = bitcast i8* %"&pSB[currWI].offset1706.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1741.i" = add nuw i64 %CurrSBIndex..1.i, 1504
  %"&pSB[currWI].offset1742.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1741.i"
  %CastToValueType1743.i = bitcast i8* %"&pSB[currWI].offset1742.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1777.i" = add nuw i64 %CurrSBIndex..1.i, 1520
  %"&pSB[currWI].offset1778.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1777.i"
  %CastToValueType1779.i = bitcast i8* %"&pSB[currWI].offset1778.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1813.i" = add nuw i64 %CurrSBIndex..1.i, 1536
  %"&pSB[currWI].offset1814.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1813.i"
  %CastToValueType1815.i = bitcast i8* %"&pSB[currWI].offset1814.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1849.i" = add nuw i64 %CurrSBIndex..1.i, 1552
  %"&pSB[currWI].offset1850.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1849.i"
  %CastToValueType1851.i = bitcast i8* %"&pSB[currWI].offset1850.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1885.i" = add nuw i64 %CurrSBIndex..1.i, 1568
  %"&pSB[currWI].offset1886.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1885.i"
  %CastToValueType1887.i = bitcast i8* %"&pSB[currWI].offset1886.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1921.i" = add nuw i64 %CurrSBIndex..1.i, 1584
  %"&pSB[currWI].offset1922.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1921.i"
  %CastToValueType1923.i = bitcast i8* %"&pSB[currWI].offset1922.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1957.i" = add nuw i64 %CurrSBIndex..1.i, 1600
  %"&pSB[currWI].offset1958.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1957.i"
  %CastToValueType1959.i = bitcast i8* %"&pSB[currWI].offset1958.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1993.i" = add nuw i64 %CurrSBIndex..1.i, 1616
  %"&pSB[currWI].offset1994.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1993.i"
  %CastToValueType1995.i = bitcast i8* %"&pSB[currWI].offset1994.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2029.i" = add nuw i64 %CurrSBIndex..1.i, 1632
  %"&pSB[currWI].offset2030.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2029.i"
  %CastToValueType2031.i = bitcast i8* %"&pSB[currWI].offset2030.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2065.i" = add nuw i64 %CurrSBIndex..1.i, 1648
  %"&pSB[currWI].offset2066.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2065.i"
  %CastToValueType2067.i = bitcast i8* %"&pSB[currWI].offset2066.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2101.i" = add nuw i64 %CurrSBIndex..1.i, 1664
  %"&pSB[currWI].offset2102.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2101.i"
  %CastToValueType2103.i = bitcast i8* %"&pSB[currWI].offset2102.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2137.i" = add nuw i64 %CurrSBIndex..1.i, 1680
  %"&pSB[currWI].offset2138.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2137.i"
  %CastToValueType2139.i = bitcast i8* %"&pSB[currWI].offset2138.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)2173.i" = add nuw i64 %CurrSBIndex..1.i, 1696
  %"&pSB[currWI].offset2174.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)2173.i"
  %CastToValueType2175.i = bitcast i8* %"&pSB[currWI].offset2174.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1573.i" = add nuw i64 %CurrSBIndex..1.i, 1376
  %"&pSB[currWI].offset1574.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1573.i"
  %CastToValueType1575.i = bitcast i8* %"&pSB[currWI].offset1574.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1587.i" = add nuw i64 %CurrSBIndex..1.i, 1392
  %"&pSB[currWI].offset1588.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1587.i"
  %CastToValueType1589.i = bitcast i8* %"&pSB[currWI].offset1588.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1601.i" = add nuw i64 %CurrSBIndex..1.i, 1408
  %"&pSB[currWI].offset1602.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1601.i"
  %CastToValueType1603.i = bitcast i8* %"&pSB[currWI].offset1602.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1615.i" = add nuw i64 %CurrSBIndex..1.i, 1424
  %"&pSB[currWI].offset1616.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1615.i"
  %CastToValueType1617.i = bitcast i8* %"&pSB[currWI].offset1616.i" to <16 x i8>*
  br label %787

; <label>:787                                     ; preds = %787, %SyncBB2211.i
  %indvar.i = phi i64 [ 0, %SyncBB2211.i ], [ %tmp.i, %787 ]
  %vectorPHI624.i = phi <16 x i8> [ %p.7..7623.i, %SyncBB2211.i ], [ %1251, %787 ]
  %vectorPHI625.i = phi <16 x i8> [ %p.5..7584.i, %SyncBB2211.i ], [ %1250, %787 ]
  %vectorPHI626.i = phi <16 x i8> [ %p.3..7545.i, %SyncBB2211.i ], [ %1249, %787 ]
  %vectorPHI627.i = phi <16 x i8> [ %p.1..7506.i, %SyncBB2211.i ], [ %1248, %787 ]
  %tmp.i = add i64 %indvar.i, 1
  store i64 %tmp.i, i64* %CastToValueType1571.i, align 8
  %scevgep.i = getelementptr <4 x i8> addrspace(3)* %16, i64 %tmp.i
  %loadedValue1454.i = load i64* %CastToValueType1453.i, align 8
  %tmp77.i = add i64 %loadedValue1454.i, %indvar.i
  %788 = and i64 %tmp77.i, 3
  %789 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1647.i, i64 0, i64 %788
  %790 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1683.i, i64 0, i64 %788
  %791 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1719.i, i64 0, i64 %788
  %792 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1755.i, i64 0, i64 %788
  %793 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1791.i, i64 0, i64 %788
  %794 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1827.i, i64 0, i64 %788
  %795 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1863.i, i64 0, i64 %788
  %796 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1899.i, i64 0, i64 %788
  %797 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1935.i, i64 0, i64 %788
  %798 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1971.i, i64 0, i64 %788
  %799 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2007.i, i64 0, i64 %788
  %800 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2043.i, i64 0, i64 %788
  %801 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2079.i, i64 0, i64 %788
  %802 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2115.i, i64 0, i64 %788
  %803 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2151.i, i64 0, i64 %788
  %804 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2187.i, i64 0, i64 %788
  %805 = load <4 x i8>* %789, align 4
  %806 = load <4 x i8>* %790, align 4
  %807 = load <4 x i8>* %791, align 4
  %808 = load <4 x i8>* %792, align 4
  %809 = load <4 x i8>* %793, align 4
  %810 = load <4 x i8>* %794, align 4
  %811 = load <4 x i8>* %795, align 4
  %812 = load <4 x i8>* %796, align 4
  %813 = load <4 x i8>* %797, align 4
  %814 = load <4 x i8>* %798, align 4
  %815 = load <4 x i8>* %799, align 4
  %816 = load <4 x i8>* %800, align 4
  %817 = load <4 x i8>* %801, align 4
  %818 = load <4 x i8>* %802, align 4
  %819 = load <4 x i8>* %803, align 4
  %820 = load <4 x i8>* %804, align 4
  %821 = extractelement <4 x i8> %805, i32 0
  %822 = extractelement <4 x i8> %806, i32 0
  %823 = extractelement <4 x i8> %807, i32 0
  %824 = extractelement <4 x i8> %808, i32 0
  %825 = extractelement <4 x i8> %809, i32 0
  %826 = extractelement <4 x i8> %810, i32 0
  %827 = extractelement <4 x i8> %811, i32 0
  %828 = extractelement <4 x i8> %812, i32 0
  %829 = extractelement <4 x i8> %813, i32 0
  %830 = extractelement <4 x i8> %814, i32 0
  %831 = extractelement <4 x i8> %815, i32 0
  %832 = extractelement <4 x i8> %816, i32 0
  %833 = extractelement <4 x i8> %817, i32 0
  %834 = extractelement <4 x i8> %818, i32 0
  %835 = extractelement <4 x i8> %819, i32 0
  %836 = extractelement <4 x i8> %820, i32 0
  %temp.vect628.i = insertelement <16 x i8> undef, i8 %821, i32 0
  %temp.vect629.i = insertelement <16 x i8> %temp.vect628.i, i8 %822, i32 1
  %temp.vect630.i = insertelement <16 x i8> %temp.vect629.i, i8 %823, i32 2
  %temp.vect631.i = insertelement <16 x i8> %temp.vect630.i, i8 %824, i32 3
  %temp.vect632.i = insertelement <16 x i8> %temp.vect631.i, i8 %825, i32 4
  %temp.vect633.i = insertelement <16 x i8> %temp.vect632.i, i8 %826, i32 5
  %temp.vect634.i = insertelement <16 x i8> %temp.vect633.i, i8 %827, i32 6
  %temp.vect635.i = insertelement <16 x i8> %temp.vect634.i, i8 %828, i32 7
  %temp.vect636.i = insertelement <16 x i8> %temp.vect635.i, i8 %829, i32 8
  %temp.vect637.i = insertelement <16 x i8> %temp.vect636.i, i8 %830, i32 9
  %temp.vect638.i = insertelement <16 x i8> %temp.vect637.i, i8 %831, i32 10
  %temp.vect639.i = insertelement <16 x i8> %temp.vect638.i, i8 %832, i32 11
  %temp.vect640.i = insertelement <16 x i8> %temp.vect639.i, i8 %833, i32 12
  %temp.vect641.i = insertelement <16 x i8> %temp.vect640.i, i8 %834, i32 13
  %temp.vect642.i = insertelement <16 x i8> %temp.vect641.i, i8 %835, i32 14
  %temp.vect643.i = insertelement <16 x i8> %temp.vect642.i, i8 %836, i32 15
  %837 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar69.i = extractelement <4 x i8> %837, i32 0
  %temp646.i = insertelement <16 x i8> undef, i8 %scalar69.i, i32 0
  %vector647.i = shufflevector <16 x i8> %temp646.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %838 = zext i8 %scalar69.i to i32
  %839 = shl i32 %838, 1
  %840 = and i32 %838, 128
  %841 = xor i32 %839, 27
  %842 = icmp eq i32 %840, 0
  %a.9.in.i = select i1 %842, i32 %839, i32 %841
  %843 = shl i32 %a.9.in.i, 1
  %844 = and i32 %a.9.in.i, 128
  %845 = xor i32 %843, 27
  %846 = icmp eq i32 %844, 0
  %a.9.in.1.i = select i1 %846, i32 %843, i32 %845
  %847 = shl i32 %a.9.in.1.i, 1
  %848 = and i32 %a.9.in.1.i, 128
  %849 = xor i32 %847, 27
  %850 = icmp eq i32 %848, 0
  %a.9.in.2.i = select i1 %850, i32 %847, i32 %849
  %851 = shl i32 %a.9.in.2.i, 1
  %852 = and i32 %a.9.in.2.i, 128
  %853 = xor i32 %851, 27
  %854 = icmp eq i32 %852, 0
  %a.9.in.3.i = select i1 %854, i32 %851, i32 %853
  %855 = shl i32 %a.9.in.3.i, 1
  %856 = and i32 %a.9.in.3.i, 128
  %857 = xor i32 %855, 27
  %858 = icmp eq i32 %856, 0
  %a.9.in.4.i = select i1 %858, i32 %855, i32 %857
  %859 = shl i32 %a.9.in.4.i, 1
  %860 = and i32 %a.9.in.4.i, 128
  %861 = xor i32 %859, 27
  %862 = icmp eq i32 %860, 0
  %a.9.in.5.i = select i1 %862, i32 %859, i32 %861
  %863 = shl i32 %a.9.in.5.i, 1
  %864 = lshr <16 x i8> %temp.vect643.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %865 = zext <16 x i8> %864 to <16 x i32>
  %866 = zext <16 x i8> %temp.vect643.i to <16 x i32>
  %867 = lshr <16 x i8> %temp.vect643.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %868 = lshr <16 x i8> %temp.vect643.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %869 = and <16 x i32> %865, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %870 = and <16 x i32> %866, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %871 = zext <16 x i8> %867 to <16 x i32>
  %872 = zext <16 x i8> %868 to <16 x i32>
  %873 = icmp eq <16 x i32> %869, zeroinitializer
  %a.9.i = trunc i32 %a.9.in.i to i8
  %temp644.i = insertelement <16 x i8> undef, i8 %a.9.i, i32 0
  %vector645.i = shufflevector <16 x i8> %temp644.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %874 = icmp eq <16 x i32> %870, zeroinitializer
  %875 = and <16 x i32> %871, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %876 = lshr <16 x i8> %temp.vect643.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %877 = lshr <16 x i8> %temp.vect643.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %878 = and <16 x i32> %872, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %879 = select <16 x i1> %873, <16 x i8> zeroinitializer, <16 x i8> %vector645.i
  %880 = select <16 x i1> %874, <16 x i8> zeroinitializer, <16 x i8> %vector647.i
  %a.9.1.i = trunc i32 %a.9.in.1.i to i8
  %temp649.i = insertelement <16 x i8> undef, i8 %a.9.1.i, i32 0
  %vector650.i = shufflevector <16 x i8> %temp649.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %881 = icmp eq <16 x i32> %875, zeroinitializer
  %882 = zext <16 x i8> %876 to <16 x i32>
  %883 = zext <16 x i8> %877 to <16 x i32>
  %884 = icmp eq <16 x i32> %878, zeroinitializer
  %a.9.2.i = trunc i32 %a.9.in.2.i to i8
  %temp651.i = insertelement <16 x i8> undef, i8 %a.9.2.i, i32 0
  %vector652.i = shufflevector <16 x i8> %temp651.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..1648.i = xor <16 x i8> %879, %880
  %885 = select <16 x i1> %881, <16 x i8> zeroinitializer, <16 x i8> %vector650.i
  %886 = and <16 x i32> %882, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %887 = lshr <16 x i8> %temp.vect643.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %888 = and i32 %a.9.in.5.i, 128
  %889 = and <16 x i32> %883, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %890 = select <16 x i1> %884, <16 x i8> zeroinitializer, <16 x i8> %vector652.i
  %p.9..2653.i = xor <16 x i8> %885, %p.9..1648.i
  %a.9.3.i = trunc i32 %a.9.in.3.i to i8
  %temp655.i = insertelement <16 x i8> undef, i8 %a.9.3.i, i32 0
  %vector656.i = shufflevector <16 x i8> %temp655.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %891 = icmp eq <16 x i32> %886, zeroinitializer
  %892 = zext <16 x i8> %887 to <16 x i32>
  %893 = icmp eq i32 %888, 0
  %894 = xor i32 %863, 27
  %895 = icmp eq <16 x i32> %889, zeroinitializer
  %a.9.4.i = trunc i32 %a.9.in.4.i to i8
  %temp657.i = insertelement <16 x i8> undef, i8 %a.9.4.i, i32 0
  %vector658.i = shufflevector <16 x i8> %temp657.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..3654.i = xor <16 x i8> %890, %p.9..2653.i
  %896 = select <16 x i1> %891, <16 x i8> zeroinitializer, <16 x i8> %vector656.i
  %897 = and <16 x i32> %892, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.9.in.6.i = select i1 %893, i32 %863, i32 %894
  %898 = select <16 x i1> %895, <16 x i8> zeroinitializer, <16 x i8> %vector658.i
  %p.9..4659.i = xor <16 x i8> %896, %p.9..3654.i
  %a.9.5.i = trunc i32 %a.9.in.5.i to i8
  %temp661.i = insertelement <16 x i8> undef, i8 %a.9.5.i, i32 0
  %vector662.i = shufflevector <16 x i8> %temp661.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %899 = icmp eq <16 x i32> %897, zeroinitializer
  %900 = icmp sgt <16 x i8> %temp.vect643.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.9.6.i = trunc i32 %a.9.in.6.i to i8
  %temp663.i = insertelement <16 x i8> undef, i8 %a.9.6.i, i32 0
  %vector664.i = shufflevector <16 x i8> %temp663.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..5660.i = xor <16 x i8> %898, %p.9..4659.i
  %901 = select <16 x i1> %899, <16 x i8> zeroinitializer, <16 x i8> %vector662.i
  %902 = select <16 x i1> %900, <16 x i8> zeroinitializer, <16 x i8> %vector664.i
  %p.9..6665.i = xor <16 x i8> %901, %p.9..5660.i
  %p.9..7666.i = xor <16 x i8> %902, %p.9..6665.i
  %903 = and i64 %tmp77.i, 3
  %904 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1643.i, i64 0, i64 %903
  %905 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1679.i, i64 0, i64 %903
  %906 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1715.i, i64 0, i64 %903
  %907 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1751.i, i64 0, i64 %903
  %908 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1787.i, i64 0, i64 %903
  %909 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1823.i, i64 0, i64 %903
  %910 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1859.i, i64 0, i64 %903
  %911 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1895.i, i64 0, i64 %903
  %912 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1931.i, i64 0, i64 %903
  %913 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1967.i, i64 0, i64 %903
  %914 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2003.i, i64 0, i64 %903
  %915 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2039.i, i64 0, i64 %903
  %916 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2075.i, i64 0, i64 %903
  %917 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2111.i, i64 0, i64 %903
  %918 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2147.i, i64 0, i64 %903
  %919 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2183.i, i64 0, i64 %903
  %920 = load <4 x i8>* %904, align 4
  %921 = load <4 x i8>* %905, align 4
  %922 = load <4 x i8>* %906, align 4
  %923 = load <4 x i8>* %907, align 4
  %924 = load <4 x i8>* %908, align 4
  %925 = load <4 x i8>* %909, align 4
  %926 = load <4 x i8>* %910, align 4
  %927 = load <4 x i8>* %911, align 4
  %928 = load <4 x i8>* %912, align 4
  %929 = load <4 x i8>* %913, align 4
  %930 = load <4 x i8>* %914, align 4
  %931 = load <4 x i8>* %915, align 4
  %932 = load <4 x i8>* %916, align 4
  %933 = load <4 x i8>* %917, align 4
  %934 = load <4 x i8>* %918, align 4
  %935 = load <4 x i8>* %919, align 4
  %936 = extractelement <4 x i8> %920, i32 0
  %937 = extractelement <4 x i8> %921, i32 0
  %938 = extractelement <4 x i8> %922, i32 0
  %939 = extractelement <4 x i8> %923, i32 0
  %940 = extractelement <4 x i8> %924, i32 0
  %941 = extractelement <4 x i8> %925, i32 0
  %942 = extractelement <4 x i8> %926, i32 0
  %943 = extractelement <4 x i8> %927, i32 0
  %944 = extractelement <4 x i8> %928, i32 0
  %945 = extractelement <4 x i8> %929, i32 0
  %946 = extractelement <4 x i8> %930, i32 0
  %947 = extractelement <4 x i8> %931, i32 0
  %948 = extractelement <4 x i8> %932, i32 0
  %949 = extractelement <4 x i8> %933, i32 0
  %950 = extractelement <4 x i8> %934, i32 0
  %951 = extractelement <4 x i8> %935, i32 0
  %temp.vect667.i = insertelement <16 x i8> undef, i8 %936, i32 0
  %temp.vect668.i = insertelement <16 x i8> %temp.vect667.i, i8 %937, i32 1
  %temp.vect669.i = insertelement <16 x i8> %temp.vect668.i, i8 %938, i32 2
  %temp.vect670.i = insertelement <16 x i8> %temp.vect669.i, i8 %939, i32 3
  %temp.vect671.i = insertelement <16 x i8> %temp.vect670.i, i8 %940, i32 4
  %temp.vect672.i = insertelement <16 x i8> %temp.vect671.i, i8 %941, i32 5
  %temp.vect673.i = insertelement <16 x i8> %temp.vect672.i, i8 %942, i32 6
  %temp.vect674.i = insertelement <16 x i8> %temp.vect673.i, i8 %943, i32 7
  %temp.vect675.i = insertelement <16 x i8> %temp.vect674.i, i8 %944, i32 8
  %temp.vect676.i = insertelement <16 x i8> %temp.vect675.i, i8 %945, i32 9
  %temp.vect677.i = insertelement <16 x i8> %temp.vect676.i, i8 %946, i32 10
  %temp.vect678.i = insertelement <16 x i8> %temp.vect677.i, i8 %947, i32 11
  %temp.vect679.i = insertelement <16 x i8> %temp.vect678.i, i8 %948, i32 12
  %temp.vect680.i = insertelement <16 x i8> %temp.vect679.i, i8 %949, i32 13
  %temp.vect681.i = insertelement <16 x i8> %temp.vect680.i, i8 %950, i32 14
  %temp.vect682.i = insertelement <16 x i8> %temp.vect681.i, i8 %951, i32 15
  %952 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar78.i = extractelement <4 x i8> %952, i32 1
  %temp685.i = insertelement <16 x i8> undef, i8 %scalar78.i, i32 0
  %vector686.i = shufflevector <16 x i8> %temp685.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %953 = zext i8 %scalar78.i to i32
  %954 = shl i32 %953, 1
  %955 = and i32 %953, 128
  %956 = xor i32 %954, 27
  %957 = icmp eq i32 %955, 0
  %a.11.in.i = select i1 %957, i32 %954, i32 %956
  %958 = shl i32 %a.11.in.i, 1
  %959 = and i32 %a.11.in.i, 128
  %960 = xor i32 %958, 27
  %961 = icmp eq i32 %959, 0
  %a.11.in.1.i = select i1 %961, i32 %958, i32 %960
  %962 = shl i32 %a.11.in.1.i, 1
  %963 = and i32 %a.11.in.1.i, 128
  %964 = xor i32 %962, 27
  %965 = icmp eq i32 %963, 0
  %a.11.in.2.i = select i1 %965, i32 %962, i32 %964
  %966 = shl i32 %a.11.in.2.i, 1
  %967 = and i32 %a.11.in.2.i, 128
  %968 = xor i32 %966, 27
  %969 = icmp eq i32 %967, 0
  %a.11.in.3.i = select i1 %969, i32 %966, i32 %968
  %970 = shl i32 %a.11.in.3.i, 1
  %971 = and i32 %a.11.in.3.i, 128
  %972 = xor i32 %970, 27
  %973 = icmp eq i32 %971, 0
  %a.11.in.4.i = select i1 %973, i32 %970, i32 %972
  %974 = shl i32 %a.11.in.4.i, 1
  %975 = and i32 %a.11.in.4.i, 128
  %976 = xor i32 %974, 27
  %977 = icmp eq i32 %975, 0
  %a.11.in.5.i = select i1 %977, i32 %974, i32 %976
  %978 = shl i32 %a.11.in.5.i, 1
  %979 = lshr <16 x i8> %temp.vect682.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %980 = zext <16 x i8> %979 to <16 x i32>
  %981 = zext <16 x i8> %temp.vect682.i to <16 x i32>
  %982 = lshr <16 x i8> %temp.vect682.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %983 = lshr <16 x i8> %temp.vect682.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %984 = and <16 x i32> %980, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %985 = and <16 x i32> %981, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %986 = zext <16 x i8> %982 to <16 x i32>
  %987 = zext <16 x i8> %983 to <16 x i32>
  %988 = icmp eq <16 x i32> %984, zeroinitializer
  %a.11.i = trunc i32 %a.11.in.i to i8
  %temp683.i = insertelement <16 x i8> undef, i8 %a.11.i, i32 0
  %vector684.i = shufflevector <16 x i8> %temp683.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %989 = icmp eq <16 x i32> %985, zeroinitializer
  %990 = and <16 x i32> %986, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %991 = lshr <16 x i8> %temp.vect682.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %992 = lshr <16 x i8> %temp.vect682.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %993 = and <16 x i32> %987, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %994 = select <16 x i1> %988, <16 x i8> zeroinitializer, <16 x i8> %vector684.i
  %995 = select <16 x i1> %989, <16 x i8> zeroinitializer, <16 x i8> %vector686.i
  %a.11.1.i = trunc i32 %a.11.in.1.i to i8
  %temp688.i = insertelement <16 x i8> undef, i8 %a.11.1.i, i32 0
  %vector689.i = shufflevector <16 x i8> %temp688.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %996 = icmp eq <16 x i32> %990, zeroinitializer
  %997 = zext <16 x i8> %991 to <16 x i32>
  %998 = zext <16 x i8> %992 to <16 x i32>
  %999 = icmp eq <16 x i32> %993, zeroinitializer
  %a.11.2.i = trunc i32 %a.11.in.2.i to i8
  %temp690.i = insertelement <16 x i8> undef, i8 %a.11.2.i, i32 0
  %vector691.i = shufflevector <16 x i8> %temp690.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..1687.i = xor <16 x i8> %994, %995
  %1000 = select <16 x i1> %996, <16 x i8> zeroinitializer, <16 x i8> %vector689.i
  %1001 = and <16 x i32> %997, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1002 = lshr <16 x i8> %temp.vect682.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1003 = and i32 %a.11.in.5.i, 128
  %1004 = and <16 x i32> %998, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1005 = select <16 x i1> %999, <16 x i8> zeroinitializer, <16 x i8> %vector691.i
  %p.11..2692.i = xor <16 x i8> %1000, %p.11..1687.i
  %a.11.3.i = trunc i32 %a.11.in.3.i to i8
  %temp694.i = insertelement <16 x i8> undef, i8 %a.11.3.i, i32 0
  %vector695.i = shufflevector <16 x i8> %temp694.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1006 = icmp eq <16 x i32> %1001, zeroinitializer
  %1007 = zext <16 x i8> %1002 to <16 x i32>
  %1008 = icmp eq i32 %1003, 0
  %1009 = xor i32 %978, 27
  %1010 = icmp eq <16 x i32> %1004, zeroinitializer
  %a.11.4.i = trunc i32 %a.11.in.4.i to i8
  %temp696.i = insertelement <16 x i8> undef, i8 %a.11.4.i, i32 0
  %vector697.i = shufflevector <16 x i8> %temp696.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..3693.i = xor <16 x i8> %1005, %p.11..2692.i
  %1011 = select <16 x i1> %1006, <16 x i8> zeroinitializer, <16 x i8> %vector695.i
  %1012 = and <16 x i32> %1007, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.11.in.6.i = select i1 %1008, i32 %978, i32 %1009
  %1013 = select <16 x i1> %1010, <16 x i8> zeroinitializer, <16 x i8> %vector697.i
  %p.11..4698.i = xor <16 x i8> %1011, %p.11..3693.i
  %a.11.5.i = trunc i32 %a.11.in.5.i to i8
  %temp700.i = insertelement <16 x i8> undef, i8 %a.11.5.i, i32 0
  %vector701.i = shufflevector <16 x i8> %temp700.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1014 = icmp eq <16 x i32> %1012, zeroinitializer
  %1015 = icmp sgt <16 x i8> %temp.vect682.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.11.6.i = trunc i32 %a.11.in.6.i to i8
  %temp702.i = insertelement <16 x i8> undef, i8 %a.11.6.i, i32 0
  %vector703.i = shufflevector <16 x i8> %temp702.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..5699.i = xor <16 x i8> %1013, %p.11..4698.i
  %1016 = select <16 x i1> %1014, <16 x i8> zeroinitializer, <16 x i8> %vector701.i
  %1017 = select <16 x i1> %1015, <16 x i8> zeroinitializer, <16 x i8> %vector703.i
  %p.11..6704.i = xor <16 x i8> %1016, %p.11..5699.i
  %p.11..7705.i = xor <16 x i8> %1017, %p.11..6704.i
  %1018 = and i64 %tmp77.i, 3
  %1019 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1639.i, i64 0, i64 %1018
  %1020 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1675.i, i64 0, i64 %1018
  %1021 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1711.i, i64 0, i64 %1018
  %1022 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1747.i, i64 0, i64 %1018
  %1023 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1783.i, i64 0, i64 %1018
  %1024 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1819.i, i64 0, i64 %1018
  %1025 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1855.i, i64 0, i64 %1018
  %1026 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1891.i, i64 0, i64 %1018
  %1027 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1927.i, i64 0, i64 %1018
  %1028 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1963.i, i64 0, i64 %1018
  %1029 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1999.i, i64 0, i64 %1018
  %1030 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2035.i, i64 0, i64 %1018
  %1031 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2071.i, i64 0, i64 %1018
  %1032 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2107.i, i64 0, i64 %1018
  %1033 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2143.i, i64 0, i64 %1018
  %1034 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2179.i, i64 0, i64 %1018
  %1035 = load <4 x i8>* %1019, align 4
  %1036 = load <4 x i8>* %1020, align 4
  %1037 = load <4 x i8>* %1021, align 4
  %1038 = load <4 x i8>* %1022, align 4
  %1039 = load <4 x i8>* %1023, align 4
  %1040 = load <4 x i8>* %1024, align 4
  %1041 = load <4 x i8>* %1025, align 4
  %1042 = load <4 x i8>* %1026, align 4
  %1043 = load <4 x i8>* %1027, align 4
  %1044 = load <4 x i8>* %1028, align 4
  %1045 = load <4 x i8>* %1029, align 4
  %1046 = load <4 x i8>* %1030, align 4
  %1047 = load <4 x i8>* %1031, align 4
  %1048 = load <4 x i8>* %1032, align 4
  %1049 = load <4 x i8>* %1033, align 4
  %1050 = load <4 x i8>* %1034, align 4
  %1051 = extractelement <4 x i8> %1035, i32 0
  %1052 = extractelement <4 x i8> %1036, i32 0
  %1053 = extractelement <4 x i8> %1037, i32 0
  %1054 = extractelement <4 x i8> %1038, i32 0
  %1055 = extractelement <4 x i8> %1039, i32 0
  %1056 = extractelement <4 x i8> %1040, i32 0
  %1057 = extractelement <4 x i8> %1041, i32 0
  %1058 = extractelement <4 x i8> %1042, i32 0
  %1059 = extractelement <4 x i8> %1043, i32 0
  %1060 = extractelement <4 x i8> %1044, i32 0
  %1061 = extractelement <4 x i8> %1045, i32 0
  %1062 = extractelement <4 x i8> %1046, i32 0
  %1063 = extractelement <4 x i8> %1047, i32 0
  %1064 = extractelement <4 x i8> %1048, i32 0
  %1065 = extractelement <4 x i8> %1049, i32 0
  %1066 = extractelement <4 x i8> %1050, i32 0
  %temp.vect706.i = insertelement <16 x i8> undef, i8 %1051, i32 0
  %temp.vect707.i = insertelement <16 x i8> %temp.vect706.i, i8 %1052, i32 1
  %temp.vect708.i = insertelement <16 x i8> %temp.vect707.i, i8 %1053, i32 2
  %temp.vect709.i = insertelement <16 x i8> %temp.vect708.i, i8 %1054, i32 3
  %temp.vect710.i = insertelement <16 x i8> %temp.vect709.i, i8 %1055, i32 4
  %temp.vect711.i = insertelement <16 x i8> %temp.vect710.i, i8 %1056, i32 5
  %temp.vect712.i = insertelement <16 x i8> %temp.vect711.i, i8 %1057, i32 6
  %temp.vect713.i = insertelement <16 x i8> %temp.vect712.i, i8 %1058, i32 7
  %temp.vect714.i = insertelement <16 x i8> %temp.vect713.i, i8 %1059, i32 8
  %temp.vect715.i = insertelement <16 x i8> %temp.vect714.i, i8 %1060, i32 9
  %temp.vect716.i = insertelement <16 x i8> %temp.vect715.i, i8 %1061, i32 10
  %temp.vect717.i = insertelement <16 x i8> %temp.vect716.i, i8 %1062, i32 11
  %temp.vect718.i = insertelement <16 x i8> %temp.vect717.i, i8 %1063, i32 12
  %temp.vect719.i = insertelement <16 x i8> %temp.vect718.i, i8 %1064, i32 13
  %temp.vect720.i = insertelement <16 x i8> %temp.vect719.i, i8 %1065, i32 14
  %temp.vect721.i = insertelement <16 x i8> %temp.vect720.i, i8 %1066, i32 15
  %1067 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar87.i = extractelement <4 x i8> %1067, i32 2
  %temp724.i = insertelement <16 x i8> undef, i8 %scalar87.i, i32 0
  %vector725.i = shufflevector <16 x i8> %temp724.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1068 = zext i8 %scalar87.i to i32
  %1069 = shl i32 %1068, 1
  %1070 = and i32 %1068, 128
  %1071 = xor i32 %1069, 27
  %1072 = icmp eq i32 %1070, 0
  %a.13.in.i = select i1 %1072, i32 %1069, i32 %1071
  %1073 = shl i32 %a.13.in.i, 1
  %1074 = and i32 %a.13.in.i, 128
  %1075 = xor i32 %1073, 27
  %1076 = icmp eq i32 %1074, 0
  %a.13.in.1.i = select i1 %1076, i32 %1073, i32 %1075
  %1077 = shl i32 %a.13.in.1.i, 1
  %1078 = and i32 %a.13.in.1.i, 128
  %1079 = xor i32 %1077, 27
  %1080 = icmp eq i32 %1078, 0
  %a.13.in.2.i = select i1 %1080, i32 %1077, i32 %1079
  %1081 = shl i32 %a.13.in.2.i, 1
  %1082 = and i32 %a.13.in.2.i, 128
  %1083 = xor i32 %1081, 27
  %1084 = icmp eq i32 %1082, 0
  %a.13.in.3.i = select i1 %1084, i32 %1081, i32 %1083
  %1085 = shl i32 %a.13.in.3.i, 1
  %1086 = and i32 %a.13.in.3.i, 128
  %1087 = xor i32 %1085, 27
  %1088 = icmp eq i32 %1086, 0
  %a.13.in.4.i = select i1 %1088, i32 %1085, i32 %1087
  %1089 = shl i32 %a.13.in.4.i, 1
  %1090 = and i32 %a.13.in.4.i, 128
  %1091 = xor i32 %1089, 27
  %1092 = icmp eq i32 %1090, 0
  %a.13.in.5.i = select i1 %1092, i32 %1089, i32 %1091
  %1093 = shl i32 %a.13.in.5.i, 1
  %1094 = lshr <16 x i8> %temp.vect721.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %1095 = zext <16 x i8> %1094 to <16 x i32>
  %1096 = zext <16 x i8> %temp.vect721.i to <16 x i32>
  %1097 = lshr <16 x i8> %temp.vect721.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %1098 = lshr <16 x i8> %temp.vect721.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %1099 = and <16 x i32> %1095, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1100 = and <16 x i32> %1096, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1101 = zext <16 x i8> %1097 to <16 x i32>
  %1102 = zext <16 x i8> %1098 to <16 x i32>
  %1103 = icmp eq <16 x i32> %1099, zeroinitializer
  %a.13.i = trunc i32 %a.13.in.i to i8
  %temp722.i = insertelement <16 x i8> undef, i8 %a.13.i, i32 0
  %vector723.i = shufflevector <16 x i8> %temp722.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1104 = icmp eq <16 x i32> %1100, zeroinitializer
  %1105 = and <16 x i32> %1101, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1106 = lshr <16 x i8> %temp.vect721.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1107 = lshr <16 x i8> %temp.vect721.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1108 = and <16 x i32> %1102, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1109 = select <16 x i1> %1103, <16 x i8> zeroinitializer, <16 x i8> %vector723.i
  %1110 = select <16 x i1> %1104, <16 x i8> zeroinitializer, <16 x i8> %vector725.i
  %a.13.1.i = trunc i32 %a.13.in.1.i to i8
  %temp727.i = insertelement <16 x i8> undef, i8 %a.13.1.i, i32 0
  %vector728.i = shufflevector <16 x i8> %temp727.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1111 = icmp eq <16 x i32> %1105, zeroinitializer
  %1112 = zext <16 x i8> %1106 to <16 x i32>
  %1113 = zext <16 x i8> %1107 to <16 x i32>
  %1114 = icmp eq <16 x i32> %1108, zeroinitializer
  %a.13.2.i = trunc i32 %a.13.in.2.i to i8
  %temp729.i = insertelement <16 x i8> undef, i8 %a.13.2.i, i32 0
  %vector730.i = shufflevector <16 x i8> %temp729.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..1726.i = xor <16 x i8> %1109, %1110
  %1115 = select <16 x i1> %1111, <16 x i8> zeroinitializer, <16 x i8> %vector728.i
  %1116 = and <16 x i32> %1112, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1117 = lshr <16 x i8> %temp.vect721.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1118 = and i32 %a.13.in.5.i, 128
  %1119 = and <16 x i32> %1113, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1120 = select <16 x i1> %1114, <16 x i8> zeroinitializer, <16 x i8> %vector730.i
  %p.13..2731.i = xor <16 x i8> %1115, %p.13..1726.i
  %a.13.3.i = trunc i32 %a.13.in.3.i to i8
  %temp733.i = insertelement <16 x i8> undef, i8 %a.13.3.i, i32 0
  %vector734.i = shufflevector <16 x i8> %temp733.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1121 = icmp eq <16 x i32> %1116, zeroinitializer
  %1122 = zext <16 x i8> %1117 to <16 x i32>
  %1123 = icmp eq i32 %1118, 0
  %1124 = xor i32 %1093, 27
  %1125 = icmp eq <16 x i32> %1119, zeroinitializer
  %a.13.4.i = trunc i32 %a.13.in.4.i to i8
  %temp735.i = insertelement <16 x i8> undef, i8 %a.13.4.i, i32 0
  %vector736.i = shufflevector <16 x i8> %temp735.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..3732.i = xor <16 x i8> %1120, %p.13..2731.i
  %1126 = select <16 x i1> %1121, <16 x i8> zeroinitializer, <16 x i8> %vector734.i
  %1127 = and <16 x i32> %1122, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.13.in.6.i = select i1 %1123, i32 %1093, i32 %1124
  %1128 = select <16 x i1> %1125, <16 x i8> zeroinitializer, <16 x i8> %vector736.i
  %p.13..4737.i = xor <16 x i8> %1126, %p.13..3732.i
  %a.13.5.i = trunc i32 %a.13.in.5.i to i8
  %temp739.i = insertelement <16 x i8> undef, i8 %a.13.5.i, i32 0
  %vector740.i = shufflevector <16 x i8> %temp739.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1129 = icmp eq <16 x i32> %1127, zeroinitializer
  %1130 = icmp sgt <16 x i8> %temp.vect721.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.13.6.i = trunc i32 %a.13.in.6.i to i8
  %temp741.i = insertelement <16 x i8> undef, i8 %a.13.6.i, i32 0
  %vector742.i = shufflevector <16 x i8> %temp741.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..5738.i = xor <16 x i8> %1128, %p.13..4737.i
  %1131 = select <16 x i1> %1129, <16 x i8> zeroinitializer, <16 x i8> %vector740.i
  %1132 = select <16 x i1> %1130, <16 x i8> zeroinitializer, <16 x i8> %vector742.i
  %p.13..6743.i = xor <16 x i8> %1131, %p.13..5738.i
  %p.13..7744.i = xor <16 x i8> %1132, %p.13..6743.i
  %1133 = and i64 %tmp77.i, 3
  %1134 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1635.i, i64 0, i64 %1133
  %1135 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1671.i, i64 0, i64 %1133
  %1136 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1707.i, i64 0, i64 %1133
  %1137 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1743.i, i64 0, i64 %1133
  %1138 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1779.i, i64 0, i64 %1133
  %1139 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1815.i, i64 0, i64 %1133
  %1140 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1851.i, i64 0, i64 %1133
  %1141 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1887.i, i64 0, i64 %1133
  %1142 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1923.i, i64 0, i64 %1133
  %1143 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1959.i, i64 0, i64 %1133
  %1144 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1995.i, i64 0, i64 %1133
  %1145 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2031.i, i64 0, i64 %1133
  %1146 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2067.i, i64 0, i64 %1133
  %1147 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2103.i, i64 0, i64 %1133
  %1148 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2139.i, i64 0, i64 %1133
  %1149 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType2175.i, i64 0, i64 %1133
  %1150 = load <4 x i8>* %1134, align 4
  %1151 = load <4 x i8>* %1135, align 4
  %1152 = load <4 x i8>* %1136, align 4
  %1153 = load <4 x i8>* %1137, align 4
  %1154 = load <4 x i8>* %1138, align 4
  %1155 = load <4 x i8>* %1139, align 4
  %1156 = load <4 x i8>* %1140, align 4
  %1157 = load <4 x i8>* %1141, align 4
  %1158 = load <4 x i8>* %1142, align 4
  %1159 = load <4 x i8>* %1143, align 4
  %1160 = load <4 x i8>* %1144, align 4
  %1161 = load <4 x i8>* %1145, align 4
  %1162 = load <4 x i8>* %1146, align 4
  %1163 = load <4 x i8>* %1147, align 4
  %1164 = load <4 x i8>* %1148, align 4
  %1165 = load <4 x i8>* %1149, align 4
  %1166 = extractelement <4 x i8> %1150, i32 0
  %1167 = extractelement <4 x i8> %1151, i32 0
  %1168 = extractelement <4 x i8> %1152, i32 0
  %1169 = extractelement <4 x i8> %1153, i32 0
  %1170 = extractelement <4 x i8> %1154, i32 0
  %1171 = extractelement <4 x i8> %1155, i32 0
  %1172 = extractelement <4 x i8> %1156, i32 0
  %1173 = extractelement <4 x i8> %1157, i32 0
  %1174 = extractelement <4 x i8> %1158, i32 0
  %1175 = extractelement <4 x i8> %1159, i32 0
  %1176 = extractelement <4 x i8> %1160, i32 0
  %1177 = extractelement <4 x i8> %1161, i32 0
  %1178 = extractelement <4 x i8> %1162, i32 0
  %1179 = extractelement <4 x i8> %1163, i32 0
  %1180 = extractelement <4 x i8> %1164, i32 0
  %1181 = extractelement <4 x i8> %1165, i32 0
  %temp.vect745.i = insertelement <16 x i8> undef, i8 %1166, i32 0
  %temp.vect746.i = insertelement <16 x i8> %temp.vect745.i, i8 %1167, i32 1
  %temp.vect747.i = insertelement <16 x i8> %temp.vect746.i, i8 %1168, i32 2
  %temp.vect748.i = insertelement <16 x i8> %temp.vect747.i, i8 %1169, i32 3
  %temp.vect749.i = insertelement <16 x i8> %temp.vect748.i, i8 %1170, i32 4
  %temp.vect750.i = insertelement <16 x i8> %temp.vect749.i, i8 %1171, i32 5
  %temp.vect751.i = insertelement <16 x i8> %temp.vect750.i, i8 %1172, i32 6
  %temp.vect752.i = insertelement <16 x i8> %temp.vect751.i, i8 %1173, i32 7
  %temp.vect753.i = insertelement <16 x i8> %temp.vect752.i, i8 %1174, i32 8
  %temp.vect754.i = insertelement <16 x i8> %temp.vect753.i, i8 %1175, i32 9
  %temp.vect755.i = insertelement <16 x i8> %temp.vect754.i, i8 %1176, i32 10
  %temp.vect756.i = insertelement <16 x i8> %temp.vect755.i, i8 %1177, i32 11
  %temp.vect757.i = insertelement <16 x i8> %temp.vect756.i, i8 %1178, i32 12
  %temp.vect758.i = insertelement <16 x i8> %temp.vect757.i, i8 %1179, i32 13
  %temp.vect759.i = insertelement <16 x i8> %temp.vect758.i, i8 %1180, i32 14
  %temp.vect760.i = insertelement <16 x i8> %temp.vect759.i, i8 %1181, i32 15
  %1182 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar96.i = extractelement <4 x i8> %1182, i32 3
  %temp763.i = insertelement <16 x i8> undef, i8 %scalar96.i, i32 0
  %vector764.i = shufflevector <16 x i8> %temp763.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1183 = zext i8 %scalar96.i to i32
  %1184 = shl i32 %1183, 1
  %1185 = and i32 %1183, 128
  %1186 = xor i32 %1184, 27
  %1187 = icmp eq i32 %1185, 0
  %a.15.in.i = select i1 %1187, i32 %1184, i32 %1186
  %1188 = shl i32 %a.15.in.i, 1
  %1189 = and i32 %a.15.in.i, 128
  %1190 = xor i32 %1188, 27
  %1191 = icmp eq i32 %1189, 0
  %a.15.in.1.i = select i1 %1191, i32 %1188, i32 %1190
  %1192 = shl i32 %a.15.in.1.i, 1
  %1193 = and i32 %a.15.in.1.i, 128
  %1194 = xor i32 %1192, 27
  %1195 = icmp eq i32 %1193, 0
  %a.15.in.2.i = select i1 %1195, i32 %1192, i32 %1194
  %1196 = shl i32 %a.15.in.2.i, 1
  %1197 = and i32 %a.15.in.2.i, 128
  %1198 = xor i32 %1196, 27
  %1199 = icmp eq i32 %1197, 0
  %a.15.in.3.i = select i1 %1199, i32 %1196, i32 %1198
  %1200 = shl i32 %a.15.in.3.i, 1
  %1201 = and i32 %a.15.in.3.i, 128
  %1202 = xor i32 %1200, 27
  %1203 = icmp eq i32 %1201, 0
  %a.15.in.4.i = select i1 %1203, i32 %1200, i32 %1202
  %1204 = shl i32 %a.15.in.4.i, 1
  %1205 = and i32 %a.15.in.4.i, 128
  %1206 = xor i32 %1204, 27
  %1207 = icmp eq i32 %1205, 0
  %a.15.in.5.i = select i1 %1207, i32 %1204, i32 %1206
  %1208 = shl i32 %a.15.in.5.i, 1
  %1209 = lshr <16 x i8> %temp.vect760.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %1210 = zext <16 x i8> %1209 to <16 x i32>
  %1211 = zext <16 x i8> %temp.vect760.i to <16 x i32>
  %1212 = lshr <16 x i8> %temp.vect760.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %1213 = lshr <16 x i8> %temp.vect760.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %1214 = and <16 x i32> %1210, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1215 = and <16 x i32> %1211, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1216 = zext <16 x i8> %1212 to <16 x i32>
  %1217 = zext <16 x i8> %1213 to <16 x i32>
  %1218 = icmp eq <16 x i32> %1214, zeroinitializer
  %a.15.i = trunc i32 %a.15.in.i to i8
  %temp761.i = insertelement <16 x i8> undef, i8 %a.15.i, i32 0
  %vector762.i = shufflevector <16 x i8> %temp761.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1219 = icmp eq <16 x i32> %1215, zeroinitializer
  %1220 = and <16 x i32> %1216, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1221 = lshr <16 x i8> %temp.vect760.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1222 = lshr <16 x i8> %temp.vect760.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1223 = and <16 x i32> %1217, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1224 = select <16 x i1> %1218, <16 x i8> zeroinitializer, <16 x i8> %vector762.i
  %1225 = select <16 x i1> %1219, <16 x i8> zeroinitializer, <16 x i8> %vector764.i
  %a.15.1.i = trunc i32 %a.15.in.1.i to i8
  %temp766.i = insertelement <16 x i8> undef, i8 %a.15.1.i, i32 0
  %vector767.i = shufflevector <16 x i8> %temp766.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1226 = icmp eq <16 x i32> %1220, zeroinitializer
  %1227 = zext <16 x i8> %1221 to <16 x i32>
  %1228 = zext <16 x i8> %1222 to <16 x i32>
  %1229 = icmp eq <16 x i32> %1223, zeroinitializer
  %a.15.2.i = trunc i32 %a.15.in.2.i to i8
  %temp768.i = insertelement <16 x i8> undef, i8 %a.15.2.i, i32 0
  %vector769.i = shufflevector <16 x i8> %temp768.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..1765.i = xor <16 x i8> %1224, %1225
  %1230 = select <16 x i1> %1226, <16 x i8> zeroinitializer, <16 x i8> %vector767.i
  %1231 = and <16 x i32> %1227, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1232 = lshr <16 x i8> %temp.vect760.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1233 = and i32 %a.15.in.5.i, 128
  %1234 = and <16 x i32> %1228, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1235 = select <16 x i1> %1229, <16 x i8> zeroinitializer, <16 x i8> %vector769.i
  %p.15..2770.i = xor <16 x i8> %1230, %p.15..1765.i
  %a.15.3.i = trunc i32 %a.15.in.3.i to i8
  %temp772.i = insertelement <16 x i8> undef, i8 %a.15.3.i, i32 0
  %vector773.i = shufflevector <16 x i8> %temp772.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1236 = icmp eq <16 x i32> %1231, zeroinitializer
  %1237 = zext <16 x i8> %1232 to <16 x i32>
  %1238 = icmp eq i32 %1233, 0
  %1239 = xor i32 %1208, 27
  %1240 = icmp eq <16 x i32> %1234, zeroinitializer
  %a.15.4.i = trunc i32 %a.15.in.4.i to i8
  %temp774.i = insertelement <16 x i8> undef, i8 %a.15.4.i, i32 0
  %vector775.i = shufflevector <16 x i8> %temp774.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..3771.i = xor <16 x i8> %1235, %p.15..2770.i
  %1241 = select <16 x i1> %1236, <16 x i8> zeroinitializer, <16 x i8> %vector773.i
  %1242 = and <16 x i32> %1237, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.15.in.6.i = select i1 %1238, i32 %1208, i32 %1239
  %1243 = select <16 x i1> %1240, <16 x i8> zeroinitializer, <16 x i8> %vector775.i
  %p.15..4776.i = xor <16 x i8> %1241, %p.15..3771.i
  %a.15.5.i = trunc i32 %a.15.in.5.i to i8
  %temp778.i = insertelement <16 x i8> undef, i8 %a.15.5.i, i32 0
  %vector779.i = shufflevector <16 x i8> %temp778.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1244 = icmp eq <16 x i32> %1242, zeroinitializer
  %1245 = icmp sgt <16 x i8> %temp.vect760.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.15.6.i = trunc i32 %a.15.in.6.i to i8
  %temp780.i = insertelement <16 x i8> undef, i8 %a.15.6.i, i32 0
  %vector781.i = shufflevector <16 x i8> %temp780.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..5777.i = xor <16 x i8> %1243, %p.15..4776.i
  %1246 = select <16 x i1> %1244, <16 x i8> zeroinitializer, <16 x i8> %vector779.i
  %1247 = select <16 x i1> %1245, <16 x i8> zeroinitializer, <16 x i8> %vector781.i
  %p.15..6782.i = xor <16 x i8> %1246, %p.15..5777.i
  %p.15..7783.i = xor <16 x i8> %1247, %p.15..6782.i
  %1248 = xor <16 x i8> %p.9..7666.i, %vectorPHI627.i
  store <16 x i8> %1248, <16 x i8>* %CastToValueType1575.i, align 16
  %1249 = xor <16 x i8> %p.11..7705.i, %vectorPHI626.i
  store <16 x i8> %1249, <16 x i8>* %CastToValueType1589.i, align 16
  %1250 = xor <16 x i8> %p.13..7744.i, %vectorPHI625.i
  store <16 x i8> %1250, <16 x i8>* %CastToValueType1603.i, align 16
  %1251 = xor <16 x i8> %p.15..7783.i, %vectorPHI624.i
  store <16 x i8> %1251, <16 x i8>* %CastToValueType1617.i, align 16
  %exitcond.i = icmp eq i64 %tmp.i, 3
  br i1 %exitcond.i, label %._crit_edge66.i, label %787

._crit_edge66.i:                                  ; preds = %787
  %"&(pSB[currWI].offset)1624.i" = add nuw i64 %CurrSBIndex..1.i, 1424
  %"&pSB[currWI].offset1625.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1624.i"
  %CastToValueType1626.i = bitcast i8* %"&pSB[currWI].offset1625.i" to <16 x i8>*
  %loadedValue1627.i = load <16 x i8>* %CastToValueType1626.i, align 16
  %extract847.i = extractelement <16 x i8> %loadedValue1627.i, i32 15
  %"&(pSB[currWI].offset)1610.i" = add nuw i64 %CurrSBIndex..1.i, 1408
  %"&pSB[currWI].offset1611.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1610.i"
  %CastToValueType1612.i = bitcast i8* %"&pSB[currWI].offset1611.i" to <16 x i8>*
  %loadedValue1613.i = load <16 x i8>* %CastToValueType1612.i, align 16
  %extract831.i = extractelement <16 x i8> %loadedValue1613.i, i32 15
  %"&(pSB[currWI].offset)1596.i" = add nuw i64 %CurrSBIndex..1.i, 1392
  %"&pSB[currWI].offset1597.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1596.i"
  %CastToValueType1598.i = bitcast i8* %"&pSB[currWI].offset1597.i" to <16 x i8>*
  %loadedValue1599.i = load <16 x i8>* %CastToValueType1598.i, align 16
  %extract815.i = extractelement <16 x i8> %loadedValue1599.i, i32 15
  %"&(pSB[currWI].offset)1582.i" = add nuw i64 %CurrSBIndex..1.i, 1376
  %"&pSB[currWI].offset1583.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1582.i"
  %CastToValueType1584.i = bitcast i8* %"&pSB[currWI].offset1583.i" to <16 x i8>*
  %loadedValue1585.i = load <16 x i8>* %CastToValueType1584.i, align 16
  %extract799.i = extractelement <16 x i8> %loadedValue1585.i, i32 15
  %1252 = insertelement <4 x i8> undef, i8 %extract799.i, i32 0
  %1253 = insertelement <4 x i8> %1252, i8 %extract815.i, i32 1
  %1254 = insertelement <4 x i8> %1253, i8 %extract831.i, i32 2
  %1255 = insertelement <4 x i8> %1254, i8 %extract847.i, i32 3
  %"&(pSB[currWI].offset)1018.i" = add nuw i64 %CurrSBIndex..1.i, 920
  %"&pSB[currWI].offset1019.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1018.i"
  %CastToValueType1020.i = bitcast i8* %"&pSB[currWI].offset1019.i" to <4 x i8> addrspace(3)**
  %loadedValue1021.i = load <4 x i8> addrspace(3)** %CastToValueType1020.i, align 8
  store <4 x i8> %1255, <4 x i8> addrspace(3)* %loadedValue1021.i, align 4
  %"&(pSB[currWI].offset)1469.i" = add nuw i64 %CurrSBIndex..1.i, 1140
  %"&pSB[currWI].offset1470.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1469.i"
  %CastToValueType1471.i = bitcast i8* %"&pSB[currWI].offset1470.i" to i32*
  %loadedValue1472.i = load i32* %CastToValueType1471.i, align 4
  %indvar.next80.i = add i32 %loadedValue1472.i, 1
  %"&(pSB[currWI].offset)1629.i" = add nuw i64 %CurrSBIndex..1.i, 1440
  %"&pSB[currWI].offset1630.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1629.i"
  %CastToValueType1631.i = bitcast i8* %"&pSB[currWI].offset1630.i" to i32*
  store i32 %indvar.next80.i, i32* %CastToValueType1631.i, align 4
  %"&(pSB[currWI].offset)1577.i" = add nuw i64 %CurrSBIndex..1.i, 1376
  %"&pSB[currWI].offset1578.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1577.i"
  %CastToValueType1579.i = bitcast i8* %"&pSB[currWI].offset1578.i" to <16 x i8>*
  %loadedValue1580.i = load <16 x i8>* %CastToValueType1579.i, align 16
  %"&(pSB[currWI].offset)1591.i" = add nuw i64 %CurrSBIndex..1.i, 1392
  %"&pSB[currWI].offset1592.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1591.i"
  %CastToValueType1593.i = bitcast i8* %"&pSB[currWI].offset1592.i" to <16 x i8>*
  %loadedValue1594.i = load <16 x i8>* %CastToValueType1593.i, align 16
  %"&(pSB[currWI].offset)1605.i" = add nuw i64 %CurrSBIndex..1.i, 1408
  %"&pSB[currWI].offset1606.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1605.i"
  %CastToValueType1607.i = bitcast i8* %"&pSB[currWI].offset1606.i" to <16 x i8>*
  %loadedValue1608.i = load <16 x i8>* %CastToValueType1607.i, align 16
  %"&(pSB[currWI].offset)1619.i" = add nuw i64 %CurrSBIndex..1.i, 1424
  %"&pSB[currWI].offset1620.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1619.i"
  %CastToValueType1621.i = bitcast i8* %"&pSB[currWI].offset1620.i" to <16 x i8>*
  %loadedValue1622.i = load <16 x i8>* %CastToValueType1621.i, align 16
  br label %194

"Barrier BB985.i":                                ; preds = %shiftRowsInv.exit.i
  %"&(pSB[currWI].offset)1524.i" = add nuw i64 %CurrSBIndex..2.i, 1284
  %"&pSB[currWI].offset1525.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1524.i"
  %CastToValueType1526.i = bitcast i8* %"&pSB[currWI].offset1525.i" to <4 x i8>*
  %loadedValue1527.i = load <4 x i8>* %CastToValueType1526.i, align 4
  %1256 = extractelement <4 x i8> %loadedValue1527.i, i32 3
  %"&(pSB[currWI].offset)1529.i" = add nuw i64 %CurrSBIndex..2.i, 1284
  %"&pSB[currWI].offset1530.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1529.i"
  %CastToValueType1531.i = bitcast i8* %"&pSB[currWI].offset1530.i" to <4 x i8>*
  %loadedValue1532.i = load <4 x i8>* %CastToValueType1531.i, align 4
  %1257 = extractelement <4 x i8> %loadedValue1532.i, i32 2
  %"&(pSB[currWI].offset)1534.i" = add nuw i64 %CurrSBIndex..2.i, 1284
  %"&pSB[currWI].offset1535.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1534.i"
  %CastToValueType1536.i = bitcast i8* %"&pSB[currWI].offset1535.i" to <4 x i8>*
  %loadedValue1537.i = load <4 x i8>* %CastToValueType1536.i, align 4
  %1258 = extractelement <4 x i8> %loadedValue1537.i, i32 1
  %"&(pSB[currWI].offset)1539.i" = add nuw i64 %CurrSBIndex..2.i, 1284
  %"&pSB[currWI].offset1540.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1539.i"
  %CastToValueType1541.i = bitcast i8* %"&pSB[currWI].offset1540.i" to <4 x i8>*
  %loadedValue1542.i = load <4 x i8>* %CastToValueType1541.i, align 4
  %1259 = extractelement <4 x i8> %loadedValue1542.i, i32 0
  %"&(pSB[currWI].offset)1009.i" = add nuw i64 %CurrSBIndex..2.i, 912
  %"&pSB[currWI].offset1010.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1009.i"
  %CastToValueType1011.i = bitcast i8* %"&pSB[currWI].offset1010.i" to i64*
  %loadedValue1012.i = load i64* %CastToValueType1011.i, align 8
  %1260 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %loadedValue1012.i
  %1261 = load <4 x i8> addrspace(1)* %1260, align 4
  %scalar101.i = extractelement <4 x i8> %1261, i32 0
  %scalar102.i = extractelement <4 x i8> %1261, i32 1
  %scalar103.i = extractelement <4 x i8> %1261, i32 2
  %scalar104.i = extractelement <4 x i8> %1261, i32 3
  %extract935.i = xor i8 %1259, %scalar101.i
  %extract951.i = xor i8 %1258, %scalar102.i
  %extract967.i = xor i8 %1257, %scalar103.i
  %extract983.i = xor i8 %1256, %scalar104.i
  %1262 = insertelement <4 x i8> undef, i8 %extract935.i, i32 0
  %1263 = insertelement <4 x i8> %1262, i8 %extract951.i, i32 1
  %1264 = insertelement <4 x i8> %1263, i8 %extract967.i, i32 2
  %1265 = insertelement <4 x i8> %1264, i8 %extract983.i, i32 3
  %"&(pSB[currWI].offset)1000.i" = add nuw i64 %CurrSBIndex..2.i, 904
  %"&pSB[currWI].offset1001.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1000.i"
  %CastToValueType1002.i = bitcast i8* %"&pSB[currWI].offset1001.i" to i64*
  %loadedValue1003.i = load i64* %CastToValueType1002.i, align 8
  %1266 = getelementptr inbounds <4 x i8> addrspace(1)* %1, i64 %loadedValue1003.i
  store <4 x i8> %1265, <4 x i8> addrspace(1)* %1266, align 4
  %check.WI.iter2224.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter2224.i, label %thenBB2221.i, label %____Vectorized_.AESDecrypt_separated_args.exit

thenBB2221.i:                                     ; preds = %"Barrier BB985.i"
  %"CurrWI++2225.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride2227.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond1.i = icmp eq i32 %currBarrier.1.i, 8
  br i1 %cond1.i, label %SyncBB2211.i, label %SyncBB.i

____Vectorized_.AESDecrypt_separated_args.exit:   ; preds = %"Barrier BB985.i"
  ret void
}

define void @__Vectorized_.AESEncrypt(i8* %pBuffer) {
entry:
  %0 = bitcast i8* %pBuffer to <4 x i8> addrspace(1)**
  %1 = load <4 x i8> addrspace(1)** %0, align 8
  %2 = getelementptr i8* %pBuffer, i64 8
  %3 = bitcast i8* %2 to <4 x i8> addrspace(1)**
  %4 = load <4 x i8> addrspace(1)** %3, align 8
  %5 = getelementptr i8* %pBuffer, i64 16
  %6 = bitcast i8* %5 to <4 x i8> addrspace(1)**
  %7 = load <4 x i8> addrspace(1)** %6, align 8
  %8 = getelementptr i8* %pBuffer, i64 24
  %9 = bitcast i8* %8 to i8 addrspace(1)**
  %10 = load i8 addrspace(1)** %9, align 8
  %11 = getelementptr i8* %pBuffer, i64 32
  %12 = bitcast i8* %11 to <4 x i8> addrspace(3)**
  %13 = load <4 x i8> addrspace(3)** %12, align 8
  %14 = getelementptr i8* %pBuffer, i64 40
  %15 = bitcast i8* %14 to <4 x i8> addrspace(3)**
  %16 = load <4 x i8> addrspace(3)** %15, align 8
  %17 = getelementptr i8* %pBuffer, i64 48
  %18 = bitcast i8* %17 to i32*
  %19 = load i32* %18, align 4
  %20 = getelementptr i8* %pBuffer, i64 52
  %21 = bitcast i8* %20 to i32*
  %22 = load i32* %21, align 4
  %23 = getelementptr i8* %pBuffer, i64 72
  %24 = bitcast i8* %23 to i64**
  %25 = load i64** %24, align 8
  %26 = getelementptr i8* %pBuffer, i64 88
  %27 = bitcast i8* %26 to %struct.PaddedDimId**
  %28 = load %struct.PaddedDimId** %27, align 8
  %29 = getelementptr i8* %pBuffer, i64 104
  %30 = bitcast i8* %29 to i64*
  %31 = load i64* %30, align 8
  %32 = getelementptr i8* %pBuffer, i64 112
  %33 = bitcast i8* %32 to i8**
  %34 = load i8** %33, align 8
  %tmp81.i = icmp ugt i32 %22, 1
  %rounds.op.i = add i32 %22, -1
  %tmp82.i = select i1 %tmp81.i, i32 %rounds.op.i, i32 0
  %35 = shl i32 %22, 2
  br label %SyncBB1715.i

SyncBB1715.i:                                     ; preds = %thenBB1726.i, %thenBB.i, %entry
  %CurrSBIndex..0.i = phi i64 [ 0, %entry ], [ %"loadedCurrSB+Stride1732.i", %thenBB1726.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ]
  %currBarrier.2.i = phi i32 [ 14, %entry ], [ %currBarrier.1.i, %thenBB1726.i ], [ %currBarrier.1.i, %thenBB.i ]
  %CurrWI..0.i = phi i64 [ 0, %entry ], [ %"CurrWI++1730.i", %thenBB1726.i ], [ %"CurrWI++.i", %thenBB.i ]
  %36 = load i64* %25, align 8
  %37 = trunc i64 %36 to i32
  %38 = getelementptr i64* %25, i64 1
  %39 = load i64* %38, align 8
  %40 = trunc i64 %39 to i32
  %41 = getelementptr %struct.PaddedDimId* %28, i64 %CurrWI..0.i, i32 0, i64 1
  %42 = load i64* %41, align 8
  %43 = trunc i64 %42 to i32
  %"&(pSB[currWI].offset).i" = add nuw i64 %CurrSBIndex..0.i, 272
  %"&pSB[currWI].offset.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset).i"
  %CastToValueType.i = bitcast i8* %"&pSB[currWI].offset.i" to i32*
  store i32 %43, i32* %CastToValueType.i, align 4
  %44 = mul i32 %40, %19
  %45 = shl i32 %37, 2
  %46 = add i32 %44, %45
  %47 = and i32 %46, -4
  %48 = add i32 %47, %43
  %"&(pSB[currWI].offset)1170.i" = add nuw i64 %CurrSBIndex..0.i, 640
  %"&pSB[currWI].offset1171.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1170.i"
  %49 = bitcast i8* %"&pSB[currWI].offset1171.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1206.i" = add nuw i64 %CurrSBIndex..0.i, 656
  %"&pSB[currWI].offset1207.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1206.i"
  %50 = bitcast i8* %"&pSB[currWI].offset1207.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1242.i" = add nuw i64 %CurrSBIndex..0.i, 672
  %"&pSB[currWI].offset1243.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1242.i"
  %51 = bitcast i8* %"&pSB[currWI].offset1243.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1278.i" = add nuw i64 %CurrSBIndex..0.i, 688
  %"&pSB[currWI].offset1279.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1278.i"
  %52 = bitcast i8* %"&pSB[currWI].offset1279.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1314.i" = add nuw i64 %CurrSBIndex..0.i, 704
  %"&pSB[currWI].offset1315.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1314.i"
  %53 = bitcast i8* %"&pSB[currWI].offset1315.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1350.i" = add nuw i64 %CurrSBIndex..0.i, 720
  %"&pSB[currWI].offset1351.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1350.i"
  %54 = bitcast i8* %"&pSB[currWI].offset1351.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1386.i" = add nuw i64 %CurrSBIndex..0.i, 736
  %"&pSB[currWI].offset1387.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1386.i"
  %55 = bitcast i8* %"&pSB[currWI].offset1387.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1422.i" = add nuw i64 %CurrSBIndex..0.i, 752
  %"&pSB[currWI].offset1423.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1422.i"
  %56 = bitcast i8* %"&pSB[currWI].offset1423.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1458.i" = add nuw i64 %CurrSBIndex..0.i, 768
  %"&pSB[currWI].offset1459.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1458.i"
  %57 = bitcast i8* %"&pSB[currWI].offset1459.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1494.i" = add nuw i64 %CurrSBIndex..0.i, 784
  %"&pSB[currWI].offset1495.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1494.i"
  %58 = bitcast i8* %"&pSB[currWI].offset1495.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1530.i" = add nuw i64 %CurrSBIndex..0.i, 800
  %"&pSB[currWI].offset1531.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1530.i"
  %59 = bitcast i8* %"&pSB[currWI].offset1531.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1566.i" = add nuw i64 %CurrSBIndex..0.i, 816
  %"&pSB[currWI].offset1567.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1566.i"
  %60 = bitcast i8* %"&pSB[currWI].offset1567.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1602.i" = add nuw i64 %CurrSBIndex..0.i, 832
  %"&pSB[currWI].offset1603.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1602.i"
  %61 = bitcast i8* %"&pSB[currWI].offset1603.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1638.i" = add nuw i64 %CurrSBIndex..0.i, 848
  %"&pSB[currWI].offset1639.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1638.i"
  %62 = bitcast i8* %"&pSB[currWI].offset1639.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1674.i" = add nuw i64 %CurrSBIndex..0.i, 864
  %"&pSB[currWI].offset1675.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1674.i"
  %63 = bitcast i8* %"&pSB[currWI].offset1675.i" to <4 x i8>*
  %"&(pSB[currWI].offset)1710.i" = add nuw i64 %CurrSBIndex..0.i, 880
  %"&pSB[currWI].offset1711.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1710.i"
  %64 = bitcast i8* %"&pSB[currWI].offset1711.i" to <4 x i8>*
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %49, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %50, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %51, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %52, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %53, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %54, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %55, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %56, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %57, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %58, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %59, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %60, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %61, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %62, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %63, align 16
  store <4 x i8> <i8 2, i8 0, i8 0, i8 0>, <4 x i8>* %64, align 16
  %"&pSB[currWI].offset1167.sum.i" = add i64 %CurrSBIndex..0.i, 644
  %65 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1167.sum.i"
  %66 = bitcast i8* %65 to <4 x i8>*
  %"&pSB[currWI].offset1203.sum.i" = add i64 %CurrSBIndex..0.i, 660
  %67 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1203.sum.i"
  %68 = bitcast i8* %67 to <4 x i8>*
  %"&pSB[currWI].offset1239.sum.i" = add i64 %CurrSBIndex..0.i, 676
  %69 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1239.sum.i"
  %70 = bitcast i8* %69 to <4 x i8>*
  %"&pSB[currWI].offset1275.sum.i" = add i64 %CurrSBIndex..0.i, 692
  %71 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1275.sum.i"
  %72 = bitcast i8* %71 to <4 x i8>*
  %"&pSB[currWI].offset1311.sum.i" = add i64 %CurrSBIndex..0.i, 708
  %73 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1311.sum.i"
  %74 = bitcast i8* %73 to <4 x i8>*
  %"&pSB[currWI].offset1347.sum.i" = add i64 %CurrSBIndex..0.i, 724
  %75 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1347.sum.i"
  %76 = bitcast i8* %75 to <4 x i8>*
  %"&pSB[currWI].offset1383.sum.i" = add i64 %CurrSBIndex..0.i, 740
  %77 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1383.sum.i"
  %78 = bitcast i8* %77 to <4 x i8>*
  %"&pSB[currWI].offset1419.sum.i" = add i64 %CurrSBIndex..0.i, 756
  %79 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1419.sum.i"
  %80 = bitcast i8* %79 to <4 x i8>*
  %"&pSB[currWI].offset1455.sum.i" = add i64 %CurrSBIndex..0.i, 772
  %81 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1455.sum.i"
  %82 = bitcast i8* %81 to <4 x i8>*
  %"&pSB[currWI].offset1491.sum.i" = add i64 %CurrSBIndex..0.i, 788
  %83 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1491.sum.i"
  %84 = bitcast i8* %83 to <4 x i8>*
  %"&pSB[currWI].offset1527.sum.i" = add i64 %CurrSBIndex..0.i, 804
  %85 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1527.sum.i"
  %86 = bitcast i8* %85 to <4 x i8>*
  %"&pSB[currWI].offset1563.sum.i" = add i64 %CurrSBIndex..0.i, 820
  %87 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1563.sum.i"
  %88 = bitcast i8* %87 to <4 x i8>*
  %"&pSB[currWI].offset1599.sum.i" = add i64 %CurrSBIndex..0.i, 836
  %89 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1599.sum.i"
  %90 = bitcast i8* %89 to <4 x i8>*
  %"&pSB[currWI].offset1635.sum.i" = add i64 %CurrSBIndex..0.i, 852
  %91 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1635.sum.i"
  %92 = bitcast i8* %91 to <4 x i8>*
  %"&pSB[currWI].offset1671.sum.i" = add i64 %CurrSBIndex..0.i, 868
  %93 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1671.sum.i"
  %94 = bitcast i8* %93 to <4 x i8>*
  %"&pSB[currWI].offset1707.sum.i" = add i64 %CurrSBIndex..0.i, 884
  %95 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1707.sum.i"
  %96 = bitcast i8* %95 to <4 x i8>*
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %66, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %68, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %70, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %72, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %74, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %76, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %78, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %80, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %82, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %84, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %86, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %88, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %90, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %92, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %94, align 4
  store <4 x i8> <i8 3, i8 0, i8 0, i8 0>, <4 x i8>* %96, align 4
  %"&pSB[currWI].offset1163.sum.i" = add i64 %CurrSBIndex..0.i, 648
  %97 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1163.sum.i"
  %98 = bitcast i8* %97 to <4 x i8>*
  %"&pSB[currWI].offset1199.sum.i" = add i64 %CurrSBIndex..0.i, 664
  %99 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1199.sum.i"
  %100 = bitcast i8* %99 to <4 x i8>*
  %"&pSB[currWI].offset1235.sum.i" = add i64 %CurrSBIndex..0.i, 680
  %101 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1235.sum.i"
  %102 = bitcast i8* %101 to <4 x i8>*
  %"&pSB[currWI].offset1271.sum.i" = add i64 %CurrSBIndex..0.i, 696
  %103 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1271.sum.i"
  %104 = bitcast i8* %103 to <4 x i8>*
  %"&pSB[currWI].offset1307.sum.i" = add i64 %CurrSBIndex..0.i, 712
  %105 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1307.sum.i"
  %106 = bitcast i8* %105 to <4 x i8>*
  %"&pSB[currWI].offset1343.sum.i" = add i64 %CurrSBIndex..0.i, 728
  %107 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1343.sum.i"
  %108 = bitcast i8* %107 to <4 x i8>*
  %"&pSB[currWI].offset1379.sum.i" = add i64 %CurrSBIndex..0.i, 744
  %109 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1379.sum.i"
  %110 = bitcast i8* %109 to <4 x i8>*
  %"&pSB[currWI].offset1415.sum.i" = add i64 %CurrSBIndex..0.i, 760
  %111 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1415.sum.i"
  %112 = bitcast i8* %111 to <4 x i8>*
  %"&pSB[currWI].offset1451.sum.i" = add i64 %CurrSBIndex..0.i, 776
  %113 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1451.sum.i"
  %114 = bitcast i8* %113 to <4 x i8>*
  %"&pSB[currWI].offset1487.sum.i" = add i64 %CurrSBIndex..0.i, 792
  %115 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1487.sum.i"
  %116 = bitcast i8* %115 to <4 x i8>*
  %"&pSB[currWI].offset1523.sum.i" = add i64 %CurrSBIndex..0.i, 808
  %117 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1523.sum.i"
  %118 = bitcast i8* %117 to <4 x i8>*
  %"&pSB[currWI].offset1559.sum.i" = add i64 %CurrSBIndex..0.i, 824
  %119 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1559.sum.i"
  %120 = bitcast i8* %119 to <4 x i8>*
  %"&pSB[currWI].offset1595.sum.i" = add i64 %CurrSBIndex..0.i, 840
  %121 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1595.sum.i"
  %122 = bitcast i8* %121 to <4 x i8>*
  %"&pSB[currWI].offset1631.sum.i" = add i64 %CurrSBIndex..0.i, 856
  %123 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1631.sum.i"
  %124 = bitcast i8* %123 to <4 x i8>*
  %"&pSB[currWI].offset1667.sum.i" = add i64 %CurrSBIndex..0.i, 872
  %125 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1667.sum.i"
  %126 = bitcast i8* %125 to <4 x i8>*
  %"&pSB[currWI].offset1703.sum.i" = add i64 %CurrSBIndex..0.i, 888
  %127 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1703.sum.i"
  %128 = bitcast i8* %127 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %98, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %100, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %102, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %104, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %106, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %108, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %110, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %112, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %114, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %116, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %118, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %120, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %122, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %124, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %126, align 8
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %128, align 8
  %"&pSB[currWI].offset1159.sum.i" = add i64 %CurrSBIndex..0.i, 652
  %129 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1159.sum.i"
  %130 = bitcast i8* %129 to <4 x i8>*
  %"&pSB[currWI].offset1195.sum.i" = add i64 %CurrSBIndex..0.i, 668
  %131 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1195.sum.i"
  %132 = bitcast i8* %131 to <4 x i8>*
  %"&pSB[currWI].offset1231.sum.i" = add i64 %CurrSBIndex..0.i, 684
  %133 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1231.sum.i"
  %134 = bitcast i8* %133 to <4 x i8>*
  %"&pSB[currWI].offset1267.sum.i" = add i64 %CurrSBIndex..0.i, 700
  %135 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1267.sum.i"
  %136 = bitcast i8* %135 to <4 x i8>*
  %"&pSB[currWI].offset1303.sum.i" = add i64 %CurrSBIndex..0.i, 716
  %137 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1303.sum.i"
  %138 = bitcast i8* %137 to <4 x i8>*
  %"&pSB[currWI].offset1339.sum.i" = add i64 %CurrSBIndex..0.i, 732
  %139 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1339.sum.i"
  %140 = bitcast i8* %139 to <4 x i8>*
  %"&pSB[currWI].offset1375.sum.i" = add i64 %CurrSBIndex..0.i, 748
  %141 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1375.sum.i"
  %142 = bitcast i8* %141 to <4 x i8>*
  %"&pSB[currWI].offset1411.sum.i" = add i64 %CurrSBIndex..0.i, 764
  %143 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1411.sum.i"
  %144 = bitcast i8* %143 to <4 x i8>*
  %"&pSB[currWI].offset1447.sum.i" = add i64 %CurrSBIndex..0.i, 780
  %145 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1447.sum.i"
  %146 = bitcast i8* %145 to <4 x i8>*
  %"&pSB[currWI].offset1483.sum.i" = add i64 %CurrSBIndex..0.i, 796
  %147 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1483.sum.i"
  %148 = bitcast i8* %147 to <4 x i8>*
  %"&pSB[currWI].offset1519.sum.i" = add i64 %CurrSBIndex..0.i, 812
  %149 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1519.sum.i"
  %150 = bitcast i8* %149 to <4 x i8>*
  %"&pSB[currWI].offset1555.sum.i" = add i64 %CurrSBIndex..0.i, 828
  %151 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1555.sum.i"
  %152 = bitcast i8* %151 to <4 x i8>*
  %"&pSB[currWI].offset1591.sum.i" = add i64 %CurrSBIndex..0.i, 844
  %153 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1591.sum.i"
  %154 = bitcast i8* %153 to <4 x i8>*
  %"&pSB[currWI].offset1627.sum.i" = add i64 %CurrSBIndex..0.i, 860
  %155 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1627.sum.i"
  %156 = bitcast i8* %155 to <4 x i8>*
  %"&pSB[currWI].offset1663.sum.i" = add i64 %CurrSBIndex..0.i, 876
  %157 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1663.sum.i"
  %158 = bitcast i8* %157 to <4 x i8>*
  %"&pSB[currWI].offset1699.sum.i" = add i64 %CurrSBIndex..0.i, 892
  %159 = getelementptr inbounds i8* %34, i64 %"&pSB[currWI].offset1699.sum.i"
  %160 = bitcast i8* %159 to <4 x i8>*
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %130, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %132, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %134, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %136, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %138, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %140, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %142, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %144, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %146, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %148, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %150, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %152, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %154, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %156, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %158, align 4
  store <4 x i8> <i8 1, i8 0, i8 0, i8 0>, <4 x i8>* %160, align 4
  %161 = zext i32 %48 to i64
  %"&(pSB[currWI].offset)524.i" = add nuw i64 %CurrSBIndex..0.i, 280
  %"&pSB[currWI].offset525.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)524.i"
  %CastToValueType526.i = bitcast i8* %"&pSB[currWI].offset525.i" to i64*
  store i64 %161, i64* %CastToValueType526.i, align 8
  %162 = getelementptr inbounds <4 x i8> addrspace(1)* %4, i64 %161
  %163 = load <4 x i8> addrspace(1)* %162, align 4
  %scalar.i = extractelement <4 x i8> %163, i32 0
  %scalar2.i = extractelement <4 x i8> %163, i32 1
  %scalar3.i = extractelement <4 x i8> %163, i32 2
  %scalar4.i = extractelement <4 x i8> %163, i32 3
  %164 = and i64 %42, 4294967295
  %165 = getelementptr inbounds <4 x i8> addrspace(3)* %13, i64 %164
  %"&(pSB[currWI].offset)533.i" = add nuw i64 %CurrSBIndex..0.i, 288
  %"&pSB[currWI].offset534.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)533.i"
  %CastToValueType535.i = bitcast i8* %"&pSB[currWI].offset534.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %165, <4 x i8> addrspace(3)** %CastToValueType535.i, align 8
  store <4 x i8> %163, <4 x i8> addrspace(3)* %165, align 4
  %166 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %164
  %167 = load <4 x i8> addrspace(1)* %166, align 4
  %scalar5.i = extractelement <4 x i8> %167, i32 0
  %scalar6.i = extractelement <4 x i8> %167, i32 1
  %scalar7.i = extractelement <4 x i8> %167, i32 2
  %scalar8.i = extractelement <4 x i8> %167, i32 3
  %168 = xor i8 %scalar.i, %scalar5.i
  %"&(pSB[currWI].offset)547.i" = add nuw i64 %CurrSBIndex..0.i, 296
  %"&pSB[currWI].offset548.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)547.i"
  store i8 %168, i8* %"&pSB[currWI].offset548.i", align 1
  %169 = xor i8 %scalar2.i, %scalar6.i
  %"&(pSB[currWI].offset)551.i" = add nuw i64 %CurrSBIndex..0.i, 297
  %"&pSB[currWI].offset552.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)551.i"
  store i8 %169, i8* %"&pSB[currWI].offset552.i", align 1
  %170 = xor i8 %scalar3.i, %scalar7.i
  %"&(pSB[currWI].offset)555.i" = add nuw i64 %CurrSBIndex..0.i, 298
  %"&pSB[currWI].offset556.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)555.i"
  store i8 %170, i8* %"&pSB[currWI].offset556.i", align 1
  %171 = xor i8 %scalar4.i, %scalar8.i
  %"&(pSB[currWI].offset)559.i" = add nuw i64 %CurrSBIndex..0.i, 299
  %"&pSB[currWI].offset560.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)559.i"
  store i8 %171, i8* %"&pSB[currWI].offset560.i", align 1
  %temp.vect.i = insertelement <4 x i8> undef, i8 %168, i32 0
  %temp.vect105.i = insertelement <4 x i8> %temp.vect.i, i8 %169, i32 1
  %temp.vect106.i = insertelement <4 x i8> %temp.vect105.i, i8 %170, i32 2
  %temp.vect107.i = insertelement <4 x i8> %temp.vect106.i, i8 %171, i32 3
  store <4 x i8> %temp.vect107.i, <4 x i8> addrspace(3)* %165, align 4
  %172 = sub i32 0, %43
  %173 = and i32 %172, 3
  %174 = zext i32 %173 to i64
  %"&(pSB[currWI].offset)1154.i" = add nuw i64 %CurrSBIndex..0.i, 640
  %"&pSB[currWI].offset1155.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1154.i"
  %CastToValueType1156.i = bitcast i8* %"&pSB[currWI].offset1155.i" to [4 x <4 x i8>]*
  %175 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1156.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)563.i" = add nuw i64 %CurrSBIndex..0.i, 304
  %"&pSB[currWI].offset564.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)563.i"
  %CastToValueType565.i = bitcast i8* %"&pSB[currWI].offset564.i" to <4 x i8>**
  store <4 x i8>* %175, <4 x i8>** %CastToValueType565.i, align 8
  %"&(pSB[currWI].offset)1190.i" = add nuw i64 %CurrSBIndex..0.i, 656
  %"&pSB[currWI].offset1191.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1190.i"
  %CastToValueType1192.i = bitcast i8* %"&pSB[currWI].offset1191.i" to [4 x <4 x i8>]*
  %176 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1192.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)587.i" = add nuw i64 %CurrSBIndex..0.i, 312
  %"&pSB[currWI].offset588.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)587.i"
  %CastToValueType589.i = bitcast i8* %"&pSB[currWI].offset588.i" to <4 x i8>**
  store <4 x i8>* %176, <4 x i8>** %CastToValueType589.i, align 8
  %"&(pSB[currWI].offset)1226.i" = add nuw i64 %CurrSBIndex..0.i, 672
  %"&pSB[currWI].offset1227.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1226.i"
  %CastToValueType1228.i = bitcast i8* %"&pSB[currWI].offset1227.i" to [4 x <4 x i8>]*
  %177 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1228.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)611.i" = add nuw i64 %CurrSBIndex..0.i, 320
  %"&pSB[currWI].offset612.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)611.i"
  %CastToValueType613.i = bitcast i8* %"&pSB[currWI].offset612.i" to <4 x i8>**
  store <4 x i8>* %177, <4 x i8>** %CastToValueType613.i, align 8
  %"&(pSB[currWI].offset)1262.i" = add nuw i64 %CurrSBIndex..0.i, 688
  %"&pSB[currWI].offset1263.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1262.i"
  %CastToValueType1264.i = bitcast i8* %"&pSB[currWI].offset1263.i" to [4 x <4 x i8>]*
  %178 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1264.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)635.i" = add nuw i64 %CurrSBIndex..0.i, 328
  %"&pSB[currWI].offset636.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)635.i"
  %CastToValueType637.i = bitcast i8* %"&pSB[currWI].offset636.i" to <4 x i8>**
  store <4 x i8>* %178, <4 x i8>** %CastToValueType637.i, align 8
  %"&(pSB[currWI].offset)1298.i" = add nuw i64 %CurrSBIndex..0.i, 704
  %"&pSB[currWI].offset1299.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1298.i"
  %CastToValueType1300.i = bitcast i8* %"&pSB[currWI].offset1299.i" to [4 x <4 x i8>]*
  %179 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1300.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)659.i" = add nuw i64 %CurrSBIndex..0.i, 336
  %"&pSB[currWI].offset660.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)659.i"
  %CastToValueType661.i = bitcast i8* %"&pSB[currWI].offset660.i" to <4 x i8>**
  store <4 x i8>* %179, <4 x i8>** %CastToValueType661.i, align 8
  %"&(pSB[currWI].offset)1334.i" = add nuw i64 %CurrSBIndex..0.i, 720
  %"&pSB[currWI].offset1335.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1334.i"
  %CastToValueType1336.i = bitcast i8* %"&pSB[currWI].offset1335.i" to [4 x <4 x i8>]*
  %180 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1336.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)683.i" = add nuw i64 %CurrSBIndex..0.i, 344
  %"&pSB[currWI].offset684.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)683.i"
  %CastToValueType685.i = bitcast i8* %"&pSB[currWI].offset684.i" to <4 x i8>**
  store <4 x i8>* %180, <4 x i8>** %CastToValueType685.i, align 8
  %"&(pSB[currWI].offset)1370.i" = add nuw i64 %CurrSBIndex..0.i, 736
  %"&pSB[currWI].offset1371.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1370.i"
  %CastToValueType1372.i = bitcast i8* %"&pSB[currWI].offset1371.i" to [4 x <4 x i8>]*
  %181 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1372.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)707.i" = add nuw i64 %CurrSBIndex..0.i, 352
  %"&pSB[currWI].offset708.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)707.i"
  %CastToValueType709.i = bitcast i8* %"&pSB[currWI].offset708.i" to <4 x i8>**
  store <4 x i8>* %181, <4 x i8>** %CastToValueType709.i, align 8
  %"&(pSB[currWI].offset)1406.i" = add nuw i64 %CurrSBIndex..0.i, 752
  %"&pSB[currWI].offset1407.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1406.i"
  %CastToValueType1408.i = bitcast i8* %"&pSB[currWI].offset1407.i" to [4 x <4 x i8>]*
  %182 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1408.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)731.i" = add nuw i64 %CurrSBIndex..0.i, 360
  %"&pSB[currWI].offset732.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)731.i"
  %CastToValueType733.i = bitcast i8* %"&pSB[currWI].offset732.i" to <4 x i8>**
  store <4 x i8>* %182, <4 x i8>** %CastToValueType733.i, align 8
  %"&(pSB[currWI].offset)1442.i" = add nuw i64 %CurrSBIndex..0.i, 768
  %"&pSB[currWI].offset1443.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1442.i"
  %CastToValueType1444.i = bitcast i8* %"&pSB[currWI].offset1443.i" to [4 x <4 x i8>]*
  %183 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1444.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)755.i" = add nuw i64 %CurrSBIndex..0.i, 368
  %"&pSB[currWI].offset756.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)755.i"
  %CastToValueType757.i = bitcast i8* %"&pSB[currWI].offset756.i" to <4 x i8>**
  store <4 x i8>* %183, <4 x i8>** %CastToValueType757.i, align 8
  %"&(pSB[currWI].offset)1478.i" = add nuw i64 %CurrSBIndex..0.i, 784
  %"&pSB[currWI].offset1479.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1478.i"
  %CastToValueType1480.i = bitcast i8* %"&pSB[currWI].offset1479.i" to [4 x <4 x i8>]*
  %184 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1480.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)779.i" = add nuw i64 %CurrSBIndex..0.i, 376
  %"&pSB[currWI].offset780.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)779.i"
  %CastToValueType781.i = bitcast i8* %"&pSB[currWI].offset780.i" to <4 x i8>**
  store <4 x i8>* %184, <4 x i8>** %CastToValueType781.i, align 8
  %"&(pSB[currWI].offset)1514.i" = add nuw i64 %CurrSBIndex..0.i, 800
  %"&pSB[currWI].offset1515.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1514.i"
  %CastToValueType1516.i = bitcast i8* %"&pSB[currWI].offset1515.i" to [4 x <4 x i8>]*
  %185 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1516.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)803.i" = add nuw i64 %CurrSBIndex..0.i, 384
  %"&pSB[currWI].offset804.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)803.i"
  %CastToValueType805.i = bitcast i8* %"&pSB[currWI].offset804.i" to <4 x i8>**
  store <4 x i8>* %185, <4 x i8>** %CastToValueType805.i, align 8
  %"&(pSB[currWI].offset)1550.i" = add nuw i64 %CurrSBIndex..0.i, 816
  %"&pSB[currWI].offset1551.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1550.i"
  %CastToValueType1552.i = bitcast i8* %"&pSB[currWI].offset1551.i" to [4 x <4 x i8>]*
  %186 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1552.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)827.i" = add nuw i64 %CurrSBIndex..0.i, 392
  %"&pSB[currWI].offset828.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)827.i"
  %CastToValueType829.i = bitcast i8* %"&pSB[currWI].offset828.i" to <4 x i8>**
  store <4 x i8>* %186, <4 x i8>** %CastToValueType829.i, align 8
  %"&(pSB[currWI].offset)1586.i" = add nuw i64 %CurrSBIndex..0.i, 832
  %"&pSB[currWI].offset1587.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1586.i"
  %CastToValueType1588.i = bitcast i8* %"&pSB[currWI].offset1587.i" to [4 x <4 x i8>]*
  %187 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1588.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)851.i" = add nuw i64 %CurrSBIndex..0.i, 400
  %"&pSB[currWI].offset852.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)851.i"
  %CastToValueType853.i = bitcast i8* %"&pSB[currWI].offset852.i" to <4 x i8>**
  store <4 x i8>* %187, <4 x i8>** %CastToValueType853.i, align 8
  %"&(pSB[currWI].offset)1622.i" = add nuw i64 %CurrSBIndex..0.i, 848
  %"&pSB[currWI].offset1623.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1622.i"
  %CastToValueType1624.i = bitcast i8* %"&pSB[currWI].offset1623.i" to [4 x <4 x i8>]*
  %188 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1624.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)875.i" = add nuw i64 %CurrSBIndex..0.i, 408
  %"&pSB[currWI].offset876.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)875.i"
  %CastToValueType877.i = bitcast i8* %"&pSB[currWI].offset876.i" to <4 x i8>**
  store <4 x i8>* %188, <4 x i8>** %CastToValueType877.i, align 8
  %"&(pSB[currWI].offset)1658.i" = add nuw i64 %CurrSBIndex..0.i, 864
  %"&pSB[currWI].offset1659.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1658.i"
  %CastToValueType1660.i = bitcast i8* %"&pSB[currWI].offset1659.i" to [4 x <4 x i8>]*
  %189 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1660.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)899.i" = add nuw i64 %CurrSBIndex..0.i, 416
  %"&pSB[currWI].offset900.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)899.i"
  %CastToValueType901.i = bitcast i8* %"&pSB[currWI].offset900.i" to <4 x i8>**
  store <4 x i8>* %189, <4 x i8>** %CastToValueType901.i, align 8
  %"&(pSB[currWI].offset)1694.i" = add nuw i64 %CurrSBIndex..0.i, 880
  %"&pSB[currWI].offset1695.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1694.i"
  %CastToValueType1696.i = bitcast i8* %"&pSB[currWI].offset1695.i" to [4 x <4 x i8>]*
  %190 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1696.i, i64 0, i64 %174
  %"&(pSB[currWI].offset)923.i" = add nuw i64 %CurrSBIndex..0.i, 424
  %"&pSB[currWI].offset924.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)923.i"
  %CastToValueType925.i = bitcast i8* %"&pSB[currWI].offset924.i" to <4 x i8>**
  store <4 x i8>* %190, <4 x i8>** %CastToValueType925.i, align 8
  %191 = getelementptr inbounds <4 x i8> addrspace(3)* %16, i64 %164
  %"&(pSB[currWI].offset)947.i" = add nuw i64 %CurrSBIndex..0.i, 432
  %"&pSB[currWI].offset948.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)947.i"
  %CastToValueType949.i = bitcast i8* %"&pSB[currWI].offset948.i" to <4 x i8> addrspace(3)**
  store <4 x i8> addrspace(3)* %191, <4 x i8> addrspace(3)** %CastToValueType949.i, align 8
  %tmp75.i = sub i64 1, %42
  %"&(pSB[currWI].offset)961.i" = add nuw i64 %CurrSBIndex..0.i, 440
  %"&pSB[currWI].offset962.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)961.i"
  %CastToValueType963.i = bitcast i8* %"&pSB[currWI].offset962.i" to i64*
  store i64 %tmp75.i, i64* %CastToValueType963.i, align 8
  %tmp86.i = add i32 %43, 4
  %"&(pSB[currWI].offset)970.i" = add nuw i64 %CurrSBIndex..0.i, 448
  %"&pSB[currWI].offset971.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)970.i"
  %CastToValueType972.i = bitcast i8* %"&pSB[currWI].offset971.i" to i32*
  store i32 %tmp86.i, i32* %CastToValueType972.i, align 4
  br label %192

; <label>:192                                     ; preds = %SyncBB1716.i, %SyncBB1715.i
  %CurrSBIndex..2.i = phi i64 [ %CurrSBIndex..0.i, %SyncBB1715.i ], [ %CurrSBIndex..1.i, %SyncBB1716.i ]
  %currBarrier.1.i = phi i32 [ %currBarrier.2.i, %SyncBB1715.i ], [ %currBarrier.0.i, %SyncBB1716.i ]
  %CurrWI..2.i = phi i64 [ %CurrWI..0.i, %SyncBB1715.i ], [ %CurrWI..1.i, %SyncBB1716.i ]
  %193 = phi i8 [ %168, %SyncBB1715.i ], [ %1080, %SyncBB1716.i ]
  %194 = phi i8 [ %169, %SyncBB1715.i ], [ %1081, %SyncBB1716.i ]
  %195 = phi i8 [ %170, %SyncBB1715.i ], [ %1082, %SyncBB1716.i ]
  %196 = phi i8 [ %171, %SyncBB1715.i ], [ %1083, %SyncBB1716.i ]
  %indvar79.i = phi i32 [ 0, %SyncBB1715.i ], [ %indvar.next80.i, %SyncBB1716.i ]
  %"&(pSB[currWI].offset)979.i" = add nuw i64 %CurrSBIndex..2.i, 452
  %"&pSB[currWI].offset980.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)979.i"
  %CastToValueType981.i = bitcast i8* %"&pSB[currWI].offset980.i" to i32*
  store i32 %indvar79.i, i32* %CastToValueType981.i, align 4
  %temp.vect108.i = insertelement <4 x i8> undef, i8 %193, i32 0
  %temp.vect109.i = insertelement <4 x i8> %temp.vect108.i, i8 %194, i32 1
  %temp.vect110.i = insertelement <4 x i8> %temp.vect109.i, i8 %195, i32 2
  %temp.vect111.i = insertelement <4 x i8> %temp.vect110.i, i8 %196, i32 3
  %tmp84.i = shl i32 %indvar79.i, 2
  %"&(pSB[currWI].offset)974.i" = add nuw i64 %CurrSBIndex..2.i, 448
  %"&pSB[currWI].offset975.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)974.i"
  %CastToValueType976.i = bitcast i8* %"&pSB[currWI].offset975.i" to i32*
  %loadedValue977.i = load i32* %CastToValueType976.i, align 4
  %tmp87.i = add i32 %loadedValue977.i, %tmp84.i
  %"&(pSB[currWI].offset)993.i" = add nuw i64 %CurrSBIndex..2.i, 456
  %"&pSB[currWI].offset994.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)993.i"
  %CastToValueType995.i = bitcast i8* %"&pSB[currWI].offset994.i" to i32*
  store i32 %tmp87.i, i32* %CastToValueType995.i, align 4
  %197 = bitcast <4 x i8> %temp.vect111.i to i32
  %tmp1.i.i = bitcast i32 %197 to <4 x i8>
  %scalar9.i = extractelement <4 x i8> %tmp1.i.i, i32 0
  %scalar10.i = extractelement <4 x i8> %tmp1.i.i, i32 1
  %scalar11.i = extractelement <4 x i8> %tmp1.i.i, i32 2
  %scalar12.i = extractelement <4 x i8> %tmp1.i.i, i32 3
  %198 = zext i8 %scalar9.i to i64
  %199 = getelementptr inbounds i8 addrspace(1)* %10, i64 %198
  %200 = load i8 addrspace(1)* %199, align 1
  %201 = zext i8 %scalar10.i to i64
  %202 = getelementptr inbounds i8 addrspace(1)* %10, i64 %201
  %203 = load i8 addrspace(1)* %202, align 1
  %204 = zext i8 %scalar11.i to i64
  %205 = getelementptr inbounds i8 addrspace(1)* %10, i64 %204
  %206 = load i8 addrspace(1)* %205, align 1
  %207 = zext i8 %scalar12.i to i64
  %208 = getelementptr inbounds i8 addrspace(1)* %10, i64 %207
  %209 = load i8 addrspace(1)* %208, align 1
  %temp.vect112.i = insertelement <4 x i8> undef, i8 %200, i32 0
  %temp.vect113.i = insertelement <4 x i8> %temp.vect112.i, i8 %203, i32 1
  %temp.vect114.i = insertelement <4 x i8> %temp.vect113.i, i8 %206, i32 2
  %temp.vect115.i = insertelement <4 x i8> %temp.vect114.i, i8 %209, i32 3
  %210 = bitcast <4 x i8> %temp.vect115.i to i32
  %tmp7.i = bitcast i32 %210 to <4 x i8>
  %211 = bitcast <4 x i8> %tmp7.i to i32
  %tmp1.i1.i = bitcast i32 %211 to <4 x i8>
  %scalar17.i = extractelement <4 x i8> %tmp1.i1.i, i32 0
  %"&(pSB[currWI].offset)1002.i" = add nuw i64 %CurrSBIndex..2.i, 460
  %"&pSB[currWI].offset1003.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1002.i"
  store i8 %scalar17.i, i8* %"&pSB[currWI].offset1003.i", align 1
  %scalar18.i = extractelement <4 x i8> %tmp1.i1.i, i32 1
  %"&(pSB[currWI].offset)1006.i" = add nuw i64 %CurrSBIndex..2.i, 461
  %"&pSB[currWI].offset1007.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1006.i"
  store i8 %scalar18.i, i8* %"&pSB[currWI].offset1007.i", align 1
  %scalar19.i = extractelement <4 x i8> %tmp1.i1.i, i32 2
  %"&(pSB[currWI].offset)1010.i" = add nuw i64 %CurrSBIndex..2.i, 462
  %"&pSB[currWI].offset1011.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1010.i"
  store i8 %scalar19.i, i8* %"&pSB[currWI].offset1011.i", align 1
  %scalar20.i = extractelement <4 x i8> %tmp1.i1.i, i32 3
  %"&(pSB[currWI].offset)1014.i" = add nuw i64 %CurrSBIndex..2.i, 463
  %"&pSB[currWI].offset1015.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1014.i"
  store i8 %scalar20.i, i8* %"&pSB[currWI].offset1015.i", align 1
  %"&(pSB[currWI].offset)514.i" = add nuw i64 %CurrSBIndex..2.i, 272
  %"&pSB[currWI].offset515.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)514.i"
  %CastToValueType516.i = bitcast i8* %"&pSB[currWI].offset515.i" to i32*
  %loadedValue517.i = load i32* %CastToValueType516.i, align 4
  %212 = icmp eq i32 %loadedValue517.i, 0
  br i1 %212, label %shiftRows.exit.i, label %bb.nph.i.preheader.i

bb.nph.i.preheader.i:                             ; preds = %192
  %"&(pSB[currWI].offset)1030.i" = add nuw i64 %CurrSBIndex..2.i, 467
  %"&pSB[currWI].offset1031.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1030.i"
  %"&(pSB[currWI].offset)1026.i" = add nuw i64 %CurrSBIndex..2.i, 466
  %"&pSB[currWI].offset1027.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1026.i"
  %"&(pSB[currWI].offset)1022.i" = add nuw i64 %CurrSBIndex..2.i, 465
  %"&pSB[currWI].offset1023.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1022.i"
  %"&(pSB[currWI].offset)1018.i" = add nuw i64 %CurrSBIndex..2.i, 464
  %"&pSB[currWI].offset1019.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1018.i"
  %"&(pSB[currWI].offset)1034.i" = add nuw i64 %CurrSBIndex..2.i, 468
  %"&pSB[currWI].offset1035.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1034.i"
  %CastToValueType1036.i = bitcast i8* %"&pSB[currWI].offset1035.i" to i32*
  %"&(pSB[currWI].offset)510.i" = add nuw i64 %CurrSBIndex..2.i, 272
  %"&pSB[currWI].offset511.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)510.i"
  %CastToValueType512.i = bitcast i8* %"&pSB[currWI].offset511.i" to i32*
  br label %bb.nph.i.i

bb.nph.i.i:                                       ; preds = %bb.nph.i.i, %bb.nph.i.preheader.i
  %i.03.i.i = phi i32 [ %213, %bb.nph.i.i ], [ 0, %bb.nph.i.preheader.i ]
  %r.02.i13.i = phi i8 [ %r.02.i14.i, %bb.nph.i.i ], [ %scalar17.i, %bb.nph.i.preheader.i ]
  %r.02.i14.i = phi i8 [ %r.02.i15.i, %bb.nph.i.i ], [ %scalar18.i, %bb.nph.i.preheader.i ]
  %r.02.i15.i = phi i8 [ %r.02.i16.i, %bb.nph.i.i ], [ %scalar19.i, %bb.nph.i.preheader.i ]
  %r.02.i16.i = phi i8 [ %r.02.i13.i, %bb.nph.i.i ], [ %scalar20.i, %bb.nph.i.preheader.i ]
  store i8 %r.02.i16.i, i8* %"&pSB[currWI].offset1031.i", align 1
  store i8 %r.02.i15.i, i8* %"&pSB[currWI].offset1027.i", align 1
  store i8 %r.02.i14.i, i8* %"&pSB[currWI].offset1023.i", align 1
  store i8 %r.02.i13.i, i8* %"&pSB[currWI].offset1019.i", align 1
  %213 = add i32 %i.03.i.i, 1
  store i32 %213, i32* %CastToValueType1036.i, align 4
  %loadedValue.i = load i32* %CastToValueType512.i, align 4
  %exitcond.i.i = icmp eq i32 %213, %loadedValue.i
  br i1 %exitcond.i.i, label %shiftRows.exit.i, label %bb.nph.i.i

shiftRows.exit.i:                                 ; preds = %bb.nph.i.i, %192
  %r.0.lcssa.i21.i = phi i8 [ %scalar17.i, %192 ], [ %r.02.i14.i, %bb.nph.i.i ]
  %r.0.lcssa.i22.i = phi i8 [ %scalar18.i, %192 ], [ %r.02.i15.i, %bb.nph.i.i ]
  %r.0.lcssa.i23.i = phi i8 [ %scalar19.i, %192 ], [ %r.02.i16.i, %bb.nph.i.i ]
  %r.0.lcssa.i24.i = phi i8 [ %scalar20.i, %192 ], [ %r.02.i13.i, %bb.nph.i.i ]
  %temp.vect116.i = insertelement <4 x i8> undef, i8 %r.0.lcssa.i21.i, i32 0
  %temp.vect117.i = insertelement <4 x i8> %temp.vect116.i, i8 %r.0.lcssa.i22.i, i32 1
  %temp.vect118.i = insertelement <4 x i8> %temp.vect117.i, i8 %r.0.lcssa.i23.i, i32 2
  %temp.vect119.i = insertelement <4 x i8> %temp.vect118.i, i8 %r.0.lcssa.i24.i, i32 3
  %214 = bitcast <4 x i8> %temp.vect119.i to i32
  %tmp5.i = bitcast i32 %214 to <4 x i8>
  %"&(pSB[currWI].offset)1038.i" = add nuw i64 %CurrSBIndex..2.i, 472
  %"&pSB[currWI].offset1039.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1038.i"
  %CastToValueType1040.i = bitcast i8* %"&pSB[currWI].offset1039.i" to <4 x i8>*
  store <4 x i8> %tmp5.i, <4 x i8>* %CastToValueType1040.i, align 4
  %"&(pSB[currWI].offset)542.i" = add nuw i64 %CurrSBIndex..2.i, 288
  %"&pSB[currWI].offset543.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)542.i"
  %CastToValueType544.i = bitcast i8* %"&pSB[currWI].offset543.i" to <4 x i8> addrspace(3)**
  %loadedValue545.i = load <4 x i8> addrspace(3)** %CastToValueType544.i, align 8
  store <4 x i8> %tmp5.i, <4 x i8> addrspace(3)* %loadedValue545.i, align 4
  %"&(pSB[currWI].offset)988.i" = add nuw i64 %CurrSBIndex..2.i, 452
  %"&pSB[currWI].offset989.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)988.i"
  %CastToValueType990.i = bitcast i8* %"&pSB[currWI].offset989.i" to i32*
  %loadedValue991.i = load i32* %CastToValueType990.i, align 4
  %exitcond83.i = icmp eq i32 %loadedValue991.i, %tmp82.i
  br i1 %exitcond83.i, label %"Barrier BB508.i", label %bb.nph65.i

bb.nph65.i:                                       ; preds = %shiftRows.exit.i
  %check.WI.iter.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter.i, label %thenBB.i, label %SyncBB.i

thenBB.i:                                         ; preds = %bb.nph65.i
  %"CurrWI++.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond.i = icmp eq i32 %currBarrier.1.i, 14
  br i1 %cond.i, label %SyncBB1715.i, label %SyncBB1716.i

SyncBB.i:                                         ; preds = %thenBB1719.i, %bb.nph65.i
  %CurrSBIndex..3.i = phi i64 [ %"loadedCurrSB+Stride1725.i", %thenBB1719.i ], [ 0, %bb.nph65.i ]
  %CurrWI..3.i = phi i64 [ %"CurrWI++1723.i", %thenBB1719.i ], [ 0, %bb.nph65.i ]
  %"&(pSB[currWI].offset)582.i" = add nuw i64 %CurrSBIndex..3.i, 304
  %"&pSB[currWI].offset583.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)582.i"
  %CastToValueType584.i = bitcast i8* %"&pSB[currWI].offset583.i" to <4 x i8>**
  %loadedValue585.i = load <4 x i8>** %CastToValueType584.i, align 8
  %215 = load <4 x i8>* %loadedValue585.i, align 4
  %"&(pSB[currWI].offset)606.i" = add nuw i64 %CurrSBIndex..3.i, 312
  %"&pSB[currWI].offset607.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)606.i"
  %CastToValueType608.i = bitcast i8* %"&pSB[currWI].offset607.i" to <4 x i8>**
  %loadedValue609.i = load <4 x i8>** %CastToValueType608.i, align 8
  %216 = load <4 x i8>* %loadedValue609.i, align 4
  %"&(pSB[currWI].offset)630.i" = add nuw i64 %CurrSBIndex..3.i, 320
  %"&pSB[currWI].offset631.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)630.i"
  %CastToValueType632.i = bitcast i8* %"&pSB[currWI].offset631.i" to <4 x i8>**
  %loadedValue633.i = load <4 x i8>** %CastToValueType632.i, align 8
  %217 = load <4 x i8>* %loadedValue633.i, align 4
  %"&(pSB[currWI].offset)654.i" = add nuw i64 %CurrSBIndex..3.i, 328
  %"&pSB[currWI].offset655.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)654.i"
  %CastToValueType656.i = bitcast i8* %"&pSB[currWI].offset655.i" to <4 x i8>**
  %loadedValue657.i = load <4 x i8>** %CastToValueType656.i, align 8
  %218 = load <4 x i8>* %loadedValue657.i, align 4
  %"&(pSB[currWI].offset)678.i" = add nuw i64 %CurrSBIndex..3.i, 336
  %"&pSB[currWI].offset679.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)678.i"
  %CastToValueType680.i = bitcast i8* %"&pSB[currWI].offset679.i" to <4 x i8>**
  %loadedValue681.i = load <4 x i8>** %CastToValueType680.i, align 8
  %219 = load <4 x i8>* %loadedValue681.i, align 4
  %"&(pSB[currWI].offset)702.i" = add nuw i64 %CurrSBIndex..3.i, 344
  %"&pSB[currWI].offset703.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)702.i"
  %CastToValueType704.i = bitcast i8* %"&pSB[currWI].offset703.i" to <4 x i8>**
  %loadedValue705.i = load <4 x i8>** %CastToValueType704.i, align 8
  %220 = load <4 x i8>* %loadedValue705.i, align 4
  %"&(pSB[currWI].offset)726.i" = add nuw i64 %CurrSBIndex..3.i, 352
  %"&pSB[currWI].offset727.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)726.i"
  %CastToValueType728.i = bitcast i8* %"&pSB[currWI].offset727.i" to <4 x i8>**
  %loadedValue729.i = load <4 x i8>** %CastToValueType728.i, align 8
  %221 = load <4 x i8>* %loadedValue729.i, align 4
  %"&(pSB[currWI].offset)750.i" = add nuw i64 %CurrSBIndex..3.i, 360
  %"&pSB[currWI].offset751.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)750.i"
  %CastToValueType752.i = bitcast i8* %"&pSB[currWI].offset751.i" to <4 x i8>**
  %loadedValue753.i = load <4 x i8>** %CastToValueType752.i, align 8
  %222 = load <4 x i8>* %loadedValue753.i, align 4
  %"&(pSB[currWI].offset)774.i" = add nuw i64 %CurrSBIndex..3.i, 368
  %"&pSB[currWI].offset775.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)774.i"
  %CastToValueType776.i = bitcast i8* %"&pSB[currWI].offset775.i" to <4 x i8>**
  %loadedValue777.i = load <4 x i8>** %CastToValueType776.i, align 8
  %223 = load <4 x i8>* %loadedValue777.i, align 4
  %"&(pSB[currWI].offset)798.i" = add nuw i64 %CurrSBIndex..3.i, 376
  %"&pSB[currWI].offset799.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)798.i"
  %CastToValueType800.i = bitcast i8* %"&pSB[currWI].offset799.i" to <4 x i8>**
  %loadedValue801.i = load <4 x i8>** %CastToValueType800.i, align 8
  %224 = load <4 x i8>* %loadedValue801.i, align 4
  %"&(pSB[currWI].offset)822.i" = add nuw i64 %CurrSBIndex..3.i, 384
  %"&pSB[currWI].offset823.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)822.i"
  %CastToValueType824.i = bitcast i8* %"&pSB[currWI].offset823.i" to <4 x i8>**
  %loadedValue825.i = load <4 x i8>** %CastToValueType824.i, align 8
  %225 = load <4 x i8>* %loadedValue825.i, align 4
  %"&(pSB[currWI].offset)846.i" = add nuw i64 %CurrSBIndex..3.i, 392
  %"&pSB[currWI].offset847.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)846.i"
  %CastToValueType848.i = bitcast i8* %"&pSB[currWI].offset847.i" to <4 x i8>**
  %loadedValue849.i = load <4 x i8>** %CastToValueType848.i, align 8
  %226 = load <4 x i8>* %loadedValue849.i, align 4
  %"&(pSB[currWI].offset)870.i" = add nuw i64 %CurrSBIndex..3.i, 400
  %"&pSB[currWI].offset871.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)870.i"
  %CastToValueType872.i = bitcast i8* %"&pSB[currWI].offset871.i" to <4 x i8>**
  %loadedValue873.i = load <4 x i8>** %CastToValueType872.i, align 8
  %227 = load <4 x i8>* %loadedValue873.i, align 4
  %"&(pSB[currWI].offset)894.i" = add nuw i64 %CurrSBIndex..3.i, 408
  %"&pSB[currWI].offset895.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)894.i"
  %CastToValueType896.i = bitcast i8* %"&pSB[currWI].offset895.i" to <4 x i8>**
  %loadedValue897.i = load <4 x i8>** %CastToValueType896.i, align 8
  %228 = load <4 x i8>* %loadedValue897.i, align 4
  %"&(pSB[currWI].offset)918.i" = add nuw i64 %CurrSBIndex..3.i, 416
  %"&pSB[currWI].offset919.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)918.i"
  %CastToValueType920.i = bitcast i8* %"&pSB[currWI].offset919.i" to <4 x i8>**
  %loadedValue921.i = load <4 x i8>** %CastToValueType920.i, align 8
  %229 = load <4 x i8>* %loadedValue921.i, align 4
  %"&(pSB[currWI].offset)942.i" = add nuw i64 %CurrSBIndex..3.i, 424
  %"&pSB[currWI].offset943.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)942.i"
  %CastToValueType944.i = bitcast i8* %"&pSB[currWI].offset943.i" to <4 x i8>**
  %loadedValue945.i = load <4 x i8>** %CastToValueType944.i, align 8
  %230 = load <4 x i8>* %loadedValue945.i, align 4
  %231 = extractelement <4 x i8> %215, i32 0
  %232 = extractelement <4 x i8> %216, i32 0
  %233 = extractelement <4 x i8> %217, i32 0
  %234 = extractelement <4 x i8> %218, i32 0
  %235 = extractelement <4 x i8> %219, i32 0
  %236 = extractelement <4 x i8> %220, i32 0
  %237 = extractelement <4 x i8> %221, i32 0
  %238 = extractelement <4 x i8> %222, i32 0
  %239 = extractelement <4 x i8> %223, i32 0
  %240 = extractelement <4 x i8> %224, i32 0
  %241 = extractelement <4 x i8> %225, i32 0
  %242 = extractelement <4 x i8> %226, i32 0
  %243 = extractelement <4 x i8> %227, i32 0
  %244 = extractelement <4 x i8> %228, i32 0
  %245 = extractelement <4 x i8> %229, i32 0
  %246 = extractelement <4 x i8> %230, i32 0
  %temp.vect132.i = insertelement <16 x i8> undef, i8 %231, i32 0
  %temp.vect133.i = insertelement <16 x i8> %temp.vect132.i, i8 %232, i32 1
  %temp.vect134.i = insertelement <16 x i8> %temp.vect133.i, i8 %233, i32 2
  %temp.vect135.i = insertelement <16 x i8> %temp.vect134.i, i8 %234, i32 3
  %temp.vect136.i = insertelement <16 x i8> %temp.vect135.i, i8 %235, i32 4
  %temp.vect137.i = insertelement <16 x i8> %temp.vect136.i, i8 %236, i32 5
  %temp.vect138.i = insertelement <16 x i8> %temp.vect137.i, i8 %237, i32 6
  %temp.vect139.i = insertelement <16 x i8> %temp.vect138.i, i8 %238, i32 7
  %temp.vect140.i = insertelement <16 x i8> %temp.vect139.i, i8 %239, i32 8
  %temp.vect141.i = insertelement <16 x i8> %temp.vect140.i, i8 %240, i32 9
  %temp.vect142.i = insertelement <16 x i8> %temp.vect141.i, i8 %241, i32 10
  %temp.vect143.i = insertelement <16 x i8> %temp.vect142.i, i8 %242, i32 11
  %temp.vect144.i = insertelement <16 x i8> %temp.vect143.i, i8 %243, i32 12
  %temp.vect145.i = insertelement <16 x i8> %temp.vect144.i, i8 %244, i32 13
  %temp.vect146.i = insertelement <16 x i8> %temp.vect145.i, i8 %245, i32 14
  %temp.vect147.i = insertelement <16 x i8> %temp.vect146.i, i8 %246, i32 15
  %247 = load <4 x i8> addrspace(3)* %13, align 4
  %scalar29.i = extractelement <4 x i8> %247, i32 0
  %temp148.i = insertelement <16 x i8> undef, i8 %scalar29.i, i32 0
  %vector149.i = shufflevector <16 x i8> %temp148.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %248 = zext i8 %scalar29.i to i32
  %249 = shl i32 %248, 1
  %250 = and i32 %248, 128
  %251 = xor i32 %249, 27
  %252 = icmp eq i32 %250, 0
  %a.1.in.i = select i1 %252, i32 %249, i32 %251
  %253 = shl i32 %a.1.in.i, 1
  %254 = and i32 %a.1.in.i, 128
  %255 = xor i32 %253, 27
  %256 = icmp eq i32 %254, 0
  %a.1.in.1.i = select i1 %256, i32 %253, i32 %255
  %257 = shl i32 %a.1.in.1.i, 1
  %258 = and i32 %a.1.in.1.i, 128
  %259 = xor i32 %257, 27
  %260 = icmp eq i32 %258, 0
  %a.1.in.2.i = select i1 %260, i32 %257, i32 %259
  %261 = shl i32 %a.1.in.2.i, 1
  %262 = and i32 %a.1.in.2.i, 128
  %263 = xor i32 %261, 27
  %264 = icmp eq i32 %262, 0
  %a.1.in.3.i = select i1 %264, i32 %261, i32 %263
  %265 = shl i32 %a.1.in.3.i, 1
  %266 = and i32 %a.1.in.3.i, 128
  %267 = xor i32 %265, 27
  %268 = icmp eq i32 %266, 0
  %a.1.in.4.i = select i1 %268, i32 %265, i32 %267
  %269 = shl i32 %a.1.in.4.i, 1
  %270 = and i32 %a.1.in.4.i, 128
  %271 = xor i32 %269, 27
  %272 = icmp eq i32 %270, 0
  %a.1.in.5.i = select i1 %272, i32 %269, i32 %271
  %273 = shl i32 %a.1.in.5.i, 1
  %274 = lshr <16 x i8> %temp.vect147.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %275 = zext <16 x i8> %274 to <16 x i32>
  %276 = zext <16 x i8> %temp.vect147.i to <16 x i32>
  %277 = lshr <16 x i8> %temp.vect147.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %278 = lshr <16 x i8> %temp.vect147.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %279 = and <16 x i32> %275, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %280 = and <16 x i32> %276, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %281 = zext <16 x i8> %277 to <16 x i32>
  %282 = zext <16 x i8> %278 to <16 x i32>
  %283 = icmp eq <16 x i32> %279, zeroinitializer
  %a.1.i = trunc i32 %a.1.in.i to i8
  %temp.i = insertelement <16 x i8> undef, i8 %a.1.i, i32 0
  %vector.i = shufflevector <16 x i8> %temp.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %284 = icmp eq <16 x i32> %280, zeroinitializer
  %285 = and <16 x i32> %281, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %286 = lshr <16 x i8> %temp.vect147.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %287 = lshr <16 x i8> %temp.vect147.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %288 = and <16 x i32> %282, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %289 = select <16 x i1> %283, <16 x i8> zeroinitializer, <16 x i8> %vector.i
  %290 = select <16 x i1> %284, <16 x i8> zeroinitializer, <16 x i8> %vector149.i
  %a.1.1.i = trunc i32 %a.1.in.1.i to i8
  %temp151.i = insertelement <16 x i8> undef, i8 %a.1.1.i, i32 0
  %vector152.i = shufflevector <16 x i8> %temp151.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %291 = icmp eq <16 x i32> %285, zeroinitializer
  %292 = zext <16 x i8> %286 to <16 x i32>
  %293 = zext <16 x i8> %287 to <16 x i32>
  %294 = icmp eq <16 x i32> %288, zeroinitializer
  %a.1.2.i = trunc i32 %a.1.in.2.i to i8
  %temp153.i = insertelement <16 x i8> undef, i8 %a.1.2.i, i32 0
  %vector154.i = shufflevector <16 x i8> %temp153.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..1150.i = xor <16 x i8> %289, %290
  %295 = select <16 x i1> %291, <16 x i8> zeroinitializer, <16 x i8> %vector152.i
  %296 = and <16 x i32> %292, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %297 = lshr <16 x i8> %temp.vect147.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %298 = and i32 %a.1.in.5.i, 128
  %299 = and <16 x i32> %293, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %300 = select <16 x i1> %294, <16 x i8> zeroinitializer, <16 x i8> %vector154.i
  %p.1..2155.i = xor <16 x i8> %295, %p.1..1150.i
  %a.1.3.i = trunc i32 %a.1.in.3.i to i8
  %temp157.i = insertelement <16 x i8> undef, i8 %a.1.3.i, i32 0
  %vector158.i = shufflevector <16 x i8> %temp157.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %301 = icmp eq <16 x i32> %296, zeroinitializer
  %302 = zext <16 x i8> %297 to <16 x i32>
  %303 = icmp eq i32 %298, 0
  %304 = xor i32 %273, 27
  %305 = icmp eq <16 x i32> %299, zeroinitializer
  %a.1.4.i = trunc i32 %a.1.in.4.i to i8
  %temp159.i = insertelement <16 x i8> undef, i8 %a.1.4.i, i32 0
  %vector160.i = shufflevector <16 x i8> %temp159.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..3156.i = xor <16 x i8> %300, %p.1..2155.i
  %306 = select <16 x i1> %301, <16 x i8> zeroinitializer, <16 x i8> %vector158.i
  %307 = and <16 x i32> %302, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.1.in.6.i = select i1 %303, i32 %273, i32 %304
  %308 = select <16 x i1> %305, <16 x i8> zeroinitializer, <16 x i8> %vector160.i
  %p.1..4161.i = xor <16 x i8> %306, %p.1..3156.i
  %a.1.5.i = trunc i32 %a.1.in.5.i to i8
  %temp163.i = insertelement <16 x i8> undef, i8 %a.1.5.i, i32 0
  %vector164.i = shufflevector <16 x i8> %temp163.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %309 = icmp eq <16 x i32> %307, zeroinitializer
  %310 = icmp sgt <16 x i8> %temp.vect147.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.1.6.i = trunc i32 %a.1.in.6.i to i8
  %temp165.i = insertelement <16 x i8> undef, i8 %a.1.6.i, i32 0
  %vector166.i = shufflevector <16 x i8> %temp165.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.1..5162.i = xor <16 x i8> %308, %p.1..4161.i
  %311 = select <16 x i1> %309, <16 x i8> zeroinitializer, <16 x i8> %vector164.i
  %312 = select <16 x i1> %310, <16 x i8> zeroinitializer, <16 x i8> %vector166.i
  %p.1..6167.i = xor <16 x i8> %311, %p.1..5162.i
  %p.1..7168.i = xor <16 x i8> %312, %p.1..6167.i
  %"&(pSB[currWI].offset)1062.i" = add nuw i64 %CurrSBIndex..3.i, 480
  %"&pSB[currWI].offset1063.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1062.i"
  %CastToValueType1064.i = bitcast i8* %"&pSB[currWI].offset1063.i" to <16 x i8>*
  store <16 x i8> %p.1..7168.i, <16 x i8>* %CastToValueType1064.i, align 16
  %"&(pSB[currWI].offset)577.i" = add nuw i64 %CurrSBIndex..3.i, 304
  %"&pSB[currWI].offset578.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)577.i"
  %CastToValueType579.i = bitcast i8* %"&pSB[currWI].offset578.i" to <4 x i8>**
  %loadedValue580.i = load <4 x i8>** %CastToValueType579.i, align 8
  %313 = load <4 x i8>* %loadedValue580.i, align 4
  %"&(pSB[currWI].offset)601.i" = add nuw i64 %CurrSBIndex..3.i, 312
  %"&pSB[currWI].offset602.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)601.i"
  %CastToValueType603.i = bitcast i8* %"&pSB[currWI].offset602.i" to <4 x i8>**
  %loadedValue604.i = load <4 x i8>** %CastToValueType603.i, align 8
  %314 = load <4 x i8>* %loadedValue604.i, align 4
  %"&(pSB[currWI].offset)625.i" = add nuw i64 %CurrSBIndex..3.i, 320
  %"&pSB[currWI].offset626.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)625.i"
  %CastToValueType627.i = bitcast i8* %"&pSB[currWI].offset626.i" to <4 x i8>**
  %loadedValue628.i = load <4 x i8>** %CastToValueType627.i, align 8
  %315 = load <4 x i8>* %loadedValue628.i, align 4
  %"&(pSB[currWI].offset)649.i" = add nuw i64 %CurrSBIndex..3.i, 328
  %"&pSB[currWI].offset650.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)649.i"
  %CastToValueType651.i = bitcast i8* %"&pSB[currWI].offset650.i" to <4 x i8>**
  %loadedValue652.i = load <4 x i8>** %CastToValueType651.i, align 8
  %316 = load <4 x i8>* %loadedValue652.i, align 4
  %"&(pSB[currWI].offset)673.i" = add nuw i64 %CurrSBIndex..3.i, 336
  %"&pSB[currWI].offset674.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)673.i"
  %CastToValueType675.i = bitcast i8* %"&pSB[currWI].offset674.i" to <4 x i8>**
  %loadedValue676.i = load <4 x i8>** %CastToValueType675.i, align 8
  %317 = load <4 x i8>* %loadedValue676.i, align 4
  %"&(pSB[currWI].offset)697.i" = add nuw i64 %CurrSBIndex..3.i, 344
  %"&pSB[currWI].offset698.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)697.i"
  %CastToValueType699.i = bitcast i8* %"&pSB[currWI].offset698.i" to <4 x i8>**
  %loadedValue700.i = load <4 x i8>** %CastToValueType699.i, align 8
  %318 = load <4 x i8>* %loadedValue700.i, align 4
  %"&(pSB[currWI].offset)721.i" = add nuw i64 %CurrSBIndex..3.i, 352
  %"&pSB[currWI].offset722.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)721.i"
  %CastToValueType723.i = bitcast i8* %"&pSB[currWI].offset722.i" to <4 x i8>**
  %loadedValue724.i = load <4 x i8>** %CastToValueType723.i, align 8
  %319 = load <4 x i8>* %loadedValue724.i, align 4
  %"&(pSB[currWI].offset)745.i" = add nuw i64 %CurrSBIndex..3.i, 360
  %"&pSB[currWI].offset746.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)745.i"
  %CastToValueType747.i = bitcast i8* %"&pSB[currWI].offset746.i" to <4 x i8>**
  %loadedValue748.i = load <4 x i8>** %CastToValueType747.i, align 8
  %320 = load <4 x i8>* %loadedValue748.i, align 4
  %"&(pSB[currWI].offset)769.i" = add nuw i64 %CurrSBIndex..3.i, 368
  %"&pSB[currWI].offset770.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)769.i"
  %CastToValueType771.i = bitcast i8* %"&pSB[currWI].offset770.i" to <4 x i8>**
  %loadedValue772.i = load <4 x i8>** %CastToValueType771.i, align 8
  %321 = load <4 x i8>* %loadedValue772.i, align 4
  %"&(pSB[currWI].offset)793.i" = add nuw i64 %CurrSBIndex..3.i, 376
  %"&pSB[currWI].offset794.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)793.i"
  %CastToValueType795.i = bitcast i8* %"&pSB[currWI].offset794.i" to <4 x i8>**
  %loadedValue796.i = load <4 x i8>** %CastToValueType795.i, align 8
  %322 = load <4 x i8>* %loadedValue796.i, align 4
  %"&(pSB[currWI].offset)817.i" = add nuw i64 %CurrSBIndex..3.i, 384
  %"&pSB[currWI].offset818.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)817.i"
  %CastToValueType819.i = bitcast i8* %"&pSB[currWI].offset818.i" to <4 x i8>**
  %loadedValue820.i = load <4 x i8>** %CastToValueType819.i, align 8
  %323 = load <4 x i8>* %loadedValue820.i, align 4
  %"&(pSB[currWI].offset)841.i" = add nuw i64 %CurrSBIndex..3.i, 392
  %"&pSB[currWI].offset842.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)841.i"
  %CastToValueType843.i = bitcast i8* %"&pSB[currWI].offset842.i" to <4 x i8>**
  %loadedValue844.i = load <4 x i8>** %CastToValueType843.i, align 8
  %324 = load <4 x i8>* %loadedValue844.i, align 4
  %"&(pSB[currWI].offset)865.i" = add nuw i64 %CurrSBIndex..3.i, 400
  %"&pSB[currWI].offset866.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)865.i"
  %CastToValueType867.i = bitcast i8* %"&pSB[currWI].offset866.i" to <4 x i8>**
  %loadedValue868.i = load <4 x i8>** %CastToValueType867.i, align 8
  %325 = load <4 x i8>* %loadedValue868.i, align 4
  %"&(pSB[currWI].offset)889.i" = add nuw i64 %CurrSBIndex..3.i, 408
  %"&pSB[currWI].offset890.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)889.i"
  %CastToValueType891.i = bitcast i8* %"&pSB[currWI].offset890.i" to <4 x i8>**
  %loadedValue892.i = load <4 x i8>** %CastToValueType891.i, align 8
  %326 = load <4 x i8>* %loadedValue892.i, align 4
  %"&(pSB[currWI].offset)913.i" = add nuw i64 %CurrSBIndex..3.i, 416
  %"&pSB[currWI].offset914.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)913.i"
  %CastToValueType915.i = bitcast i8* %"&pSB[currWI].offset914.i" to <4 x i8>**
  %loadedValue916.i = load <4 x i8>** %CastToValueType915.i, align 8
  %327 = load <4 x i8>* %loadedValue916.i, align 4
  %"&(pSB[currWI].offset)937.i" = add nuw i64 %CurrSBIndex..3.i, 424
  %"&pSB[currWI].offset938.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)937.i"
  %CastToValueType939.i = bitcast i8* %"&pSB[currWI].offset938.i" to <4 x i8>**
  %loadedValue940.i = load <4 x i8>** %CastToValueType939.i, align 8
  %328 = load <4 x i8>* %loadedValue940.i, align 4
  %329 = extractelement <4 x i8> %313, i32 0
  %330 = extractelement <4 x i8> %314, i32 0
  %331 = extractelement <4 x i8> %315, i32 0
  %332 = extractelement <4 x i8> %316, i32 0
  %333 = extractelement <4 x i8> %317, i32 0
  %334 = extractelement <4 x i8> %318, i32 0
  %335 = extractelement <4 x i8> %319, i32 0
  %336 = extractelement <4 x i8> %320, i32 0
  %337 = extractelement <4 x i8> %321, i32 0
  %338 = extractelement <4 x i8> %322, i32 0
  %339 = extractelement <4 x i8> %323, i32 0
  %340 = extractelement <4 x i8> %324, i32 0
  %341 = extractelement <4 x i8> %325, i32 0
  %342 = extractelement <4 x i8> %326, i32 0
  %343 = extractelement <4 x i8> %327, i32 0
  %344 = extractelement <4 x i8> %328, i32 0
  %temp.vect169.i = insertelement <16 x i8> undef, i8 %329, i32 0
  %temp.vect170.i = insertelement <16 x i8> %temp.vect169.i, i8 %330, i32 1
  %temp.vect171.i = insertelement <16 x i8> %temp.vect170.i, i8 %331, i32 2
  %temp.vect172.i = insertelement <16 x i8> %temp.vect171.i, i8 %332, i32 3
  %temp.vect173.i = insertelement <16 x i8> %temp.vect172.i, i8 %333, i32 4
  %temp.vect174.i = insertelement <16 x i8> %temp.vect173.i, i8 %334, i32 5
  %temp.vect175.i = insertelement <16 x i8> %temp.vect174.i, i8 %335, i32 6
  %temp.vect176.i = insertelement <16 x i8> %temp.vect175.i, i8 %336, i32 7
  %temp.vect177.i = insertelement <16 x i8> %temp.vect176.i, i8 %337, i32 8
  %temp.vect178.i = insertelement <16 x i8> %temp.vect177.i, i8 %338, i32 9
  %temp.vect179.i = insertelement <16 x i8> %temp.vect178.i, i8 %339, i32 10
  %temp.vect180.i = insertelement <16 x i8> %temp.vect179.i, i8 %340, i32 11
  %temp.vect181.i = insertelement <16 x i8> %temp.vect180.i, i8 %341, i32 12
  %temp.vect182.i = insertelement <16 x i8> %temp.vect181.i, i8 %342, i32 13
  %temp.vect183.i = insertelement <16 x i8> %temp.vect182.i, i8 %343, i32 14
  %temp.vect184.i = insertelement <16 x i8> %temp.vect183.i, i8 %344, i32 15
  %345 = load <4 x i8> addrspace(3)* %13, align 4
  %scalar38.i = extractelement <4 x i8> %345, i32 1
  %temp187.i = insertelement <16 x i8> undef, i8 %scalar38.i, i32 0
  %vector188.i = shufflevector <16 x i8> %temp187.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %346 = zext i8 %scalar38.i to i32
  %347 = shl i32 %346, 1
  %348 = and i32 %346, 128
  %349 = xor i32 %347, 27
  %350 = icmp eq i32 %348, 0
  %a.3.in.i = select i1 %350, i32 %347, i32 %349
  %351 = shl i32 %a.3.in.i, 1
  %352 = and i32 %a.3.in.i, 128
  %353 = xor i32 %351, 27
  %354 = icmp eq i32 %352, 0
  %a.3.in.1.i = select i1 %354, i32 %351, i32 %353
  %355 = shl i32 %a.3.in.1.i, 1
  %356 = and i32 %a.3.in.1.i, 128
  %357 = xor i32 %355, 27
  %358 = icmp eq i32 %356, 0
  %a.3.in.2.i = select i1 %358, i32 %355, i32 %357
  %359 = shl i32 %a.3.in.2.i, 1
  %360 = and i32 %a.3.in.2.i, 128
  %361 = xor i32 %359, 27
  %362 = icmp eq i32 %360, 0
  %a.3.in.3.i = select i1 %362, i32 %359, i32 %361
  %363 = shl i32 %a.3.in.3.i, 1
  %364 = and i32 %a.3.in.3.i, 128
  %365 = xor i32 %363, 27
  %366 = icmp eq i32 %364, 0
  %a.3.in.4.i = select i1 %366, i32 %363, i32 %365
  %367 = shl i32 %a.3.in.4.i, 1
  %368 = and i32 %a.3.in.4.i, 128
  %369 = xor i32 %367, 27
  %370 = icmp eq i32 %368, 0
  %a.3.in.5.i = select i1 %370, i32 %367, i32 %369
  %371 = shl i32 %a.3.in.5.i, 1
  %372 = lshr <16 x i8> %temp.vect184.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %373 = zext <16 x i8> %372 to <16 x i32>
  %374 = zext <16 x i8> %temp.vect184.i to <16 x i32>
  %375 = lshr <16 x i8> %temp.vect184.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %376 = lshr <16 x i8> %temp.vect184.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %377 = and <16 x i32> %373, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %378 = and <16 x i32> %374, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %379 = zext <16 x i8> %375 to <16 x i32>
  %380 = zext <16 x i8> %376 to <16 x i32>
  %381 = icmp eq <16 x i32> %377, zeroinitializer
  %a.3.i = trunc i32 %a.3.in.i to i8
  %temp185.i = insertelement <16 x i8> undef, i8 %a.3.i, i32 0
  %vector186.i = shufflevector <16 x i8> %temp185.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %382 = icmp eq <16 x i32> %378, zeroinitializer
  %383 = and <16 x i32> %379, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %384 = lshr <16 x i8> %temp.vect184.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %385 = lshr <16 x i8> %temp.vect184.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %386 = and <16 x i32> %380, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %387 = select <16 x i1> %381, <16 x i8> zeroinitializer, <16 x i8> %vector186.i
  %388 = select <16 x i1> %382, <16 x i8> zeroinitializer, <16 x i8> %vector188.i
  %a.3.1.i = trunc i32 %a.3.in.1.i to i8
  %temp190.i = insertelement <16 x i8> undef, i8 %a.3.1.i, i32 0
  %vector191.i = shufflevector <16 x i8> %temp190.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %389 = icmp eq <16 x i32> %383, zeroinitializer
  %390 = zext <16 x i8> %384 to <16 x i32>
  %391 = zext <16 x i8> %385 to <16 x i32>
  %392 = icmp eq <16 x i32> %386, zeroinitializer
  %a.3.2.i = trunc i32 %a.3.in.2.i to i8
  %temp192.i = insertelement <16 x i8> undef, i8 %a.3.2.i, i32 0
  %vector193.i = shufflevector <16 x i8> %temp192.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..1189.i = xor <16 x i8> %387, %388
  %393 = select <16 x i1> %389, <16 x i8> zeroinitializer, <16 x i8> %vector191.i
  %394 = and <16 x i32> %390, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %395 = lshr <16 x i8> %temp.vect184.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %396 = and i32 %a.3.in.5.i, 128
  %397 = and <16 x i32> %391, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %398 = select <16 x i1> %392, <16 x i8> zeroinitializer, <16 x i8> %vector193.i
  %p.3..2194.i = xor <16 x i8> %393, %p.3..1189.i
  %a.3.3.i = trunc i32 %a.3.in.3.i to i8
  %temp196.i = insertelement <16 x i8> undef, i8 %a.3.3.i, i32 0
  %vector197.i = shufflevector <16 x i8> %temp196.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %399 = icmp eq <16 x i32> %394, zeroinitializer
  %400 = zext <16 x i8> %395 to <16 x i32>
  %401 = icmp eq i32 %396, 0
  %402 = xor i32 %371, 27
  %403 = icmp eq <16 x i32> %397, zeroinitializer
  %a.3.4.i = trunc i32 %a.3.in.4.i to i8
  %temp198.i = insertelement <16 x i8> undef, i8 %a.3.4.i, i32 0
  %vector199.i = shufflevector <16 x i8> %temp198.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..3195.i = xor <16 x i8> %398, %p.3..2194.i
  %404 = select <16 x i1> %399, <16 x i8> zeroinitializer, <16 x i8> %vector197.i
  %405 = and <16 x i32> %400, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.3.in.6.i = select i1 %401, i32 %371, i32 %402
  %406 = select <16 x i1> %403, <16 x i8> zeroinitializer, <16 x i8> %vector199.i
  %p.3..4200.i = xor <16 x i8> %404, %p.3..3195.i
  %a.3.5.i = trunc i32 %a.3.in.5.i to i8
  %temp202.i = insertelement <16 x i8> undef, i8 %a.3.5.i, i32 0
  %vector203.i = shufflevector <16 x i8> %temp202.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %407 = icmp eq <16 x i32> %405, zeroinitializer
  %408 = icmp sgt <16 x i8> %temp.vect184.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.3.6.i = trunc i32 %a.3.in.6.i to i8
  %temp204.i = insertelement <16 x i8> undef, i8 %a.3.6.i, i32 0
  %vector205.i = shufflevector <16 x i8> %temp204.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.3..5201.i = xor <16 x i8> %406, %p.3..4200.i
  %409 = select <16 x i1> %407, <16 x i8> zeroinitializer, <16 x i8> %vector203.i
  %410 = select <16 x i1> %408, <16 x i8> zeroinitializer, <16 x i8> %vector205.i
  %p.3..6206.i = xor <16 x i8> %409, %p.3..5201.i
  %p.3..7207.i = xor <16 x i8> %410, %p.3..6206.i
  %"&(pSB[currWI].offset)1066.i" = add nuw i64 %CurrSBIndex..3.i, 496
  %"&pSB[currWI].offset1067.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1066.i"
  %CastToValueType1068.i = bitcast i8* %"&pSB[currWI].offset1067.i" to <16 x i8>*
  store <16 x i8> %p.3..7207.i, <16 x i8>* %CastToValueType1068.i, align 16
  %"&(pSB[currWI].offset)572.i" = add nuw i64 %CurrSBIndex..3.i, 304
  %"&pSB[currWI].offset573.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)572.i"
  %CastToValueType574.i = bitcast i8* %"&pSB[currWI].offset573.i" to <4 x i8>**
  %loadedValue575.i = load <4 x i8>** %CastToValueType574.i, align 8
  %411 = load <4 x i8>* %loadedValue575.i, align 4
  %"&(pSB[currWI].offset)596.i" = add nuw i64 %CurrSBIndex..3.i, 312
  %"&pSB[currWI].offset597.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)596.i"
  %CastToValueType598.i = bitcast i8* %"&pSB[currWI].offset597.i" to <4 x i8>**
  %loadedValue599.i = load <4 x i8>** %CastToValueType598.i, align 8
  %412 = load <4 x i8>* %loadedValue599.i, align 4
  %"&(pSB[currWI].offset)620.i" = add nuw i64 %CurrSBIndex..3.i, 320
  %"&pSB[currWI].offset621.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)620.i"
  %CastToValueType622.i = bitcast i8* %"&pSB[currWI].offset621.i" to <4 x i8>**
  %loadedValue623.i = load <4 x i8>** %CastToValueType622.i, align 8
  %413 = load <4 x i8>* %loadedValue623.i, align 4
  %"&(pSB[currWI].offset)644.i" = add nuw i64 %CurrSBIndex..3.i, 328
  %"&pSB[currWI].offset645.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)644.i"
  %CastToValueType646.i = bitcast i8* %"&pSB[currWI].offset645.i" to <4 x i8>**
  %loadedValue647.i = load <4 x i8>** %CastToValueType646.i, align 8
  %414 = load <4 x i8>* %loadedValue647.i, align 4
  %"&(pSB[currWI].offset)668.i" = add nuw i64 %CurrSBIndex..3.i, 336
  %"&pSB[currWI].offset669.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)668.i"
  %CastToValueType670.i = bitcast i8* %"&pSB[currWI].offset669.i" to <4 x i8>**
  %loadedValue671.i = load <4 x i8>** %CastToValueType670.i, align 8
  %415 = load <4 x i8>* %loadedValue671.i, align 4
  %"&(pSB[currWI].offset)692.i" = add nuw i64 %CurrSBIndex..3.i, 344
  %"&pSB[currWI].offset693.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)692.i"
  %CastToValueType694.i = bitcast i8* %"&pSB[currWI].offset693.i" to <4 x i8>**
  %loadedValue695.i = load <4 x i8>** %CastToValueType694.i, align 8
  %416 = load <4 x i8>* %loadedValue695.i, align 4
  %"&(pSB[currWI].offset)716.i" = add nuw i64 %CurrSBIndex..3.i, 352
  %"&pSB[currWI].offset717.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)716.i"
  %CastToValueType718.i = bitcast i8* %"&pSB[currWI].offset717.i" to <4 x i8>**
  %loadedValue719.i = load <4 x i8>** %CastToValueType718.i, align 8
  %417 = load <4 x i8>* %loadedValue719.i, align 4
  %"&(pSB[currWI].offset)740.i" = add nuw i64 %CurrSBIndex..3.i, 360
  %"&pSB[currWI].offset741.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)740.i"
  %CastToValueType742.i = bitcast i8* %"&pSB[currWI].offset741.i" to <4 x i8>**
  %loadedValue743.i = load <4 x i8>** %CastToValueType742.i, align 8
  %418 = load <4 x i8>* %loadedValue743.i, align 4
  %"&(pSB[currWI].offset)764.i" = add nuw i64 %CurrSBIndex..3.i, 368
  %"&pSB[currWI].offset765.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)764.i"
  %CastToValueType766.i = bitcast i8* %"&pSB[currWI].offset765.i" to <4 x i8>**
  %loadedValue767.i = load <4 x i8>** %CastToValueType766.i, align 8
  %419 = load <4 x i8>* %loadedValue767.i, align 4
  %"&(pSB[currWI].offset)788.i" = add nuw i64 %CurrSBIndex..3.i, 376
  %"&pSB[currWI].offset789.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)788.i"
  %CastToValueType790.i = bitcast i8* %"&pSB[currWI].offset789.i" to <4 x i8>**
  %loadedValue791.i = load <4 x i8>** %CastToValueType790.i, align 8
  %420 = load <4 x i8>* %loadedValue791.i, align 4
  %"&(pSB[currWI].offset)812.i" = add nuw i64 %CurrSBIndex..3.i, 384
  %"&pSB[currWI].offset813.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)812.i"
  %CastToValueType814.i = bitcast i8* %"&pSB[currWI].offset813.i" to <4 x i8>**
  %loadedValue815.i = load <4 x i8>** %CastToValueType814.i, align 8
  %421 = load <4 x i8>* %loadedValue815.i, align 4
  %"&(pSB[currWI].offset)836.i" = add nuw i64 %CurrSBIndex..3.i, 392
  %"&pSB[currWI].offset837.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)836.i"
  %CastToValueType838.i = bitcast i8* %"&pSB[currWI].offset837.i" to <4 x i8>**
  %loadedValue839.i = load <4 x i8>** %CastToValueType838.i, align 8
  %422 = load <4 x i8>* %loadedValue839.i, align 4
  %"&(pSB[currWI].offset)860.i" = add nuw i64 %CurrSBIndex..3.i, 400
  %"&pSB[currWI].offset861.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)860.i"
  %CastToValueType862.i = bitcast i8* %"&pSB[currWI].offset861.i" to <4 x i8>**
  %loadedValue863.i = load <4 x i8>** %CastToValueType862.i, align 8
  %423 = load <4 x i8>* %loadedValue863.i, align 4
  %"&(pSB[currWI].offset)884.i" = add nuw i64 %CurrSBIndex..3.i, 408
  %"&pSB[currWI].offset885.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)884.i"
  %CastToValueType886.i = bitcast i8* %"&pSB[currWI].offset885.i" to <4 x i8>**
  %loadedValue887.i = load <4 x i8>** %CastToValueType886.i, align 8
  %424 = load <4 x i8>* %loadedValue887.i, align 4
  %"&(pSB[currWI].offset)908.i" = add nuw i64 %CurrSBIndex..3.i, 416
  %"&pSB[currWI].offset909.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)908.i"
  %CastToValueType910.i = bitcast i8* %"&pSB[currWI].offset909.i" to <4 x i8>**
  %loadedValue911.i = load <4 x i8>** %CastToValueType910.i, align 8
  %425 = load <4 x i8>* %loadedValue911.i, align 4
  %"&(pSB[currWI].offset)932.i" = add nuw i64 %CurrSBIndex..3.i, 424
  %"&pSB[currWI].offset933.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)932.i"
  %CastToValueType934.i = bitcast i8* %"&pSB[currWI].offset933.i" to <4 x i8>**
  %loadedValue935.i = load <4 x i8>** %CastToValueType934.i, align 8
  %426 = load <4 x i8>* %loadedValue935.i, align 4
  %427 = extractelement <4 x i8> %411, i32 0
  %428 = extractelement <4 x i8> %412, i32 0
  %429 = extractelement <4 x i8> %413, i32 0
  %430 = extractelement <4 x i8> %414, i32 0
  %431 = extractelement <4 x i8> %415, i32 0
  %432 = extractelement <4 x i8> %416, i32 0
  %433 = extractelement <4 x i8> %417, i32 0
  %434 = extractelement <4 x i8> %418, i32 0
  %435 = extractelement <4 x i8> %419, i32 0
  %436 = extractelement <4 x i8> %420, i32 0
  %437 = extractelement <4 x i8> %421, i32 0
  %438 = extractelement <4 x i8> %422, i32 0
  %439 = extractelement <4 x i8> %423, i32 0
  %440 = extractelement <4 x i8> %424, i32 0
  %441 = extractelement <4 x i8> %425, i32 0
  %442 = extractelement <4 x i8> %426, i32 0
  %temp.vect208.i = insertelement <16 x i8> undef, i8 %427, i32 0
  %temp.vect209.i = insertelement <16 x i8> %temp.vect208.i, i8 %428, i32 1
  %temp.vect210.i = insertelement <16 x i8> %temp.vect209.i, i8 %429, i32 2
  %temp.vect211.i = insertelement <16 x i8> %temp.vect210.i, i8 %430, i32 3
  %temp.vect212.i = insertelement <16 x i8> %temp.vect211.i, i8 %431, i32 4
  %temp.vect213.i = insertelement <16 x i8> %temp.vect212.i, i8 %432, i32 5
  %temp.vect214.i = insertelement <16 x i8> %temp.vect213.i, i8 %433, i32 6
  %temp.vect215.i = insertelement <16 x i8> %temp.vect214.i, i8 %434, i32 7
  %temp.vect216.i = insertelement <16 x i8> %temp.vect215.i, i8 %435, i32 8
  %temp.vect217.i = insertelement <16 x i8> %temp.vect216.i, i8 %436, i32 9
  %temp.vect218.i = insertelement <16 x i8> %temp.vect217.i, i8 %437, i32 10
  %temp.vect219.i = insertelement <16 x i8> %temp.vect218.i, i8 %438, i32 11
  %temp.vect220.i = insertelement <16 x i8> %temp.vect219.i, i8 %439, i32 12
  %temp.vect221.i = insertelement <16 x i8> %temp.vect220.i, i8 %440, i32 13
  %temp.vect222.i = insertelement <16 x i8> %temp.vect221.i, i8 %441, i32 14
  %temp.vect223.i = insertelement <16 x i8> %temp.vect222.i, i8 %442, i32 15
  %443 = load <4 x i8> addrspace(3)* %13, align 4
  %scalar47.i = extractelement <4 x i8> %443, i32 2
  %temp226.i = insertelement <16 x i8> undef, i8 %scalar47.i, i32 0
  %vector227.i = shufflevector <16 x i8> %temp226.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %444 = zext i8 %scalar47.i to i32
  %445 = shl i32 %444, 1
  %446 = and i32 %444, 128
  %447 = xor i32 %445, 27
  %448 = icmp eq i32 %446, 0
  %a.5.in.i = select i1 %448, i32 %445, i32 %447
  %449 = shl i32 %a.5.in.i, 1
  %450 = and i32 %a.5.in.i, 128
  %451 = xor i32 %449, 27
  %452 = icmp eq i32 %450, 0
  %a.5.in.1.i = select i1 %452, i32 %449, i32 %451
  %453 = shl i32 %a.5.in.1.i, 1
  %454 = and i32 %a.5.in.1.i, 128
  %455 = xor i32 %453, 27
  %456 = icmp eq i32 %454, 0
  %a.5.in.2.i = select i1 %456, i32 %453, i32 %455
  %457 = shl i32 %a.5.in.2.i, 1
  %458 = and i32 %a.5.in.2.i, 128
  %459 = xor i32 %457, 27
  %460 = icmp eq i32 %458, 0
  %a.5.in.3.i = select i1 %460, i32 %457, i32 %459
  %461 = shl i32 %a.5.in.3.i, 1
  %462 = and i32 %a.5.in.3.i, 128
  %463 = xor i32 %461, 27
  %464 = icmp eq i32 %462, 0
  %a.5.in.4.i = select i1 %464, i32 %461, i32 %463
  %465 = shl i32 %a.5.in.4.i, 1
  %466 = and i32 %a.5.in.4.i, 128
  %467 = xor i32 %465, 27
  %468 = icmp eq i32 %466, 0
  %a.5.in.5.i = select i1 %468, i32 %465, i32 %467
  %469 = shl i32 %a.5.in.5.i, 1
  %470 = lshr <16 x i8> %temp.vect223.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %471 = zext <16 x i8> %470 to <16 x i32>
  %472 = zext <16 x i8> %temp.vect223.i to <16 x i32>
  %473 = lshr <16 x i8> %temp.vect223.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %474 = lshr <16 x i8> %temp.vect223.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %475 = and <16 x i32> %471, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %476 = and <16 x i32> %472, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %477 = zext <16 x i8> %473 to <16 x i32>
  %478 = zext <16 x i8> %474 to <16 x i32>
  %479 = icmp eq <16 x i32> %475, zeroinitializer
  %a.5.i = trunc i32 %a.5.in.i to i8
  %temp224.i = insertelement <16 x i8> undef, i8 %a.5.i, i32 0
  %vector225.i = shufflevector <16 x i8> %temp224.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %480 = icmp eq <16 x i32> %476, zeroinitializer
  %481 = and <16 x i32> %477, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %482 = lshr <16 x i8> %temp.vect223.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %483 = lshr <16 x i8> %temp.vect223.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %484 = and <16 x i32> %478, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %485 = select <16 x i1> %479, <16 x i8> zeroinitializer, <16 x i8> %vector225.i
  %486 = select <16 x i1> %480, <16 x i8> zeroinitializer, <16 x i8> %vector227.i
  %a.5.1.i = trunc i32 %a.5.in.1.i to i8
  %temp229.i = insertelement <16 x i8> undef, i8 %a.5.1.i, i32 0
  %vector230.i = shufflevector <16 x i8> %temp229.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %487 = icmp eq <16 x i32> %481, zeroinitializer
  %488 = zext <16 x i8> %482 to <16 x i32>
  %489 = zext <16 x i8> %483 to <16 x i32>
  %490 = icmp eq <16 x i32> %484, zeroinitializer
  %a.5.2.i = trunc i32 %a.5.in.2.i to i8
  %temp231.i = insertelement <16 x i8> undef, i8 %a.5.2.i, i32 0
  %vector232.i = shufflevector <16 x i8> %temp231.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..1228.i = xor <16 x i8> %485, %486
  %491 = select <16 x i1> %487, <16 x i8> zeroinitializer, <16 x i8> %vector230.i
  %492 = and <16 x i32> %488, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %493 = lshr <16 x i8> %temp.vect223.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %494 = and i32 %a.5.in.5.i, 128
  %495 = and <16 x i32> %489, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %496 = select <16 x i1> %490, <16 x i8> zeroinitializer, <16 x i8> %vector232.i
  %p.5..2233.i = xor <16 x i8> %491, %p.5..1228.i
  %a.5.3.i = trunc i32 %a.5.in.3.i to i8
  %temp235.i = insertelement <16 x i8> undef, i8 %a.5.3.i, i32 0
  %vector236.i = shufflevector <16 x i8> %temp235.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %497 = icmp eq <16 x i32> %492, zeroinitializer
  %498 = zext <16 x i8> %493 to <16 x i32>
  %499 = icmp eq i32 %494, 0
  %500 = xor i32 %469, 27
  %501 = icmp eq <16 x i32> %495, zeroinitializer
  %a.5.4.i = trunc i32 %a.5.in.4.i to i8
  %temp237.i = insertelement <16 x i8> undef, i8 %a.5.4.i, i32 0
  %vector238.i = shufflevector <16 x i8> %temp237.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..3234.i = xor <16 x i8> %496, %p.5..2233.i
  %502 = select <16 x i1> %497, <16 x i8> zeroinitializer, <16 x i8> %vector236.i
  %503 = and <16 x i32> %498, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.5.in.6.i = select i1 %499, i32 %469, i32 %500
  %504 = select <16 x i1> %501, <16 x i8> zeroinitializer, <16 x i8> %vector238.i
  %p.5..4239.i = xor <16 x i8> %502, %p.5..3234.i
  %a.5.5.i = trunc i32 %a.5.in.5.i to i8
  %temp241.i = insertelement <16 x i8> undef, i8 %a.5.5.i, i32 0
  %vector242.i = shufflevector <16 x i8> %temp241.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %505 = icmp eq <16 x i32> %503, zeroinitializer
  %506 = icmp sgt <16 x i8> %temp.vect223.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.5.6.i = trunc i32 %a.5.in.6.i to i8
  %temp243.i = insertelement <16 x i8> undef, i8 %a.5.6.i, i32 0
  %vector244.i = shufflevector <16 x i8> %temp243.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.5..5240.i = xor <16 x i8> %504, %p.5..4239.i
  %507 = select <16 x i1> %505, <16 x i8> zeroinitializer, <16 x i8> %vector242.i
  %508 = select <16 x i1> %506, <16 x i8> zeroinitializer, <16 x i8> %vector244.i
  %p.5..6245.i = xor <16 x i8> %507, %p.5..5240.i
  %p.5..7246.i = xor <16 x i8> %508, %p.5..6245.i
  %"&(pSB[currWI].offset)1070.i" = add nuw i64 %CurrSBIndex..3.i, 512
  %"&pSB[currWI].offset1071.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1070.i"
  %CastToValueType1072.i = bitcast i8* %"&pSB[currWI].offset1071.i" to <16 x i8>*
  store <16 x i8> %p.5..7246.i, <16 x i8>* %CastToValueType1072.i, align 16
  %"&(pSB[currWI].offset)567.i" = add nuw i64 %CurrSBIndex..3.i, 304
  %"&pSB[currWI].offset568.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)567.i"
  %CastToValueType569.i = bitcast i8* %"&pSB[currWI].offset568.i" to <4 x i8>**
  %loadedValue570.i = load <4 x i8>** %CastToValueType569.i, align 8
  %509 = load <4 x i8>* %loadedValue570.i, align 4
  %"&(pSB[currWI].offset)591.i" = add nuw i64 %CurrSBIndex..3.i, 312
  %"&pSB[currWI].offset592.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)591.i"
  %CastToValueType593.i = bitcast i8* %"&pSB[currWI].offset592.i" to <4 x i8>**
  %loadedValue594.i = load <4 x i8>** %CastToValueType593.i, align 8
  %510 = load <4 x i8>* %loadedValue594.i, align 4
  %"&(pSB[currWI].offset)615.i" = add nuw i64 %CurrSBIndex..3.i, 320
  %"&pSB[currWI].offset616.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)615.i"
  %CastToValueType617.i = bitcast i8* %"&pSB[currWI].offset616.i" to <4 x i8>**
  %loadedValue618.i = load <4 x i8>** %CastToValueType617.i, align 8
  %511 = load <4 x i8>* %loadedValue618.i, align 4
  %"&(pSB[currWI].offset)639.i" = add nuw i64 %CurrSBIndex..3.i, 328
  %"&pSB[currWI].offset640.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)639.i"
  %CastToValueType641.i = bitcast i8* %"&pSB[currWI].offset640.i" to <4 x i8>**
  %loadedValue642.i = load <4 x i8>** %CastToValueType641.i, align 8
  %512 = load <4 x i8>* %loadedValue642.i, align 4
  %"&(pSB[currWI].offset)663.i" = add nuw i64 %CurrSBIndex..3.i, 336
  %"&pSB[currWI].offset664.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)663.i"
  %CastToValueType665.i = bitcast i8* %"&pSB[currWI].offset664.i" to <4 x i8>**
  %loadedValue666.i = load <4 x i8>** %CastToValueType665.i, align 8
  %513 = load <4 x i8>* %loadedValue666.i, align 4
  %"&(pSB[currWI].offset)687.i" = add nuw i64 %CurrSBIndex..3.i, 344
  %"&pSB[currWI].offset688.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)687.i"
  %CastToValueType689.i = bitcast i8* %"&pSB[currWI].offset688.i" to <4 x i8>**
  %loadedValue690.i = load <4 x i8>** %CastToValueType689.i, align 8
  %514 = load <4 x i8>* %loadedValue690.i, align 4
  %"&(pSB[currWI].offset)711.i" = add nuw i64 %CurrSBIndex..3.i, 352
  %"&pSB[currWI].offset712.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)711.i"
  %CastToValueType713.i = bitcast i8* %"&pSB[currWI].offset712.i" to <4 x i8>**
  %loadedValue714.i = load <4 x i8>** %CastToValueType713.i, align 8
  %515 = load <4 x i8>* %loadedValue714.i, align 4
  %"&(pSB[currWI].offset)735.i" = add nuw i64 %CurrSBIndex..3.i, 360
  %"&pSB[currWI].offset736.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)735.i"
  %CastToValueType737.i = bitcast i8* %"&pSB[currWI].offset736.i" to <4 x i8>**
  %loadedValue738.i = load <4 x i8>** %CastToValueType737.i, align 8
  %516 = load <4 x i8>* %loadedValue738.i, align 4
  %"&(pSB[currWI].offset)759.i" = add nuw i64 %CurrSBIndex..3.i, 368
  %"&pSB[currWI].offset760.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)759.i"
  %CastToValueType761.i = bitcast i8* %"&pSB[currWI].offset760.i" to <4 x i8>**
  %loadedValue762.i = load <4 x i8>** %CastToValueType761.i, align 8
  %517 = load <4 x i8>* %loadedValue762.i, align 4
  %"&(pSB[currWI].offset)783.i" = add nuw i64 %CurrSBIndex..3.i, 376
  %"&pSB[currWI].offset784.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)783.i"
  %CastToValueType785.i = bitcast i8* %"&pSB[currWI].offset784.i" to <4 x i8>**
  %loadedValue786.i = load <4 x i8>** %CastToValueType785.i, align 8
  %518 = load <4 x i8>* %loadedValue786.i, align 4
  %"&(pSB[currWI].offset)807.i" = add nuw i64 %CurrSBIndex..3.i, 384
  %"&pSB[currWI].offset808.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)807.i"
  %CastToValueType809.i = bitcast i8* %"&pSB[currWI].offset808.i" to <4 x i8>**
  %loadedValue810.i = load <4 x i8>** %CastToValueType809.i, align 8
  %519 = load <4 x i8>* %loadedValue810.i, align 4
  %"&(pSB[currWI].offset)831.i" = add nuw i64 %CurrSBIndex..3.i, 392
  %"&pSB[currWI].offset832.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)831.i"
  %CastToValueType833.i = bitcast i8* %"&pSB[currWI].offset832.i" to <4 x i8>**
  %loadedValue834.i = load <4 x i8>** %CastToValueType833.i, align 8
  %520 = load <4 x i8>* %loadedValue834.i, align 4
  %"&(pSB[currWI].offset)855.i" = add nuw i64 %CurrSBIndex..3.i, 400
  %"&pSB[currWI].offset856.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)855.i"
  %CastToValueType857.i = bitcast i8* %"&pSB[currWI].offset856.i" to <4 x i8>**
  %loadedValue858.i = load <4 x i8>** %CastToValueType857.i, align 8
  %521 = load <4 x i8>* %loadedValue858.i, align 4
  %"&(pSB[currWI].offset)879.i" = add nuw i64 %CurrSBIndex..3.i, 408
  %"&pSB[currWI].offset880.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)879.i"
  %CastToValueType881.i = bitcast i8* %"&pSB[currWI].offset880.i" to <4 x i8>**
  %loadedValue882.i = load <4 x i8>** %CastToValueType881.i, align 8
  %522 = load <4 x i8>* %loadedValue882.i, align 4
  %"&(pSB[currWI].offset)903.i" = add nuw i64 %CurrSBIndex..3.i, 416
  %"&pSB[currWI].offset904.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)903.i"
  %CastToValueType905.i = bitcast i8* %"&pSB[currWI].offset904.i" to <4 x i8>**
  %loadedValue906.i = load <4 x i8>** %CastToValueType905.i, align 8
  %523 = load <4 x i8>* %loadedValue906.i, align 4
  %"&(pSB[currWI].offset)927.i" = add nuw i64 %CurrSBIndex..3.i, 424
  %"&pSB[currWI].offset928.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)927.i"
  %CastToValueType929.i = bitcast i8* %"&pSB[currWI].offset928.i" to <4 x i8>**
  %loadedValue930.i = load <4 x i8>** %CastToValueType929.i, align 8
  %524 = load <4 x i8>* %loadedValue930.i, align 4
  %525 = extractelement <4 x i8> %509, i32 0
  %526 = extractelement <4 x i8> %510, i32 0
  %527 = extractelement <4 x i8> %511, i32 0
  %528 = extractelement <4 x i8> %512, i32 0
  %529 = extractelement <4 x i8> %513, i32 0
  %530 = extractelement <4 x i8> %514, i32 0
  %531 = extractelement <4 x i8> %515, i32 0
  %532 = extractelement <4 x i8> %516, i32 0
  %533 = extractelement <4 x i8> %517, i32 0
  %534 = extractelement <4 x i8> %518, i32 0
  %535 = extractelement <4 x i8> %519, i32 0
  %536 = extractelement <4 x i8> %520, i32 0
  %537 = extractelement <4 x i8> %521, i32 0
  %538 = extractelement <4 x i8> %522, i32 0
  %539 = extractelement <4 x i8> %523, i32 0
  %540 = extractelement <4 x i8> %524, i32 0
  %temp.vect247.i = insertelement <16 x i8> undef, i8 %525, i32 0
  %temp.vect248.i = insertelement <16 x i8> %temp.vect247.i, i8 %526, i32 1
  %temp.vect249.i = insertelement <16 x i8> %temp.vect248.i, i8 %527, i32 2
  %temp.vect250.i = insertelement <16 x i8> %temp.vect249.i, i8 %528, i32 3
  %temp.vect251.i = insertelement <16 x i8> %temp.vect250.i, i8 %529, i32 4
  %temp.vect252.i = insertelement <16 x i8> %temp.vect251.i, i8 %530, i32 5
  %temp.vect253.i = insertelement <16 x i8> %temp.vect252.i, i8 %531, i32 6
  %temp.vect254.i = insertelement <16 x i8> %temp.vect253.i, i8 %532, i32 7
  %temp.vect255.i = insertelement <16 x i8> %temp.vect254.i, i8 %533, i32 8
  %temp.vect256.i = insertelement <16 x i8> %temp.vect255.i, i8 %534, i32 9
  %temp.vect257.i = insertelement <16 x i8> %temp.vect256.i, i8 %535, i32 10
  %temp.vect258.i = insertelement <16 x i8> %temp.vect257.i, i8 %536, i32 11
  %temp.vect259.i = insertelement <16 x i8> %temp.vect258.i, i8 %537, i32 12
  %temp.vect260.i = insertelement <16 x i8> %temp.vect259.i, i8 %538, i32 13
  %temp.vect261.i = insertelement <16 x i8> %temp.vect260.i, i8 %539, i32 14
  %temp.vect262.i = insertelement <16 x i8> %temp.vect261.i, i8 %540, i32 15
  %541 = load <4 x i8> addrspace(3)* %13, align 4
  %scalar56.i = extractelement <4 x i8> %541, i32 3
  %temp265.i = insertelement <16 x i8> undef, i8 %scalar56.i, i32 0
  %vector266.i = shufflevector <16 x i8> %temp265.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %542 = zext i8 %scalar56.i to i32
  %543 = shl i32 %542, 1
  %544 = and i32 %542, 128
  %545 = xor i32 %543, 27
  %546 = icmp eq i32 %544, 0
  %a.7.in.i = select i1 %546, i32 %543, i32 %545
  %547 = shl i32 %a.7.in.i, 1
  %548 = and i32 %a.7.in.i, 128
  %549 = xor i32 %547, 27
  %550 = icmp eq i32 %548, 0
  %a.7.in.1.i = select i1 %550, i32 %547, i32 %549
  %551 = shl i32 %a.7.in.1.i, 1
  %552 = and i32 %a.7.in.1.i, 128
  %553 = xor i32 %551, 27
  %554 = icmp eq i32 %552, 0
  %a.7.in.2.i = select i1 %554, i32 %551, i32 %553
  %555 = shl i32 %a.7.in.2.i, 1
  %556 = and i32 %a.7.in.2.i, 128
  %557 = xor i32 %555, 27
  %558 = icmp eq i32 %556, 0
  %a.7.in.3.i = select i1 %558, i32 %555, i32 %557
  %559 = shl i32 %a.7.in.3.i, 1
  %560 = and i32 %a.7.in.3.i, 128
  %561 = xor i32 %559, 27
  %562 = icmp eq i32 %560, 0
  %a.7.in.4.i = select i1 %562, i32 %559, i32 %561
  %563 = shl i32 %a.7.in.4.i, 1
  %564 = and i32 %a.7.in.4.i, 128
  %565 = xor i32 %563, 27
  %566 = icmp eq i32 %564, 0
  %a.7.in.5.i = select i1 %566, i32 %563, i32 %565
  %567 = shl i32 %a.7.in.5.i, 1
  %568 = lshr <16 x i8> %temp.vect262.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %569 = zext <16 x i8> %568 to <16 x i32>
  %570 = zext <16 x i8> %temp.vect262.i to <16 x i32>
  %571 = lshr <16 x i8> %temp.vect262.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %572 = lshr <16 x i8> %temp.vect262.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %573 = and <16 x i32> %569, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %574 = and <16 x i32> %570, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %575 = zext <16 x i8> %571 to <16 x i32>
  %576 = zext <16 x i8> %572 to <16 x i32>
  %577 = icmp eq <16 x i32> %573, zeroinitializer
  %a.7.i = trunc i32 %a.7.in.i to i8
  %temp263.i = insertelement <16 x i8> undef, i8 %a.7.i, i32 0
  %vector264.i = shufflevector <16 x i8> %temp263.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %578 = icmp eq <16 x i32> %574, zeroinitializer
  %579 = and <16 x i32> %575, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %580 = lshr <16 x i8> %temp.vect262.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %581 = lshr <16 x i8> %temp.vect262.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %582 = and <16 x i32> %576, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %583 = select <16 x i1> %577, <16 x i8> zeroinitializer, <16 x i8> %vector264.i
  %584 = select <16 x i1> %578, <16 x i8> zeroinitializer, <16 x i8> %vector266.i
  %a.7.1.i = trunc i32 %a.7.in.1.i to i8
  %temp268.i = insertelement <16 x i8> undef, i8 %a.7.1.i, i32 0
  %vector269.i = shufflevector <16 x i8> %temp268.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %585 = icmp eq <16 x i32> %579, zeroinitializer
  %586 = zext <16 x i8> %580 to <16 x i32>
  %587 = zext <16 x i8> %581 to <16 x i32>
  %588 = icmp eq <16 x i32> %582, zeroinitializer
  %a.7.2.i = trunc i32 %a.7.in.2.i to i8
  %temp270.i = insertelement <16 x i8> undef, i8 %a.7.2.i, i32 0
  %vector271.i = shufflevector <16 x i8> %temp270.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..1267.i = xor <16 x i8> %583, %584
  %589 = select <16 x i1> %585, <16 x i8> zeroinitializer, <16 x i8> %vector269.i
  %590 = and <16 x i32> %586, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %591 = lshr <16 x i8> %temp.vect262.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %592 = and i32 %a.7.in.5.i, 128
  %593 = and <16 x i32> %587, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %594 = select <16 x i1> %588, <16 x i8> zeroinitializer, <16 x i8> %vector271.i
  %p.7..2272.i = xor <16 x i8> %589, %p.7..1267.i
  %a.7.3.i = trunc i32 %a.7.in.3.i to i8
  %temp274.i = insertelement <16 x i8> undef, i8 %a.7.3.i, i32 0
  %vector275.i = shufflevector <16 x i8> %temp274.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %595 = icmp eq <16 x i32> %590, zeroinitializer
  %596 = zext <16 x i8> %591 to <16 x i32>
  %597 = icmp eq i32 %592, 0
  %598 = xor i32 %567, 27
  %599 = icmp eq <16 x i32> %593, zeroinitializer
  %a.7.4.i = trunc i32 %a.7.in.4.i to i8
  %temp276.i = insertelement <16 x i8> undef, i8 %a.7.4.i, i32 0
  %vector277.i = shufflevector <16 x i8> %temp276.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..3273.i = xor <16 x i8> %594, %p.7..2272.i
  %600 = select <16 x i1> %595, <16 x i8> zeroinitializer, <16 x i8> %vector275.i
  %601 = and <16 x i32> %596, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.7.in.6.i = select i1 %597, i32 %567, i32 %598
  %602 = select <16 x i1> %599, <16 x i8> zeroinitializer, <16 x i8> %vector277.i
  %p.7..4278.i = xor <16 x i8> %600, %p.7..3273.i
  %a.7.5.i = trunc i32 %a.7.in.5.i to i8
  %temp280.i = insertelement <16 x i8> undef, i8 %a.7.5.i, i32 0
  %vector281.i = shufflevector <16 x i8> %temp280.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %603 = icmp eq <16 x i32> %601, zeroinitializer
  %604 = icmp sgt <16 x i8> %temp.vect262.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.7.6.i = trunc i32 %a.7.in.6.i to i8
  %temp282.i = insertelement <16 x i8> undef, i8 %a.7.6.i, i32 0
  %vector283.i = shufflevector <16 x i8> %temp282.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.7..5279.i = xor <16 x i8> %602, %p.7..4278.i
  %605 = select <16 x i1> %603, <16 x i8> zeroinitializer, <16 x i8> %vector281.i
  %606 = select <16 x i1> %604, <16 x i8> zeroinitializer, <16 x i8> %vector283.i
  %p.7..6284.i = xor <16 x i8> %605, %p.7..5279.i
  %p.7..7285.i = xor <16 x i8> %606, %p.7..6284.i
  %"&(pSB[currWI].offset)1074.i" = add nuw i64 %CurrSBIndex..3.i, 528
  %"&pSB[currWI].offset1075.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1074.i"
  %CastToValueType1076.i = bitcast i8* %"&pSB[currWI].offset1075.i" to <16 x i8>*
  store <16 x i8> %p.7..7285.i, <16 x i8>* %CastToValueType1076.i, align 16
  %"&(pSB[currWI].offset)1078.i" = add nuw i64 %CurrSBIndex..3.i, 544
  %"&pSB[currWI].offset1079.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1078.i"
  %CastToValueType1080.i = bitcast i8* %"&pSB[currWI].offset1079.i" to i64*
  %"&(pSB[currWI].offset)965.i" = add nuw i64 %CurrSBIndex..3.i, 440
  %"&pSB[currWI].offset966.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)965.i"
  %CastToValueType967.i = bitcast i8* %"&pSB[currWI].offset966.i" to i64*
  %"&(pSB[currWI].offset)1150.i" = add nuw i64 %CurrSBIndex..3.i, 640
  %"&pSB[currWI].offset1151.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1150.i"
  %CastToValueType1152.i = bitcast i8* %"&pSB[currWI].offset1151.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1186.i" = add nuw i64 %CurrSBIndex..3.i, 656
  %"&pSB[currWI].offset1187.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1186.i"
  %CastToValueType1188.i = bitcast i8* %"&pSB[currWI].offset1187.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1222.i" = add nuw i64 %CurrSBIndex..3.i, 672
  %"&pSB[currWI].offset1223.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1222.i"
  %CastToValueType1224.i = bitcast i8* %"&pSB[currWI].offset1223.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1258.i" = add nuw i64 %CurrSBIndex..3.i, 688
  %"&pSB[currWI].offset1259.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1258.i"
  %CastToValueType1260.i = bitcast i8* %"&pSB[currWI].offset1259.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1294.i" = add nuw i64 %CurrSBIndex..3.i, 704
  %"&pSB[currWI].offset1295.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1294.i"
  %CastToValueType1296.i = bitcast i8* %"&pSB[currWI].offset1295.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1330.i" = add nuw i64 %CurrSBIndex..3.i, 720
  %"&pSB[currWI].offset1331.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1330.i"
  %CastToValueType1332.i = bitcast i8* %"&pSB[currWI].offset1331.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1366.i" = add nuw i64 %CurrSBIndex..3.i, 736
  %"&pSB[currWI].offset1367.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1366.i"
  %CastToValueType1368.i = bitcast i8* %"&pSB[currWI].offset1367.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1402.i" = add nuw i64 %CurrSBIndex..3.i, 752
  %"&pSB[currWI].offset1403.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1402.i"
  %CastToValueType1404.i = bitcast i8* %"&pSB[currWI].offset1403.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1438.i" = add nuw i64 %CurrSBIndex..3.i, 768
  %"&pSB[currWI].offset1439.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1438.i"
  %CastToValueType1440.i = bitcast i8* %"&pSB[currWI].offset1439.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1474.i" = add nuw i64 %CurrSBIndex..3.i, 784
  %"&pSB[currWI].offset1475.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1474.i"
  %CastToValueType1476.i = bitcast i8* %"&pSB[currWI].offset1475.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1510.i" = add nuw i64 %CurrSBIndex..3.i, 800
  %"&pSB[currWI].offset1511.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1510.i"
  %CastToValueType1512.i = bitcast i8* %"&pSB[currWI].offset1511.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1546.i" = add nuw i64 %CurrSBIndex..3.i, 816
  %"&pSB[currWI].offset1547.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1546.i"
  %CastToValueType1548.i = bitcast i8* %"&pSB[currWI].offset1547.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1582.i" = add nuw i64 %CurrSBIndex..3.i, 832
  %"&pSB[currWI].offset1583.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1582.i"
  %CastToValueType1584.i = bitcast i8* %"&pSB[currWI].offset1583.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1618.i" = add nuw i64 %CurrSBIndex..3.i, 848
  %"&pSB[currWI].offset1619.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1618.i"
  %CastToValueType1620.i = bitcast i8* %"&pSB[currWI].offset1619.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1654.i" = add nuw i64 %CurrSBIndex..3.i, 864
  %"&pSB[currWI].offset1655.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1654.i"
  %CastToValueType1656.i = bitcast i8* %"&pSB[currWI].offset1655.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1690.i" = add nuw i64 %CurrSBIndex..3.i, 880
  %"&pSB[currWI].offset1691.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1690.i"
  %CastToValueType1692.i = bitcast i8* %"&pSB[currWI].offset1691.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1146.i" = add nuw i64 %CurrSBIndex..3.i, 640
  %"&pSB[currWI].offset1147.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1146.i"
  %CastToValueType1148.i = bitcast i8* %"&pSB[currWI].offset1147.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1182.i" = add nuw i64 %CurrSBIndex..3.i, 656
  %"&pSB[currWI].offset1183.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1182.i"
  %CastToValueType1184.i = bitcast i8* %"&pSB[currWI].offset1183.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1218.i" = add nuw i64 %CurrSBIndex..3.i, 672
  %"&pSB[currWI].offset1219.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1218.i"
  %CastToValueType1220.i = bitcast i8* %"&pSB[currWI].offset1219.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1254.i" = add nuw i64 %CurrSBIndex..3.i, 688
  %"&pSB[currWI].offset1255.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1254.i"
  %CastToValueType1256.i = bitcast i8* %"&pSB[currWI].offset1255.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1290.i" = add nuw i64 %CurrSBIndex..3.i, 704
  %"&pSB[currWI].offset1291.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1290.i"
  %CastToValueType1292.i = bitcast i8* %"&pSB[currWI].offset1291.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1326.i" = add nuw i64 %CurrSBIndex..3.i, 720
  %"&pSB[currWI].offset1327.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1326.i"
  %CastToValueType1328.i = bitcast i8* %"&pSB[currWI].offset1327.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1362.i" = add nuw i64 %CurrSBIndex..3.i, 736
  %"&pSB[currWI].offset1363.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1362.i"
  %CastToValueType1364.i = bitcast i8* %"&pSB[currWI].offset1363.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1398.i" = add nuw i64 %CurrSBIndex..3.i, 752
  %"&pSB[currWI].offset1399.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1398.i"
  %CastToValueType1400.i = bitcast i8* %"&pSB[currWI].offset1399.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1434.i" = add nuw i64 %CurrSBIndex..3.i, 768
  %"&pSB[currWI].offset1435.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1434.i"
  %CastToValueType1436.i = bitcast i8* %"&pSB[currWI].offset1435.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1470.i" = add nuw i64 %CurrSBIndex..3.i, 784
  %"&pSB[currWI].offset1471.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1470.i"
  %CastToValueType1472.i = bitcast i8* %"&pSB[currWI].offset1471.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1506.i" = add nuw i64 %CurrSBIndex..3.i, 800
  %"&pSB[currWI].offset1507.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1506.i"
  %CastToValueType1508.i = bitcast i8* %"&pSB[currWI].offset1507.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1542.i" = add nuw i64 %CurrSBIndex..3.i, 816
  %"&pSB[currWI].offset1543.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1542.i"
  %CastToValueType1544.i = bitcast i8* %"&pSB[currWI].offset1543.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1578.i" = add nuw i64 %CurrSBIndex..3.i, 832
  %"&pSB[currWI].offset1579.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1578.i"
  %CastToValueType1580.i = bitcast i8* %"&pSB[currWI].offset1579.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1614.i" = add nuw i64 %CurrSBIndex..3.i, 848
  %"&pSB[currWI].offset1615.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1614.i"
  %CastToValueType1616.i = bitcast i8* %"&pSB[currWI].offset1615.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1650.i" = add nuw i64 %CurrSBIndex..3.i, 864
  %"&pSB[currWI].offset1651.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1650.i"
  %CastToValueType1652.i = bitcast i8* %"&pSB[currWI].offset1651.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1686.i" = add nuw i64 %CurrSBIndex..3.i, 880
  %"&pSB[currWI].offset1687.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1686.i"
  %CastToValueType1688.i = bitcast i8* %"&pSB[currWI].offset1687.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1142.i" = add nuw i64 %CurrSBIndex..3.i, 640
  %"&pSB[currWI].offset1143.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1142.i"
  %CastToValueType1144.i = bitcast i8* %"&pSB[currWI].offset1143.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1178.i" = add nuw i64 %CurrSBIndex..3.i, 656
  %"&pSB[currWI].offset1179.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1178.i"
  %CastToValueType1180.i = bitcast i8* %"&pSB[currWI].offset1179.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1214.i" = add nuw i64 %CurrSBIndex..3.i, 672
  %"&pSB[currWI].offset1215.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1214.i"
  %CastToValueType1216.i = bitcast i8* %"&pSB[currWI].offset1215.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1250.i" = add nuw i64 %CurrSBIndex..3.i, 688
  %"&pSB[currWI].offset1251.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1250.i"
  %CastToValueType1252.i = bitcast i8* %"&pSB[currWI].offset1251.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1286.i" = add nuw i64 %CurrSBIndex..3.i, 704
  %"&pSB[currWI].offset1287.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1286.i"
  %CastToValueType1288.i = bitcast i8* %"&pSB[currWI].offset1287.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1322.i" = add nuw i64 %CurrSBIndex..3.i, 720
  %"&pSB[currWI].offset1323.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1322.i"
  %CastToValueType1324.i = bitcast i8* %"&pSB[currWI].offset1323.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1358.i" = add nuw i64 %CurrSBIndex..3.i, 736
  %"&pSB[currWI].offset1359.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1358.i"
  %CastToValueType1360.i = bitcast i8* %"&pSB[currWI].offset1359.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1394.i" = add nuw i64 %CurrSBIndex..3.i, 752
  %"&pSB[currWI].offset1395.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1394.i"
  %CastToValueType1396.i = bitcast i8* %"&pSB[currWI].offset1395.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1430.i" = add nuw i64 %CurrSBIndex..3.i, 768
  %"&pSB[currWI].offset1431.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1430.i"
  %CastToValueType1432.i = bitcast i8* %"&pSB[currWI].offset1431.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1466.i" = add nuw i64 %CurrSBIndex..3.i, 784
  %"&pSB[currWI].offset1467.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1466.i"
  %CastToValueType1468.i = bitcast i8* %"&pSB[currWI].offset1467.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1502.i" = add nuw i64 %CurrSBIndex..3.i, 800
  %"&pSB[currWI].offset1503.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1502.i"
  %CastToValueType1504.i = bitcast i8* %"&pSB[currWI].offset1503.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1538.i" = add nuw i64 %CurrSBIndex..3.i, 816
  %"&pSB[currWI].offset1539.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1538.i"
  %CastToValueType1540.i = bitcast i8* %"&pSB[currWI].offset1539.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1574.i" = add nuw i64 %CurrSBIndex..3.i, 832
  %"&pSB[currWI].offset1575.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1574.i"
  %CastToValueType1576.i = bitcast i8* %"&pSB[currWI].offset1575.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1610.i" = add nuw i64 %CurrSBIndex..3.i, 848
  %"&pSB[currWI].offset1611.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1610.i"
  %CastToValueType1612.i = bitcast i8* %"&pSB[currWI].offset1611.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1646.i" = add nuw i64 %CurrSBIndex..3.i, 864
  %"&pSB[currWI].offset1647.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1646.i"
  %CastToValueType1648.i = bitcast i8* %"&pSB[currWI].offset1647.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1682.i" = add nuw i64 %CurrSBIndex..3.i, 880
  %"&pSB[currWI].offset1683.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1682.i"
  %CastToValueType1684.i = bitcast i8* %"&pSB[currWI].offset1683.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1138.i" = add nuw i64 %CurrSBIndex..3.i, 640
  %"&pSB[currWI].offset1139.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1138.i"
  %CastToValueType1140.i = bitcast i8* %"&pSB[currWI].offset1139.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1174.i" = add nuw i64 %CurrSBIndex..3.i, 656
  %"&pSB[currWI].offset1175.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1174.i"
  %CastToValueType1176.i = bitcast i8* %"&pSB[currWI].offset1175.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1210.i" = add nuw i64 %CurrSBIndex..3.i, 672
  %"&pSB[currWI].offset1211.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1210.i"
  %CastToValueType1212.i = bitcast i8* %"&pSB[currWI].offset1211.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1246.i" = add nuw i64 %CurrSBIndex..3.i, 688
  %"&pSB[currWI].offset1247.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1246.i"
  %CastToValueType1248.i = bitcast i8* %"&pSB[currWI].offset1247.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1282.i" = add nuw i64 %CurrSBIndex..3.i, 704
  %"&pSB[currWI].offset1283.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1282.i"
  %CastToValueType1284.i = bitcast i8* %"&pSB[currWI].offset1283.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1318.i" = add nuw i64 %CurrSBIndex..3.i, 720
  %"&pSB[currWI].offset1319.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1318.i"
  %CastToValueType1320.i = bitcast i8* %"&pSB[currWI].offset1319.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1354.i" = add nuw i64 %CurrSBIndex..3.i, 736
  %"&pSB[currWI].offset1355.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1354.i"
  %CastToValueType1356.i = bitcast i8* %"&pSB[currWI].offset1355.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1390.i" = add nuw i64 %CurrSBIndex..3.i, 752
  %"&pSB[currWI].offset1391.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1390.i"
  %CastToValueType1392.i = bitcast i8* %"&pSB[currWI].offset1391.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1426.i" = add nuw i64 %CurrSBIndex..3.i, 768
  %"&pSB[currWI].offset1427.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1426.i"
  %CastToValueType1428.i = bitcast i8* %"&pSB[currWI].offset1427.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1462.i" = add nuw i64 %CurrSBIndex..3.i, 784
  %"&pSB[currWI].offset1463.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1462.i"
  %CastToValueType1464.i = bitcast i8* %"&pSB[currWI].offset1463.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1498.i" = add nuw i64 %CurrSBIndex..3.i, 800
  %"&pSB[currWI].offset1499.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1498.i"
  %CastToValueType1500.i = bitcast i8* %"&pSB[currWI].offset1499.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1534.i" = add nuw i64 %CurrSBIndex..3.i, 816
  %"&pSB[currWI].offset1535.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1534.i"
  %CastToValueType1536.i = bitcast i8* %"&pSB[currWI].offset1535.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1570.i" = add nuw i64 %CurrSBIndex..3.i, 832
  %"&pSB[currWI].offset1571.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1570.i"
  %CastToValueType1572.i = bitcast i8* %"&pSB[currWI].offset1571.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1606.i" = add nuw i64 %CurrSBIndex..3.i, 848
  %"&pSB[currWI].offset1607.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1606.i"
  %CastToValueType1608.i = bitcast i8* %"&pSB[currWI].offset1607.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1642.i" = add nuw i64 %CurrSBIndex..3.i, 864
  %"&pSB[currWI].offset1643.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1642.i"
  %CastToValueType1644.i = bitcast i8* %"&pSB[currWI].offset1643.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1678.i" = add nuw i64 %CurrSBIndex..3.i, 880
  %"&pSB[currWI].offset1679.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1678.i"
  %CastToValueType1680.i = bitcast i8* %"&pSB[currWI].offset1679.i" to [4 x <4 x i8>]*
  %"&(pSB[currWI].offset)1082.i" = add nuw i64 %CurrSBIndex..3.i, 560
  %"&pSB[currWI].offset1083.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1082.i"
  %CastToValueType1084.i = bitcast i8* %"&pSB[currWI].offset1083.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1091.i" = add nuw i64 %CurrSBIndex..3.i, 576
  %"&pSB[currWI].offset1092.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1091.i"
  %CastToValueType1093.i = bitcast i8* %"&pSB[currWI].offset1092.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1100.i" = add nuw i64 %CurrSBIndex..3.i, 592
  %"&pSB[currWI].offset1101.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1100.i"
  %CastToValueType1102.i = bitcast i8* %"&pSB[currWI].offset1101.i" to <16 x i8>*
  %"&(pSB[currWI].offset)1109.i" = add nuw i64 %CurrSBIndex..3.i, 608
  %"&pSB[currWI].offset1110.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1109.i"
  %CastToValueType1111.i = bitcast i8* %"&pSB[currWI].offset1110.i" to <16 x i8>*
  br label %607

; <label>:607                                     ; preds = %607, %SyncBB.i
  %indvar.i = phi i64 [ 0, %SyncBB.i ], [ %tmp.i, %607 ]
  %vectorPHI.i = phi <16 x i8> [ %p.7..7285.i, %SyncBB.i ], [ %1071, %607 ]
  %vectorPHI286.i = phi <16 x i8> [ %p.5..7246.i, %SyncBB.i ], [ %1070, %607 ]
  %vectorPHI287.i = phi <16 x i8> [ %p.3..7207.i, %SyncBB.i ], [ %1069, %607 ]
  %vectorPHI288.i = phi <16 x i8> [ %p.1..7168.i, %SyncBB.i ], [ %1068, %607 ]
  %tmp.i = add i64 %indvar.i, 1
  store i64 %tmp.i, i64* %CastToValueType1080.i, align 8
  %scevgep.i = getelementptr <4 x i8> addrspace(3)* %13, i64 %tmp.i
  %loadedValue968.i = load i64* %CastToValueType967.i, align 8
  %tmp77.i = add i64 %loadedValue968.i, %indvar.i
  %608 = and i64 %tmp77.i, 3
  %609 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1152.i, i64 0, i64 %608
  %610 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1188.i, i64 0, i64 %608
  %611 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1224.i, i64 0, i64 %608
  %612 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1260.i, i64 0, i64 %608
  %613 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1296.i, i64 0, i64 %608
  %614 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1332.i, i64 0, i64 %608
  %615 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1368.i, i64 0, i64 %608
  %616 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1404.i, i64 0, i64 %608
  %617 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1440.i, i64 0, i64 %608
  %618 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1476.i, i64 0, i64 %608
  %619 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1512.i, i64 0, i64 %608
  %620 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1548.i, i64 0, i64 %608
  %621 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1584.i, i64 0, i64 %608
  %622 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1620.i, i64 0, i64 %608
  %623 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1656.i, i64 0, i64 %608
  %624 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1692.i, i64 0, i64 %608
  %625 = load <4 x i8>* %609, align 4
  %626 = load <4 x i8>* %610, align 4
  %627 = load <4 x i8>* %611, align 4
  %628 = load <4 x i8>* %612, align 4
  %629 = load <4 x i8>* %613, align 4
  %630 = load <4 x i8>* %614, align 4
  %631 = load <4 x i8>* %615, align 4
  %632 = load <4 x i8>* %616, align 4
  %633 = load <4 x i8>* %617, align 4
  %634 = load <4 x i8>* %618, align 4
  %635 = load <4 x i8>* %619, align 4
  %636 = load <4 x i8>* %620, align 4
  %637 = load <4 x i8>* %621, align 4
  %638 = load <4 x i8>* %622, align 4
  %639 = load <4 x i8>* %623, align 4
  %640 = load <4 x i8>* %624, align 4
  %641 = extractelement <4 x i8> %625, i32 0
  %642 = extractelement <4 x i8> %626, i32 0
  %643 = extractelement <4 x i8> %627, i32 0
  %644 = extractelement <4 x i8> %628, i32 0
  %645 = extractelement <4 x i8> %629, i32 0
  %646 = extractelement <4 x i8> %630, i32 0
  %647 = extractelement <4 x i8> %631, i32 0
  %648 = extractelement <4 x i8> %632, i32 0
  %649 = extractelement <4 x i8> %633, i32 0
  %650 = extractelement <4 x i8> %634, i32 0
  %651 = extractelement <4 x i8> %635, i32 0
  %652 = extractelement <4 x i8> %636, i32 0
  %653 = extractelement <4 x i8> %637, i32 0
  %654 = extractelement <4 x i8> %638, i32 0
  %655 = extractelement <4 x i8> %639, i32 0
  %656 = extractelement <4 x i8> %640, i32 0
  %temp.vect289.i = insertelement <16 x i8> undef, i8 %641, i32 0
  %temp.vect290.i = insertelement <16 x i8> %temp.vect289.i, i8 %642, i32 1
  %temp.vect291.i = insertelement <16 x i8> %temp.vect290.i, i8 %643, i32 2
  %temp.vect292.i = insertelement <16 x i8> %temp.vect291.i, i8 %644, i32 3
  %temp.vect293.i = insertelement <16 x i8> %temp.vect292.i, i8 %645, i32 4
  %temp.vect294.i = insertelement <16 x i8> %temp.vect293.i, i8 %646, i32 5
  %temp.vect295.i = insertelement <16 x i8> %temp.vect294.i, i8 %647, i32 6
  %temp.vect296.i = insertelement <16 x i8> %temp.vect295.i, i8 %648, i32 7
  %temp.vect297.i = insertelement <16 x i8> %temp.vect296.i, i8 %649, i32 8
  %temp.vect298.i = insertelement <16 x i8> %temp.vect297.i, i8 %650, i32 9
  %temp.vect299.i = insertelement <16 x i8> %temp.vect298.i, i8 %651, i32 10
  %temp.vect300.i = insertelement <16 x i8> %temp.vect299.i, i8 %652, i32 11
  %temp.vect301.i = insertelement <16 x i8> %temp.vect300.i, i8 %653, i32 12
  %temp.vect302.i = insertelement <16 x i8> %temp.vect301.i, i8 %654, i32 13
  %temp.vect303.i = insertelement <16 x i8> %temp.vect302.i, i8 %655, i32 14
  %temp.vect304.i = insertelement <16 x i8> %temp.vect303.i, i8 %656, i32 15
  %657 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar61.i = extractelement <4 x i8> %657, i32 0
  %temp307.i = insertelement <16 x i8> undef, i8 %scalar61.i, i32 0
  %vector308.i = shufflevector <16 x i8> %temp307.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %658 = zext i8 %scalar61.i to i32
  %659 = shl i32 %658, 1
  %660 = and i32 %658, 128
  %661 = xor i32 %659, 27
  %662 = icmp eq i32 %660, 0
  %a.9.in.i = select i1 %662, i32 %659, i32 %661
  %663 = shl i32 %a.9.in.i, 1
  %664 = and i32 %a.9.in.i, 128
  %665 = xor i32 %663, 27
  %666 = icmp eq i32 %664, 0
  %a.9.in.1.i = select i1 %666, i32 %663, i32 %665
  %667 = shl i32 %a.9.in.1.i, 1
  %668 = and i32 %a.9.in.1.i, 128
  %669 = xor i32 %667, 27
  %670 = icmp eq i32 %668, 0
  %a.9.in.2.i = select i1 %670, i32 %667, i32 %669
  %671 = shl i32 %a.9.in.2.i, 1
  %672 = and i32 %a.9.in.2.i, 128
  %673 = xor i32 %671, 27
  %674 = icmp eq i32 %672, 0
  %a.9.in.3.i = select i1 %674, i32 %671, i32 %673
  %675 = shl i32 %a.9.in.3.i, 1
  %676 = and i32 %a.9.in.3.i, 128
  %677 = xor i32 %675, 27
  %678 = icmp eq i32 %676, 0
  %a.9.in.4.i = select i1 %678, i32 %675, i32 %677
  %679 = shl i32 %a.9.in.4.i, 1
  %680 = and i32 %a.9.in.4.i, 128
  %681 = xor i32 %679, 27
  %682 = icmp eq i32 %680, 0
  %a.9.in.5.i = select i1 %682, i32 %679, i32 %681
  %683 = shl i32 %a.9.in.5.i, 1
  %684 = lshr <16 x i8> %temp.vect304.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %685 = zext <16 x i8> %684 to <16 x i32>
  %686 = zext <16 x i8> %temp.vect304.i to <16 x i32>
  %687 = lshr <16 x i8> %temp.vect304.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %688 = lshr <16 x i8> %temp.vect304.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %689 = and <16 x i32> %685, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %690 = and <16 x i32> %686, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %691 = zext <16 x i8> %687 to <16 x i32>
  %692 = zext <16 x i8> %688 to <16 x i32>
  %693 = icmp eq <16 x i32> %689, zeroinitializer
  %a.9.i = trunc i32 %a.9.in.i to i8
  %temp305.i = insertelement <16 x i8> undef, i8 %a.9.i, i32 0
  %vector306.i = shufflevector <16 x i8> %temp305.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %694 = icmp eq <16 x i32> %690, zeroinitializer
  %695 = and <16 x i32> %691, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %696 = lshr <16 x i8> %temp.vect304.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %697 = lshr <16 x i8> %temp.vect304.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %698 = and <16 x i32> %692, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %699 = select <16 x i1> %693, <16 x i8> zeroinitializer, <16 x i8> %vector306.i
  %700 = select <16 x i1> %694, <16 x i8> zeroinitializer, <16 x i8> %vector308.i
  %a.9.1.i = trunc i32 %a.9.in.1.i to i8
  %temp310.i = insertelement <16 x i8> undef, i8 %a.9.1.i, i32 0
  %vector311.i = shufflevector <16 x i8> %temp310.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %701 = icmp eq <16 x i32> %695, zeroinitializer
  %702 = zext <16 x i8> %696 to <16 x i32>
  %703 = zext <16 x i8> %697 to <16 x i32>
  %704 = icmp eq <16 x i32> %698, zeroinitializer
  %a.9.2.i = trunc i32 %a.9.in.2.i to i8
  %temp312.i = insertelement <16 x i8> undef, i8 %a.9.2.i, i32 0
  %vector313.i = shufflevector <16 x i8> %temp312.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..1309.i = xor <16 x i8> %699, %700
  %705 = select <16 x i1> %701, <16 x i8> zeroinitializer, <16 x i8> %vector311.i
  %706 = and <16 x i32> %702, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %707 = lshr <16 x i8> %temp.vect304.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %708 = and i32 %a.9.in.5.i, 128
  %709 = and <16 x i32> %703, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %710 = select <16 x i1> %704, <16 x i8> zeroinitializer, <16 x i8> %vector313.i
  %p.9..2314.i = xor <16 x i8> %705, %p.9..1309.i
  %a.9.3.i = trunc i32 %a.9.in.3.i to i8
  %temp316.i = insertelement <16 x i8> undef, i8 %a.9.3.i, i32 0
  %vector317.i = shufflevector <16 x i8> %temp316.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %711 = icmp eq <16 x i32> %706, zeroinitializer
  %712 = zext <16 x i8> %707 to <16 x i32>
  %713 = icmp eq i32 %708, 0
  %714 = xor i32 %683, 27
  %715 = icmp eq <16 x i32> %709, zeroinitializer
  %a.9.4.i = trunc i32 %a.9.in.4.i to i8
  %temp318.i = insertelement <16 x i8> undef, i8 %a.9.4.i, i32 0
  %vector319.i = shufflevector <16 x i8> %temp318.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..3315.i = xor <16 x i8> %710, %p.9..2314.i
  %716 = select <16 x i1> %711, <16 x i8> zeroinitializer, <16 x i8> %vector317.i
  %717 = and <16 x i32> %712, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.9.in.6.i = select i1 %713, i32 %683, i32 %714
  %718 = select <16 x i1> %715, <16 x i8> zeroinitializer, <16 x i8> %vector319.i
  %p.9..4320.i = xor <16 x i8> %716, %p.9..3315.i
  %a.9.5.i = trunc i32 %a.9.in.5.i to i8
  %temp322.i = insertelement <16 x i8> undef, i8 %a.9.5.i, i32 0
  %vector323.i = shufflevector <16 x i8> %temp322.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %719 = icmp eq <16 x i32> %717, zeroinitializer
  %720 = icmp sgt <16 x i8> %temp.vect304.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.9.6.i = trunc i32 %a.9.in.6.i to i8
  %temp324.i = insertelement <16 x i8> undef, i8 %a.9.6.i, i32 0
  %vector325.i = shufflevector <16 x i8> %temp324.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.9..5321.i = xor <16 x i8> %718, %p.9..4320.i
  %721 = select <16 x i1> %719, <16 x i8> zeroinitializer, <16 x i8> %vector323.i
  %722 = select <16 x i1> %720, <16 x i8> zeroinitializer, <16 x i8> %vector325.i
  %p.9..6326.i = xor <16 x i8> %721, %p.9..5321.i
  %p.9..7327.i = xor <16 x i8> %722, %p.9..6326.i
  %723 = and i64 %tmp77.i, 3
  %724 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1148.i, i64 0, i64 %723
  %725 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1184.i, i64 0, i64 %723
  %726 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1220.i, i64 0, i64 %723
  %727 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1256.i, i64 0, i64 %723
  %728 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1292.i, i64 0, i64 %723
  %729 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1328.i, i64 0, i64 %723
  %730 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1364.i, i64 0, i64 %723
  %731 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1400.i, i64 0, i64 %723
  %732 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1436.i, i64 0, i64 %723
  %733 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1472.i, i64 0, i64 %723
  %734 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1508.i, i64 0, i64 %723
  %735 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1544.i, i64 0, i64 %723
  %736 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1580.i, i64 0, i64 %723
  %737 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1616.i, i64 0, i64 %723
  %738 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1652.i, i64 0, i64 %723
  %739 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1688.i, i64 0, i64 %723
  %740 = load <4 x i8>* %724, align 4
  %741 = load <4 x i8>* %725, align 4
  %742 = load <4 x i8>* %726, align 4
  %743 = load <4 x i8>* %727, align 4
  %744 = load <4 x i8>* %728, align 4
  %745 = load <4 x i8>* %729, align 4
  %746 = load <4 x i8>* %730, align 4
  %747 = load <4 x i8>* %731, align 4
  %748 = load <4 x i8>* %732, align 4
  %749 = load <4 x i8>* %733, align 4
  %750 = load <4 x i8>* %734, align 4
  %751 = load <4 x i8>* %735, align 4
  %752 = load <4 x i8>* %736, align 4
  %753 = load <4 x i8>* %737, align 4
  %754 = load <4 x i8>* %738, align 4
  %755 = load <4 x i8>* %739, align 4
  %756 = extractelement <4 x i8> %740, i32 0
  %757 = extractelement <4 x i8> %741, i32 0
  %758 = extractelement <4 x i8> %742, i32 0
  %759 = extractelement <4 x i8> %743, i32 0
  %760 = extractelement <4 x i8> %744, i32 0
  %761 = extractelement <4 x i8> %745, i32 0
  %762 = extractelement <4 x i8> %746, i32 0
  %763 = extractelement <4 x i8> %747, i32 0
  %764 = extractelement <4 x i8> %748, i32 0
  %765 = extractelement <4 x i8> %749, i32 0
  %766 = extractelement <4 x i8> %750, i32 0
  %767 = extractelement <4 x i8> %751, i32 0
  %768 = extractelement <4 x i8> %752, i32 0
  %769 = extractelement <4 x i8> %753, i32 0
  %770 = extractelement <4 x i8> %754, i32 0
  %771 = extractelement <4 x i8> %755, i32 0
  %temp.vect328.i = insertelement <16 x i8> undef, i8 %756, i32 0
  %temp.vect329.i = insertelement <16 x i8> %temp.vect328.i, i8 %757, i32 1
  %temp.vect330.i = insertelement <16 x i8> %temp.vect329.i, i8 %758, i32 2
  %temp.vect331.i = insertelement <16 x i8> %temp.vect330.i, i8 %759, i32 3
  %temp.vect332.i = insertelement <16 x i8> %temp.vect331.i, i8 %760, i32 4
  %temp.vect333.i = insertelement <16 x i8> %temp.vect332.i, i8 %761, i32 5
  %temp.vect334.i = insertelement <16 x i8> %temp.vect333.i, i8 %762, i32 6
  %temp.vect335.i = insertelement <16 x i8> %temp.vect334.i, i8 %763, i32 7
  %temp.vect336.i = insertelement <16 x i8> %temp.vect335.i, i8 %764, i32 8
  %temp.vect337.i = insertelement <16 x i8> %temp.vect336.i, i8 %765, i32 9
  %temp.vect338.i = insertelement <16 x i8> %temp.vect337.i, i8 %766, i32 10
  %temp.vect339.i = insertelement <16 x i8> %temp.vect338.i, i8 %767, i32 11
  %temp.vect340.i = insertelement <16 x i8> %temp.vect339.i, i8 %768, i32 12
  %temp.vect341.i = insertelement <16 x i8> %temp.vect340.i, i8 %769, i32 13
  %temp.vect342.i = insertelement <16 x i8> %temp.vect341.i, i8 %770, i32 14
  %temp.vect343.i = insertelement <16 x i8> %temp.vect342.i, i8 %771, i32 15
  %772 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar70.i = extractelement <4 x i8> %772, i32 1
  %temp346.i = insertelement <16 x i8> undef, i8 %scalar70.i, i32 0
  %vector347.i = shufflevector <16 x i8> %temp346.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %773 = zext i8 %scalar70.i to i32
  %774 = shl i32 %773, 1
  %775 = and i32 %773, 128
  %776 = xor i32 %774, 27
  %777 = icmp eq i32 %775, 0
  %a.11.in.i = select i1 %777, i32 %774, i32 %776
  %778 = shl i32 %a.11.in.i, 1
  %779 = and i32 %a.11.in.i, 128
  %780 = xor i32 %778, 27
  %781 = icmp eq i32 %779, 0
  %a.11.in.1.i = select i1 %781, i32 %778, i32 %780
  %782 = shl i32 %a.11.in.1.i, 1
  %783 = and i32 %a.11.in.1.i, 128
  %784 = xor i32 %782, 27
  %785 = icmp eq i32 %783, 0
  %a.11.in.2.i = select i1 %785, i32 %782, i32 %784
  %786 = shl i32 %a.11.in.2.i, 1
  %787 = and i32 %a.11.in.2.i, 128
  %788 = xor i32 %786, 27
  %789 = icmp eq i32 %787, 0
  %a.11.in.3.i = select i1 %789, i32 %786, i32 %788
  %790 = shl i32 %a.11.in.3.i, 1
  %791 = and i32 %a.11.in.3.i, 128
  %792 = xor i32 %790, 27
  %793 = icmp eq i32 %791, 0
  %a.11.in.4.i = select i1 %793, i32 %790, i32 %792
  %794 = shl i32 %a.11.in.4.i, 1
  %795 = and i32 %a.11.in.4.i, 128
  %796 = xor i32 %794, 27
  %797 = icmp eq i32 %795, 0
  %a.11.in.5.i = select i1 %797, i32 %794, i32 %796
  %798 = shl i32 %a.11.in.5.i, 1
  %799 = lshr <16 x i8> %temp.vect343.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %800 = zext <16 x i8> %799 to <16 x i32>
  %801 = zext <16 x i8> %temp.vect343.i to <16 x i32>
  %802 = lshr <16 x i8> %temp.vect343.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %803 = lshr <16 x i8> %temp.vect343.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %804 = and <16 x i32> %800, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %805 = and <16 x i32> %801, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %806 = zext <16 x i8> %802 to <16 x i32>
  %807 = zext <16 x i8> %803 to <16 x i32>
  %808 = icmp eq <16 x i32> %804, zeroinitializer
  %a.11.i = trunc i32 %a.11.in.i to i8
  %temp344.i = insertelement <16 x i8> undef, i8 %a.11.i, i32 0
  %vector345.i = shufflevector <16 x i8> %temp344.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %809 = icmp eq <16 x i32> %805, zeroinitializer
  %810 = and <16 x i32> %806, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %811 = lshr <16 x i8> %temp.vect343.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %812 = lshr <16 x i8> %temp.vect343.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %813 = and <16 x i32> %807, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %814 = select <16 x i1> %808, <16 x i8> zeroinitializer, <16 x i8> %vector345.i
  %815 = select <16 x i1> %809, <16 x i8> zeroinitializer, <16 x i8> %vector347.i
  %a.11.1.i = trunc i32 %a.11.in.1.i to i8
  %temp349.i = insertelement <16 x i8> undef, i8 %a.11.1.i, i32 0
  %vector350.i = shufflevector <16 x i8> %temp349.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %816 = icmp eq <16 x i32> %810, zeroinitializer
  %817 = zext <16 x i8> %811 to <16 x i32>
  %818 = zext <16 x i8> %812 to <16 x i32>
  %819 = icmp eq <16 x i32> %813, zeroinitializer
  %a.11.2.i = trunc i32 %a.11.in.2.i to i8
  %temp351.i = insertelement <16 x i8> undef, i8 %a.11.2.i, i32 0
  %vector352.i = shufflevector <16 x i8> %temp351.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..1348.i = xor <16 x i8> %814, %815
  %820 = select <16 x i1> %816, <16 x i8> zeroinitializer, <16 x i8> %vector350.i
  %821 = and <16 x i32> %817, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %822 = lshr <16 x i8> %temp.vect343.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %823 = and i32 %a.11.in.5.i, 128
  %824 = and <16 x i32> %818, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %825 = select <16 x i1> %819, <16 x i8> zeroinitializer, <16 x i8> %vector352.i
  %p.11..2353.i = xor <16 x i8> %820, %p.11..1348.i
  %a.11.3.i = trunc i32 %a.11.in.3.i to i8
  %temp355.i = insertelement <16 x i8> undef, i8 %a.11.3.i, i32 0
  %vector356.i = shufflevector <16 x i8> %temp355.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %826 = icmp eq <16 x i32> %821, zeroinitializer
  %827 = zext <16 x i8> %822 to <16 x i32>
  %828 = icmp eq i32 %823, 0
  %829 = xor i32 %798, 27
  %830 = icmp eq <16 x i32> %824, zeroinitializer
  %a.11.4.i = trunc i32 %a.11.in.4.i to i8
  %temp357.i = insertelement <16 x i8> undef, i8 %a.11.4.i, i32 0
  %vector358.i = shufflevector <16 x i8> %temp357.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..3354.i = xor <16 x i8> %825, %p.11..2353.i
  %831 = select <16 x i1> %826, <16 x i8> zeroinitializer, <16 x i8> %vector356.i
  %832 = and <16 x i32> %827, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.11.in.6.i = select i1 %828, i32 %798, i32 %829
  %833 = select <16 x i1> %830, <16 x i8> zeroinitializer, <16 x i8> %vector358.i
  %p.11..4359.i = xor <16 x i8> %831, %p.11..3354.i
  %a.11.5.i = trunc i32 %a.11.in.5.i to i8
  %temp361.i = insertelement <16 x i8> undef, i8 %a.11.5.i, i32 0
  %vector362.i = shufflevector <16 x i8> %temp361.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %834 = icmp eq <16 x i32> %832, zeroinitializer
  %835 = icmp sgt <16 x i8> %temp.vect343.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.11.6.i = trunc i32 %a.11.in.6.i to i8
  %temp363.i = insertelement <16 x i8> undef, i8 %a.11.6.i, i32 0
  %vector364.i = shufflevector <16 x i8> %temp363.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.11..5360.i = xor <16 x i8> %833, %p.11..4359.i
  %836 = select <16 x i1> %834, <16 x i8> zeroinitializer, <16 x i8> %vector362.i
  %837 = select <16 x i1> %835, <16 x i8> zeroinitializer, <16 x i8> %vector364.i
  %p.11..6365.i = xor <16 x i8> %836, %p.11..5360.i
  %p.11..7366.i = xor <16 x i8> %837, %p.11..6365.i
  %838 = and i64 %tmp77.i, 3
  %839 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1144.i, i64 0, i64 %838
  %840 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1180.i, i64 0, i64 %838
  %841 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1216.i, i64 0, i64 %838
  %842 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1252.i, i64 0, i64 %838
  %843 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1288.i, i64 0, i64 %838
  %844 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1324.i, i64 0, i64 %838
  %845 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1360.i, i64 0, i64 %838
  %846 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1396.i, i64 0, i64 %838
  %847 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1432.i, i64 0, i64 %838
  %848 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1468.i, i64 0, i64 %838
  %849 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1504.i, i64 0, i64 %838
  %850 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1540.i, i64 0, i64 %838
  %851 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1576.i, i64 0, i64 %838
  %852 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1612.i, i64 0, i64 %838
  %853 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1648.i, i64 0, i64 %838
  %854 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1684.i, i64 0, i64 %838
  %855 = load <4 x i8>* %839, align 4
  %856 = load <4 x i8>* %840, align 4
  %857 = load <4 x i8>* %841, align 4
  %858 = load <4 x i8>* %842, align 4
  %859 = load <4 x i8>* %843, align 4
  %860 = load <4 x i8>* %844, align 4
  %861 = load <4 x i8>* %845, align 4
  %862 = load <4 x i8>* %846, align 4
  %863 = load <4 x i8>* %847, align 4
  %864 = load <4 x i8>* %848, align 4
  %865 = load <4 x i8>* %849, align 4
  %866 = load <4 x i8>* %850, align 4
  %867 = load <4 x i8>* %851, align 4
  %868 = load <4 x i8>* %852, align 4
  %869 = load <4 x i8>* %853, align 4
  %870 = load <4 x i8>* %854, align 4
  %871 = extractelement <4 x i8> %855, i32 0
  %872 = extractelement <4 x i8> %856, i32 0
  %873 = extractelement <4 x i8> %857, i32 0
  %874 = extractelement <4 x i8> %858, i32 0
  %875 = extractelement <4 x i8> %859, i32 0
  %876 = extractelement <4 x i8> %860, i32 0
  %877 = extractelement <4 x i8> %861, i32 0
  %878 = extractelement <4 x i8> %862, i32 0
  %879 = extractelement <4 x i8> %863, i32 0
  %880 = extractelement <4 x i8> %864, i32 0
  %881 = extractelement <4 x i8> %865, i32 0
  %882 = extractelement <4 x i8> %866, i32 0
  %883 = extractelement <4 x i8> %867, i32 0
  %884 = extractelement <4 x i8> %868, i32 0
  %885 = extractelement <4 x i8> %869, i32 0
  %886 = extractelement <4 x i8> %870, i32 0
  %temp.vect367.i = insertelement <16 x i8> undef, i8 %871, i32 0
  %temp.vect368.i = insertelement <16 x i8> %temp.vect367.i, i8 %872, i32 1
  %temp.vect369.i = insertelement <16 x i8> %temp.vect368.i, i8 %873, i32 2
  %temp.vect370.i = insertelement <16 x i8> %temp.vect369.i, i8 %874, i32 3
  %temp.vect371.i = insertelement <16 x i8> %temp.vect370.i, i8 %875, i32 4
  %temp.vect372.i = insertelement <16 x i8> %temp.vect371.i, i8 %876, i32 5
  %temp.vect373.i = insertelement <16 x i8> %temp.vect372.i, i8 %877, i32 6
  %temp.vect374.i = insertelement <16 x i8> %temp.vect373.i, i8 %878, i32 7
  %temp.vect375.i = insertelement <16 x i8> %temp.vect374.i, i8 %879, i32 8
  %temp.vect376.i = insertelement <16 x i8> %temp.vect375.i, i8 %880, i32 9
  %temp.vect377.i = insertelement <16 x i8> %temp.vect376.i, i8 %881, i32 10
  %temp.vect378.i = insertelement <16 x i8> %temp.vect377.i, i8 %882, i32 11
  %temp.vect379.i = insertelement <16 x i8> %temp.vect378.i, i8 %883, i32 12
  %temp.vect380.i = insertelement <16 x i8> %temp.vect379.i, i8 %884, i32 13
  %temp.vect381.i = insertelement <16 x i8> %temp.vect380.i, i8 %885, i32 14
  %temp.vect382.i = insertelement <16 x i8> %temp.vect381.i, i8 %886, i32 15
  %887 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar79.i = extractelement <4 x i8> %887, i32 2
  %temp385.i = insertelement <16 x i8> undef, i8 %scalar79.i, i32 0
  %vector386.i = shufflevector <16 x i8> %temp385.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %888 = zext i8 %scalar79.i to i32
  %889 = shl i32 %888, 1
  %890 = and i32 %888, 128
  %891 = xor i32 %889, 27
  %892 = icmp eq i32 %890, 0
  %a.13.in.i = select i1 %892, i32 %889, i32 %891
  %893 = shl i32 %a.13.in.i, 1
  %894 = and i32 %a.13.in.i, 128
  %895 = xor i32 %893, 27
  %896 = icmp eq i32 %894, 0
  %a.13.in.1.i = select i1 %896, i32 %893, i32 %895
  %897 = shl i32 %a.13.in.1.i, 1
  %898 = and i32 %a.13.in.1.i, 128
  %899 = xor i32 %897, 27
  %900 = icmp eq i32 %898, 0
  %a.13.in.2.i = select i1 %900, i32 %897, i32 %899
  %901 = shl i32 %a.13.in.2.i, 1
  %902 = and i32 %a.13.in.2.i, 128
  %903 = xor i32 %901, 27
  %904 = icmp eq i32 %902, 0
  %a.13.in.3.i = select i1 %904, i32 %901, i32 %903
  %905 = shl i32 %a.13.in.3.i, 1
  %906 = and i32 %a.13.in.3.i, 128
  %907 = xor i32 %905, 27
  %908 = icmp eq i32 %906, 0
  %a.13.in.4.i = select i1 %908, i32 %905, i32 %907
  %909 = shl i32 %a.13.in.4.i, 1
  %910 = and i32 %a.13.in.4.i, 128
  %911 = xor i32 %909, 27
  %912 = icmp eq i32 %910, 0
  %a.13.in.5.i = select i1 %912, i32 %909, i32 %911
  %913 = shl i32 %a.13.in.5.i, 1
  %914 = lshr <16 x i8> %temp.vect382.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %915 = zext <16 x i8> %914 to <16 x i32>
  %916 = zext <16 x i8> %temp.vect382.i to <16 x i32>
  %917 = lshr <16 x i8> %temp.vect382.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %918 = lshr <16 x i8> %temp.vect382.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %919 = and <16 x i32> %915, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %920 = and <16 x i32> %916, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %921 = zext <16 x i8> %917 to <16 x i32>
  %922 = zext <16 x i8> %918 to <16 x i32>
  %923 = icmp eq <16 x i32> %919, zeroinitializer
  %a.13.i = trunc i32 %a.13.in.i to i8
  %temp383.i = insertelement <16 x i8> undef, i8 %a.13.i, i32 0
  %vector384.i = shufflevector <16 x i8> %temp383.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %924 = icmp eq <16 x i32> %920, zeroinitializer
  %925 = and <16 x i32> %921, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %926 = lshr <16 x i8> %temp.vect382.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %927 = lshr <16 x i8> %temp.vect382.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %928 = and <16 x i32> %922, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %929 = select <16 x i1> %923, <16 x i8> zeroinitializer, <16 x i8> %vector384.i
  %930 = select <16 x i1> %924, <16 x i8> zeroinitializer, <16 x i8> %vector386.i
  %a.13.1.i = trunc i32 %a.13.in.1.i to i8
  %temp388.i = insertelement <16 x i8> undef, i8 %a.13.1.i, i32 0
  %vector389.i = shufflevector <16 x i8> %temp388.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %931 = icmp eq <16 x i32> %925, zeroinitializer
  %932 = zext <16 x i8> %926 to <16 x i32>
  %933 = zext <16 x i8> %927 to <16 x i32>
  %934 = icmp eq <16 x i32> %928, zeroinitializer
  %a.13.2.i = trunc i32 %a.13.in.2.i to i8
  %temp390.i = insertelement <16 x i8> undef, i8 %a.13.2.i, i32 0
  %vector391.i = shufflevector <16 x i8> %temp390.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..1387.i = xor <16 x i8> %929, %930
  %935 = select <16 x i1> %931, <16 x i8> zeroinitializer, <16 x i8> %vector389.i
  %936 = and <16 x i32> %932, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %937 = lshr <16 x i8> %temp.vect382.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %938 = and i32 %a.13.in.5.i, 128
  %939 = and <16 x i32> %933, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %940 = select <16 x i1> %934, <16 x i8> zeroinitializer, <16 x i8> %vector391.i
  %p.13..2392.i = xor <16 x i8> %935, %p.13..1387.i
  %a.13.3.i = trunc i32 %a.13.in.3.i to i8
  %temp394.i = insertelement <16 x i8> undef, i8 %a.13.3.i, i32 0
  %vector395.i = shufflevector <16 x i8> %temp394.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %941 = icmp eq <16 x i32> %936, zeroinitializer
  %942 = zext <16 x i8> %937 to <16 x i32>
  %943 = icmp eq i32 %938, 0
  %944 = xor i32 %913, 27
  %945 = icmp eq <16 x i32> %939, zeroinitializer
  %a.13.4.i = trunc i32 %a.13.in.4.i to i8
  %temp396.i = insertelement <16 x i8> undef, i8 %a.13.4.i, i32 0
  %vector397.i = shufflevector <16 x i8> %temp396.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..3393.i = xor <16 x i8> %940, %p.13..2392.i
  %946 = select <16 x i1> %941, <16 x i8> zeroinitializer, <16 x i8> %vector395.i
  %947 = and <16 x i32> %942, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.13.in.6.i = select i1 %943, i32 %913, i32 %944
  %948 = select <16 x i1> %945, <16 x i8> zeroinitializer, <16 x i8> %vector397.i
  %p.13..4398.i = xor <16 x i8> %946, %p.13..3393.i
  %a.13.5.i = trunc i32 %a.13.in.5.i to i8
  %temp400.i = insertelement <16 x i8> undef, i8 %a.13.5.i, i32 0
  %vector401.i = shufflevector <16 x i8> %temp400.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %949 = icmp eq <16 x i32> %947, zeroinitializer
  %950 = icmp sgt <16 x i8> %temp.vect382.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.13.6.i = trunc i32 %a.13.in.6.i to i8
  %temp402.i = insertelement <16 x i8> undef, i8 %a.13.6.i, i32 0
  %vector403.i = shufflevector <16 x i8> %temp402.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.13..5399.i = xor <16 x i8> %948, %p.13..4398.i
  %951 = select <16 x i1> %949, <16 x i8> zeroinitializer, <16 x i8> %vector401.i
  %952 = select <16 x i1> %950, <16 x i8> zeroinitializer, <16 x i8> %vector403.i
  %p.13..6404.i = xor <16 x i8> %951, %p.13..5399.i
  %p.13..7405.i = xor <16 x i8> %952, %p.13..6404.i
  %953 = and i64 %tmp77.i, 3
  %954 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1140.i, i64 0, i64 %953
  %955 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1176.i, i64 0, i64 %953
  %956 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1212.i, i64 0, i64 %953
  %957 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1248.i, i64 0, i64 %953
  %958 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1284.i, i64 0, i64 %953
  %959 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1320.i, i64 0, i64 %953
  %960 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1356.i, i64 0, i64 %953
  %961 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1392.i, i64 0, i64 %953
  %962 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1428.i, i64 0, i64 %953
  %963 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1464.i, i64 0, i64 %953
  %964 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1500.i, i64 0, i64 %953
  %965 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1536.i, i64 0, i64 %953
  %966 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1572.i, i64 0, i64 %953
  %967 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1608.i, i64 0, i64 %953
  %968 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1644.i, i64 0, i64 %953
  %969 = getelementptr inbounds [4 x <4 x i8>]* %CastToValueType1680.i, i64 0, i64 %953
  %970 = load <4 x i8>* %954, align 4
  %971 = load <4 x i8>* %955, align 4
  %972 = load <4 x i8>* %956, align 4
  %973 = load <4 x i8>* %957, align 4
  %974 = load <4 x i8>* %958, align 4
  %975 = load <4 x i8>* %959, align 4
  %976 = load <4 x i8>* %960, align 4
  %977 = load <4 x i8>* %961, align 4
  %978 = load <4 x i8>* %962, align 4
  %979 = load <4 x i8>* %963, align 4
  %980 = load <4 x i8>* %964, align 4
  %981 = load <4 x i8>* %965, align 4
  %982 = load <4 x i8>* %966, align 4
  %983 = load <4 x i8>* %967, align 4
  %984 = load <4 x i8>* %968, align 4
  %985 = load <4 x i8>* %969, align 4
  %986 = extractelement <4 x i8> %970, i32 0
  %987 = extractelement <4 x i8> %971, i32 0
  %988 = extractelement <4 x i8> %972, i32 0
  %989 = extractelement <4 x i8> %973, i32 0
  %990 = extractelement <4 x i8> %974, i32 0
  %991 = extractelement <4 x i8> %975, i32 0
  %992 = extractelement <4 x i8> %976, i32 0
  %993 = extractelement <4 x i8> %977, i32 0
  %994 = extractelement <4 x i8> %978, i32 0
  %995 = extractelement <4 x i8> %979, i32 0
  %996 = extractelement <4 x i8> %980, i32 0
  %997 = extractelement <4 x i8> %981, i32 0
  %998 = extractelement <4 x i8> %982, i32 0
  %999 = extractelement <4 x i8> %983, i32 0
  %1000 = extractelement <4 x i8> %984, i32 0
  %1001 = extractelement <4 x i8> %985, i32 0
  %temp.vect406.i = insertelement <16 x i8> undef, i8 %986, i32 0
  %temp.vect407.i = insertelement <16 x i8> %temp.vect406.i, i8 %987, i32 1
  %temp.vect408.i = insertelement <16 x i8> %temp.vect407.i, i8 %988, i32 2
  %temp.vect409.i = insertelement <16 x i8> %temp.vect408.i, i8 %989, i32 3
  %temp.vect410.i = insertelement <16 x i8> %temp.vect409.i, i8 %990, i32 4
  %temp.vect411.i = insertelement <16 x i8> %temp.vect410.i, i8 %991, i32 5
  %temp.vect412.i = insertelement <16 x i8> %temp.vect411.i, i8 %992, i32 6
  %temp.vect413.i = insertelement <16 x i8> %temp.vect412.i, i8 %993, i32 7
  %temp.vect414.i = insertelement <16 x i8> %temp.vect413.i, i8 %994, i32 8
  %temp.vect415.i = insertelement <16 x i8> %temp.vect414.i, i8 %995, i32 9
  %temp.vect416.i = insertelement <16 x i8> %temp.vect415.i, i8 %996, i32 10
  %temp.vect417.i = insertelement <16 x i8> %temp.vect416.i, i8 %997, i32 11
  %temp.vect418.i = insertelement <16 x i8> %temp.vect417.i, i8 %998, i32 12
  %temp.vect419.i = insertelement <16 x i8> %temp.vect418.i, i8 %999, i32 13
  %temp.vect420.i = insertelement <16 x i8> %temp.vect419.i, i8 %1000, i32 14
  %temp.vect421.i = insertelement <16 x i8> %temp.vect420.i, i8 %1001, i32 15
  %1002 = load <4 x i8> addrspace(3)* %scevgep.i, align 4
  %scalar88.i = extractelement <4 x i8> %1002, i32 3
  %temp424.i = insertelement <16 x i8> undef, i8 %scalar88.i, i32 0
  %vector425.i = shufflevector <16 x i8> %temp424.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1003 = zext i8 %scalar88.i to i32
  %1004 = shl i32 %1003, 1
  %1005 = and i32 %1003, 128
  %1006 = xor i32 %1004, 27
  %1007 = icmp eq i32 %1005, 0
  %a.15.in.i = select i1 %1007, i32 %1004, i32 %1006
  %1008 = shl i32 %a.15.in.i, 1
  %1009 = and i32 %a.15.in.i, 128
  %1010 = xor i32 %1008, 27
  %1011 = icmp eq i32 %1009, 0
  %a.15.in.1.i = select i1 %1011, i32 %1008, i32 %1010
  %1012 = shl i32 %a.15.in.1.i, 1
  %1013 = and i32 %a.15.in.1.i, 128
  %1014 = xor i32 %1012, 27
  %1015 = icmp eq i32 %1013, 0
  %a.15.in.2.i = select i1 %1015, i32 %1012, i32 %1014
  %1016 = shl i32 %a.15.in.2.i, 1
  %1017 = and i32 %a.15.in.2.i, 128
  %1018 = xor i32 %1016, 27
  %1019 = icmp eq i32 %1017, 0
  %a.15.in.3.i = select i1 %1019, i32 %1016, i32 %1018
  %1020 = shl i32 %a.15.in.3.i, 1
  %1021 = and i32 %a.15.in.3.i, 128
  %1022 = xor i32 %1020, 27
  %1023 = icmp eq i32 %1021, 0
  %a.15.in.4.i = select i1 %1023, i32 %1020, i32 %1022
  %1024 = shl i32 %a.15.in.4.i, 1
  %1025 = and i32 %a.15.in.4.i, 128
  %1026 = xor i32 %1024, 27
  %1027 = icmp eq i32 %1025, 0
  %a.15.in.5.i = select i1 %1027, i32 %1024, i32 %1026
  %1028 = shl i32 %a.15.in.5.i, 1
  %1029 = lshr <16 x i8> %temp.vect421.i, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %1030 = zext <16 x i8> %1029 to <16 x i32>
  %1031 = zext <16 x i8> %temp.vect421.i to <16 x i32>
  %1032 = lshr <16 x i8> %temp.vect421.i, <i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2, i8 2>
  %1033 = lshr <16 x i8> %temp.vect421.i, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %1034 = and <16 x i32> %1030, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1035 = and <16 x i32> %1031, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1036 = zext <16 x i8> %1032 to <16 x i32>
  %1037 = zext <16 x i8> %1033 to <16 x i32>
  %1038 = icmp eq <16 x i32> %1034, zeroinitializer
  %a.15.i = trunc i32 %a.15.in.i to i8
  %temp422.i = insertelement <16 x i8> undef, i8 %a.15.i, i32 0
  %vector423.i = shufflevector <16 x i8> %temp422.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1039 = icmp eq <16 x i32> %1035, zeroinitializer
  %1040 = and <16 x i32> %1036, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1041 = lshr <16 x i8> %temp.vect421.i, <i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4, i8 4>
  %1042 = lshr <16 x i8> %temp.vect421.i, <i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5, i8 5>
  %1043 = and <16 x i32> %1037, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1044 = select <16 x i1> %1038, <16 x i8> zeroinitializer, <16 x i8> %vector423.i
  %1045 = select <16 x i1> %1039, <16 x i8> zeroinitializer, <16 x i8> %vector425.i
  %a.15.1.i = trunc i32 %a.15.in.1.i to i8
  %temp427.i = insertelement <16 x i8> undef, i8 %a.15.1.i, i32 0
  %vector428.i = shufflevector <16 x i8> %temp427.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1046 = icmp eq <16 x i32> %1040, zeroinitializer
  %1047 = zext <16 x i8> %1041 to <16 x i32>
  %1048 = zext <16 x i8> %1042 to <16 x i32>
  %1049 = icmp eq <16 x i32> %1043, zeroinitializer
  %a.15.2.i = trunc i32 %a.15.in.2.i to i8
  %temp429.i = insertelement <16 x i8> undef, i8 %a.15.2.i, i32 0
  %vector430.i = shufflevector <16 x i8> %temp429.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..1426.i = xor <16 x i8> %1044, %1045
  %1050 = select <16 x i1> %1046, <16 x i8> zeroinitializer, <16 x i8> %vector428.i
  %1051 = and <16 x i32> %1047, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1052 = lshr <16 x i8> %temp.vect421.i, <i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6, i8 6>
  %1053 = and i32 %a.15.in.5.i, 128
  %1054 = and <16 x i32> %1048, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %1055 = select <16 x i1> %1049, <16 x i8> zeroinitializer, <16 x i8> %vector430.i
  %p.15..2431.i = xor <16 x i8> %1050, %p.15..1426.i
  %a.15.3.i = trunc i32 %a.15.in.3.i to i8
  %temp433.i = insertelement <16 x i8> undef, i8 %a.15.3.i, i32 0
  %vector434.i = shufflevector <16 x i8> %temp433.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1056 = icmp eq <16 x i32> %1051, zeroinitializer
  %1057 = zext <16 x i8> %1052 to <16 x i32>
  %1058 = icmp eq i32 %1053, 0
  %1059 = xor i32 %1028, 27
  %1060 = icmp eq <16 x i32> %1054, zeroinitializer
  %a.15.4.i = trunc i32 %a.15.in.4.i to i8
  %temp435.i = insertelement <16 x i8> undef, i8 %a.15.4.i, i32 0
  %vector436.i = shufflevector <16 x i8> %temp435.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..3432.i = xor <16 x i8> %1055, %p.15..2431.i
  %1061 = select <16 x i1> %1056, <16 x i8> zeroinitializer, <16 x i8> %vector434.i
  %1062 = and <16 x i32> %1057, <i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1, i32 1>
  %a.15.in.6.i = select i1 %1058, i32 %1028, i32 %1059
  %1063 = select <16 x i1> %1060, <16 x i8> zeroinitializer, <16 x i8> %vector436.i
  %p.15..4437.i = xor <16 x i8> %1061, %p.15..3432.i
  %a.15.5.i = trunc i32 %a.15.in.5.i to i8
  %temp439.i = insertelement <16 x i8> undef, i8 %a.15.5.i, i32 0
  %vector440.i = shufflevector <16 x i8> %temp439.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %1064 = icmp eq <16 x i32> %1062, zeroinitializer
  %1065 = icmp sgt <16 x i8> %temp.vect421.i, <i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1, i8 -1>
  %a.15.6.i = trunc i32 %a.15.in.6.i to i8
  %temp441.i = insertelement <16 x i8> undef, i8 %a.15.6.i, i32 0
  %vector442.i = shufflevector <16 x i8> %temp441.i, <16 x i8> undef, <16 x i32> zeroinitializer
  %p.15..5438.i = xor <16 x i8> %1063, %p.15..4437.i
  %1066 = select <16 x i1> %1064, <16 x i8> zeroinitializer, <16 x i8> %vector440.i
  %1067 = select <16 x i1> %1065, <16 x i8> zeroinitializer, <16 x i8> %vector442.i
  %p.15..6443.i = xor <16 x i8> %1066, %p.15..5438.i
  %p.15..7444.i = xor <16 x i8> %1067, %p.15..6443.i
  %1068 = xor <16 x i8> %p.9..7327.i, %vectorPHI288.i
  store <16 x i8> %1068, <16 x i8>* %CastToValueType1084.i, align 16
  %1069 = xor <16 x i8> %p.11..7366.i, %vectorPHI287.i
  store <16 x i8> %1069, <16 x i8>* %CastToValueType1093.i, align 16
  %1070 = xor <16 x i8> %p.13..7405.i, %vectorPHI286.i
  store <16 x i8> %1070, <16 x i8>* %CastToValueType1102.i, align 16
  %1071 = xor <16 x i8> %p.15..7444.i, %vectorPHI.i
  store <16 x i8> %1071, <16 x i8>* %CastToValueType1111.i, align 16
  %exitcond.i = icmp eq i64 %tmp.i, 3
  br i1 %exitcond.i, label %._crit_edge66.i, label %607

._crit_edge66.i:                                  ; preds = %607
  %"&(pSB[currWI].offset)1113.i" = add nuw i64 %CurrSBIndex..3.i, 608
  %"&pSB[currWI].offset1114.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1113.i"
  %CastToValueType1115.i = bitcast i8* %"&pSB[currWI].offset1114.i" to <16 x i8>*
  %loadedValue1116.i = load <16 x i8>* %CastToValueType1115.i, align 16
  %extract507.i = extractelement <16 x i8> %loadedValue1116.i, i32 15
  %"&(pSB[currWI].offset)1104.i" = add nuw i64 %CurrSBIndex..3.i, 592
  %"&pSB[currWI].offset1105.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1104.i"
  %CastToValueType1106.i = bitcast i8* %"&pSB[currWI].offset1105.i" to <16 x i8>*
  %loadedValue1107.i = load <16 x i8>* %CastToValueType1106.i, align 16
  %extract491.i = extractelement <16 x i8> %loadedValue1107.i, i32 15
  %"&(pSB[currWI].offset)1095.i" = add nuw i64 %CurrSBIndex..3.i, 576
  %"&pSB[currWI].offset1096.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1095.i"
  %CastToValueType1097.i = bitcast i8* %"&pSB[currWI].offset1096.i" to <16 x i8>*
  %loadedValue1098.i = load <16 x i8>* %CastToValueType1097.i, align 16
  %extract475.i = extractelement <16 x i8> %loadedValue1098.i, i32 15
  %"&(pSB[currWI].offset)1086.i" = add nuw i64 %CurrSBIndex..3.i, 560
  %"&pSB[currWI].offset1087.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1086.i"
  %CastToValueType1088.i = bitcast i8* %"&pSB[currWI].offset1087.i" to <16 x i8>*
  %loadedValue1089.i = load <16 x i8>* %CastToValueType1088.i, align 16
  %extract459.i = extractelement <16 x i8> %loadedValue1089.i, i32 15
  %1072 = insertelement <4 x i8> undef, i8 %extract459.i, i32 0
  %1073 = insertelement <4 x i8> %1072, i8 %extract475.i, i32 1
  %1074 = insertelement <4 x i8> %1073, i8 %extract491.i, i32 2
  %1075 = insertelement <4 x i8> %1074, i8 %extract507.i, i32 3
  %"&(pSB[currWI].offset)951.i" = add nuw i64 %CurrSBIndex..3.i, 432
  %"&pSB[currWI].offset952.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)951.i"
  %CastToValueType953.i = bitcast i8* %"&pSB[currWI].offset952.i" to <4 x i8> addrspace(3)**
  %loadedValue954.i = load <4 x i8> addrspace(3)** %CastToValueType953.i, align 8
  store <4 x i8> %1075, <4 x i8> addrspace(3)* %loadedValue954.i, align 4
  %check.WI.iter1722.i = icmp ult i64 %CurrWI..3.i, %31
  br i1 %check.WI.iter1722.i, label %thenBB1719.i, label %SyncBB1716.i

thenBB1719.i:                                     ; preds = %._crit_edge66.i
  %"CurrWI++1723.i" = add nuw i64 %CurrWI..3.i, 1
  %"loadedCurrSB+Stride1725.i" = add nuw i64 %CurrSBIndex..3.i, 1712
  br label %SyncBB.i

SyncBB1716.i:                                     ; preds = %thenBB1726.i, %._crit_edge66.i, %thenBB.i
  %CurrSBIndex..1.i = phi i64 [ %"loadedCurrSB+Stride1732.i", %thenBB1726.i ], [ %"loadedCurrSB+Stride.i", %thenBB.i ], [ 0, %._crit_edge66.i ]
  %currBarrier.0.i = phi i32 [ %currBarrier.1.i, %thenBB1726.i ], [ %currBarrier.1.i, %thenBB.i ], [ 5, %._crit_edge66.i ]
  %CurrWI..1.i = phi i64 [ %"CurrWI++1730.i", %thenBB1726.i ], [ %"CurrWI++.i", %thenBB.i ], [ 0, %._crit_edge66.i ]
  %"&(pSB[currWI].offset)956.i" = add nuw i64 %CurrSBIndex..1.i, 432
  %"&pSB[currWI].offset957.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)956.i"
  %CastToValueType958.i = bitcast i8* %"&pSB[currWI].offset957.i" to <4 x i8> addrspace(3)**
  %loadedValue959.i = load <4 x i8> addrspace(3)** %CastToValueType958.i, align 8
  %1076 = load <4 x i8> addrspace(3)* %loadedValue959.i, align 4
  %scalar89.i = extractelement <4 x i8> %1076, i32 0
  %scalar90.i = extractelement <4 x i8> %1076, i32 1
  %scalar91.i = extractelement <4 x i8> %1076, i32 2
  %scalar92.i = extractelement <4 x i8> %1076, i32 3
  %"&(pSB[currWI].offset)997.i" = add nuw i64 %CurrSBIndex..1.i, 456
  %"&pSB[currWI].offset998.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)997.i"
  %CastToValueType999.i = bitcast i8* %"&pSB[currWI].offset998.i" to i32*
  %loadedValue1000.i = load i32* %CastToValueType999.i, align 4
  %1077 = zext i32 %loadedValue1000.i to i64
  %1078 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %1077
  %1079 = load <4 x i8> addrspace(1)* %1078, align 4
  %scalar93.i = extractelement <4 x i8> %1079, i32 0
  %scalar94.i = extractelement <4 x i8> %1079, i32 1
  %scalar95.i = extractelement <4 x i8> %1079, i32 2
  %scalar96.i = extractelement <4 x i8> %1079, i32 3
  %1080 = xor i8 %scalar89.i, %scalar93.i
  %"&(pSB[currWI].offset)1118.i" = add nuw i64 %CurrSBIndex..1.i, 624
  %"&pSB[currWI].offset1119.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1118.i"
  store i8 %1080, i8* %"&pSB[currWI].offset1119.i", align 1
  %1081 = xor i8 %scalar90.i, %scalar94.i
  %"&(pSB[currWI].offset)1122.i" = add nuw i64 %CurrSBIndex..1.i, 625
  %"&pSB[currWI].offset1123.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1122.i"
  store i8 %1081, i8* %"&pSB[currWI].offset1123.i", align 1
  %1082 = xor i8 %scalar91.i, %scalar95.i
  %"&(pSB[currWI].offset)1126.i" = add nuw i64 %CurrSBIndex..1.i, 626
  %"&pSB[currWI].offset1127.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1126.i"
  store i8 %1082, i8* %"&pSB[currWI].offset1127.i", align 1
  %1083 = xor i8 %scalar92.i, %scalar96.i
  %"&(pSB[currWI].offset)1130.i" = add nuw i64 %CurrSBIndex..1.i, 627
  %"&pSB[currWI].offset1131.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1130.i"
  store i8 %1083, i8* %"&pSB[currWI].offset1131.i", align 1
  %temp.vect124.i = insertelement <4 x i8> undef, i8 %1080, i32 0
  %temp.vect125.i = insertelement <4 x i8> %temp.vect124.i, i8 %1081, i32 1
  %temp.vect126.i = insertelement <4 x i8> %temp.vect125.i, i8 %1082, i32 2
  %temp.vect127.i = insertelement <4 x i8> %temp.vect126.i, i8 %1083, i32 3
  %"&(pSB[currWI].offset)537.i" = add nuw i64 %CurrSBIndex..1.i, 288
  %"&pSB[currWI].offset538.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)537.i"
  %CastToValueType539.i = bitcast i8* %"&pSB[currWI].offset538.i" to <4 x i8> addrspace(3)**
  %loadedValue540.i = load <4 x i8> addrspace(3)** %CastToValueType539.i, align 8
  store <4 x i8> %temp.vect127.i, <4 x i8> addrspace(3)* %loadedValue540.i, align 4
  %"&(pSB[currWI].offset)983.i" = add nuw i64 %CurrSBIndex..1.i, 452
  %"&pSB[currWI].offset984.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)983.i"
  %CastToValueType985.i = bitcast i8* %"&pSB[currWI].offset984.i" to i32*
  %loadedValue986.i = load i32* %CastToValueType985.i, align 4
  %indvar.next80.i = add i32 %loadedValue986.i, 1
  %"&(pSB[currWI].offset)1134.i" = add nuw i64 %CurrSBIndex..1.i, 628
  %"&pSB[currWI].offset1135.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1134.i"
  %CastToValueType1136.i = bitcast i8* %"&pSB[currWI].offset1135.i" to i32*
  store i32 %indvar.next80.i, i32* %CastToValueType1136.i, align 4
  br label %192

"Barrier BB508.i":                                ; preds = %shiftRows.exit.i
  %"&(pSB[currWI].offset)1042.i" = add nuw i64 %CurrSBIndex..2.i, 472
  %"&pSB[currWI].offset1043.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1042.i"
  %CastToValueType1044.i = bitcast i8* %"&pSB[currWI].offset1043.i" to <4 x i8>*
  %loadedValue1045.i = load <4 x i8>* %CastToValueType1044.i, align 4
  %scalar100.i = extractelement <4 x i8> %loadedValue1045.i, i32 3
  %"&(pSB[currWI].offset)1047.i" = add nuw i64 %CurrSBIndex..2.i, 472
  %"&pSB[currWI].offset1048.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1047.i"
  %CastToValueType1049.i = bitcast i8* %"&pSB[currWI].offset1048.i" to <4 x i8>*
  %loadedValue1050.i = load <4 x i8>* %CastToValueType1049.i, align 4
  %scalar99.i = extractelement <4 x i8> %loadedValue1050.i, i32 2
  %"&(pSB[currWI].offset)1052.i" = add nuw i64 %CurrSBIndex..2.i, 472
  %"&pSB[currWI].offset1053.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1052.i"
  %CastToValueType1054.i = bitcast i8* %"&pSB[currWI].offset1053.i" to <4 x i8>*
  %loadedValue1055.i = load <4 x i8>* %CastToValueType1054.i, align 4
  %scalar98.i = extractelement <4 x i8> %loadedValue1055.i, i32 1
  %"&(pSB[currWI].offset)1057.i" = add nuw i64 %CurrSBIndex..2.i, 472
  %"&pSB[currWI].offset1058.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)1057.i"
  %CastToValueType1059.i = bitcast i8* %"&pSB[currWI].offset1058.i" to <4 x i8>*
  %loadedValue1060.i = load <4 x i8>* %CastToValueType1059.i, align 4
  %scalar97.i = extractelement <4 x i8> %loadedValue1060.i, i32 0
  %"&(pSB[currWI].offset)519.i" = add nuw i64 %CurrSBIndex..2.i, 272
  %"&pSB[currWI].offset520.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)519.i"
  %CastToValueType521.i = bitcast i8* %"&pSB[currWI].offset520.i" to i32*
  %loadedValue522.i = load i32* %CastToValueType521.i, align 4
  %1084 = add i32 %loadedValue522.i, %35
  %1085 = zext i32 %1084 to i64
  %1086 = getelementptr inbounds <4 x i8> addrspace(1)* %7, i64 %1085
  %1087 = load <4 x i8> addrspace(1)* %1086, align 4
  %scalar101.i = extractelement <4 x i8> %1087, i32 0
  %scalar102.i = extractelement <4 x i8> %1087, i32 1
  %scalar103.i = extractelement <4 x i8> %1087, i32 2
  %scalar104.i = extractelement <4 x i8> %1087, i32 3
  %1088 = xor i8 %scalar97.i, %scalar101.i
  %1089 = xor i8 %scalar98.i, %scalar102.i
  %1090 = xor i8 %scalar99.i, %scalar103.i
  %1091 = xor i8 %scalar100.i, %scalar104.i
  %temp.vect128.i = insertelement <4 x i8> undef, i8 %1088, i32 0
  %temp.vect129.i = insertelement <4 x i8> %temp.vect128.i, i8 %1089, i32 1
  %temp.vect130.i = insertelement <4 x i8> %temp.vect129.i, i8 %1090, i32 2
  %temp.vect131.i = insertelement <4 x i8> %temp.vect130.i, i8 %1091, i32 3
  %"&(pSB[currWI].offset)528.i" = add nuw i64 %CurrSBIndex..2.i, 280
  %"&pSB[currWI].offset529.i" = getelementptr inbounds i8* %34, i64 %"&(pSB[currWI].offset)528.i"
  %CastToValueType530.i = bitcast i8* %"&pSB[currWI].offset529.i" to i64*
  %loadedValue531.i = load i64* %CastToValueType530.i, align 8
  %1092 = getelementptr inbounds <4 x i8> addrspace(1)* %1, i64 %loadedValue531.i
  store <4 x i8> %temp.vect131.i, <4 x i8> addrspace(1)* %1092, align 4
  %check.WI.iter1729.i = icmp ult i64 %CurrWI..2.i, %31
  br i1 %check.WI.iter1729.i, label %thenBB1726.i, label %____Vectorized_.AESEncrypt_separated_args.exit

thenBB1726.i:                                     ; preds = %"Barrier BB508.i"
  %"CurrWI++1730.i" = add nuw i64 %CurrWI..2.i, 1
  %"loadedCurrSB+Stride1732.i" = add nuw i64 %CurrSBIndex..2.i, 1712
  %cond1.i = icmp eq i32 %currBarrier.1.i, 14
  br i1 %cond1.i, label %SyncBB1715.i, label %SyncBB1716.i

____Vectorized_.AESEncrypt_separated_args.exit:   ; preds = %"Barrier BB508.i"
  ret void
}

!opencl.kernels = !{!0, !2}

!0 = metadata !{void (<4 x i8> addrspace(1)*, <4 x i8> addrspace(1)*, <4 x i8> addrspace(1)*, i8 addrspace(1)*, <4 x i8> addrspace(3)*, <4 x i8> addrspace(3)*, i32, i32, i8 addrspace(3)*, %struct.WorkDim*, i64*, %struct.PaddedDimId*, %struct.PaddedDimId*, i64*, i64, i8*, i64*)* @__AESEncrypt_separated_args, metadata !1, metadata !1, metadata !"", metadata !"uchar4 __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(1))) *, uchar __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(3))) *, uchar4 __attribute__((address_space(3))) *, uint const, uint const", metadata !"opencl_AESEncrypt_locals_anchor", void (i8*)* @AESEncrypt}
!1 = metadata !{i32 0, i32 0, i32 0}
!2 = metadata !{void (<4 x i8> addrspace(1)*, <4 x i8> addrspace(1)*, <4 x i8> addrspace(1)*, i8 addrspace(1)*, <4 x i8> addrspace(3)*, <4 x i8> addrspace(3)*, i32, i32, i8 addrspace(3)*, %struct.WorkDim*, i64*, %struct.PaddedDimId*, %struct.PaddedDimId*, i64*, i64, i8*, i64*)* @__AESDecrypt_separated_args, metadata !1, metadata !1, metadata !"", metadata !"uchar4 __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(1))) *, uchar __attribute__((address_space(1))) *, uchar4 __attribute__((address_space(3))) *, uchar4 __attribute__((address_space(3))) *, uint const, uint const", metadata !"opencl_AESDecrypt_locals_anchor", void (i8*)* @AESDecrypt}
